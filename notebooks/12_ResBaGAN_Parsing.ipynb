{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7977c66",
   "metadata": {},
   "source": [
    "# Fase 1.2: Convertir la ResBaGAN inicial de PyTorch a ONXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c92a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import math,random,struct,os,time,sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn import preprocessing\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funciones y parámetros de la ResBaGAN\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import resbagan_networks\n",
    "import resbagan_datasets\n",
    "from cnn21_pix import read_pgm, save_pgm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a944779",
   "metadata": {},
   "source": [
    "## 1. Conversión de la ResBaGAN inicial de PyTorch a ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d4b15",
   "metadata": {},
   "source": [
    "### 1.1. Conversión del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrada\n",
    "\n",
    "batch_size = 100\n",
    "B = 5\n",
    "sizex = 32\n",
    "sizey = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros y cargar datos\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "MODEL=\"../results/models/model_ResBaGAN.pt\"\n",
    "\n",
    "# Queremos usar todos los datos para la inferencia\n",
    "SAMPLES=[0.0,0.0]\n",
    "\n",
    "# Carga de datos para la inferencia en el discriminador\n",
    "dataset = resbagan_datasets.HyperDataset(\n",
    "    \"oitaven_river\", segmented=False, patch_size=32, ratios=(SAMPLES[0], SAMPLES[1]))\n",
    "\n",
    "# Almacenamos las dimensiones en variables\n",
    "H = dataset.height\n",
    "V = dataset.width\n",
    "\n",
    "samples = dataset.ordered_test_set['samples']\n",
    "\n",
    "# Obtenemos el array de gt\n",
    "truth = dataset.gt.flatten()\n",
    "# Obtenemos un array de indices para test\n",
    "test = dataset.test_index_list\n",
    "\n",
    "# Obtenemos el numero de clases y el numero de clases no vacias para test\n",
    "nclases = dataset.classes_count\n",
    "nclases_no_vacias = 0\n",
    "for i in range(nclases):\n",
    "    clase_actual = i + 1\n",
    "    if any(truth[idx] == clase_actual for idx in test):\n",
    "        nclases_no_vacias += 1\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# The custom HyperDataset object contains all the train, validation and test data\n",
    "#   --> But it will wrapped into a PyTorch data feeder for convenience\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d64089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo\n",
    "\n",
    "cuda=True if torch.cuda.is_available() else False\n",
    "device=torch.device('cuda' if cuda else 'cpu')\n",
    "device='cpu'\n",
    "\n",
    "if torch.backends.cudnn.is_available():\n",
    "    print('* Activando CUDNN')\n",
    "    torch.backends.cudnn.enabled=True\n",
    "    torch.backends.cudnn.beBhmark=True\n",
    "\n",
    "hyperparams = {\n",
    "    \"latent_size\":   128,\n",
    "    \"activation\":    \"lrelu\",\n",
    "    \"p_dropout\":     0.05,\n",
    "    \"weight_init\":   \"xavier\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\":        100,\n",
    "    \"batch_size\":    100,\n",
    "    \"num_workers\":   4,\n",
    "    \"device\":        \"cpu\",\n",
    "}\n",
    "\n",
    "# Cargar el discriminador\n",
    "model = resbagan_networks.ResBaGAN_Discriminator(dataset=dataset, device=hyperparams[\"device\"], hyperparams=hyperparams)\n",
    "\n",
    "# Cargar los pesos guardados\n",
    "model.load_state_dict(torch.load(\"../results/models/model_ResBaGAN_discriminator.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función personalizada para la operación torch.vdot\n",
    "# Esto se debe a que el conversor no soporta esta operación\n",
    "\n",
    "def vdot_replacement(a, b):\n",
    "    return torch.sum(torch.conj(a) * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos la nueva operación torch.vdot a la función personalizada\n",
    "\n",
    "torch.vdot = vdot_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c472f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el modelo a ONNX\n",
    "\n",
    "# Crear un tensor de entrada de ejemplo \n",
    "# El tensor tendrá tamanho (batch_size, canales, altura, ancho)\n",
    "# Lo ajustamos al rango [-1, 1]\n",
    "input_tensor = (torch.rand(batch_size, B, sizex, sizey) * 2 - 1).to(device)\n",
    "\n",
    "# Exportamos el modelo a onnx\n",
    "onnx_filename = \"../results/models/model_ResBaGAN_discriminator.onnx\"\n",
    "torch.onnx.export(\n",
    "    model, # Modelo entrenado\n",
    "    input_tensor, # Entrada de ejemplo\n",
    "    onnx_filename, # Ruta de salida del archivo ONNX\n",
    "    export_params=True, # Exportar parámetros del modelo\n",
    "    opset_version=12, # Versión de opset\n",
    "    do_constant_folding=True, # Optimización de constantes\n",
    "    input_names=['input'], # Nombre de la entrada\n",
    "    output_names=['output'], # Nombre de la salida\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf552f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar que la conversión es correcta\n",
    "\n",
    "onnx_model = onnx.load(onnx_filename)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f903f9",
   "metadata": {},
   "source": [
    "### 1.2. Evaluación del modelo en ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los modelos\n",
    "\n",
    "# Cargar el modelo convertido a ONNX\n",
    "ort_session = ort.InferenceSession(\"../results/models/model_ResBaGAN_discriminator.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar la diferencia de precisión\n",
    "\n",
    "# Crear tensor de entrada de prueba\n",
    "input_tensor = (torch.rand(1, B, sizex, sizey) * 2 - 1).to(device)\n",
    "\n",
    "# Salida del modelo PyTorch\n",
    "with torch.no_grad():\n",
    "    output_torch, _ = model(input_tensor)\n",
    "\n",
    "# Salida del modelo ONNX\n",
    "output_onnx = ort_session.run(None, {'input': input_tensor.cpu().numpy()})[0]\n",
    "\n",
    "# Comparar las diferencias\n",
    "error = np.abs(output_torch - output_onnx).mean()\n",
    "print(f'Error medio entre PyTorch y ONNX: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos e inferencia completa para el modelo en ONNX\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir parámetros y cargar datos\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "MODEL=\"../results/models/model_ResBaGAN.pt\"\n",
    "\n",
    "# Queremos usar todos los datos para la inferencia\n",
    "SAMPLES=[0.0,0.0]\n",
    "\n",
    "# Carga de datos para la inferencia en el discriminador\n",
    "dataset = resbagan_datasets.HyperDataset(\n",
    "    \"oitaven_river\", segmented=False, patch_size=32, ratios=(SAMPLES[0], SAMPLES[1]))\n",
    "\n",
    "# Almacenamos las dimensiones en variables\n",
    "H = dataset.height\n",
    "V = dataset.width\n",
    "\n",
    "samples = dataset.ordered_test_set['samples']\n",
    "\n",
    "# Obtenemos el array de gt\n",
    "truth = dataset.gt.flatten()\n",
    "# Obtenemos un array de indices para test\n",
    "test = dataset.test_index_list\n",
    "\n",
    "# Obtenemos el numero de clases y el numero de clases no vacias para test\n",
    "nclases = dataset.classes_count\n",
    "nclases_no_vacias = 0\n",
    "for i in range(nclases):\n",
    "    clase_actual = i + 1\n",
    "    if any(truth[idx] == clase_actual for idx in test):\n",
    "        nclases_no_vacias += 1\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# The custom HyperDataset object contains all the train, validation and test data\n",
    "#   --> But it will wrapped into a PyTorch data feeder for convenience\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "output=np.zeros(H*V, dtype=np.uint8)\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "\n",
    "# Realizar la predicción\n",
    "total=0\n",
    "for batch_id, (inputs, labels, targets_pixel_level) in enumerate(data_loader):\n",
    "    inputs_np=inputs.numpy()\n",
    "    # Realizar la inferencia\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    predicted=np.argmax(outputs_discriminator, axis=1)\n",
    "    \n",
    "    for i in range(len(predicted)):\n",
    "        output[test[total+i]]=np.uint8(predicted[i]+1)\n",
    "    total+=labels.size(0)\n",
    "    if(total%100000==0): print('  Test:',total,'/', len(dataset))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Prediction time: {:.4f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a07861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el output\n",
    "\n",
    "np.save('../results/predictions/predictions_ResBaGAN_discriminator_onnx.npy', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32045d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el output\n",
    "\n",
    "output = np.load('../results/predictions/predictions_ResBaGAN_discriminator_onnx.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b073cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el desempeño del modelo\n",
    "\n",
    "# Precisiones a nivel de clase\n",
    "correct=0; total=0; AA=0; OA=0\n",
    "class_correct=[0]*(nclases+1)\n",
    "class_total=[0]*(nclases+1)\n",
    "class_aa=[0]*(nclases+1)\n",
    "\n",
    "for i in test:\n",
    "    if(output[i]==0 or truth[i]==0): continue\n",
    "    total+=1; class_total[truth[i]]+=1\n",
    "    if(output[i]==truth[i]):\n",
    "          correct+=1\n",
    "          class_correct[truth[i]]+=1\n",
    "for i in range(1,nclases+1):\n",
    "    if(class_total[i]!=0): class_aa[i]=100*class_correct[i]/class_total[i]\n",
    "    else: class_aa[i]=0\n",
    "    AA+=class_aa[i]\n",
    "OA=100*correct/total; AA=AA/nclases_no_vacias\n",
    "\n",
    "for i in range(1,nclases+1): print('  Class %02d: %02.02f'%(i,class_aa[i]))\n",
    "print('* Accuracy (pixels) OA=%02.02f, AA=%02.02f'%(OA,AA))\n",
    "print('  total:',total,'correct:',correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la salida\n",
    "\n",
    "save_pgm(output,V,H,nclases,'../results/predictions/predictions_ResBaGAN_discriminator_onnx.pgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a379375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la salida\n",
    "\n",
    "OUTPUT='../results/predictions/predictions_ResBaGAN_discriminator_onnx.pgm'\n",
    "\n",
    "(imagen_output, H, V) = read_pgm(OUTPUT)\n",
    "\n",
    "# Convertir la lista a array y redimensionar\n",
    "imagen_output = np.array(imagen_output, dtype=np.uint8).reshape(V, H)\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(imagen_output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61a4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77bb25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hyper_env] *",
   "language": "python",
   "name": "conda-env-hyper_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
