{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7977c66",
   "metadata": {},
   "source": [
    "# Fase 0.1: Convertir la CNN inicial de PyTorch a ONXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c92a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import math,random,struct,os,time,sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn import preprocessing\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Funciones y parámetros de la CNN base\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from cnn21_pix import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a944779",
   "metadata": {},
   "source": [
    "## 1. Conversión de la CNN inicial de PyTorch a ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d4b15",
   "metadata": {},
   "source": [
    "### 1.1. Conversión del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0bf853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrada\n",
    "batch_size = 100\n",
    "B = 5\n",
    "sizex = 32\n",
    "sizey = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c472f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el modelo a ONNX\n",
    "\n",
    "device='cpu'\n",
    "model = torch.load(\"../results/models/model_cnn21.pth\", weights_only=False)\n",
    "model.eval()\n",
    "\n",
    "# Crear un tensor de entrada de ejemplo \n",
    "# El tensor tendrá tamanho (batch_size, canales, altura, ancho)\n",
    "input_tensor = torch.randn(batch_size, B, sizex, sizey).to(device)\n",
    "\n",
    "# Exportamos el modelo a onnx\n",
    "onnx_filename = \"../results/models/model_cnn21.onnx\"\n",
    "torch.onnx.export(\n",
    "    model, # Modelo entrenado\n",
    "    input_tensor, # Entrada de ejemplo\n",
    "    onnx_filename, # Ruta de salida del archivo ONNX\n",
    "    export_params=True, # Exportar parámetros del modelo\n",
    "    opset_version=12, # Versión de opset\n",
    "    do_constant_folding=True, # Optimización de constantes\n",
    "    input_names=['input'], # Nombre de la entrada\n",
    "    output_names=['output'], # Nombre de la salida\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf552f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar que la conversión es correcta\n",
    "\n",
    "onnx_model = onnx.load(onnx_filename)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f903f9",
   "metadata": {},
   "source": [
    "### 1.2. Evaluación del modelo en ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8c36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los modelos\n",
    "\n",
    "# Cargar el modelo original de PyTorch\n",
    "model = torch.load(\"../results/models/model_cnn21.pth\", weights_only=False)\n",
    "model.eval()\n",
    "\n",
    "# Cargar el modelo convertido a ONNX\n",
    "ort_session = ort.InferenceSession(\"../results/models/model_cnn21.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a4d8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error medio entre PyTorch y ONNX: 1.1444091796875e-05\n"
     ]
    }
   ],
   "source": [
    "# Comprobar la diferencia de precisión\n",
    "\n",
    "# Crear tensor de entrada de prueba\n",
    "input_tensor = torch.randn(1, B, sizex, sizey).to(device)\n",
    "\n",
    "# Salida del modelo PyTorch\n",
    "with torch.no_grad():\n",
    "    output_torch = model(input_tensor).cpu().numpy()\n",
    "\n",
    "# Salida del modelo ONNX\n",
    "output_onnx = ort_session.run(None, {'input': input_tensor.cpu().numpy()})[0]\n",
    "\n",
    "# Comparar las diferencias\n",
    "error = np.abs(output_torch - output_onnx).mean()\n",
    "print(f'Error medio entre PyTorch y ONNX: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234797c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos e inferencia completa para el modelo en ONNX\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir parámetros y cargar datos\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "\n",
    "# Queremos usar todos los datos para la inferencia\n",
    "SAMPLES=[0,0]\n",
    "PAD=1\n",
    "AUM=0\n",
    "\n",
    "# Carga de datos\n",
    "(datos,H,V,B)=read_raw(DATASET)\n",
    "(truth,H1,V1)=read_pgm(GT)\n",
    "\n",
    "# Durante la ejecucion de la red vamos a coger patches de tamano cuadrado\n",
    "sizex=32; sizey=32 \n",
    "\n",
    "# Hacemos padding en el dataset para poder aprovechar hasta el borde\n",
    "if(PAD):\n",
    "    datos=torch.FloatTensor(np.pad(datos,((sizey//2,sizey//2),(sizex//2,sizex//2),(0,0)),'symmetric'))\n",
    "    H=H+2*(sizex//2); V=V+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(-1,H1))\n",
    "    truth=np.pad(truth,((sizey//2,sizey//2),(sizex//2,sizex//2)),'constant')\n",
    "    H1=H1+2*(sizex//2); V1=V1+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(H1*V1))\n",
    "    \n",
    "# Necesitamos los datos en band-vector para hacer convoluciones\n",
    "datos=np.transpose(datos,(2,0,1))\n",
    "\n",
    "# Seleccionar conjunto de test (en este caso es una predicción)\n",
    "(train,val,test,nclases,nclases_no_vacias)=select_training_samples(truth,H,V,sizex,sizey,SAMPLES)\n",
    "dataset_test=HyperDataset(datos,truth,test,H,V,sizex,sizey)\n",
    "print('  - test dataset:',len(dataset_test))\n",
    "\n",
    "# Dataloader\n",
    "batch_size=100 # defecto 100\n",
    "test_loader=DataLoader(dataset_test,batch_size,shuffle=False)\n",
    "\n",
    "output=np.zeros(H*V,dtype=np.uint8)\n",
    "\n",
    "# Modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Realizar la predicción\n",
    "total=0\n",
    "for (inputs, labels) in test_loader:\n",
    "    # Convertir inputs a un formato adecuado para ONNX (numpy array)\n",
    "    inputs_np = inputs.numpy()\n",
    "    \n",
    "    # Realizar la inferencia\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    \n",
    "    predicted=np.argmax(outputs[0], axis=1) # outputs[0] contiene las predicciones\n",
    "    \n",
    "    # Asignar las predicciones al array de salida\n",
    "    for i in range(len(predicted)):\n",
    "        output[test[total+i]]=np.uint8(predicted[i]+1)\n",
    "    total+=labels.size(0)\n",
    "    \n",
    "    # Mostrar el progreso\n",
    "    if(total%100000==0): print('  Test:',total,'/',len(dataset_test))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Prediction time: {:.4f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963827dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el output\n",
    "\n",
    "np.save('../results/predictions/predictions_cnn21_onnx.npy', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el output\n",
    "\n",
    "output = np.load('../results/predictions/predictions_cnn21_onnx.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b073cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el desempeño del modelo\n",
    "\n",
    "# Precisiones a nivel de clase\n",
    "correct=0; total=0; AA=0; OA=0\n",
    "class_correct=[0]*(nclases+1)\n",
    "class_total=[0]*(nclases+1)\n",
    "class_aa=[0]*(nclases+1)\n",
    "\n",
    "for i in test:\n",
    "    if(output[i]==0 or truth[i]==0): continue\n",
    "    total+=1; class_total[truth[i]]+=1\n",
    "    if(output[i]==truth[i]):\n",
    "          correct+=1\n",
    "          class_correct[truth[i]]+=1\n",
    "for i in range(1,nclases+1):\n",
    "    if(class_total[i]!=0): class_aa[i]=100*class_correct[i]/class_total[i]\n",
    "    else: class_aa[i]=0\n",
    "    AA+=class_aa[i]\n",
    "OA=100*correct/total; AA=AA/nclases_no_vacias\n",
    "\n",
    "for i in range(1,nclases+1): print('  Class %02d: %02.02f'%(i,class_aa[i]))\n",
    "print('* Accuracy (pixels) OA=%02.02f, AA=%02.02f'%(OA,AA))\n",
    "print('  total:',total,'correct:',correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la salida\n",
    "\n",
    "if(PAD):\n",
    "    output=np.reshape(output,(-1,H1))\n",
    "    output=output[sizey//2:V1-sizey//2,sizex//2:H1-sizex//2]\n",
    "    H1=H1-2*(sizex//2); V1=V1-2*(sizey//2)\n",
    "    output=np.reshape(output,(H1*V1))\n",
    "\n",
    "save_pgm(output,H1,V1,nclases,'../results/predictions/predictions_cnn21_onnx.pgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a379375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la salida\n",
    "\n",
    "OUTPUT='../results/predictions/predictions_cnn21_onnx.pgm'\n",
    "\n",
    "(imagen_output, H1, V1) = read_pgm(OUTPUT)\n",
    "\n",
    "# Convertir la lista a array y redimensionar\n",
    "imagen_output = np.array(imagen_output, dtype=np.uint8).reshape(V1, H1)\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(imagen_output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61a4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c74e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hyper_env]",
   "language": "python",
   "name": "conda-env-hyper_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
