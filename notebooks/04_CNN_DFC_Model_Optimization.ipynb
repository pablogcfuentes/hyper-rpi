{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b76dd13",
   "metadata": {},
   "source": [
    "# Fase 0.4: Optimización del modelo en HAR (Hailo Archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from matplotlib import patches\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.python.eager.context import eager_mode\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from itertools import islice\n",
    "\n",
    "# Funciones y parámetros de la CNN base\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from cnn21_pix import *\n",
    "\n",
    "# import the hailo sdk client relevant classes\n",
    "from hailo_sdk_client import ClientRunner, InferenceContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d16a4d",
   "metadata": {},
   "source": [
    "## 1. Optimización detallada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f860d1c",
   "metadata": {},
   "source": [
    "### 1.1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a555f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "\n",
    "# Queremos usar todos los datos para la inferencia\n",
    "SAMPLES=[0,0]\n",
    "PAD=1\n",
    "AUM=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "\n",
    "(datos,H,V,B)=read_raw(DATASET)\n",
    "(truth,H1,V1)=read_pgm(GT)\n",
    "\n",
    "# Durante la ejecucion de la red vamos a coger patches de tamano cuadrado\n",
    "sizex=32; sizey=32 \n",
    "\n",
    "# Hacemos padding en el dataset para poder aprovechar hasta el borde\n",
    "if(PAD):\n",
    "    datos=torch.FloatTensor(np.pad(datos,((sizey//2,sizey//2),(sizex//2,sizex//2),(0,0)),'symmetric'))\n",
    "    H=H+2*(sizex//2); V=V+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(-1,H1))\n",
    "    truth=np.pad(truth,((sizey//2,sizey//2),(sizex//2,sizex//2)),'constant')\n",
    "    H1=H1+2*(sizex//2); V1=V1+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(H1*V1))\n",
    "    \n",
    "# Necesitamos los datos en band-vector para hacer convoluciones\n",
    "datos=np.transpose(datos,(2,0,1))\n",
    "\n",
    "# Seleccionar conjunto de test (en este caso es una predicción)\n",
    "(train,val,test,nclases,nclases_no_vacias)=select_training_samples(truth,H,V,sizex,sizey,SAMPLES)\n",
    "dataset_test=HyperDataset(datos,truth,test,H,V,sizex,sizey)\n",
    "print('  - test dataset:',len(dataset_test))\n",
    "\n",
    "# Dataloader\n",
    "batch_size=100 # defecto 100\n",
    "# Indicamos shuffle = True porque no se evalúa todo el dataset\n",
    "test_loader=DataLoader(dataset_test,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf81525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo convertido a ONNX\n",
    "\n",
    "ort_session = ort.InferenceSession(\"../results/models/model_cnn21.onnx\")\n",
    "\n",
    "# Cargar el modelo en HAR\n",
    "\n",
    "model_name = \"../results/models/model_cnn21\"\n",
    "hailo_model_har_name = f\"{model_name}_hailo_model.har\"\n",
    "assert os.path.isfile(hailo_model_har_name), \"Please provide valid path for HAR file\"\n",
    "runner = ClientRunner(har=hailo_model_har_name, hw_arch=\"hailo8l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0ecb0",
   "metadata": {},
   "source": [
    "### 1.2 Evaluar el modelo en har sin optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a259b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobacion rapida de la diferencia de precisión\n",
    "\n",
    "# Crear tensor de entrada de prueba\n",
    "input_tensor = torch.randn(1, B, sizex, sizey).to(\"cpu\")\n",
    "input_np = input_tensor.cpu().numpy()\n",
    "\n",
    "# Realizar la inferencia en ONNX\n",
    "output_onnx = ort_session.run(None, {'input': input_np})[0]\n",
    "\n",
    "# print(output_onnx)\n",
    "\n",
    "# Realizar la inferencia en HAR\n",
    "with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "    input_har = np.transpose(input_np, (0, 2, 3, 1))\n",
    "\n",
    "    # Realizar la inferencia en el modelo .har\n",
    "    output_har = runner.infer(ctx, input_har)\n",
    "\n",
    "    # print(output_har) \n",
    "\n",
    "# Comparar las diferencias\n",
    "error = np.abs(output_onnx - output_har).mean()\n",
    "print(f'Error medio entre ONNX y HAR: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ef5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# El bucle de inferencia tiene un memory leak que proviene del SDK de hailo con el emulador NATIVE\n",
    "# Se realiza la evaluacion, por tanto, con un unico batch\n",
    "\n",
    "# Inferencia\n",
    "\n",
    "output=np.zeros(H*V,dtype=np.uint8)\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "start_time = time.time()\n",
    "\n",
    "# Realizar la predicción\n",
    "with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "    total=0\n",
    "    for (inputs, labels) in test_loader:\n",
    "        # Convertir inputs a un formato adecuado para Hailo (numpy array)\n",
    "        # Cambiamos de (batch_size, B, sizex, sizey) a (batch_size, sizey, sizex, B)\n",
    "        inputs_np = np.transpose(inputs.numpy(), (0, 3, 2, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_np)\n",
    "        \n",
    "        predicted=np.argmax(native_res, axis=-1)\n",
    "        predicted=predicted.squeeze()\n",
    "        \n",
    "        # Asignar las predicciones al array de salida\n",
    "        for i in range(len(predicted)):\n",
    "            output[test[total+i]]=np.uint8(predicted[i]+1)\n",
    "        total+=labels.size(0)\n",
    "\n",
    "        # Mostrar el progreso\n",
    "        if(total%100000==0): print('  Test:',total,'/',len(dataset_test))\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Prediction time: {:.4f} seconds\".format(end_time - start_time))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en HAR sin optimizacion\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "data_iter = iter(test_loader)\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    inputs, labels = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    preds_onnx=np.argmax(outputs[0], axis=1) # outputs[0] contiene las predicciones\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)\n",
    "        \n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e9139",
   "metadata": {},
   "source": [
    "### 1.3 Aplicar modificaciones de optimización al modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac30ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un model script para el proceso de optimización\n",
    "\n",
    "model_script_lines = [\n",
    "    # Add normalization layer with mean [123.675, 116.28, 103.53] and std [58.395, 57.12, 57.375])\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # For multiple input nodes:\n",
    "    # {normalization_layer_name_1} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_1_from_hn})\\n',\n",
    "    # {normalization_layer_name_2} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_2_from_hn})\\n',\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Load the model script to ClientRunner so it will be considered on optimization\n",
    "runner.load_model_script(\"\".join(model_script_lines))\n",
    "runner.optimize_full_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en HAR con optimizacion\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "data_iter = iter(test_loader)\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    inputs, labels = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    preds_onnx=np.argmax(outputs[0], axis=1) # outputs[0] contiene las predicciones\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_FP_OPTIMIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)\n",
    "        \n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce0f2c",
   "metadata": {},
   "source": [
    "### 1.4 Cuantizar el modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataset de calibración\n",
    "# The original images are being used, just as the input to the SDK_FP_OPTIMIZED emulator\n",
    "total_images = 1050\n",
    "\n",
    "calib_dataset = np.zeros((total_images, sizex, sizey, B), dtype = np.float32)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Seleccionamos batches del dataloader para guardarlos en el dataset\n",
    "for inputs, _ in test_loader:\n",
    "    for img in inputs:\n",
    "        if count >= total_images:\n",
    "            break\n",
    "            \n",
    "        # Los inputs son de la forma (batch_size, B, sizex, sizey)\n",
    "        img_np = img.numpy()\n",
    "        # Trasponemos los inputs a formato (batch_size, sizex, sizey, B)\n",
    "        img_har = np.transpose(img_np, (1, 2, 0))\n",
    "\n",
    "        calib_dataset[count] = img_har\n",
    "        count += 1\n",
    "        \n",
    "    if count >= total_images:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantizar el modelo con el dataset de calibración\n",
    "\n",
    "# For calling Optimize, use the short version: runner.optimize(calib_dataset)\n",
    "# A more general approach is being used here that works also with multiple input nodes.\n",
    "# The calibration dataset could also be a dictionary with the format:\n",
    "# {input_layer_name_1_from_hn: layer_1_calib_dataset, input_layer_name_2_from_hn: layer_2_calib_dataset}\n",
    "hn_layers = runner.get_hn_dict()[\"layers\"]\n",
    "print(\"Input layers are: \")\n",
    "print([layer for layer in hn_layers if hn_layers[layer][\"type\"] == \"input_layer\"])  # See available input layer names\n",
    "calib_dataset_dict = {\"model_cnn21/input_layer1\": calib_dataset}  # In our case there is only one input layer\n",
    "\n",
    "optimization_level = -100\n",
    "compression_level = 0\n",
    "# Mapeamos las proporciones de pesos de 4 bits según el nivel de compresión\n",
    "compression_ratios = {\n",
    "    0: 0.0,\n",
    "    1: 0.2,\n",
    "    2: 0.4,\n",
    "    3: 0.6,\n",
    "    4: 0.8,\n",
    "    5: 1.0\n",
    "}\n",
    "auto_4bit_ratio = compression_ratios.get(compression_level, 0.0)\n",
    "\n",
    "alls_lines = [\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # Batch size is 8 by default; 2 was used for stability on PCs with low amount of RAM / VRAM\n",
    "    f\"model_optimization_flavor(optimization_level={optimization_level}, compression_level={compression_level}, batch_size=8)\\n\",\n",
    "    # The following line is needed because this is a really small model, and the compression_level is always reverted back to 0.'\n",
    "    # To force using compression_level with small models, the following line should be used (compression level=4 equals to 80% 4-bit):\n",
    "    f\"model_optimization_config(compression_params, auto_4bit_weights_ratio={auto_4bit_ratio})\\n\",\n",
    "    # The application of the compression could be seen by the [info] messages: \"Assigning 4bit weight to layer ..\"\n",
    "]\n",
    "\n",
    "runner.load_model_script(\"\".join(alls_lines))\n",
    "\n",
    "runner.optimize(calib_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c487df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en HAR cuantizado\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "data_iter = iter(test_loader)\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    inputs, labels = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    preds_onnx=np.argmax(outputs[0], axis=1) # outputs[0] contiene las predicciones\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_QUANTIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)\n",
    "        \n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eebb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo cuantizado\n",
    "# Let's save the runner's state to a Quantized HAR\n",
    "quantized_model_har_path = f\"{model_name}_quantized_model_o{optimization_level}_c{compression_level}.har\"\n",
    "runner.save_har(quantized_model_har_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24260b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b9b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e8585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e46da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bddfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad4227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f51e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6bf698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f531731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5561f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ada418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fb9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hailo_gpu_env]",
   "language": "python",
   "name": "conda-env-hailo_gpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
