{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b76dd13",
   "metadata": {},
   "source": [
    "# Fase 1.4: Optimización del modelo en HAR (Hailo Archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from matplotlib import patches\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.python.eager.context import eager_mode\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from itertools import islice\n",
    "\n",
    "# Funciones y parámetros de la CNN base\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import resbagan_networks\n",
    "import resbagan_datasets\n",
    "\n",
    "# import the hailo sdk client relevant classes\n",
    "from hailo_sdk_client import ClientRunner, InferenceContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d16a4d",
   "metadata": {},
   "source": [
    "## 1. Optimización detallada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f860d1c",
   "metadata": {},
   "source": [
    "### 1.1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f18540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrada\n",
    "\n",
    "batch_size = 100\n",
    "B = 5\n",
    "sizex = 32\n",
    "sizey = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros y cargar datos\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "MODEL=\"../results/models/model_ResBaGAN.pt\"\n",
    "\n",
    "# Proporción de entrenamiento, validación y test\n",
    "SAMPLES=[0.02,0.01]\n",
    "\n",
    "# Carga de datos para la inferencia en el discriminador\n",
    "dataset = resbagan_datasets.HyperDataset(\n",
    "    \"oitaven_river\", segmented=False, patch_size=32, ratios=(SAMPLES[0], SAMPLES[1]))\n",
    "\n",
    "# Almacenamos las dimensiones en variables\n",
    "H = dataset.height\n",
    "V = dataset.width\n",
    "\n",
    "# En este caso seleccionamos samples aleatorios\n",
    "samples = dataset.test_set['samples']\n",
    "\n",
    "# Obtenemos el array de gt\n",
    "truth = dataset.gt.flatten()\n",
    "# Obtenemos un array de indices para test\n",
    "test = dataset.test_index_list\n",
    "\n",
    "# Obtenemos el numero de clases y el numero de clases no vacias para test\n",
    "nclases = dataset.classes_count\n",
    "nclases_no_vacias = 0\n",
    "for i in range(nclases):\n",
    "    clase_actual = i + 1\n",
    "    if any(truth[idx] == clase_actual for idx in test):\n",
    "        nclases_no_vacias += 1\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# The custom HyperDataset object contains all the train, validation and test data\n",
    "#   --> But it will wrapped into a PyTorch data feeder for convenience\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf81525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo convertido a ONNX\n",
    "\n",
    "ort_session = ort.InferenceSession(\"../results/models/model_ResBaGAN_discriminator.onnx\")\n",
    "\n",
    "# Cargar el modelo en HAR\n",
    "\n",
    "model_name = \"../results/models/model_ResBaGAN_discriminator\"\n",
    "hailo_model_har_name = f\"{model_name}_hailo_model.har\"\n",
    "assert os.path.isfile(hailo_model_har_name), \"Please provide valid path for HAR file\"\n",
    "runner = ClientRunner(har=hailo_model_har_name, hw_arch=\"hailo8l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0ecb0",
   "metadata": {},
   "source": [
    "### 1.2 Evaluar el modelo en har sin optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a259b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobacion rapida de la diferencia de precisión\n",
    "\n",
    "# Crear tensor de entrada de prueba\n",
    "input_tensor = (torch.rand(1, B, sizex, sizey) * 2 - 1).to(\"cpu\")\n",
    "input_np = input_tensor.cpu().numpy()\n",
    "\n",
    "# Realizar la inferencia en ONNX\n",
    "output_onnx = ort_session.run(None, {'input': input_np})[0]\n",
    "\n",
    "print(output_onnx)\n",
    "\n",
    "# Realizar la inferencia en HAR\n",
    "with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "    input_har = np.transpose(input_np, (0, 2, 3, 1))\n",
    "\n",
    "    # Realizar la inferencia en el modelo .har\n",
    "    output_har = runner.infer(ctx, input_har)[0]\n",
    "\n",
    "    print(output_har) \n",
    "\n",
    "# Comparar las diferencias\n",
    "error = np.abs(output_onnx - output_har).mean()\n",
    "print(f'Error medio entre ONNX y HAR: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en HAR sin optimizacion\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e9139",
   "metadata": {},
   "source": [
    "### 1.3 Aplicar modificaciones de optimización al modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac30ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un model script para el proceso de optimización\n",
    "\n",
    "model_script_lines = [\n",
    "    # Add normalization layer with mean [123.675, 116.28, 103.53] and std [58.395, 57.12, 57.375])\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # For multiple input nodes:\n",
    "    # {normalization_layer_name_1} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_1_from_hn})\\n',\n",
    "    # {normalization_layer_name_2} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_2_from_hn})\\n',\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Load the model script to ClientRunner so it will be considered on optimization\n",
    "runner.load_model_script(\"\".join(model_script_lines))\n",
    "runner.optimize_full_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en HAR con optimizacion\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_FP_OPTIMIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce0f2c",
   "metadata": {},
   "source": [
    "### 1.4 Cuantizar el modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataset de calibración\n",
    "# The original images are being used, just as the input to the SDK_FP_OPTIMIZED emulator\n",
    "total_images = 1050\n",
    "\n",
    "dataset.to_train()\n",
    "calib_dataset = np.zeros((total_images, sizex, sizey, B), dtype = np.float32)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Seleccionamos batches del dataloader para guardarlos en el dataset\n",
    "for (inputs, labels, targets_pixel_level) in data_loader:\n",
    "    for img in inputs:\n",
    "        if count >= total_images:\n",
    "            break\n",
    "            \n",
    "        # Los inputs son de la forma (batch_size, B, sizex, sizey)\n",
    "        img_np = img.numpy()\n",
    "        # Trasponemos los inputs a formato (batch_size, sizex, sizey, B)\n",
    "        img_har = np.transpose(img_np, (1, 2, 0))\n",
    "\n",
    "        calib_dataset[count] = img_har\n",
    "        count += 1\n",
    "        \n",
    "    if count >= total_images:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantizar el modelo con el dataset de calibración\n",
    "\n",
    "# For calling Optimize, use the short version: runner.optimize(calib_dataset)\n",
    "# A more general approach is being used here that works also with multiple input nodes.\n",
    "# The calibration dataset could also be a dictionary with the format:\n",
    "# {input_layer_name_1_from_hn: layer_1_calib_dataset, input_layer_name_2_from_hn: layer_2_calib_dataset}\n",
    "hn_layers = runner.get_hn_dict()[\"layers\"]\n",
    "print(\"Input layers are: \")\n",
    "print([layer for layer in hn_layers if hn_layers[layer][\"type\"] == \"input_layer\"])  # See available input layer names\n",
    "calib_dataset_dict = {\"model_ResBaGAN_discriminator/input_layer1\": calib_dataset}  # In our case there is only one input layer\n",
    "\n",
    "optimization_level = 4\n",
    "compression_level = 3\n",
    "# Mapeamos las proporciones de pesos de 4 bits según el nivel de compresión\n",
    "compression_ratios = {\n",
    "    0: 0.0,\n",
    "    1: 0.2,\n",
    "    2: 0.4,\n",
    "    3: 0.6,\n",
    "    4: 0.8,\n",
    "    5: 1.0\n",
    "}\n",
    "auto_4bit_ratio = compression_ratios.get(compression_level, 0.0)\n",
    "\n",
    "alls_lines = [\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # Batch size is 8 by default; 2 was used for stability on PCs with low amount of RAM / VRAM\n",
    "    f\"model_optimization_flavor(optimization_level={optimization_level}, compression_level={compression_level}, batch_size=8)\\n\",\n",
    "    # The following line is needed because this is a really small model, and the compression_level is always reverted back to 0.'\n",
    "    # To force using compression_level with small models, the following line should be used (compression level=4 equals to 80% 4-bit):\n",
    "    f\"model_optimization_config(compression_params, auto_4bit_weights_ratio={auto_4bit_ratio})\\n\",\n",
    "    # The application of the compression could be seen by the [info] messages: \"Assigning 4bit weight to layer ..\"\n",
    "]\n",
    "\n",
    "runner.load_model_script(\"\".join(alls_lines))\n",
    "\n",
    "runner.optimize(calib_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb54f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en HAR cuantizado\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_QUANTIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eebb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo cuantizado\n",
    "# Let's save the runner's state to a Quantized HAR\n",
    "quantized_model_har_path = f\"{model_name}_quantized_model_o{optimization_level}_c{compression_level}.har\"\n",
    "runner.save_har(quantized_model_har_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24260b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b9b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dcee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hailo_gpu_env]",
   "language": "python",
   "name": "conda-env-hailo_gpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
