{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5e60a4",
   "metadata": {},
   "source": [
    "# Fase 0.1: Entrenar y ejecutar una CNN básica para clasificación de imágenes hiperespectrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef7d0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import math,random,struct,os,time,sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from sklearn import preprocessing\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395d1b8",
   "metadata": {},
   "source": [
    "## 1. Definición de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab02e67",
   "metadata": {},
   "source": [
    "### 1.1. Leer y mostrar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ecffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer imágenes en formato raw\n",
    "\n",
    "def read_raw(fichero):\n",
    "  (B,H,V)=np.fromfile(fichero,count=3,dtype=np.uint32)\n",
    "  datos=np.fromfile(fichero,count=B*H*V,offset=3*4,dtype=np.int32)\n",
    "  print('* Read dataset:',fichero)\n",
    "  print('  B:',B,'H:',H,'V:',V)\n",
    "  print('  Read:',len(datos))\n",
    "  # para normalizar el dataset en [0:1] (en esta red no hace falta)\n",
    "  # datos=preprocessing.minmax_scale(datos)\n",
    "  datos=datos.reshape(V,H,B)\n",
    "  datos=torch.FloatTensor(datos)\n",
    "  return(datos,H,V,B)\n",
    "\n",
    "def save_raw(output,H,V,B,filename):\n",
    "  try:\n",
    "    f=open(filename,\"wb\")\n",
    "  except IOError:\n",
    "    print('No puedo abrir ',filename)\n",
    "    exit(0)\n",
    "  else:\n",
    "    f.write(struct.pack('i',B))\n",
    "    f.write(struct.pack('i',H))\n",
    "    f.write(struct.pack('i',V))\n",
    "    output=output.reshape(H*V*B)\n",
    "    for i in range(H*V*B):\n",
    "      f.write(struct.pack('i',np.int(output[i])))\n",
    "    f.close()\n",
    "    print('* Saved file:',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar una imagen hiperespectral de ejemplo\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "\n",
    "(datos,H,V,B)=read_raw(DATASET)\n",
    "\n",
    "# Seleccionar bandas representativas\n",
    "bandas_rgb = [0, 1, 2]\n",
    "\n",
    "# Extraer las bandas seleccionadas\n",
    "imagen_rgb = datos[:, :, bandas_rgb]\n",
    "\n",
    "# Normalizar la imagen\n",
    "imagen_rgb = imagen_rgb.numpy()\n",
    "imagen_rgb = (imagen_rgb - imagen_rgb.min()) / (imagen_rgb.max() - imagen_rgb.min())\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(imagen_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0801c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer imágenes en formato pgm\n",
    "\n",
    "def read_pgm(fichero):\n",
    "  try:\n",
    "    pgmf=open(fichero,\"rb\")\n",
    "  except IOError:\n",
    "    print('No puedo abrir ',fichero)\n",
    "  else:\n",
    "    assert pgmf.readline().decode()=='P5\\n'\n",
    "    line=pgmf.readline().decode()\n",
    "    while(line[0]=='#'):\n",
    "      line=pgmf.readline().decode()\n",
    "    (H,V)=line.split()\n",
    "    H=int(H); V=int(V)\n",
    "    depth=int(pgmf.readline().decode())\n",
    "    assert depth<=255\n",
    "    raster=[]\n",
    "    for i in range(H*V):\n",
    "      raster.append(ord(pgmf.read(1)))\n",
    "    print('* Read GT:',fichero)\n",
    "    print('  H:',H,'V:',V,'depth:',depth)\n",
    "    print('  Read:',len(raster))\n",
    "    return(raster,H,V)\n",
    "\n",
    "def save_pgm(output,H,V,nclases,filename):\n",
    "  try:\n",
    "    f=open(filename,\"wb\")\n",
    "  except IOError:\n",
    "    print('No puedo abrir ',filename)\n",
    "    exit(0)\n",
    "  else:\n",
    "    # f.write(b'P5\\n')\n",
    "    cadena='P5\\n'+str(H)+' '+str(V)+'\\n'+str(nclases)+'\\n'\n",
    "    f.write(bytes(cadena,'utf-8'))\n",
    "    f.write(output)\n",
    "    f.close()\n",
    "    print('* Saved file:',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e326cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el Ground-Truth de la imagen anterior\n",
    "\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "\n",
    "(imagen_gt, H, V) = read_pgm(GT)\n",
    "\n",
    "# Convertir la lista a array y redimensionar\n",
    "imagen_gt = np.array(imagen_gt, dtype=np.uint8).reshape(V, H)\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(imagen_gt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa204ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el Ground-Truth de formato pgm a raw\n",
    "\n",
    "def save_gt_raw(gt_array, height, width, bands, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        # Cabecera: width, height, bands (1)\n",
    "        f.write(struct.pack('i', width))\n",
    "        f.write(struct.pack('i', height))\n",
    "        f.write(struct.pack('i', bands))\n",
    "        # Datos planos int32\n",
    "        gt_array = gt_array.reshape(height * width).astype(np.int32)\n",
    "        for val in gt_array:\n",
    "            f.write(struct.pack('i', int(val)))\n",
    "    print(f'* Saved GT raw: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5da654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "RAW_GT='../data/imagenes_rios/oitaven_river_converted_gt.raw'\n",
    "\n",
    "(imagen_gt, H, V) = read_pgm(GT)\n",
    "\n",
    "# Convertir la lista a array y redimensionar\n",
    "imagen_gt = np.array(imagen_gt, dtype=np.uint8).reshape(V, H)\n",
    "\n",
    "\n",
    "save_gt_raw(imagen_gt, H, V, 5, RAW_GT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea0baf",
   "metadata": {},
   "source": [
    "### 1.2. Seleccionar conjuntos de entrenamiento, validación y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494505b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar muestrar para entrenamiento, validación y test\n",
    "\n",
    "def select_training_samples(truth,H,V,sizex,sizey,porcentaje):\n",
    "  print('* Select training samples')\n",
    "  # hacemos una lista con las clases, pero puede haber clases vacias\n",
    "  nclases=0; nclases_no_vacias=0\n",
    "  N=len(truth)\n",
    "  for i in truth:\n",
    "    if(i>nclases): nclases=i\n",
    "  print('  nclasses:',nclases)\n",
    "  lista=[0]*nclases;\n",
    "  for i in range(nclases):\n",
    "    lista[i]=[]\n",
    "  for i in range(int(sizey/2),V-int(sizey/2)-1):\n",
    "    for j in range(int(sizex/2),H-int(sizex/2)-1):\n",
    "      ind=i*H+j\n",
    "      if(truth[ind]>0): lista[truth[ind]-1].append(ind)\n",
    "  for i in range(nclases):\n",
    "    random.shuffle(lista[i])\n",
    "  # seleccionamos muestras para train, validacion y test\n",
    "  print('  Class  # :   total | train |   val |    test')\n",
    "  train=[]; val=[]; test=[]\n",
    "  for i in range(nclases):\n",
    "    # tot0: numero muestras entrenamiento, tot1: validacion \n",
    "    if(porcentaje[0]>=1): tot0=porcentaje[0]\n",
    "    else: tot0=int(porcentaje[0]*len(lista[i]))\n",
    "    if(tot0>=len(lista[i])): tot0=len(lista[i])//2\n",
    "    if(tot0<0 and len(lista[i])>0): tot0=1\n",
    "    if(tot0!=0): nclases_no_vacias+=1\n",
    "    if(porcentaje[1]>=1): tot1=porcentaje[1]\n",
    "    else: tot1=int(porcentaje[1]*len(lista[i]))\n",
    "    if(tot1>=len(lista[i])-tot0): tot1=(len(lista[i])-tot0)//2\n",
    "    if(tot1<1 and len(lista[i])>0): tot1=0\n",
    "    for j in range(len(lista[i])):\n",
    "      if(j<tot0): train.append(lista[i][j])\n",
    "      elif(j<tot0+tot1): val.append(lista[i][j])\n",
    "      else: test.append(lista[i][j])\n",
    "    print('  Class',f'{i+1:2d}',':',f'{len(lista[i]):7d}','|',f'{tot0:5d}','|',\n",
    "      f'{tot1:5d}','|',f'{len(lista[i])-tot0-tot1:7d}')\n",
    "      \n",
    "  # Modificamos la funcion para obtener el conjunto para inferencia\n",
    "  # Verificamos si estamos usando el 100% de las muestras para el conjunto de test\n",
    "  if len(train) == 0 and len(val) == 0:\n",
    "    # Verificamos las clases presentes en el conjunto de test y actualizamos nclases_no_vacias\n",
    "    for i in range(nclases):\n",
    "      if any(truth[idx] == i+1 for idx in test):\n",
    "        nclases_no_vacias += 1\n",
    "        \n",
    "  return(train,val,test,nclases,nclases_no_vacias)\n",
    "\n",
    "# Extraer una subsección de la imagen\n",
    "def select_patch(datos,sizex,sizey,x,y):\n",
    "  x1=x-int(sizex/2); x2=x+int(math.ceil(sizex/2));     \n",
    "  y1=y-int(sizey/2); y2=y+int(math.ceil(sizey/2));\n",
    "  patch=datos[:,y1:y2,x1:x2]\n",
    "  return(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba29dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejar datasets en PyTorch\n",
    "\n",
    "# Seleccionar muestras sin Ground-Truth\n",
    "class HyperAllDataset(Dataset):\n",
    "  def __init__(self,datos,samples,H,V,sizex,sizey):\n",
    "    self.datos=datos; self.samples=samples\n",
    "    self.H=H; self.V=V; self.sizex=sizex; self.sizey=sizey;\n",
    "    self.transform=transforms.Compose(\n",
    "      [transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip()])\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.samples)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    datos=self.datos; H=self.H; V=self.V;\n",
    "    sizex=self.sizex; sizey=self.sizey; \n",
    "    x=self.samples[idx]%H; y=int(self.samples[idx]/H)\n",
    "    patch=select_patch(datos,sizex,sizey,x,y)\n",
    "    if(AUM==1): patch=self.transform(patch)\n",
    "    return(patch)\n",
    "\n",
    "# Seleccionar muestrar con Ground-Truth\n",
    "class HyperDataset(Dataset):\n",
    "  def __init__(self,datos,truth,samples,H,V,sizex,sizey):\n",
    "    self.datos=datos; self.truth=truth; self.samples=samples\n",
    "    self.H=H; self.V=V; self.sizex=sizex; self.sizey=sizey;\n",
    "    self.transform=transforms.Compose(\n",
    "      [transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip()])\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.samples)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    datos=self.datos; truth=self.truth; H=self.H; V=self.V;\n",
    "    sizex=self.sizex; sizey=self.sizey; \n",
    "    x=self.samples[idx]%H; y=int(self.samples[idx]/H)\n",
    "    patch=select_patch(datos,sizex,sizey,x,y)\n",
    "    if(AUM==1): patch=self.transform(patch)\n",
    "    # renumeramos porque la red clasifica tambien la clase 0 \n",
    "    return(patch,truth[self.samples[idx]]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar conjuntos de entrenamiento, validación y test\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "\n",
    "SAMPLES=[0.02,0.01] # [entrenamiento,validacion]: muestras/clase (200,50) o porcentaje (0.02,0.01) \n",
    "PAD=1  # hacemos padding en los bordes para aprovechar todas las muestras\n",
    "\n",
    "(datos,H,V,B)=read_raw(DATASET)\n",
    "(truth,H1,V1)=read_pgm(GT)\n",
    "\n",
    "# Durante la ejecucion de la red vamos a coger patches de tamano cuadrado\n",
    "sizex=32; sizey=32 \n",
    "\n",
    "# Hacemos padding en el dataset para poder aprovechar hasta el borde\n",
    "if(PAD):\n",
    "    datos=torch.FloatTensor(np.pad(datos,((sizey//2,sizey//2),(sizex//2,sizex//2),(0,0)),'symmetric'))\n",
    "    H=H+2*(sizex//2); V=V+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(-1,H1))\n",
    "    truth=np.pad(truth,((sizey//2,sizey//2),(sizex//2,sizex//2)),'constant')\n",
    "    H1=H1+2*(sizex//2); V1=V1+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(H1*V1))\n",
    "\n",
    "# Necesitamos los datos en band-vector para hacer convoluciones\n",
    "datos=np.transpose(datos,(2,0,1))\n",
    "\n",
    "# Seleccionar los conjuntos\n",
    "(train,val,test,nclases,nclases_no_vacias)=select_training_samples(truth,H,V,sizex,sizey,SAMPLES)\n",
    "dataset_train=HyperDataset(datos,truth,train,H,V,sizex,sizey)\n",
    "print('  - train dataset:',len(dataset_train))\n",
    "dataset_test=HyperDataset(datos,truth,test,H,V,sizex,sizey)\n",
    "print('  - test dataset:',len(dataset_test))\n",
    "\n",
    "# Dataloader\n",
    "batch_size=100 # defecto 100\n",
    "train_loader=DataLoader(dataset_train,batch_size,shuffle=True)\n",
    "test_loader=DataLoader(dataset_test,batch_size,shuffle=False)\n",
    "\n",
    "# Si queremos validacion\n",
    "if(len(val)>0):\n",
    "    dataset_val=HyperDataset(datos,truth,val,H,V,sizex,sizey)\n",
    "    print('  - val dataset:',len(dataset_val))\n",
    "    val_loader=DataLoader(dataset_val,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a084c0",
   "metadata": {},
   "source": [
    "### 1.3. Funciones auxiliares para el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulsando CNLT-C acabamos el entrenamiento y pasamos a testear\n",
    "def signal_handler(sig, frame):\n",
    "  print('\\n* Ctrl+C. Exit training')\n",
    "  global endTrain\n",
    "  endTrain=True\n",
    "\n",
    "# Actualizar el learning rate manualmente\n",
    "def update_lr(optimizer,lr):    \n",
    "  for param_group in optimizer.param_groups:\n",
    "    param_group['lr']=lr\n",
    "\n",
    "# Calcular los promedios de precisiones\n",
    "def accuracy_mean_deviation(OA,AA,aa):\n",
    "  n=len(OA); nclases=len(aa[0])\n",
    "  print('* Means and deviations (%d exp):'%(n))\n",
    "  # medias\n",
    "  OAm=0; AAm=0; aam=[0]*nclases;\n",
    "  for i in range(n):\n",
    "     OAm+=OA[i]; AAm+=AA[i]\n",
    "     for j in range(1,nclases): aam[j]+=aa[i][j]\n",
    "  OAm/=n; AAm/=n\n",
    "  for j in range(1,nclases): aam[j]/=n\n",
    "  # desviaciones, usamos la formula que divide entre (n-1)\n",
    "  OAd=0; AAd=0; aad=[0]*nclases\n",
    "  for i in range(n):\n",
    "     OAd+=(OA[i]-OAm)*(OA[i]-OAm); AAd+=(AA[i]-AAm)*(AA[i]-OAm)\n",
    "     for j in range(1,nclases): aad[j]+=(aa[i][j]-aam[j])*(aa[i][j]-aam[j])\n",
    "  OAd=math.sqrt(OAd/(n-1)); AAd=math.sqrt(AAd/(n-1))\n",
    "  for j in range(1,nclases): aad[j]=math.sqrt(aad[j]/(n-1))\n",
    "  for j in range(1,nclases): print('  Class %02d: %02.02f+%02.02f'%(j,aam[j],aad[j]))\n",
    "  print('  OA=%02.02f+%02.02f, AA=%02.02f+%02.02f'%(OAm,OAd,AAm,AAd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e964e",
   "metadata": {},
   "source": [
    "### 1.4. Construcción de la Red Neuronal Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la CNN\n",
    "\n",
    "# Convolutional neural network (two convolutional layers y una lineal)\n",
    "class CNN21(nn.Module):\n",
    "  def __init__(self,N1,N2,N3,N4,N5,D1,D2):\n",
    "    super(CNN21,self).__init__()\n",
    "    self.layer1=nn.Sequential(\n",
    "      nn.Conv2d(N1,N2,kernel_size=3,stride=1,padding=2),\n",
    "      nn.BatchNorm2d(N2),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2,stride=D1))\n",
    "    self.layer2=nn.Sequential(\n",
    "      nn.Conv2d(N2,N3,kernel_size=5,stride=1,padding=2),\n",
    "      nn.BatchNorm2d(N3),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2,stride=D2))\n",
    "    self.fc=nn.Linear(N4,N5)\n",
    "      \n",
    "  def forward(self,x):\n",
    "    out=self.layer1(x)\n",
    "    out=self.layer2(out)\n",
    "    out=out.reshape(out.size(0),-1)\n",
    "    out=self.fc(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b282183",
   "metadata": {},
   "source": [
    "## 2. Flujo principal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc15cb",
   "metadata": {},
   "source": [
    "### 2.1. Configuración de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd704d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de parámetros\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "\n",
    "EXP=1    # numero de experimentos\n",
    "EPOCHS=100 # EPOCHS de entrenamiente del clasificador, default=100\n",
    "SAMPLES=[0.02,0.01] # [entrenamiento,validacion]: muestras/clase (200,50) o porcentaje (0.02,0.01) \n",
    "PAD=1  # hacemos padding en los bordes para aprovechar todas las muestras\n",
    "ADA=0  # learning rate: 0-fijo, 1-manual, 2-MultiStepLR, 3-CosineAnnealingLR, 4-StepLR\n",
    "AUM=0  # aumentado: 0-sin_aumentado, 1-con_aumentado\n",
    "DET=0  # experimentos: 0-aleatorios, 1-deterministas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db02363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de parámetros\n",
    "\n",
    "cuda=True if torch.cuda.is_available() else False\n",
    "# device=torch.device('cuda' if cuda else 'cpu')\n",
    "# device='cpu'\n",
    "\n",
    "if torch.backends.cudnn.is_available():\n",
    "    print('* Activando CUDNN')\n",
    "    torch.backends.cudnn.enabled=True\n",
    "    torch.backends.cudnn.beBhmark=True\n",
    "# Experimentos deterministas o aleatorios\n",
    "if(DET==1):\n",
    "    SEED=0\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    if(cuda==False):\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        g=torch.Generator(); g.manual_seed(SEED)\n",
    "    else:\n",
    "        torch.backends.cudnn.deterministic=True\n",
    "        torch.backends.cudnn.benchmark=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a30915",
   "metadata": {},
   "source": [
    "### 2.2. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b36cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el número de píxeles que contienen datos de la imagen completa\n",
    "\n",
    "(datos,H,V,B)=read_raw(DATASET)\n",
    "\n",
    "pixeles_totales = datos.shape[0] * datos.shape[1]\n",
    "pixeles_vacios = ((datos == 0).all(dim=2)).sum().item()\n",
    "pixeles_con_valor = pixeles_totales - pixeles_vacios\n",
    "\n",
    "print(f'Pixeles totales: {pixeles_totales}')\n",
    "print(f'Pixeles vacíos: {pixeles_vacios}')\n",
    "print(f'Pixeles con valor: {pixeles_con_valor}')\n",
    "\n",
    "print(f'Porcentaje de pixeles con valor: {((pixeles_con_valor/pixeles_totales) * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01df412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "\n",
    "(datos,H,V,B)=read_raw(DATASET)\n",
    "(truth,H1,V1)=read_pgm(GT)\n",
    "\n",
    "# Durante la ejecucion de la red vamos a coger patches de tamano cuadrado\n",
    "sizex=32; sizey=32 \n",
    "\n",
    "# Hacemos padding en el dataset para poder aprovechar hasta el borde\n",
    "if(PAD):\n",
    "    datos=torch.FloatTensor(np.pad(datos,((sizey//2,sizey//2),(sizex//2,sizex//2),(0,0)),'symmetric'))\n",
    "    H=H+2*(sizex//2); V=V+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(-1,H1))\n",
    "    truth=np.pad(truth,((sizey//2,sizey//2),(sizex//2,sizex//2)),'constant')\n",
    "    H1=H1+2*(sizex//2); V1=V1+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(H1*V1))\n",
    "    \n",
    "# Necesitamos los datos en band-vector para hacer convoluciones\n",
    "datos=np.transpose(datos,(2,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87ee58",
   "metadata": {},
   "source": [
    "### 2.3. Selección de conjuntos de entrenamiento, validación y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59170f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar conjuntos de entrenamiento, validación y test\n",
    "(train,val,test,nclases,nclases_no_vacias)=select_training_samples(truth,H,V,sizex,sizey,SAMPLES)\n",
    "dataset_train=HyperDataset(datos,truth,train,H,V,sizex,sizey)\n",
    "print('  - train dataset:',len(dataset_train))\n",
    "dataset_test=HyperDataset(datos,truth,test,H,V,sizex,sizey)\n",
    "print('  - test dataset:',len(dataset_test))\n",
    "\n",
    "# Dataloader\n",
    "batch_size=100 # defecto 100\n",
    "train_loader=DataLoader(dataset_train,batch_size,shuffle=True)\n",
    "test_loader=DataLoader(dataset_test,batch_size,shuffle=False)\n",
    "\n",
    "# Si queremos validacion\n",
    "if(len(val)>0):\n",
    "    dataset_val=HyperDataset(datos,truth,val,H,V,sizex,sizey)\n",
    "    print('  - val dataset:',len(dataset_val))\n",
    "    val_loader=DataLoader(dataset_val,batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2a69b",
   "metadata": {},
   "source": [
    "### 2.4. Definición de la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ccab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la CNN\n",
    "\n",
    "# Hiperparámetros\n",
    "if(ADA==0): lr=0.001\n",
    "else: lr=0.001\n",
    "\n",
    "# Capas de la CNN: Dos capas convolucionales y una lineal\n",
    "# Capa conv.1\n",
    "N1=B          # dimension de entrada\n",
    "D1=2          # decimacion,por defecto 2\n",
    "HH1=sizex      # lado patches entrada, por defecto 32 (sizex=sizey)\n",
    "N2=16         # dimension de salida (seleccionada), por defecto 32\n",
    "H2=int(HH1/D1) # lado patches salida (calculada), por defecto 32 (sizex=sizey)\n",
    "\n",
    "# Capa conv.2,parametros de entrada N2, H2 vienen dados por la capa anterior\n",
    "N3=32         # dimension de salida (seleccionada), por defecto 32\n",
    "D2=2          # decimacion, defecto 2\n",
    "H3=int(H2/D2) # lado patches salida\n",
    "\n",
    "# Capa completamente conectada,parametro de entrada N4 viene de la etapa anterior \n",
    "N4=H3*H3*N3   # dimension de entrada\n",
    "N5=nclases    # dimension de salida\n",
    "\n",
    "# Declaración del modelo\n",
    "model=CNN21(N1,N2,N3,N4,N5,D1,D2).to(device)\n",
    "\n",
    "# Función de pérdida, optimizador y programador de tasas de aprendizaje\n",
    "# Mean-squared error loss\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "# Create an optimizer object: Adam optimizer with learning rate lr\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "# Scheduler (no es estrictamente necesario)\n",
    "if(ADA==2): scheduler=torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[EPOCHS//2,(5*EPOCHS)//6],gamma=0.1)\n",
    "elif(ADA==3): scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=EPOCHS,eta_min=0, verbose=True)\n",
    "elif(ADA==4): scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99, verbose=True)\n",
    "else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45601882",
   "metadata": {},
   "source": [
    "### 2.5. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bb858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "\n",
    "global endTrain\n",
    "endTrain=False\n",
    "\n",
    "# signal.signal(signal.SIGINT,signal_handler)\n",
    "total_step=len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i,(inputs,labels) in enumerate(train_loader):\n",
    "        # Cogemos muestras y etiquetas para entrenar\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        # reset the gradients (PyTorch accumulates gradients)\n",
    "        optimizer.zero_grad()\n",
    "        # compute accumulated gradients\n",
    "        loss.backward()\n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "\n",
    "    # si tenemos validacion usamos estas muestras, si no el propio train\n",
    "    if(len(val)>0):\n",
    "        if(epoch%10==0 or epoch==EPOCHS-1):\n",
    "            for i,(inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                outputs=model(inputs)\n",
    "                loss_val=criterion(outputs,labels)\n",
    "            print ('  Epoch: %3d/%d, Loss(train): %.4f, Loss(val): %.4f'\n",
    "             %(epoch,EPOCHS,loss.item(),loss_val.item()))\n",
    "    else: \n",
    "        if(epoch%10==0 or epoch==EPOCHS-1):\n",
    "            print ('  Epoch: %3d/%d, Loss: %.4f'%(epoch,EPOCHS,loss.item()))\n",
    "\n",
    "    # Decay learning rate (lo decrementamos cconforme aumentan las iteraciones)\n",
    "    if(ADA==1 and (epoch+1)%20==0): lr/=2; update_lr(optimizer,lr)\n",
    "    elif(ADA>1): scheduler.step()\n",
    "    if(endTrain): break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba4c57",
   "metadata": {},
   "source": [
    "### 2.6. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f212821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el comportamiento del modelo\n",
    "\n",
    "output=np.zeros(H*V,dtype=np.uint8)\n",
    "\n",
    "# eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct=0; total=0; recoge=[]\n",
    "    for(inputs,labels) in test_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(inputs)\n",
    "        (_,predicted)=torch.max(outputs.data,1)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "        predicted_cpu=predicted.cpu()\n",
    "        for i in range(len(predicted_cpu)):\n",
    "            output[test[total+i]]=np.uint8(predicted_cpu[i]+1)\n",
    "        total+=labels.size(0)\n",
    "        if(total%100000==0): print('  Test:',total,'/',len(dataset_test))\n",
    "\n",
    "print('* Accuracy: %02.02f'%(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisiones a nivel de clase\n",
    "\n",
    "correct=0; total=0; AA=0; OA=0\n",
    "class_correct=[0]*(nclases+1)\n",
    "class_total=[0]*(nclases+1)\n",
    "class_aa=[0]*(nclases+1)\n",
    "\n",
    "for i in test:\n",
    "    if(output[i]==0 or truth[i]==0): continue\n",
    "    total+=1; class_total[truth[i]]+=1\n",
    "    if(output[i]==truth[i]):\n",
    "        correct+=1\n",
    "        class_correct[truth[i]]+=1\n",
    "        \n",
    "for i in range(1,nclases+1):\n",
    "    if(class_total[i]!=0): class_aa[i]=100*class_correct[i]/class_total[i]\n",
    "    else: class_aa[i]=0\n",
    "    AA+=class_aa[i]\n",
    "    \n",
    "OA=100*correct/total; AA=AA/nclases_no_vacias\n",
    "\n",
    "for i in range(1,nclases+1): print('  Class %02d: %02.02f'%(i,class_aa[i]))\n",
    "print('* Accuracy (pixels), OA=%02.02f, AA=%02.02f'%(OA,AA))\n",
    "print('  total:',total,'correct:',correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048259a",
   "metadata": {},
   "source": [
    "### 2.7. Guardar la salida y el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cba44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la salida\n",
    "\n",
    "if(PAD):\n",
    "    output=np.reshape(output,(-1,H1))\n",
    "    output=output[sizey//2:V1-sizey//2,sizex//2:H1-sizex//2]\n",
    "    H1=H1-2*(sizex//2); V1=V1-2*(sizey//2)\n",
    "    output=np.reshape(output,(H1*V1))\n",
    "\n",
    "save_pgm(output,H1,V1,nclases,'../results/predictions/output_cnn21.pgm')\n",
    "    \n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(),'../results/models/model_cnn21.ckpt')\n",
    "# Save the entire model\n",
    "torch.save(model, '../results/models/model_cnn21.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la salida\n",
    "\n",
    "OUTPUT='../results/predictions/output_cnn21.pgm'\n",
    "\n",
    "(imagen_output, H1, V1) = read_pgm(OUTPUT)\n",
    "\n",
    "# Convertir la lista a array y redimensionar\n",
    "imagen_output = np.array(imagen_output, dtype=np.uint8).reshape(V1, H1)\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(imagen_output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b9444",
   "metadata": {},
   "source": [
    "## 3. Uso del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "MODEL=\"../results/models/model_cnn21.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edc47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo cnn21\n",
    "\n",
    "cuda=True if torch.cuda.is_available() else False\n",
    "device=torch.device('cuda' if cuda else 'cpu')\n",
    "device='cpu'\n",
    "\n",
    "if torch.backends.cudnn.is_available():\n",
    "    print('* Activando CUDNN')\n",
    "    torch.backends.cudnn.enabled=True\n",
    "    torch.backends.cudnn.beBhmark=True\n",
    "\n",
    "model = torch.load(MODEL, weights_only=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos e inferencia\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir parámetros y cargar datos\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "MODEL=\"../results/models/model_cnn21.pth\"\n",
    "\n",
    "# Queremos usar todos los datos para la inferencia\n",
    "SAMPLES=[0,0]\n",
    "PAD=1\n",
    "AUM=0\n",
    "\n",
    "# Carga de datos\n",
    "(datos,H,V,B)=read_raw(DATASET)\n",
    "(truth,H1,V1)=read_pgm(GT)\n",
    "\n",
    "# Durante la ejecucion de la red vamos a coger patches de tamano cuadrado\n",
    "sizex=32; sizey=32 \n",
    "\n",
    "# Hacemos padding en el dataset para poder aprovechar hasta el borde\n",
    "if(PAD):\n",
    "    datos=torch.FloatTensor(np.pad(datos,((sizey//2,sizey//2),(sizex//2,sizex//2),(0,0)),'symmetric'))\n",
    "    H=H+2*(sizex//2); V=V+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(-1,H1))\n",
    "    truth=np.pad(truth,((sizey//2,sizey//2),(sizex//2,sizex//2)),'constant')\n",
    "    H1=H1+2*(sizex//2); V1=V1+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(H1*V1))\n",
    "    \n",
    "# Necesitamos los datos en band-vector para hacer convoluciones\n",
    "datos=np.transpose(datos,(2,0,1))\n",
    "\n",
    "# Seleccionar conjunto de test (en este caso es una predicción)\n",
    "(train,val,test,nclases,nclases_no_vacias)=select_training_samples(truth,H,V,sizex,sizey,SAMPLES)\n",
    "dataset_test=HyperDataset(datos,truth,test,H,V,sizex,sizey)\n",
    "print('  - test dataset:',len(dataset_test))\n",
    "\n",
    "# Dataloader\n",
    "batch_size=100 # defecto 100\n",
    "test_loader=DataLoader(dataset_test,batch_size,shuffle=False)\n",
    "\n",
    "output=np.zeros(H*V,dtype=np.uint8)\n",
    "\n",
    "# Modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Realizar la predicción\n",
    "with torch.no_grad():\n",
    "    total=0\n",
    "    for (inputs, labels) in test_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        outputs=model(inputs)\n",
    "        (_,predicted)=torch.max(outputs.data,1)\n",
    "        predicted_cpu=predicted.cpu()\n",
    "        for i in range(len(predicted_cpu)):\n",
    "            output[test[total+i]]=np.uint8(predicted_cpu[i]+1)\n",
    "        total+=labels.size(0)\n",
    "        if(total%100000==0): print('  Test:',total,'/',len(dataset_test))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Prediction time: {:.4f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9945a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el output\n",
    "\n",
    "np.save('../results/predictions/predictions_cnn21.npy', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el output\n",
    "\n",
    "output = np.load('../results/predictions/predictions_cnn21.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400de0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el desempeño del modelo\n",
    "\n",
    "# Precisiones a nivel de clase\n",
    "correct=0; total=0; AA=0; OA=0\n",
    "class_correct=[0]*(nclases+1)\n",
    "class_total=[0]*(nclases+1)\n",
    "class_aa=[0]*(nclases+1)\n",
    "\n",
    "for i in test:\n",
    "    if(output[i]==0 or truth[i]==0): continue\n",
    "    total+=1; class_total[truth[i]]+=1\n",
    "    if(output[i]==truth[i]):\n",
    "          correct+=1\n",
    "          class_correct[truth[i]]+=1\n",
    "for i in range(1,nclases+1):\n",
    "    if(class_total[i]!=0): class_aa[i]=100*class_correct[i]/class_total[i]\n",
    "    else: class_aa[i]=0\n",
    "    AA+=class_aa[i]\n",
    "OA=100*correct/total; AA=AA/nclases_no_vacias\n",
    "\n",
    "for i in range(1,nclases+1): print('  Class %02d: %02.02f'%(i,class_aa[i]))\n",
    "print('* Accuracy (pixels) OA=%02.02f, AA=%02.02f'%(OA,AA))\n",
    "print('  total:',total,'correct:',correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la salida\n",
    "\n",
    "if(PAD):\n",
    "    output=np.reshape(output,(-1,H1))\n",
    "    output=output[sizey//2:V1-sizey//2,sizex//2:H1-sizex//2]\n",
    "    H1=H1-2*(sizex//2); V1=V1-2*(sizey//2)\n",
    "    output=np.reshape(output,(H1*V1))\n",
    "\n",
    "save_pgm(output,H1,V1,nclases,'../results/predictions/predictions_cnn21.pgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la salida\n",
    "\n",
    "OUTPUT='../results/predictions/predictions_cnn21.pgm'\n",
    "\n",
    "(imagen_output, H1, V1) = read_pgm(OUTPUT)\n",
    "\n",
    "# Convertir la lista a array y redimensionar\n",
    "imagen_output = np.array(imagen_output, dtype=np.uint8).reshape(V1, H1)\n",
    "\n",
    "# Mostrar la imagen\n",
    "plt.imshow(imagen_output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28d8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bfa63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb144f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hyper_env] *",
   "language": "python",
   "name": "conda-env-hyper_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
