{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b76dd13",
   "metadata": {},
   "source": [
    "# Fase 1.3: Optimización del modelo en HAR (Hailo Archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f181ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 18:47:18.984130: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-08 18:47:19.758272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/pablo/anaconda3/envs/hailo_gpu_env/lib/python3.8/site-packages/nvidia/dali/backend.py:77: Warning: DALI 1.49 is the last release to support Python 3.8 Please update your environment to use Python 3.9, or newer.\n",
      "  deprecation_warning(\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from matplotlib import patches\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.python.eager.context import eager_mode\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from itertools import islice\n",
    "\n",
    "# Funciones y parámetros de la CNN base\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import resbagan_networks\n",
    "import resbagan_datasets\n",
    "\n",
    "# import the hailo sdk client relevant classes\n",
    "from hailo_sdk_client import ClientRunner, InferenceContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d16a4d",
   "metadata": {},
   "source": [
    "## 1. Optimización detallada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f860d1c",
   "metadata": {},
   "source": [
    "### 1.1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f18540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrada\n",
    "\n",
    "batch_size = 100\n",
    "B = 5\n",
    "sizex = 32\n",
    "sizey = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0231fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading dataset oitaven_river from disk\n",
      "\toitaven_river dataset is in RAW format\n",
      "[*] Recording available classes\n",
      "[*] Starting preprocessing\n",
      "[*] Scaling dataset to [-1, 1]\n",
      "[*] Splitting dataset into train, validation, and test sets: ratios (0.02, 0.01)\n",
      "[*] Total samples: 6067179\n",
      "\t[*] Recording samples for class Water (309248 items)\n",
      "\t[*] Recording samples for class Bare soil (113324 items)\n",
      "\t[*] Recording samples for class Rock (79152 items)\n",
      "\t[*] Recording samples for class Asphalt (43861 items)\n",
      "\t[*] Recording samples for class Concrete (128022 items)\n",
      "\t[*] Recording samples for class Tiles (78785 items)\n",
      "\t[*] Recording samples for class Meadows (2428482 items)\n",
      "\t[*] Recording samples for class Native trees (1829360 items)\n",
      "\t[*] Recording samples for class Pines (193884 items)\n",
      "\t[*] Recording samples for class Eucalyptus (863061 items)\n",
      "\n",
      "[*] HyperDataset summary:\n",
      "\tName: oitaven_river\n",
      "\tShape: (height) 6689, (width) 6722, (bands) 5\n",
      "\tClasses: ['Water', 'Bare soil', 'Rock', 'Asphalt', 'Concrete', 'Tiles', 'Meadows', 'Native trees', 'Pines', 'Eucalyptus']\n",
      "\tClasses count: 10\n",
      "\tSegmented: False\n",
      "\tSuperpixels count: 0\n",
      "\tPatch size: 32\n",
      "\tRatios: (train) 0.02, (val) 0.01\n",
      "\tSamples count: (train) 121339, (val) 60670, (test) 5885170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir parámetros y cargar datos\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "MODEL=\"../results/models/model_ResBaGAN.pt\"\n",
    "\n",
    "# Proporción de entrenamiento, validación y test\n",
    "SAMPLES=[0.02,0.01]\n",
    "\n",
    "# Carga de datos para la inferencia en el discriminador\n",
    "dataset = resbagan_datasets.HyperDataset(\n",
    "    \"oitaven_river\", segmented=False, patch_size=32, ratios=(SAMPLES[0], SAMPLES[1]))\n",
    "\n",
    "# Almacenamos las dimensiones en variables\n",
    "H = dataset.height\n",
    "V = dataset.width\n",
    "\n",
    "# En este caso seleccionamos samples aleatorios\n",
    "samples = dataset.test_set['samples']\n",
    "\n",
    "# Obtenemos el array de gt\n",
    "truth = dataset.gt.flatten()\n",
    "# Obtenemos un array de indices para test\n",
    "test = dataset.test_index_list\n",
    "\n",
    "# Obtenemos el numero de clases y el numero de clases no vacias para test\n",
    "nclases = dataset.classes_count\n",
    "nclases_no_vacias = 0\n",
    "for i in range(nclases):\n",
    "    clase_actual = i + 1\n",
    "    if any(truth[idx] == clase_actual for idx in test):\n",
    "        nclases_no_vacias += 1\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# The custom HyperDataset object contains all the train, validation and test data\n",
    "#   --> But it will wrapped into a PyTorch data feeder for convenience\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf81525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo convertido a ONNX\n",
    "\n",
    "ort_session = ort.InferenceSession(\"../results/models/model_ResBaGAN_discriminator.onnx\")\n",
    "\n",
    "# Cargar el modelo en HAR\n",
    "\n",
    "model_name = \"../results/models/model_ResBaGAN_discriminator\"\n",
    "hailo_model_har_name = f\"{model_name}_hailo_model.har\"\n",
    "assert os.path.isfile(hailo_model_har_name), \"Please provide valid path for HAR file\"\n",
    "runner = ClientRunner(har=hailo_model_har_name, hw_arch=\"hailo8l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0ecb0",
   "metadata": {},
   "source": [
    "### 1.2 Evaluar el modelo en har sin optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a259b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.4338574   1.9349066  -1.1357371 -12.580229   -3.8186932   1.6274607\n",
      "   -6.9782634  -1.3601333   5.832494   -5.047649    8.855347 ]]\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 20:57:12.424312: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 20:57:12.524259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 8entries [00:00, 247.31entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ -2.5148022   1.4130999  -0.5689734 -10.232361   -1.7181966\n",
      "      0.7633981  -2.620554   -2.6805184   2.9597077  -3.3096926\n",
      "      5.988242 ]]]]\n",
      "Error medio entre ONNX y HAR: 1.952363133430481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Comprobacion rapida de la diferencia de precisión\n",
    "\n",
    "# Crear tensor de entrada de prueba\n",
    "input_tensor = (torch.rand(1, B, sizex, sizey) * 2 - 1).to(\"cpu\")\n",
    "input_np = input_tensor.cpu().numpy()\n",
    "\n",
    "# Realizar la inferencia en ONNX\n",
    "output_onnx = ort_session.run(None, {'input': input_np})[0]\n",
    "\n",
    "print(output_onnx)\n",
    "\n",
    "# Realizar la inferencia en HAR\n",
    "with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "    input_har = np.transpose(input_np, (0, 2, 3, 1))\n",
    "\n",
    "    # Realizar la inferencia en el modelo .har\n",
    "    output_har = runner.infer(ctx, input_har)[0]\n",
    "\n",
    "    print(output_har) \n",
    "\n",
    "# Comparar las diferencias\n",
    "error = np.abs(output_onnx - output_har).mean()\n",
    "print(f'Error medio entre ONNX y HAR: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16be5c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:04.413847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.419331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.419525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.422797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.423007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.423214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:06.504143: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:06.504376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:06.504563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:06.504701: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-07 23:34:06.504723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-07 23:34:06.658158: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:07.443633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-07 23:34:14.600249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2025-06-07 23:34:15.915506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Inference: 104entries [00:08, 11.81entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.5300 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:34:16.336811: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:16.441401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1341.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:16.650773: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:16.754623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1450.86entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.3200 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:16.947318: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:17.053381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1470.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.4000 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:17.254454: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:17.363471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1527.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.1900 ; Coincidencias: 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:17.561969: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:17.668376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1472.30entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:17.872931: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:17.971694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1449.86entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.3700 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:18.171859: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:18.270555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1499.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.1600 ; Coincidencias: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:18.466656: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:18.567202: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1452.23entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.4600 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:18.760160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:18.861526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1557.96entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.5900 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:19.062206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:19.159028: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1634.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.2800 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:19.334027: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:19.433828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1545.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.3400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:19.635662: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:19.736819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1645.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.3700 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:19.908076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:20.007599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1545.18entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.2000 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:20.201079: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:20.304468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1349.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.4900 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:20.510608: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:20.614806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1313.12entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.3500 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:20.840357: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:20.938342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1524.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.3200 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:21.126102: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:21.225441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1508.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.4400 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:21.406574: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:21.505760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1578.15entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:21.685393: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:21.785320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1532.34entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.3800 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:21.971498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:22.069723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1596.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.2700 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:22.244747: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:22.343876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1633.53entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.4300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:22.528339: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:22.630837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1423.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.2700 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:22.875973: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:22.974045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1571.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.5500 ; Coincidencias: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:23.173105: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:23.273424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1483.73entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.2800 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:23.466854: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:23.567350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1661.05entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.2700 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:23.747132: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:23.846073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1669.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.4300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:24.020512: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:24.119094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1471.33entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.2600 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:24.300104: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:24.399585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1549.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:24.581281: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:24.681169: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1559.30entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.3900 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:24.865457: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:24.964043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1598.31entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.4700 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:25.135530: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:25.233164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1545.27entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.3800 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:25.408357: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:25.504934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1654.29entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.3500 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:25.703706: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:25.804422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1665.64entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.2800 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:25.988273: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:26.086341: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1661.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.3300 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:26.266350: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:26.366856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1697.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.2800 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:26.539675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:26.637750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1622.81entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.2900 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:26.822507: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:26.923240: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1591.81entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.3800 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:27.104311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:27.202029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1583.45entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.2600 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:27.383299: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:27.482623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.3700 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:27.657949: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:27.756564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1575.37entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.2300 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:27.928806: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:28.028290: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1504.93entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.3100 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:28.238518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:28.336128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1557.95entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.2400 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:28.514813: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:28.611720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1653.84entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.3700 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:28.784599: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:28.882080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1676.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.2300 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:29.064821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:29.164921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1566.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.3000 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:29.355355: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:29.453554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1672.75entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.3600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:29.638585: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:29.738628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1660.25entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.4200 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:29.921699: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:30.021168: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1556.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.2500 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:30.212133: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:30.311205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1627.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:30.500558: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:30.602040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1469.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.3400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:30.798684: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:30.936539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1468.12entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.3900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:34:31.133775: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:31.239530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1427.54entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:31.428341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:31.530919: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1532.79entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:31.714850: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:31.813857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1620.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.4600 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:31.996176: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:32.094696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:32.269482: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:32.367906: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1539.03entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.4400 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:32.544051: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:32.641318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1629.59entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.3500 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:32.819472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:32.920435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1486.23entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.2800 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:33.121154: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:33.219017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1645.12entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.4200 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:33.390085: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:33.487564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1549.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.4700 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:33.662725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:33.764683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1458.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.4500 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:33.969175: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:34.068467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1595.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.5000 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:34.260531: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:34.361102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1586.74entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.3400 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:34.534826: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:34.632846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1599.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.4600 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:34.813160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:34.912840: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1543.78entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.3300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:35.104087: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:35.203281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1625.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.4200 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:35.386482: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:35.485178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1646.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.2500 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:35.660854: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:35.758731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1635.31entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:35.931586: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:36.029982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1663.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:36.206848: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:36.304523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1652.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:36.494031: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:36.593461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1640.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.3800 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:36.774162: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:36.873610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1667.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.3200 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:37.052097: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:37.151523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1526.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.2400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:37.350411: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:37.450671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1651.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.4000 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:37.636959: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:37.737092: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1544.00entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.2400 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:37.927089: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:38.030507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1491.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.3500 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:38.223149: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:38.322768: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:38.497999: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:38.596402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1480.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.4200 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:38.789679: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:38.890432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1517.03entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.2500 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:39.075666: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:39.175711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1605.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.3500 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:39.349461: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:39.450130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1510.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.3500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:39.665302: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:39.765641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1510.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:39.966426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:40.064596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1661.42entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.2900 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:40.243700: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:40.341428: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1607.21entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.3200 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:40.517695: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:40.619999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1466.83entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.3400 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:40.803063: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:40.904069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1525.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:41.093111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:41.191363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1581.83entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:41.369341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:41.467264: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1603.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:41.641954: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:41.740337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1580.63entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.3600 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:41.935870: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:42.036194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1384.16entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.4000 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:42.234043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:42.344520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1483.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.2800 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:42.533002: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:42.631912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.42entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.3600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:42.802249: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:42.899921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1601.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.4200 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:43.076516: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:43.175553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1600.42entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.2100 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:43.369673: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:43.470982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1324.93entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.3000 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:43.702081: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:43.802838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1496.21entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.4700 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:43.982785: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:44.082144: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1557.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.4900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:44.271766: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:44.374167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1515.55entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.4000 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:44.569055: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:44.669716: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1505.83entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.3400 ; Coincidencias: 84/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.354600\n",
      "Precisión global: 82.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR sin optimizacion\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e9139",
   "metadata": {},
   "source": [
    "### 1.3 Aplicar modificaciones de optimización al modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac30ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warning] Model script is empty\n",
      "[info] Loading model script commands to model_ResBaGAN_discriminator from string\n",
      "[warning] Model script is empty\n",
      "[warning] DEPRECATION WARNING: Optimizing in full precision will require calibration data in the near future, to allow more accurate optimization algorithms which require inference on actual data.\n"
     ]
    }
   ],
   "source": [
    "# Crear un model script para el proceso de optimización\n",
    "\n",
    "model_script_lines = [\n",
    "    # Add normalization layer with mean [123.675, 116.28, 103.53] and std [58.395, 57.12, 57.375])\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # For multiple input nodes:\n",
    "    # {normalization_layer_name_1} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_1_from_hn})\\n',\n",
    "    # {normalization_layer_name_2} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_2_from_hn})\\n',\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Load the model script to ClientRunner so it will be considered on optimization\n",
    "runner.load_model_script(\"\".join(model_script_lines))\n",
    "runner.optimize_full_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d521d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:07.796378: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:08.558899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:04, 25.80entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.3900 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:35:12.695495: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:12.800920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1602.44entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.3500 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:12.987117: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:13.093916: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1597.56entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.4800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:13.274844: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:13.379376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1628.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.2600 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:13.563201: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:13.666750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1655.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:13.855468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:13.959353: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1627.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.2100 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:14.139219: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:14.244643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1639.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:14.422088: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:14.523884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1642.74entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.3400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:14.718330: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:14.819922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1668.52entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.3200 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:15.055009: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:15.164555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1336.18entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:15.358369: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:15.462884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1493.55entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.3400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:15.651544: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:15.756334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1541.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.3400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:15.937065: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:16.044294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1520.15entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.3500 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:16.242235: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:16.346185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1662.04entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.3900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:16.522809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:16.623804: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1609.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.4500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:16.815246: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:16.920566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1718.65entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.3700 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:17.100420: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:17.202553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.3100 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:17.377375: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:17.480373: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1635.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.4500 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:17.654455: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:17.755830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1636.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.2200 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:17.933288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:18.034868: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1599.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.3400 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:18.228513: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:18.341691: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1503.01entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.3700 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:18.541240: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:18.644940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1612.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.2900 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:18.822397: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:18.928234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1575.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.3600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:19.123144: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:19.226669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1524.07entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.3600 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:19.408771: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:19.511637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1626.79entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.4900 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:19.692160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:19.792999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1704.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.2900 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:19.967550: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:20.072116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1504.15entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.3300 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:20.272627: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:20.375815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1714.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.4000 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:20.567977: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:20.672901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1639.00entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.3900 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:20.847155: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:20.951061: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1531.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.2100 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:21.137706: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:21.240267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1620.76entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.4000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:21.418685: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:21.525149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1533.57entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:21.708001: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:21.809293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1577.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.4700 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:21.987203: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:22.088683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1621.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:22.281945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:22.387712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1510.78entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.4400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:22.589717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:22.694708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1691.16entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.4800 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:22.874198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:22.977385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1689.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.5000 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:23.161164: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:23.268578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1464.21entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.3000 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:23.459708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:23.564975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1426.23entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.2800 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:23.760617: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:23.865138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1653.22entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.3500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:24.047658: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:24.154836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1427.28entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.3200 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:24.349928: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:24.454482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1639.80entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.1600 ; Coincidencias: 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:24.635087: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:24.739933: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1417.57entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.5100 ; Coincidencias: 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:24.952367: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:25.060538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1677.19entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.3100 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:25.236034: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:25.338013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1645.16entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:25.536746: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:25.642535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1633.45entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.3600 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:25.820852: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:25.924902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1677.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.4300 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:26.107036: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:26.209377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1564.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.3500 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:26.392229: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:26.495311: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1619.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.3500 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:26.673461: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:26.775646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1513.41entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.5100 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:26.993868: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:27.099546: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1565.93entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:27.330517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:27.432412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1661.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.3300 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:27.616785: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:27.720957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1483.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.2800 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:27.907575: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:28.010494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1596.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.4400 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:28.186809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:28.290234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1651.84entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.5400 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:28.465045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:28.569646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1625.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.3200 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:28.745518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:28.846847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1558.37entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.1900 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:29.032225: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:29.136197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1669.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.3800 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:29.316178: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:29.418501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1669.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.2300 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:29.607586: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:29.710537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1664.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.2000 ; Coincidencias: 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:29.885946: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:29.988656: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1538.41entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.4000 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:30.170797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:30.273921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1693.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.2700 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:30.466348: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:30.569291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1666.38entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.2300 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:30.743047: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:30.845760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1662.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:31.037514: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:31.142079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1496.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.5100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:31.334949: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:31.440261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1580.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.5400 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:31.634971: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:31.737255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1627.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.2600 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:31.922210: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:32.024838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1623.45entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:32.218880: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:32.320741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1635.30entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.5000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:32.499824: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:32.601815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1636.05entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.4500 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:32.784146: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:32.888293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1542.13entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.5900 ; Coincidencias: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:33.077617: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:33.179707: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1512.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.2900 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:33.368869: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:33.473956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1406.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.4900 ; Coincidencias: 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:33.677136: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:33.783950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1481.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.4100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:33.971186: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:34.073852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1652.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.3300 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:34.261340: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:34.366348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1486.49entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.5000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:34.579083: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:34.684794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1490.77entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.5100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:34.881561: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:34.986508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1422.67entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.3900 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:35.180137: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:35.283757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1554.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.4700 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:35.486339: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:35.590724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1597.73entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.2600 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:35.782435: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:35.886398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1547.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.2700 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:36.064846: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:36.179443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1525.22entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.2600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:36.372095: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:36.478306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1604.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.3200 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:36.655668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:36.759929: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1504.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.3200 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:36.950231: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:37.052227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1662.91entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.4100 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:37.230991: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:37.333758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1643.18entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:37.515156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:37.620283: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1453.17entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.2600 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:37.808121: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:37.913175: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1645.65entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.4700 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:38.102572: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:38.207377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1559.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.2100 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:38.391187: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:38.500051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1466.02entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.3300 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:38.688337: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:38.791709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1462.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.4700 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:38.981979: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:39.087228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1536.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.3400 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:39.286252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:39.390561: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1585.09entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.4100 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:39.570191: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:39.675532: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1581.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.4200 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:39.868267: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:39.974315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1626.75entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.1400 ; Coincidencias: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:40.160341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:40.266267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1496.84entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:40.465552: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:40.569989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1619.12entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.3600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:40.750174: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:40.857530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1440.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.4200 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:41.053111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:41.156590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1618.50entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.3600 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:41.344027: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:41.450568: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1530.31entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.3200 ; Coincidencias: 84/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.355800\n",
      "Precisión global: 82.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR con optimizacion\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_FP_OPTIMIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce0f2c",
   "metadata": {},
   "source": [
    "### 1.4 Cuantizar el modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8005d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataset de calibración\n",
    "# The original images are being used, just as the input to the SDK_FP_OPTIMIZED emulator\n",
    "total_images = 1050\n",
    "\n",
    "dataset.to_train()\n",
    "calib_dataset = np.zeros((total_images, sizex, sizey, B), dtype = np.float32)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Seleccionamos batches del dataloader para guardarlos en el dataset\n",
    "for (inputs, labels, targets_pixel_level) in data_loader:\n",
    "    for img in inputs:\n",
    "        if count >= total_images:\n",
    "            break\n",
    "            \n",
    "        # Los inputs son de la forma (batch_size, B, sizex, sizey)\n",
    "        img_np = img.numpy()\n",
    "        # Trasponemos los inputs a formato (batch_size, sizex, sizey, B)\n",
    "        img_har = np.transpose(img_np, (1, 2, 0))\n",
    "\n",
    "        calib_dataset[count] = img_har\n",
    "        count += 1\n",
    "        \n",
    "    if count >= total_images:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layers are: \n",
      "['model_ResBaGAN_discriminator/input_layer1']\n",
      "[info] Loading model script commands to model_ResBaGAN_discriminator from string\n",
      "[info] Starting Model Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 18:48:47.317625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:47.330404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:47.330667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:47.331934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:47.332145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:47.332333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.695977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.696229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.696422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.696573: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-08 18:48:48.696599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-08 18:48:48.930123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.931988: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.932199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.933768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.933975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:48.934160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.324010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.324253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.324456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.324605: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-08 18:48:50.324632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model received quantization params from the hn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 18:48:50.742883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.745101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.745344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.746618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.746831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:50.747033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.081865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.082110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.082318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.082473: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-08 18:48:52.082509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-08 18:48:52.321162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.323132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.323343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.324470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.324676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:52.324866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:53.720367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:53.720642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:53.720833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:48:53.720975: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-08 18:48:53.721000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] MatmulDecompose skipped\n",
      "[info] Starting Mixed Precision\n",
      "[info] Model Optimization Algorithm Mixed Precision is done (completion time is 00:00:00.20)\n",
      "[info] LayerNorm Decomposition skipped\n",
      "[info] Starting Statistics Collector\n",
      "[info] Using dataset with 64 entries for calibration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration:   0%|                                          | 0/64 [00:00<?, ?entries/s]2025-06-08 18:48:57.821409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:48:57.841689: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:05.683119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "Calibration: 100%|█████████████████████████████████| 64/64 [00:10<00:00,  6.30entries/s]\n",
      "2025-06-08 18:49:06.504502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-06-08 18:49:06.508945: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:06.524867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:06.540775: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:06.556613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:06.572115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:06.587999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:06.603558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Statistics Collector is done (completion time is 00:00:10.94)\n",
      "[info] Starting Fix zp_comp Encoding\n",
      "[info] Model Optimization Algorithm Fix zp_comp Encoding is done (completion time is 00:00:00.00)\n",
      "[info] Matmul Equalization skipped\n",
      "[info] Starting MatmulDecomposeFix\n",
      "[info] Model Optimization Algorithm MatmulDecomposeFix is done (completion time is 00:00:00.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 18:49:15.205252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:15.219842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:15.220098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:15.221542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:15.221760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:15.221962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:16.593939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:16.594181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:16.594385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:16.594534: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-08 18:49:16.594562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-08 18:49:17.293892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:17.295641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:17.295868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:17.297266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:17.297486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:17.297687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:18.613587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:18.613843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:18.614054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 18:49:18.614230: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-08 18:49:18.614257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Finetune encoding skipped\n",
      "[info] Bias Correction skipped\n",
      "[warning] Dataset is larger than dataset_size in Adaround. Increasing the algorithm dataset size might improve the results\n",
      "[info] Starting Adaround\n",
      "[info] The algorithm Adaround will use up to 0.23 GB of storage space\n",
      "[info] Using dataset with 1024 entries for Adaround\n",
      "[info] Using dataset with 64 entries for bias correction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 18:49:21.796199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:21.796410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:22.363370: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:22.363529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:   0%| | 0/26 [00:00<?, ?blocks/s, Layers=['model_ResBaGAN_discriminator/conv1_2025-06-08 18:49:23.000464: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 18:49:24.766834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 18:49:29.425809: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-06-08 18:49:29.494704: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x55615406c8c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-08 18:49:29.494725: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-06-08 18:49:29.510940: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-08 18:49:29.641205: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<32:08:13,  2.82s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<32:08:13,  2.82s/batches, l2_loss: 0.0001 - round_loss:\u001b[A\n",
      "Training:   0%| | 93/40960 [00:03<16:00, 42.55batches/s, l2_loss: 0.0001 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 93/40960 [00:03<16:00, 42.55batches/s, l2_loss: 0.0002 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 188/40960 [00:03<07:20, 92.66batches/s, l2_loss: 0.0002 - round_loss: \u001b[A\n",
      "Training:   0%| | 188/40960 [00:03<07:20, 92.66batches/s, l2_loss: 0.0003 - round_loss: \u001b[A\n",
      "Training:   1%| | 282/40960 [00:03<04:38, 146.24batches/s, l2_loss: 0.0003 - round_loss:\u001b[A\n",
      "Training:   1%| | 282/40960 [00:03<04:38, 146.24batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   1%| | 376/40960 [00:03<03:22, 200.57batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   1%| | 376/40960 [00:03<03:22, 200.57batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   1%| | 470/40960 [00:03<02:40, 252.35batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   1%| | 470/40960 [00:03<02:40, 252.35batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   1%| | 565/40960 [00:04<02:14, 300.13batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   1%| | 565/40960 [00:04<02:14, 300.13batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   2%| | 662/40960 [00:04<01:57, 343.07batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   2%| | 662/40960 [00:04<01:57, 343.07batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   2%| | 755/40960 [00:04<01:47, 372.99batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   2%| | 755/40960 [00:04<01:47, 372.99batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   2%| | 846/40960 [00:04<01:41, 394.19batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   2%| | 846/40960 [00:04<01:41, 394.19batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   2%| | 940/40960 [00:04<01:36, 413.70batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   2%| | 940/40960 [00:04<01:36, 413.70batches/s, l2_loss: 0.0002 - round_loss:\u001b[A\n",
      "Training:   3%| | 1034/40960 [00:05<01:33, 428.44batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1034/40960 [00:05<01:33, 428.44batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1131/40960 [00:05<01:29, 443.36batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1131/40960 [00:05<01:29, 443.36batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1226/40960 [00:05<01:28, 451.28batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1226/40960 [00:05<01:28, 451.28batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1315/40960 [00:05<01:28, 449.41batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1315/40960 [00:05<01:28, 449.41batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1401/40960 [00:05<01:29, 443.36batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   3%| | 1401/40960 [00:05<01:29, 443.36batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   4%| | 1493/40960 [00:06<01:28, 448.11batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   4%| | 1493/40960 [00:06<01:28, 448.11batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   4%| | 1587/40960 [00:06<01:26, 454.46batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   4%| | 1587/40960 [00:06<01:26, 454.46batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   4%| | 1674/40960 [00:06<01:27, 448.53batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   4%| | 1674/40960 [00:06<01:27, 448.53batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   4%| | 1765/40960 [00:06<01:27, 448.99batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   4%| | 1765/40960 [00:06<01:27, 448.99batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 1844/40960 [00:06<01:30, 431.91batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 1844/40960 [00:06<01:30, 431.91batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 1934/40960 [00:07<01:29, 436.43batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 1934/40960 [00:07<01:29, 436.43batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 2027/40960 [00:07<01:27, 443.88batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 2027/40960 [00:07<01:27, 443.88batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 2123/40960 [00:07<01:25, 453.73batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 2123/40960 [00:07<01:25, 453.73batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 2213/40960 [00:07<01:25, 451.52batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   5%| | 2213/40960 [00:07<01:25, 451.52batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2292/40960 [00:07<01:29, 434.06batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2292/40960 [00:07<01:29, 434.06batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2381/40960 [00:08<01:28, 436.49batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2381/40960 [00:08<01:28, 436.49batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2469/40960 [00:08<01:28, 437.13batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2469/40960 [00:08<01:28, 437.13batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2563/40960 [00:08<01:26, 445.96batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%| | 2563/40960 [00:08<01:26, 445.96batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2659/40960 [00:08<01:24, 455.22batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   6%| | 2659/40960 [00:08<01:24, 455.22batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   7%| | 2750/40960 [00:08<01:24, 453.92batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   7%| | 2750/40960 [00:08<01:24, 453.92batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   7%| | 2844/40960 [00:09<01:23, 458.31batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   7%| | 2844/40960 [00:09<01:23, 458.31batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   7%| | 2938/40960 [00:09<01:22, 460.62batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   7%| | 2938/40960 [00:09<01:22, 460.62batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   7%| | 3028/40960 [00:09<01:22, 457.41batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   7%| | 3028/40960 [00:09<01:22, 457.41batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3116/40960 [00:09<01:23, 451.70batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3116/40960 [00:09<01:23, 451.70batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3202/40960 [00:09<01:25, 444.16batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3202/40960 [00:09<01:25, 444.16batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3289/40960 [00:10<01:25, 441.21batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3289/40960 [00:10<01:25, 441.21batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3382/40960 [00:10<01:23, 447.62batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3382/40960 [00:10<01:23, 447.62batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3476/40960 [00:10<01:22, 453.38batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   8%| | 3476/40960 [00:10<01:22, 453.38batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   9%| | 3572/40960 [00:10<01:21, 461.12batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   9%| | 3572/40960 [00:10<01:21, 461.12batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   9%| | 3669/40960 [00:10<01:19, 467.91batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   9%| | 3669/40960 [00:10<01:19, 467.91batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   9%| | 3764/40960 [00:11<01:19, 468.74batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   9%| | 3764/40960 [00:11<01:19, 468.74batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   9%| | 3858/40960 [00:11<01:19, 469.07batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:   9%| | 3858/40960 [00:11<01:19, 469.07batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  10%| | 3943/40960 [00:11<01:21, 454.74batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  10%| | 3943/40960 [00:11<01:21, 454.74batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  10%| | 4029/40960 [00:11<01:22, 446.01batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  10%| | 4029/40960 [00:11<01:22, 446.01batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  10%| | 4123/40960 [00:11<01:21, 452.72batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  10%| | 4123/40960 [00:11<01:21, 452.72batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  10%| | 4217/40960 [00:12<01:20, 456.93batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  10%| | 4217/40960 [00:12<01:20, 456.93batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4310/40960 [00:12<01:19, 459.06batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4310/40960 [00:12<01:19, 459.06batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4403/40960 [00:12<01:19, 460.38batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4403/40960 [00:12<01:19, 460.38batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4495/40960 [00:12<01:19, 459.28batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4495/40960 [00:12<01:19, 459.28batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4591/40960 [00:12<01:18, 464.69batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4591/40960 [00:12<01:18, 464.69batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4679/40960 [00:13<01:19, 457.05batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  11%| | 4679/40960 [00:13<01:19, 457.05batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  12%| | 4765/40960 [00:13<01:20, 448.16batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  12%| | 4765/40960 [00:13<01:20, 448.16batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  12%| | 4851/40960 [00:13<01:21, 442.47batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  12%| | 4851/40960 [00:13<01:21, 442.47batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  12%| | 4941/40960 [00:13<01:21, 444.42batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  12%| | 4941/40960 [00:13<01:21, 444.42batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  12%| | 5034/40960 [00:13<01:19, 450.57batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  12%| | 5034/40960 [00:13<01:19, 450.57batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5128/40960 [00:14<01:18, 455.37batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5128/40960 [00:14<01:18, 455.37batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5222/40960 [00:14<01:17, 458.63batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5222/40960 [00:14<01:17, 458.63batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5310/40960 [00:14<01:18, 452.78batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5310/40960 [00:14<01:18, 452.78batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5393/40960 [00:14<01:20, 440.10batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5393/40960 [00:14<01:20, 440.10batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5474/40960 [00:14<01:22, 429.18batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5474/40960 [00:14<01:22, 429.18batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5564/40960 [00:15<01:21, 434.61batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5564/40960 [00:15<01:21, 434.61batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5659/40960 [00:15<01:19, 445.99batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5659/40960 [00:15<01:19, 445.99batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5754/40960 [00:15<01:17, 453.24batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5754/40960 [00:15<01:17, 453.24batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5849/40960 [00:15<01:16, 459.26batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5849/40960 [00:15<01:16, 459.26batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5945/40960 [00:15<01:15, 464.53batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5945/40960 [00:15<01:15, 464.53batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6041/40960 [00:16<01:14, 468.06batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6041/40960 [00:16<01:14, 468.06batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6136/40960 [00:16<01:14, 469.54batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6136/40960 [00:16<01:14, 469.54batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6230/40960 [00:16<01:14, 469.23batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6230/40960 [00:16<01:14, 469.23batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6324/40960 [00:16<01:13, 468.97batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6324/40960 [00:16<01:13, 468.97batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6421/40960 [00:16<01:13, 472.90batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6421/40960 [00:16<01:13, 472.90batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6516/40960 [00:17<01:12, 473.32batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6516/40960 [00:17<01:12, 473.32batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6607/40960 [00:17<01:13, 467.19batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6607/40960 [00:17<01:13, 467.19batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|▏| 6703/40960 [00:17<01:12, 470.05batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6703/40960 [00:17<01:12, 470.05batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6799/40960 [00:17<01:12, 472.09batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6799/40960 [00:17<01:12, 472.09batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6895/40960 [00:17<01:11, 473.82batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6895/40960 [00:17<01:11, 473.82batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6992/40960 [00:18<01:11, 475.83batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6992/40960 [00:18<01:11, 475.83batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7088/40960 [00:18<01:11, 476.01batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7088/40960 [00:18<01:11, 476.01batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7183/40960 [00:18<01:11, 475.65batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7183/40960 [00:18<01:11, 475.65batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7278/40960 [00:18<01:10, 474.48batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7278/40960 [00:18<01:10, 474.48batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7373/40960 [00:18<01:10, 474.11batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7373/40960 [00:18<01:10, 474.11batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7468/40960 [00:19<01:10, 473.01batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7468/40960 [00:19<01:10, 473.01batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7565/40960 [00:19<01:10, 475.30batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7565/40960 [00:19<01:10, 475.30batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7660/40960 [00:19<01:10, 474.64batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7660/40960 [00:19<01:10, 474.64batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7755/40960 [00:19<01:09, 474.47batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7755/40960 [00:19<01:09, 474.47batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7850/40960 [00:19<01:09, 474.59batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7850/40960 [00:19<01:09, 474.59batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7945/40960 [00:20<01:09, 474.11batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7945/40960 [00:20<01:09, 474.11batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8041/40960 [00:20<01:09, 474.67batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8041/40960 [00:20<01:09, 474.67batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8136/40960 [00:20<01:09, 473.95batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8136/40960 [00:20<01:09, 473.95batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8221/40960 [00:20<01:11, 458.36batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8221/40960 [00:20<01:11, 458.36batches/s, l2_loss: 0.0001 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8309/40960 [00:20<01:12, 451.41batches/s, l2_loss: 0.0001 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8309/40960 [00:20<01:12, 451.41batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8393/40960 [00:21<01:13, 441.12batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8393/40960 [00:21<01:13, 441.12batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8480/40960 [00:21<01:14, 438.30batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8480/40960 [00:21<01:14, 438.30batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8568/40960 [00:21<01:13, 438.20batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8568/40960 [00:21<01:13, 438.20batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8657/40960 [00:21<01:13, 438.92batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8657/40960 [00:21<01:13, 438.92batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8744/40960 [00:21<01:13, 437.14batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8744/40960 [00:21<01:13, 437.14batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8830/40960 [00:22<01:13, 434.47batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8830/40960 [00:22<01:13, 434.47batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8917/40960 [00:22<01:13, 433.53batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8917/40960 [00:22<01:13, 433.53batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9003/40960 [00:22<01:13, 431.92batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9003/40960 [00:22<01:13, 431.92batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9089/40960 [00:22<01:14, 430.51batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9089/40960 [00:22<01:14, 430.51batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9175/40960 [00:22<01:13, 430.13batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9175/40960 [00:22<01:13, 430.13batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9262/40960 [00:23<01:13, 430.70batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9262/40960 [00:23<01:13, 430.70batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9349/40960 [00:23<01:13, 430.27batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9349/40960 [00:23<01:13, 430.27batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9432/40960 [00:23<01:14, 424.99batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9432/40960 [00:23<01:14, 424.99batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9518/40960 [00:23<01:13, 425.86batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9518/40960 [00:23<01:13, 425.86batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9606/40960 [00:23<01:13, 428.71batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9606/40960 [00:23<01:13, 428.71batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9687/40960 [00:24<01:14, 420.27batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9687/40960 [00:24<01:14, 420.27batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9770/40960 [00:24<01:14, 417.57batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9770/40960 [00:24<01:14, 417.57batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9853/40960 [00:24<01:14, 416.26batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9853/40960 [00:24<01:14, 416.26batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9940/40960 [00:24<01:13, 420.73batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9940/40960 [00:24<01:13, 420.73batches/s, l2_loss: 0.0002 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10026/40960 [00:24<01:13, 422.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  24%|▏| 10026/40960 [00:24<01:13, 422.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  25%|▏| 10110/40960 [00:25<01:13, 420.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  25%|▏| 10110/40960 [00:25<01:13, 420.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  25%|▏| 10195/40960 [00:25<01:13, 420.89batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  25%|▏| 10195/40960 [00:25<01:13, 420.89batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  25%|▎| 10283/40960 [00:25<01:12, 425.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  25%|▎| 10283/40960 [00:25<01:12, 425.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  25%|▎| 10369/40960 [00:25<01:11, 426.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  25%|▎| 10369/40960 [00:25<01:11, 426.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10456/40960 [00:25<01:11, 428.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10456/40960 [00:25<01:11, 428.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10538/40960 [00:26<01:12, 422.24batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10538/40960 [00:26<01:12, 422.24batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10622/40960 [00:26<01:12, 421.14batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10622/40960 [00:26<01:12, 421.14batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10707/40960 [00:26<01:11, 422.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10707/40960 [00:26<01:11, 422.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10795/40960 [00:26<01:10, 427.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  26%|▎| 10795/40960 [00:26<01:10, 427.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 10880/40960 [00:26<01:10, 426.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 10880/40960 [00:26<01:10, 426.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 10968/40960 [00:27<01:09, 429.63batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 10968/40960 [00:27<01:09, 429.63batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 11054/40960 [00:27<01:09, 429.55batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 11054/40960 [00:27<01:09, 429.55batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 11141/40960 [00:27<01:09, 430.57batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 11141/40960 [00:27<01:09, 430.57batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 11226/40960 [00:27<01:09, 428.80batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  27%|▎| 11226/40960 [00:27<01:09, 428.80batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11314/40960 [00:27<01:08, 431.80batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11314/40960 [00:27<01:08, 431.80batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11401/40960 [00:28<01:08, 431.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11401/40960 [00:28<01:08, 431.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11483/40960 [00:28<01:09, 424.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11483/40960 [00:28<01:09, 424.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11570/40960 [00:28<01:08, 427.54batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11570/40960 [00:28<01:08, 427.54batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11654/40960 [00:28<01:08, 425.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11654/40960 [00:28<01:08, 425.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 11738/40960 [00:28<01:09, 423.37batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 11738/40960 [00:28<01:09, 423.37batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 11825/40960 [00:29<01:08, 426.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 11825/40960 [00:29<01:08, 426.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 11908/40960 [00:29<01:08, 422.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 11908/40960 [00:29<01:08, 422.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 11995/40960 [00:29<01:08, 424.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 11995/40960 [00:29<01:08, 424.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 12081/40960 [00:29<01:07, 425.74batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  29%|▎| 12081/40960 [00:29<01:07, 425.74batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12164/40960 [00:29<01:08, 422.28batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12164/40960 [00:29<01:08, 422.28batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12251/40960 [00:30<01:07, 425.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12251/40960 [00:30<01:07, 425.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12334/40960 [00:30<01:07, 421.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12334/40960 [00:30<01:07, 421.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12419/40960 [00:30<01:07, 421.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12419/40960 [00:30<01:07, 421.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12506/40960 [00:30<01:06, 425.74batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12506/40960 [00:30<01:06, 425.74batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12595/40960 [00:30<01:05, 430.76batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12595/40960 [00:30<01:05, 430.76batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12680/40960 [00:31<01:06, 427.90batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12680/40960 [00:31<01:06, 427.90batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12765/40960 [00:31<01:06, 426.36batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12765/40960 [00:31<01:06, 426.36batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12851/40960 [00:31<01:05, 426.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  31%|▎| 12851/40960 [00:31<01:05, 426.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 12938/40960 [00:31<01:05, 428.51batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 12938/40960 [00:31<01:05, 428.51batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13024/40960 [00:31<01:05, 428.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13024/40960 [00:31<01:05, 428.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13111/40960 [00:32<01:04, 429.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13111/40960 [00:32<01:04, 429.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13190/40960 [00:32<01:06, 417.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13190/40960 [00:32<01:06, 417.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13266/40960 [00:32<01:08, 405.72batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13266/40960 [00:32<01:08, 405.72batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13347/40960 [00:32<01:08, 404.33batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13347/40960 [00:32<01:08, 404.33batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13434/40960 [00:32<01:06, 412.24batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13434/40960 [00:32<01:06, 412.24batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13520/40960 [00:33<01:05, 416.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13520/40960 [00:33<01:05, 416.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13598/40960 [00:33<01:07, 407.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13598/40960 [00:33<01:07, 407.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13676/40960 [00:33<01:08, 400.76batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  33%|▎| 13676/40960 [00:33<01:08, 400.76batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13751/40960 [00:33<01:09, 392.74batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13751/40960 [00:33<01:09, 392.74batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13831/40960 [00:34<01:08, 394.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13831/40960 [00:34<01:08, 394.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13910/40960 [00:34<01:08, 394.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13910/40960 [00:34<01:08, 394.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13994/40960 [00:34<01:07, 400.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13994/40960 [00:34<01:07, 400.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 14079/40960 [00:34<01:06, 406.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  34%|▎| 14079/40960 [00:34<01:06, 406.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14157/40960 [00:34<01:06, 400.47batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14157/40960 [00:34<01:06, 400.47batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14226/40960 [00:35<01:09, 382.67batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14226/40960 [00:35<01:09, 382.67batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14298/40960 [00:35<01:11, 375.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14298/40960 [00:35<01:11, 375.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14376/40960 [00:35<01:10, 379.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14376/40960 [00:35<01:10, 379.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14463/40960 [00:35<01:06, 395.84batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14463/40960 [00:35<01:06, 395.84batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14548/40960 [00:35<01:05, 403.66batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14548/40960 [00:35<01:05, 403.66batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14633/40960 [00:36<01:04, 409.72batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14633/40960 [00:36<01:04, 409.72batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14700/40960 [00:36<01:08, 385.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14700/40960 [00:36<01:08, 385.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14772/40960 [00:36<01:09, 377.36batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14772/40960 [00:36<01:09, 377.36batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14838/40960 [00:36<01:12, 362.06batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14838/40960 [00:36<01:12, 362.06batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14914/40960 [00:36<01:11, 366.82batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  36%|▎| 14914/40960 [00:36<01:11, 366.82batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 14997/40960 [00:37<01:08, 380.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 14997/40960 [00:37<01:08, 380.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15081/40960 [00:37<01:06, 391.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15081/40960 [00:37<01:06, 391.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15144/40960 [00:37<01:10, 367.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15144/40960 [00:37<01:10, 367.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15216/40960 [00:37<01:10, 364.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15216/40960 [00:37<01:10, 364.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15295/40960 [00:37<01:08, 372.37batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15295/40960 [00:37<01:08, 372.37batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15357/40960 [00:38<01:12, 353.64batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  37%|▎| 15357/40960 [00:38<01:12, 353.64batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15402/40960 [00:38<01:21, 314.94batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15402/40960 [00:38<01:21, 314.94batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15465/40960 [00:38<01:21, 314.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15465/40960 [00:38<01:21, 314.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15526/40960 [00:38<01:21, 310.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15526/40960 [00:38<01:21, 310.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15579/40960 [00:38<01:25, 296.96batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15579/40960 [00:38<01:25, 296.96batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15627/40960 [00:39<01:30, 279.46batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15627/40960 [00:39<01:30, 279.46batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15669/40960 [00:39<01:37, 258.46batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15669/40960 [00:39<01:37, 258.46batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15710/40960 [00:39<01:44, 242.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15710/40960 [00:39<01:44, 242.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15756/40960 [00:39<01:45, 237.84batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15756/40960 [00:39<01:45, 237.84batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 15801/40960 [00:39<01:47, 233.25batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 15801/40960 [00:39<01:47, 233.25batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 15868/40960 [00:40<01:35, 263.26batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 15868/40960 [00:40<01:35, 263.26batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 15942/40960 [00:40<01:24, 294.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 15942/40960 [00:40<01:24, 294.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 16006/40960 [00:40<01:22, 301.46batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 16006/40960 [00:40<01:22, 301.46batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 16088/40960 [00:40<01:14, 333.85batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 16088/40960 [00:40<01:14, 333.85batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 16167/40960 [00:40<01:10, 350.83batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  39%|▍| 16167/40960 [00:40<01:10, 350.83batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16240/40960 [00:41<01:09, 353.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16240/40960 [00:41<01:09, 353.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16320/40960 [00:41<01:07, 367.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16320/40960 [00:41<01:07, 367.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16390/40960 [00:41<01:07, 361.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16390/40960 [00:41<01:07, 361.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16461/40960 [00:41<01:08, 358.42batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16461/40960 [00:41<01:08, 358.42batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16540/40960 [00:41<01:06, 369.13batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  40%|▍| 16540/40960 [00:41<01:06, 369.13batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16619/40960 [00:42<01:04, 376.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16619/40960 [00:42<01:04, 376.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16703/40960 [00:42<01:02, 388.19batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16703/40960 [00:42<01:02, 388.19batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16786/40960 [00:42<01:01, 395.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16786/40960 [00:42<01:01, 395.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16864/40960 [00:42<01:01, 393.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16864/40960 [00:42<01:01, 393.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16948/40960 [00:42<00:59, 400.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  41%|▍| 16948/40960 [00:42<00:59, 400.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17035/40960 [00:43<00:58, 409.54batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17035/40960 [00:43<00:58, 409.54batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17120/40960 [00:43<00:57, 413.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17120/40960 [00:43<00:57, 413.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17205/40960 [00:43<00:56, 417.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17205/40960 [00:43<00:56, 417.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17291/40960 [00:43<00:56, 419.71batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17291/40960 [00:43<00:56, 419.71batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17376/40960 [00:43<00:56, 420.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  42%|▍| 17376/40960 [00:43<00:56, 420.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17451/40960 [00:44<00:57, 406.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17451/40960 [00:44<00:57, 406.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17518/40960 [00:44<01:01, 383.78batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17518/40960 [00:44<01:01, 383.78batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17598/40960 [00:44<01:00, 387.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17598/40960 [00:44<01:00, 387.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17669/40960 [00:44<01:01, 377.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17669/40960 [00:44<01:01, 377.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17724/40960 [00:44<01:07, 346.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17724/40960 [00:44<01:07, 346.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17808/40960 [00:45<01:02, 368.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  43%|▍| 17808/40960 [00:45<01:02, 368.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  44%|▍| 17894/40960 [00:45<00:59, 385.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  44%|▍| 17894/40960 [00:45<00:59, 385.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  44%|▍| 17980/40960 [00:45<00:57, 397.51batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  44%|▍| 17980/40960 [00:45<00:57, 397.51batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  44%|▍| 18061/40960 [00:45<00:57, 398.57batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  44%|▍| 18061/40960 [00:45<00:57, 398.57batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  44%|▍| 18145/40960 [00:45<00:56, 404.22batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  44%|▍| 18145/40960 [00:45<00:56, 404.22batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18232/40960 [00:46<00:55, 412.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18232/40960 [00:46<00:55, 412.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18315/40960 [00:46<00:54, 411.96batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18315/40960 [00:46<00:54, 411.96batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18401/40960 [00:46<00:54, 417.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18401/40960 [00:46<00:54, 417.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18486/40960 [00:46<00:53, 418.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18486/40960 [00:46<00:53, 418.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18568/40960 [00:46<00:53, 416.08batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  45%|▍| 18568/40960 [00:46<00:53, 416.08batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18649/40960 [00:47<00:54, 411.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18649/40960 [00:47<00:54, 411.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18734/40960 [00:47<00:53, 414.21batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18734/40960 [00:47<00:53, 414.21batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18816/40960 [00:47<00:53, 411.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18816/40960 [00:47<00:53, 411.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18900/40960 [00:47<00:53, 412.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18900/40960 [00:47<00:53, 412.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18981/40960 [00:47<00:53, 409.54batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  46%|▍| 18981/40960 [00:47<00:53, 409.54batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19067/40960 [00:48<00:52, 414.47batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19067/40960 [00:48<00:52, 414.47batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19153/40960 [00:48<00:52, 417.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19153/40960 [00:48<00:52, 417.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19235/40960 [00:48<00:52, 414.87batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19235/40960 [00:48<00:52, 414.87batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19319/40960 [00:48<00:52, 415.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19319/40960 [00:48<00:52, 415.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19405/40960 [00:48<00:51, 419.60batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  47%|▍| 19405/40960 [00:48<00:51, 419.60batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19490/40960 [00:49<00:51, 420.90batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19490/40960 [00:49<00:51, 420.90batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19574/40960 [00:49<00:50, 420.19batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19574/40960 [00:49<00:50, 420.19batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19658/40960 [00:49<00:50, 419.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19658/40960 [00:49<00:50, 419.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19744/40960 [00:49<00:50, 421.49batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19744/40960 [00:49<00:50, 421.49batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19827/40960 [00:49<00:50, 419.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  48%|▍| 19827/40960 [00:49<00:50, 419.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 19911/40960 [00:50<00:50, 418.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 19911/40960 [00:50<00:50, 418.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 19994/40960 [00:50<00:50, 417.03batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 19994/40960 [00:50<00:50, 417.03batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 20079/40960 [00:50<00:49, 418.29batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 20079/40960 [00:50<00:49, 418.29batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 20164/40960 [00:50<00:49, 419.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 20164/40960 [00:50<00:49, 419.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 20249/40960 [00:50<00:49, 421.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  49%|▍| 20249/40960 [00:50<00:49, 421.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▍| 20336/40960 [00:51<00:48, 424.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▍| 20336/40960 [00:51<00:48, 424.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▍| 20423/40960 [00:51<00:48, 426.82batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▍| 20423/40960 [00:51<00:48, 426.82batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▌| 20504/40960 [00:51<00:48, 420.07batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▌| 20504/40960 [00:51<00:48, 420.07batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▌| 20589/40960 [00:51<00:48, 420.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▌| 20589/40960 [00:51<00:48, 420.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▌| 20672/40960 [00:51<00:48, 418.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  50%|▌| 20672/40960 [00:51<00:48, 418.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  51%|▌| 20756/40960 [00:52<00:48, 418.56batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  51%|▌| 20756/40960 [00:52<00:48, 418.56batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  51%|▌| 20842/40960 [00:52<00:47, 421.11batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  51%|▌| 20842/40960 [00:52<00:47, 421.11batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  51%|▌| 20929/40960 [00:52<00:47, 424.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  51%|▌| 20929/40960 [00:52<00:47, 424.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  51%|▌| 21016/40960 [00:52<00:46, 426.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  51%|▌| 21016/40960 [00:52<00:46, 426.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21101/40960 [00:52<00:46, 425.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21101/40960 [00:52<00:46, 425.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21185/40960 [00:53<00:46, 422.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21185/40960 [00:53<00:46, 422.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21273/40960 [00:53<00:46, 427.28batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21273/40960 [00:53<00:46, 427.28batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21358/40960 [00:53<00:45, 426.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21358/40960 [00:53<00:45, 426.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21445/40960 [00:53<00:45, 428.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  52%|▌| 21445/40960 [00:53<00:45, 428.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21532/40960 [00:53<00:45, 429.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21532/40960 [00:53<00:45, 429.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21617/40960 [00:54<00:45, 427.67batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21617/40960 [00:54<00:45, 427.67batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21703/40960 [00:54<00:45, 427.63batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21703/40960 [00:54<00:45, 427.63batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21786/40960 [00:54<00:45, 423.83batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21786/40960 [00:54<00:45, 423.83batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21871/40960 [00:54<00:45, 423.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  53%|▌| 21871/40960 [00:54<00:45, 423.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 21956/40960 [00:54<00:44, 423.24batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 21956/40960 [00:54<00:44, 423.24batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 22042/40960 [00:55<00:44, 424.26batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 22042/40960 [00:55<00:44, 424.26batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 22128/40960 [00:55<00:44, 424.61batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 22128/40960 [00:55<00:44, 424.61batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 22211/40960 [00:55<00:44, 421.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 22211/40960 [00:55<00:44, 421.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [00:55<00:44, 422.09batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [00:55<00:44, 422.09batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22380/40960 [00:55<00:44, 420.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22380/40960 [00:55<00:44, 420.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22465/40960 [00:56<00:43, 421.29batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22465/40960 [00:56<00:43, 421.29batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22551/40960 [00:56<00:43, 423.67batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22551/40960 [00:56<00:43, 423.67batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22638/40960 [00:56<00:42, 426.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22638/40960 [00:56<00:42, 426.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22724/40960 [00:56<00:42, 427.05batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  55%|▌| 22724/40960 [00:56<00:42, 427.05batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  56%|▌| 22809/40960 [00:56<00:42, 425.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  56%|▌| 22809/40960 [00:56<00:42, 425.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  56%|▌| 22893/40960 [00:57<00:42, 423.63batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  56%|▌| 22893/40960 [00:57<00:42, 423.63batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  56%|▌| 22978/40960 [00:57<00:42, 423.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  56%|▌| 22978/40960 [00:57<00:42, 423.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  56%|▌| 23061/40960 [00:57<00:42, 420.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  56%|▌| 23061/40960 [00:57<00:42, 420.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23146/40960 [00:57<00:42, 421.03batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23146/40960 [00:57<00:42, 421.03batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23233/40960 [00:57<00:41, 424.76batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23233/40960 [00:57<00:41, 424.76batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23320/40960 [00:58<00:41, 427.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23320/40960 [00:58<00:41, 427.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23408/40960 [00:58<00:40, 430.09batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23408/40960 [00:58<00:40, 430.09batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23495/40960 [00:58<00:40, 430.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  57%|▌| 23495/40960 [00:58<00:40, 430.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23580/40960 [00:58<00:40, 428.48batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23580/40960 [00:58<00:40, 428.48batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23665/40960 [00:58<00:40, 426.37batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23665/40960 [00:58<00:40, 426.37batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23752/40960 [00:59<00:40, 427.56batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23752/40960 [00:59<00:40, 427.56batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23836/40960 [00:59<00:40, 424.57batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23836/40960 [00:59<00:40, 424.57batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23922/40960 [00:59<00:40, 425.85batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  58%|▌| 23922/40960 [00:59<00:40, 425.85batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24006/40960 [00:59<00:40, 423.80batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24006/40960 [00:59<00:40, 423.80batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24091/40960 [00:59<00:39, 423.64batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24091/40960 [00:59<00:39, 423.64batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24179/40960 [01:00<00:39, 427.61batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24179/40960 [01:00<00:39, 427.61batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24264/40960 [01:00<00:39, 426.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24264/40960 [01:00<00:39, 426.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24349/40960 [01:00<00:39, 425.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  59%|▌| 24349/40960 [01:00<00:39, 425.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24436/40960 [01:00<00:38, 427.79batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24436/40960 [01:00<00:38, 427.79batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24524/40960 [01:00<00:38, 430.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24524/40960 [01:00<00:38, 430.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24610/40960 [01:01<00:38, 429.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24610/40960 [01:01<00:38, 429.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24695/40960 [01:01<00:38, 427.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24695/40960 [01:01<00:38, 427.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24775/40960 [01:01<00:38, 418.17batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  60%|▌| 24775/40960 [01:01<00:38, 418.17batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  61%|▌| 24862/40960 [01:01<00:38, 422.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  61%|▌| 24862/40960 [01:01<00:38, 422.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  61%|▌| 24948/40960 [01:01<00:37, 423.77batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  61%|▌| 24948/40960 [01:01<00:37, 423.77batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  61%|▌| 25035/40960 [01:02<00:37, 426.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 25035/40960 [01:02<00:37, 426.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  61%|▌| 25121/40960 [01:02<00:37, 427.07batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  61%|▌| 25121/40960 [01:02<00:37, 427.07batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25204/40960 [01:02<00:37, 423.22batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25204/40960 [01:02<00:37, 423.22batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25290/40960 [01:02<00:36, 424.24batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25290/40960 [01:02<00:36, 424.24batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25377/40960 [01:02<00:36, 426.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25377/40960 [01:02<00:36, 426.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25461/40960 [01:03<00:36, 423.48batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25461/40960 [01:03<00:36, 423.48batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25547/40960 [01:03<00:36, 424.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  62%|▌| 25547/40960 [01:03<00:36, 424.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25627/40960 [01:03<00:36, 417.11batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25627/40960 [01:03<00:36, 417.11batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25714/40960 [01:03<00:36, 421.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25714/40960 [01:03<00:36, 421.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25798/40960 [01:03<00:36, 420.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25798/40960 [01:03<00:36, 420.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25881/40960 [01:04<00:36, 417.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25881/40960 [01:04<00:36, 417.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25968/40960 [01:04<00:35, 421.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  63%|▋| 25968/40960 [01:04<00:35, 421.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26053/40960 [01:04<00:35, 422.72batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26053/40960 [01:04<00:35, 422.72batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26140/40960 [01:04<00:34, 426.03batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26140/40960 [01:04<00:34, 426.03batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26224/40960 [01:04<00:34, 423.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26224/40960 [01:04<00:34, 423.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26306/40960 [01:05<00:35, 417.96batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26306/40960 [01:05<00:35, 417.96batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26390/40960 [01:05<00:34, 418.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  64%|▋| 26390/40960 [01:05<00:34, 418.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26475/40960 [01:05<00:34, 418.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26475/40960 [01:05<00:34, 418.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26560/40960 [01:05<00:34, 420.21batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26560/40960 [01:05<00:34, 420.21batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26647/40960 [01:05<00:33, 423.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26647/40960 [01:06<00:33, 423.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26733/40960 [01:06<00:33, 425.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26733/40960 [01:06<00:33, 425.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26818/40960 [01:06<00:33, 424.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  65%|▋| 26818/40960 [01:06<00:33, 424.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  66%|▋| 26904/40960 [01:06<00:33, 425.61batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  66%|▋| 26904/40960 [01:06<00:33, 425.61batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  66%|▋| 26987/40960 [01:06<00:33, 422.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  66%|▋| 26987/40960 [01:06<00:33, 422.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  66%|▋| 27071/40960 [01:07<00:33, 420.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  66%|▋| 27071/40960 [01:07<00:33, 420.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  66%|▋| 27158/40960 [01:07<00:32, 423.86batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  66%|▋| 27158/40960 [01:07<00:32, 423.86batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27241/40960 [01:07<00:32, 420.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27241/40960 [01:07<00:32, 420.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27324/40960 [01:07<00:32, 418.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27324/40960 [01:07<00:32, 418.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27406/40960 [01:07<00:32, 414.29batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27406/40960 [01:07<00:32, 414.29batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27494/40960 [01:08<00:32, 420.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27494/40960 [01:08<00:32, 420.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27580/40960 [01:08<00:31, 422.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  67%|▋| 27580/40960 [01:08<00:31, 422.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 27668/40960 [01:08<00:31, 426.66batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 27668/40960 [01:08<00:31, 426.66batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 27755/40960 [01:08<00:30, 429.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 27755/40960 [01:08<00:30, 429.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 27838/40960 [01:08<00:30, 424.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 27838/40960 [01:08<00:30, 424.52batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 27922/40960 [01:09<00:30, 421.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 27922/40960 [01:09<00:30, 421.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 28008/40960 [01:09<00:30, 424.06batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  68%|▋| 28008/40960 [01:09<00:30, 424.06batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28095/40960 [01:09<00:30, 426.23batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28095/40960 [01:09<00:30, 426.23batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28184/40960 [01:09<00:29, 431.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28184/40960 [01:09<00:29, 431.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28268/40960 [01:09<00:29, 427.16batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28268/40960 [01:09<00:29, 427.16batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28356/40960 [01:10<00:29, 430.26batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28356/40960 [01:10<00:29, 430.26batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28442/40960 [01:10<00:29, 428.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  69%|▋| 28442/40960 [01:10<00:29, 428.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28529/40960 [01:10<00:28, 429.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28529/40960 [01:10<00:28, 429.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28615/40960 [01:10<00:28, 429.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28615/40960 [01:10<00:28, 429.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28700/40960 [01:10<00:28, 428.08batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28700/40960 [01:10<00:28, 428.08batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28785/40960 [01:11<00:28, 425.72batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28785/40960 [01:11<00:28, 425.72batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28870/40960 [01:11<00:28, 425.03batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  70%|▋| 28870/40960 [01:11<00:28, 425.03batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  71%|▋| 28956/40960 [01:11<00:28, 425.76batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  71%|▋| 28956/40960 [01:11<00:28, 425.76batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  71%|▋| 29043/40960 [01:11<00:27, 428.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  71%|▋| 29043/40960 [01:11<00:27, 428.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  71%|▋| 29127/40960 [01:11<00:27, 424.77batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  71%|▋| 29127/40960 [01:11<00:27, 424.77batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  71%|▋| 29213/40960 [01:12<00:27, 426.09batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  71%|▋| 29213/40960 [01:12<00:27, 426.09batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29296/40960 [01:12<00:27, 422.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29296/40960 [01:12<00:27, 422.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29385/40960 [01:12<00:27, 427.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29385/40960 [01:12<00:27, 427.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29473/40960 [01:12<00:26, 430.21batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29473/40960 [01:12<00:26, 430.21batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29557/40960 [01:12<00:26, 426.77batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29557/40960 [01:12<00:26, 426.77batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29641/40960 [01:13<00:26, 423.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  72%|▋| 29641/40960 [01:13<00:26, 423.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 29729/40960 [01:13<00:26, 427.48batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 29729/40960 [01:13<00:26, 427.48batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 29815/40960 [01:13<00:26, 428.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 29815/40960 [01:13<00:26, 428.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 29903/40960 [01:13<00:25, 431.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 29903/40960 [01:13<00:25, 431.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 29988/40960 [01:13<00:25, 429.23batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 29988/40960 [01:13<00:25, 429.23batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 30075/40960 [01:14<00:25, 430.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  73%|▋| 30075/40960 [01:14<00:25, 430.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30162/40960 [01:14<00:25, 430.55batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30162/40960 [01:14<00:25, 430.55batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30247/40960 [01:14<00:24, 428.64batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30247/40960 [01:14<00:24, 428.64batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30334/40960 [01:14<00:24, 429.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30334/40960 [01:14<00:24, 429.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30419/40960 [01:14<00:24, 426.75batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30419/40960 [01:14<00:24, 426.75batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30507/40960 [01:15<00:24, 430.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  74%|▋| 30507/40960 [01:15<00:24, 430.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  75%|▋| 30591/40960 [01:15<00:24, 426.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  75%|▋| 30591/40960 [01:15<00:24, 426.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  75%|▋| 30678/40960 [01:15<00:24, 427.42batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  75%|▋| 30678/40960 [01:15<00:24, 427.42batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  75%|▊| 30762/40960 [01:15<00:23, 425.06batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  75%|▊| 30762/40960 [01:15<00:23, 425.06batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  75%|▊| 30846/40960 [01:15<00:23, 423.25batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  75%|▊| 30846/40960 [01:15<00:23, 423.25batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 30931/40960 [01:16<00:23, 422.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 30931/40960 [01:16<00:23, 422.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 31017/40960 [01:16<00:23, 424.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 31017/40960 [01:16<00:23, 424.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 31105/40960 [01:16<00:22, 428.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 31105/40960 [01:16<00:22, 428.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 31189/40960 [01:16<00:22, 425.96batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 31189/40960 [01:16<00:22, 425.96batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 31275/40960 [01:16<00:22, 425.82batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  76%|▊| 31275/40960 [01:16<00:22, 425.82batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31363/40960 [01:17<00:22, 428.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31363/40960 [01:17<00:22, 428.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31448/40960 [01:17<00:22, 426.78batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31448/40960 [01:17<00:22, 426.78batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31535/40960 [01:17<00:22, 428.08batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31535/40960 [01:17<00:22, 428.08batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31620/40960 [01:17<00:21, 426.50batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31620/40960 [01:17<00:21, 426.50batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31706/40960 [01:17<00:21, 427.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  77%|▊| 31706/40960 [01:17<00:21, 427.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 31793/40960 [01:18<00:21, 428.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 31793/40960 [01:18<00:21, 428.58batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 31877/40960 [01:18<00:21, 425.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 31877/40960 [01:18<00:21, 425.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 31963/40960 [01:18<00:21, 425.61batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 31963/40960 [01:18<00:21, 425.61batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 32049/40960 [01:18<00:20, 425.77batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 32049/40960 [01:18<00:20, 425.77batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 32136/40960 [01:18<00:20, 427.80batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  78%|▊| 32136/40960 [01:18<00:20, 427.80batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  79%|▊| 32222/40960 [01:19<00:20, 428.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  79%|▊| 32222/40960 [01:19<00:20, 428.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  79%|▊| 32305/40960 [01:19<00:20, 423.49batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  79%|▊| 32305/40960 [01:19<00:20, 423.49batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  79%|▊| 32390/40960 [01:19<00:20, 422.66batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  79%|▊| 32390/40960 [01:19<00:20, 422.66batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  79%|▊| 32477/40960 [01:19<00:19, 424.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  79%|▊| 32477/40960 [01:19<00:19, 424.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32564/40960 [01:19<00:19, 427.19batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32564/40960 [01:19<00:19, 427.19batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32652/40960 [01:20<00:19, 429.64batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32652/40960 [01:20<00:19, 429.64batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32734/40960 [01:20<00:19, 423.62batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32734/40960 [01:20<00:19, 423.62batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32820/40960 [01:20<00:19, 425.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32820/40960 [01:20<00:19, 425.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32904/40960 [01:20<00:19, 423.23batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  80%|▊| 32904/40960 [01:20<00:19, 423.23batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 32991/40960 [01:20<00:18, 426.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 32991/40960 [01:20<00:18, 426.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 33076/40960 [01:21<00:18, 425.94batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 33076/40960 [01:21<00:18, 425.94batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 33161/40960 [01:21<00:18, 424.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 33161/40960 [01:21<00:18, 424.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 33244/40960 [01:21<00:18, 421.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 33244/40960 [01:21<00:18, 421.15batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 33329/40960 [01:21<00:18, 422.21batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  81%|▊| 33329/40960 [01:21<00:18, 422.21batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33414/40960 [01:21<00:17, 422.70batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33414/40960 [01:21<00:17, 422.70batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33501/40960 [01:22<00:17, 425.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33501/40960 [01:22<00:17, 425.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33587/40960 [01:22<00:17, 426.57batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33587/40960 [01:22<00:17, 426.57batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33670/40960 [01:22<00:17, 421.67batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33670/40960 [01:22<00:17, 421.67batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33757/40960 [01:22<00:16, 424.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  82%|▊| 33757/40960 [01:22<00:16, 424.10batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 33843/40960 [01:22<00:16, 425.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 33843/40960 [01:22<00:16, 425.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 33928/40960 [01:23<00:16, 424.33batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 33928/40960 [01:23<00:16, 424.33batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 34014/40960 [01:23<00:16, 424.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 34014/40960 [01:23<00:16, 424.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 34097/40960 [01:23<00:16, 420.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 34097/40960 [01:23<00:16, 420.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 34185/40960 [01:23<00:15, 425.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  83%|▊| 34185/40960 [01:23<00:15, 425.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34271/40960 [01:23<00:15, 425.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34271/40960 [01:23<00:15, 425.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34354/40960 [01:24<00:15, 421.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34354/40960 [01:24<00:15, 421.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34434/40960 [01:24<00:15, 414.12batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34434/40960 [01:24<00:15, 414.12batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34520/40960 [01:24<00:15, 417.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34520/40960 [01:24<00:15, 417.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34608/40960 [01:24<00:15, 423.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  84%|▊| 34608/40960 [01:24<00:15, 423.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  85%|▊| 34694/40960 [01:24<00:14, 423.92batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  85%|▊| 34694/40960 [01:24<00:14, 423.92batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  85%|▊| 34779/40960 [01:25<00:14, 422.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  85%|▊| 34779/40960 [01:25<00:14, 422.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  85%|▊| 34864/40960 [01:25<00:14, 423.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  85%|▊| 34864/40960 [01:25<00:14, 423.01batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  85%|▊| 34949/40960 [01:25<00:14, 423.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  85%|▊| 34949/40960 [01:25<00:14, 423.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35036/40960 [01:25<00:13, 426.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35036/40960 [01:25<00:13, 426.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35124/40960 [01:25<00:13, 430.08batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35124/40960 [01:25<00:13, 430.08batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35211/40960 [01:26<00:13, 430.84batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35211/40960 [01:26<00:13, 430.84batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35294/40960 [01:26<00:13, 425.19batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35294/40960 [01:26<00:13, 425.19batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35382/40960 [01:26<00:12, 429.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  86%|▊| 35382/40960 [01:26<00:12, 429.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35467/40960 [01:26<00:12, 426.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35467/40960 [01:26<00:12, 426.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35551/40960 [01:26<00:12, 423.47batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35551/40960 [01:26<00:12, 423.47batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35632/40960 [01:27<00:12, 417.95batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35632/40960 [01:27<00:12, 417.95batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35718/40960 [01:27<00:12, 420.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35718/40960 [01:27<00:12, 420.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35805/40960 [01:27<00:12, 424.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  87%|▊| 35805/40960 [01:27<00:12, 424.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 35893/40960 [01:27<00:11, 429.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 35893/40960 [01:27<00:11, 429.04batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 35978/40960 [01:27<00:11, 427.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 35978/40960 [01:27<00:11, 427.02batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 36061/40960 [01:28<00:11, 423.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 36061/40960 [01:28<00:11, 423.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 36148/40960 [01:28<00:11, 426.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 36148/40960 [01:28<00:11, 426.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 36235/40960 [01:28<00:11, 428.90batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  88%|▉| 36235/40960 [01:28<00:11, 428.90batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  89%|▉| 36321/40960 [01:28<00:10, 428.95batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  89%|▉| 36321/40960 [01:28<00:10, 428.95batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  89%|▉| 36408/40960 [01:28<00:10, 430.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  89%|▉| 36408/40960 [01:28<00:10, 430.53batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36493/40960 [01:29<00:10, 428.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  89%|▉| 36493/40960 [01:29<00:10, 428.34batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  89%|▉| 36579/40960 [01:29<00:10, 428.62batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  89%|▉| 36579/40960 [01:29<00:10, 428.62batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 36662/40960 [01:29<00:10, 423.92batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 36662/40960 [01:29<00:10, 423.92batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 36750/40960 [01:29<00:09, 427.89batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 36750/40960 [01:29<00:09, 427.89batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 36837/40960 [01:29<00:09, 429.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 36837/40960 [01:29<00:09, 429.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 36922/40960 [01:30<00:09, 428.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 36922/40960 [01:30<00:09, 428.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 37007/40960 [01:30<00:09, 426.74batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  90%|▉| 37007/40960 [01:30<00:09, 426.74batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37092/40960 [01:30<00:09, 424.66batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37092/40960 [01:30<00:09, 424.66batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37179/40960 [01:30<00:08, 427.11batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37179/40960 [01:30<00:08, 427.11batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37267/40960 [01:30<00:08, 429.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37267/40960 [01:30<00:08, 429.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37353/40960 [01:31<00:08, 429.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37353/40960 [01:31<00:08, 429.44batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37436/40960 [01:31<00:08, 424.85batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  91%|▉| 37436/40960 [01:31<00:08, 424.85batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37522/40960 [01:31<00:08, 425.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37522/40960 [01:31<00:08, 425.20batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37606/40960 [01:31<00:07, 422.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37606/40960 [01:31<00:07, 422.93batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37692/40960 [01:31<00:07, 424.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37692/40960 [01:31<00:07, 424.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37780/40960 [01:32<00:07, 427.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37780/40960 [01:32<00:07, 427.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37866/40960 [01:32<00:07, 427.62batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  92%|▉| 37866/40960 [01:32<00:07, 427.62batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 37952/40960 [01:32<00:07, 426.90batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 37952/40960 [01:32<00:07, 426.90batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 38032/40960 [01:32<00:07, 417.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 38032/40960 [01:32<00:07, 417.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 38116/40960 [01:32<00:06, 418.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 38116/40960 [01:32<00:06, 418.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 38201/40960 [01:33<00:06, 419.26batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 38201/40960 [01:33<00:06, 419.26batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 38289/40960 [01:33<00:06, 425.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  93%|▉| 38289/40960 [01:33<00:06, 425.32batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  94%|▉| 38375/40960 [01:33<00:06, 426.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  94%|▉| 38375/40960 [01:33<00:06, 426.39batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  94%|▉| 38461/40960 [01:33<00:05, 426.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  94%|▉| 38461/40960 [01:33<00:05, 426.38batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  94%|▉| 38545/40960 [01:33<00:05, 423.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  94%|▉| 38545/40960 [01:33<00:05, 423.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  94%|▉| 38631/40960 [01:34<00:05, 424.62batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  94%|▉| 38631/40960 [01:34<00:05, 424.62batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 38717/40960 [01:34<00:05, 425.79batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 38717/40960 [01:34<00:05, 425.79batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 38802/40960 [01:34<00:05, 425.22batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 38802/40960 [01:34<00:05, 425.22batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 38888/40960 [01:34<00:04, 425.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 38888/40960 [01:34<00:04, 425.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 38973/40960 [01:34<00:04, 425.54batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 38973/40960 [01:34<00:04, 425.54batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 39057/40960 [01:35<00:04, 422.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  95%|▉| 39057/40960 [01:35<00:04, 422.81batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39141/40960 [01:35<00:04, 420.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39141/40960 [01:35<00:04, 420.65batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39227/40960 [01:35<00:04, 423.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39227/40960 [01:35<00:04, 423.40batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39312/40960 [01:35<00:03, 423.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39312/40960 [01:35<00:03, 423.30batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39397/40960 [01:35<00:03, 422.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39397/40960 [01:35<00:03, 422.91batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39480/40960 [01:36<00:03, 420.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  96%|▉| 39480/40960 [01:36<00:03, 420.45batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39566/40960 [01:36<00:03, 423.09batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39566/40960 [01:36<00:03, 423.09batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39650/40960 [01:36<00:03, 420.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39650/40960 [01:36<00:03, 420.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39733/40960 [01:36<00:02, 418.87batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39733/40960 [01:36<00:02, 418.87batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39819/40960 [01:36<00:02, 421.85batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39819/40960 [01:36<00:02, 421.85batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39904/40960 [01:37<00:02, 422.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  97%|▉| 39904/40960 [01:37<00:02, 422.59batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 39992/40960 [01:37<00:02, 426.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 39992/40960 [01:37<00:02, 426.97batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 40078/40960 [01:37<00:02, 427.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 40078/40960 [01:37<00:02, 427.68batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 40162/40960 [01:37<00:01, 423.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 40162/40960 [01:37<00:01, 423.98batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 40249/40960 [01:37<00:01, 426.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40249/40960 [01:37<00:01, 426.18batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 40334/40960 [01:38<00:01, 425.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  98%|▉| 40334/40960 [01:38<00:01, 425.27batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  99%|▉| 40421/40960 [01:38<00:01, 426.79batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  99%|▉| 40421/40960 [01:38<00:01, 426.79batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  99%|▉| 40506/40960 [01:38<00:01, 425.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  99%|▉| 40506/40960 [01:38<00:01, 425.73batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  99%|▉| 40587/40960 [01:38<00:00, 417.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  99%|▉| 40587/40960 [01:38<00:00, 417.88batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  99%|▉| 40674/40960 [01:38<00:00, 422.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training:  99%|▉| 40674/40960 [01:38<00:00, 422.35batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training: 100%|▉| 40761/40960 [01:39<00:00, 425.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training: 100%|▉| 40761/40960 [01:39<00:00, 425.99batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training: 100%|▉| 40846/40960 [01:39<00:00, 425.36batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training: 100%|▉| 40846/40960 [01:39<00:00, 425.36batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training: 100%|▉| 40933/40960 [01:39<00:00, 427.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "Training: 100%|▉| 40933/40960 [01:39<00:00, 427.43batches/s, l2_loss: 0.0002 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 18:51:07.171291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:   4%| | 1/26 [01:46<44:07, 105.90s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 18:51:08.916073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 18:51:11.857956: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<11:50:56,  1.04s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<11:50:56,  1.04s/batches, l2_loss: 0.0013 - round_loss:\u001b[A\n",
      "Training:   0%| | 94/40960 [00:01<06:45, 100.84batches/s, l2_loss: 0.0013 - round_loss: \u001b[A\n",
      "Training:   0%| | 94/40960 [00:01<06:45, 100.84batches/s, l2_loss: 0.0007 - round_loss: \u001b[A\n",
      "Training:   0%| | 187/40960 [00:01<03:38, 186.41batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   0%| | 187/40960 [00:01<03:38, 186.41batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 280/40960 [00:01<02:38, 256.27batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 280/40960 [00:01<02:38, 256.27batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 374/40960 [00:01<02:09, 312.67batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 374/40960 [00:01<02:09, 312.67batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 465/40960 [00:02<01:55, 351.00batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 465/40960 [00:02<01:55, 351.00batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 558/40960 [00:02<01:45, 382.80batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 558/40960 [00:02<01:45, 382.80batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 651/40960 [00:02<01:39, 406.10batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 651/40960 [00:02<01:39, 406.10batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 742/40960 [00:02<01:35, 420.28batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 742/40960 [00:02<01:35, 420.28batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 835/40960 [00:02<01:32, 433.18batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 835/40960 [00:02<01:32, 433.18batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 928/40960 [00:03<01:30, 441.41batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 928/40960 [00:03<01:30, 441.41batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   2%| | 1023/40960 [00:03<01:28, 451.02batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   2%| | 1023/40960 [00:03<01:28, 451.02batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1118/40960 [00:03<01:26, 458.00batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1118/40960 [00:03<01:26, 458.00batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1211/40960 [00:03<01:26, 459.31batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1211/40960 [00:03<01:26, 459.31batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1295/40960 [00:03<01:28, 447.03batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1295/40960 [00:03<01:28, 447.03batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1384/40960 [00:04<01:28, 445.57batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1384/40960 [00:04<01:28, 445.57batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   4%| | 1476/40960 [00:04<01:27, 449.62batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   4%| | 1476/40960 [00:04<01:27, 449.62batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   4%| | 1571/40960 [00:04<01:26, 456.16batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   4%| | 1571/40960 [00:04<01:26, 456.16batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   4%| | 1664/40960 [00:04<01:25, 457.65batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   4%| | 1664/40960 [00:04<01:25, 457.65batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   4%| | 1756/40960 [00:04<01:25, 457.49batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   4%| | 1756/40960 [00:04<01:25, 457.49batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 1847/40960 [00:05<01:25, 455.80batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 1847/40960 [00:05<01:25, 455.80batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 1941/40960 [00:05<01:25, 458.88batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 1941/40960 [00:05<01:25, 458.88batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 2029/40960 [00:05<01:26, 452.14batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 2029/40960 [00:05<01:26, 452.14batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 2123/40960 [00:05<01:25, 456.71batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 2123/40960 [00:05<01:25, 456.71batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 2215/40960 [00:05<01:24, 456.25batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   5%| | 2215/40960 [00:05<01:24, 456.25batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   6%| | 2309/40960 [00:06<01:24, 459.71batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   6%| | 2309/40960 [00:06<01:24, 459.71batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   6%| | 2404/40960 [00:06<01:23, 463.49batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   6%| | 2404/40960 [00:06<01:23, 463.49batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   6%| | 2495/40960 [00:06<01:23, 460.43batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   6%| | 2495/40960 [00:06<01:23, 460.43batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   6%| | 2589/40960 [00:06<01:23, 462.07batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   6%| | 2589/40960 [00:06<01:23, 462.07batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 2682/40960 [00:06<01:22, 462.30batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 2682/40960 [00:06<01:22, 462.30batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 2775/40960 [00:07<01:22, 463.04batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 2775/40960 [00:07<01:22, 463.04batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 2870/40960 [00:07<01:21, 465.82batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 2870/40960 [00:07<01:21, 465.82batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 2966/40960 [00:07<01:20, 469.57batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 2966/40960 [00:07<01:20, 469.57batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 3062/40960 [00:07<01:20, 471.50batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   7%| | 3062/40960 [00:07<01:20, 471.50batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   8%| | 3156/40960 [00:07<01:20, 470.71batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   8%| | 3156/40960 [00:07<01:20, 470.71batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   8%| | 3250/40960 [00:08<01:20, 470.50batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   8%| | 3250/40960 [00:08<01:20, 470.50batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   8%| | 3341/40960 [00:08<01:20, 465.55batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   8%| | 3341/40960 [00:08<01:20, 465.55batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   8%| | 3430/40960 [00:08<01:21, 459.17batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   8%| | 3430/40960 [00:08<01:21, 459.17batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   9%| | 3525/40960 [00:08<01:20, 463.89batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   9%| | 3525/40960 [00:08<01:20, 463.89batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   9%| | 3619/40960 [00:08<01:20, 464.47batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   9%| | 3619/40960 [00:08<01:20, 464.47batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   9%| | 3713/40960 [00:09<01:19, 465.97batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   9%| | 3713/40960 [00:09<01:19, 465.97batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   9%| | 3806/40960 [00:09<01:19, 465.54batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   9%| | 3806/40960 [00:09<01:19, 465.54batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 3898/40960 [00:09<01:19, 463.47batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 3898/40960 [00:09<01:19, 463.47batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 3993/40960 [00:09<01:19, 466.63batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 3993/40960 [00:09<01:19, 466.63batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 4086/40960 [00:09<01:19, 465.01batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 4086/40960 [00:09<01:19, 465.01batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 4180/40960 [00:10<01:18, 466.25batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 4180/40960 [00:10<01:18, 466.25batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 4272/40960 [00:10<01:19, 463.83batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  10%| | 4272/40960 [00:10<01:19, 463.83batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  11%| | 4366/40960 [00:10<01:18, 464.47batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  11%| | 4366/40960 [00:10<01:18, 464.47batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  11%| | 4458/40960 [00:10<01:19, 462.00batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  11%| | 4458/40960 [00:10<01:19, 462.00batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  11%| | 4552/40960 [00:10<01:18, 463.23batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  11%| | 4552/40960 [00:10<01:18, 463.23batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  11%| | 4645/40960 [00:11<01:18, 463.69batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  11%| | 4645/40960 [00:11<01:18, 463.69batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 4738/40960 [00:11<01:18, 463.92batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 4738/40960 [00:11<01:18, 463.92batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 4830/40960 [00:11<01:18, 461.48batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 4830/40960 [00:11<01:18, 461.48batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 4922/40960 [00:11<01:18, 460.70batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 4922/40960 [00:11<01:18, 460.70batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 5016/40960 [00:11<01:17, 462.61batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 5016/40960 [00:11<01:17, 462.61batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 5109/40960 [00:12<01:17, 462.38batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  12%| | 5109/40960 [00:12<01:17, 462.38batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5202/40960 [00:12<01:17, 462.99batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5202/40960 [00:12<01:17, 462.99batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5298/40960 [00:12<01:16, 467.79batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5298/40960 [00:12<01:16, 467.79batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5392/40960 [00:12<01:16, 467.16batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5392/40960 [00:12<01:16, 467.16batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5487/40960 [00:12<01:15, 468.88batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5487/40960 [00:12<01:15, 468.88batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5581/40960 [00:13<01:15, 468.35batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5581/40960 [00:13<01:15, 468.35batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5676/40960 [00:13<01:15, 469.45batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5676/40960 [00:13<01:15, 469.45batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5768/40960 [00:13<01:15, 465.75batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5768/40960 [00:13<01:15, 465.75batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5862/40960 [00:13<01:15, 466.77batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5862/40960 [00:13<01:15, 466.77batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5956/40960 [00:13<01:15, 466.21batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5956/40960 [00:13<01:15, 466.21batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6048/40960 [00:14<01:15, 463.87batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6048/40960 [00:14<01:15, 463.87batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6142/40960 [00:14<01:14, 464.84batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6142/40960 [00:14<01:14, 464.84batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6237/40960 [00:14<01:14, 467.14batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6237/40960 [00:14<01:14, 467.14batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6331/40960 [00:14<01:14, 467.08batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6331/40960 [00:14<01:14, 467.08batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:14<01:13, 467.44batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:14<01:13, 467.44batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6518/40960 [00:15<01:14, 465.32batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6518/40960 [00:15<01:14, 465.32batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6613/40960 [00:15<01:13, 467.21batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6613/40960 [00:15<01:13, 467.21batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6707/40960 [00:15<01:13, 466.81batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6707/40960 [00:15<01:13, 466.81batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6801/40960 [00:15<01:13, 466.90batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6801/40960 [00:15<01:13, 466.90batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|▏| 6894/40960 [00:15<01:13, 465.78batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6894/40960 [00:15<01:13, 465.78batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6989/40960 [00:16<01:12, 467.33batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6989/40960 [00:16<01:12, 467.33batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7082/40960 [00:16<01:12, 465.81batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7082/40960 [00:16<01:12, 465.81batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7175/40960 [00:16<01:12, 464.41batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7175/40960 [00:16<01:12, 464.41batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7267/40960 [00:16<01:12, 462.79batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7267/40960 [00:16<01:12, 462.79batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7359/40960 [00:16<01:12, 461.02batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7359/40960 [00:16<01:12, 461.02batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7449/40960 [00:17<01:13, 457.02batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7449/40960 [00:17<01:13, 457.02batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7541/40960 [00:17<01:13, 457.42batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7541/40960 [00:17<01:13, 457.42batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7634/40960 [00:17<01:12, 458.55batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7634/40960 [00:17<01:12, 458.55batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7728/40960 [00:17<01:11, 461.57batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7728/40960 [00:17<01:11, 461.57batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7820/40960 [00:17<01:11, 460.39batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7820/40960 [00:17<01:11, 460.39batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7914/40960 [00:18<01:11, 462.79batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7914/40960 [00:18<01:11, 462.79batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8006/40960 [00:18<01:11, 461.53batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8006/40960 [00:18<01:11, 461.53batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8100/40960 [00:18<01:10, 463.53batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8100/40960 [00:18<01:10, 463.53batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8193/40960 [00:18<01:10, 462.19batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8193/40960 [00:18<01:10, 462.19batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8280/40960 [00:18<01:12, 453.26batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8280/40960 [00:18<01:12, 453.26batches/s, l2_loss: 0.0006 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8365/40960 [00:19<01:13, 443.01batches/s, l2_loss: 0.0006 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8365/40960 [00:19<01:13, 443.01batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8448/40960 [00:19<01:14, 434.19batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8448/40960 [00:19<01:14, 434.19batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8532/40960 [00:19<01:15, 429.39batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8532/40960 [00:19<01:15, 429.39batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8615/40960 [00:19<01:16, 424.89batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8615/40960 [00:19<01:16, 424.89batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8699/40960 [00:19<01:16, 422.08batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8699/40960 [00:19<01:16, 422.08batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8782/40960 [00:20<01:16, 419.58batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8782/40960 [00:20<01:16, 419.58batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8868/40960 [00:20<01:16, 422.19batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8868/40960 [00:20<01:16, 422.19batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8951/40960 [00:20<01:16, 419.07batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8951/40960 [00:20<01:16, 419.07batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9032/40960 [00:20<01:16, 414.80batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9032/40960 [00:20<01:16, 414.80batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9114/40960 [00:20<01:17, 412.53batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9114/40960 [00:20<01:17, 412.53batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9199/40960 [00:21<01:16, 415.53batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9199/40960 [00:21<01:16, 415.53batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9284/40960 [00:21<01:15, 417.87batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9284/40960 [00:21<01:15, 417.87batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9369/40960 [00:21<01:15, 419.74batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9369/40960 [00:21<01:15, 419.74batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9457/40960 [00:21<01:14, 425.29batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9457/40960 [00:21<01:14, 425.29batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9543/40960 [00:21<01:13, 425.45batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9543/40960 [00:21<01:13, 425.45batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9630/40960 [00:22<01:13, 427.07batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9630/40960 [00:22<01:13, 427.07batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9713/40960 [00:22<01:13, 423.00batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9713/40960 [00:22<01:13, 423.00batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9799/40960 [00:22<01:13, 424.20batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9799/40960 [00:22<01:13, 424.20batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9883/40960 [00:22<01:13, 422.19batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9883/40960 [00:22<01:13, 422.19batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9968/40960 [00:22<01:13, 422.77batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9968/40960 [00:22<01:13, 422.77batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10052/40960 [00:23<01:13, 421.44batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▏| 10052/40960 [00:23<01:13, 421.44batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▏| 10133/40960 [00:23<01:14, 415.30batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▏| 10133/40960 [00:23<01:14, 415.30batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▏| 10217/40960 [00:23<01:14, 415.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▏| 10217/40960 [00:23<01:14, 415.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▎| 10301/40960 [00:23<01:13, 415.57batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▎| 10301/40960 [00:23<01:13, 415.57batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▎| 10383/40960 [00:23<01:14, 412.84batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  25%|▎| 10383/40960 [00:23<01:14, 412.84batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10466/40960 [00:24<01:13, 413.29batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10466/40960 [00:24<01:13, 413.29batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10551/40960 [00:24<01:13, 416.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10551/40960 [00:24<01:13, 416.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10634/40960 [00:24<01:12, 415.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10634/40960 [00:24<01:12, 415.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10715/40960 [00:24<01:13, 411.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10715/40960 [00:24<01:13, 411.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10800/40960 [00:24<01:12, 414.91batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  26%|▎| 10800/40960 [00:24<01:12, 414.91batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 10885/40960 [00:25<01:12, 417.47batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 10885/40960 [00:25<01:12, 417.47batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 10970/40960 [00:25<01:11, 418.80batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 10970/40960 [00:25<01:11, 418.80batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 11052/40960 [00:25<01:11, 415.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 11052/40960 [00:25<01:11, 415.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 11138/40960 [00:25<01:11, 419.24batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 11138/40960 [00:25<01:11, 419.24batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 11223/40960 [00:25<01:10, 420.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  27%|▎| 11223/40960 [00:25<01:10, 420.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11309/40960 [00:26<01:10, 422.62batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11309/40960 [00:26<01:10, 422.62batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11394/40960 [00:26<01:09, 422.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11394/40960 [00:26<01:09, 422.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11479/40960 [00:26<01:09, 423.28batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11479/40960 [00:26<01:09, 423.28batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11560/40960 [00:26<01:10, 416.29batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11560/40960 [00:26<01:10, 416.29batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11644/40960 [00:26<01:10, 416.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11644/40960 [00:26<01:10, 416.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11727/40960 [00:27<01:10, 414.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11727/40960 [00:27<01:10, 414.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11812/40960 [00:27<01:09, 416.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11812/40960 [00:27<01:09, 416.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11895/40960 [00:27<01:09, 415.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11895/40960 [00:27<01:09, 415.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11977/40960 [00:27<01:10, 413.28batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11977/40960 [00:27<01:10, 413.28batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 12061/40960 [00:27<01:09, 414.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  29%|▎| 12061/40960 [00:27<01:09, 414.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12145/40960 [00:28<01:09, 415.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12145/40960 [00:28<01:09, 415.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12228/40960 [00:28<01:09, 414.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12228/40960 [00:28<01:09, 414.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12308/40960 [00:28<01:09, 410.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12308/40960 [00:28<01:09, 410.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12394/40960 [00:28<01:08, 414.70batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12394/40960 [00:28<01:08, 414.70batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12476/40960 [00:28<01:09, 412.66batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  30%|▎| 12476/40960 [00:28<01:09, 412.66batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12562/40960 [00:29<01:08, 416.53batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12562/40960 [00:29<01:08, 416.53batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12646/40960 [00:29<01:07, 417.19batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12646/40960 [00:29<01:07, 417.19batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12731/40960 [00:29<01:07, 418.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12731/40960 [00:29<01:07, 418.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12814/40960 [00:29<01:07, 416.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12814/40960 [00:29<01:07, 416.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12899/40960 [00:29<01:07, 417.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12899/40960 [00:30<01:07, 417.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  32%|▎| 12983/40960 [00:30<01:06, 417.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  32%|▎| 12983/40960 [00:30<01:06, 417.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  32%|▎| 13069/40960 [00:30<01:06, 420.83batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  32%|▎| 13069/40960 [00:30<01:06, 420.83batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  32%|▎| 13151/40960 [00:30<01:06, 417.14batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  32%|▎| 13151/40960 [00:30<01:06, 417.14batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  32%|▎| 13234/40960 [00:30<01:06, 415.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  32%|▎| 13234/40960 [00:30<01:06, 415.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13319/40960 [00:31<01:06, 417.93batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13319/40960 [00:31<01:06, 417.93batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13400/40960 [00:31<01:06, 413.72batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13400/40960 [00:31<01:06, 413.72batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13487/40960 [00:31<01:05, 419.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13487/40960 [00:31<01:05, 419.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13572/40960 [00:31<01:05, 420.36batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13572/40960 [00:31<01:05, 420.36batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13655/40960 [00:31<01:05, 418.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  33%|▎| 13655/40960 [00:31<01:05, 418.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 13740/40960 [00:32<01:04, 419.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 13740/40960 [00:32<01:04, 419.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 13825/40960 [00:32<01:04, 419.31batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 13825/40960 [00:32<01:04, 419.31batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 13909/40960 [00:32<01:04, 419.19batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 13909/40960 [00:32<01:04, 419.19batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 13991/40960 [00:32<01:04, 415.17batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 13991/40960 [00:32<01:04, 415.17batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 14073/40960 [00:32<01:05, 413.59batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  34%|▎| 14073/40960 [00:32<01:05, 413.59batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14156/40960 [00:33<01:04, 412.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14156/40960 [00:33<01:04, 412.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14241/40960 [00:33<01:04, 416.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14241/40960 [00:33<01:04, 416.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14326/40960 [00:33<01:03, 417.27batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14326/40960 [00:33<01:03, 417.27batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14409/40960 [00:33<01:03, 415.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14409/40960 [00:33<01:03, 415.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14493/40960 [00:33<01:03, 416.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  35%|▎| 14493/40960 [00:33<01:03, 416.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14576/40960 [00:34<01:03, 414.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14576/40960 [00:34<01:03, 414.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14658/40960 [00:34<01:03, 412.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14658/40960 [00:34<01:03, 412.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14741/40960 [00:34<01:03, 412.21batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14741/40960 [00:34<01:03, 412.21batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14824/40960 [00:34<01:03, 412.23batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14824/40960 [00:34<01:03, 412.23batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14906/40960 [00:34<01:03, 410.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  36%|▎| 14906/40960 [00:34<01:03, 410.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 14993/40960 [00:35<01:02, 416.45batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 14993/40960 [00:35<01:02, 416.45batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 15077/40960 [00:35<01:02, 416.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 15077/40960 [00:35<01:02, 416.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 15162/40960 [00:35<01:01, 417.72batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 15162/40960 [00:35<01:01, 417.72batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 15248/40960 [00:35<01:01, 421.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 15248/40960 [00:35<01:01, 421.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 15331/40960 [00:35<01:01, 418.83batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  37%|▎| 15331/40960 [00:35<01:01, 418.83batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15417/40960 [00:36<01:00, 421.32batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15417/40960 [00:36<01:00, 421.32batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15502/40960 [00:36<01:00, 421.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15502/40960 [00:36<01:00, 421.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15585/40960 [00:36<01:00, 418.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15585/40960 [00:36<01:00, 418.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15670/40960 [00:36<01:00, 419.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15670/40960 [00:36<01:00, 419.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15755/40960 [00:36<00:59, 420.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  38%|▍| 15755/40960 [00:36<00:59, 420.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 15839/40960 [00:37<00:59, 420.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 15839/40960 [00:37<00:59, 420.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 15924/40960 [00:37<00:59, 420.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 15924/40960 [00:37<00:59, 420.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 16009/40960 [00:37<00:59, 421.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 16009/40960 [00:37<00:59, 421.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 16093/40960 [00:37<00:59, 419.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 16093/40960 [00:37<00:59, 419.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 16178/40960 [00:37<00:58, 420.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  39%|▍| 16178/40960 [00:37<00:58, 420.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  40%|▍| 16261/40960 [00:38<00:59, 418.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  40%|▍| 16261/40960 [00:38<00:59, 418.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  40%|▍| 16345/40960 [00:38<00:58, 417.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  40%|▍| 16345/40960 [00:38<00:58, 417.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  40%|▍| 16426/40960 [00:38<00:59, 412.98batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  40%|▍| 16426/40960 [00:38<00:59, 412.98batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  40%|▍| 16510/40960 [00:38<00:58, 414.66batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  40%|▍| 16510/40960 [00:38<00:58, 414.66batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16594/40960 [00:38<00:58, 415.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16594/40960 [00:38<00:58, 415.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16678/40960 [00:39<00:58, 416.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16678/40960 [00:39<00:58, 416.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16763/40960 [00:39<00:57, 418.80batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16763/40960 [00:39<00:57, 418.80batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16847/40960 [00:39<00:57, 418.16batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16847/40960 [00:39<00:57, 418.16batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16930/40960 [00:39<00:57, 416.69batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  41%|▍| 16930/40960 [00:39<00:57, 416.69batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17015/40960 [00:39<00:57, 418.83batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17015/40960 [00:39<00:57, 418.83batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17097/40960 [00:40<00:57, 415.00batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17097/40960 [00:40<00:57, 415.00batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17176/40960 [00:40<00:58, 407.59batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17176/40960 [00:40<00:58, 407.59batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17260/40960 [00:40<00:57, 410.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17260/40960 [00:40<00:57, 410.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17345/40960 [00:40<00:57, 413.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  42%|▍| 17345/40960 [00:40<00:57, 413.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17429/40960 [00:40<00:56, 414.19batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17429/40960 [00:40<00:56, 414.19batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17511/40960 [00:41<00:56, 411.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17511/40960 [00:41<00:56, 411.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17596/40960 [00:41<00:56, 415.33batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17596/40960 [00:41<00:56, 415.33batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17681/40960 [00:41<00:55, 417.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17681/40960 [00:41<00:55, 417.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17766/40960 [00:41<00:55, 418.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  43%|▍| 17766/40960 [00:41<00:55, 418.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 17852/40960 [00:41<00:54, 420.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 17852/40960 [00:41<00:54, 420.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 17938/40960 [00:42<00:54, 422.39batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 17938/40960 [00:42<00:54, 422.39batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 18019/40960 [00:42<00:55, 417.04batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 18019/40960 [00:42<00:55, 417.04batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 18103/40960 [00:42<00:54, 417.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 18103/40960 [00:42<00:54, 417.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  44%|▍| 18185/40960 [00:42<00:54, 414.40batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 18185/40960 [00:42<00:54, 414.40batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18270/40960 [00:42<00:54, 416.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18270/40960 [00:42<00:54, 416.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18356/40960 [00:43<00:53, 420.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18356/40960 [00:43<00:53, 420.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18441/40960 [00:43<00:53, 421.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18441/40960 [00:43<00:53, 421.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18522/40960 [00:43<00:53, 416.51batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18522/40960 [00:43<00:53, 416.51batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18609/40960 [00:43<00:53, 421.15batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  45%|▍| 18609/40960 [00:43<00:53, 421.15batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 18697/40960 [00:43<00:52, 425.80batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 18697/40960 [00:43<00:52, 425.80batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 18781/40960 [00:44<00:52, 424.02batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 18781/40960 [00:44<00:52, 424.02batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 18866/40960 [00:44<00:52, 423.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 18866/40960 [00:44<00:52, 423.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 18952/40960 [00:44<00:51, 424.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 18952/40960 [00:44<00:51, 424.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 19038/40960 [00:44<00:51, 425.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  46%|▍| 19038/40960 [00:44<00:51, 425.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  47%|▍| 19122/40960 [00:44<00:51, 422.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  47%|▍| 19122/40960 [00:44<00:51, 422.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  47%|▍| 19207/40960 [00:45<00:51, 422.21batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  47%|▍| 19207/40960 [00:45<00:51, 422.21batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  47%|▍| 19289/40960 [00:45<00:51, 418.23batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  47%|▍| 19289/40960 [00:45<00:51, 418.23batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  47%|▍| 19370/40960 [00:45<00:52, 413.71batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  47%|▍| 19370/40960 [00:45<00:52, 413.71batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19456/40960 [00:45<00:51, 417.88batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19456/40960 [00:45<00:51, 417.88batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19541/40960 [00:45<00:51, 419.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19541/40960 [00:45<00:51, 419.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19625/40960 [00:46<00:50, 419.30batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19625/40960 [00:46<00:50, 419.30batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19708/40960 [00:46<00:50, 417.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19708/40960 [00:46<00:50, 417.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19793/40960 [00:46<00:50, 419.53batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  48%|▍| 19793/40960 [00:46<00:50, 419.53batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 19878/40960 [00:46<00:50, 420.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 19878/40960 [00:46<00:50, 420.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 19963/40960 [00:46<00:49, 422.14batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 19963/40960 [00:46<00:49, 422.14batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 20047/40960 [00:47<00:49, 420.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 20047/40960 [00:47<00:49, 420.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 20130/40960 [00:47<00:49, 418.72batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 20130/40960 [00:47<00:49, 418.72batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 20214/40960 [00:47<00:49, 418.16batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  49%|▍| 20214/40960 [00:47<00:49, 418.16batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▍| 20298/40960 [00:47<00:49, 418.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▍| 20298/40960 [00:47<00:49, 418.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▍| 20378/40960 [00:47<00:49, 412.90batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▍| 20378/40960 [00:47<00:49, 412.90batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▍| 20461/40960 [00:48<00:49, 412.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▍| 20461/40960 [00:48<00:49, 412.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▌| 20544/40960 [00:48<00:49, 412.61batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▌| 20544/40960 [00:48<00:49, 412.61batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▌| 20624/40960 [00:48<00:49, 408.44batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  50%|▌| 20624/40960 [00:48<00:49, 408.44batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 20708/40960 [00:48<00:49, 411.83batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 20708/40960 [00:48<00:49, 411.83batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 20791/40960 [00:48<00:49, 411.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 20791/40960 [00:48<00:49, 411.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 20872/40960 [00:49<00:49, 409.14batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 20872/40960 [00:49<00:49, 409.14batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 20954/40960 [00:49<00:49, 408.12batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 20954/40960 [00:49<00:49, 408.12batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 21036/40960 [00:49<00:48, 408.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  51%|▌| 21036/40960 [00:49<00:48, 408.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21120/40960 [00:49<00:48, 410.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21120/40960 [00:49<00:48, 410.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21202/40960 [00:49<00:48, 409.00batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21202/40960 [00:49<00:48, 409.00batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21286/40960 [00:50<00:47, 411.85batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21286/40960 [00:50<00:47, 411.85batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21370/40960 [00:50<00:47, 413.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21370/40960 [00:50<00:47, 413.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21456/40960 [00:50<00:46, 417.44batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  52%|▌| 21456/40960 [00:50<00:46, 417.44batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21540/40960 [00:50<00:46, 417.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21540/40960 [00:50<00:46, 417.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21626/40960 [00:50<00:45, 420.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21626/40960 [00:50<00:45, 420.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21709/40960 [00:51<00:46, 417.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21709/40960 [00:51<00:46, 417.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21795/40960 [00:51<00:45, 420.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21795/40960 [00:51<00:45, 420.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21881/40960 [00:51<00:45, 422.87batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  53%|▌| 21881/40960 [00:51<00:45, 422.87batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|▌| 21965/40960 [00:51<00:45, 421.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 21965/40960 [00:51<00:45, 421.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 22051/40960 [00:51<00:44, 423.04batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 22051/40960 [00:51<00:44, 423.04batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 22134/40960 [00:52<00:44, 420.09batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 22134/40960 [00:52<00:44, 420.09batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 22220/40960 [00:52<00:44, 422.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 22220/40960 [00:52<00:44, 422.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 22306/40960 [00:52<00:44, 423.87batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  54%|▌| 22306/40960 [00:52<00:44, 423.87batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22389/40960 [00:52<00:44, 420.06batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22389/40960 [00:52<00:44, 420.06batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22474/40960 [00:52<00:43, 421.06batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22474/40960 [00:52<00:43, 421.06batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22557/40960 [00:53<00:43, 418.74batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22557/40960 [00:53<00:43, 418.74batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22642/40960 [00:53<00:43, 420.30batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22642/40960 [00:53<00:43, 420.30batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22728/40960 [00:53<00:43, 421.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  55%|▌| 22728/40960 [00:53<00:43, 421.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  56%|▌| 22814/40960 [00:53<00:42, 423.51batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  56%|▌| 22814/40960 [00:53<00:42, 423.51batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  56%|▌| 22900/40960 [00:53<00:42, 424.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  56%|▌| 22900/40960 [00:53<00:42, 424.78batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  56%|▌| 22984/40960 [00:54<00:42, 422.13batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  56%|▌| 22984/40960 [00:54<00:42, 422.13batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  56%|▌| 23070/40960 [00:54<00:42, 423.61batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  56%|▌| 23070/40960 [00:54<00:42, 423.61batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23151/40960 [00:54<00:42, 416.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23151/40960 [00:54<00:42, 416.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23236/40960 [00:54<00:42, 417.72batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23236/40960 [00:54<00:42, 417.72batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23320/40960 [00:54<00:42, 418.01batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23320/40960 [00:54<00:42, 418.01batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23405/40960 [00:55<00:41, 418.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23405/40960 [00:55<00:41, 418.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23489/40960 [00:55<00:41, 418.79batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  57%|▌| 23489/40960 [00:55<00:41, 418.79batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23575/40960 [00:55<00:41, 420.77batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23575/40960 [00:55<00:41, 420.77batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23660/40960 [00:55<00:41, 421.43batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23660/40960 [00:55<00:41, 421.43batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23746/40960 [00:55<00:40, 422.65batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23746/40960 [00:55<00:40, 422.65batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23827/40960 [00:56<00:41, 416.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23827/40960 [00:56<00:41, 416.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23912/40960 [00:56<00:40, 418.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  58%|▌| 23912/40960 [00:56<00:40, 418.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 23998/40960 [00:56<00:40, 421.06batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 23998/40960 [00:56<00:40, 421.06batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 24083/40960 [00:56<00:40, 421.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 24083/40960 [00:56<00:40, 421.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 24165/40960 [00:56<00:40, 416.88batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 24165/40960 [00:56<00:40, 416.88batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 24249/40960 [00:57<00:40, 416.91batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 24249/40960 [00:57<00:40, 416.91batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 24332/40960 [00:57<00:39, 416.02batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  59%|▌| 24332/40960 [00:57<00:39, 416.02batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24415/40960 [00:57<00:39, 415.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24415/40960 [00:57<00:39, 415.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24499/40960 [00:57<00:39, 415.85batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24499/40960 [00:57<00:39, 415.85batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24585/40960 [00:57<00:39, 419.43batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24585/40960 [00:57<00:39, 419.43batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24667/40960 [00:58<00:39, 416.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24667/40960 [00:58<00:39, 416.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24752/40960 [00:58<00:38, 418.68batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24752/40960 [00:58<00:38, 418.68batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 24837/40960 [00:58<00:38, 419.62batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 24837/40960 [00:58<00:38, 419.62batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 24921/40960 [00:58<00:38, 418.70batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 24921/40960 [00:58<00:38, 418.70batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 25007/40960 [00:58<00:37, 420.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 25007/40960 [00:58<00:37, 420.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 25092/40960 [00:59<00:37, 421.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 25092/40960 [00:59<00:37, 421.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 25177/40960 [00:59<00:37, 421.46batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  61%|▌| 25177/40960 [00:59<00:37, 421.46batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25259/40960 [00:59<00:37, 417.31batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25259/40960 [00:59<00:37, 417.31batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25345/40960 [00:59<00:37, 419.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25345/40960 [00:59<00:37, 419.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25429/40960 [00:59<00:37, 419.14batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25429/40960 [00:59<00:37, 419.14batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25513/40960 [01:00<00:36, 418.74batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25513/40960 [01:00<00:36, 418.74batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25594/40960 [01:00<00:37, 413.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  62%|▌| 25594/40960 [01:00<00:37, 413.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  63%|▋| 25678/40960 [01:00<00:36, 415.13batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|▋| 25678/40960 [01:00<00:36, 415.13batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  63%|▋| 25761/40960 [01:00<00:36, 414.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  63%|▋| 25761/40960 [01:00<00:36, 414.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  63%|▋| 25847/40960 [01:00<00:36, 419.13batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  63%|▋| 25847/40960 [01:00<00:36, 419.13batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  63%|▋| 25931/40960 [01:01<00:35, 419.28batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  63%|▋| 25931/40960 [01:01<00:35, 419.28batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26017/40960 [01:01<00:35, 421.60batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26017/40960 [01:01<00:35, 421.60batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26102/40960 [01:01<00:35, 421.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26102/40960 [01:01<00:35, 421.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26187/40960 [01:01<00:34, 422.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26187/40960 [01:01<00:34, 422.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26268/40960 [01:01<00:35, 416.90batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26268/40960 [01:01<00:35, 416.90batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26353/40960 [01:02<00:34, 418.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  64%|▋| 26353/40960 [01:02<00:34, 418.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26438/40960 [01:02<00:34, 419.85batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26438/40960 [01:02<00:34, 419.85batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26523/40960 [01:02<00:34, 420.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26523/40960 [01:02<00:34, 420.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26607/40960 [01:02<00:34, 419.79batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26607/40960 [01:02<00:34, 419.79batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26691/40960 [01:02<00:33, 419.77batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26691/40960 [01:02<00:33, 419.77batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26775/40960 [01:03<00:33, 419.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  65%|▋| 26775/40960 [01:03<00:33, 419.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 26860/40960 [01:03<00:33, 420.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 26860/40960 [01:03<00:33, 420.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 26944/40960 [01:03<00:33, 420.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 26944/40960 [01:03<00:33, 420.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 27030/40960 [01:03<00:32, 422.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 27030/40960 [01:03<00:32, 422.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 27111/40960 [01:03<00:33, 416.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 27111/40960 [01:04<00:33, 416.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 27196/40960 [01:04<00:32, 418.74batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  66%|▋| 27196/40960 [01:04<00:32, 418.74batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27281/40960 [01:04<00:32, 419.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27281/40960 [01:04<00:32, 419.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27362/40960 [01:04<00:32, 414.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27362/40960 [01:04<00:32, 414.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27445/40960 [01:04<00:32, 414.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27445/40960 [01:04<00:32, 414.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27530/40960 [01:05<00:32, 417.28batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27530/40960 [01:05<00:32, 417.28batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27614/40960 [01:05<00:31, 417.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  67%|▋| 27614/40960 [01:05<00:31, 417.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 27699/40960 [01:05<00:31, 418.47batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 27699/40960 [01:05<00:31, 418.47batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 27783/40960 [01:05<00:31, 417.65batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 27783/40960 [01:05<00:31, 417.65batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 27862/40960 [01:05<00:31, 410.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 27862/40960 [01:05<00:31, 410.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 27948/40960 [01:06<00:31, 415.32batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 27948/40960 [01:06<00:31, 415.32batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 28033/40960 [01:06<00:30, 417.65batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  68%|▋| 28033/40960 [01:06<00:30, 417.65batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28117/40960 [01:06<00:30, 417.76batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28117/40960 [01:06<00:30, 417.76batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28202/40960 [01:06<00:30, 418.51batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28202/40960 [01:06<00:30, 418.51batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28287/40960 [01:06<00:30, 420.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28287/40960 [01:06<00:30, 420.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28370/40960 [01:07<00:30, 417.68batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28370/40960 [01:07<00:30, 417.68batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28454/40960 [01:07<00:29, 417.62batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  69%|▋| 28454/40960 [01:07<00:29, 417.62batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28539/40960 [01:07<00:29, 419.60batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28539/40960 [01:07<00:29, 419.60batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28622/40960 [01:07<00:29, 417.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28622/40960 [01:07<00:29, 417.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28705/40960 [01:07<00:29, 416.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28705/40960 [01:07<00:29, 416.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28789/40960 [01:08<00:29, 416.62batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28789/40960 [01:08<00:29, 416.62batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28867/40960 [01:08<00:29, 408.45batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  70%|▋| 28867/40960 [01:08<00:29, 408.45batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  71%|▋| 28953/40960 [01:08<00:29, 413.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  71%|▋| 28953/40960 [01:08<00:29, 413.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  71%|▋| 29039/40960 [01:08<00:28, 417.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  71%|▋| 29039/40960 [01:08<00:28, 417.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  71%|▋| 29121/40960 [01:08<00:28, 414.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  71%|▋| 29121/40960 [01:08<00:28, 414.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  71%|▋| 29206/40960 [01:09<00:28, 417.60batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  71%|▋| 29206/40960 [01:09<00:28, 417.60batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29288/40960 [01:09<00:28, 415.23batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29288/40960 [01:09<00:28, 415.23batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29371/40960 [01:09<00:27, 414.24batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29371/40960 [01:09<00:27, 414.24batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|▋| 29456/40960 [01:09<00:27, 416.55batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29456/40960 [01:09<00:27, 416.55batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29539/40960 [01:09<00:27, 414.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29539/40960 [01:09<00:27, 414.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29623/40960 [01:10<00:27, 415.71batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  72%|▋| 29623/40960 [01:10<00:27, 415.71batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 29708/40960 [01:10<00:26, 417.59batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 29708/40960 [01:10<00:26, 417.59batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 29794/40960 [01:10<00:26, 420.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 29794/40960 [01:10<00:26, 420.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 29877/40960 [01:10<00:26, 418.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 29877/40960 [01:10<00:26, 418.67batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 29965/40960 [01:10<00:25, 423.88batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 29965/40960 [01:10<00:25, 423.88batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 30046/40960 [01:11<00:26, 417.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  73%|▋| 30046/40960 [01:11<00:26, 417.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30131/40960 [01:11<00:25, 418.27batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30131/40960 [01:11<00:25, 418.27batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30216/40960 [01:11<00:25, 419.76batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30216/40960 [01:11<00:25, 419.76batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30299/40960 [01:11<00:25, 417.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30299/40960 [01:11<00:25, 417.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30383/40960 [01:11<00:25, 417.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30383/40960 [01:11<00:25, 417.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30467/40960 [01:12<00:25, 417.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  74%|▋| 30467/40960 [01:12<00:25, 417.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▋| 30549/40960 [01:12<00:25, 415.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▋| 30549/40960 [01:12<00:25, 415.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▋| 30631/40960 [01:12<00:25, 412.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▋| 30631/40960 [01:12<00:25, 412.73batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▋| 30715/40960 [01:12<00:24, 413.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▋| 30715/40960 [01:12<00:24, 413.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▊| 30799/40960 [01:12<00:24, 414.85batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▊| 30799/40960 [01:12<00:24, 414.85batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▊| 30882/40960 [01:13<00:24, 413.66batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  75%|▊| 30882/40960 [01:13<00:24, 413.66batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 30967/40960 [01:13<00:23, 416.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 30967/40960 [01:13<00:23, 416.89batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 31051/40960 [01:13<00:23, 417.69batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 31051/40960 [01:13<00:23, 417.69batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 31134/40960 [01:13<00:23, 415.70batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 31134/40960 [01:13<00:23, 415.70batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 31216/40960 [01:13<00:23, 413.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 31216/40960 [01:13<00:23, 413.07batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 31296/40960 [01:14<00:23, 409.12batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  76%|▊| 31296/40960 [01:14<00:23, 409.12batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31379/40960 [01:14<00:23, 410.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31379/40960 [01:14<00:23, 410.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31464/40960 [01:14<00:22, 414.00batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31464/40960 [01:14<00:22, 414.00batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31548/40960 [01:14<00:22, 414.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31548/40960 [01:14<00:22, 414.99batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31634/40960 [01:14<00:22, 418.44batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31634/40960 [01:14<00:22, 418.44batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31720/40960 [01:15<00:21, 420.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  77%|▊| 31720/40960 [01:15<00:21, 420.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 31805/40960 [01:15<00:21, 421.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 31805/40960 [01:15<00:21, 421.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 31889/40960 [01:15<00:21, 419.76batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 31889/40960 [01:15<00:21, 419.76batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 31974/40960 [01:15<00:21, 419.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 31974/40960 [01:15<00:21, 419.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 32060/40960 [01:15<00:21, 422.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 32060/40960 [01:15<00:21, 422.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 32145/40960 [01:16<00:20, 422.46batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  78%|▊| 32145/40960 [01:16<00:20, 422.46batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  79%|▊| 32229/40960 [01:16<00:20, 420.32batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  79%|▊| 32229/40960 [01:16<00:20, 420.32batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  79%|▊| 32312/40960 [01:16<00:20, 418.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  79%|▊| 32312/40960 [01:16<00:20, 418.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  79%|▊| 32396/40960 [01:16<00:20, 418.45batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  79%|▊| 32396/40960 [01:16<00:20, 418.45batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  79%|▊| 32480/40960 [01:16<00:20, 417.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  79%|▊| 32480/40960 [01:16<00:20, 417.52batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32567/40960 [01:17<00:19, 421.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32567/40960 [01:17<00:19, 421.35batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32653/40960 [01:17<00:19, 422.39batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32653/40960 [01:17<00:19, 422.39batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32736/40960 [01:17<00:19, 419.68batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32736/40960 [01:17<00:19, 419.68batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32815/40960 [01:17<00:19, 411.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32815/40960 [01:17<00:19, 411.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32895/40960 [01:17<00:19, 407.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  80%|▊| 32895/40960 [01:17<00:19, 407.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 32979/40960 [01:18<00:19, 411.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 32979/40960 [01:18<00:19, 411.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33064/40960 [01:18<00:19, 414.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33064/40960 [01:18<00:19, 414.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33147/40960 [01:18<00:18, 414.74batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|▊| 33147/40960 [01:18<00:18, 414.74batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33228/40960 [01:18<00:18, 411.30batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33228/40960 [01:18<00:18, 411.30batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33312/40960 [01:18<00:18, 413.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33312/40960 [01:18<00:18, 413.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33395/40960 [01:19<00:18, 413.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33395/40960 [01:19<00:18, 413.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33477/40960 [01:19<00:18, 412.02batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33477/40960 [01:19<00:18, 412.02batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33562/40960 [01:19<00:17, 415.36batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33562/40960 [01:19<00:17, 415.36batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33643/40960 [01:19<00:17, 411.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33643/40960 [01:19<00:17, 411.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33724/40960 [01:19<00:17, 408.04batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  82%|▊| 33724/40960 [01:19<00:17, 408.04batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 33807/40960 [01:20<00:17, 409.17batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 33807/40960 [01:20<00:17, 409.17batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 33893/40960 [01:20<00:17, 414.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 33893/40960 [01:20<00:17, 414.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 33976/40960 [01:20<00:16, 413.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 33976/40960 [01:20<00:16, 413.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 34059/40960 [01:20<00:16, 414.12batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 34059/40960 [01:20<00:16, 414.12batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 34138/40960 [01:20<00:16, 407.70batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  83%|▊| 34138/40960 [01:20<00:16, 407.70batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34224/40960 [01:21<00:16, 413.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34224/40960 [01:21<00:16, 413.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34309/40960 [01:21<00:15, 416.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34309/40960 [01:21<00:15, 416.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34394/40960 [01:21<00:15, 418.15batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34394/40960 [01:21<00:15, 418.15batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34479/40960 [01:21<00:15, 419.76batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34479/40960 [01:21<00:15, 419.76batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34564/40960 [01:21<00:15, 420.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  84%|▊| 34564/40960 [01:21<00:15, 420.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34649/40960 [01:22<00:14, 421.53batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34649/40960 [01:22<00:14, 421.53batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34735/40960 [01:22<00:14, 423.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34735/40960 [01:22<00:14, 423.11batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34820/40960 [01:22<00:14, 423.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34820/40960 [01:22<00:14, 423.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34904/40960 [01:22<00:14, 421.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34904/40960 [01:22<00:14, 421.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34990/40960 [01:22<00:14, 423.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  85%|▊| 34990/40960 [01:22<00:14, 423.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35075/40960 [01:23<00:13, 423.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35075/40960 [01:23<00:13, 423.95batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35161/40960 [01:23<00:13, 424.36batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35161/40960 [01:23<00:13, 424.36batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35241/40960 [01:23<00:13, 415.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35241/40960 [01:23<00:13, 415.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35327/40960 [01:23<00:13, 419.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35327/40960 [01:23<00:13, 419.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35412/40960 [01:23<00:13, 420.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  86%|▊| 35412/40960 [01:23<00:13, 420.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35496/40960 [01:24<00:13, 419.98batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35496/40960 [01:24<00:13, 419.98batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [01:24<00:12, 420.42batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [01:24<00:12, 420.42batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35664/40960 [01:24<00:12, 418.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35664/40960 [01:24<00:12, 418.64batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35748/40960 [01:24<00:12, 418.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35748/40960 [01:24<00:12, 418.22batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35834/40960 [01:24<00:12, 420.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  87%|▊| 35834/40960 [01:24<00:12, 420.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  88%|▉| 35918/40960 [01:25<00:11, 420.21batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  88%|▉| 35918/40960 [01:25<00:11, 420.21batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  88%|▉| 36004/40960 [01:25<00:11, 422.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  88%|▉| 36004/40960 [01:25<00:11, 422.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  88%|▉| 36089/40960 [01:25<00:11, 421.93batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  88%|▉| 36089/40960 [01:25<00:11, 421.93batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  88%|▉| 36173/40960 [01:25<00:11, 420.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  88%|▉| 36173/40960 [01:25<00:11, 420.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36257/40960 [01:25<00:11, 420.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36257/40960 [01:25<00:11, 420.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36342/40960 [01:26<00:10, 421.39batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36342/40960 [01:26<00:10, 421.39batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36425/40960 [01:26<00:10, 418.53batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36425/40960 [01:26<00:10, 418.53batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36510/40960 [01:26<00:10, 419.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36510/40960 [01:26<00:10, 419.48batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36593/40960 [01:26<00:10, 416.90batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  89%|▉| 36593/40960 [01:26<00:10, 416.90batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 36675/40960 [01:26<00:10, 414.59batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 36675/40960 [01:26<00:10, 414.59batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 36756/40960 [01:27<00:10, 411.31batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 36756/40960 [01:27<00:10, 411.31batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 36841/40960 [01:27<00:09, 414.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 36841/40960 [01:27<00:09, 414.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 36922/40960 [01:27<00:09, 410.21batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 36922/40960 [01:27<00:09, 410.21batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 37003/40960 [01:27<00:09, 407.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  90%|▉| 37003/40960 [01:27<00:09, 407.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37086/40960 [01:27<00:09, 409.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37086/40960 [01:27<00:09, 409.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37169/40960 [01:28<00:09, 410.57batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37169/40960 [01:28<00:09, 410.57batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37252/40960 [01:28<00:09, 410.98batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37252/40960 [01:28<00:09, 410.98batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37336/40960 [01:28<00:08, 412.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37336/40960 [01:28<00:08, 412.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37420/40960 [01:28<00:08, 414.32batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  91%|▉| 37420/40960 [01:28<00:08, 414.32batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37503/40960 [01:28<00:08, 413.93batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37503/40960 [01:28<00:08, 413.93batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37588/40960 [01:29<00:08, 416.25batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37588/40960 [01:29<00:08, 416.25batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37671/40960 [01:29<00:07, 415.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37671/40960 [01:29<00:07, 415.63batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37755/40960 [01:29<00:07, 416.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37755/40960 [01:29<00:07, 416.37batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37838/40960 [01:29<00:07, 414.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  92%|▉| 37838/40960 [01:29<00:07, 414.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 37922/40960 [01:29<00:07, 415.29batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 37922/40960 [01:29<00:07, 415.29batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 38007/40960 [01:30<00:07, 417.57batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 38007/40960 [01:30<00:07, 417.57batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 38091/40960 [01:30<00:06, 417.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 38091/40960 [01:30<00:06, 417.50batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 38171/40960 [01:30<00:06, 411.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 38171/40960 [01:30<00:06, 411.94batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 38252/40960 [01:30<00:06, 409.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  93%|▉| 38252/40960 [01:30<00:06, 409.41batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38338/40960 [01:30<00:06, 414.36batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38338/40960 [01:30<00:06, 414.36batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [01:31<00:06, 418.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [01:31<00:06, 418.86batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38507/40960 [01:31<00:05, 416.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38507/40960 [01:31<00:05, 416.54batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38589/40960 [01:31<00:05, 413.84batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38589/40960 [01:31<00:05, 413.84batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38671/40960 [01:31<00:05, 412.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  94%|▉| 38671/40960 [01:31<00:05, 412.38batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 38757/40960 [01:31<00:05, 417.19batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 38757/40960 [01:31<00:05, 417.19batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 38841/40960 [01:32<00:05, 417.00batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 38841/40960 [01:32<00:05, 417.00batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 38926/40960 [01:32<00:04, 418.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 38926/40960 [01:32<00:04, 418.34batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 39010/40960 [01:32<00:04, 417.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 39010/40960 [01:32<00:04, 417.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 39094/40960 [01:32<00:04, 417.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  95%|▉| 39094/40960 [01:32<00:04, 417.75batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39179/40960 [01:32<00:04, 419.42batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39179/40960 [01:32<00:04, 419.42batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39264/40960 [01:33<00:04, 419.88batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39264/40960 [01:33<00:04, 419.88batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39348/40960 [01:33<00:03, 418.80batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39348/40960 [01:33<00:03, 418.80batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39432/40960 [01:33<00:03, 418.92batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39432/40960 [01:33<00:03, 418.92batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39515/40960 [01:33<00:03, 417.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  96%|▉| 39515/40960 [01:33<00:03, 417.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  97%|▉| 39601/40960 [01:33<00:03, 420.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  97%|▉| 39601/40960 [01:33<00:03, 420.08batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  97%|▉| 39686/40960 [01:34<00:03, 421.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  97%|▉| 39686/40960 [01:34<00:03, 421.20batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  97%|▉| 39770/40960 [01:34<00:02, 419.45batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  97%|▉| 39770/40960 [01:34<00:02, 419.45batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  97%|▉| 39855/40960 [01:34<00:02, 420.57batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  97%|▉| 39855/40960 [01:34<00:02, 420.57batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 39940/40960 [01:34<00:02, 421.42batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 39940/40960 [01:34<00:02, 421.42batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 40025/40960 [01:34<00:02, 421.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 40025/40960 [01:34<00:02, 421.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 40110/40960 [01:35<00:02, 422.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 40110/40960 [01:35<00:02, 422.03batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 40193/40960 [01:35<00:01, 419.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 40193/40960 [01:35<00:01, 419.26batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 40279/40960 [01:35<00:01, 421.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  98%|▉| 40279/40960 [01:35<00:01, 421.81batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40363/40960 [01:35<00:01, 420.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40363/40960 [01:35<00:01, 420.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40449/40960 [01:35<00:01, 423.04batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40449/40960 [01:35<00:01, 423.04batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40533/40960 [01:36<00:01, 422.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40533/40960 [01:36<00:01, 422.10batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40617/40960 [01:36<00:00, 420.56batches/s, l2_loss: 0.0008 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|▉| 40617/40960 [01:36<00:00, 420.56batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40699/40960 [01:36<00:00, 415.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training:  99%|▉| 40699/40960 [01:36<00:00, 415.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training: 100%|▉| 40782/40960 [01:36<00:00, 415.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training: 100%|▉| 40782/40960 [01:36<00:00, 415.18batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training: 100%|▉| 40867/40960 [01:36<00:00, 416.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training: 100%|▉| 40867/40960 [01:36<00:00, 416.97batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training: 100%|▉| 40950/40960 [01:37<00:00, 415.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "Training: 100%|▉| 40950/40960 [01:37<00:00, 415.49batches/s, l2_loss: 0.0008 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 18:52:48.432372: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:   8%| | 2/26 [03:26<41:09, 102.90s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 18:52:49.697368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 18:52:52.420764: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<10:41:37,  1.06batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:41:37,  1.06batches/s, l2_loss: 0.0192 - round_loss:\u001b[A\n",
      "Training:   0%| | 96/40960 [00:01<06:06, 111.44batches/s, l2_loss: 0.0192 - round_loss: \u001b[A\n",
      "Training:   0%| | 96/40960 [00:01<06:06, 111.44batches/s, l2_loss: 0.0161 - round_loss: \u001b[A\n",
      "Training:   0%| | 188/40960 [00:01<03:25, 198.28batches/s, l2_loss: 0.0161 - round_loss:\u001b[A\n",
      "Training:   0%| | 188/40960 [00:01<03:25, 198.28batches/s, l2_loss: 0.0122 - round_loss:\u001b[A\n",
      "Training:   1%| | 282/40960 [00:01<02:31, 269.20batches/s, l2_loss: 0.0122 - round_loss:\u001b[A\n",
      "Training:   1%| | 282/40960 [00:01<02:31, 269.20batches/s, l2_loss: 0.0127 - round_loss:\u001b[A\n",
      "Training:   1%| | 375/40960 [00:01<02:05, 322.24batches/s, l2_loss: 0.0127 - round_loss:\u001b[A\n",
      "Training:   1%| | 375/40960 [00:01<02:05, 322.24batches/s, l2_loss: 0.0135 - round_loss:\u001b[A\n",
      "Training:   1%| | 470/40960 [00:01<01:51, 364.09batches/s, l2_loss: 0.0135 - round_loss:\u001b[A\n",
      "Training:   1%| | 470/40960 [00:01<01:51, 364.09batches/s, l2_loss: 0.0128 - round_loss:\u001b[A\n",
      "Training:   1%| | 562/40960 [00:02<01:43, 391.28batches/s, l2_loss: 0.0128 - round_loss:\u001b[A\n",
      "Training:   1%| | 562/40960 [00:02<01:43, 391.28batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   2%| | 656/40960 [00:02<01:37, 414.04batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   2%| | 656/40960 [00:02<01:37, 414.04batches/s, l2_loss: 0.0135 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:02<01:34, 427.77batches/s, l2_loss: 0.0135 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:02<01:34, 427.77batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   2%| | 841/40960 [00:02<01:31, 436.73batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   2%| | 841/40960 [00:02<01:31, 436.73batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 935/40960 [00:02<01:29, 446.39batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 935/40960 [00:02<01:29, 446.39batches/s, l2_loss: 0.0133 - round_loss:\u001b[A\n",
      "Training:   3%| | 1027/40960 [00:03<01:28, 450.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   3%| | 1027/40960 [00:03<01:28, 450.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   3%| | 1121/40960 [00:03<01:27, 455.71batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   3%| | 1121/40960 [00:03<01:27, 455.71batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:   3%| | 1213/40960 [00:03<01:27, 456.31batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:   3%| | 1213/40960 [00:03<01:27, 456.31batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   3%| | 1307/40960 [00:03<01:26, 459.63batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   3%| | 1307/40960 [00:03<01:26, 459.63batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   3%| | 1401/40960 [00:03<01:25, 462.68batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   3%| | 1401/40960 [00:03<01:25, 462.68batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   4%| | 1495/40960 [00:04<01:25, 464.06batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   4%| | 1495/40960 [00:04<01:25, 464.06batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   4%| | 1589/40960 [00:04<01:24, 465.08batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   4%| | 1589/40960 [00:04<01:24, 465.08batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   4%| | 1681/40960 [00:04<01:24, 462.62batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   4%| | 1681/40960 [00:04<01:24, 462.62batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   4%| | 1775/40960 [00:04<01:24, 464.07batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   4%| | 1775/40960 [00:04<01:24, 464.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   5%| | 1868/40960 [00:04<01:24, 463.93batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   5%| | 1868/40960 [00:04<01:24, 463.93batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   5%| | 1962/40960 [00:05<01:23, 464.86batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   5%| | 1962/40960 [00:05<01:23, 464.86batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   5%| | 2055/40960 [00:05<01:23, 464.52batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   5%| | 2055/40960 [00:05<01:23, 464.52batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   5%| | 2148/40960 [00:05<01:23, 463.63batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   5%| | 2148/40960 [00:05<01:23, 463.63batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:   5%| | 2243/40960 [00:05<01:22, 466.96batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:   5%| | 2243/40960 [00:05<01:22, 466.96batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   6%| | 2336/40960 [00:05<01:22, 465.35batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   6%| | 2336/40960 [00:05<01:22, 465.35batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   6%| | 2426/40960 [00:06<01:23, 460.48batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   6%| | 2426/40960 [00:06<01:23, 460.48batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   6%| | 2518/40960 [00:06<01:23, 459.83batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   6%| | 2518/40960 [00:06<01:23, 459.83batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   6%| | 2609/40960 [00:06<01:23, 458.31batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   6%| | 2609/40960 [00:06<01:23, 458.31batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   7%| | 2703/40960 [00:06<01:23, 460.70batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   7%| | 2703/40960 [00:06<01:23, 460.70batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2797/40960 [00:06<01:22, 462.19batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2797/40960 [00:06<01:22, 462.19batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   7%| | 2891/40960 [00:07<01:22, 463.86batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   7%| | 2891/40960 [00:07<01:22, 463.86batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2985/40960 [00:07<01:21, 465.39batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2985/40960 [00:07<01:21, 465.39batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3078/40960 [00:07<01:21, 464.37batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3078/40960 [00:07<01:21, 464.37batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3170/40960 [00:07<01:21, 462.47batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3170/40960 [00:07<01:21, 462.47batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3262/40960 [00:07<01:21, 461.26batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3262/40960 [00:07<01:21, 461.26batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   8%| | 3353/40960 [00:08<01:21, 459.14batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   8%| | 3353/40960 [00:08<01:21, 459.14batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3446/40960 [00:08<01:21, 459.99batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3446/40960 [00:08<01:21, 459.99batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3541/40960 [00:08<01:20, 464.01batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3541/40960 [00:08<01:20, 464.01batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3635/40960 [00:08<01:20, 464.95batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3635/40960 [00:08<01:20, 464.95batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   9%| | 3729/40960 [00:08<01:20, 465.29batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   9%| | 3729/40960 [00:08<01:20, 465.29batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   9%| | 3822/40960 [00:09<01:19, 465.03batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   9%| | 3822/40960 [00:09<01:19, 465.03batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  10%| | 3917/40960 [00:09<01:19, 467.67batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  10%| | 3917/40960 [00:09<01:19, 467.67batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  10%| | 4013/40960 [00:09<01:18, 470.58batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  10%| | 4013/40960 [00:09<01:18, 470.58batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  10%| | 4105/40960 [00:09<01:18, 466.61batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  10%| | 4105/40960 [00:09<01:18, 466.61batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  10%| | 4199/40960 [00:09<01:18, 467.13batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  10%| | 4199/40960 [00:09<01:18, 467.13batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4293/40960 [00:10<01:18, 466.98batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4293/40960 [00:10<01:18, 466.98batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4388/40960 [00:10<01:18, 468.40batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4388/40960 [00:10<01:18, 468.40batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4481/40960 [00:10<01:18, 466.91batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4481/40960 [00:10<01:18, 466.91batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4575/40960 [00:10<01:17, 466.90batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4575/40960 [00:10<01:17, 466.90batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4668/40960 [00:10<01:17, 465.31batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4668/40960 [00:10<01:17, 465.31batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  12%| | 4762/40960 [00:11<01:17, 466.20batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  12%| | 4762/40960 [00:11<01:17, 466.20batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 4856/40960 [00:11<01:17, 467.18batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 4856/40960 [00:11<01:17, 467.18batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 4948/40960 [00:11<01:17, 464.64batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 4948/40960 [00:11<01:17, 464.64batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 5041/40960 [00:11<01:17, 464.50batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 5041/40960 [00:11<01:17, 464.50batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5136/40960 [00:11<01:16, 466.90batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5136/40960 [00:11<01:16, 466.90batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5230/40960 [00:12<01:16, 467.48batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5230/40960 [00:12<01:16, 467.48batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5322/40960 [00:12<01:16, 464.07batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5322/40960 [00:12<01:16, 464.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5415/40960 [00:12<01:16, 464.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5415/40960 [00:12<01:16, 464.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5509/40960 [00:12<01:16, 465.08batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5509/40960 [00:12<01:16, 465.08batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5603/40960 [00:12<01:15, 466.54batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5603/40960 [00:12<01:15, 466.54batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5695/40960 [00:13<01:15, 464.53batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5695/40960 [00:13<01:15, 464.53batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5787/40960 [00:13<01:16, 462.01batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5787/40960 [00:13<01:16, 462.01batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5882/40960 [00:13<01:15, 464.75batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5882/40960 [00:13<01:15, 464.75batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5974/40960 [00:13<01:15, 463.31batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5974/40960 [00:13<01:15, 463.31batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6067/40960 [00:13<01:15, 463.42batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6067/40960 [00:14<01:15, 463.42batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6161/40960 [00:14<01:14, 464.42batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6161/40960 [00:14<01:14, 464.42batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6253/40960 [00:14<01:15, 462.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6253/40960 [00:14<01:15, 462.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6349/40960 [00:14<01:14, 466.13batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6349/40960 [00:14<01:14, 466.13batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6443/40960 [00:14<01:13, 467.17batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6443/40960 [00:14<01:13, 467.17batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6536/40960 [00:15<01:13, 465.71batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6536/40960 [00:15<01:13, 465.71batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6629/40960 [00:15<01:13, 465.24batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6629/40960 [00:15<01:13, 465.24batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6723/40960 [00:15<01:13, 466.34batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6723/40960 [00:15<01:13, 466.34batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6818/40960 [00:15<01:12, 467.92batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6818/40960 [00:15<01:12, 467.92batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6911/40960 [00:15<01:12, 466.65batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6911/40960 [00:15<01:12, 466.65batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7004/40960 [00:16<01:12, 465.17batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7004/40960 [00:16<01:12, 465.17batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7098/40960 [00:16<01:12, 465.30batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7098/40960 [00:16<01:12, 465.30batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7188/40960 [00:16<01:13, 460.22batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7188/40960 [00:16<01:13, 460.22batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|▏| 7279/40960 [00:16<01:13, 458.52batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7279/40960 [00:16<01:13, 458.52batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7371/40960 [00:16<01:13, 458.47batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7371/40960 [00:16<01:13, 458.47batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7464/40960 [00:17<01:12, 459.53batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7464/40960 [00:17<01:12, 459.53batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7557/40960 [00:17<01:12, 460.81batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7557/40960 [00:17<01:12, 460.81batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7650/40960 [00:17<01:12, 461.51batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7650/40960 [00:17<01:12, 461.51batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7744/40960 [00:17<01:11, 463.41batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7744/40960 [00:17<01:11, 463.41batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7835/40960 [00:17<01:12, 459.75batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7835/40960 [00:17<01:12, 459.75batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7929/40960 [00:18<01:11, 461.82batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7929/40960 [00:18<01:11, 461.82batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8021/40960 [00:18<01:11, 460.67batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8021/40960 [00:18<01:11, 460.67batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8113/40960 [00:18<01:11, 460.45batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8113/40960 [00:18<01:11, 460.45batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8204/40960 [00:18<01:11, 457.34batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8204/40960 [00:18<01:11, 457.34batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8288/40960 [00:18<01:13, 445.84batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8288/40960 [00:18<01:13, 445.84batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8372/40960 [00:19<01:14, 437.07batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8372/40960 [00:19<01:14, 437.07batches/s, l2_loss: 0.0124 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8457/40960 [00:19<01:15, 432.81batches/s, l2_loss: 0.0124 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8457/40960 [00:19<01:15, 432.81batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8542/40960 [00:19<01:15, 429.43batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8542/40960 [00:19<01:15, 429.43batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8624/40960 [00:19<01:16, 423.09batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8624/40960 [00:19<01:16, 423.09batches/s, l2_loss: 0.0137 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8708/40960 [00:19<01:16, 421.95batches/s, l2_loss: 0.0137 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8708/40960 [00:19<01:16, 421.95batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8790/40960 [00:20<01:17, 417.16batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8790/40960 [00:20<01:17, 417.16batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8875/40960 [00:20<01:16, 418.99batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8875/40960 [00:20<01:16, 418.99batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8961/40960 [00:20<01:15, 422.28batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8961/40960 [00:20<01:15, 422.28batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9043/40960 [00:20<01:16, 418.30batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9043/40960 [00:20<01:16, 418.30batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9126/40960 [00:20<01:16, 415.96batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9126/40960 [00:20<01:16, 415.96batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9206/40960 [00:21<01:17, 410.63batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9206/40960 [00:21<01:17, 410.63batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9290/40960 [00:21<01:16, 412.53batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9290/40960 [00:21<01:16, 412.53batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9372/40960 [00:21<01:16, 411.61batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9372/40960 [00:21<01:16, 411.61batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9455/40960 [00:21<01:16, 412.07batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9455/40960 [00:21<01:16, 412.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9540/40960 [00:21<01:15, 414.85batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9540/40960 [00:21<01:15, 414.85batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9624/40960 [00:22<01:15, 416.19batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9624/40960 [00:22<01:15, 416.19batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9707/40960 [00:22<01:15, 415.80batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9707/40960 [00:22<01:15, 415.80batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9790/40960 [00:22<01:15, 414.74batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9790/40960 [00:22<01:15, 414.74batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9872/40960 [00:22<01:15, 412.93batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9872/40960 [00:22<01:15, 412.93batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9956/40960 [00:22<01:14, 413.93batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9956/40960 [00:22<01:14, 413.93batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10041/40960 [00:23<01:14, 415.87batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▏| 10041/40960 [00:23<01:14, 415.87batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▏| 10126/40960 [00:23<01:13, 417.73batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▏| 10126/40960 [00:23<01:13, 417.73batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▏| 10212/40960 [00:23<01:13, 420.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▏| 10212/40960 [00:23<01:13, 420.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▎| 10293/40960 [00:23<01:13, 414.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▎| 10293/40960 [00:23<01:13, 414.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▎| 10379/40960 [00:23<01:13, 418.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  25%|▎| 10379/40960 [00:23<01:13, 418.29batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  26%|▎| 10464/40960 [00:24<01:12, 419.62batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  26%|▎| 10464/40960 [00:24<01:12, 419.62batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  26%|▎| 10549/40960 [00:24<01:12, 420.75batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  26%|▎| 10549/40960 [00:24<01:12, 420.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  26%|▎| 10634/40960 [00:24<01:11, 421.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  26%|▎| 10634/40960 [00:24<01:11, 421.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  26%|▎| 10717/40960 [00:24<01:12, 419.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  26%|▎| 10717/40960 [00:24<01:12, 419.69batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  26%|▎| 10801/40960 [00:24<01:11, 419.11batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  26%|▎| 10801/40960 [00:24<01:11, 419.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  27%|▎| 10885/40960 [00:25<01:11, 419.34batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  27%|▎| 10885/40960 [00:25<01:11, 419.34batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  27%|▎| 10970/40960 [00:25<01:11, 419.62batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  27%|▎| 10970/40960 [00:25<01:11, 419.62batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  27%|▎| 11055/40960 [00:25<01:11, 419.87batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|▎| 11055/40960 [00:25<01:11, 419.87batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  27%|▎| 11140/40960 [00:25<01:10, 421.29batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  27%|▎| 11140/40960 [00:25<01:10, 421.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  27%|▎| 11223/40960 [00:25<01:11, 418.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  27%|▎| 11223/40960 [00:25<01:11, 418.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  28%|▎| 11309/40960 [00:26<01:10, 421.13batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  28%|▎| 11309/40960 [00:26<01:10, 421.13batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  28%|▎| 11391/40960 [00:26<01:10, 417.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  28%|▎| 11391/40960 [00:26<01:10, 417.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  28%|▎| 11476/40960 [00:26<01:10, 418.34batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  28%|▎| 11476/40960 [00:26<01:10, 418.34batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  28%|▎| 11559/40960 [00:26<01:10, 416.61batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  28%|▎| 11559/40960 [00:26<01:10, 416.61batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  28%|▎| 11644/40960 [00:26<01:10, 418.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  28%|▎| 11644/40960 [00:26<01:10, 418.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  29%|▎| 11727/40960 [00:27<01:10, 416.09batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  29%|▎| 11727/40960 [00:27<01:10, 416.09batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  29%|▎| 11808/40960 [00:27<01:10, 412.71batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  29%|▎| 11808/40960 [00:27<01:10, 412.71batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  29%|▎| 11892/40960 [00:27<01:10, 414.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  29%|▎| 11892/40960 [00:27<01:10, 414.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  29%|▎| 11976/40960 [00:27<01:09, 415.10batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  29%|▎| 11976/40960 [00:27<01:09, 415.10batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  29%|▎| 12060/40960 [00:27<01:09, 415.39batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  29%|▎| 12060/40960 [00:27<01:09, 415.39batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12142/40960 [00:28<01:09, 413.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12142/40960 [00:28<01:09, 413.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12227/40960 [00:28<01:09, 416.02batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12227/40960 [00:28<01:09, 416.02batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12307/40960 [00:28<01:09, 411.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12307/40960 [00:28<01:09, 411.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12390/40960 [00:28<01:09, 411.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12390/40960 [00:28<01:09, 411.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12471/40960 [00:28<01:09, 408.41batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  30%|▎| 12471/40960 [00:28<01:09, 408.41batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  31%|▎| 12555/40960 [00:29<01:09, 411.31batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  31%|▎| 12555/40960 [00:29<01:09, 411.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  31%|▎| 12637/40960 [00:29<01:09, 410.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  31%|▎| 12637/40960 [00:29<01:09, 410.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  31%|▎| 12718/40960 [00:29<01:09, 407.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  31%|▎| 12718/40960 [00:29<01:09, 407.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  31%|▎| 12802/40960 [00:29<01:08, 410.84batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  31%|▎| 12802/40960 [00:29<01:08, 410.84batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  31%|▎| 12885/40960 [00:29<01:08, 411.65batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  31%|▎| 12885/40960 [00:29<01:08, 411.65batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 12970/40960 [00:30<01:07, 414.44batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 12970/40960 [00:30<01:07, 414.44batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 13052/40960 [00:30<01:07, 412.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 13052/40960 [00:30<01:07, 412.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 13132/40960 [00:30<01:08, 408.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 13132/40960 [00:30<01:08, 408.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 13215/40960 [00:30<01:07, 409.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 13215/40960 [00:30<01:07, 409.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 13299/40960 [00:30<01:07, 412.09batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  32%|▎| 13299/40960 [00:30<01:07, 412.09batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  33%|▎| 13385/40960 [00:31<01:06, 416.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  33%|▎| 13385/40960 [00:31<01:06, 416.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  33%|▎| 13470/40960 [00:31<01:05, 418.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  33%|▎| 13470/40960 [00:31<01:05, 418.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  33%|▎| 13553/40960 [00:31<01:05, 417.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  33%|▎| 13553/40960 [00:31<01:05, 417.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  33%|▎| 13638/40960 [00:31<01:05, 418.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  33%|▎| 13638/40960 [00:31<01:05, 418.35batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  34%|▎| 13722/40960 [00:31<01:05, 418.30batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  34%|▎| 13722/40960 [00:31<01:05, 418.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  34%|▎| 13806/40960 [00:32<01:04, 418.40batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  34%|▎| 13806/40960 [00:32<01:04, 418.40batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  34%|▎| 13889/40960 [00:32<01:04, 417.14batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  34%|▎| 13889/40960 [00:32<01:04, 417.14batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  34%|▎| 13972/40960 [00:32<01:04, 415.96batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  34%|▎| 13972/40960 [00:32<01:04, 415.96batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  34%|▎| 14055/40960 [00:32<01:04, 415.43batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  34%|▎| 14055/40960 [00:32<01:04, 415.43batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14138/40960 [00:32<01:04, 415.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14138/40960 [00:32<01:04, 415.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14222/40960 [00:33<01:04, 415.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14222/40960 [00:33<01:04, 415.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14307/40960 [00:33<01:03, 417.71batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14307/40960 [00:33<01:03, 417.71batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14392/40960 [00:33<01:03, 419.79batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14392/40960 [00:33<01:03, 419.79batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14477/40960 [00:33<01:02, 420.91batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  35%|▎| 14477/40960 [00:33<01:02, 420.91batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14562/40960 [00:33<01:02, 422.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14562/40960 [00:33<01:02, 422.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14647/40960 [00:34<01:02, 421.93batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14647/40960 [00:34<01:02, 421.93batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14727/40960 [00:34<01:03, 413.97batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14727/40960 [00:34<01:03, 413.97batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|▎| 14810/40960 [00:34<01:03, 413.77batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14810/40960 [00:34<01:03, 413.77batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14892/40960 [00:34<01:03, 412.13batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  36%|▎| 14892/40960 [00:34<01:03, 412.13batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  37%|▎| 14976/40960 [00:34<01:02, 414.28batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  37%|▎| 14976/40960 [00:34<01:02, 414.28batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  37%|▎| 15058/40960 [00:35<01:02, 412.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  37%|▎| 15058/40960 [00:35<01:02, 412.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  37%|▎| 15143/40960 [00:35<01:02, 415.16batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  37%|▎| 15143/40960 [00:35<01:02, 415.16batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  37%|▎| 15227/40960 [00:35<01:01, 416.51batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  37%|▎| 15227/40960 [00:35<01:01, 416.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  37%|▎| 15313/40960 [00:35<01:01, 419.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  37%|▎| 15313/40960 [00:35<01:01, 419.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15395/40960 [00:35<01:01, 415.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15395/40960 [00:35<01:01, 415.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15477/40960 [00:36<01:01, 412.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15477/40960 [00:36<01:01, 412.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15561/40960 [00:36<01:01, 414.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15561/40960 [00:36<01:01, 414.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15642/40960 [00:36<01:01, 410.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15642/40960 [00:36<01:01, 410.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15724/40960 [00:36<01:01, 409.55batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  38%|▍| 15724/40960 [00:36<01:01, 409.55batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  39%|▍| 15808/40960 [00:36<01:01, 412.08batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  39%|▍| 15808/40960 [00:36<01:01, 412.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  39%|▍| 15890/40960 [00:37<01:01, 410.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  39%|▍| 15890/40960 [00:37<01:01, 410.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  39%|▍| 15973/40960 [00:37<01:00, 410.77batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  39%|▍| 15973/40960 [00:37<01:00, 410.77batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  39%|▍| 16059/40960 [00:37<00:59, 415.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  39%|▍| 16059/40960 [00:37<00:59, 415.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  39%|▍| 16142/40960 [00:37<00:59, 414.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  39%|▍| 16142/40960 [00:37<00:59, 414.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16221/40960 [00:37<01:00, 407.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16221/40960 [00:37<01:00, 407.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16305/40960 [00:38<00:59, 411.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16305/40960 [00:38<00:59, 411.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16386/40960 [00:38<01:00, 408.23batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16386/40960 [00:38<01:00, 408.23batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16469/40960 [00:38<00:59, 409.52batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16469/40960 [00:38<00:59, 409.52batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16551/40960 [00:38<00:59, 409.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  40%|▍| 16551/40960 [00:38<00:59, 409.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  41%|▍| 16634/40960 [00:38<00:59, 410.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  41%|▍| 16634/40960 [00:38<00:59, 410.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  41%|▍| 16718/40960 [00:39<00:58, 412.97batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  41%|▍| 16718/40960 [00:39<00:58, 412.97batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  41%|▍| 16802/40960 [00:39<00:58, 414.99batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  41%|▍| 16802/40960 [00:39<00:58, 414.99batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  41%|▍| 16886/40960 [00:39<00:57, 415.74batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  41%|▍| 16886/40960 [00:39<00:57, 415.74batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  41%|▍| 16973/40960 [00:39<00:56, 420.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  41%|▍| 16973/40960 [00:39<00:56, 420.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17057/40960 [00:39<00:57, 419.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17057/40960 [00:39<00:57, 419.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17143/40960 [00:40<00:56, 421.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17143/40960 [00:40<00:56, 421.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17227/40960 [00:40<00:56, 420.16batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17227/40960 [00:40<00:56, 420.16batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17308/40960 [00:40<00:57, 414.16batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17308/40960 [00:40<00:57, 414.16batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17393/40960 [00:40<00:56, 416.05batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  42%|▍| 17393/40960 [00:40<00:56, 416.05batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17475/40960 [00:40<00:56, 414.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17475/40960 [00:40<00:56, 414.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17560/40960 [00:41<00:56, 416.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17560/40960 [00:41<00:56, 416.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17644/40960 [00:41<00:55, 417.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17644/40960 [00:41<00:55, 417.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17727/40960 [00:41<00:55, 415.45batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17727/40960 [00:41<00:55, 415.45batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17813/40960 [00:41<00:55, 419.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  43%|▍| 17813/40960 [00:41<00:55, 419.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  44%|▍| 17893/40960 [00:41<00:55, 413.14batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  44%|▍| 17893/40960 [00:41<00:55, 413.14batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  44%|▍| 17978/40960 [00:42<00:55, 416.42batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  44%|▍| 17978/40960 [00:42<00:55, 416.42batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  44%|▍| 18063/40960 [00:42<00:54, 418.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  44%|▍| 18063/40960 [00:42<00:54, 418.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  44%|▍| 18144/40960 [00:42<00:55, 413.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  44%|▍| 18144/40960 [00:42<00:55, 413.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18228/40960 [00:42<00:54, 414.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18228/40960 [00:42<00:54, 414.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18313/40960 [00:42<00:54, 416.96batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18313/40960 [00:42<00:54, 416.96batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18396/40960 [00:43<00:54, 415.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18396/40960 [00:43<00:54, 415.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18480/40960 [00:43<00:54, 415.92batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 18480/40960 [00:43<00:54, 415.92batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18565/40960 [00:43<00:53, 417.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  45%|▍| 18565/40960 [00:43<00:53, 417.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18649/40960 [00:43<00:53, 417.10batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18649/40960 [00:43<00:53, 417.10batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18731/40960 [00:43<00:53, 413.83batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18731/40960 [00:43<00:53, 413.83batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18814/40960 [00:44<00:53, 412.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18814/40960 [00:44<00:53, 412.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18897/40960 [00:44<00:53, 413.26batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18897/40960 [00:44<00:53, 413.26batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18981/40960 [00:44<00:53, 414.19batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  46%|▍| 18981/40960 [00:44<00:53, 414.19batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19066/40960 [00:44<00:52, 416.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19066/40960 [00:44<00:52, 416.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19150/40960 [00:44<00:52, 417.28batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19150/40960 [00:44<00:52, 417.28batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19234/40960 [00:45<00:52, 417.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19234/40960 [00:45<00:52, 417.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19317/40960 [00:45<00:52, 415.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19317/40960 [00:45<00:52, 415.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19401/40960 [00:45<00:51, 417.00batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  47%|▍| 19401/40960 [00:45<00:51, 417.00batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19485/40960 [00:45<00:51, 417.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19485/40960 [00:45<00:51, 417.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19570/40960 [00:45<00:50, 419.65batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19570/40960 [00:45<00:50, 419.65batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19655/40960 [00:46<00:50, 420.28batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19655/40960 [00:46<00:50, 420.28batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19736/40960 [00:46<00:51, 414.91batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19736/40960 [00:46<00:51, 414.91batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19820/40960 [00:46<00:50, 416.26batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  48%|▍| 19820/40960 [00:46<00:50, 416.26batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 19905/40960 [00:46<00:50, 417.97batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 19905/40960 [00:46<00:50, 417.97batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 19988/40960 [00:46<00:50, 416.19batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 19988/40960 [00:46<00:50, 416.19batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 20074/40960 [00:47<00:49, 419.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 20074/40960 [00:47<00:49, 419.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 20157/40960 [00:47<00:49, 417.32batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 20157/40960 [00:47<00:49, 417.32batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 20241/40960 [00:47<00:49, 417.36batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  49%|▍| 20241/40960 [00:47<00:49, 417.36batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▍| 20326/40960 [00:47<00:49, 418.65batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▍| 20326/40960 [00:47<00:49, 418.65batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▍| 20411/40960 [00:47<00:48, 420.25batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▍| 20411/40960 [00:47<00:48, 420.25batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▌| 20494/40960 [00:48<00:48, 418.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▌| 20494/40960 [00:48<00:48, 418.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▌| 20577/40960 [00:48<00:48, 416.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▌| 20577/40960 [00:48<00:48, 416.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▌| 20660/40960 [00:48<00:48, 415.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  50%|▌| 20660/40960 [00:48<00:48, 415.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 20742/40960 [00:48<00:48, 413.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 20742/40960 [00:48<00:48, 413.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 20825/40960 [00:48<00:48, 412.41batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 20825/40960 [00:48<00:48, 412.41batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 20907/40960 [00:49<00:48, 410.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 20907/40960 [00:49<00:48, 410.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 20993/40960 [00:49<00:48, 415.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 20993/40960 [00:49<00:48, 415.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 21077/40960 [00:49<00:47, 415.20batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  51%|▌| 21077/40960 [00:49<00:47, 415.20batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21157/40960 [00:49<00:48, 410.39batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21157/40960 [00:49<00:48, 410.39batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21239/40960 [00:50<00:48, 409.26batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21239/40960 [00:50<00:48, 409.26batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21321/40960 [00:50<00:48, 408.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21321/40960 [00:50<00:48, 408.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21401/40960 [00:50<00:48, 404.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21401/40960 [00:50<00:48, 404.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21479/40960 [00:50<00:48, 399.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  52%|▌| 21479/40960 [00:50<00:48, 399.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21563/40960 [00:50<00:47, 404.54batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21563/40960 [00:50<00:47, 404.54batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21647/40960 [00:51<00:47, 408.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21647/40960 [00:51<00:47, 408.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21730/40960 [00:51<00:46, 409.34batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21730/40960 [00:51<00:46, 409.34batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21810/40960 [00:51<00:47, 405.48batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21810/40960 [00:51<00:47, 405.48batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21891/40960 [00:51<00:47, 404.70batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  53%|▌| 21891/40960 [00:51<00:47, 404.70batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 21974/40960 [00:51<00:46, 406.70batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 21974/40960 [00:51<00:46, 406.70batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 22057/40960 [00:52<00:46, 408.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 22057/40960 [00:52<00:46, 408.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 22126/40960 [00:52<00:48, 388.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 22126/40960 [00:52<00:48, 388.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|▌| 22196/40960 [00:52<00:49, 376.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 22196/40960 [00:52<00:49, 376.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 22269/40960 [00:52<00:50, 373.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  54%|▌| 22269/40960 [00:52<00:50, 373.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22349/40960 [00:52<00:48, 380.37batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22349/40960 [00:52<00:48, 380.37batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22430/40960 [00:53<00:47, 387.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22430/40960 [00:53<00:47, 387.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22507/40960 [00:53<00:47, 385.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22507/40960 [00:53<00:47, 385.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22582/40960 [00:53<00:48, 380.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22582/40960 [00:53<00:48, 380.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22662/40960 [00:53<00:47, 385.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  55%|▌| 22662/40960 [00:53<00:47, 385.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 22740/40960 [00:53<00:47, 386.00batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 22740/40960 [00:53<00:47, 386.00batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 22822/40960 [00:54<00:46, 393.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 22822/40960 [00:54<00:46, 393.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 22903/40960 [00:54<00:45, 395.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 22903/40960 [00:54<00:45, 395.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 22978/40960 [00:54<00:46, 388.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 22978/40960 [00:54<00:46, 388.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 23057/40960 [00:54<00:45, 390.42batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 23057/40960 [00:54<00:45, 390.42batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 23135/40960 [00:54<00:45, 389.94batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  56%|▌| 23135/40960 [00:54<00:45, 389.94batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23214/40960 [00:55<00:45, 390.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23214/40960 [00:55<00:45, 390.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23294/40960 [00:55<00:45, 392.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23294/40960 [00:55<00:45, 392.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23372/40960 [00:55<00:44, 390.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23372/40960 [00:55<00:44, 390.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23452/40960 [00:55<00:44, 392.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23452/40960 [00:55<00:44, 392.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23525/40960 [00:55<00:45, 384.14batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  57%|▌| 23525/40960 [00:55<00:45, 384.14batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23605/40960 [00:56<00:44, 388.61batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23605/40960 [00:56<00:44, 388.61batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23690/40960 [00:56<00:43, 398.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23690/40960 [00:56<00:43, 398.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23766/40960 [00:56<00:43, 391.54batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23766/40960 [00:56<00:43, 391.54batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23845/40960 [00:56<00:43, 391.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23845/40960 [00:56<00:43, 391.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23929/40960 [00:56<00:42, 400.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  58%|▌| 23929/40960 [00:56<00:42, 400.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24008/40960 [00:57<00:42, 397.99batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24008/40960 [00:57<00:42, 397.99batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24083/40960 [00:57<00:43, 390.77batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24083/40960 [00:57<00:43, 390.77batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24158/40960 [00:57<00:43, 385.36batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24158/40960 [00:57<00:43, 385.36batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24236/40960 [00:57<00:43, 385.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24236/40960 [00:57<00:43, 385.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24319/40960 [00:57<00:42, 393.39batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  59%|▌| 24319/40960 [00:57<00:42, 393.39batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24394/40960 [00:58<00:42, 386.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24394/40960 [00:58<00:42, 386.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24479/40960 [00:58<00:41, 397.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24479/40960 [00:58<00:41, 397.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24560/40960 [00:58<00:41, 397.93batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24560/40960 [00:58<00:41, 397.93batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24638/40960 [00:58<00:41, 394.44batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24638/40960 [00:58<00:41, 394.44batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24713/40960 [00:58<00:41, 388.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  60%|▌| 24713/40960 [00:58<00:41, 388.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 24793/40960 [00:59<00:41, 391.23batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 24793/40960 [00:59<00:41, 391.23batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 24870/40960 [00:59<00:41, 388.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 24870/40960 [00:59<00:41, 388.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 24951/40960 [00:59<00:40, 392.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 24951/40960 [00:59<00:40, 392.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 25027/40960 [00:59<00:41, 387.48batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 25027/40960 [00:59<00:41, 387.48batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 25100/40960 [00:59<00:41, 380.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 25100/40960 [00:59<00:41, 380.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 25179/40960 [01:00<00:41, 383.78batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  61%|▌| 25179/40960 [01:00<00:41, 383.78batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25255/40960 [01:00<00:41, 381.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25255/40960 [01:00<00:41, 381.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25336/40960 [01:00<00:40, 387.64batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25336/40960 [01:00<00:40, 387.64batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25409/40960 [01:00<00:40, 379.72batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25409/40960 [01:00<00:40, 379.72batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25486/40960 [01:00<00:40, 380.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25486/40960 [01:00<00:40, 380.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25565/40960 [01:01<00:40, 384.61batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  62%|▌| 25565/40960 [01:01<00:40, 384.61batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25643/40960 [01:01<00:39, 386.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|▋| 25643/40960 [01:01<00:39, 386.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25719/40960 [01:01<00:39, 384.05batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25719/40960 [01:01<00:39, 384.05batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25794/40960 [01:01<00:39, 380.41batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25794/40960 [01:01<00:39, 380.41batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25871/40960 [01:01<00:39, 381.72batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25871/40960 [01:01<00:39, 381.72batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25954/40960 [01:02<00:38, 390.61batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  63%|▋| 25954/40960 [01:02<00:38, 390.61batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26038/40960 [01:02<00:37, 399.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26038/40960 [01:02<00:37, 399.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26122/40960 [01:02<00:36, 404.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26122/40960 [01:02<00:36, 404.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26205/40960 [01:02<00:36, 407.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26205/40960 [01:02<00:36, 407.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26289/40960 [01:02<00:35, 410.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26289/40960 [01:02<00:35, 410.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26369/40960 [01:03<00:35, 406.54batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  64%|▋| 26369/40960 [01:03<00:35, 406.54batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26452/40960 [01:03<00:35, 408.78batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26452/40960 [01:03<00:35, 408.78batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26534/40960 [01:03<00:35, 408.16batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26534/40960 [01:03<00:35, 408.16batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26618/40960 [01:03<00:34, 411.33batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26618/40960 [01:03<00:34, 411.33batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26704/40960 [01:03<00:34, 415.76batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26704/40960 [01:03<00:34, 415.76batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26789/40960 [01:04<00:33, 417.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  65%|▋| 26789/40960 [01:04<00:33, 417.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 26871/40960 [01:04<00:34, 413.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 26871/40960 [01:04<00:34, 413.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 26951/40960 [01:04<00:34, 408.40batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 26951/40960 [01:04<00:34, 408.40batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 27034/40960 [01:04<00:33, 410.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 27034/40960 [01:04<00:33, 410.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 27116/40960 [01:04<00:33, 409.24batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 27116/40960 [01:04<00:33, 409.24batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:05<00:33, 411.78batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:05<00:33, 411.78batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27280/40960 [01:05<00:33, 407.83batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27280/40960 [01:05<00:33, 407.83batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27355/40960 [01:05<00:34, 397.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27355/40960 [01:05<00:34, 397.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27434/40960 [01:05<00:34, 396.78batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27434/40960 [01:05<00:34, 396.78batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27513/40960 [01:05<00:34, 394.97batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27513/40960 [01:05<00:34, 394.97batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27595/40960 [01:06<00:33, 398.22batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  67%|▋| 27595/40960 [01:06<00:33, 398.22batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27679/40960 [01:06<00:32, 403.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27679/40960 [01:06<00:32, 403.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27763/40960 [01:06<00:32, 407.53batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27763/40960 [01:06<00:32, 407.53batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27847/40960 [01:06<00:31, 410.93batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27847/40960 [01:06<00:31, 410.93batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27920/40960 [01:06<00:32, 395.64batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27920/40960 [01:06<00:32, 395.64batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27989/40960 [01:07<00:34, 379.99batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  68%|▋| 27989/40960 [01:07<00:34, 379.99batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28059/40960 [01:07<00:34, 369.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28059/40960 [01:07<00:34, 369.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28134/40960 [01:07<00:34, 370.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28134/40960 [01:07<00:34, 370.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28211/40960 [01:07<00:34, 374.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28211/40960 [01:07<00:34, 374.63batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28288/40960 [01:07<00:33, 376.64batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28288/40960 [01:07<00:33, 376.64batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28356/40960 [01:08<00:34, 365.44batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28356/40960 [01:08<00:34, 365.44batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28434/40960 [01:08<00:33, 372.43batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28434/40960 [01:08<00:33, 372.43batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28517/40960 [01:08<00:32, 384.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28517/40960 [01:08<00:32, 384.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28599/40960 [01:08<00:31, 390.52batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28599/40960 [01:08<00:31, 390.52batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28682/40960 [01:08<00:30, 397.21batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28682/40960 [01:08<00:30, 397.21batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28763/40960 [01:09<00:30, 399.48batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28763/40960 [01:09<00:30, 399.48batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28834/40960 [01:09<00:31, 385.10batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  70%|▋| 28834/40960 [01:09<00:31, 385.10batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 28902/40960 [01:09<00:32, 370.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 28902/40960 [01:09<00:32, 370.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 28977/40960 [01:09<00:32, 371.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 28977/40960 [01:09<00:32, 371.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 29053/40960 [01:09<00:31, 372.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 29053/40960 [01:09<00:31, 372.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 29134/40960 [01:10<00:30, 381.53batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 29134/40960 [01:10<00:30, 381.53batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|▋| 29199/40960 [01:10<00:32, 364.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 29199/40960 [01:10<00:32, 364.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 29267/40960 [01:10<00:32, 356.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  71%|▋| 29267/40960 [01:10<00:32, 356.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29344/40960 [01:10<00:31, 364.02batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29344/40960 [01:10<00:31, 364.02batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29426/40960 [01:10<00:30, 377.65batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29426/40960 [01:10<00:30, 377.65batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29510/40960 [01:11<00:29, 389.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29510/40960 [01:11<00:29, 389.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29595/40960 [01:11<00:28, 399.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29595/40960 [01:11<00:28, 399.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29678/40960 [01:11<00:27, 403.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  72%|▋| 29678/40960 [01:11<00:27, 403.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 29762/40960 [01:11<00:27, 408.20batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 29762/40960 [01:11<00:27, 408.20batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 29847/40960 [01:11<00:26, 411.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 29847/40960 [01:11<00:26, 411.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 29931/40960 [01:12<00:26, 413.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 29931/40960 [01:12<00:26, 413.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 30015/40960 [01:12<00:26, 413.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 30015/40960 [01:12<00:26, 413.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 30085/40960 [01:12<00:27, 394.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  73%|▋| 30085/40960 [01:12<00:27, 394.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30158/40960 [01:12<00:28, 384.22batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30158/40960 [01:12<00:28, 384.22batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30236/40960 [01:12<00:27, 385.43batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30236/40960 [01:12<00:27, 385.43batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30311/40960 [01:13<00:27, 381.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30311/40960 [01:13<00:27, 381.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30387/40960 [01:13<00:27, 380.84batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30387/40960 [01:13<00:27, 380.84batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30457/40960 [01:13<00:28, 370.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  74%|▋| 30457/40960 [01:13<00:28, 370.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▋| 30529/40960 [01:13<00:28, 367.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▋| 30529/40960 [01:13<00:28, 367.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▋| 30607/40960 [01:13<00:27, 373.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▋| 30607/40960 [01:13<00:27, 373.01batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▋| 30691/40960 [01:14<00:26, 386.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▋| 30691/40960 [01:14<00:26, 386.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▊| 30771/40960 [01:14<00:26, 389.05batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▊| 30771/40960 [01:14<00:26, 389.05batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▊| 30854/40960 [01:14<00:25, 396.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  75%|▊| 30854/40960 [01:14<00:25, 396.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 30937/40960 [01:14<00:24, 401.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 30937/40960 [01:14<00:24, 401.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31019/40960 [01:14<00:24, 403.80batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31019/40960 [01:14<00:24, 403.80batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31102/40960 [01:15<00:24, 406.88batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31102/40960 [01:15<00:24, 406.88batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31177/40960 [01:15<00:24, 396.23batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31177/40960 [01:15<00:24, 396.23batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31251/40960 [01:15<00:25, 387.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31251/40960 [01:15<00:25, 387.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31333/40960 [01:15<00:24, 392.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  76%|▊| 31333/40960 [01:15<00:24, 392.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31410/40960 [01:15<00:24, 389.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31410/40960 [01:15<00:24, 389.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31485/40960 [01:16<00:24, 385.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31485/40960 [01:16<00:24, 385.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31568/40960 [01:16<00:23, 393.53batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31568/40960 [01:16<00:23, 393.53batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31649/40960 [01:16<00:23, 396.52batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31649/40960 [01:16<00:23, 396.52batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31720/40960 [01:16<00:24, 382.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  77%|▊| 31720/40960 [01:16<00:24, 382.58batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 31790/40960 [01:16<00:24, 372.80batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 31790/40960 [01:16<00:24, 372.80batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 31872/40960 [01:17<00:23, 383.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 31872/40960 [01:17<00:23, 383.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 31954/40960 [01:17<00:23, 390.25batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 31954/40960 [01:17<00:23, 390.25batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 32031/40960 [01:17<00:23, 388.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 32031/40960 [01:17<00:23, 388.12batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 32107/40960 [01:17<00:22, 384.96batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  78%|▊| 32107/40960 [01:17<00:22, 384.96batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32185/40960 [01:17<00:22, 386.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32185/40960 [01:17<00:22, 386.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32265/40960 [01:18<00:22, 390.28batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32265/40960 [01:18<00:22, 390.28batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32342/40960 [01:18<00:22, 388.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32342/40960 [01:18<00:22, 388.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32418/40960 [01:18<00:22, 385.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32418/40960 [01:18<00:22, 385.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32495/40960 [01:18<00:22, 384.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  79%|▊| 32495/40960 [01:18<00:22, 384.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32574/40960 [01:18<00:21, 387.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32574/40960 [01:18<00:21, 387.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32650/40960 [01:19<00:21, 384.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32650/40960 [01:19<00:21, 384.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32727/40960 [01:19<00:21, 383.72batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32727/40960 [01:19<00:21, 383.72batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32804/40960 [01:19<00:21, 383.03batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32804/40960 [01:19<00:21, 383.03batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32883/40960 [01:19<00:20, 385.24batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32883/40960 [01:19<00:20, 385.24batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32961/40960 [01:19<00:20, 386.40batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  80%|▊| 32961/40960 [01:19<00:20, 386.40batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33042/40960 [01:20<00:20, 391.43batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33042/40960 [01:20<00:20, 391.43batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33124/40960 [01:20<00:19, 396.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33124/40960 [01:20<00:19, 396.51batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33199/40960 [01:20<00:19, 388.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33199/40960 [01:20<00:19, 388.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33276/40960 [01:20<00:19, 387.57batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33276/40960 [01:20<00:19, 387.57batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33352/40960 [01:20<00:19, 385.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  81%|▊| 33352/40960 [01:20<00:19, 385.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33430/40960 [01:21<00:19, 385.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33430/40960 [01:21<00:19, 385.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33509/40960 [01:21<00:19, 388.03batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33509/40960 [01:21<00:19, 388.03batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33585/40960 [01:21<00:19, 384.49batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33585/40960 [01:21<00:19, 384.49batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33659/40960 [01:21<00:19, 379.70batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33659/40960 [01:21<00:19, 379.70batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33741/40960 [01:22<00:18, 387.19batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33741/40960 [01:22<00:18, 387.19batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 33823/40960 [01:22<00:18, 392.71batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 33823/40960 [01:22<00:18, 392.71batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 33906/40960 [01:22<00:17, 399.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 33906/40960 [01:22<00:17, 399.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 33990/40960 [01:22<00:17, 405.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 33990/40960 [01:22<00:17, 405.29batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 34073/40960 [01:22<00:16, 407.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 34073/40960 [01:22<00:16, 407.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 34157/40960 [01:23<00:16, 411.07batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  83%|▊| 34157/40960 [01:23<00:16, 411.07batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34236/40960 [01:23<00:16, 405.25batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34236/40960 [01:23<00:16, 405.25batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34315/40960 [01:23<00:16, 401.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34315/40960 [01:23<00:16, 401.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34393/40960 [01:23<00:16, 396.87batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34393/40960 [01:23<00:16, 396.87batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34475/40960 [01:23<00:16, 400.00batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34475/40960 [01:23<00:16, 400.00batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34559/40960 [01:24<00:15, 405.36batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  84%|▊| 34559/40960 [01:24<00:15, 405.36batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34637/40960 [01:24<00:15, 400.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34637/40960 [01:24<00:15, 400.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34712/40960 [01:24<00:15, 392.37batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34712/40960 [01:24<00:15, 392.37batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34787/40960 [01:24<00:15, 385.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34787/40960 [01:24<00:15, 385.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34863/40960 [01:24<00:15, 383.45batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34863/40960 [01:24<00:15, 383.45batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34938/40960 [01:25<00:15, 380.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 34938/40960 [01:25<00:15, 380.06batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 35017/40960 [01:25<00:15, 383.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  85%|▊| 35017/40960 [01:25<00:15, 383.31batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35094/40960 [01:25<00:15, 383.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35094/40960 [01:25<00:15, 383.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35173/40960 [01:25<00:14, 386.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35173/40960 [01:25<00:14, 386.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35253/40960 [01:25<00:14, 390.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35253/40960 [01:25<00:14, 390.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35328/40960 [01:26<00:14, 385.73batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35328/40960 [01:26<00:14, 385.73batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35402/40960 [01:26<00:14, 380.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35402/40960 [01:26<00:14, 380.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35482/40960 [01:26<00:14, 385.37batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35482/40960 [01:26<00:14, 385.37batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35557/40960 [01:26<00:14, 381.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35557/40960 [01:26<00:14, 381.27batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35632/40960 [01:26<00:14, 378.62batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35632/40960 [01:26<00:14, 378.62batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35709/40960 [01:27<00:13, 379.48batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35709/40960 [01:27<00:13, 379.48batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35787/40960 [01:27<00:13, 382.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  87%|▊| 35787/40960 [01:27<00:13, 382.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 35869/40960 [01:27<00:13, 389.74batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 35869/40960 [01:27<00:13, 389.74batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 35954/40960 [01:27<00:12, 399.03batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 35954/40960 [01:27<00:12, 399.03batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 36036/40960 [01:27<00:12, 401.74batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 36036/40960 [01:27<00:12, 401.74batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 36118/40960 [01:28<00:12, 402.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 36118/40960 [01:28<00:12, 402.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|▉| 36200/40960 [01:28<00:11, 404.21batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  88%|▉| 36200/40960 [01:28<00:11, 404.21batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36276/40960 [01:28<00:11, 396.21batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36276/40960 [01:28<00:11, 396.21batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36353/40960 [01:28<00:11, 392.26batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36353/40960 [01:28<00:11, 392.26batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36429/40960 [01:28<00:11, 388.56batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36429/40960 [01:28<00:11, 388.56batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36513/40960 [01:29<00:11, 396.55batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36513/40960 [01:29<00:11, 396.55batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36597/40960 [01:29<00:10, 402.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  89%|▉| 36597/40960 [01:29<00:10, 402.86batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36675/40960 [01:29<00:10, 397.77batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36675/40960 [01:29<00:10, 397.77batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36750/40960 [01:29<00:10, 390.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36750/40960 [01:29<00:10, 390.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36823/40960 [01:29<00:10, 381.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36823/40960 [01:29<00:10, 381.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36900/40960 [01:30<00:10, 381.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36900/40960 [01:30<00:10, 381.90batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36978/40960 [01:30<00:10, 383.67batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 36978/40960 [01:30<00:10, 383.67batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 37054/40960 [01:30<00:10, 381.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  90%|▉| 37054/40960 [01:30<00:10, 381.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37134/40960 [01:30<00:09, 386.73batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37134/40960 [01:30<00:09, 386.73batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37211/40960 [01:30<00:09, 384.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37211/40960 [01:30<00:09, 384.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37289/40960 [01:31<00:09, 386.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37289/40960 [01:31<00:09, 386.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37369/40960 [01:31<00:09, 389.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37369/40960 [01:31<00:09, 389.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37450/40960 [01:31<00:08, 392.91batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  91%|▉| 37450/40960 [01:31<00:08, 392.91batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37527/40960 [01:31<00:08, 389.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37527/40960 [01:31<00:08, 389.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37609/40960 [01:31<00:08, 395.05batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37609/40960 [01:31<00:08, 395.05batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37693/40960 [01:32<00:08, 402.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37693/40960 [01:32<00:08, 402.04batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37773/40960 [01:32<00:07, 401.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37773/40960 [01:32<00:07, 401.38batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37846/40960 [01:32<00:07, 390.36batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  92%|▉| 37846/40960 [01:32<00:07, 390.36batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 37922/40960 [01:32<00:07, 386.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 37922/40960 [01:32<00:07, 386.81batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 38001/40960 [01:32<00:07, 389.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 38001/40960 [01:32<00:07, 389.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 38085/40960 [01:33<00:07, 398.34batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 38085/40960 [01:33<00:07, 398.34batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 38166/40960 [01:33<00:06, 400.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 38166/40960 [01:33<00:06, 400.11batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 38242/40960 [01:33<00:06, 392.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  93%|▉| 38242/40960 [01:33<00:06, 392.89batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38315/40960 [01:33<00:06, 383.32batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38315/40960 [01:33<00:06, 383.32batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38394/40960 [01:33<00:06, 385.76batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38394/40960 [01:33<00:06, 385.76batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38473/40960 [01:34<00:06, 387.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38473/40960 [01:34<00:06, 387.15batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38551/40960 [01:34<00:06, 386.64batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38551/40960 [01:34<00:06, 386.64batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38627/40960 [01:34<00:06, 383.76batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38627/40960 [01:34<00:06, 383.76batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38704/40960 [01:34<00:05, 383.62batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  94%|▉| 38704/40960 [01:34<00:05, 383.62batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 38779/40960 [01:34<00:05, 380.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 38779/40960 [01:34<00:05, 380.59batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 38861/40960 [01:35<00:05, 388.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 38861/40960 [01:35<00:05, 388.66batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 38944/40960 [01:35<00:05, 395.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 38944/40960 [01:35<00:05, 395.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 39021/40960 [01:35<00:04, 391.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 39021/40960 [01:35<00:04, 391.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 39096/40960 [01:35<00:04, 385.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  95%|▉| 39096/40960 [01:35<00:04, 385.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39177/40960 [01:35<00:04, 390.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39177/40960 [01:35<00:04, 390.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39260/40960 [01:36<00:04, 396.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39260/40960 [01:36<00:04, 396.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39341/40960 [01:36<00:04, 398.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39341/40960 [01:36<00:04, 398.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39416/40960 [01:36<00:03, 390.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39416/40960 [01:36<00:03, 390.95batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39491/40960 [01:36<00:03, 385.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  96%|▉| 39491/40960 [01:36<00:03, 385.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39568/40960 [01:36<00:03, 384.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39568/40960 [01:36<00:03, 384.18batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39646/40960 [01:37<00:03, 384.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39646/40960 [01:37<00:03, 384.82batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39717/40960 [01:37<00:03, 375.32batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39717/40960 [01:37<00:03, 375.32batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39793/40960 [01:37<00:03, 376.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39793/40960 [01:37<00:03, 376.47batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39871/40960 [01:37<00:02, 380.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  97%|▉| 39871/40960 [01:37<00:02, 380.35batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 39945/40960 [01:37<00:02, 376.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 39945/40960 [01:37<00:02, 376.17batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 40020/40960 [01:38<00:02, 375.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 40020/40960 [01:38<00:02, 375.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 40099/40960 [01:38<00:02, 380.44batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 40099/40960 [01:38<00:02, 380.44batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 40181/40960 [01:38<00:02, 389.03batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 40181/40960 [01:38<00:02, 389.03batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 40264/40960 [01:38<00:01, 396.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  98%|▉| 40264/40960 [01:38<00:01, 396.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40346/40960 [01:38<00:01, 399.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40346/40960 [01:38<00:01, 399.75batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40424/40960 [01:39<00:01, 395.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40424/40960 [01:39<00:01, 395.69batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40501/40960 [01:39<00:01, 391.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40501/40960 [01:39<00:01, 391.85batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40585/40960 [01:39<00:00, 399.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40585/40960 [01:39<00:00, 399.30batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40667/40960 [01:39<00:00, 402.42batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40667/40960 [01:39<00:00, 402.42batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40747/40960 [01:39<00:00, 401.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  99%|▉| 40747/40960 [01:39<00:00, 401.68batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training: 100%|▉| 40830/40960 [01:40<00:00, 405.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training: 100%|▉| 40830/40960 [01:40<00:00, 405.08batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training: 100%|▉| 40913/40960 [01:40<00:00, 407.24batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training: 100%|▉| 40913/40960 [01:40<00:00, 407.24batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 18:54:32.266961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  12%| | 3/26 [05:10<39:36, 103.34s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 18:54:33.563582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 18:54:36.274650: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<10:35:43,  1.07batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:35:43,  1.07batches/s, l2_loss: 0.0022 - round_loss:\u001b[A\n",
      "Training:   0%| | 93/40960 [00:01<06:15, 108.69batches/s, l2_loss: 0.0022 - round_loss: \u001b[A\n",
      "Training:   0%| | 93/40960 [00:01<06:15, 108.69batches/s, l2_loss: 0.0047 - round_loss: \u001b[A\n",
      "Training:   0%| | 185/40960 [00:01<03:27, 196.71batches/s, l2_loss: 0.0047 - round_loss:\u001b[A\n",
      "Training:   0%| | 185/40960 [00:01<03:27, 196.71batches/s, l2_loss: 0.0092 - round_loss:\u001b[A\n",
      "Training:   1%| | 279/40960 [00:01<02:31, 268.70batches/s, l2_loss: 0.0092 - round_loss:\u001b[A\n",
      "Training:   1%| | 279/40960 [00:01<02:31, 268.70batches/s, l2_loss: 0.0090 - round_loss:\u001b[A\n",
      "Training:   1%| | 373/40960 [00:01<02:05, 323.52batches/s, l2_loss: 0.0090 - round_loss:\u001b[A\n",
      "Training:   1%| | 373/40960 [00:01<02:05, 323.52batches/s, l2_loss: 0.0093 - round_loss:\u001b[A\n",
      "Training:   1%| | 468/40960 [00:01<01:50, 365.92batches/s, l2_loss: 0.0093 - round_loss:\u001b[A\n",
      "Training:   1%| | 468/40960 [00:01<01:50, 365.92batches/s, l2_loss: 0.0085 - round_loss:\u001b[A\n",
      "Training:   1%| | 561/40960 [00:02<01:42, 393.31batches/s, l2_loss: 0.0085 - round_loss:\u001b[A\n",
      "Training:   1%| | 561/40960 [00:02<01:42, 393.31batches/s, l2_loss: 0.0092 - round_loss:\u001b[A\n",
      "Training:   2%| | 655/40960 [00:02<01:37, 415.36batches/s, l2_loss: 0.0092 - round_loss:\u001b[A\n",
      "Training:   2%| | 655/40960 [00:02<01:37, 415.36batches/s, l2_loss: 0.0090 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:02<01:33, 430.35batches/s, l2_loss: 0.0090 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:02<01:33, 430.35batches/s, l2_loss: 0.0091 - round_loss:\u001b[A\n",
      "Training:   2%| | 841/40960 [00:02<01:31, 438.11batches/s, l2_loss: 0.0091 - round_loss:\u001b[A\n",
      "Training:   2%| | 841/40960 [00:02<01:31, 438.11batches/s, l2_loss: 0.0093 - round_loss:\u001b[A\n",
      "Training:   2%| | 935/40960 [00:02<01:29, 446.12batches/s, l2_loss: 0.0093 - round_loss:\u001b[A\n",
      "Training:   2%| | 935/40960 [00:02<01:29, 446.12batches/s, l2_loss: 0.0090 - round_loss:\u001b[A\n",
      "Training:   3%| | 1030/40960 [00:03<01:27, 453.89batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   3%| | 1030/40960 [00:03<01:27, 453.89batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:   3%| | 1122/40960 [00:03<01:27, 454.86batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:   3%| | 1122/40960 [00:03<01:27, 454.86batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:   3%| | 1215/40960 [00:03<01:27, 456.57batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:   3%| | 1215/40960 [00:03<01:27, 456.57batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:   3%| | 1308/40960 [00:03<01:26, 458.30batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:   3%| | 1308/40960 [00:03<01:26, 458.30batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   3%| | 1401/40960 [00:03<01:25, 460.18batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   3%| | 1401/40960 [00:03<01:25, 460.18batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:   4%| | 1495/40960 [00:04<01:25, 462.87batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:   4%| | 1495/40960 [00:04<01:25, 462.87batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:   4%| | 1591/40960 [00:04<01:24, 467.90batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:   4%| | 1591/40960 [00:04<01:24, 467.90batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:   4%| | 1682/40960 [00:04<01:24, 463.66batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:   4%| | 1682/40960 [00:04<01:24, 463.66batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   4%| | 1774/40960 [00:04<01:24, 462.20batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   4%| | 1774/40960 [00:04<01:24, 462.20batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   5%| | 1867/40960 [00:04<01:24, 462.70batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   5%| | 1867/40960 [00:04<01:24, 462.70batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   5%| | 1961/40960 [00:05<01:24, 463.70batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 1961/40960 [00:05<01:24, 463.70batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   5%| | 2052/40960 [00:05<01:24, 460.36batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   5%| | 2052/40960 [00:05<01:24, 460.36batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   5%| | 2149/40960 [00:05<01:23, 466.64batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   5%| | 2149/40960 [00:05<01:23, 466.64batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   5%| | 2243/40960 [00:05<01:22, 467.30batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   5%| | 2243/40960 [00:05<01:22, 467.30batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   6%| | 2336/40960 [00:05<01:22, 465.94batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   6%| | 2336/40960 [00:05<01:22, 465.94batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   6%| | 2432/40960 [00:06<01:22, 468.93batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   6%| | 2432/40960 [00:06<01:22, 468.93batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   6%| | 2525/40960 [00:06<01:22, 467.68batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   6%| | 2525/40960 [00:06<01:22, 467.68batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   6%| | 2619/40960 [00:06<01:22, 467.31batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   6%| | 2619/40960 [00:06<01:22, 467.31batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   7%| | 2712/40960 [00:06<01:21, 466.44batches/s, l2_loss: 0.0091 - round_loss\u001b[A\n",
      "Training:   7%| | 2712/40960 [00:06<01:21, 466.44batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   7%| | 2807/40960 [00:06<01:21, 468.13batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   7%| | 2807/40960 [00:06<01:21, 468.13batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   7%| | 2900/40960 [00:07<01:21, 466.11batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   7%| | 2900/40960 [00:07<01:21, 466.11batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   7%| | 2995/40960 [00:07<01:21, 468.05batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   7%| | 2995/40960 [00:07<01:21, 468.05batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   8%| | 3091/40960 [00:07<01:20, 470.92batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   8%| | 3091/40960 [00:07<01:20, 470.92batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   8%| | 3187/40960 [00:07<01:19, 472.37batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   8%| | 3187/40960 [00:07<01:19, 472.37batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:   8%| | 3280/40960 [00:07<01:20, 469.63batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:   8%| | 3280/40960 [00:07<01:20, 469.63batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   8%| | 3372/40960 [00:08<01:20, 466.00batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   8%| | 3372/40960 [00:08<01:20, 466.00batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   8%| | 3468/40960 [00:08<01:19, 468.84batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   8%| | 3468/40960 [00:08<01:19, 468.84batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   9%| | 3563/40960 [00:08<01:19, 470.03batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   9%| | 3563/40960 [00:08<01:19, 470.03batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   9%| | 3655/40960 [00:08<01:20, 465.69batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   9%| | 3655/40960 [00:08<01:20, 465.69batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:   9%| | 3751/40960 [00:08<01:19, 469.66batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:   9%| | 3751/40960 [00:08<01:19, 469.66batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:   9%| | 3847/40960 [00:09<01:18, 471.56batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:   9%| | 3847/40960 [00:09<01:18, 471.56batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  10%| | 3940/40960 [00:09<01:18, 469.30batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  10%| | 3940/40960 [00:09<01:18, 469.30batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  10%| | 4034/40960 [00:09<01:18, 468.98batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  10%| | 4034/40960 [00:09<01:18, 468.98batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  10%| | 4121/40960 [00:09<01:20, 458.70batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  10%| | 4121/40960 [00:09<01:20, 458.70batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  10%| | 4215/40960 [00:09<01:19, 461.26batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  10%| | 4215/40960 [00:09<01:19, 461.26batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  11%| | 4309/40960 [00:10<01:19, 463.60batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  11%| | 4309/40960 [00:10<01:19, 463.60batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  11%| | 4403/40960 [00:10<01:18, 465.21batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  11%| | 4403/40960 [00:10<01:18, 465.21batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  11%| | 4497/40960 [00:10<01:18, 465.70batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  11%| | 4497/40960 [00:10<01:18, 465.70batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  11%| | 4585/40960 [00:10<01:19, 456.76batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  11%| | 4585/40960 [00:10<01:19, 456.76batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  11%| | 4673/40960 [00:10<01:20, 451.61batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  11%| | 4673/40960 [00:10<01:20, 451.61batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  12%| | 4761/40960 [00:11<01:20, 447.31batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  12%| | 4761/40960 [00:11<01:20, 447.31batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  12%| | 4848/40960 [00:11<01:21, 443.38batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  12%| | 4848/40960 [00:11<01:21, 443.38batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  12%| | 4935/40960 [00:11<01:21, 439.96batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  12%| | 4935/40960 [00:11<01:21, 439.96batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  12%| | 5023/40960 [00:11<01:21, 439.07batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  12%| | 5023/40960 [00:11<01:21, 439.07batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  12%| | 5109/40960 [00:11<01:22, 435.39batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  12%| | 5109/40960 [00:11<01:22, 435.39batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5199/40960 [00:12<01:21, 438.41batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5199/40960 [00:12<01:21, 438.41batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5288/40960 [00:12<01:21, 440.21batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5288/40960 [00:12<01:21, 440.21batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5381/40960 [00:12<01:19, 446.84batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5381/40960 [00:12<01:19, 446.84batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5472/40960 [00:12<01:19, 448.90batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5472/40960 [00:12<01:19, 448.90batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5564/40960 [00:12<01:18, 451.48batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5564/40960 [00:12<01:18, 451.48batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5658/40960 [00:13<01:17, 456.73batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5658/40960 [00:13<01:17, 456.73batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5750/40960 [00:13<01:17, 457.17batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5750/40960 [00:13<01:17, 457.17batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5840/40960 [00:13<01:17, 454.40batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5840/40960 [00:13<01:17, 454.40batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5928/40960 [00:13<01:18, 448.98batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5928/40960 [00:13<01:18, 448.98batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6021/40960 [00:13<01:17, 452.73batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6021/40960 [00:14<01:17, 452.73batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 6115/40960 [00:14<01:16, 456.66batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6115/40960 [00:14<01:16, 456.66batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6207/40960 [00:14<01:16, 457.15batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6207/40960 [00:14<01:16, 457.15batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6300/40960 [00:14<01:15, 459.25batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6300/40960 [00:14<01:15, 459.25batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6381/40960 [00:14<01:18, 442.44batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6381/40960 [00:14<01:18, 442.44batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6464/40960 [00:15<01:19, 434.08batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6464/40960 [00:15<01:19, 434.08batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6552/40960 [00:15<01:18, 435.65batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6552/40960 [00:15<01:18, 435.65batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6642/40960 [00:15<01:18, 438.94batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6642/40960 [00:15<01:18, 438.94batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6735/40960 [00:15<01:16, 446.52batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6735/40960 [00:15<01:16, 446.52batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6824/40960 [00:15<01:16, 446.04batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6824/40960 [00:15<01:16, 446.04batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6910/40960 [00:16<01:17, 440.89batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6910/40960 [00:16<01:17, 440.89batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7001/40960 [00:16<01:16, 444.53batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7001/40960 [00:16<01:16, 444.53batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7094/40960 [00:16<01:15, 450.03batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7094/40960 [00:16<01:15, 450.03batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7181/40960 [00:16<01:15, 444.84batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7181/40960 [00:16<01:15, 444.84batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7268/40960 [00:16<01:16, 440.47batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7268/40960 [00:16<01:16, 440.47batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7363/40960 [00:17<01:14, 450.48batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7363/40960 [00:17<01:14, 450.48batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7454/40960 [00:17<01:14, 451.51batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7454/40960 [00:17<01:14, 451.51batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7541/40960 [00:17<01:15, 445.39batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7541/40960 [00:17<01:15, 445.39batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7627/40960 [00:17<01:15, 439.99batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7627/40960 [00:17<01:15, 439.99batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7719/40960 [00:17<01:14, 444.92batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7719/40960 [00:17<01:14, 444.92batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7813/40960 [00:18<01:13, 451.61batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7813/40960 [00:18<01:13, 451.61batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7907/40960 [00:18<01:12, 455.37batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7907/40960 [00:18<01:12, 455.37batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7986/40960 [00:18<01:15, 435.72batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7986/40960 [00:18<01:15, 435.72batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8062/40960 [00:18<01:18, 418.71batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8062/40960 [00:18<01:18, 418.71batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8149/40960 [00:18<01:17, 423.45batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8149/40960 [00:18<01:17, 423.45batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8234/40960 [00:19<01:17, 422.91batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8234/40960 [00:19<01:17, 422.91batches/s, l2_loss: 0.0060 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8320/40960 [00:19<01:16, 424.13batches/s, l2_loss: 0.0060 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8320/40960 [00:19<01:16, 424.13batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8402/40960 [00:19<01:17, 418.73batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8402/40960 [00:19<01:17, 418.73batches/s, l2_loss: 0.0098 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8481/40960 [00:19<01:19, 410.57batches/s, l2_loss: 0.0098 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8481/40960 [00:19<01:19, 410.57batches/s, l2_loss: 0.0098 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8566/40960 [00:19<01:18, 413.53batches/s, l2_loss: 0.0098 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8566/40960 [00:19<01:18, 413.53batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8651/40960 [00:20<01:17, 416.80batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8651/40960 [00:20<01:17, 416.80batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8738/40960 [00:20<01:16, 421.21batches/s, l2_loss: 0.0092 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8738/40960 [00:20<01:16, 421.21batches/s, l2_loss: 0.0085 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8822/40960 [00:20<01:16, 419.99batches/s, l2_loss: 0.0085 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8822/40960 [00:20<01:16, 419.99batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8898/40960 [00:20<01:18, 407.11batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8898/40960 [00:20<01:18, 407.11batches/s, l2_loss: 0.0085 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8979/40960 [00:20<01:18, 405.27batches/s, l2_loss: 0.0085 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8979/40960 [00:20<01:18, 405.27batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9065/40960 [00:21<01:17, 412.00batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9065/40960 [00:21<01:17, 412.00batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9151/40960 [00:21<01:16, 416.79batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9151/40960 [00:21<01:16, 416.79batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9237/40960 [00:21<01:15, 419.92batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9237/40960 [00:21<01:15, 419.92batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9321/40960 [00:21<01:15, 419.90batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9321/40960 [00:21<01:15, 419.90batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9404/40960 [00:21<01:15, 417.49batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9404/40960 [00:21<01:15, 417.49batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9487/40960 [00:22<01:15, 416.64batches/s, l2_loss: 0.0089 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9487/40960 [00:22<01:15, 416.64batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9571/40960 [00:22<01:15, 416.19batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9571/40960 [00:22<01:15, 416.19batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9654/40960 [00:22<01:15, 414.58batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9654/40960 [00:22<01:15, 414.58batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9726/40960 [00:22<01:18, 397.44batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9726/40960 [00:22<01:18, 397.44batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9803/40960 [00:22<01:19, 392.37batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9803/40960 [00:22<01:19, 392.37batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9886/40960 [00:23<01:17, 398.70batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|▏| 9886/40960 [00:23<01:17, 398.70batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9969/40960 [00:23<01:16, 403.47batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9969/40960 [00:23<01:16, 403.47batches/s, l2_loss: 0.0087 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10055/40960 [00:23<01:15, 410.60batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  25%|▏| 10055/40960 [00:23<01:15, 410.60batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  25%|▏| 10136/40960 [00:23<01:15, 407.82batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  25%|▏| 10136/40960 [00:23<01:15, 407.82batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  25%|▏| 10219/40960 [00:23<01:14, 409.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  25%|▏| 10219/40960 [00:23<01:14, 409.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  25%|▎| 10297/40960 [00:24<01:16, 402.76batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  25%|▎| 10297/40960 [00:24<01:16, 402.76batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  25%|▎| 10376/40960 [00:24<01:16, 400.34batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  25%|▎| 10376/40960 [00:24<01:16, 400.34batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  26%|▎| 10459/40960 [00:24<01:15, 403.65batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  26%|▎| 10459/40960 [00:24<01:15, 403.65batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  26%|▎| 10544/40960 [00:24<01:14, 409.64batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  26%|▎| 10544/40960 [00:24<01:14, 409.64batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  26%|▎| 10630/40960 [00:24<01:13, 415.00batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  26%|▎| 10630/40960 [00:24<01:13, 415.00batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  26%|▎| 10715/40960 [00:25<01:12, 417.42batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  26%|▎| 10715/40960 [00:25<01:12, 417.42batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  26%|▎| 10801/40960 [00:25<01:11, 421.06batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  26%|▎| 10801/40960 [00:25<01:11, 421.06batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  27%|▎| 10885/40960 [00:25<01:11, 420.55batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  27%|▎| 10885/40960 [00:25<01:11, 420.55batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  27%|▎| 10970/40960 [00:25<01:11, 421.51batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  27%|▎| 10970/40960 [00:25<01:11, 421.51batches/s, l2_loss: 0.0088 - round_los\u001b[A\n",
      "Training:  27%|▎| 11057/40960 [00:25<01:10, 424.70batches/s, l2_loss: 0.0088 - round_los\u001b[A\n",
      "Training:  27%|▎| 11057/40960 [00:25<01:10, 424.70batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  27%|▎| 11143/40960 [00:26<01:10, 425.11batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  27%|▎| 11143/40960 [00:26<01:10, 425.11batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  27%|▎| 11226/40960 [00:26<01:10, 421.75batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  27%|▎| 11226/40960 [00:26<01:10, 421.75batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  28%|▎| 11314/40960 [00:26<01:09, 425.80batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  28%|▎| 11314/40960 [00:26<01:09, 425.80batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  28%|▎| 11398/40960 [00:26<01:09, 423.52batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  28%|▎| 11398/40960 [00:26<01:09, 423.52batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  28%|▎| 11483/40960 [00:26<01:09, 423.63batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  28%|▎| 11483/40960 [00:26<01:09, 423.63batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  28%|▎| 11565/40960 [00:27<01:10, 418.24batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  28%|▎| 11565/40960 [00:27<01:10, 418.24batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  28%|▎| 11649/40960 [00:27<01:10, 418.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  28%|▎| 11649/40960 [00:27<01:10, 418.47batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  29%|▎| 11733/40960 [00:27<01:09, 417.65batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  29%|▎| 11733/40960 [00:27<01:09, 417.65batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  29%|▎| 11817/40960 [00:27<01:09, 417.86batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  29%|▎| 11817/40960 [00:27<01:09, 417.86batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  29%|▎| 11903/40960 [00:27<01:09, 420.99batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  29%|▎| 11903/40960 [00:27<01:09, 420.99batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  29%|▎| 11987/40960 [00:28<01:09, 419.62batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  29%|▎| 11987/40960 [00:28<01:09, 419.62batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  29%|▎| 12070/40960 [00:28<01:09, 417.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  29%|▎| 12070/40960 [00:28<01:09, 417.89batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  30%|▎| 12154/40960 [00:28<01:09, 417.23batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  30%|▎| 12154/40960 [00:28<01:09, 417.23batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  30%|▎| 12241/40960 [00:28<01:08, 421.96batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  30%|▎| 12241/40960 [00:28<01:08, 421.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  30%|▎| 12323/40960 [00:28<01:08, 417.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  30%|▎| 12323/40960 [00:28<01:08, 417.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  30%|▎| 12408/40960 [00:29<01:07, 420.01batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  30%|▎| 12408/40960 [00:29<01:07, 420.01batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  30%|▎| 12490/40960 [00:29<01:08, 416.22batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  30%|▎| 12490/40960 [00:29<01:08, 416.22batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  31%|▎| 12572/40960 [00:29<01:08, 414.25batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  31%|▎| 12572/40960 [00:29<01:08, 414.25batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  31%|▎| 12660/40960 [00:29<01:07, 420.62batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  31%|▎| 12660/40960 [00:29<01:07, 420.62batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  31%|▎| 12746/40960 [00:29<01:06, 422.84batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  31%|▎| 12746/40960 [00:29<01:06, 422.84batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  31%|▎| 12831/40960 [00:30<01:06, 422.83batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  31%|▎| 12831/40960 [00:30<01:06, 422.83batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 12918/40960 [00:30<01:05, 425.73batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 12918/40960 [00:30<01:05, 425.73batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 13006/40960 [00:30<01:05, 428.68batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 13006/40960 [00:30<01:05, 428.68batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 13091/40960 [00:30<01:05, 427.22batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 13091/40960 [00:30<01:05, 427.22batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 13175/40960 [00:30<01:05, 424.41batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 13175/40960 [00:30<01:05, 424.41batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 13261/40960 [00:31<01:05, 425.19batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  32%|▎| 13261/40960 [00:31<01:05, 425.19batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  33%|▎| 13345/40960 [00:31<01:05, 422.78batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  33%|▎| 13345/40960 [00:31<01:05, 422.78batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  33%|▎| 13433/40960 [00:31<01:04, 427.22batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  33%|▎| 13433/40960 [00:31<01:04, 427.22batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  33%|▎| 13516/40960 [00:31<01:04, 423.15batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  33%|▎| 13516/40960 [00:31<01:04, 423.15batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  33%|▎| 13600/40960 [00:31<01:04, 421.17batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  33%|▎| 13600/40960 [00:31<01:04, 421.17batches/s, l2_loss: 0.0087 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|▎| 13683/40960 [00:32<01:05, 419.32batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  33%|▎| 13683/40960 [00:32<01:05, 419.32batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  34%|▎| 13768/40960 [00:32<01:04, 420.50batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  34%|▎| 13768/40960 [00:32<01:04, 420.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  34%|▎| 13852/40960 [00:32<01:04, 419.67batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  34%|▎| 13852/40960 [00:32<01:04, 419.67batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  34%|▎| 13937/40960 [00:32<01:04, 420.71batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  34%|▎| 13937/40960 [00:32<01:04, 420.71batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  34%|▎| 14019/40960 [00:32<01:04, 417.08batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  34%|▎| 14019/40960 [00:32<01:04, 417.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  34%|▎| 14104/40960 [00:33<01:04, 418.09batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  34%|▎| 14104/40960 [00:33<01:04, 418.09batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  35%|▎| 14191/40960 [00:33<01:03, 422.39batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  35%|▎| 14191/40960 [00:33<01:03, 422.39batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  35%|▎| 14276/40960 [00:33<01:03, 422.93batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  35%|▎| 14276/40960 [00:33<01:03, 422.93batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  35%|▎| 14363/40960 [00:33<01:02, 425.26batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  35%|▎| 14363/40960 [00:33<01:02, 425.26batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  35%|▎| 14447/40960 [00:33<01:02, 423.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  35%|▎| 14447/40960 [00:33<01:02, 423.37batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  35%|▎| 14529/40960 [00:34<01:03, 418.70batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  35%|▎| 14529/40960 [00:34<01:03, 418.70batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14611/40960 [00:34<01:03, 415.66batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14611/40960 [00:34<01:03, 415.66batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14697/40960 [00:34<01:02, 418.68batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14697/40960 [00:34<01:02, 418.68batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14779/40960 [00:34<01:03, 415.11batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14779/40960 [00:34<01:03, 415.11batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14859/40960 [00:34<01:03, 409.80batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14859/40960 [00:34<01:03, 409.80batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14942/40960 [00:35<01:03, 411.05batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  36%|▎| 14942/40960 [00:35<01:03, 411.05batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  37%|▎| 15025/40960 [00:35<01:02, 412.16batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  37%|▎| 15025/40960 [00:35<01:02, 412.16batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  37%|▎| 15110/40960 [00:35<01:02, 415.13batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  37%|▎| 15110/40960 [00:35<01:02, 415.13batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  37%|▎| 15196/40960 [00:35<01:01, 418.56batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  37%|▎| 15196/40960 [00:35<01:01, 418.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  37%|▎| 15283/40960 [00:35<01:00, 422.22batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  37%|▎| 15283/40960 [00:35<01:00, 422.22batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  38%|▍| 15368/40960 [00:36<01:00, 422.58batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  38%|▍| 15368/40960 [00:36<01:00, 422.58batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  38%|▍| 15452/40960 [00:36<01:00, 421.55batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  38%|▍| 15452/40960 [00:36<01:00, 421.55batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  38%|▍| 15538/40960 [00:36<01:00, 423.29batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  38%|▍| 15538/40960 [00:36<01:00, 423.29batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  38%|▍| 15623/40960 [00:36<00:59, 423.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  38%|▍| 15623/40960 [00:36<00:59, 423.00batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  38%|▍| 15706/40960 [00:36<01:00, 420.42batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  38%|▍| 15706/40960 [00:36<01:00, 420.42batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  39%|▍| 15791/40960 [00:37<00:59, 421.01batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  39%|▍| 15791/40960 [00:37<00:59, 421.01batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  39%|▍| 15877/40960 [00:37<00:59, 423.03batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  39%|▍| 15877/40960 [00:37<00:59, 423.03batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  39%|▍| 15961/40960 [00:37<00:59, 421.74batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  39%|▍| 15961/40960 [00:37<00:59, 421.74batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  39%|▍| 16048/40960 [00:37<00:58, 424.41batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  39%|▍| 16048/40960 [00:37<00:58, 424.41batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  39%|▍| 16135/40960 [00:37<00:58, 427.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  39%|▍| 16135/40960 [00:37<00:58, 427.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  40%|▍| 16219/40960 [00:38<00:58, 424.67batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  40%|▍| 16219/40960 [00:38<00:58, 424.67batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  40%|▍| 16304/40960 [00:38<00:58, 423.51batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  40%|▍| 16304/40960 [00:38<00:58, 423.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  40%|▍| 16386/40960 [00:38<00:58, 419.21batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  40%|▍| 16386/40960 [00:38<00:58, 419.21batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  40%|▍| 16471/40960 [00:38<00:58, 420.65batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  40%|▍| 16471/40960 [00:38<00:58, 420.65batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  40%|▍| 16557/40960 [00:38<00:57, 422.31batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  40%|▍| 16557/40960 [00:38<00:57, 422.31batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  41%|▍| 16643/40960 [00:39<00:57, 423.15batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  41%|▍| 16643/40960 [00:39<00:57, 423.15batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  41%|▍| 16728/40960 [00:39<00:57, 423.47batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  41%|▍| 16728/40960 [00:39<00:57, 423.47batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  41%|▍| 16813/40960 [00:39<00:57, 422.56batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  41%|▍| 16813/40960 [00:39<00:57, 422.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  41%|▍| 16899/40960 [00:39<00:56, 424.66batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  41%|▍| 16899/40960 [00:39<00:56, 424.66batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  41%|▍| 16983/40960 [00:39<00:56, 422.53batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  41%|▍| 16983/40960 [00:39<00:56, 422.53batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  42%|▍| 17067/40960 [00:40<00:56, 420.57batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  42%|▍| 17067/40960 [00:40<00:56, 420.57batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  42%|▍| 17151/40960 [00:40<00:56, 420.21batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  42%|▍| 17151/40960 [00:40<00:56, 420.21batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  42%|▍| 17235/40960 [00:40<00:56, 419.55batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  42%|▍| 17235/40960 [00:40<00:56, 419.55batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  42%|▍| 17322/40960 [00:40<00:55, 423.94batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  42%|▍| 17322/40960 [00:40<00:55, 423.94batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  42%|▍| 17407/40960 [00:40<00:55, 423.95batches/s, l2_loss: 0.0087 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|▍| 17407/40960 [00:40<00:55, 423.95batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  43%|▍| 17493/40960 [00:41<00:55, 425.58batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  43%|▍| 17493/40960 [00:41<00:55, 425.58batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  43%|▍| 17581/40960 [00:41<00:54, 429.30batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  43%|▍| 17581/40960 [00:41<00:54, 429.30batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  43%|▍| 17666/40960 [00:41<00:54, 427.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  43%|▍| 17666/40960 [00:41<00:54, 427.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  43%|▍| 17750/40960 [00:41<00:54, 424.35batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  43%|▍| 17750/40960 [00:41<00:54, 424.35batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 17833/40960 [00:41<00:54, 420.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 17833/40960 [00:41<00:54, 420.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 17918/40960 [00:42<00:54, 421.55batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 17918/40960 [00:42<00:54, 421.55batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 18002/40960 [00:42<00:54, 420.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 18002/40960 [00:42<00:54, 420.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 18084/40960 [00:42<00:54, 416.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 18084/40960 [00:42<00:54, 416.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 18169/40960 [00:42<00:54, 418.52batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  44%|▍| 18169/40960 [00:42<00:54, 418.52batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  45%|▍| 18254/40960 [00:42<00:54, 419.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  45%|▍| 18254/40960 [00:42<00:54, 419.40batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  45%|▍| 18338/40960 [00:43<00:54, 418.04batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  45%|▍| 18338/40960 [00:43<00:54, 418.04batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  45%|▍| 18424/40960 [00:43<00:53, 420.12batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  45%|▍| 18424/40960 [00:43<00:53, 420.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  45%|▍| 18509/40960 [00:43<00:53, 421.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  45%|▍| 18509/40960 [00:43<00:53, 421.15batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  45%|▍| 18592/40960 [00:43<00:53, 418.62batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  45%|▍| 18592/40960 [00:43<00:53, 418.62batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  46%|▍| 18675/40960 [00:43<00:53, 417.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  46%|▍| 18675/40960 [00:43<00:53, 417.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  46%|▍| 18759/40960 [00:44<00:53, 418.05batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  46%|▍| 18759/40960 [00:44<00:53, 418.05batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  46%|▍| 18841/40960 [00:44<00:53, 414.92batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  46%|▍| 18841/40960 [00:44<00:53, 414.92batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  46%|▍| 18922/40960 [00:44<00:53, 411.36batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  46%|▍| 18922/40960 [00:44<00:53, 411.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  46%|▍| 19007/40960 [00:44<00:53, 413.74batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  46%|▍| 19007/40960 [00:44<00:53, 413.74batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  47%|▍| 19088/40960 [00:44<00:53, 410.45batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  47%|▍| 19088/40960 [00:44<00:53, 410.45batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  47%|▍| 19176/40960 [00:45<00:51, 419.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  47%|▍| 19176/40960 [00:45<00:51, 419.16batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  47%|▍| 19262/40960 [00:45<00:51, 422.10batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  47%|▍| 19262/40960 [00:45<00:51, 422.10batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  47%|▍| 19348/40960 [00:45<00:50, 424.38batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  47%|▍| 19348/40960 [00:45<00:50, 424.38batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  47%|▍| 19434/40960 [00:45<00:50, 424.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  47%|▍| 19434/40960 [00:45<00:50, 424.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  48%|▍| 19520/40960 [00:45<00:50, 425.18batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  48%|▍| 19520/40960 [00:45<00:50, 425.18batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  48%|▍| 19606/40960 [00:46<00:50, 425.42batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  48%|▍| 19606/40960 [00:46<00:50, 425.42batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  48%|▍| 19692/40960 [00:46<00:49, 425.75batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  48%|▍| 19692/40960 [00:46<00:49, 425.75batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  48%|▍| 19779/40960 [00:46<00:49, 428.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  48%|▍| 19779/40960 [00:46<00:49, 428.12batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  48%|▍| 19863/40960 [00:46<00:49, 424.94batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  48%|▍| 19863/40960 [00:46<00:49, 424.94batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  49%|▍| 19947/40960 [00:46<00:49, 422.75batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  49%|▍| 19947/40960 [00:46<00:49, 422.75batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  49%|▍| 20032/40960 [00:47<00:49, 422.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  49%|▍| 20032/40960 [00:47<00:49, 422.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  49%|▍| 20117/40960 [00:47<00:49, 422.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  49%|▍| 20117/40960 [00:47<00:49, 422.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  49%|▍| 20203/40960 [00:47<00:48, 424.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  49%|▍| 20203/40960 [00:47<00:48, 424.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▍| 20290/40960 [00:47<00:48, 426.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▍| 20290/40960 [00:47<00:48, 426.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▍| 20376/40960 [00:47<00:48, 427.04batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▍| 20376/40960 [00:47<00:48, 427.04batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▍| 20460/40960 [00:48<00:48, 424.11batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▍| 20460/40960 [00:48<00:48, 424.11batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▌| 20544/40960 [00:48<00:48, 422.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▌| 20544/40960 [00:48<00:48, 422.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▌| 20630/40960 [00:48<00:47, 424.32batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  50%|▌| 20630/40960 [00:48<00:47, 424.32batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 20714/40960 [00:48<00:47, 422.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 20714/40960 [00:48<00:47, 422.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 20798/40960 [00:48<00:47, 421.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 20798/40960 [00:48<00:47, 421.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 20884/40960 [00:49<00:47, 422.67batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 20884/40960 [00:49<00:47, 422.67batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 20971/40960 [00:49<00:46, 425.41batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 20971/40960 [00:49<00:46, 425.41batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 21056/40960 [00:49<00:46, 423.86batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  51%|▌| 21056/40960 [00:49<00:46, 423.86batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21137/40960 [00:49<00:47, 417.33batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21137/40960 [00:49<00:47, 417.33batches/s, l2_loss: 0.0086 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21221/40960 [00:49<00:47, 416.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21221/40960 [00:50<00:47, 416.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21305/40960 [00:50<00:47, 416.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21305/40960 [00:50<00:47, 416.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21390/40960 [00:50<00:46, 418.25batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21390/40960 [00:50<00:46, 418.25batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21476/40960 [00:50<00:46, 420.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  52%|▌| 21476/40960 [00:50<00:46, 420.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21563/40960 [00:50<00:45, 423.90batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21563/40960 [00:50<00:45, 423.90batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21646/40960 [00:51<00:45, 421.02batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21646/40960 [00:51<00:45, 421.02batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21732/40960 [00:51<00:45, 422.32batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21732/40960 [00:51<00:45, 422.32batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21818/40960 [00:51<00:45, 424.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21818/40960 [00:51<00:45, 424.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21905/40960 [00:51<00:44, 426.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  53%|▌| 21905/40960 [00:51<00:44, 426.96batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  54%|▌| 21992/40960 [00:51<00:44, 428.30batches/s, l2_loss: 0.0087 - round_los\u001b[A\n",
      "Training:  54%|▌| 21992/40960 [00:51<00:44, 428.30batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  54%|▌| 22075/40960 [00:52<00:44, 423.87batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  54%|▌| 22075/40960 [00:52<00:44, 423.87batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  54%|▌| 22159/40960 [00:52<00:44, 422.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  54%|▌| 22159/40960 [00:52<00:44, 422.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  54%|▌| 22244/40960 [00:52<00:44, 421.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  54%|▌| 22244/40960 [00:52<00:44, 421.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22328/40960 [00:52<00:44, 420.13batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22328/40960 [00:52<00:44, 420.13batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22413/40960 [00:52<00:44, 420.62batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22413/40960 [00:52<00:44, 420.62batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22499/40960 [00:53<00:43, 422.61batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22499/40960 [00:53<00:43, 422.61batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22585/40960 [00:53<00:43, 424.45batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22585/40960 [00:53<00:43, 424.45batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22669/40960 [00:53<00:43, 423.06batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  55%|▌| 22669/40960 [00:53<00:43, 423.06batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 22756/40960 [00:53<00:42, 426.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 22756/40960 [00:53<00:42, 426.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 22842/40960 [00:53<00:42, 427.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 22842/40960 [00:53<00:42, 427.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 22928/40960 [00:54<00:42, 427.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 22928/40960 [00:54<00:42, 427.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 23013/40960 [00:54<00:42, 425.77batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 23013/40960 [00:54<00:42, 425.77batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 23098/40960 [00:54<00:42, 425.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  56%|▌| 23098/40960 [00:54<00:42, 425.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23186/40960 [00:54<00:41, 429.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23186/40960 [00:54<00:41, 429.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23270/40960 [00:54<00:41, 426.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23270/40960 [00:54<00:41, 426.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23352/40960 [00:55<00:41, 420.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23352/40960 [00:55<00:41, 420.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23437/40960 [00:55<00:41, 421.69batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23437/40960 [00:55<00:41, 421.69batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23523/40960 [00:55<00:41, 423.22batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  57%|▌| 23523/40960 [00:55<00:41, 423.22batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23608/40960 [00:55<00:41, 422.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23608/40960 [00:55<00:41, 422.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23692/40960 [00:55<00:41, 420.79batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23692/40960 [00:55<00:41, 420.79batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23776/40960 [00:56<00:40, 419.48batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23776/40960 [00:56<00:40, 419.48batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23864/40960 [00:56<00:40, 424.04batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23864/40960 [00:56<00:40, 424.04batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23950/40960 [00:56<00:40, 424.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  58%|▌| 23950/40960 [00:56<00:40, 424.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24033/40960 [00:56<00:40, 421.26batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24033/40960 [00:56<00:40, 421.26batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24117/40960 [00:56<00:40, 419.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24117/40960 [00:56<00:40, 419.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24202/40960 [00:57<00:39, 420.07batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24202/40960 [00:57<00:39, 420.07batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24286/40960 [00:57<00:39, 420.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24286/40960 [00:57<00:39, 420.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24370/40960 [00:57<00:39, 418.66batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  59%|▌| 24370/40960 [00:57<00:39, 418.66batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  60%|▌| 24458/40960 [00:57<00:38, 424.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  60%|▌| 24458/40960 [00:57<00:38, 424.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  60%|▌| 24544/40960 [00:57<00:38, 425.54batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  60%|▌| 24544/40960 [00:57<00:38, 425.54batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  60%|▌| 24627/40960 [00:58<00:38, 420.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  60%|▌| 24627/40960 [00:58<00:38, 420.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  60%|▌| 24710/40960 [00:58<00:38, 417.63batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  60%|▌| 24710/40960 [00:58<00:38, 417.63batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 24793/40960 [00:58<00:38, 416.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 24793/40960 [00:58<00:38, 416.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 24878/40960 [00:58<00:38, 417.77batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 24878/40960 [00:58<00:38, 417.77batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 24961/40960 [00:58<00:38, 416.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 24961/40960 [00:58<00:38, 416.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 25045/40960 [00:59<00:38, 416.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 25045/40960 [00:59<00:38, 416.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 25127/40960 [00:59<00:38, 414.03batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  61%|▌| 25127/40960 [00:59<00:38, 414.03batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25210/40960 [00:59<00:38, 412.95batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25210/40960 [00:59<00:38, 412.95batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25291/40960 [00:59<00:38, 409.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25291/40960 [00:59<00:38, 409.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25378/40960 [00:59<00:37, 416.54batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25378/40960 [00:59<00:37, 416.54batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25463/40960 [01:00<00:37, 418.76batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25463/40960 [01:00<00:37, 418.76batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25548/40960 [01:00<00:36, 420.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25548/40960 [01:00<00:36, 420.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25633/40960 [01:00<00:36, 420.57batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25633/40960 [01:00<00:36, 420.57batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25715/40960 [01:00<00:36, 416.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25715/40960 [01:00<00:36, 416.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25796/40960 [01:00<00:36, 411.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25796/40960 [01:00<00:36, 411.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25882/40960 [01:01<00:36, 416.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25882/40960 [01:01<00:36, 416.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25966/40960 [01:01<00:35, 416.93batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25966/40960 [01:01<00:35, 416.93batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26049/40960 [01:01<00:35, 415.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26049/40960 [01:01<00:35, 415.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26135/40960 [01:01<00:35, 418.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26135/40960 [01:01<00:35, 418.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26218/40960 [01:01<00:35, 416.48batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26218/40960 [01:01<00:35, 416.48batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26299/40960 [01:02<00:35, 412.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26299/40960 [01:02<00:35, 412.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26383/40960 [01:02<00:35, 414.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  64%|▋| 26383/40960 [01:02<00:35, 414.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26468/40960 [01:02<00:34, 416.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26468/40960 [01:02<00:34, 416.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26554/40960 [01:02<00:34, 418.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26554/40960 [01:02<00:34, 418.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26641/40960 [01:02<00:33, 422.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26641/40960 [01:02<00:33, 422.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26725/40960 [01:03<00:33, 421.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26725/40960 [01:03<00:33, 421.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26808/40960 [01:03<00:33, 419.28batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  65%|▋| 26808/40960 [01:03<00:33, 419.28batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 26893/40960 [01:03<00:33, 420.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 26893/40960 [01:03<00:33, 420.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 26979/40960 [01:03<00:33, 422.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 26979/40960 [01:03<00:33, 422.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 27063/40960 [01:03<00:33, 420.73batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 27063/40960 [01:03<00:33, 420.73batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 27145/40960 [01:04<00:33, 417.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 27145/40960 [01:04<00:33, 417.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 27231/40960 [01:04<00:32, 419.82batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  66%|▋| 27231/40960 [01:04<00:32, 419.82batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  67%|▋| 27316/40960 [01:04<00:32, 420.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  67%|▋| 27316/40960 [01:04<00:32, 420.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  67%|▋| 27401/40960 [01:04<00:32, 421.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  67%|▋| 27401/40960 [01:04<00:32, 421.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  67%|▋| 27484/40960 [01:04<00:32, 419.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  67%|▋| 27484/40960 [01:04<00:32, 419.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  67%|▋| 27566/40960 [01:05<00:32, 415.21batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  67%|▋| 27566/40960 [01:05<00:32, 415.21batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27651/40960 [01:05<00:31, 416.79batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27651/40960 [01:05<00:31, 416.79batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27735/40960 [01:05<00:31, 417.14batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27735/40960 [01:05<00:31, 417.14batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27819/40960 [01:05<00:31, 417.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27819/40960 [01:05<00:31, 417.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27903/40960 [01:05<00:31, 417.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27903/40960 [01:05<00:31, 417.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27987/40960 [01:06<00:31, 417.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  68%|▋| 27987/40960 [01:06<00:31, 417.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28072/40960 [01:06<00:30, 419.09batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28072/40960 [01:06<00:30, 419.09batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28157/40960 [01:06<00:30, 420.35batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28157/40960 [01:06<00:30, 420.35batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28241/40960 [01:06<00:30, 419.09batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28241/40960 [01:06<00:30, 419.09batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28326/40960 [01:06<00:30, 419.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28326/40960 [01:06<00:30, 419.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28413/40960 [01:07<00:29, 423.25batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  69%|▋| 28413/40960 [01:07<00:29, 423.25batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28494/40960 [01:07<00:29, 416.83batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28494/40960 [01:07<00:29, 416.83batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28575/40960 [01:07<00:30, 412.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28575/40960 [01:07<00:30, 412.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28657/40960 [01:07<00:29, 411.32batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28657/40960 [01:07<00:29, 411.32batches/s, l2_loss: 0.0086 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28742/40960 [01:07<00:29, 414.93batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28742/40960 [01:07<00:29, 414.93batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28828/40960 [01:08<00:29, 418.28batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  70%|▋| 28828/40960 [01:08<00:29, 418.28batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 28913/40960 [01:08<00:28, 420.05batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 28913/40960 [01:08<00:28, 420.05batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 28999/40960 [01:08<00:28, 422.84batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 28999/40960 [01:08<00:28, 422.84batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 29084/40960 [01:08<00:28, 423.06batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 29084/40960 [01:08<00:28, 423.06batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 29171/40960 [01:08<00:27, 426.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 29171/40960 [01:08<00:27, 426.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 29255/40960 [01:09<00:27, 423.53batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  71%|▋| 29255/40960 [01:09<00:27, 423.53batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29340/40960 [01:09<00:27, 423.84batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29340/40960 [01:09<00:27, 423.84batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29426/40960 [01:09<00:27, 425.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29426/40960 [01:09<00:27, 425.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29509/40960 [01:09<00:27, 422.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29509/40960 [01:09<00:27, 422.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29595/40960 [01:09<00:26, 424.07batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29595/40960 [01:09<00:26, 424.07batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29680/40960 [01:10<00:26, 423.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  72%|▋| 29680/40960 [01:10<00:26, 423.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  73%|▋| 29767/40960 [01:10<00:26, 426.14batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  73%|▋| 29767/40960 [01:10<00:26, 426.14batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  73%|▋| 29850/40960 [01:10<00:26, 422.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  73%|▋| 29850/40960 [01:10<00:26, 422.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  73%|▋| 29936/40960 [01:10<00:25, 424.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  73%|▋| 29936/40960 [01:10<00:25, 424.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  73%|▋| 30023/40960 [01:10<00:25, 426.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  73%|▋| 30023/40960 [01:10<00:25, 426.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30107/40960 [01:11<00:25, 424.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30107/40960 [01:11<00:25, 424.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30193/40960 [01:11<00:25, 425.41batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30193/40960 [01:11<00:25, 425.41batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30280/40960 [01:11<00:25, 426.98batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30280/40960 [01:11<00:25, 426.98batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30363/40960 [01:11<00:25, 422.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30363/40960 [01:11<00:25, 422.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30443/40960 [01:11<00:25, 415.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  74%|▋| 30443/40960 [01:11<00:25, 415.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▋| 30526/40960 [01:12<00:25, 414.73batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▋| 30526/40960 [01:12<00:25, 414.73batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▋| 30610/40960 [01:12<00:24, 415.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▋| 30610/40960 [01:12<00:24, 415.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▋| 30697/40960 [01:12<00:24, 420.69batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▋| 30697/40960 [01:12<00:24, 420.69batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▊| 30781/40960 [01:12<00:24, 420.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▊| 30781/40960 [01:12<00:24, 420.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▊| 30862/40960 [01:12<00:24, 414.92batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  75%|▊| 30862/40960 [01:12<00:24, 414.92batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 30948/40960 [01:13<00:23, 418.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 30948/40960 [01:13<00:23, 418.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 31034/40960 [01:13<00:23, 421.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 31034/40960 [01:13<00:23, 421.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 31118/40960 [01:13<00:23, 419.77batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 31118/40960 [01:13<00:23, 419.77batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 31200/40960 [01:13<00:23, 416.78batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 31200/40960 [01:13<00:23, 416.78batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 31285/40960 [01:13<00:23, 419.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  76%|▊| 31285/40960 [01:13<00:23, 419.23batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31369/40960 [01:14<00:22, 418.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31369/40960 [01:14<00:22, 418.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31455/40960 [01:14<00:22, 421.03batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31455/40960 [01:14<00:22, 421.03batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31541/40960 [01:14<00:22, 423.25batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31541/40960 [01:14<00:22, 423.25batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31623/40960 [01:14<00:22, 419.11batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31623/40960 [01:14<00:22, 419.11batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31708/40960 [01:14<00:22, 419.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  77%|▊| 31708/40960 [01:14<00:22, 419.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 31794/40960 [01:15<00:21, 421.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 31794/40960 [01:15<00:21, 421.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 31877/40960 [01:15<00:21, 419.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 31877/40960 [01:15<00:21, 419.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 31959/40960 [01:15<00:21, 415.93batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 31959/40960 [01:15<00:21, 415.93batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 32043/40960 [01:15<00:21, 416.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 32043/40960 [01:15<00:21, 416.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 32127/40960 [01:15<00:21, 416.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  78%|▊| 32127/40960 [01:15<00:21, 416.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32209/40960 [01:16<00:21, 413.69batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32209/40960 [01:16<00:21, 413.69batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32292/40960 [01:16<00:20, 413.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32292/40960 [01:16<00:20, 413.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32378/40960 [01:16<00:20, 417.29batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32378/40960 [01:16<00:20, 417.29batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32464/40960 [01:16<00:20, 420.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|▊| 32464/40960 [01:16<00:20, 420.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32551/40960 [01:16<00:19, 423.75batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  79%|▊| 32551/40960 [01:16<00:19, 423.75batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32638/40960 [01:17<00:19, 426.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32638/40960 [01:17<00:19, 426.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32725/40960 [01:17<00:19, 428.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32725/40960 [01:17<00:19, 428.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32813/40960 [01:17<00:18, 431.04batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32813/40960 [01:17<00:18, 431.04batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32901/40960 [01:17<00:18, 432.48batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32901/40960 [01:17<00:18, 432.48batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 32989/40960 [01:17<00:18, 434.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 32989/40960 [01:17<00:18, 434.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 33073/40960 [01:18<00:18, 429.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 33073/40960 [01:18<00:18, 429.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 33157/40960 [01:18<00:18, 426.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 33157/40960 [01:18<00:18, 426.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 33241/40960 [01:18<00:18, 424.61batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 33241/40960 [01:18<00:18, 424.61batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 33326/40960 [01:18<00:18, 423.52batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  81%|▊| 33326/40960 [01:18<00:18, 423.52batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33409/40960 [01:18<00:17, 420.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33409/40960 [01:18<00:17, 420.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33494/40960 [01:19<00:17, 420.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33494/40960 [01:19<00:17, 420.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33578/40960 [01:19<00:17, 419.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33578/40960 [01:19<00:17, 419.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33660/40960 [01:19<00:17, 415.97batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33660/40960 [01:19<00:17, 415.97batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33742/40960 [01:19<00:17, 414.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  82%|▊| 33742/40960 [01:19<00:17, 414.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 33827/40960 [01:19<00:17, 416.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 33827/40960 [01:19<00:17, 416.68batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 33911/40960 [01:20<00:16, 416.97batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 33911/40960 [01:20<00:16, 416.97batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 33995/40960 [01:20<00:16, 417.05batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 33995/40960 [01:20<00:16, 417.05batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 34077/40960 [01:20<00:16, 414.71batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 34077/40960 [01:20<00:16, 414.71batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 34162/40960 [01:20<00:16, 417.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  83%|▊| 34162/40960 [01:20<00:16, 417.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34247/40960 [01:20<00:16, 418.62batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34247/40960 [01:20<00:16, 418.62batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34332/40960 [01:21<00:15, 419.45batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34332/40960 [01:21<00:15, 419.45batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34416/40960 [01:21<00:15, 419.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34416/40960 [01:21<00:15, 419.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34501/40960 [01:21<00:15, 420.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34501/40960 [01:21<00:15, 420.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34587/40960 [01:21<00:15, 423.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  84%|▊| 34587/40960 [01:21<00:15, 423.16batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 34675/40960 [01:21<00:14, 426.87batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 34675/40960 [01:21<00:14, 426.87batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 34761/40960 [01:22<00:14, 427.55batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 34761/40960 [01:22<00:14, 427.55batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 34849/40960 [01:22<00:14, 430.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 34849/40960 [01:22<00:14, 430.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 34933/40960 [01:22<00:14, 427.03batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 34933/40960 [01:22<00:14, 427.03batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 35016/40960 [01:22<00:14, 423.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  85%|▊| 35016/40960 [01:22<00:14, 423.34batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  86%|▊| 35097/40960 [01:22<00:14, 417.04batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  86%|▊| 35097/40960 [01:22<00:14, 417.04batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  86%|▊| 35182/40960 [01:23<00:13, 418.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  86%|▊| 35182/40960 [01:23<00:13, 418.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  86%|▊| 35266/40960 [01:23<00:13, 418.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  86%|▊| 35266/40960 [01:23<00:13, 418.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  86%|▊| 35351/40960 [01:23<00:13, 420.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  86%|▊| 35351/40960 [01:23<00:13, 420.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35434/40960 [01:23<00:13, 417.87batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35434/40960 [01:23<00:13, 417.87batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35516/40960 [01:23<00:13, 413.98batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35516/40960 [01:23<00:13, 413.98batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35597/40960 [01:24<00:13, 410.90batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35597/40960 [01:24<00:13, 410.90batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35680/40960 [01:24<00:12, 411.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35680/40960 [01:24<00:12, 411.15batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35766/40960 [01:24<00:12, 416.28batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  87%|▊| 35766/40960 [01:24<00:12, 416.28batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 35851/40960 [01:24<00:12, 418.11batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 35851/40960 [01:24<00:12, 418.11batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 35937/40960 [01:24<00:11, 420.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 35937/40960 [01:25<00:11, 420.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36023/40960 [01:25<00:11, 422.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36023/40960 [01:25<00:11, 422.64batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36108/40960 [01:25<00:11, 422.26batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36108/40960 [01:25<00:11, 422.26batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36194/40960 [01:25<00:11, 424.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36194/40960 [01:25<00:11, 424.50batches/s, l2_loss: 0.0086 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36280/40960 [01:25<00:11, 425.09batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36280/40960 [01:25<00:11, 425.09batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36365/40960 [01:26<00:10, 424.88batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36365/40960 [01:26<00:10, 424.88batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36451/40960 [01:26<00:10, 425.58batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36451/40960 [01:26<00:10, 425.58batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36532/40960 [01:26<00:10, 418.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36532/40960 [01:26<00:10, 418.60batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36619/40960 [01:26<00:10, 422.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  89%|▉| 36619/40960 [01:26<00:10, 422.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 36703/40960 [01:26<00:10, 421.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 36703/40960 [01:26<00:10, 421.00batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 36790/40960 [01:27<00:09, 424.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 36790/40960 [01:27<00:09, 424.08batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 36875/40960 [01:27<00:09, 423.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 36875/40960 [01:27<00:09, 423.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 36959/40960 [01:27<00:09, 422.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 36959/40960 [01:27<00:09, 422.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 37044/40960 [01:27<00:09, 422.61batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  90%|▉| 37044/40960 [01:27<00:09, 422.61batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37129/40960 [01:27<00:09, 422.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37129/40960 [01:27<00:09, 422.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37214/40960 [01:28<00:08, 422.17batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37214/40960 [01:28<00:08, 422.17batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37299/40960 [01:28<00:08, 422.93batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37299/40960 [01:28<00:08, 422.93batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37378/40960 [01:28<00:08, 413.57batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37378/40960 [01:28<00:08, 413.57batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37453/40960 [01:28<00:08, 401.07batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  91%|▉| 37453/40960 [01:28<00:08, 401.07batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37528/40960 [01:28<00:08, 392.98batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37528/40960 [01:28<00:08, 392.98batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37608/40960 [01:29<00:08, 394.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37608/40960 [01:29<00:08, 394.49batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37691/40960 [01:29<00:08, 399.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37691/40960 [01:29<00:08, 399.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37768/40960 [01:29<00:08, 393.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37768/40960 [01:29<00:08, 393.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37851/40960 [01:29<00:07, 399.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  92%|▉| 37851/40960 [01:29<00:07, 399.31batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 37928/40960 [01:29<00:07, 394.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 37928/40960 [01:29<00:07, 394.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 38009/40960 [01:30<00:07, 396.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 38009/40960 [01:30<00:07, 396.91batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 38090/40960 [01:30<00:07, 398.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 38090/40960 [01:30<00:07, 398.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 38164/40960 [01:30<00:07, 389.33batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 38164/40960 [01:30<00:07, 389.33batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 38243/40960 [01:30<00:06, 389.84batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  93%|▉| 38243/40960 [01:30<00:06, 389.84batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38330/40960 [01:30<00:06, 402.84batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38330/40960 [01:30<00:06, 402.84batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38416/40960 [01:31<00:06, 410.03batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38416/40960 [01:31<00:06, 410.03batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38498/40960 [01:31<00:06, 409.94batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38498/40960 [01:31<00:06, 409.94batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38574/40960 [01:31<00:05, 400.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38574/40960 [01:31<00:05, 400.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38653/40960 [01:31<00:05, 397.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  94%|▉| 38653/40960 [01:31<00:05, 397.85batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 38732/40960 [01:31<00:05, 396.01batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 38732/40960 [01:31<00:05, 396.01batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 38812/40960 [01:32<00:05, 396.53batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 38812/40960 [01:32<00:05, 396.53batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 38893/40960 [01:32<00:05, 398.05batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 38893/40960 [01:32<00:05, 398.05batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 38973/40960 [01:32<00:04, 397.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 38973/40960 [01:32<00:04, 397.43batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 39056/40960 [01:32<00:04, 401.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  95%|▉| 39056/40960 [01:32<00:04, 401.81batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39139/40960 [01:32<00:04, 405.52batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39139/40960 [01:32<00:04, 405.52batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39218/40960 [01:33<00:04, 402.24batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39218/40960 [01:33<00:04, 402.24batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39297/40960 [01:33<00:04, 399.48batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39297/40960 [01:33<00:04, 399.48batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39374/40960 [01:33<00:04, 394.20batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39374/40960 [01:33<00:04, 394.20batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39454/40960 [01:33<00:03, 395.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  96%|▉| 39454/40960 [01:33<00:03, 395.36batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39538/40960 [01:33<00:03, 401.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39538/40960 [01:33<00:03, 401.96batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39623/40960 [01:34<00:03, 408.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39623/40960 [01:34<00:03, 408.37batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39705/40960 [01:34<00:03, 407.98batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39705/40960 [01:34<00:03, 407.98batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39784/40960 [01:34<00:02, 403.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39784/40960 [01:34<00:02, 403.89batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  97%|▉| 39866/40960 [01:34<00:02, 405.44batches/s, l2_loss: 0.0086 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39866/40960 [01:34<00:02, 405.44batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 39948/40960 [01:34<00:02, 405.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 39948/40960 [01:34<00:02, 405.72batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 40032/40960 [01:35<00:02, 409.75batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 40032/40960 [01:35<00:02, 409.75batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [01:35<00:02, 410.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [01:35<00:02, 410.51batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 40196/40960 [01:35<00:01, 407.79batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 40196/40960 [01:35<00:01, 407.79batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 40280/40960 [01:35<00:01, 410.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  98%|▉| 40280/40960 [01:35<00:01, 410.59batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40367/40960 [01:35<00:01, 417.24batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40367/40960 [01:35<00:01, 417.24batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40450/40960 [01:36<00:01, 415.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40450/40960 [01:36<00:01, 415.56batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40534/40960 [01:36<00:01, 416.87batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40534/40960 [01:36<00:01, 416.87batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40620/40960 [01:36<00:00, 419.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40620/40960 [01:36<00:00, 419.40batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40700/40960 [01:36<00:00, 413.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training:  99%|▉| 40700/40960 [01:36<00:00, 413.12batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training: 100%|▉| 40776/40960 [01:36<00:00, 403.13batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training: 100%|▉| 40776/40960 [01:36<00:00, 403.13batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training: 100%|▉| 40857/40960 [01:37<00:00, 402.63batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training: 100%|▉| 40857/40960 [01:37<00:00, 402.63batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training: 100%|▉| 40941/40960 [01:37<00:00, 407.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "Training: 100%|▉| 40941/40960 [01:37<00:00, 407.47batches/s, l2_loss: 0.0086 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 18:56:13.041057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  15%|▏| 4/26 [06:51<37:31, 102.32s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 18:56:14.327680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 18:56:18.669695: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<21:55:19,  1.93s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<21:55:19,  1.93s/batches, l2_loss: 0.0076 - round_loss:\u001b[A\n",
      "Training:   0%| | 74/40960 [00:02<14:20, 47.52batches/s, l2_loss: 0.0076 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 74/40960 [00:02<14:20, 47.52batches/s, l2_loss: 0.0145 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 145/40960 [00:02<07:08, 95.34batches/s, l2_loss: 0.0145 - round_loss: \u001b[A\n",
      "Training:   0%| | 145/40960 [00:02<07:08, 95.34batches/s, l2_loss: 0.0129 - round_loss: \u001b[A\n",
      "Training:   1%| | 219/40960 [00:02<04:40, 145.07batches/s, l2_loss: 0.0129 - round_loss:\u001b[A\n",
      "Training:   1%| | 219/40960 [00:02<04:40, 145.07batches/s, l2_loss: 0.0142 - round_loss:\u001b[A\n",
      "Training:   1%| | 300/40960 [00:02<03:24, 198.42batches/s, l2_loss: 0.0142 - round_loss:\u001b[A\n",
      "Training:   1%| | 300/40960 [00:02<03:24, 198.42batches/s, l2_loss: 0.0140 - round_loss:\u001b[A\n",
      "Training:   1%| | 380/40960 [00:02<02:46, 244.10batches/s, l2_loss: 0.0140 - round_loss:\u001b[A\n",
      "Training:   1%| | 380/40960 [00:02<02:46, 244.10batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   1%| | 461/40960 [00:03<02:23, 283.11batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   1%| | 461/40960 [00:03<02:23, 283.11batches/s, l2_loss: 0.0140 - round_loss:\u001b[A\n",
      "Training:   1%| | 542/40960 [00:03<02:08, 314.50batches/s, l2_loss: 0.0140 - round_loss:\u001b[A\n",
      "Training:   1%| | 542/40960 [00:03<02:08, 314.50batches/s, l2_loss: 0.0138 - round_loss:\u001b[A\n",
      "Training:   2%| | 623/40960 [00:03<01:59, 338.63batches/s, l2_loss: 0.0138 - round_loss:\u001b[A\n",
      "Training:   2%| | 623/40960 [00:03<01:59, 338.63batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 702/40960 [00:03<01:53, 353.30batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 702/40960 [00:03<01:53, 353.30batches/s, l2_loss: 0.0135 - round_loss:\u001b[A\n",
      "Training:   2%| | 783/40960 [00:03<01:49, 366.99batches/s, l2_loss: 0.0135 - round_loss:\u001b[A\n",
      "Training:   2%| | 783/40960 [00:03<01:49, 366.99batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 861/40960 [00:04<01:47, 372.55batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 861/40960 [00:04<01:47, 372.55batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   2%| | 941/40960 [00:04<01:45, 379.20batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   2%| | 941/40960 [00:04<01:45, 379.20batches/s, l2_loss: 0.0133 - round_loss:\u001b[A\n",
      "Training:   2%| | 1021/40960 [00:04<01:43, 385.26batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   2%| | 1021/40960 [00:04<01:43, 385.26batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   3%| | 1102/40960 [00:04<01:42, 390.43batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   3%| | 1102/40960 [00:04<01:42, 390.43batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   3%| | 1183/40960 [00:04<01:41, 393.57batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   3%| | 1183/40960 [00:04<01:41, 393.57batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   3%| | 1261/40960 [00:05<01:41, 391.37batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   3%| | 1261/40960 [00:05<01:41, 391.37batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   3%| | 1339/40960 [00:05<01:41, 390.95batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   3%| | 1339/40960 [00:05<01:41, 390.95batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   3%| | 1419/40960 [00:05<01:40, 392.79batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   3%| | 1419/40960 [00:05<01:40, 392.79batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   4%| | 1499/40960 [00:05<01:40, 394.59batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   4%| | 1499/40960 [00:05<01:40, 394.59batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   4%| | 1581/40960 [00:05<01:38, 398.12batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   4%| | 1581/40960 [00:05<01:38, 398.12batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   4%| | 1661/40960 [00:06<01:38, 397.35batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   4%| | 1661/40960 [00:06<01:38, 397.35batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   4%| | 1739/40960 [00:06<01:39, 394.30batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   4%| | 1739/40960 [00:06<01:39, 394.30batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   4%| | 1816/40960 [00:06<01:40, 390.82batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   4%| | 1816/40960 [00:06<01:40, 390.82batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   5%| | 1893/40960 [00:06<01:40, 388.36batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 1893/40960 [00:06<01:40, 388.36batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   5%| | 1969/40960 [00:06<01:41, 385.19batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   5%| | 1969/40960 [00:06<01:41, 385.19batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   5%| | 2052/40960 [00:07<01:38, 393.19batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   5%| | 2052/40960 [00:07<01:38, 393.19batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   5%| | 2124/40960 [00:07<01:41, 382.40batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   5%| | 2124/40960 [00:07<01:41, 382.40batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   5%| | 2198/40960 [00:07<01:42, 378.05batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   5%| | 2198/40960 [00:07<01:42, 378.05batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   6%| | 2280/40960 [00:07<01:39, 387.12batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   6%| | 2280/40960 [00:07<01:39, 387.12batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   6%| | 2362/40960 [00:07<01:38, 393.36batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   6%| | 2362/40960 [00:07<01:38, 393.36batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   6%| | 2444/40960 [00:08<01:36, 397.90batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   6%| | 2444/40960 [00:08<01:36, 397.90batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   6%| | 2521/40960 [00:08<01:37, 392.65batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   6%| | 2521/40960 [00:08<01:37, 392.65batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   6%| | 2605/40960 [00:08<01:35, 399.91batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   6%| | 2605/40960 [00:08<01:35, 399.91batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2686/40960 [00:08<01:35, 401.01batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2686/40960 [00:08<01:35, 401.01batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2767/40960 [00:08<01:35, 401.54batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2767/40960 [00:08<01:35, 401.54batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2846/40960 [00:09<01:35, 399.17batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2846/40960 [00:09<01:35, 399.17batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2928/40960 [00:09<01:34, 400.61batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   7%| | 2928/40960 [00:09<01:34, 400.61batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   7%| | 3009/40960 [00:09<01:34, 401.46batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   7%| | 3009/40960 [00:09<01:34, 401.46batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3090/40960 [00:09<01:34, 401.96batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3090/40960 [00:09<01:34, 401.96batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   8%| | 3170/40960 [00:09<01:34, 400.55batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   8%| | 3170/40960 [00:09<01:34, 400.55batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3251/40960 [00:10<01:33, 401.83batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3251/40960 [00:10<01:33, 401.83batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   8%| | 3328/40960 [00:10<01:35, 395.60batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   8%| | 3328/40960 [00:10<01:35, 395.60batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3409/40960 [00:10<01:34, 397.44batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   8%| | 3409/40960 [00:10<01:34, 397.44batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3490/40960 [00:10<01:34, 398.54batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3490/40960 [00:10<01:34, 398.54batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3572/40960 [00:10<01:33, 401.31batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3572/40960 [00:10<01:33, 401.31batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3656/40960 [00:11<01:31, 406.19batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3656/40960 [00:11<01:31, 406.19batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3739/40960 [00:11<01:31, 408.35batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3739/40960 [00:11<01:31, 408.35batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3813/40960 [00:11<01:33, 396.45batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   9%| | 3813/40960 [00:11<01:33, 396.45batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 3894/40960 [00:11<01:33, 398.46batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 3894/40960 [00:11<01:33, 398.46batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 3978/40960 [00:11<01:31, 404.89batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 3978/40960 [00:11<01:31, 404.89batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4050/40960 [00:12<01:34, 389.07batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4050/40960 [00:12<01:34, 389.07batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  10%| | 4098/40960 [00:12<01:47, 344.37batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  10%| | 4098/40960 [00:12<01:47, 344.37batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4164/40960 [00:12<01:48, 339.61batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4164/40960 [00:12<01:48, 339.61batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4214/40960 [00:12<01:57, 312.32batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4214/40960 [00:12<01:57, 312.32batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4266/40960 [00:12<02:04, 295.37batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  10%| | 4266/40960 [00:13<02:04, 295.37batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4318/40960 [00:13<02:09, 283.70batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4318/40960 [00:13<02:09, 283.70batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4383/40960 [00:13<02:03, 295.06batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4383/40960 [00:13<02:03, 295.06batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  11%| | 4464/40960 [00:13<01:51, 326.88batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  11%| | 4464/40960 [00:13<01:51, 326.88batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  11%| | 4548/40960 [00:13<01:43, 353.49batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  11%| | 4548/40960 [00:13<01:43, 353.49batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4627/40960 [00:14<01:39, 365.47batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  11%| | 4627/40960 [00:14<01:39, 365.47batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  11%| | 4706/40960 [00:14<01:37, 373.45batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  11%| | 4706/40960 [00:14<01:37, 373.45batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 4786/40960 [00:14<01:35, 380.75batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 4786/40960 [00:14<01:35, 380.75batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  12%| | 4867/40960 [00:14<01:33, 387.47batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  12%| | 4867/40960 [00:14<01:33, 387.47batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  12%| | 4948/40960 [00:14<01:31, 391.76batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  12%| | 4948/40960 [00:14<01:31, 391.76batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  12%| | 5032/40960 [00:15<01:29, 399.29batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  12%| | 5032/40960 [00:15<01:29, 399.29batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 5114/40960 [00:15<01:29, 402.33batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  12%| | 5114/40960 [00:15<01:29, 402.33batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5194/40960 [00:15<01:29, 401.27batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5194/40960 [00:15<01:29, 401.27batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5273/40960 [00:15<01:29, 398.22batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5273/40960 [00:15<01:29, 398.22batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|▏| 5354/40960 [00:15<01:29, 399.38batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5354/40960 [00:15<01:29, 399.38batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5434/40960 [00:16<01:29, 398.86batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5434/40960 [00:16<01:29, 398.86batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5518/40960 [00:16<01:27, 403.66batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5518/40960 [00:16<01:27, 403.66batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5599/40960 [00:16<01:27, 402.94batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5599/40960 [00:16<01:27, 402.94batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5677/40960 [00:16<01:28, 399.06batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5677/40960 [00:16<01:28, 399.06batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5732/40960 [00:16<01:37, 360.56batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5732/40960 [00:16<01:37, 360.56batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5804/40960 [00:17<01:37, 359.86batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5804/40960 [00:17<01:37, 359.86batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5873/40960 [00:17<01:38, 355.32batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5873/40960 [00:17<01:38, 355.32batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5957/40960 [00:17<01:33, 373.33batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5957/40960 [00:17<01:33, 373.33batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6040/40960 [00:17<01:30, 385.33batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6040/40960 [00:17<01:30, 385.33batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6123/40960 [00:17<01:28, 393.46batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6123/40960 [00:17<01:28, 393.46batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6206/40960 [00:18<01:27, 398.84batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6206/40960 [00:18<01:27, 398.84batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6287/40960 [00:18<01:26, 400.14batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6287/40960 [00:18<01:26, 400.14batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6369/40960 [00:18<01:25, 402.47batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6369/40960 [00:18<01:25, 402.47batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6454/40960 [00:18<01:24, 408.03batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6454/40960 [00:18<01:24, 408.03batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6538/40960 [00:18<01:23, 410.19batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6538/40960 [00:18<01:23, 410.19batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6621/40960 [00:19<01:23, 411.45batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6621/40960 [00:19<01:23, 411.45batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6703/40960 [00:19<01:23, 410.06batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6703/40960 [00:19<01:23, 410.06batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6786/40960 [00:19<01:23, 410.38batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6786/40960 [00:19<01:23, 410.38batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6868/40960 [00:19<01:23, 410.16batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6868/40960 [00:19<01:23, 410.16batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6952/40960 [00:19<01:22, 412.48batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6952/40960 [00:19<01:22, 412.48batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7033/40960 [00:20<01:22, 408.88batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7033/40960 [00:20<01:22, 408.88batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7114/40960 [00:20<01:23, 406.42batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7114/40960 [00:20<01:23, 406.42batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7196/40960 [00:20<01:23, 405.84batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7196/40960 [00:20<01:23, 405.84batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7278/40960 [00:20<01:22, 406.06batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7278/40960 [00:20<01:22, 406.06batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7349/40960 [00:20<01:26, 389.78batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7349/40960 [00:20<01:26, 389.78batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7416/40960 [00:21<01:30, 372.30batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7416/40960 [00:21<01:30, 372.30batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7487/40960 [00:21<01:31, 365.82batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7487/40960 [00:21<01:31, 365.82batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7564/40960 [00:21<01:30, 370.85batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7564/40960 [00:21<01:30, 370.85batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7645/40960 [00:21<01:27, 380.96batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7645/40960 [00:21<01:27, 380.96batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7725/40960 [00:21<01:26, 385.29batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7725/40960 [00:21<01:26, 385.29batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7789/40960 [00:22<01:30, 364.62batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7789/40960 [00:22<01:30, 364.62batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7852/40960 [00:22<01:34, 348.95batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7852/40960 [00:22<01:34, 348.95batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7915/40960 [00:22<01:37, 338.57batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7915/40960 [00:22<01:37, 338.57batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7994/40960 [00:22<01:32, 354.80batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7994/40960 [00:22<01:32, 354.80batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8075/40960 [00:22<01:29, 368.58batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8075/40960 [00:22<01:29, 368.58batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8155/40960 [00:23<01:27, 376.96batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8155/40960 [00:23<01:27, 376.96batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8230/40960 [00:23<01:27, 375.44batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8230/40960 [00:23<01:27, 375.44batches/s, l2_loss: 0.0160 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8301/40960 [00:23<01:28, 368.70batches/s, l2_loss: 0.0160 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8301/40960 [00:23<01:28, 368.70batches/s, l2_loss: 0.0137 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8375/40960 [00:23<01:28, 369.06batches/s, l2_loss: 0.0137 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8375/40960 [00:23<01:28, 369.06batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8450/40960 [00:23<01:27, 370.69batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8450/40960 [00:23<01:27, 370.69batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8526/40960 [00:24<01:27, 372.75batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8526/40960 [00:24<01:27, 372.75batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8599/40960 [00:24<01:27, 370.18batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8599/40960 [00:24<01:27, 370.18batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8675/40960 [00:24<01:26, 372.15batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8675/40960 [00:24<01:26, 372.15batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8751/40960 [00:24<01:26, 373.55batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|▏| 8751/40960 [00:24<01:26, 373.55batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8825/40960 [00:24<01:26, 371.86batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8825/40960 [00:24<01:26, 371.86batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8899/40960 [00:25<01:26, 370.79batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8899/40960 [00:25<01:26, 370.79batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8976/40960 [00:25<01:25, 374.67batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8976/40960 [00:25<01:25, 374.67batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9052/40960 [00:25<01:25, 374.69batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9052/40960 [00:25<01:25, 374.69batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9125/40960 [00:25<01:25, 371.77batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9125/40960 [00:25<01:25, 371.77batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9194/40960 [00:25<01:27, 363.05batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9194/40960 [00:25<01:27, 363.05batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9267/40960 [00:26<01:27, 362.27batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9267/40960 [00:26<01:27, 362.27batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9343/40960 [00:26<01:26, 366.89batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9343/40960 [00:26<01:26, 366.89batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9417/40960 [00:26<01:25, 367.68batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9417/40960 [00:26<01:25, 367.68batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9490/40960 [00:26<01:26, 365.56batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9490/40960 [00:26<01:26, 365.56batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9565/40960 [00:26<01:25, 368.13batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9565/40960 [00:26<01:25, 368.13batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9638/40960 [00:27<01:25, 366.93batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9638/40960 [00:27<01:25, 366.93batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9712/40960 [00:27<01:25, 367.00batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9712/40960 [00:27<01:25, 367.00batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9780/40960 [00:27<01:27, 358.27batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9780/40960 [00:27<01:27, 358.27batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9851/40960 [00:27<01:27, 355.67batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9851/40960 [00:27<01:27, 355.67batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9924/40960 [00:27<01:26, 358.16batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9924/40960 [00:27<01:26, 358.16batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9998/40960 [00:28<01:25, 361.08batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9998/40960 [00:28<01:25, 361.08batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10070/40960 [00:28<01:25, 359.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  25%|▏| 10070/40960 [00:28<01:25, 359.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  25%|▏| 10144/40960 [00:28<01:25, 361.45batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  25%|▏| 10144/40960 [00:28<01:25, 361.45batches/s, l2_loss: 0.0131 - round_los\u001b[A\n",
      "Training:  25%|▏| 10220/40960 [00:28<01:24, 365.74batches/s, l2_loss: 0.0131 - round_los\u001b[A\n",
      "Training:  25%|▏| 10220/40960 [00:28<01:24, 365.74batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  25%|▎| 10289/40960 [00:28<01:25, 358.76batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  25%|▎| 10289/40960 [00:28<01:25, 358.76batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  25%|▎| 10353/40960 [00:29<01:28, 346.00batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  25%|▎| 10353/40960 [00:29<01:28, 346.00batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  25%|▎| 10416/40960 [00:29<01:30, 335.77batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  25%|▎| 10416/40960 [00:29<01:30, 335.77batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  26%|▎| 10484/40960 [00:29<01:30, 336.80batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  26%|▎| 10484/40960 [00:29<01:30, 336.80batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  26%|▎| 10554/40960 [00:29<01:29, 339.62batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  26%|▎| 10554/40960 [00:29<01:29, 339.62batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  26%|▎| 10625/40960 [00:29<01:28, 343.83batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  26%|▎| 10625/40960 [00:29<01:28, 343.83batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  26%|▎| 10690/40960 [00:30<01:29, 336.37batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  26%|▎| 10690/40960 [00:30<01:29, 336.37batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  26%|▎| 10759/40960 [00:30<01:29, 338.60batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  26%|▎| 10759/40960 [00:30<01:29, 338.60batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  26%|▎| 10827/40960 [00:30<01:29, 338.12batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  26%|▎| 10827/40960 [00:30<01:29, 338.12batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  27%|▎| 10902/40960 [00:30<01:26, 349.08batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  27%|▎| 10902/40960 [00:30<01:26, 349.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  27%|▎| 10976/40960 [00:30<01:24, 353.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  27%|▎| 10976/40960 [00:30<01:24, 353.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  27%|▎| 11050/40960 [00:31<01:23, 357.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  27%|▎| 11050/40960 [00:31<01:23, 357.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  27%|▎| 11124/40960 [00:31<01:22, 361.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  27%|▎| 11124/40960 [00:31<01:22, 361.01batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  27%|▎| 11198/40960 [00:31<01:22, 362.70batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  27%|▎| 11198/40960 [00:31<01:22, 362.70batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  28%|▎| 11269/40960 [00:31<01:22, 360.32batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  28%|▎| 11269/40960 [00:31<01:22, 360.32batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  28%|▎| 11338/40960 [00:31<01:23, 354.66batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  28%|▎| 11338/40960 [00:31<01:23, 354.66batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  28%|▎| 11408/40960 [00:32<01:23, 352.94batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  28%|▎| 11408/40960 [00:32<01:23, 352.94batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  28%|▎| 11479/40960 [00:32<01:23, 353.15batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  28%|▎| 11479/40960 [00:32<01:23, 353.15batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  28%|▎| 11555/40960 [00:32<01:21, 359.66batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  28%|▎| 11555/40960 [00:32<01:21, 359.66batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  28%|▎| 11627/40960 [00:32<01:21, 359.48batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  28%|▎| 11627/40960 [00:32<01:21, 359.48batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11697/40960 [00:32<01:22, 355.74batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11697/40960 [00:32<01:22, 355.74batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11769/40960 [00:33<01:21, 356.00batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11769/40960 [00:33<01:21, 356.00batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11844/40960 [00:33<01:20, 361.11batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11844/40960 [00:33<01:20, 361.11batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11910/40960 [00:33<01:22, 351.54batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11910/40960 [00:33<01:22, 351.54batches/s, l2_loss: 0.0129 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|▎| 11978/40960 [00:33<01:23, 346.63batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 11978/40960 [00:33<01:23, 346.63batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 12047/40960 [00:33<01:23, 344.80batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  29%|▎| 12047/40960 [00:33<01:23, 344.80batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12122/40960 [00:34<01:21, 352.50batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12122/40960 [00:34<01:21, 352.50batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12197/40960 [00:34<01:20, 359.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12197/40960 [00:34<01:20, 359.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12272/40960 [00:34<01:19, 362.56batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12272/40960 [00:34<01:19, 362.56batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12344/40960 [00:34<01:19, 360.50batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12344/40960 [00:34<01:19, 360.50batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  30%|▎| 12411/40960 [00:34<01:21, 351.91batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  30%|▎| 12411/40960 [00:34<01:21, 351.91batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12478/40960 [00:35<01:22, 346.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  30%|▎| 12478/40960 [00:35<01:22, 346.74batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  31%|▎| 12548/40960 [00:35<01:21, 347.66batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  31%|▎| 12548/40960 [00:35<01:21, 347.66batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12619/40960 [00:35<01:21, 349.67batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12619/40960 [00:35<01:21, 349.67batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12691/40960 [00:35<01:20, 352.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12691/40960 [00:35<01:20, 352.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12765/40960 [00:35<01:19, 356.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12765/40960 [00:35<01:19, 356.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12838/40960 [00:36<01:18, 357.37batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12838/40960 [00:36<01:18, 357.37batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12902/40960 [00:36<01:21, 344.85batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  31%|▎| 12902/40960 [00:36<01:21, 344.85batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  32%|▎| 12970/40960 [00:36<01:21, 342.02batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  32%|▎| 12970/40960 [00:36<01:21, 342.02batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  32%|▎| 13033/40960 [00:36<01:23, 333.75batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  32%|▎| 13033/40960 [00:36<01:23, 333.75batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  32%|▎| 13098/40960 [00:36<01:24, 331.02batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  32%|▎| 13098/40960 [00:36<01:24, 331.02batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  32%|▎| 13170/40960 [00:37<01:22, 338.71batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  32%|▎| 13170/40960 [00:37<01:22, 338.71batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  32%|▎| 13243/40960 [00:37<01:20, 346.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  32%|▎| 13243/40960 [00:37<01:20, 346.08batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  33%|▎| 13319/40960 [00:37<01:17, 354.90batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  33%|▎| 13319/40960 [00:37<01:17, 354.90batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13393/40960 [00:37<01:16, 359.27batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13393/40960 [00:37<01:16, 359.27batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13469/40960 [00:37<01:15, 364.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13469/40960 [00:37<01:15, 364.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13542/40960 [00:38<01:15, 363.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13542/40960 [00:38<01:15, 363.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13618/40960 [00:38<01:14, 367.82batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13618/40960 [00:38<01:14, 367.82batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13690/40960 [00:38<01:14, 365.40batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  33%|▎| 13690/40960 [00:38<01:14, 365.40batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 13763/40960 [00:38<01:14, 365.19batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 13763/40960 [00:38<01:14, 365.19batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  34%|▎| 13837/40960 [00:38<01:14, 365.35batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  34%|▎| 13837/40960 [00:38<01:14, 365.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 13908/40960 [00:39<01:14, 361.79batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 13908/40960 [00:39<01:14, 361.79batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 13981/40960 [00:39<01:14, 362.53batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 13981/40960 [00:39<01:14, 362.53batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 14053/40960 [00:39<01:14, 361.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 14053/40960 [00:39<01:14, 361.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 14126/40960 [00:39<01:14, 361.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  34%|▎| 14126/40960 [00:39<01:14, 361.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14196/40960 [00:39<01:14, 357.63batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14196/40960 [00:39<01:14, 357.63batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14263/40960 [00:40<01:16, 350.75batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14263/40960 [00:40<01:16, 350.75batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14336/40960 [00:40<01:15, 354.54batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14336/40960 [00:40<01:15, 354.54batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14408/40960 [00:40<01:14, 355.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14408/40960 [00:40<01:14, 355.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14481/40960 [00:40<01:14, 357.25batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  35%|▎| 14481/40960 [00:40<01:14, 357.25batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14555/40960 [00:40<01:13, 360.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14555/40960 [00:41<01:13, 360.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14630/40960 [00:41<01:12, 364.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14630/40960 [00:41<01:12, 364.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14706/40960 [00:41<01:11, 367.83batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14706/40960 [00:41<01:11, 367.83batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14770/40960 [00:41<01:14, 353.20batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14770/40960 [00:41<01:14, 353.20batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14834/40960 [00:41<01:16, 342.28batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14834/40960 [00:41<01:16, 342.28batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14897/40960 [00:42<01:18, 333.99batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  36%|▎| 14897/40960 [00:42<01:18, 333.99batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 14966/40960 [00:42<01:17, 336.06batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 14966/40960 [00:42<01:17, 336.06batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15025/40960 [00:42<01:20, 323.61batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15025/40960 [00:42<01:20, 323.61batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15078/40960 [00:42<01:24, 305.20batches/s, l2_loss: 0.0128 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15078/40960 [00:42<01:24, 305.20batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15140/40960 [00:42<01:24, 306.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15140/40960 [00:42<01:24, 306.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15202/40960 [00:43<01:23, 307.18batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15202/40960 [00:43<01:23, 307.18batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15257/40960 [00:43<01:26, 296.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15257/40960 [00:43<01:26, 296.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15321/40960 [00:43<01:24, 303.15batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  37%|▎| 15321/40960 [00:43<01:24, 303.15batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15390/40960 [00:43<01:21, 315.26batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15390/40960 [00:43<01:21, 315.26batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15461/40960 [00:43<01:18, 326.25batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15461/40960 [00:43<01:18, 326.25batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15531/40960 [00:44<01:16, 332.30batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15531/40960 [00:44<01:16, 332.30batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15592/40960 [00:44<01:18, 322.13batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15592/40960 [00:44<01:18, 322.13batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15654/40960 [00:44<01:19, 316.70batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15654/40960 [00:44<01:19, 316.70batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15718/40960 [00:44<01:19, 316.93batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  38%|▍| 15718/40960 [00:44<01:19, 316.93batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 15778/40960 [00:44<01:20, 311.00batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 15778/40960 [00:44<01:20, 311.00batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 15841/40960 [00:45<01:20, 311.23batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 15841/40960 [00:45<01:20, 311.23batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 15912/40960 [00:45<01:17, 322.73batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 15912/40960 [00:45<01:17, 322.73batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 15981/40960 [00:45<01:15, 328.70batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 15981/40960 [00:45<01:15, 328.70batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 16046/40960 [00:45<01:16, 327.55batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 16046/40960 [00:45<01:16, 327.55batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 16116/40960 [00:45<01:14, 333.51batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  39%|▍| 16116/40960 [00:45<01:14, 333.51batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16185/40960 [00:46<01:13, 336.51batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16185/40960 [00:46<01:13, 336.51batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16253/40960 [00:46<01:13, 337.54batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16253/40960 [00:46<01:13, 337.54batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16321/40960 [00:46<01:13, 336.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16321/40960 [00:46<01:13, 336.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16388/40960 [00:46<01:13, 335.79batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16388/40960 [00:46<01:13, 335.79batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16454/40960 [00:46<01:13, 334.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16454/40960 [00:46<01:13, 334.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16529/40960 [00:47<01:10, 345.37batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  40%|▍| 16529/40960 [00:47<01:10, 345.37batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16602/40960 [00:47<01:09, 350.61batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16602/40960 [00:47<01:09, 350.61batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16671/40960 [00:47<01:09, 347.59batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16671/40960 [00:47<01:09, 347.59batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16741/40960 [00:47<01:09, 346.83batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16741/40960 [00:47<01:09, 346.83batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16808/40960 [00:47<01:10, 342.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16808/40960 [00:47<01:10, 342.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16883/40960 [00:48<01:08, 351.45batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16883/40960 [00:48<01:08, 351.45batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16957/40960 [00:48<01:07, 356.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  41%|▍| 16957/40960 [00:48<01:07, 356.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17026/40960 [00:48<01:07, 353.24batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17026/40960 [00:48<01:07, 353.24batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17094/40960 [00:48<01:08, 348.82batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17094/40960 [00:48<01:08, 348.82batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17166/40960 [00:48<01:07, 350.97batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17166/40960 [00:48<01:07, 350.97batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17238/40960 [00:49<01:07, 352.99batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17238/40960 [00:49<01:07, 352.99batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17304/40960 [00:49<01:08, 346.09batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17304/40960 [00:49<01:08, 346.09batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17375/40960 [00:49<01:07, 348.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  42%|▍| 17375/40960 [00:49<01:07, 348.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17450/40960 [00:49<01:06, 355.83batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17450/40960 [00:49<01:06, 355.83batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17518/40960 [00:49<01:06, 350.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17518/40960 [00:49<01:06, 350.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17591/40960 [00:50<01:05, 354.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17591/40960 [00:50<01:05, 354.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17662/40960 [00:50<01:05, 353.50batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17662/40960 [00:50<01:05, 353.50batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17730/40960 [00:50<01:06, 348.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17730/40960 [00:50<01:06, 348.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17798/40960 [00:50<01:06, 345.72batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  43%|▍| 17798/40960 [00:50<01:06, 345.72batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 17863/40960 [00:50<01:08, 339.13batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 17863/40960 [00:50<01:08, 339.13batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 17929/40960 [00:51<01:08, 335.62batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 17929/40960 [00:51<01:08, 335.62batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 17999/40960 [00:51<01:07, 339.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 17999/40960 [00:51<01:07, 339.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 18065/40960 [00:51<01:08, 336.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 18065/40960 [00:51<01:08, 336.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 18133/40960 [00:51<01:07, 337.02batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 18133/40960 [00:51<01:07, 337.02batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 18206/40960 [00:51<01:05, 345.17batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  44%|▍| 18206/40960 [00:51<01:05, 345.17batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18276/40960 [00:52<01:05, 346.24batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18276/40960 [00:52<01:05, 346.24batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18342/40960 [00:52<01:06, 340.91batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18342/40960 [00:52<01:06, 340.91batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18411/40960 [00:52<01:05, 342.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18411/40960 [00:52<01:05, 342.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18477/40960 [00:52<01:06, 338.32batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18477/40960 [00:52<01:06, 338.32batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18548/40960 [00:52<01:05, 342.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18548/40960 [00:52<01:05, 342.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18620/40960 [00:53<01:04, 347.99batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  45%|▍| 18620/40960 [00:53<01:04, 347.99batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18690/40960 [00:53<01:03, 348.24batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18690/40960 [00:53<01:03, 348.24batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18764/40960 [00:53<01:02, 354.57batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18764/40960 [00:53<01:02, 354.57batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18831/40960 [00:53<01:03, 348.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18831/40960 [00:53<01:03, 348.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18904/40960 [00:53<01:02, 352.15batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18904/40960 [00:53<01:02, 352.15batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18978/40960 [00:54<01:01, 357.14batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 18978/40960 [00:54<01:01, 357.14batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 19043/40960 [00:54<01:03, 346.39batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  46%|▍| 19043/40960 [00:54<01:03, 346.39batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19111/40960 [00:54<01:03, 344.31batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19111/40960 [00:54<01:03, 344.31batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19186/40960 [00:54<01:01, 352.46batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19186/40960 [00:54<01:01, 352.46batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19264/40960 [00:54<00:59, 362.91batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19264/40960 [00:54<00:59, 362.91batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19335/40960 [00:55<01:00, 359.51batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19335/40960 [00:55<01:00, 359.51batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19404/40960 [00:55<01:00, 354.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  47%|▍| 19404/40960 [00:55<01:00, 354.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19473/40960 [00:55<01:01, 351.02batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19473/40960 [00:55<01:01, 351.02batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19548/40960 [00:55<00:59, 357.07batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19548/40960 [00:55<00:59, 357.07batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19619/40960 [00:55<01:00, 355.33batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19619/40960 [00:55<01:00, 355.33batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19693/40960 [00:56<00:59, 359.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19693/40960 [00:56<00:59, 359.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19764/40960 [00:56<00:59, 357.12batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19764/40960 [00:56<00:59, 357.12batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19833/40960 [00:56<00:59, 353.27batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  48%|▍| 19833/40960 [00:56<00:59, 353.27batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 19902/40960 [00:56<01:00, 350.61batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 19902/40960 [00:56<01:00, 350.61batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 19976/40960 [00:56<00:58, 356.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 19976/40960 [00:56<00:58, 356.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 20050/40960 [00:57<00:58, 359.19batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 20050/40960 [00:57<00:58, 359.19batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 20124/40960 [00:57<00:57, 362.39batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 20124/40960 [00:57<00:57, 362.39batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 20198/40960 [00:57<00:57, 363.46batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  49%|▍| 20198/40960 [00:57<00:57, 363.46batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▍| 20277/40960 [00:57<00:55, 372.17batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▍| 20277/40960 [00:57<00:55, 372.17batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▍| 20349/40960 [00:57<00:55, 368.40batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▍| 20349/40960 [00:57<00:55, 368.40batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▍| 20423/40960 [00:58<00:55, 368.67batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▍| 20423/40960 [00:58<00:55, 368.67batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▌| 20490/40960 [00:58<00:57, 356.87batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▌| 20490/40960 [00:58<00:57, 356.87batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▌| 20553/40960 [00:58<00:59, 344.19batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▌| 20553/40960 [00:58<00:59, 344.19batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▌| 20625/40960 [00:58<00:58, 347.99batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  50%|▌| 20625/40960 [00:58<00:58, 347.99batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20700/40960 [00:58<00:57, 355.13batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20700/40960 [00:58<00:57, 355.13batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20777/40960 [00:59<00:55, 363.23batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20777/40960 [00:59<00:55, 363.23batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20850/40960 [00:59<00:55, 362.94batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20850/40960 [00:59<00:55, 362.94batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20920/40960 [00:59<00:55, 358.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20920/40960 [00:59<00:55, 358.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20992/40960 [00:59<00:55, 358.77batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 20992/40960 [00:59<00:55, 358.77batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 21063/40960 [00:59<00:55, 356.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  51%|▌| 21063/40960 [00:59<00:55, 356.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21137/40960 [01:00<00:55, 359.37batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21137/40960 [01:00<00:55, 359.37batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21207/40960 [01:00<00:55, 356.15batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21207/40960 [01:00<00:55, 356.15batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21278/40960 [01:00<00:55, 355.20batches/s, l2_loss: 0.0128 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21278/40960 [01:00<00:55, 355.20batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21349/40960 [01:00<00:55, 354.27batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21349/40960 [01:00<00:55, 354.27batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21427/40960 [01:00<00:53, 364.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21427/40960 [01:00<00:53, 364.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21503/40960 [01:01<00:52, 367.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  52%|▌| 21503/40960 [01:01<00:52, 367.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21576/40960 [01:01<00:52, 366.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21576/40960 [01:01<00:52, 366.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21651/40960 [01:01<00:52, 368.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21651/40960 [01:01<00:52, 368.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21719/40960 [01:01<00:53, 359.58batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21719/40960 [01:01<00:53, 359.58batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21794/40960 [01:01<00:52, 363.47batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21794/40960 [01:01<00:52, 363.47batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21861/40960 [01:02<00:53, 354.67batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  53%|▌| 21861/40960 [01:02<00:53, 354.67batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 21929/40960 [01:02<00:54, 350.00batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 21929/40960 [01:02<00:54, 350.00batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22004/40960 [01:02<00:53, 356.23batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22004/40960 [01:02<00:53, 356.23batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22079/40960 [01:02<00:52, 360.56batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22079/40960 [01:02<00:52, 360.56batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22156/40960 [01:02<00:51, 367.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22156/40960 [01:02<00:51, 367.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22214/40960 [01:03<00:54, 342.44batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22214/40960 [01:03<00:54, 342.44batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22264/40960 [01:03<00:59, 312.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  54%|▌| 22264/40960 [01:03<00:59, 312.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22337/40960 [01:03<00:56, 327.58batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22337/40960 [01:03<00:56, 327.58batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22411/40960 [01:03<00:54, 339.82batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22411/40960 [01:03<00:54, 339.82batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22487/40960 [01:03<00:52, 351.17batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22487/40960 [01:03<00:52, 351.17batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22558/40960 [01:04<00:52, 349.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22558/40960 [01:04<00:52, 349.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22631/40960 [01:04<00:51, 352.85batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22631/40960 [01:04<00:51, 352.85batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22706/40960 [01:04<00:50, 358.76batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  55%|▌| 22706/40960 [01:04<00:50, 358.76batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 22781/40960 [01:04<00:50, 363.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 22781/40960 [01:04<00:50, 363.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 22857/40960 [01:04<00:49, 367.55batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 22857/40960 [01:04<00:49, 367.55batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 22932/40960 [01:05<00:48, 369.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 22932/40960 [01:05<00:48, 369.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 22995/40960 [01:05<00:50, 353.13batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 22995/40960 [01:05<00:50, 353.13batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 23070/40960 [01:05<00:49, 358.86batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  56%|▌| 23070/40960 [01:05<00:49, 358.86batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23143/40960 [01:05<00:49, 360.53batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23143/40960 [01:05<00:49, 360.53batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23218/40960 [01:05<00:48, 364.47batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23218/40960 [01:05<00:48, 364.47batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23282/40960 [01:06<00:50, 350.56batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23282/40960 [01:06<00:50, 350.56batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23345/40960 [01:06<00:51, 338.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23345/40960 [01:06<00:51, 338.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23417/40960 [01:06<00:50, 344.00batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23417/40960 [01:06<00:50, 344.00batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23493/40960 [01:06<00:49, 353.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  57%|▌| 23493/40960 [01:06<00:49, 353.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23568/40960 [01:06<00:48, 359.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23568/40960 [01:06<00:48, 359.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23642/40960 [01:07<00:47, 362.63batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23642/40960 [01:07<00:47, 362.63batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23715/40960 [01:07<00:47, 362.05batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23715/40960 [01:07<00:47, 362.05batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23784/40960 [01:07<00:48, 356.44batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23784/40960 [01:07<00:48, 356.44batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  58%|▌| 23854/40960 [01:07<00:48, 353.97batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  58%|▌| 23854/40960 [01:07<00:48, 353.97batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23925/40960 [01:07<00:48, 353.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  58%|▌| 23925/40960 [01:07<00:48, 353.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 23995/40960 [01:08<00:48, 352.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 23995/40960 [01:08<00:48, 352.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24066/40960 [01:08<00:47, 352.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24066/40960 [01:08<00:47, 352.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24137/40960 [01:08<00:47, 353.09batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24137/40960 [01:08<00:47, 353.09batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24205/40960 [01:08<00:48, 348.61batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24205/40960 [01:08<00:48, 348.61batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24275/40960 [01:08<00:47, 348.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24275/40960 [01:08<00:47, 348.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24348/40960 [01:09<00:47, 352.48batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  59%|▌| 24348/40960 [01:09<00:47, 352.48batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24425/40960 [01:09<00:45, 362.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24425/40960 [01:09<00:45, 362.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 24501/40960 [01:09<00:44, 366.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24501/40960 [01:09<00:44, 366.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24578/40960 [01:09<00:44, 371.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24578/40960 [01:09<00:44, 371.01batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24645/40960 [01:09<00:45, 359.53batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24645/40960 [01:09<00:45, 359.53batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24714/40960 [01:10<00:45, 354.30batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  60%|▌| 24714/40960 [01:10<00:45, 354.30batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 24784/40960 [01:10<00:45, 352.16batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 24784/40960 [01:10<00:45, 352.16batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 24856/40960 [01:10<00:45, 353.68batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 24856/40960 [01:10<00:45, 353.68batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 24929/40960 [01:10<00:44, 356.31batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 24929/40960 [01:10<00:44, 356.31batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 25002/40960 [01:10<00:44, 357.87batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 25002/40960 [01:11<00:44, 357.87batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 25075/40960 [01:11<00:44, 358.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 25075/40960 [01:11<00:44, 358.95batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 25149/40960 [01:11<00:43, 361.87batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  61%|▌| 25149/40960 [01:11<00:43, 361.87batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25222/40960 [01:11<00:43, 361.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25222/40960 [01:11<00:43, 361.41batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25296/40960 [01:11<00:43, 363.10batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25296/40960 [01:11<00:43, 363.10batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25370/40960 [01:12<00:42, 364.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25370/40960 [01:12<00:42, 364.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25443/40960 [01:12<00:42, 363.70batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25443/40960 [01:12<00:42, 363.70batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  62%|▌| 25517/40960 [01:12<00:42, 364.83batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  62%|▌| 25517/40960 [01:12<00:42, 364.83batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25590/40960 [01:12<00:42, 364.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  62%|▌| 25590/40960 [01:12<00:42, 364.36batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25662/40960 [01:12<00:42, 362.82batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25662/40960 [01:12<00:42, 362.82batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25730/40960 [01:13<00:42, 355.64batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25730/40960 [01:13<00:42, 355.64batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25799/40960 [01:13<00:43, 352.04batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25799/40960 [01:13<00:43, 352.04batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25877/40960 [01:13<00:41, 362.48batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25877/40960 [01:13<00:41, 362.48batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25947/40960 [01:13<00:41, 357.90batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  63%|▋| 25947/40960 [01:13<00:41, 357.90batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26017/40960 [01:13<00:42, 355.53batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26017/40960 [01:13<00:42, 355.53batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26087/40960 [01:14<00:42, 352.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26087/40960 [01:14<00:42, 352.52batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26162/40960 [01:14<00:41, 358.22batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26162/40960 [01:14<00:41, 358.22batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26232/40960 [01:14<00:41, 354.73batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26232/40960 [01:14<00:41, 354.73batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26304/40960 [01:14<00:41, 355.96batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26304/40960 [01:14<00:41, 355.96batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26377/40960 [01:14<00:40, 358.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  64%|▋| 26377/40960 [01:14<00:40, 358.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26444/40960 [01:15<00:41, 351.06batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26444/40960 [01:15<00:41, 351.06batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26509/40960 [01:15<00:42, 343.18batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26509/40960 [01:15<00:42, 343.18batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26582/40960 [01:15<00:41, 349.05batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26582/40960 [01:15<00:41, 349.05batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26656/40960 [01:15<00:40, 355.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26656/40960 [01:15<00:40, 355.08batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26725/40960 [01:15<00:40, 350.88batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  65%|▋| 26725/40960 [01:15<00:40, 350.88batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  65%|▋| 26790/40960 [01:16<00:41, 342.15batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  65%|▋| 26790/40960 [01:16<00:41, 342.15batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 26858/40960 [01:16<00:41, 340.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 26858/40960 [01:16<00:41, 340.29batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 26928/40960 [01:16<00:40, 342.32batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 26928/40960 [01:16<00:40, 342.32batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 27001/40960 [01:16<00:40, 348.19batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 27001/40960 [01:16<00:40, 348.19batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 27077/40960 [01:16<00:38, 357.46batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 27077/40960 [01:16<00:38, 357.46batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 27155/40960 [01:17<00:37, 365.90batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 27155/40960 [01:17<00:37, 365.90batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 27228/40960 [01:17<00:37, 364.40batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  66%|▋| 27228/40960 [01:17<00:37, 364.40batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27303/40960 [01:17<00:37, 367.45batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27303/40960 [01:17<00:37, 367.45batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27379/40960 [01:17<00:36, 370.47batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27379/40960 [01:17<00:36, 370.47batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27455/40960 [01:17<00:36, 372.07batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27455/40960 [01:17<00:36, 372.07batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27530/40960 [01:18<00:36, 371.57batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27530/40960 [01:18<00:36, 371.57batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27601/40960 [01:18<00:36, 365.97batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  67%|▋| 27601/40960 [01:18<00:36, 365.97batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  68%|▋| 27672/40960 [01:18<00:36, 361.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|▋| 27672/40960 [01:18<00:36, 361.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  68%|▋| 27745/40960 [01:18<00:36, 362.38batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  68%|▋| 27745/40960 [01:18<00:36, 362.38batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  68%|▋| 27819/40960 [01:18<00:36, 363.65batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  68%|▋| 27819/40960 [01:18<00:36, 363.65batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  68%|▋| 27893/40960 [01:19<00:35, 365.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  68%|▋| 27893/40960 [01:19<00:35, 365.35batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  68%|▋| 27967/40960 [01:19<00:35, 366.14batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  68%|▋| 27967/40960 [01:19<00:35, 366.14batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  68%|▋| 28039/40960 [01:19<00:35, 363.59batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  68%|▋| 28039/40960 [01:19<00:35, 363.59batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  69%|▋| 28113/40960 [01:19<00:35, 365.16batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  69%|▋| 28113/40960 [01:19<00:35, 365.16batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  69%|▋| 28188/40960 [01:19<00:34, 367.11batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  69%|▋| 28188/40960 [01:19<00:34, 367.11batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  69%|▋| 28262/40960 [01:20<00:34, 367.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  69%|▋| 28262/40960 [01:20<00:34, 367.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  69%|▋| 28333/40960 [01:20<00:34, 362.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  69%|▋| 28333/40960 [01:20<00:34, 362.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  69%|▋| 28406/40960 [01:20<00:34, 361.96batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  69%|▋| 28406/40960 [01:20<00:34, 361.96batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28478/40960 [01:20<00:34, 360.68batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28478/40960 [01:20<00:34, 360.68batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28554/40960 [01:20<00:33, 365.31batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28554/40960 [01:20<00:33, 365.31batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28627/40960 [01:21<00:33, 363.66batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28627/40960 [01:21<00:33, 363.66batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28696/40960 [01:21<00:34, 356.89batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28696/40960 [01:21<00:34, 356.89batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28765/40960 [01:21<00:34, 353.27batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28765/40960 [01:21<00:34, 353.27batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28840/40960 [01:21<00:33, 358.40batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  70%|▋| 28840/40960 [01:21<00:33, 358.40batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  71%|▋| 28916/40960 [01:21<00:33, 363.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  71%|▋| 28916/40960 [01:21<00:33, 363.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  71%|▋| 28993/40960 [01:22<00:32, 369.12batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  71%|▋| 28993/40960 [01:22<00:32, 369.12batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  71%|▋| 29069/40960 [01:22<00:32, 371.37batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  71%|▋| 29069/40960 [01:22<00:32, 371.37batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  71%|▋| 29141/40960 [01:22<00:32, 367.80batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  71%|▋| 29141/40960 [01:22<00:32, 367.80batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  71%|▋| 29212/40960 [01:22<00:32, 363.17batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  71%|▋| 29212/40960 [01:22<00:32, 363.17batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  71%|▋| 29283/40960 [01:22<00:32, 359.63batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  71%|▋| 29283/40960 [01:22<00:32, 359.63batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  72%|▋| 29353/40960 [01:23<00:32, 355.68batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  72%|▋| 29353/40960 [01:23<00:32, 355.68batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  72%|▋| 29421/40960 [01:23<00:32, 350.51batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  72%|▋| 29421/40960 [01:23<00:32, 350.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  72%|▋| 29494/40960 [01:23<00:32, 353.34batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  72%|▋| 29494/40960 [01:23<00:32, 353.34batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  72%|▋| 29561/40960 [01:23<00:32, 347.12batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  72%|▋| 29561/40960 [01:23<00:32, 347.12batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  72%|▋| 29633/40960 [01:23<00:32, 350.39batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  72%|▋| 29633/40960 [01:23<00:32, 350.39batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  73%|▋| 29709/40960 [01:24<00:31, 358.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  73%|▋| 29709/40960 [01:24<00:31, 358.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  73%|▋| 29785/40960 [01:24<00:30, 364.01batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  73%|▋| 29785/40960 [01:24<00:30, 364.01batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  73%|▋| 29859/40960 [01:24<00:30, 365.49batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  73%|▋| 29859/40960 [01:24<00:30, 365.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  73%|▋| 29930/40960 [01:24<00:30, 361.45batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  73%|▋| 29930/40960 [01:24<00:30, 361.45batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  73%|▋| 29997/40960 [01:24<00:31, 351.71batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  73%|▋| 29997/40960 [01:24<00:31, 351.71batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  73%|▋| 30065/40960 [01:25<00:31, 347.62batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  73%|▋| 30065/40960 [01:25<00:31, 347.62batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  74%|▋| 30140/40960 [01:25<00:30, 355.58batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  74%|▋| 30140/40960 [01:25<00:30, 355.58batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  74%|▋| 30215/40960 [01:25<00:29, 360.59batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  74%|▋| 30215/40960 [01:25<00:29, 360.59batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  74%|▋| 30282/40960 [01:25<00:30, 352.57batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  74%|▋| 30282/40960 [01:25<00:30, 352.57batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  74%|▋| 30348/40960 [01:25<00:30, 344.74batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  74%|▋| 30348/40960 [01:25<00:30, 344.74batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  74%|▋| 30421/40960 [01:26<00:30, 350.09batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  74%|▋| 30421/40960 [01:26<00:30, 350.09batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  74%|▋| 30494/40960 [01:26<00:29, 353.32batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  74%|▋| 30494/40960 [01:26<00:29, 353.32batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  75%|▋| 30566/40960 [01:26<00:29, 354.23batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  75%|▋| 30566/40960 [01:26<00:29, 354.23batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  75%|▋| 30639/40960 [01:26<00:28, 356.54batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  75%|▋| 30639/40960 [01:26<00:28, 356.54batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  75%|▋| 30712/40960 [01:26<00:28, 358.02batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  75%|▋| 30712/40960 [01:26<00:28, 358.02batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  75%|▊| 30778/40960 [01:27<00:29, 348.38batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  75%|▊| 30778/40960 [01:27<00:29, 348.38batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  75%|▊| 30845/40960 [01:27<00:29, 343.50batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  75%|▊| 30845/40960 [01:27<00:29, 343.50batches/s, l2_loss: 0.0127 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▊| 30919/40960 [01:27<00:28, 349.91batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  75%|▊| 30919/40960 [01:27<00:28, 349.91batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  76%|▊| 30991/40960 [01:27<00:28, 352.86batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  76%|▊| 30991/40960 [01:27<00:28, 352.86batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  76%|▊| 31065/40960 [01:27<00:27, 356.96batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  76%|▊| 31065/40960 [01:27<00:27, 356.96batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  76%|▊| 31138/40960 [01:28<00:27, 358.75batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  76%|▊| 31138/40960 [01:28<00:27, 358.75batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  76%|▊| 31213/40960 [01:28<00:26, 362.66batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  76%|▊| 31213/40960 [01:28<00:26, 362.66batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  76%|▊| 31287/40960 [01:28<00:26, 364.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  76%|▊| 31287/40960 [01:28<00:26, 364.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  77%|▊| 31362/40960 [01:28<00:26, 366.42batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  77%|▊| 31362/40960 [01:28<00:26, 366.42batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31430/40960 [01:28<00:26, 357.40batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31430/40960 [01:28<00:26, 357.40batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31495/40960 [01:29<00:27, 346.42batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31495/40960 [01:29<00:27, 346.42batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31566/40960 [01:29<00:26, 348.66batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31566/40960 [01:29<00:26, 348.66batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31637/40960 [01:29<00:26, 349.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31637/40960 [01:29<00:26, 349.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31710/40960 [01:29<00:26, 354.00batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  77%|▊| 31710/40960 [01:29<00:26, 354.00batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 31785/40960 [01:29<00:25, 359.64batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 31785/40960 [01:29<00:25, 359.64batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 31857/40960 [01:30<00:25, 359.56batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 31857/40960 [01:30<00:25, 359.56batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 31929/40960 [01:30<00:25, 359.63batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 31929/40960 [01:30<00:25, 359.63batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  78%|▊| 32002/40960 [01:30<00:24, 360.15batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  78%|▊| 32002/40960 [01:30<00:24, 360.15batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 32074/40960 [01:30<00:24, 359.73batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 32074/40960 [01:30<00:24, 359.73batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 32139/40960 [01:30<00:25, 348.39batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  78%|▊| 32139/40960 [01:30<00:25, 348.39batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32205/40960 [01:31<00:25, 341.34batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32205/40960 [01:31<00:25, 341.34batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32273/40960 [01:31<00:25, 339.94batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32273/40960 [01:31<00:25, 339.94batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  79%|▊| 32346/40960 [01:31<00:24, 347.30batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  79%|▊| 32346/40960 [01:31<00:24, 347.30batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32416/40960 [01:31<00:24, 346.92batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32416/40960 [01:31<00:24, 346.92batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  79%|▊| 32488/40960 [01:31<00:24, 349.54batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  79%|▊| 32488/40960 [01:31<00:24, 349.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32562/40960 [01:32<00:23, 354.32batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32562/40960 [01:32<00:23, 354.32batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32637/40960 [01:32<00:23, 360.15batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32637/40960 [01:32<00:23, 360.15batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32705/40960 [01:32<00:23, 353.65batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32705/40960 [01:32<00:23, 353.65batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32773/40960 [01:32<00:23, 349.21batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32773/40960 [01:32<00:23, 349.21batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32841/40960 [01:32<00:23, 346.39batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32841/40960 [01:32<00:23, 346.39batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32917/40960 [01:33<00:22, 356.26batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32917/40960 [01:33<00:22, 356.26batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 32986/40960 [01:33<00:22, 349.91batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 32986/40960 [01:33<00:22, 349.91batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33055/40960 [01:33<00:22, 347.34batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33055/40960 [01:33<00:22, 347.34batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33125/40960 [01:33<00:22, 347.56batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33125/40960 [01:33<00:22, 347.56batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33200/40960 [01:33<00:21, 354.29batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33200/40960 [01:33<00:21, 354.29batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33269/40960 [01:34<00:21, 351.23batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33269/40960 [01:34<00:21, 351.23batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33334/40960 [01:34<00:22, 342.62batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  81%|▊| 33334/40960 [01:34<00:22, 342.62batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33404/40960 [01:34<00:21, 344.66batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33404/40960 [01:34<00:21, 344.66batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33475/40960 [01:34<00:21, 347.13batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33475/40960 [01:34<00:21, 347.13batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33548/40960 [01:34<00:21, 352.08batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33548/40960 [01:34<00:21, 352.08batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33617/40960 [01:35<00:21, 348.58batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33617/40960 [01:35<00:21, 348.58batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  82%|▊| 33686/40960 [01:35<00:20, 347.49batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  82%|▊| 33686/40960 [01:35<00:20, 347.49batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33763/40960 [01:35<00:20, 357.39batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  82%|▊| 33763/40960 [01:35<00:20, 357.39batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 33838/40960 [01:35<00:19, 361.85batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 33838/40960 [01:35<00:19, 361.85batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 33911/40960 [01:35<00:19, 361.87batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 33911/40960 [01:35<00:19, 361.87batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 33985/40960 [01:36<00:19, 363.77batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 33985/40960 [01:36<00:19, 363.77batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 34061/40960 [01:36<00:18, 368.24batches/s, l2_loss: 0.0127 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 34061/40960 [01:36<00:18, 368.24batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 34131/40960 [01:36<00:18, 362.53batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 34131/40960 [01:36<00:18, 362.53batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 34201/40960 [01:36<00:18, 358.69batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  83%|▊| 34201/40960 [01:36<00:18, 358.69batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34273/40960 [01:36<00:18, 358.26batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34273/40960 [01:36<00:18, 358.26batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34344/40960 [01:37<00:18, 356.60batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34344/40960 [01:37<00:18, 356.60batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34416/40960 [01:37<00:18, 357.12batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34416/40960 [01:37<00:18, 357.12batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34486/40960 [01:37<00:18, 354.05batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34486/40960 [01:37<00:18, 354.05batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34561/40960 [01:37<00:17, 359.05batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34561/40960 [01:37<00:17, 359.05batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34626/40960 [01:37<00:18, 348.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34626/40960 [01:37<00:18, 348.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34694/40960 [01:38<00:18, 344.99batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34694/40960 [01:38<00:18, 344.99batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34764/40960 [01:38<00:17, 346.04batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34764/40960 [01:38<00:17, 346.04batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34839/40960 [01:38<00:17, 353.82batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34839/40960 [01:38<00:17, 353.82batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34907/40960 [01:38<00:17, 348.62batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34907/40960 [01:38<00:17, 348.62batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34975/40960 [01:39<00:17, 345.13batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  85%|▊| 34975/40960 [01:39<00:17, 345.13batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35043/40960 [01:39<00:17, 342.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35043/40960 [01:39<00:17, 342.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35112/40960 [01:39<00:17, 342.70batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35112/40960 [01:39<00:17, 342.70batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35181/40960 [01:39<00:16, 342.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35181/40960 [01:39<00:16, 342.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35248/40960 [01:39<00:16, 339.90batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35248/40960 [01:39<00:16, 339.90batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35317/40960 [01:40<00:16, 340.93batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35317/40960 [01:40<00:16, 340.93batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35390/40960 [01:40<00:16, 347.45batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  86%|▊| 35390/40960 [01:40<00:16, 347.45batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35468/40960 [01:40<00:15, 359.28batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35468/40960 [01:40<00:15, 359.28batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35544/40960 [01:40<00:14, 364.48batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35544/40960 [01:40<00:14, 364.48batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35621/40960 [01:40<00:14, 369.84batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35621/40960 [01:40<00:14, 369.84batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35698/40960 [01:41<00:14, 373.21batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35698/40960 [01:41<00:14, 373.21batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35773/40960 [01:41<00:13, 372.50batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  87%|▊| 35773/40960 [01:41<00:13, 372.50batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 35851/40960 [01:41<00:13, 377.10batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 35851/40960 [01:41<00:13, 377.10batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 35921/40960 [01:41<00:13, 368.06batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 35921/40960 [01:41<00:13, 368.06batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 35989/40960 [01:41<00:13, 358.82batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 35989/40960 [01:41<00:13, 358.82batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 36061/40960 [01:42<00:13, 358.24batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 36061/40960 [01:42<00:13, 358.24batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 36124/40960 [01:42<00:14, 342.75batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 36124/40960 [01:42<00:14, 342.75batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 36179/40960 [01:42<00:14, 320.72batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 36179/40960 [01:42<00:14, 320.72batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 36245/40960 [01:42<00:14, 323.11batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  88%|▉| 36245/40960 [01:42<00:14, 323.11batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36313/40960 [01:42<00:14, 327.66batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36313/40960 [01:42<00:14, 327.66batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36380/40960 [01:43<00:13, 329.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36380/40960 [01:43<00:13, 329.54batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36453/40960 [01:43<00:13, 340.11batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36453/40960 [01:43<00:13, 340.11batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36524/40960 [01:43<00:12, 343.57batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36524/40960 [01:43<00:12, 343.57batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36600/40960 [01:43<00:12, 354.36batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  89%|▉| 36600/40960 [01:43<00:12, 354.36batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36670/40960 [01:43<00:12, 352.42batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36670/40960 [01:43<00:12, 352.42batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36737/40960 [01:44<00:12, 347.10batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36737/40960 [01:44<00:12, 347.10batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36804/40960 [01:44<00:12, 343.02batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36804/40960 [01:44<00:12, 343.02batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36875/40960 [01:44<00:11, 346.55batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36875/40960 [01:44<00:11, 346.55batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36948/40960 [01:44<00:11, 351.58batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 36948/40960 [01:44<00:11, 351.58batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 37017/40960 [01:44<00:11, 348.90batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  90%|▉| 37017/40960 [01:44<00:11, 348.90batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37086/40960 [01:45<00:11, 347.31batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37086/40960 [01:45<00:11, 347.31batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37157/40960 [01:45<00:10, 349.23batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37157/40960 [01:45<00:10, 349.23batches/s, l2_loss: 0.0127 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|▉| 37229/40960 [01:45<00:10, 351.36batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37229/40960 [01:45<00:10, 351.36batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37301/40960 [01:45<00:10, 352.93batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37301/40960 [01:45<00:10, 352.93batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37374/40960 [01:45<00:10, 356.53batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37374/40960 [01:45<00:10, 356.53batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37443/40960 [01:46<00:10, 351.57batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  91%|▉| 37443/40960 [01:46<00:10, 351.57batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37520/40960 [01:46<00:09, 360.83batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37520/40960 [01:46<00:09, 360.83batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37596/40960 [01:46<00:09, 365.18batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37596/40960 [01:46<00:09, 365.18batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37665/40960 [01:46<00:09, 358.01batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37665/40960 [01:46<00:09, 358.01batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37730/40960 [01:46<00:09, 347.82batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37730/40960 [01:46<00:09, 347.82batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37801/40960 [01:47<00:09, 348.58batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37801/40960 [01:47<00:09, 348.58batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37866/40960 [01:47<00:09, 341.32batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  92%|▉| 37866/40960 [01:47<00:09, 341.32batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 37930/40960 [01:47<00:09, 333.64batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 37930/40960 [01:47<00:09, 333.64batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38001/40960 [01:47<00:08, 339.05batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38001/40960 [01:47<00:08, 339.05batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38061/40960 [01:47<00:08, 327.16batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38061/40960 [01:47<00:08, 327.16batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38128/40960 [01:48<00:08, 328.33batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38128/40960 [01:48<00:08, 328.33batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38196/40960 [01:48<00:08, 330.98batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38196/40960 [01:48<00:08, 330.98batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38267/40960 [01:48<00:07, 336.76batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  93%|▉| 38267/40960 [01:48<00:07, 336.76batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38338/40960 [01:48<00:07, 342.02batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38338/40960 [01:48<00:07, 342.02batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38407/40960 [01:48<00:07, 342.62batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38407/40960 [01:48<00:07, 342.62batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38479/40960 [01:49<00:07, 346.93batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38479/40960 [01:49<00:07, 346.93batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38553/40960 [01:49<00:06, 352.67batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38553/40960 [01:49<00:06, 352.67batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38626/40960 [01:49<00:06, 356.24batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38626/40960 [01:49<00:06, 356.24batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38702/40960 [01:49<00:06, 363.12batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  94%|▉| 38702/40960 [01:49<00:06, 363.12batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38778/40960 [01:49<00:05, 367.57batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38778/40960 [01:49<00:05, 367.57batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38853/40960 [01:50<00:05, 369.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38853/40960 [01:50<00:05, 369.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38926/40960 [01:50<00:05, 366.96batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38926/40960 [01:50<00:05, 366.96batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38996/40960 [01:50<00:05, 360.79batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38996/40960 [01:50<00:05, 360.79batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 39061/40960 [01:50<00:05, 349.92batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  95%|▉| 39061/40960 [01:50<00:05, 349.92batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39131/40960 [01:50<00:05, 349.21batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39131/40960 [01:50<00:05, 349.21batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39205/40960 [01:51<00:04, 355.33batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39205/40960 [01:51<00:04, 355.33batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39277/40960 [01:51<00:04, 356.27batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39277/40960 [01:51<00:04, 356.27batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39345/40960 [01:51<00:04, 350.62batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39345/40960 [01:51<00:04, 350.62batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39411/40960 [01:51<00:04, 343.42batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39411/40960 [01:51<00:04, 343.42batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39478/40960 [01:51<00:04, 339.75batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  96%|▉| 39478/40960 [01:51<00:04, 339.75batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39546/40960 [01:52<00:04, 339.63batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39546/40960 [01:52<00:04, 339.63batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39615/40960 [01:52<00:03, 340.77batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39615/40960 [01:52<00:03, 340.77batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39686/40960 [01:52<00:03, 344.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39686/40960 [01:52<00:03, 344.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39758/40960 [01:52<00:03, 348.41batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39758/40960 [01:52<00:03, 348.41batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39828/40960 [01:52<00:03, 347.82batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39828/40960 [01:52<00:03, 347.82batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39896/40960 [01:53<00:03, 344.34batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  97%|▉| 39896/40960 [01:53<00:03, 344.34batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 39959/40960 [01:53<00:02, 335.04batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 39959/40960 [01:53<00:02, 335.04batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40021/40960 [01:53<00:02, 327.47batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40021/40960 [01:53<00:02, 327.47batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40088/40960 [01:53<00:02, 328.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40088/40960 [01:53<00:02, 328.51batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40153/40960 [01:53<00:02, 326.97batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40153/40960 [01:53<00:02, 326.97batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40223/40960 [01:54<00:02, 332.53batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40223/40960 [01:54<00:02, 332.53batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  98%|▉| 40296/40960 [01:54<00:01, 341.00batches/s, l2_loss: 0.0127 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40296/40960 [01:54<00:01, 341.00batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40370/40960 [01:54<00:01, 349.52batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40370/40960 [01:54<00:01, 349.52batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40445/40960 [01:54<00:01, 355.94batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40445/40960 [01:54<00:01, 355.94batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40514/40960 [01:54<00:01, 351.83batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40514/40960 [01:54<00:01, 351.83batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40586/40960 [01:55<00:01, 354.14batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40586/40960 [01:55<00:01, 354.14batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40663/40960 [01:55<00:00, 362.87batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40663/40960 [01:55<00:00, 362.87batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40737/40960 [01:55<00:00, 364.20batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  99%|▉| 40737/40960 [01:55<00:00, 364.20batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training: 100%|▉| 40812/40960 [01:55<00:00, 366.47batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training: 100%|▉| 40812/40960 [01:55<00:00, 366.47batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training: 100%|▉| 40882/40960 [01:55<00:00, 360.56batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training: 100%|▉| 40882/40960 [01:55<00:00, 360.56batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training: 100%|▉| 40948/40960 [01:56<00:00, 350.67batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training: 100%|▉| 40948/40960 [01:56<00:00, 350.67batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 18:58:13.761073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  19%|▏| 5/26 [08:52<38:13, 109.23s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 18:58:15.797178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 18:58:18.465824: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<10:03:39,  1.13batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:03:39,  1.13batches/s, l2_loss: 0.0045 - round_loss:\u001b[A\n",
      "Training:   0%| | 96/40960 [00:01<05:50, 116.74batches/s, l2_loss: 0.0045 - round_loss: \u001b[A\n",
      "Training:   0%| | 96/40960 [00:01<05:50, 116.74batches/s, l2_loss: 0.0071 - round_loss: \u001b[A\n",
      "Training:   0%| | 182/40960 [00:01<03:26, 197.27batches/s, l2_loss: 0.0071 - round_loss:\u001b[A\n",
      "Training:   0%| | 182/40960 [00:01<03:26, 197.27batches/s, l2_loss: 0.0070 - round_loss:\u001b[A\n",
      "Training:   1%| | 266/40960 [00:01<02:38, 256.42batches/s, l2_loss: 0.0070 - round_loss:\u001b[A\n",
      "Training:   1%| | 266/40960 [00:01<02:38, 256.42batches/s, l2_loss: 0.0075 - round_loss:\u001b[A\n",
      "Training:   1%| | 351/40960 [00:01<02:14, 302.38batches/s, l2_loss: 0.0075 - round_loss:\u001b[A\n",
      "Training:   1%| | 351/40960 [00:01<02:14, 302.38batches/s, l2_loss: 0.0077 - round_loss:\u001b[A\n",
      "Training:   1%| | 441/40960 [00:01<01:57, 343.46batches/s, l2_loss: 0.0077 - round_loss:\u001b[A\n",
      "Training:   1%| | 441/40960 [00:01<01:57, 343.46batches/s, l2_loss: 0.0075 - round_loss:\u001b[A\n",
      "Training:   1%| | 536/40960 [00:02<01:46, 380.89batches/s, l2_loss: 0.0075 - round_loss:\u001b[A\n",
      "Training:   1%| | 536/40960 [00:02<01:46, 380.89batches/s, l2_loss: 0.0076 - round_loss:\u001b[A\n",
      "Training:   2%| | 620/40960 [00:02<01:43, 391.56batches/s, l2_loss: 0.0076 - round_loss:\u001b[A\n",
      "Training:   2%| | 620/40960 [00:02<01:43, 391.56batches/s, l2_loss: 0.0077 - round_loss:\u001b[A\n",
      "Training:   2%| | 708/40960 [00:02<01:39, 404.88batches/s, l2_loss: 0.0077 - round_loss:\u001b[A\n",
      "Training:   2%| | 708/40960 [00:02<01:39, 404.88batches/s, l2_loss: 0.0075 - round_loss:\u001b[A\n",
      "Training:   2%| | 800/40960 [00:02<01:35, 421.05batches/s, l2_loss: 0.0075 - round_loss:\u001b[A\n",
      "Training:   2%| | 800/40960 [00:02<01:35, 421.05batches/s, l2_loss: 0.0075 - round_loss:\u001b[A\n",
      "Training:   2%| | 888/40960 [00:02<01:33, 426.32batches/s, l2_loss: 0.0075 - round_loss:\u001b[A\n",
      "Training:   2%| | 888/40960 [00:02<01:33, 426.32batches/s, l2_loss: 0.0076 - round_loss:\u001b[A\n",
      "Training:   2%| | 977/40960 [00:03<01:32, 430.60batches/s, l2_loss: 0.0076 - round_loss:\u001b[A\n",
      "Training:   2%| | 977/40960 [00:03<01:32, 430.60batches/s, l2_loss: 0.0076 - round_loss:\u001b[A\n",
      "Training:   3%| | 1069/40960 [00:03<01:30, 438.85batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   3%| | 1069/40960 [00:03<01:30, 438.85batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:   3%| | 1165/40960 [00:03<01:28, 450.07batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:   3%| | 1165/40960 [00:03<01:28, 450.07batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   3%| | 1261/40960 [00:03<01:26, 457.71batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   3%| | 1261/40960 [00:03<01:26, 457.71batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   3%| | 1358/40960 [00:03<01:25, 465.71batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   3%| | 1358/40960 [00:03<01:25, 465.71batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   4%| | 1452/40960 [00:04<01:24, 466.09batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   4%| | 1452/40960 [00:04<01:24, 466.09batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   4%| | 1546/40960 [00:04<01:24, 466.47batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   4%| | 1546/40960 [00:04<01:24, 466.47batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   4%| | 1642/40960 [00:04<01:23, 470.04batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   4%| | 1642/40960 [00:04<01:23, 470.04batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   4%| | 1731/40960 [00:04<01:25, 461.48batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   4%| | 1731/40960 [00:04<01:25, 461.48batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   4%| | 1816/40960 [00:04<01:27, 449.49batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   4%| | 1816/40960 [00:04<01:27, 449.49batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   5%| | 1907/40960 [00:05<01:26, 450.55batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   5%| | 1907/40960 [00:05<01:26, 450.55batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   5%| | 2002/40960 [00:05<01:25, 457.36batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   5%| | 2002/40960 [00:05<01:25, 457.36batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   5%| | 2092/40960 [00:05<01:25, 453.86batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   5%| | 2092/40960 [00:05<01:25, 453.86batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   5%| | 2184/40960 [00:05<01:25, 454.96batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   5%| | 2184/40960 [00:05<01:25, 454.96batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2273/40960 [00:05<01:25, 450.43batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2273/40960 [00:05<01:25, 450.43batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   6%| | 2369/40960 [00:06<01:24, 458.65batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   6%| | 2369/40960 [00:06<01:24, 458.65batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2465/40960 [00:06<01:22, 464.29batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2465/40960 [00:06<01:22, 464.29batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2560/40960 [00:06<01:22, 467.02batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%| | 2560/40960 [00:06<01:22, 467.02batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2652/40960 [00:06<01:22, 464.53batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2652/40960 [00:06<01:22, 464.53batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 2743/40960 [00:06<01:22, 460.91batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 2743/40960 [00:06<01:22, 460.91batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 2838/40960 [00:07<01:21, 465.07batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 2838/40960 [00:07<01:21, 465.07batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 2935/40960 [00:07<01:20, 470.57batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 2935/40960 [00:07<01:20, 470.57batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 3029/40960 [00:07<01:20, 469.82batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 3029/40960 [00:07<01:20, 469.82batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   8%| | 3126/40960 [00:07<01:19, 473.13batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   8%| | 3126/40960 [00:07<01:19, 473.13batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   8%| | 3221/40960 [00:07<01:19, 473.39batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   8%| | 3221/40960 [00:07<01:19, 473.39batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   8%| | 3306/40960 [00:08<01:22, 458.70batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   8%| | 3306/40960 [00:08<01:22, 458.70batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   8%| | 3394/40960 [00:08<01:23, 451.75batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   8%| | 3394/40960 [00:08<01:23, 451.75batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   9%| | 3486/40960 [00:08<01:22, 453.48batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   9%| | 3486/40960 [00:08<01:22, 453.48batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   9%| | 3582/40960 [00:08<01:21, 460.97batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   9%| | 3582/40960 [00:08<01:21, 460.97batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   9%| | 3669/40960 [00:08<01:22, 452.28batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   9%| | 3669/40960 [00:08<01:22, 452.28batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   9%| | 3754/40960 [00:09<01:23, 444.11batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   9%| | 3754/40960 [00:09<01:23, 444.11batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   9%| | 3846/40960 [00:09<01:22, 448.06batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   9%| | 3846/40960 [00:09<01:22, 448.06batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  10%| | 3940/40960 [00:09<01:21, 454.47batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  10%| | 3940/40960 [00:09<01:21, 454.47batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  10%| | 4035/40960 [00:09<01:20, 459.60batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  10%| | 4035/40960 [00:09<01:20, 459.60batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  10%| | 4126/40960 [00:09<01:20, 457.10batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  10%| | 4126/40960 [00:09<01:20, 457.10batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  10%| | 4218/40960 [00:10<01:20, 457.42batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  10%| | 4218/40960 [00:10<01:20, 457.42batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4312/40960 [00:10<01:19, 460.67batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4312/40960 [00:10<01:19, 460.67batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4400/40960 [00:10<01:20, 453.46batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4400/40960 [00:10<01:20, 453.46batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4489/40960 [00:10<01:21, 449.74batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4489/40960 [00:10<01:21, 449.74batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4575/40960 [00:10<01:22, 443.08batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4575/40960 [00:10<01:22, 443.08batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4669/40960 [00:11<01:20, 450.29batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  11%| | 4669/40960 [00:11<01:20, 450.29batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  12%| | 4756/40960 [00:11<01:21, 443.83batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  12%| | 4756/40960 [00:11<01:21, 443.83batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  12%| | 4844/40960 [00:11<01:21, 441.67batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  12%| | 4844/40960 [00:11<01:21, 441.67batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  12%| | 4933/40960 [00:11<01:21, 441.60batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  12%| | 4933/40960 [00:11<01:21, 441.60batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  12%| | 5028/40960 [00:11<01:19, 450.26batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  12%| | 5028/40960 [00:11<01:19, 450.26batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5122/40960 [00:12<01:18, 454.84batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5122/40960 [00:12<01:18, 454.84batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5215/40960 [00:12<01:18, 456.92batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5215/40960 [00:12<01:18, 456.92batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5308/40960 [00:12<01:17, 459.21batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5308/40960 [00:12<01:17, 459.21batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5401/40960 [00:12<01:17, 459.98batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5401/40960 [00:12<01:17, 459.98batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5499/40960 [00:12<01:15, 468.01batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5499/40960 [00:12<01:15, 468.01batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5595/40960 [00:13<01:15, 471.11batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5595/40960 [00:13<01:15, 471.11batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5689/40960 [00:13<01:15, 469.97batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5689/40960 [00:13<01:15, 469.97batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5778/40960 [00:13<01:16, 462.22batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5778/40960 [00:13<01:16, 462.22batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5866/40960 [00:13<01:17, 454.52batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5866/40960 [00:13<01:17, 454.52batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5954/40960 [00:13<01:17, 449.46batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5954/40960 [00:13<01:17, 449.46batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6051/40960 [00:14<01:15, 459.60batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6051/40960 [00:14<01:15, 459.60batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6145/40960 [00:14<01:15, 461.35batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6145/40960 [00:14<01:15, 461.35batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6227/40960 [00:14<01:18, 445.23batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6227/40960 [00:14<01:18, 445.23batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6312/40960 [00:14<01:19, 438.58batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6312/40960 [00:14<01:19, 438.58batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6404/40960 [00:14<01:17, 444.89batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6404/40960 [00:14<01:17, 444.89batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6497/40960 [00:15<01:16, 450.62batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6497/40960 [00:15<01:16, 450.62batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6592/40960 [00:15<01:15, 457.60batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6592/40960 [00:15<01:15, 457.60batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|▏| 6688/40960 [00:15<01:13, 463.15batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6688/40960 [00:15<01:13, 463.15batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6774/40960 [00:15<01:15, 452.71batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6774/40960 [00:15<01:15, 452.71batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6866/40960 [00:15<01:15, 454.47batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6866/40960 [00:15<01:15, 454.47batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6960/40960 [00:16<01:14, 457.70batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6960/40960 [00:16<01:14, 457.70batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7056/40960 [00:16<01:13, 463.81batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7056/40960 [00:16<01:13, 463.81batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7150/40960 [00:16<01:12, 464.70batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7150/40960 [00:16<01:12, 464.70batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7239/40960 [00:16<01:13, 458.81batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7239/40960 [00:16<01:13, 458.81batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7333/40960 [00:16<01:12, 461.71batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7333/40960 [00:16<01:12, 461.71batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7426/40960 [00:17<01:12, 461.92batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7426/40960 [00:17<01:12, 461.92batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7520/40960 [00:17<01:12, 463.73batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7520/40960 [00:17<01:12, 463.73batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7612/40960 [00:17<01:12, 461.17batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7612/40960 [00:17<01:12, 461.17batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7707/40960 [00:17<01:11, 463.82batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7707/40960 [00:17<01:11, 463.82batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7798/40960 [00:17<01:12, 460.53batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7798/40960 [00:17<01:12, 460.53batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7892/40960 [00:18<01:11, 462.83batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7892/40960 [00:18<01:11, 462.83batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7982/40960 [00:18<01:11, 458.48batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7982/40960 [00:18<01:11, 458.48batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8076/40960 [00:18<01:11, 460.97batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8076/40960 [00:18<01:11, 460.97batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8162/40960 [00:18<01:12, 450.32batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8162/40960 [00:18<01:12, 450.32batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8244/40960 [00:18<01:14, 438.06batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8244/40960 [00:18<01:14, 438.06batches/s, l2_loss: 0.0062 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8327/40960 [00:19<01:15, 430.64batches/s, l2_loss: 0.0062 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8327/40960 [00:19<01:15, 430.64batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8412/40960 [00:19<01:16, 427.62batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8412/40960 [00:19<01:16, 427.62batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8494/40960 [00:19<01:17, 420.74batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8494/40960 [00:19<01:17, 420.74batches/s, l2_loss: 0.0077 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8573/40960 [00:19<01:18, 412.92batches/s, l2_loss: 0.0077 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8573/40960 [00:19<01:18, 412.92batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8655/40960 [00:19<01:18, 411.52batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8655/40960 [00:19<01:18, 411.52batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8738/40960 [00:20<01:18, 411.02batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8738/40960 [00:20<01:18, 411.02batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8825/40960 [00:20<01:17, 417.02batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8825/40960 [00:20<01:17, 417.02batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8912/40960 [00:20<01:15, 422.01batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8912/40960 [00:20<01:15, 422.01batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9000/40960 [00:20<01:14, 426.26batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9000/40960 [00:20<01:14, 426.26batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9083/40960 [00:21<01:15, 422.27batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9083/40960 [00:21<01:15, 422.27batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9169/40960 [00:21<01:15, 423.84batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9169/40960 [00:21<01:15, 423.84batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9253/40960 [00:21<01:15, 422.42batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9253/40960 [00:21<01:15, 422.42batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9334/40960 [00:21<01:15, 416.60batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9334/40960 [00:21<01:15, 416.60batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9413/40960 [00:21<01:16, 409.92batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9413/40960 [00:21<01:16, 409.92batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9499/40960 [00:22<01:15, 415.70batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9499/40960 [00:22<01:15, 415.70batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9586/40960 [00:22<01:14, 420.25batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9586/40960 [00:22<01:14, 420.25batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9674/40960 [00:22<01:13, 425.42batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9674/40960 [00:22<01:13, 425.42batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9757/40960 [00:22<01:13, 421.71batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9757/40960 [00:22<01:13, 421.71batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9837/40960 [00:22<01:15, 413.79batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9837/40960 [00:22<01:15, 413.79batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9916/40960 [00:23<01:16, 407.74batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9916/40960 [00:23<01:16, 407.74batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10000/40960 [00:23<01:15, 409.98batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  24%|▏| 10000/40960 [00:23<01:15, 409.98batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▏| 10084/40960 [00:23<01:14, 411.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▏| 10084/40960 [00:23<01:14, 411.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▏| 10161/40960 [00:23<01:16, 403.54batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▏| 10161/40960 [00:23<01:16, 403.54batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▎| 10241/40960 [00:23<01:16, 402.20batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▎| 10241/40960 [00:23<01:16, 402.20batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▎| 10324/40960 [00:24<01:15, 405.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▎| 10324/40960 [00:24<01:15, 405.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▎| 10404/40960 [00:24<01:15, 403.89batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  25%|▎| 10404/40960 [00:24<01:15, 403.89batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10490/40960 [00:24<01:14, 410.13batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10490/40960 [00:24<01:14, 410.13batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10575/40960 [00:24<01:13, 413.55batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10575/40960 [00:24<01:13, 413.55batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10660/40960 [00:24<01:12, 416.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10660/40960 [00:24<01:12, 416.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10743/40960 [00:25<01:12, 415.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10743/40960 [00:25<01:12, 415.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10821/40960 [00:25<01:14, 407.21batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10821/40960 [00:25<01:14, 407.21batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  27%|▎| 10907/40960 [00:25<01:12, 413.12batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  27%|▎| 10907/40960 [00:25<01:12, 413.12batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  27%|▎| 10987/40960 [00:25<01:13, 408.13batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  27%|▎| 10987/40960 [00:25<01:13, 408.13batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11073/40960 [00:25<01:12, 413.50batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11073/40960 [00:25<01:12, 413.50batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11156/40960 [00:26<01:12, 413.03batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11156/40960 [00:26<01:12, 413.03batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11235/40960 [00:26<01:13, 406.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11235/40960 [00:26<01:13, 406.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11315/40960 [00:26<01:13, 404.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11315/40960 [00:26<01:13, 404.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11399/40960 [00:26<01:12, 407.72batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11399/40960 [00:26<01:12, 407.72batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11478/40960 [00:26<01:13, 403.45batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11478/40960 [00:26<01:13, 403.45batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11558/40960 [00:27<01:13, 402.38batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11558/40960 [00:27<01:13, 402.38batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11641/40960 [00:27<01:12, 405.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11641/40960 [00:27<01:12, 405.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11722/40960 [00:27<01:12, 404.49batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11722/40960 [00:27<01:12, 404.49batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11802/40960 [00:27<01:12, 402.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11802/40960 [00:27<01:12, 402.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11884/40960 [00:27<01:12, 403.33batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11884/40960 [00:27<01:12, 403.33batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11968/40960 [00:28<01:11, 407.26batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11968/40960 [00:28<01:11, 407.26batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  29%|▎| 12049/40960 [00:28<01:11, 405.35batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  29%|▎| 12049/40960 [00:28<01:11, 405.35batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  30%|▎| 12119/40960 [00:28<01:14, 387.43batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  30%|▎| 12119/40960 [00:28<01:14, 387.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12194/40960 [00:28<01:15, 382.83batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12194/40960 [00:28<01:15, 382.83batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12279/40960 [00:28<01:12, 394.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12279/40960 [00:28<01:12, 394.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12361/40960 [00:29<01:11, 399.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12361/40960 [00:29<01:11, 399.02batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  30%|▎| 12449/40960 [00:29<01:09, 410.22batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  30%|▎| 12449/40960 [00:29<01:09, 410.22batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12524/40960 [00:29<01:11, 399.34batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12524/40960 [00:29<01:11, 399.34batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12600/40960 [00:29<01:12, 392.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12600/40960 [00:29<01:12, 392.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12683/40960 [00:29<01:11, 398.21batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12683/40960 [00:29<01:11, 398.21batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12767/40960 [00:30<01:09, 404.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12767/40960 [00:30<01:09, 404.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12846/40960 [00:30<01:10, 400.69batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12846/40960 [00:30<01:10, 400.69batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  32%|▎| 12932/40960 [00:30<01:08, 408.23batches/s, l2_loss: 0.0075 - round_los\u001b[A\n",
      "Training:  32%|▎| 12932/40960 [00:30<01:08, 408.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13018/40960 [00:30<01:07, 413.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13018/40960 [00:30<01:07, 413.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13091/40960 [00:30<01:09, 398.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13091/40960 [00:30<01:09, 398.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13167/40960 [00:31<01:10, 392.48batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13167/40960 [00:31<01:10, 392.48batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13249/40960 [00:31<01:09, 396.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13249/40960 [00:31<01:09, 396.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13334/40960 [00:31<01:08, 404.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13334/40960 [00:31<01:08, 404.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13417/40960 [00:31<01:07, 406.21batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13417/40960 [00:31<01:07, 406.21batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13502/40960 [00:31<01:06, 411.04batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13502/40960 [00:31<01:06, 411.04batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13583/40960 [00:32<01:06, 408.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13583/40960 [00:32<01:06, 408.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13672/40960 [00:32<01:05, 418.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13672/40960 [00:32<01:05, 418.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13758/40960 [00:32<01:04, 420.55batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13758/40960 [00:32<01:04, 420.55batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13836/40960 [00:32<01:05, 411.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13836/40960 [00:32<01:05, 411.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13915/40960 [00:32<01:06, 405.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13915/40960 [00:32<01:06, 405.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13999/40960 [00:33<01:06, 408.36batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13999/40960 [00:33<01:06, 408.36batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 14083/40960 [00:33<01:05, 411.40batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  34%|▎| 14083/40960 [00:33<01:05, 411.40batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14165/40960 [00:33<01:05, 410.94batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14165/40960 [00:33<01:05, 410.94batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14245/40960 [00:33<01:05, 406.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14245/40960 [00:33<01:05, 406.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14332/40960 [00:33<01:04, 414.89batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14332/40960 [00:33<01:04, 414.89batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14415/40960 [00:34<01:04, 413.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14415/40960 [00:34<01:04, 413.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14495/40960 [00:34<01:04, 409.09batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14495/40960 [00:34<01:04, 409.09batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14571/40960 [00:34<01:06, 398.98batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14571/40960 [00:34<01:06, 398.98batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14647/40960 [00:34<01:07, 392.67batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14647/40960 [00:34<01:07, 392.67batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14731/40960 [00:34<01:05, 400.14batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14731/40960 [00:34<01:05, 400.14batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14804/40960 [00:35<01:07, 389.46batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14804/40960 [00:35<01:07, 389.46batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14875/40960 [00:35<01:08, 378.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14875/40960 [00:35<01:08, 378.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 14958/40960 [00:35<01:06, 388.81batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 14958/40960 [00:35<01:06, 388.81batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15041/40960 [00:35<01:05, 395.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15041/40960 [00:35<01:05, 395.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15124/40960 [00:35<01:04, 400.94batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15124/40960 [00:35<01:04, 400.94batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15209/40960 [00:36<01:03, 406.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15209/40960 [00:36<01:03, 406.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15278/40960 [00:36<01:06, 388.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15278/40960 [00:36<01:06, 388.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15351/40960 [00:36<01:07, 380.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15351/40960 [00:36<01:07, 380.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15432/40960 [00:36<01:05, 387.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15432/40960 [00:36<01:05, 387.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15516/40960 [00:36<01:04, 395.85batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15516/40960 [00:36<01:04, 395.85batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15593/40960 [00:37<01:04, 391.90batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15593/40960 [00:37<01:04, 391.90batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15673/40960 [00:37<01:04, 393.42batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15673/40960 [00:37<01:04, 393.42batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15754/40960 [00:37<01:03, 396.12batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15754/40960 [00:37<01:03, 396.12batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15830/40960 [00:37<01:04, 391.22batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15830/40960 [00:37<01:04, 391.22batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15903/40960 [00:37<01:05, 382.49batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15903/40960 [00:37<01:05, 382.49batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15978/40960 [00:38<01:05, 379.60batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15978/40960 [00:38<01:05, 379.60batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 16062/40960 [00:38<01:03, 391.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 16062/40960 [00:38<01:03, 391.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 16143/40960 [00:38<01:02, 395.41batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  39%|▍| 16143/40960 [00:38<01:02, 395.41batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16226/40960 [00:38<01:01, 400.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16226/40960 [00:38<01:01, 400.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16307/40960 [00:38<01:01, 401.34batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16307/40960 [00:38<01:01, 401.34batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16387/40960 [00:39<01:01, 399.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16387/40960 [00:39<01:01, 399.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16472/40960 [00:39<01:00, 406.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16472/40960 [00:39<01:00, 406.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16552/40960 [00:39<01:00, 403.27batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16552/40960 [00:39<01:00, 403.27batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16635/40960 [00:39<00:59, 406.33batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16635/40960 [00:39<00:59, 406.33batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16715/40960 [00:39<01:00, 403.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16715/40960 [00:39<01:00, 403.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16797/40960 [00:40<00:59, 405.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16797/40960 [00:40<00:59, 405.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16879/40960 [00:40<00:59, 405.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16879/40960 [00:40<00:59, 405.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16959/40960 [00:40<00:59, 402.91batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16959/40960 [00:40<00:59, 402.91batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17044/40960 [00:40<00:58, 408.92batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17044/40960 [00:40<00:58, 408.92batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17123/40960 [00:40<00:58, 404.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17123/40960 [00:40<00:58, 404.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17204/40960 [00:41<00:58, 403.24batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17204/40960 [00:41<00:58, 403.24batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17287/40960 [00:41<00:58, 405.74batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17287/40960 [00:41<00:58, 405.74batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17369/40960 [00:41<00:58, 406.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17369/40960 [00:41<00:58, 406.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17452/40960 [00:41<00:57, 407.72batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17452/40960 [00:41<00:57, 407.72batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17530/40960 [00:41<00:58, 402.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17530/40960 [00:41<00:58, 402.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17615/40960 [00:42<00:57, 407.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17615/40960 [00:42<00:57, 407.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17696/40960 [00:42<00:57, 405.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17696/40960 [00:42<00:57, 405.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17778/40960 [00:42<00:56, 406.71batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  43%|▍| 17778/40960 [00:42<00:56, 406.71batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 17860/40960 [00:42<00:56, 406.91batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 17860/40960 [00:42<00:56, 406.91batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 17942/40960 [00:42<00:56, 406.57batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 17942/40960 [00:42<00:56, 406.57batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 18021/40960 [00:43<00:57, 402.13batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 18021/40960 [00:43<00:57, 402.13batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 18102/40960 [00:43<00:56, 401.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 18102/40960 [00:43<00:56, 401.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 18184/40960 [00:43<00:56, 404.14batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  44%|▍| 18184/40960 [00:43<00:56, 404.14batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18265/40960 [00:43<00:56, 403.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18265/40960 [00:43<00:56, 403.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18351/40960 [00:43<00:55, 410.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18351/40960 [00:43<00:55, 410.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18436/40960 [00:44<00:54, 414.16batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18436/40960 [00:44<00:54, 414.16batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18517/40960 [00:44<00:54, 409.99batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18517/40960 [00:44<00:54, 409.99batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18593/40960 [00:44<00:55, 399.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  45%|▍| 18593/40960 [00:44<00:55, 399.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 18670/40960 [00:44<00:56, 394.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 18670/40960 [00:44<00:56, 394.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 18751/40960 [00:44<00:55, 397.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 18751/40960 [00:44<00:55, 397.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 18839/40960 [00:45<00:53, 409.69batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 18839/40960 [00:45<00:53, 409.69batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 18923/40960 [00:45<00:53, 412.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 18923/40960 [00:45<00:53, 412.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 19004/40960 [00:45<00:53, 409.40batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  46%|▍| 19004/40960 [00:45<00:53, 409.40batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19088/40960 [00:45<00:53, 411.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19088/40960 [00:45<00:53, 411.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19167/40960 [00:45<00:53, 404.90batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19167/40960 [00:45<00:53, 404.90batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19246/40960 [00:46<00:54, 401.26batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19246/40960 [00:46<00:54, 401.26batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19327/40960 [00:46<00:53, 402.37batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19327/40960 [00:46<00:53, 402.37batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19412/40960 [00:46<00:52, 407.49batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  47%|▍| 19412/40960 [00:46<00:52, 407.49batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19480/40960 [00:46<00:55, 386.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19480/40960 [00:46<00:55, 386.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19555/40960 [00:46<00:56, 382.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19555/40960 [00:46<00:56, 382.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19636/40960 [00:47<00:54, 388.95batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19636/40960 [00:47<00:54, 388.95batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19718/40960 [00:47<00:53, 394.75batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19718/40960 [00:47<00:53, 394.75batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19797/40960 [00:47<00:53, 394.33batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  48%|▍| 19797/40960 [00:47<00:53, 394.33batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 19875/40960 [00:47<00:53, 392.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 19875/40960 [00:47<00:53, 392.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 19956/40960 [00:47<00:53, 395.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 19956/40960 [00:47<00:53, 395.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 20035/40960 [00:48<00:53, 394.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 20035/40960 [00:48<00:53, 394.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 20116/40960 [00:48<00:52, 396.46batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 20116/40960 [00:48<00:52, 396.46batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 20194/40960 [00:48<00:52, 394.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 20194/40960 [00:48<00:52, 394.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 20269/40960 [00:48<00:53, 388.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  49%|▍| 20269/40960 [00:48<00:53, 388.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▍| 20351/40960 [00:48<00:52, 393.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▍| 20351/40960 [00:48<00:52, 393.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▍| 20436/40960 [00:49<00:51, 402.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▍| 20436/40960 [00:49<00:51, 402.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▌| 20518/40960 [00:49<00:50, 404.36batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▌| 20518/40960 [00:49<00:50, 404.36batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▌| 20603/40960 [00:49<00:49, 410.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▌| 20603/40960 [00:49<00:49, 410.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▌| 20684/40960 [00:49<00:49, 408.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  50%|▌| 20684/40960 [00:49<00:49, 408.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  51%|▌| 20766/40960 [00:49<00:49, 408.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  51%|▌| 20766/40960 [00:49<00:49, 408.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  51%|▌| 20850/40960 [00:50<00:48, 410.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  51%|▌| 20850/40960 [00:50<00:48, 410.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  51%|▌| 20932/40960 [00:50<00:48, 409.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  51%|▌| 20932/40960 [00:50<00:48, 409.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  51%|▌| 21017/40960 [00:50<00:48, 412.74batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  51%|▌| 21017/40960 [00:50<00:48, 412.74batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21098/40960 [00:50<00:48, 409.41batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21098/40960 [00:50<00:48, 409.41batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21181/40960 [00:50<00:48, 409.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21181/40960 [00:50<00:48, 409.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21258/40960 [00:51<00:49, 401.77batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21258/40960 [00:51<00:49, 401.77batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21336/40960 [00:51<00:49, 397.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21336/40960 [00:51<00:49, 397.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21421/40960 [00:51<00:48, 404.55batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21421/40960 [00:51<00:48, 404.55batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21501/40960 [00:51<00:48, 402.22batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  52%|▌| 21501/40960 [00:51<00:48, 402.22batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  53%|▌| 21585/40960 [00:52<00:47, 406.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  53%|▌| 21585/40960 [00:52<00:47, 406.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  53%|▌| 21671/40960 [00:52<00:46, 411.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  53%|▌| 21671/40960 [00:52<00:46, 411.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  53%|▌| 21758/40960 [00:52<00:45, 418.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  53%|▌| 21758/40960 [00:52<00:45, 418.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  53%|▌| 21843/40960 [00:52<00:45, 420.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  53%|▌| 21843/40960 [00:52<00:45, 420.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 21931/40960 [00:52<00:44, 426.03batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 21931/40960 [00:52<00:44, 426.03batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 22013/40960 [00:53<00:44, 421.09batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 22013/40960 [00:53<00:44, 421.09batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 22090/40960 [00:53<00:46, 409.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 22090/40960 [00:53<00:46, 409.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 22167/40960 [00:53<00:46, 400.92batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 22167/40960 [00:53<00:46, 400.92batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 22246/40960 [00:53<00:46, 398.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  54%|▌| 22246/40960 [00:53<00:46, 398.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22331/40960 [00:53<00:45, 405.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22331/40960 [00:53<00:45, 405.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22416/40960 [00:54<00:45, 410.81batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22416/40960 [00:54<00:45, 410.81batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22502/40960 [00:54<00:44, 415.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22502/40960 [00:54<00:44, 415.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22585/40960 [00:54<00:44, 414.78batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22585/40960 [00:54<00:44, 414.78batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22672/40960 [00:54<00:43, 420.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  55%|▌| 22672/40960 [00:54<00:43, 420.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 22756/40960 [00:54<00:43, 419.37batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 22756/40960 [00:54<00:43, 419.37batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 22841/40960 [00:55<00:43, 420.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 22841/40960 [00:55<00:43, 420.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 22927/40960 [00:55<00:42, 421.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 22927/40960 [00:55<00:42, 421.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 23012/40960 [00:55<00:42, 421.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 23012/40960 [00:55<00:42, 421.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 23098/40960 [00:55<00:42, 423.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  56%|▌| 23098/40960 [00:55<00:42, 423.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23181/40960 [00:55<00:42, 420.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23181/40960 [00:55<00:42, 420.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23260/40960 [00:56<00:42, 411.89batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23260/40960 [00:56<00:42, 411.89batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23344/40960 [00:56<00:42, 414.06batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23344/40960 [00:56<00:42, 414.06batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23420/40960 [00:56<00:43, 402.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23420/40960 [00:56<00:43, 402.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23501/40960 [00:56<00:43, 403.01batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  57%|▌| 23501/40960 [00:56<00:43, 403.01batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23579/40960 [00:56<00:43, 398.95batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23579/40960 [00:56<00:43, 398.95batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23659/40960 [00:57<00:43, 398.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23659/40960 [00:57<00:43, 398.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23743/40960 [00:57<00:42, 404.48batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23743/40960 [00:57<00:42, 404.48batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23823/40960 [00:57<00:42, 403.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23823/40960 [00:57<00:42, 403.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23909/40960 [00:57<00:41, 409.94batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  58%|▌| 23909/40960 [00:57<00:41, 409.94batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 23997/40960 [00:57<00:40, 417.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 23997/40960 [00:57<00:40, 417.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 24078/40960 [00:58<00:40, 412.68batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 24078/40960 [00:58<00:40, 412.68batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 24162/40960 [00:58<00:40, 414.16batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 24162/40960 [00:58<00:40, 414.16batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 24246/40960 [00:58<00:40, 415.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 24246/40960 [00:58<00:40, 415.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 24330/40960 [00:58<00:40, 415.00batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  59%|▌| 24330/40960 [00:58<00:40, 415.00batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24407/40960 [00:58<00:40, 405.36batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24407/40960 [00:58<00:40, 405.36batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24485/40960 [00:59<00:41, 399.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24485/40960 [00:59<00:41, 399.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24574/40960 [00:59<00:39, 411.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24574/40960 [00:59<00:39, 411.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24661/40960 [00:59<00:38, 417.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24661/40960 [00:59<00:38, 417.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24747/40960 [00:59<00:38, 420.16batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  60%|▌| 24747/40960 [00:59<00:38, 420.16batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 24817/40960 [00:59<00:40, 397.83batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 24817/40960 [00:59<00:40, 397.83batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 24895/40960 [01:00<00:40, 394.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 24895/40960 [01:00<00:40, 394.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 24981/40960 [01:00<00:39, 404.45batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 24981/40960 [01:00<00:39, 404.45batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 25068/40960 [01:00<00:38, 412.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 25068/40960 [01:00<00:38, 412.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 25152/40960 [01:00<00:38, 414.57batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  61%|▌| 25152/40960 [01:00<00:38, 414.57batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25235/40960 [01:00<00:38, 413.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25235/40960 [01:00<00:38, 413.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25311/40960 [01:01<00:38, 403.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25311/40960 [01:01<00:38, 403.02batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25390/40960 [01:01<00:38, 399.38batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25390/40960 [01:01<00:38, 399.38batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25478/40960 [01:01<00:37, 410.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25478/40960 [01:01<00:37, 410.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25563/40960 [01:01<00:37, 413.75batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  62%|▌| 25563/40960 [01:01<00:37, 413.75batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25649/40960 [01:01<00:36, 417.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25649/40960 [01:01<00:36, 417.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25738/40960 [01:02<00:35, 424.81batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25738/40960 [01:02<00:35, 424.81batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25821/40960 [01:02<00:35, 421.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25821/40960 [01:02<00:35, 421.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25906/40960 [01:02<00:35, 422.22batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25906/40960 [01:02<00:35, 422.22batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25978/40960 [01:02<00:37, 403.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  63%|▋| 25978/40960 [01:02<00:37, 403.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26050/40960 [01:02<00:38, 389.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26050/40960 [01:02<00:38, 389.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26133/40960 [01:03<00:37, 396.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26133/40960 [01:03<00:37, 396.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26211/40960 [01:03<00:37, 393.72batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26211/40960 [01:03<00:37, 393.72batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26297/40960 [01:03<00:36, 404.19batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26297/40960 [01:03<00:36, 404.19batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26377/40960 [01:03<00:36, 401.84batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  64%|▋| 26377/40960 [01:03<00:36, 401.84batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26462/40960 [01:03<00:35, 408.39batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26462/40960 [01:03<00:35, 408.39batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26547/40960 [01:04<00:34, 412.36batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26547/40960 [01:04<00:34, 412.36batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26626/40960 [01:04<00:35, 406.24batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26626/40960 [01:04<00:35, 406.24batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26707/40960 [01:04<00:35, 405.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26707/40960 [01:04<00:35, 405.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26793/40960 [01:04<00:34, 411.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  65%|▋| 26793/40960 [01:04<00:34, 411.56batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 26869/40960 [01:04<00:35, 401.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 26869/40960 [01:04<00:35, 401.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 26943/40960 [01:05<00:35, 391.89batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 26943/40960 [01:05<00:35, 391.89batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 27023/40960 [01:05<00:35, 394.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 27023/40960 [01:05<00:35, 394.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 27100/40960 [01:05<00:35, 391.00batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 27100/40960 [01:05<00:35, 391.00batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 27185/40960 [01:05<00:34, 400.67batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  66%|▋| 27185/40960 [01:05<00:34, 400.67batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27270/40960 [01:05<00:33, 407.85batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27270/40960 [01:05<00:33, 407.85batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27354/40960 [01:06<00:33, 410.85batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27354/40960 [01:06<00:33, 410.85batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27438/40960 [01:06<00:32, 413.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27438/40960 [01:06<00:32, 413.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27524/40960 [01:06<00:32, 417.42batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27524/40960 [01:06<00:32, 417.42batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27607/40960 [01:06<00:32, 415.69batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  67%|▋| 27607/40960 [01:06<00:32, 415.69batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 27688/40960 [01:06<00:32, 411.88batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 27688/40960 [01:06<00:32, 411.88batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 27771/40960 [01:07<00:31, 412.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 27771/40960 [01:07<00:31, 412.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 27854/40960 [01:07<00:31, 412.42batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 27854/40960 [01:07<00:31, 412.42batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 27939/40960 [01:07<00:31, 415.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 27939/40960 [01:07<00:31, 415.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 28023/40960 [01:07<00:31, 416.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  68%|▋| 28023/40960 [01:07<00:31, 416.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28110/40960 [01:07<00:30, 420.99batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28110/40960 [01:07<00:30, 420.99batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28198/40960 [01:08<00:29, 425.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28198/40960 [01:08<00:29, 425.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28280/40960 [01:08<00:30, 419.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28280/40960 [01:08<00:30, 419.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28367/40960 [01:08<00:29, 423.37batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28367/40960 [01:08<00:29, 423.37batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28450/40960 [01:08<00:29, 420.14batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  69%|▋| 28450/40960 [01:08<00:29, 420.14batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  70%|▋| 28535/40960 [01:08<00:29, 420.28batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  70%|▋| 28535/40960 [01:08<00:29, 420.28batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  70%|▋| 28621/40960 [01:09<00:29, 422.29batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  70%|▋| 28621/40960 [01:09<00:29, 422.29batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28705/40960 [01:09<00:29, 420.98batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  70%|▋| 28705/40960 [01:09<00:29, 420.98batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  70%|▋| 28792/40960 [01:09<00:28, 423.91batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  70%|▋| 28792/40960 [01:09<00:28, 423.91batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 28879/40960 [01:09<00:28, 426.09batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 28879/40960 [01:09<00:28, 426.09batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 28965/40960 [01:09<00:28, 427.12batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 28965/40960 [01:09<00:28, 427.12batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 29052/40960 [01:10<00:27, 428.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 29052/40960 [01:10<00:27, 428.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 29132/40960 [01:10<00:28, 419.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 29132/40960 [01:10<00:28, 419.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 29213/40960 [01:10<00:28, 414.91batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  71%|▋| 29213/40960 [01:10<00:28, 414.91batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29298/40960 [01:10<00:28, 416.41batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29298/40960 [01:10<00:28, 416.41batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29381/40960 [01:10<00:27, 415.34batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29381/40960 [01:10<00:27, 415.34batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29461/40960 [01:11<00:28, 410.04batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29461/40960 [01:11<00:28, 410.04batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29546/40960 [01:11<00:27, 414.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29546/40960 [01:11<00:27, 414.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29627/40960 [01:11<00:27, 410.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  72%|▋| 29627/40960 [01:11<00:27, 410.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 29706/40960 [01:11<00:27, 405.57batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 29706/40960 [01:11<00:27, 405.57batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 29790/40960 [01:11<00:27, 409.01batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 29790/40960 [01:11<00:27, 409.01batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 29872/40960 [01:12<00:27, 408.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 29872/40960 [01:12<00:27, 408.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 29955/40960 [01:12<00:26, 410.26batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 29955/40960 [01:12<00:26, 410.26batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 30038/40960 [01:12<00:26, 410.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  73%|▋| 30038/40960 [01:12<00:26, 410.53batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30118/40960 [01:12<00:26, 407.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30118/40960 [01:12<00:26, 407.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30197/40960 [01:12<00:26, 402.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30197/40960 [01:12<00:26, 402.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30276/40960 [01:13<00:26, 399.39batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30276/40960 [01:13<00:26, 399.39batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30362/40960 [01:13<00:25, 408.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30362/40960 [01:13<00:25, 408.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30443/40960 [01:13<00:25, 407.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  74%|▋| 30443/40960 [01:13<00:25, 407.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▋| 30524/40960 [01:13<00:25, 405.63batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▋| 30524/40960 [01:13<00:25, 405.63batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▋| 30606/40960 [01:13<00:25, 406.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▋| 30606/40960 [01:13<00:25, 406.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▋| 30688/40960 [01:14<00:25, 406.14batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▋| 30688/40960 [01:14<00:25, 406.14batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▊| 30775/40960 [01:14<00:24, 414.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▊| 30775/40960 [01:14<00:24, 414.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▊| 30859/40960 [01:14<00:24, 414.78batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  75%|▊| 30859/40960 [01:14<00:24, 414.78batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 30940/40960 [01:14<00:24, 411.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 30940/40960 [01:14<00:24, 411.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 31023/40960 [01:14<00:24, 411.95batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 31023/40960 [01:14<00:24, 411.95batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 31107/40960 [01:15<00:23, 413.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 31107/40960 [01:15<00:23, 413.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 31188/40960 [01:15<00:23, 410.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 31188/40960 [01:15<00:23, 410.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 31272/40960 [01:15<00:23, 412.05batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  76%|▊| 31272/40960 [01:15<00:23, 412.05batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31360/40960 [01:15<00:22, 418.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31360/40960 [01:15<00:22, 418.97batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31446/40960 [01:15<00:22, 421.34batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31446/40960 [01:15<00:22, 421.34batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31531/40960 [01:16<00:22, 421.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31531/40960 [01:16<00:22, 421.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31614/40960 [01:16<00:22, 418.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31614/40960 [01:16<00:22, 418.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31700/40960 [01:16<00:22, 420.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  77%|▊| 31700/40960 [01:16<00:22, 420.80batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 31784/40960 [01:16<00:21, 420.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 31784/40960 [01:16<00:21, 420.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 31870/40960 [01:16<00:21, 422.90batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 31870/40960 [01:16<00:21, 422.90batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 31954/40960 [01:17<00:21, 421.40batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 31954/40960 [01:17<00:21, 421.40batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 32037/40960 [01:17<00:21, 418.45batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 32037/40960 [01:17<00:21, 418.45batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 32119/40960 [01:17<00:21, 415.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  78%|▊| 32119/40960 [01:17<00:21, 415.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32205/40960 [01:17<00:20, 418.46batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32205/40960 [01:17<00:20, 418.46batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32290/40960 [01:17<00:20, 419.63batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32290/40960 [01:17<00:20, 419.63batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32376/40960 [01:18<00:20, 422.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|▊| 32376/40960 [01:18<00:20, 422.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32461/40960 [01:18<00:20, 422.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32461/40960 [01:18<00:20, 422.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32548/40960 [01:18<00:19, 425.42batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  79%|▊| 32548/40960 [01:18<00:19, 425.42batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32630/40960 [01:18<00:19, 419.38batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32630/40960 [01:18<00:19, 419.38batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32713/40960 [01:18<00:19, 416.77batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32713/40960 [01:18<00:19, 416.77batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32793/40960 [01:19<00:19, 411.77batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32793/40960 [01:19<00:19, 411.77batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32879/40960 [01:19<00:19, 417.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32879/40960 [01:19<00:19, 417.07batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32965/40960 [01:19<00:19, 419.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  80%|▊| 32965/40960 [01:19<00:19, 419.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  81%|▊| 33048/40960 [01:19<00:18, 417.74batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  81%|▊| 33048/40960 [01:19<00:18, 417.74batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  81%|▊| 33133/40960 [01:19<00:18, 419.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  81%|▊| 33133/40960 [01:19<00:18, 419.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  81%|▊| 33216/40960 [01:20<00:18, 417.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  81%|▊| 33216/40960 [01:20<00:18, 417.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  81%|▊| 33302/40960 [01:20<00:18, 420.08batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  81%|▊| 33302/40960 [01:20<00:18, 420.08batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33388/40960 [01:20<00:17, 421.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33388/40960 [01:20<00:17, 421.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33471/40960 [01:20<00:17, 419.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33471/40960 [01:20<00:17, 419.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33557/40960 [01:20<00:17, 421.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33557/40960 [01:20<00:17, 421.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33639/40960 [01:21<00:17, 416.84batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33639/40960 [01:21<00:17, 416.84batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33725/40960 [01:21<00:17, 419.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  82%|▊| 33725/40960 [01:21<00:17, 419.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33809/40960 [01:21<00:17, 419.19batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33809/40960 [01:21<00:17, 419.19batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33885/40960 [01:21<00:17, 407.40batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33885/40960 [01:21<00:17, 407.40batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33963/40960 [01:21<00:17, 401.30batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33963/40960 [01:21<00:17, 401.30batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 34043/40960 [01:22<00:17, 399.57batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 34043/40960 [01:22<00:17, 399.57batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 34125/40960 [01:22<00:17, 401.67batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  83%|▊| 34125/40960 [01:22<00:17, 401.67batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34207/40960 [01:22<00:16, 402.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34207/40960 [01:22<00:16, 402.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34288/40960 [01:22<00:16, 402.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34288/40960 [01:22<00:16, 402.93batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34371/40960 [01:22<00:16, 406.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34371/40960 [01:22<00:16, 406.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34455/40960 [01:23<00:15, 409.39batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34455/40960 [01:23<00:15, 409.39batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34539/40960 [01:23<00:15, 412.01batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  84%|▊| 34539/40960 [01:23<00:15, 412.01batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34616/40960 [01:23<00:15, 402.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34616/40960 [01:23<00:15, 402.70batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [01:23<00:15, 397.20batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [01:23<00:15, 397.20batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34775/40960 [01:23<00:15, 400.28batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34775/40960 [01:24<00:15, 400.28batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34856/40960 [01:24<00:15, 400.50batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34856/40960 [01:24<00:15, 400.50batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34938/40960 [01:24<00:14, 403.05batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  85%|▊| 34938/40960 [01:24<00:14, 403.05batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35025/40960 [01:24<00:14, 411.48batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35025/40960 [01:24<00:14, 411.48batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35107/40960 [01:24<00:14, 410.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35107/40960 [01:24<00:14, 410.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35191/40960 [01:25<00:13, 412.86batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35191/40960 [01:25<00:13, 412.86batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35272/40960 [01:25<00:13, 410.41batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35272/40960 [01:25<00:13, 410.41batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35354/40960 [01:25<00:13, 409.04batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  86%|▊| 35354/40960 [01:25<00:13, 409.04batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35432/40960 [01:25<00:13, 402.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35432/40960 [01:25<00:13, 402.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35514/40960 [01:25<00:13, 404.18batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35514/40960 [01:25<00:13, 404.18batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35598/40960 [01:26<00:13, 408.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35598/40960 [01:26<00:13, 408.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35684/40960 [01:26<00:12, 413.92batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35684/40960 [01:26<00:12, 413.92batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35770/40960 [01:26<00:12, 418.00batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  87%|▊| 35770/40960 [01:26<00:12, 418.00batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 35856/40960 [01:26<00:12, 420.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 35856/40960 [01:26<00:12, 420.32batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 35942/40960 [01:26<00:11, 421.88batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 35942/40960 [01:26<00:11, 421.88batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 36025/40960 [01:27<00:11, 418.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 36025/40960 [01:27<00:11, 418.66batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|▉| 36109/40960 [01:27<00:11, 418.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 36109/40960 [01:27<00:11, 418.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 36193/40960 [01:27<00:11, 417.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  88%|▉| 36193/40960 [01:27<00:11, 417.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36270/40960 [01:27<00:11, 408.09batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36270/40960 [01:27<00:11, 408.09batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36349/40960 [01:27<00:11, 403.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36349/40960 [01:27<00:11, 403.44batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36419/40960 [01:28<00:11, 387.21batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36419/40960 [01:28<00:11, 387.21batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36493/40960 [01:28<00:11, 380.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36493/40960 [01:28<00:11, 380.76batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36573/40960 [01:28<00:11, 386.30batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36573/40960 [01:28<00:11, 386.30batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36658/40960 [01:28<00:10, 397.19batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  89%|▉| 36658/40960 [01:28<00:10, 397.19batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  90%|▉| 36742/40960 [01:28<00:10, 403.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  90%|▉| 36742/40960 [01:28<00:10, 403.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  90%|▉| 36828/40960 [01:29<00:10, 410.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  90%|▉| 36828/40960 [01:29<00:10, 410.61batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  90%|▉| 36909/40960 [01:29<00:09, 408.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  90%|▉| 36909/40960 [01:29<00:09, 408.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  90%|▉| 36994/40960 [01:29<00:09, 413.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  90%|▉| 36994/40960 [01:29<00:09, 413.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [01:29<00:09, 402.87batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [01:29<00:09, 402.87batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37151/40960 [01:29<00:09, 402.72batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37151/40960 [01:29<00:09, 402.72batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37238/40960 [01:30<00:09, 411.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37238/40960 [01:30<00:09, 411.43batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37323/40960 [01:30<00:08, 414.20batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37323/40960 [01:30<00:08, 414.20batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37402/40960 [01:30<00:08, 407.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  91%|▉| 37402/40960 [01:30<00:08, 407.35batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37484/40960 [01:30<00:08, 407.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37484/40960 [01:30<00:08, 407.47batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37566/40960 [01:30<00:08, 407.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37566/40960 [01:30<00:08, 407.15batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37646/40960 [01:31<00:08, 403.87batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37646/40960 [01:31<00:08, 403.87batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37728/40960 [01:31<00:07, 405.37batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37728/40960 [01:31<00:07, 405.37batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37807/40960 [01:31<00:07, 400.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37807/40960 [01:31<00:07, 400.96batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37887/40960 [01:31<00:07, 400.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  92%|▉| 37887/40960 [01:31<00:07, 400.10batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  93%|▉| 37973/40960 [01:31<00:07, 408.29batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  93%|▉| 37973/40960 [01:31<00:07, 408.29batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  93%|▉| 38057/40960 [01:32<00:07, 411.68batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  93%|▉| 38057/40960 [01:32<00:07, 411.68batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  93%|▉| 38136/40960 [01:32<00:06, 405.63batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  93%|▉| 38136/40960 [01:32<00:06, 405.63batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  93%|▉| 38218/40960 [01:32<00:06, 406.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  93%|▉| 38218/40960 [01:32<00:06, 406.25batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38305/40960 [01:32<00:06, 414.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38305/40960 [01:32<00:06, 414.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38385/40960 [01:32<00:06, 409.06batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38385/40960 [01:32<00:06, 409.06batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38461/40960 [01:33<00:06, 400.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38461/40960 [01:33<00:06, 400.31batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38543/40960 [01:33<00:06, 401.95batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38543/40960 [01:33<00:06, 401.95batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38628/40960 [01:33<00:05, 407.81batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  94%|▉| 38628/40960 [01:33<00:05, 407.81batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 38710/40960 [01:33<00:05, 407.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 38710/40960 [01:33<00:05, 407.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 38791/40960 [01:33<00:05, 406.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 38791/40960 [01:33<00:05, 406.23batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 38873/40960 [01:34<00:05, 407.04batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 38873/40960 [01:34<00:05, 407.04batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 38952/40960 [01:34<00:04, 402.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 38952/40960 [01:34<00:04, 402.62batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 39036/40960 [01:34<00:04, 407.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 39036/40960 [01:34<00:04, 407.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 39114/40960 [01:34<00:04, 401.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  95%|▉| 39114/40960 [01:34<00:04, 401.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39200/40960 [01:34<00:04, 409.29batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39200/40960 [01:34<00:04, 409.29batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39282/40960 [01:35<00:04, 408.69batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39282/40960 [01:35<00:04, 408.69batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39366/40960 [01:35<00:03, 411.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39366/40960 [01:35<00:03, 411.51batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39442/40960 [01:35<00:03, 401.13batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39442/40960 [01:35<00:03, 401.13batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39516/40960 [01:35<00:03, 391.78batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39516/40960 [01:35<00:03, 391.78batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39600/40960 [01:35<00:03, 400.16batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39600/40960 [01:35<00:03, 400.16batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39683/40960 [01:36<00:03, 403.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39683/40960 [01:36<00:03, 403.79batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39761/40960 [01:36<00:03, 399.54batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39761/40960 [01:36<00:03, 399.54batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39844/40960 [01:36<00:02, 403.87batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39844/40960 [01:36<00:02, 403.87batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39926/40960 [01:36<00:02, 404.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  97%|▉| 39926/40960 [01:36<00:02, 404.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40006/40960 [01:36<00:02, 403.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40006/40960 [01:36<00:02, 403.11batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40092/40960 [01:37<00:02, 409.88batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40092/40960 [01:37<00:02, 409.88batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40172/40960 [01:37<00:01, 406.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40172/40960 [01:37<00:01, 406.52batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40255/40960 [01:37<00:01, 407.65batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40255/40960 [01:37<00:01, 407.65batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40340/40960 [01:37<00:01, 412.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  98%|▉| 40340/40960 [01:37<00:01, 412.59batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40418/40960 [01:37<00:01, 404.74batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40418/40960 [01:37<00:01, 404.74batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40499/40960 [01:38<00:01, 404.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40499/40960 [01:38<00:01, 404.64batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40580/40960 [01:38<00:00, 404.08batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40580/40960 [01:38<00:00, 404.08batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40656/40960 [01:38<00:00, 396.78batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40656/40960 [01:38<00:00, 396.78batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40739/40960 [01:38<00:00, 401.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training:  99%|▉| 40739/40960 [01:38<00:00, 401.73batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training: 100%|▉| 40821/40960 [01:38<00:00, 403.65batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training: 100%|▉| 40821/40960 [01:38<00:00, 403.65batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training: 100%|▉| 40900/40960 [01:39<00:00, 400.05batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "Training: 100%|▉| 40900/40960 [01:39<00:00, 400.05batches/s, l2_loss: 0.0074 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 18:59:57.168825: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  23%|▏| 6/26 [10:35<35:40, 107.02s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 18:59:58.546191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:00:05.543431: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<19:29:37,  1.71s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<19:29:37,  1.71s/batches, l2_loss: 0.0169 - round_loss:\u001b[A\n",
      "Training:   0%| | 65/40960 [00:01<14:45, 46.18batches/s, l2_loss: 0.0169 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 65/40960 [00:01<14:45, 46.18batches/s, l2_loss: 0.0331 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 131/40960 [00:02<07:13, 94.10batches/s, l2_loss: 0.0331 - round_loss: \u001b[A\n",
      "Training:   0%| | 131/40960 [00:02<07:13, 94.10batches/s, l2_loss: 0.0273 - round_loss: \u001b[A\n",
      "Training:   0%| | 196/40960 [00:02<04:54, 138.64batches/s, l2_loss: 0.0273 - round_loss:\u001b[A\n",
      "Training:   0%| | 196/40960 [00:02<04:54, 138.64batches/s, l2_loss: 0.0287 - round_loss:\u001b[A\n",
      "Training:   1%| | 262/40960 [00:02<03:46, 179.99batches/s, l2_loss: 0.0287 - round_loss:\u001b[A\n",
      "Training:   1%| | 262/40960 [00:02<03:46, 179.99batches/s, l2_loss: 0.0273 - round_loss:\u001b[A\n",
      "Training:   1%| | 325/40960 [00:02<03:12, 211.46batches/s, l2_loss: 0.0273 - round_loss:\u001b[A\n",
      "Training:   1%| | 325/40960 [00:02<03:12, 211.46batches/s, l2_loss: 0.0258 - round_loss:\u001b[A\n",
      "Training:   1%| | 387/40960 [00:02<02:52, 235.34batches/s, l2_loss: 0.0258 - round_loss:\u001b[A\n",
      "Training:   1%| | 387/40960 [00:02<02:52, 235.34batches/s, l2_loss: 0.0274 - round_loss:\u001b[A\n",
      "Training:   1%| | 453/40960 [00:03<02:35, 260.12batches/s, l2_loss: 0.0274 - round_loss:\u001b[A\n",
      "Training:   1%| | 453/40960 [00:03<02:35, 260.12batches/s, l2_loss: 0.0276 - round_loss:\u001b[A\n",
      "Training:   1%| | 517/40960 [00:03<02:26, 276.15batches/s, l2_loss: 0.0276 - round_loss:\u001b[A\n",
      "Training:   1%| | 517/40960 [00:03<02:26, 276.15batches/s, l2_loss: 0.0274 - round_loss:\u001b[A\n",
      "Training:   1%| | 583/40960 [00:03<02:18, 291.20batches/s, l2_loss: 0.0274 - round_loss:\u001b[A\n",
      "Training:   1%| | 583/40960 [00:03<02:18, 291.20batches/s, l2_loss: 0.0276 - round_loss:\u001b[A\n",
      "Training:   2%| | 652/40960 [00:03<02:11, 306.26batches/s, l2_loss: 0.0276 - round_loss:\u001b[A\n",
      "Training:   2%| | 652/40960 [00:03<02:11, 306.26batches/s, l2_loss: 0.0273 - round_loss:\u001b[A\n",
      "Training:   2%| | 717/40960 [00:03<02:09, 310.72batches/s, l2_loss: 0.0273 - round_loss:\u001b[A\n",
      "Training:   2%| | 717/40960 [00:03<02:09, 310.72batches/s, l2_loss: 0.0272 - round_loss:\u001b[A\n",
      "Training:   2%| | 781/40960 [00:04<02:08, 312.37batches/s, l2_loss: 0.0272 - round_loss:\u001b[A\n",
      "Training:   2%| | 781/40960 [00:04<02:08, 312.37batches/s, l2_loss: 0.0274 - round_loss:\u001b[A\n",
      "Training:   2%| | 848/40960 [00:04<02:06, 317.93batches/s, l2_loss: 0.0274 - round_loss:\u001b[A\n",
      "Training:   2%| | 848/40960 [00:04<02:06, 317.93batches/s, l2_loss: 0.0274 - round_loss:\u001b[A\n",
      "Training:   2%| | 921/40960 [00:04<02:01, 330.61batches/s, l2_loss: 0.0274 - round_loss:\u001b[A\n",
      "Training:   2%| | 921/40960 [00:04<02:01, 330.61batches/s, l2_loss: 0.0273 - round_loss:\u001b[A\n",
      "Training:   2%| | 993/40960 [00:04<01:58, 338.31batches/s, l2_loss: 0.0273 - round_loss:\u001b[A\n",
      "Training:   2%| | 993/40960 [00:04<01:58, 338.31batches/s, l2_loss: 0.0277 - round_loss:\u001b[A\n",
      "Training:   3%| | 1066/40960 [00:04<01:55, 345.14batches/s, l2_loss: 0.0277 - round_loss\u001b[A\n",
      "Training:   3%| | 1066/40960 [00:04<01:55, 345.14batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   3%| | 1134/40960 [00:05<01:56, 342.41batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   3%| | 1134/40960 [00:05<01:56, 342.41batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   3%| | 1201/40960 [00:05<01:57, 339.21batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   3%| | 1201/40960 [00:05<01:57, 339.21batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   3%| | 1271/40960 [00:05<01:56, 341.55batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   3%| | 1271/40960 [00:05<01:56, 341.55batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   3%| | 1341/40960 [00:05<01:55, 342.80batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   3%| | 1341/40960 [00:05<01:55, 342.80batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   3%| | 1405/40960 [00:05<01:57, 335.61batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   3%| | 1405/40960 [00:05<01:57, 335.61batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   4%| | 1471/40960 [00:06<01:58, 333.89batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%| | 1471/40960 [00:06<01:58, 333.89batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   4%| | 1533/40960 [00:06<02:01, 325.44batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   4%| | 1533/40960 [00:06<02:01, 325.44batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   4%| | 1596/40960 [00:06<02:02, 322.32batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   4%| | 1596/40960 [00:06<02:02, 322.32batches/s, l2_loss: 0.0276 - round_loss\u001b[A\n",
      "Training:   4%| | 1657/40960 [00:06<02:04, 316.47batches/s, l2_loss: 0.0276 - round_loss\u001b[A\n",
      "Training:   4%| | 1657/40960 [00:06<02:04, 316.47batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   4%| | 1722/40960 [00:06<02:03, 318.11batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   4%| | 1722/40960 [00:06<02:03, 318.11batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   4%| | 1782/40960 [00:07<02:05, 312.20batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   4%| | 1782/40960 [00:07<02:05, 312.20batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   5%| | 1846/40960 [00:07<02:04, 313.56batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   5%| | 1846/40960 [00:07<02:04, 313.56batches/s, l2_loss: 0.0276 - round_loss\u001b[A\n",
      "Training:   5%| | 1918/40960 [00:07<01:59, 326.19batches/s, l2_loss: 0.0276 - round_loss\u001b[A\n",
      "Training:   5%| | 1918/40960 [00:07<01:59, 326.19batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   5%| | 1987/40960 [00:07<01:57, 330.33batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   5%| | 1987/40960 [00:07<01:57, 330.33batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   5%| | 2056/40960 [00:07<01:56, 333.67batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   5%| | 2056/40960 [00:07<01:56, 333.67batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   5%| | 2128/40960 [00:08<01:54, 340.33batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   5%| | 2128/40960 [00:08<01:54, 340.33batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   5%| | 2199/40960 [00:08<01:52, 344.68batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   5%| | 2199/40960 [00:08<01:52, 344.68batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   6%| | 2263/40960 [00:08<01:54, 336.91batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   6%| | 2263/40960 [00:08<01:54, 336.91batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:   6%| | 2321/40960 [00:08<02:00, 321.68batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:   6%| | 2321/40960 [00:08<02:00, 321.68batches/s, l2_loss: 0.0276 - round_loss\u001b[A\n",
      "Training:   6%| | 2389/40960 [00:08<01:58, 326.47batches/s, l2_loss: 0.0276 - round_loss\u001b[A\n",
      "Training:   6%| | 2389/40960 [00:08<01:58, 326.47batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   6%| | 2459/40960 [00:09<01:55, 332.40batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:   6%| | 2459/40960 [00:09<01:55, 332.40batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   6%| | 2527/40960 [00:09<01:54, 334.43batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   6%| | 2527/40960 [00:09<01:54, 334.43batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   6%| | 2595/40960 [00:09<01:54, 334.81batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   6%| | 2595/40960 [00:09<01:54, 334.81batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:   7%| | 2666/40960 [00:09<01:52, 340.51batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:   7%| | 2666/40960 [00:09<01:52, 340.51batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   7%| | 2732/40960 [00:09<01:53, 337.31batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   7%| | 2732/40960 [00:09<01:53, 337.31batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:   7%| | 2798/40960 [00:10<01:54, 333.84batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:   7%| | 2798/40960 [00:10<01:54, 333.84batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   7%| | 2862/40960 [00:10<01:55, 329.65batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   7%| | 2862/40960 [00:10<01:55, 329.65batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   7%| | 2923/40960 [00:10<01:58, 320.42batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   7%| | 2923/40960 [00:10<01:58, 320.42batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   7%| | 2995/40960 [00:10<01:54, 331.04batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   7%| | 2995/40960 [00:10<01:54, 331.04batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   7%| | 3058/40960 [00:10<01:56, 325.91batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   7%| | 3058/40960 [00:10<01:56, 325.91batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   8%| | 3124/40960 [00:11<01:55, 326.90batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   8%| | 3124/40960 [00:11<01:55, 326.90batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   8%| | 3191/40960 [00:11<01:54, 329.32batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   8%| | 3191/40960 [00:11<01:54, 329.32batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   8%| | 3259/40960 [00:11<01:53, 331.90batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   8%| | 3259/40960 [00:11<01:53, 331.90batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   8%| | 3327/40960 [00:11<01:52, 333.17batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   8%| | 3327/40960 [00:11<01:52, 333.17batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   8%| | 3394/40960 [00:11<01:53, 332.30batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   8%| | 3394/40960 [00:12<01:53, 332.30batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   8%| | 3464/40960 [00:12<01:51, 337.20batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:   8%| | 3464/40960 [00:12<01:51, 337.20batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3536/40960 [00:12<01:48, 343.45batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3536/40960 [00:12<01:48, 343.45batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3605/40960 [00:12<01:48, 343.30batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3605/40960 [00:12<01:48, 343.30batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3667/40960 [00:12<01:52, 332.73batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3667/40960 [00:12<01:52, 332.73batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3731/40960 [00:13<01:53, 327.58batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3731/40960 [00:13<01:53, 327.58batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3802/40960 [00:13<01:50, 335.05batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:   9%| | 3802/40960 [00:13<01:50, 335.05batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:   9%| | 3874/40960 [00:13<01:48, 342.48batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:   9%| | 3874/40960 [00:13<01:48, 342.48batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  10%| | 3938/40960 [00:13<01:50, 334.72batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  10%| | 3938/40960 [00:13<01:50, 334.72batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  10%| | 4002/40960 [00:13<01:52, 329.09batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  10%| | 4002/40960 [00:13<01:52, 329.09batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  10%| | 4064/40960 [00:14<01:54, 322.36batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  10%| | 4064/40960 [00:14<01:54, 322.36batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  10%| | 4129/40960 [00:14<01:54, 322.44batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  10%| | 4129/40960 [00:14<01:54, 322.44batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  10%| | 4200/40960 [00:14<01:50, 331.83batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  10%| | 4200/40960 [00:14<01:50, 331.83batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  10%| | 4272/40960 [00:14<01:47, 340.18batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  10%| | 4272/40960 [00:14<01:47, 340.18batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4327/40960 [00:14<01:54, 319.52batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4327/40960 [00:14<01:54, 319.52batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4388/40960 [00:15<01:56, 314.91batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4388/40960 [00:15<01:56, 314.91batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%| | 4458/40960 [00:15<01:52, 323.93batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4458/40960 [00:15<01:52, 323.93batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4523/40960 [00:15<01:52, 323.76batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4523/40960 [00:15<01:52, 323.76batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  11%| | 4594/40960 [00:15<01:49, 331.94batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  11%| | 4594/40960 [00:15<01:49, 331.94batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4652/40960 [00:15<01:53, 318.74batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  11%| | 4652/40960 [00:15<01:53, 318.74batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  12%| | 4718/40960 [00:16<01:52, 320.91batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  12%| | 4718/40960 [00:16<01:52, 320.91batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  12%| | 4786/40960 [00:16<01:50, 326.08batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  12%| | 4786/40960 [00:16<01:50, 326.08batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  12%| | 4848/40960 [00:16<01:52, 320.52batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  12%| | 4848/40960 [00:16<01:52, 320.52batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  12%| | 4911/40960 [00:16<01:53, 318.86batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  12%| | 4911/40960 [00:16<01:53, 318.86batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  12%| | 4983/40960 [00:16<01:48, 330.12batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  12%| | 4983/40960 [00:16<01:48, 330.12batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  12%| | 5053/40960 [00:17<01:47, 335.10batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  12%| | 5053/40960 [00:17<01:47, 335.10batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5123/40960 [00:17<01:45, 339.21batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5123/40960 [00:17<01:45, 339.21batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5189/40960 [00:17<01:46, 336.00batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5189/40960 [00:17<01:46, 336.00batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5249/40960 [00:17<01:50, 324.35batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5249/40960 [00:17<01:50, 324.35batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5311/40960 [00:17<01:51, 319.55batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5311/40960 [00:17<01:51, 319.55batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5369/40960 [00:18<01:55, 309.01batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5369/40960 [00:18<01:55, 309.01batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5429/40960 [00:18<01:56, 305.87batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5429/40960 [00:18<01:56, 305.87batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5493/40960 [00:18<01:54, 309.80batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5493/40960 [00:18<01:54, 309.80batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5555/40960 [00:18<01:54, 309.00batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5555/40960 [00:18<01:54, 309.00batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5621/40960 [00:18<01:52, 314.32batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5621/40960 [00:18<01:52, 314.32batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5690/40960 [00:19<01:49, 322.22batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5690/40960 [00:19<01:49, 322.22batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5760/40960 [00:19<01:46, 329.76batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5760/40960 [00:19<01:46, 329.76batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5832/40960 [00:19<01:43, 338.24batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5832/40960 [00:19<01:43, 338.24batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5903/40960 [00:19<01:42, 342.45batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5903/40960 [00:19<01:42, 342.45batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5975/40960 [00:19<01:40, 347.63batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5975/40960 [00:19<01:40, 347.63batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6038/40960 [00:20<01:43, 336.49batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6038/40960 [00:20<01:43, 336.49batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6103/40960 [00:20<01:44, 333.06batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6103/40960 [00:20<01:44, 333.06batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6170/40960 [00:20<01:44, 332.80batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6170/40960 [00:20<01:44, 332.80batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6235/40960 [00:20<01:45, 330.28batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6235/40960 [00:20<01:45, 330.28batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6299/40960 [00:20<01:46, 326.02batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6299/40960 [00:20<01:46, 326.02batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6359/40960 [00:21<01:48, 318.24batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6359/40960 [00:21<01:48, 318.24batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:21<01:47, 321.64batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:21<01:47, 321.64batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6493/40960 [00:21<01:45, 326.58batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6493/40960 [00:21<01:45, 326.58batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6559/40960 [00:21<01:45, 326.33batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6559/40960 [00:21<01:45, 326.33batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6629/40960 [00:21<01:43, 332.91batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6629/40960 [00:21<01:43, 332.91batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6694/40960 [00:22<01:44, 328.76batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6694/40960 [00:22<01:44, 328.76batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6757/40960 [00:22<01:45, 324.35batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6757/40960 [00:22<01:45, 324.35batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6823/40960 [00:22<01:45, 325.03batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6823/40960 [00:22<01:45, 325.03batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6886/40960 [00:22<01:46, 320.96batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6886/40960 [00:22<01:46, 320.96batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6944/40960 [00:22<01:49, 311.34batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6944/40960 [00:22<01:49, 311.34batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7003/40960 [00:23<01:50, 306.21batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7003/40960 [00:23<01:50, 306.21batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7069/40960 [00:23<01:48, 313.05batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7069/40960 [00:23<01:48, 313.05batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7139/40960 [00:23<01:44, 323.30batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7139/40960 [00:23<01:44, 323.30batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7205/40960 [00:23<01:43, 325.05batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7205/40960 [00:23<01:43, 325.05batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7272/40960 [00:23<01:43, 326.90batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7272/40960 [00:23<01:43, 326.90batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7333/40960 [00:24<01:45, 320.26batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|▏| 7333/40960 [00:24<01:45, 320.26batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7397/40960 [00:24<01:45, 318.99batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7397/40960 [00:24<01:45, 318.99batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:24<01:42, 326.82batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:24<01:42, 326.82batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7534/40960 [00:24<01:41, 328.20batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7534/40960 [00:24<01:41, 328.20batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7604/40960 [00:24<01:39, 334.10batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7604/40960 [00:24<01:39, 334.10batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7672/40960 [00:25<01:39, 335.68batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7672/40960 [00:25<01:39, 335.68batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7737/40960 [00:25<01:40, 332.15batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7737/40960 [00:25<01:40, 332.15batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7802/40960 [00:25<01:40, 329.12batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7802/40960 [00:25<01:40, 329.12batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7865/40960 [00:25<01:41, 324.70batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7865/40960 [00:25<01:41, 324.70batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7931/40960 [00:25<01:41, 325.99batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7931/40960 [00:25<01:41, 325.99batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7995/40960 [00:26<01:41, 323.66batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7995/40960 [00:26<01:41, 323.66batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8062/40960 [00:26<01:40, 325.89batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8062/40960 [00:26<01:40, 325.89batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8133/40960 [00:26<01:38, 334.01batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8133/40960 [00:26<01:38, 334.01batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8203/40960 [00:26<01:36, 338.44batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8203/40960 [00:26<01:36, 338.44batches/s, l2_loss: 0.0172 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8265/40960 [00:26<01:39, 328.47batches/s, l2_loss: 0.0172 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8265/40960 [00:26<01:39, 328.47batches/s, l2_loss: 0.0248 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8325/40960 [00:27<01:42, 317.72batches/s, l2_loss: 0.0248 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8325/40960 [00:27<01:42, 317.72batches/s, l2_loss: 0.0282 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8381/40960 [00:27<01:47, 304.39batches/s, l2_loss: 0.0282 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8381/40960 [00:27<01:47, 304.39batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8446/40960 [00:27<01:44, 310.19batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8446/40960 [00:27<01:44, 310.19batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8508/40960 [00:27<01:44, 309.80batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8508/40960 [00:27<01:44, 309.80batches/s, l2_loss: 0.0276 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8567/40960 [00:27<01:46, 304.76batches/s, l2_loss: 0.0276 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8567/40960 [00:27<01:46, 304.76batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8631/40960 [00:28<01:44, 308.83batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8631/40960 [00:28<01:44, 308.83batches/s, l2_loss: 0.0268 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8696/40960 [00:28<01:43, 312.62batches/s, l2_loss: 0.0268 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8696/40960 [00:28<01:43, 312.62batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8759/40960 [00:28<01:43, 312.36batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8759/40960 [00:28<01:43, 312.36batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8816/40960 [00:28<01:45, 303.70batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8816/40960 [00:28<01:45, 303.70batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8874/40960 [00:28<01:48, 296.96batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8874/40960 [00:28<01:48, 296.96batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8932/40960 [00:29<01:48, 293.91batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8932/40960 [00:29<01:48, 293.91batches/s, l2_loss: 0.0269 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8998/40960 [00:29<01:45, 304.08batches/s, l2_loss: 0.0269 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8998/40960 [00:29<01:45, 304.08batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9059/40960 [00:29<01:45, 303.64batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9059/40960 [00:29<01:45, 303.64batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9116/40960 [00:29<01:47, 297.14batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9116/40960 [00:29<01:47, 297.14batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9174/40960 [00:29<01:48, 293.06batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9174/40960 [00:29<01:48, 293.06batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9230/40960 [00:30<01:49, 288.62batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9230/40960 [00:30<01:49, 288.62batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9291/40960 [00:30<01:48, 292.61batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9291/40960 [00:30<01:48, 292.61batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9347/40960 [00:30<01:50, 287.33batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9347/40960 [00:30<01:50, 287.33batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9400/40960 [00:30<01:52, 280.57batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9400/40960 [00:30<01:52, 280.57batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9461/40960 [00:30<01:49, 287.66batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9461/40960 [00:30<01:49, 287.66batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9527/40960 [00:31<01:44, 299.48batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9527/40960 [00:31<01:44, 299.48batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9590/40960 [00:31<01:43, 303.72batches/s, l2_loss: 0.0275 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9590/40960 [00:31<01:43, 303.72batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9657/40960 [00:31<01:40, 312.05batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9657/40960 [00:31<01:40, 312.05batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9720/40960 [00:31<01:39, 312.92batches/s, l2_loss: 0.0273 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9720/40960 [00:31<01:39, 312.92batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9784/40960 [00:31<01:39, 313.93batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9784/40960 [00:31<01:39, 313.93batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9846/40960 [00:32<01:39, 311.74batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9846/40960 [00:32<01:39, 311.74batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9913/40960 [00:32<01:37, 317.73batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9913/40960 [00:32<01:37, 317.73batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9973/40960 [00:32<01:39, 311.17batches/s, l2_loss: 0.0272 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9973/40960 [00:32<01:39, 311.17batches/s, l2_loss: 0.0271 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10029/40960 [00:32<01:42, 301.74batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  24%|▏| 10029/40960 [00:32<01:42, 301.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  25%|▏| 10081/40960 [00:32<01:46, 289.25batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  25%|▏| 10081/40960 [00:32<01:46, 289.25batches/s, l2_loss: 0.0272 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▏| 10145/40960 [00:33<01:43, 296.91batches/s, l2_loss: 0.0272 - round_los\u001b[A\n",
      "Training:  25%|▏| 10145/40960 [00:33<01:43, 296.91batches/s, l2_loss: 0.0272 - round_los\u001b[A\n",
      "Training:  25%|▏| 10210/40960 [00:33<01:40, 304.68batches/s, l2_loss: 0.0272 - round_los\u001b[A\n",
      "Training:  25%|▏| 10210/40960 [00:33<01:40, 304.68batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  25%|▎| 10278/40960 [00:33<01:37, 314.20batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  25%|▎| 10278/40960 [00:33<01:37, 314.20batches/s, l2_loss: 0.0273 - round_los\u001b[A\n",
      "Training:  25%|▎| 10342/40960 [00:33<01:37, 314.46batches/s, l2_loss: 0.0273 - round_los\u001b[A\n",
      "Training:  25%|▎| 10342/40960 [00:33<01:37, 314.46batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  25%|▎| 10404/40960 [00:33<01:37, 312.52batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  25%|▎| 10404/40960 [00:33<01:37, 312.52batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  26%|▎| 10464/40960 [00:34<01:38, 308.18batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  26%|▎| 10464/40960 [00:34<01:38, 308.18batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10523/40960 [00:34<01:40, 304.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10523/40960 [00:34<01:40, 304.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10589/40960 [00:34<01:37, 311.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10589/40960 [00:34<01:37, 311.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10652/40960 [00:34<01:37, 311.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10652/40960 [00:34<01:37, 311.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10714/40960 [00:34<01:37, 309.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10714/40960 [00:34<01:37, 309.81batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  26%|▎| 10767/40960 [00:35<01:42, 295.51batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  26%|▎| 10767/40960 [00:35<01:42, 295.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10829/40960 [00:35<01:40, 298.64batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  26%|▎| 10829/40960 [00:35<01:40, 298.64batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 10892/40960 [00:35<01:39, 302.46batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 10892/40960 [00:35<01:39, 302.46batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 10957/40960 [00:35<01:37, 308.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 10957/40960 [00:35<01:37, 308.72batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  27%|▎| 11018/40960 [00:35<01:37, 306.91batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  27%|▎| 11018/40960 [00:35<01:37, 306.91batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  27%|▎| 11077/40960 [00:36<01:38, 302.02batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  27%|▎| 11077/40960 [00:36<01:38, 302.02batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 11139/40960 [00:36<01:38, 303.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 11139/40960 [00:36<01:38, 303.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 11200/40960 [00:36<01:38, 303.61batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 11200/40960 [00:36<01:38, 303.61batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 11261/40960 [00:36<01:38, 302.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  27%|▎| 11261/40960 [00:36<01:38, 302.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  28%|▎| 11327/40960 [00:37<01:35, 310.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  28%|▎| 11327/40960 [00:37<01:35, 310.09batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  28%|▎| 11396/40960 [00:37<01:32, 319.34batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  28%|▎| 11396/40960 [00:37<01:32, 319.34batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  28%|▎| 11454/40960 [00:37<01:35, 309.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  28%|▎| 11454/40960 [00:37<01:35, 309.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  28%|▎| 11510/40960 [00:37<01:38, 299.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  28%|▎| 11510/40960 [00:37<01:38, 299.89batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  28%|▎| 11574/40960 [00:37<01:36, 305.49batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  28%|▎| 11574/40960 [00:37<01:36, 305.49batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  28%|▎| 11637/40960 [00:38<01:35, 306.85batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  28%|▎| 11637/40960 [00:38<01:35, 306.85batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  29%|▎| 11699/40960 [00:38<01:35, 306.48batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  29%|▎| 11699/40960 [00:38<01:35, 306.48batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  29%|▎| 11758/40960 [00:38<01:36, 301.55batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  29%|▎| 11758/40960 [00:38<01:36, 301.55batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  29%|▎| 11817/40960 [00:38<01:37, 299.45batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  29%|▎| 11817/40960 [00:38<01:37, 299.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  29%|▎| 11880/40960 [00:38<01:35, 303.06batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  29%|▎| 11880/40960 [00:38<01:35, 303.06batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  29%|▎| 11948/40960 [00:39<01:32, 312.88batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  29%|▎| 11948/40960 [00:39<01:32, 312.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  29%|▎| 12012/40960 [00:39<01:32, 313.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  29%|▎| 12012/40960 [00:39<01:32, 313.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  29%|▎| 12074/40960 [00:39<01:32, 312.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  29%|▎| 12074/40960 [00:39<01:32, 312.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  30%|▎| 12133/40960 [00:39<01:34, 305.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  30%|▎| 12133/40960 [00:39<01:34, 305.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  30%|▎| 12193/40960 [00:39<01:34, 303.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  30%|▎| 12193/40960 [00:39<01:34, 303.88batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  30%|▎| 12260/40960 [00:40<01:31, 312.91batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  30%|▎| 12260/40960 [00:40<01:31, 312.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  30%|▎| 12326/40960 [00:40<01:30, 317.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  30%|▎| 12326/40960 [00:40<01:30, 317.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  30%|▎| 12393/40960 [00:40<01:28, 321.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  30%|▎| 12393/40960 [00:40<01:28, 321.97batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  30%|▎| 12459/40960 [00:40<01:28, 322.95batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  30%|▎| 12459/40960 [00:40<01:28, 322.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  31%|▎| 12525/40960 [00:40<01:27, 323.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  31%|▎| 12525/40960 [00:40<01:27, 323.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  31%|▎| 12589/40960 [00:41<01:27, 322.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  31%|▎| 12589/40960 [00:41<01:27, 322.62batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  31%|▎| 12655/40960 [00:41<01:27, 323.74batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  31%|▎| 12655/40960 [00:41<01:27, 323.74batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  31%|▎| 12720/40960 [00:41<01:27, 323.69batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  31%|▎| 12720/40960 [00:41<01:27, 323.69batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  31%|▎| 12784/40960 [00:41<01:27, 322.43batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  31%|▎| 12784/40960 [00:41<01:27, 322.43batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  31%|▎| 12850/40960 [00:41<01:26, 324.25batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  31%|▎| 12850/40960 [00:41<01:26, 324.25batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 12915/40960 [00:42<01:26, 323.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 12915/40960 [00:42<01:26, 323.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 12979/40960 [00:42<01:27, 321.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 12979/40960 [00:42<01:27, 321.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 13045/40960 [00:42<01:26, 322.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 13045/40960 [00:42<01:26, 322.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 13110/40960 [00:42<01:26, 322.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 13110/40960 [00:42<01:26, 322.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 13175/40960 [00:42<01:26, 322.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 13175/40960 [00:42<01:26, 322.62batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  32%|▎| 13241/40960 [00:43<01:25, 323.97batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  32%|▎| 13241/40960 [00:43<01:25, 323.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 13307/40960 [00:43<01:24, 325.71batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  32%|▎| 13307/40960 [00:43<01:24, 325.71batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13371/40960 [00:43<01:25, 323.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13371/40960 [00:43<01:25, 323.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13438/40960 [00:43<01:24, 326.35batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13438/40960 [00:43<01:24, 326.35batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13498/40960 [00:43<01:26, 318.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13498/40960 [00:43<01:26, 318.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13557/40960 [00:44<01:28, 310.20batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13557/40960 [00:44<01:28, 310.20batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13618/40960 [00:44<01:28, 308.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  33%|▎| 13618/40960 [00:44<01:28, 308.27batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  33%|▎| 13679/40960 [00:44<01:28, 307.08batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  33%|▎| 13679/40960 [00:44<01:28, 307.08batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  34%|▎| 13748/40960 [00:44<01:25, 317.20batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  34%|▎| 13748/40960 [00:44<01:25, 317.20batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 13809/40960 [00:44<01:26, 313.47batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 13809/40960 [00:44<01:26, 313.47batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 13867/40960 [00:45<01:28, 305.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 13867/40960 [00:45<01:28, 305.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 13928/40960 [00:45<01:28, 304.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 13928/40960 [00:45<01:28, 304.32batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  34%|▎| 13992/40960 [00:45<01:27, 308.50batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  34%|▎| 13992/40960 [00:45<01:27, 308.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 14056/40960 [00:45<01:26, 311.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 14056/40960 [00:45<01:26, 311.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 14117/40960 [00:45<01:26, 309.10batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  34%|▎| 14117/40960 [00:45<01:26, 309.10batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14173/40960 [00:46<01:29, 299.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14173/40960 [00:46<01:29, 299.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14231/40960 [00:46<01:30, 295.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14231/40960 [00:46<01:30, 295.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14287/40960 [00:46<01:31, 290.70batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14287/40960 [00:46<01:31, 290.70batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14346/40960 [00:46<01:31, 290.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14346/40960 [00:46<01:31, 290.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14410/40960 [00:46<01:28, 298.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14410/40960 [00:46<01:28, 298.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14469/40960 [00:47<01:29, 296.12batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14469/40960 [00:47<01:29, 296.12batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14535/40960 [00:47<01:26, 305.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  35%|▎| 14535/40960 [00:47<01:26, 305.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  36%|▎| 14596/40960 [00:47<01:26, 304.31batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  36%|▎| 14596/40960 [00:47<01:26, 304.31batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  36%|▎| 14654/40960 [00:47<01:27, 299.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  36%|▎| 14654/40960 [00:47<01:27, 299.94batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  36%|▎| 14713/40960 [00:47<01:28, 298.19batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  36%|▎| 14713/40960 [00:47<01:28, 298.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  36%|▎| 14773/40960 [00:48<01:27, 297.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  36%|▎| 14773/40960 [00:48<01:27, 297.65batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  36%|▎| 14834/40960 [00:48<01:27, 298.55batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  36%|▎| 14834/40960 [00:48<01:27, 298.55batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  36%|▎| 14891/40960 [00:48<01:28, 294.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  36%|▎| 14891/40960 [00:48<01:28, 294.32batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  37%|▎| 14952/40960 [00:48<01:27, 296.85batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  37%|▎| 14952/40960 [00:48<01:27, 296.85batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15016/40960 [00:48<01:25, 303.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15016/40960 [00:48<01:25, 303.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15077/40960 [00:49<01:25, 303.34batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15077/40960 [00:49<01:25, 303.34batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15140/40960 [00:49<01:24, 305.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15140/40960 [00:49<01:24, 305.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15203/40960 [00:49<01:23, 308.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15203/40960 [00:49<01:23, 308.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15265/40960 [00:49<01:23, 307.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15265/40960 [00:49<01:23, 307.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15326/40960 [00:49<01:23, 306.10batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  37%|▎| 15326/40960 [00:49<01:23, 306.10batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15391/40960 [00:50<01:22, 311.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15391/40960 [00:50<01:22, 311.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15452/40960 [00:50<01:22, 309.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15452/40960 [00:50<01:22, 309.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15507/40960 [00:50<01:25, 298.55batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15507/40960 [00:50<01:25, 298.55batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15563/40960 [00:50<01:26, 292.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15563/40960 [00:50<01:26, 292.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15629/40960 [00:50<01:23, 302.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15629/40960 [00:50<01:23, 302.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|▍| 15689/40960 [00:51<01:23, 301.71batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  38%|▍| 15689/40960 [00:51<01:23, 301.71batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  38%|▍| 15748/40960 [00:51<01:24, 299.21batches/s, l2_loss: 0.0271 - round_los\u001b[A\n",
      "Training:  38%|▍| 15748/40960 [00:51<01:24, 299.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 15811/40960 [00:51<01:22, 303.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 15811/40960 [00:51<01:22, 303.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 15874/40960 [00:51<01:21, 307.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 15874/40960 [00:51<01:21, 307.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 15940/40960 [00:51<01:19, 313.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 15940/40960 [00:51<01:19, 313.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 16003/40960 [00:52<01:19, 313.39batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 16003/40960 [00:52<01:19, 313.39batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 16067/40960 [00:52<01:19, 314.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 16067/40960 [00:52<01:19, 314.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 16130/40960 [00:52<01:19, 313.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  39%|▍| 16130/40960 [00:52<01:19, 313.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16192/40960 [00:52<01:19, 311.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16192/40960 [00:52<01:19, 311.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16254/40960 [00:52<01:19, 309.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16254/40960 [00:52<01:19, 309.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16318/40960 [00:53<01:18, 312.12batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16318/40960 [00:53<01:18, 312.12batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16379/40960 [00:53<01:19, 309.83batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16379/40960 [00:53<01:19, 309.83batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16441/40960 [00:53<01:19, 309.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16441/40960 [00:53<01:19, 309.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16506/40960 [00:53<01:18, 312.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16506/40960 [00:53<01:18, 312.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16564/40960 [00:53<01:19, 305.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  40%|▍| 16564/40960 [00:53<01:19, 305.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16628/40960 [00:54<01:18, 309.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16628/40960 [00:54<01:18, 309.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16688/40960 [00:54<01:19, 305.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16688/40960 [00:54<01:19, 305.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16751/40960 [00:54<01:18, 307.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16751/40960 [00:54<01:18, 307.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16814/40960 [00:54<01:18, 308.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16814/40960 [00:54<01:18, 308.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16874/40960 [00:54<01:19, 304.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16874/40960 [00:54<01:19, 304.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16937/40960 [00:55<01:18, 306.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16937/40960 [00:55<01:18, 306.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16998/40960 [00:55<01:18, 304.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  41%|▍| 16998/40960 [00:55<01:18, 304.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17061/40960 [00:55<01:17, 306.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17061/40960 [00:55<01:17, 306.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17124/40960 [00:55<01:17, 307.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17124/40960 [00:55<01:17, 307.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17190/40960 [00:55<01:15, 313.18batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17190/40960 [00:55<01:15, 313.18batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17250/40960 [00:56<01:16, 309.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17250/40960 [00:56<01:16, 309.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17314/40960 [00:56<01:15, 311.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17314/40960 [00:56<01:15, 311.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17375/40960 [00:56<01:16, 307.66batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  42%|▍| 17375/40960 [00:56<01:16, 307.66batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17426/40960 [00:56<01:20, 291.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17426/40960 [00:56<01:20, 291.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17490/40960 [00:56<01:18, 298.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17490/40960 [00:56<01:18, 298.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17552/40960 [00:57<01:17, 301.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17552/40960 [00:57<01:17, 301.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17614/40960 [00:57<01:17, 302.90batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17614/40960 [00:57<01:17, 302.90batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17675/40960 [00:57<01:16, 302.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17675/40960 [00:57<01:16, 302.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17735/40960 [00:57<01:17, 300.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17735/40960 [00:57<01:17, 300.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17798/40960 [00:57<01:16, 303.85batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  43%|▍| 17798/40960 [00:57<01:16, 303.85batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 17863/40960 [00:58<01:14, 308.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 17863/40960 [00:58<01:14, 308.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 17926/40960 [00:58<01:14, 309.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 17926/40960 [00:58<01:14, 309.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 17985/40960 [00:58<01:15, 305.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 17985/40960 [00:58<01:15, 305.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 18046/40960 [00:58<01:15, 304.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 18046/40960 [00:58<01:15, 304.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 18108/40960 [00:58<01:14, 306.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 18108/40960 [00:58<01:14, 306.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 18176/40960 [00:59<01:12, 315.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  44%|▍| 18176/40960 [00:59<01:12, 315.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18237/40960 [00:59<01:12, 312.20batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18237/40960 [00:59<01:12, 312.20batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18296/40960 [00:59<01:14, 305.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18296/40960 [00:59<01:14, 305.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18360/40960 [00:59<01:12, 309.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18360/40960 [00:59<01:12, 309.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18427/40960 [00:59<01:11, 316.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 18427/40960 [00:59<01:11, 316.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18488/40960 [01:00<01:12, 312.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18488/40960 [01:00<01:12, 312.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18550/40960 [01:00<01:12, 310.70batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18550/40960 [01:00<01:12, 310.70batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18599/40960 [01:00<01:17, 289.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  45%|▍| 18599/40960 [01:00<01:17, 289.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18660/40960 [01:00<01:15, 293.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18660/40960 [01:00<01:15, 293.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18722/40960 [01:01<01:14, 297.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18722/40960 [01:01<01:14, 297.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18786/40960 [01:01<01:13, 303.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18786/40960 [01:01<01:13, 303.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18849/40960 [01:01<01:12, 306.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18849/40960 [01:01<01:12, 306.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18914/40960 [01:01<01:10, 311.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18914/40960 [01:01<01:10, 311.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18975/40960 [01:01<01:11, 308.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 18975/40960 [01:01<01:11, 308.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 19034/40960 [01:02<01:12, 303.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  46%|▍| 19034/40960 [01:02<01:12, 303.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19095/40960 [01:02<01:12, 303.61batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19095/40960 [01:02<01:12, 303.61batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19156/40960 [01:02<01:11, 303.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19156/40960 [01:02<01:11, 303.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19215/40960 [01:02<01:12, 300.63batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19215/40960 [01:02<01:12, 300.63batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19275/40960 [01:02<01:12, 299.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19275/40960 [01:02<01:12, 299.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19341/40960 [01:03<01:10, 307.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19341/40960 [01:03<01:10, 307.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19408/40960 [01:03<01:08, 314.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  47%|▍| 19408/40960 [01:03<01:08, 314.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19470/40960 [01:03<01:08, 312.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19470/40960 [01:03<01:08, 312.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19526/40960 [01:03<01:11, 301.69batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19526/40960 [01:03<01:11, 301.69batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19586/40960 [01:03<01:11, 300.68batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19586/40960 [01:03<01:11, 300.68batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19650/40960 [01:04<01:09, 306.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19650/40960 [01:04<01:09, 306.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19714/40960 [01:04<01:08, 310.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19714/40960 [01:04<01:08, 310.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19777/40960 [01:04<01:08, 310.61batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19777/40960 [01:04<01:08, 310.61batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19845/40960 [01:04<01:06, 318.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  48%|▍| 19845/40960 [01:04<01:06, 318.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 19905/40960 [01:04<01:07, 311.64batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 19905/40960 [01:04<01:07, 311.64batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 19955/40960 [01:05<01:11, 291.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 19955/40960 [01:05<01:11, 291.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 19998/40960 [01:05<01:18, 268.47batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 19998/40960 [01:05<01:18, 268.47batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 20057/40960 [01:05<01:15, 276.25batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 20057/40960 [01:05<01:15, 276.25batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 20123/40960 [01:05<01:11, 292.23batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 20123/40960 [01:05<01:11, 292.23batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 20190/40960 [01:05<01:08, 303.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 20190/40960 [01:05<01:08, 303.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 20259/40960 [01:06<01:05, 314.38batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  49%|▍| 20259/40960 [01:06<01:05, 314.38batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▍| 20324/40960 [01:06<01:05, 316.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▍| 20324/40960 [01:06<01:05, 316.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▍| 20379/40960 [01:06<01:07, 303.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▍| 20379/40960 [01:06<01:07, 303.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▍| 20437/40960 [01:06<01:08, 298.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▍| 20437/40960 [01:06<01:08, 298.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▌| 20495/40960 [01:06<01:09, 294.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▌| 20495/40960 [01:06<01:09, 294.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▌| 20552/40960 [01:07<01:10, 290.39batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▌| 20552/40960 [01:07<01:10, 290.39batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▌| 20610/40960 [01:07<01:10, 289.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▌| 20610/40960 [01:07<01:10, 289.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▌| 20670/40960 [01:07<01:09, 292.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  50%|▌| 20670/40960 [01:07<01:09, 292.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20735/40960 [01:07<01:07, 301.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20735/40960 [01:07<01:07, 301.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20796/40960 [01:07<01:06, 301.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20796/40960 [01:07<01:06, 301.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20854/40960 [01:08<01:07, 296.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20854/40960 [01:08<01:07, 296.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20918/40960 [01:08<01:06, 302.06batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20918/40960 [01:08<01:06, 302.06batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20984/40960 [01:08<01:04, 309.37batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 20984/40960 [01:08<01:04, 309.37batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 21049/40960 [01:08<01:03, 313.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  51%|▌| 21049/40960 [01:08<01:03, 313.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21111/40960 [01:08<01:03, 312.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21111/40960 [01:08<01:03, 312.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21164/40960 [01:09<01:06, 297.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21164/40960 [01:09<01:06, 297.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21218/40960 [01:09<01:08, 288.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21218/40960 [01:09<01:08, 288.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21283/40960 [01:09<01:05, 298.90batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21283/40960 [01:09<01:05, 298.90batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21350/40960 [01:09<01:03, 309.13batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21350/40960 [01:09<01:03, 309.13batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21415/40960 [01:09<01:02, 312.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21415/40960 [01:09<01:02, 312.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21474/40960 [01:10<01:03, 307.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  52%|▌| 21474/40960 [01:10<01:03, 307.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21531/40960 [01:10<01:04, 299.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21531/40960 [01:10<01:04, 299.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21587/40960 [01:10<01:06, 291.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21587/40960 [01:10<01:06, 291.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21645/40960 [01:10<01:06, 289.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21645/40960 [01:10<01:06, 289.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21709/40960 [01:10<01:04, 298.16batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21709/40960 [01:10<01:04, 298.16batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21770/40960 [01:11<01:04, 299.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21770/40960 [01:11<01:04, 299.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21830/40960 [01:11<01:03, 298.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21830/40960 [01:11<01:03, 298.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21892/40960 [01:11<01:03, 302.08batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  53%|▌| 21892/40960 [01:11<01:03, 302.08batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 21956/40960 [01:11<01:01, 307.22batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 21956/40960 [01:11<01:01, 307.22batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22012/40960 [01:11<01:03, 298.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22012/40960 [01:11<01:03, 298.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22071/40960 [01:12<01:03, 296.58batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22071/40960 [01:12<01:03, 296.58batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22128/40960 [01:12<01:04, 292.66batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22128/40960 [01:12<01:04, 292.66batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22186/40960 [01:12<01:04, 290.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22186/40960 [01:12<01:04, 290.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22251/40960 [01:12<01:02, 300.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22251/40960 [01:12<01:02, 300.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22318/40960 [01:12<01:00, 310.42batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  54%|▌| 22318/40960 [01:12<01:00, 310.42batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22380/40960 [01:13<00:59, 310.03batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22380/40960 [01:13<00:59, 310.03batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22440/40960 [01:13<01:00, 306.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22440/40960 [01:13<01:00, 306.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22503/40960 [01:13<00:59, 308.34batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22503/40960 [01:13<00:59, 308.34batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22568/40960 [01:13<00:58, 312.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22568/40960 [01:13<00:58, 312.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22632/40960 [01:13<00:58, 314.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22632/40960 [01:13<00:58, 314.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22699/40960 [01:14<00:57, 320.25batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  55%|▌| 22699/40960 [01:14<00:57, 320.25batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 22764/40960 [01:14<00:56, 321.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 22764/40960 [01:14<00:56, 321.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 22823/40960 [01:14<00:58, 312.17batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 22823/40960 [01:14<00:58, 312.17batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 22889/40960 [01:14<00:56, 317.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 22889/40960 [01:14<00:56, 317.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 22956/40960 [01:14<00:55, 321.71batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 22956/40960 [01:14<00:55, 321.71batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 23021/40960 [01:15<00:55, 322.13batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 23021/40960 [01:15<00:55, 322.13batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 23082/40960 [01:15<00:56, 315.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  56%|▌| 23082/40960 [01:15<00:56, 315.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23143/40960 [01:15<00:57, 311.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23143/40960 [01:15<00:57, 311.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23203/40960 [01:15<00:57, 307.04batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23203/40960 [01:15<00:57, 307.04batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23264/40960 [01:15<00:57, 305.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23264/40960 [01:15<00:57, 305.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23325/40960 [01:16<00:57, 304.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23325/40960 [01:16<00:57, 304.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23384/40960 [01:16<00:58, 300.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23384/40960 [01:16<00:58, 300.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23446/40960 [01:16<00:57, 303.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23446/40960 [01:16<00:57, 303.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23511/40960 [01:16<00:56, 308.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  57%|▌| 23511/40960 [01:16<00:56, 308.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23577/40960 [01:16<00:55, 314.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23577/40960 [01:16<00:55, 314.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23627/40960 [01:17<00:58, 295.02batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23627/40960 [01:17<00:58, 295.02batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23688/40960 [01:17<00:58, 296.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23688/40960 [01:17<00:58, 296.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23748/40960 [01:17<00:57, 296.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23748/40960 [01:17<00:57, 296.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23812/40960 [01:17<00:56, 303.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23812/40960 [01:17<00:56, 303.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23874/40960 [01:17<00:56, 303.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|▌| 23874/40960 [01:17<00:56, 303.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23940/40960 [01:18<00:54, 311.16batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  58%|▌| 23940/40960 [01:18<00:54, 311.16batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24006/40960 [01:18<00:53, 315.64batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24006/40960 [01:18<00:53, 315.64batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24072/40960 [01:18<00:52, 318.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24072/40960 [01:18<00:52, 318.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24137/40960 [01:18<00:52, 319.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24137/40960 [01:18<00:52, 319.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24189/40960 [01:18<00:55, 301.12batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24189/40960 [01:18<00:55, 301.12batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24238/40960 [01:19<00:59, 281.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24238/40960 [01:19<00:59, 281.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24298/40960 [01:19<00:58, 285.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24298/40960 [01:19<00:58, 285.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24355/40960 [01:19<00:58, 285.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  59%|▌| 24355/40960 [01:19<00:58, 285.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24418/40960 [01:19<00:56, 294.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24418/40960 [01:19<00:56, 294.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24484/40960 [01:19<00:54, 304.22batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24484/40960 [01:19<00:54, 304.22batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24545/40960 [01:20<00:54, 303.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24545/40960 [01:20<00:54, 303.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24590/40960 [01:20<00:58, 277.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24590/40960 [01:20<00:58, 277.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24646/40960 [01:20<00:58, 277.47batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24646/40960 [01:20<00:58, 277.47batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24701/40960 [01:20<00:58, 275.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24701/40960 [01:20<00:58, 275.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24761/40960 [01:20<00:57, 282.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  60%|▌| 24761/40960 [01:20<00:57, 282.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [01:21<00:54, 294.12batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [01:21<00:54, 294.12batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 24886/40960 [01:21<00:54, 295.34batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 24886/40960 [01:21<00:54, 295.34batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 24942/40960 [01:21<00:55, 289.69batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 24942/40960 [01:21<00:55, 289.69batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 25001/40960 [01:21<00:54, 290.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 25001/40960 [01:21<00:54, 290.78batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 25058/40960 [01:21<00:55, 288.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 25058/40960 [01:21<00:55, 288.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 25119/40960 [01:22<00:54, 291.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 25119/40960 [01:22<00:54, 291.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 25180/40960 [01:22<00:53, 294.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  61%|▌| 25180/40960 [01:22<00:53, 294.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25239/40960 [01:22<00:53, 294.25batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25239/40960 [01:22<00:53, 294.25batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25301/40960 [01:22<00:52, 298.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25301/40960 [01:22<00:52, 298.94batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25368/40960 [01:22<00:50, 309.58batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25368/40960 [01:22<00:50, 309.58batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25433/40960 [01:23<00:49, 312.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25433/40960 [01:23<00:49, 312.57batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  62%|▌| 25487/40960 [01:23<00:51, 298.31batches/s, l2_loss: 0.0269 - round_los\u001b[A\n",
      "Training:  62%|▌| 25487/40960 [01:23<00:51, 298.31batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25531/40960 [01:23<00:56, 273.90batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25531/40960 [01:23<00:56, 273.90batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25593/40960 [01:23<00:54, 283.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  62%|▌| 25593/40960 [01:23<00:54, 283.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25653/40960 [01:24<00:53, 288.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25653/40960 [01:24<00:53, 288.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25715/40960 [01:24<00:51, 293.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25715/40960 [01:24<00:51, 293.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25782/40960 [01:24<00:49, 305.04batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25782/40960 [01:24<00:49, 305.04batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25846/40960 [01:24<00:48, 308.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25846/40960 [01:24<00:48, 308.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25912/40960 [01:24<00:47, 315.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25912/40960 [01:24<00:47, 315.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25978/40960 [01:25<00:46, 319.46batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  63%|▋| 25978/40960 [01:25<00:46, 319.46batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26039/40960 [01:25<00:47, 315.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26039/40960 [01:25<00:47, 315.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26092/40960 [01:25<00:49, 299.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26092/40960 [01:25<00:49, 299.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26146/40960 [01:25<00:51, 289.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26146/40960 [01:25<00:51, 289.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26209/40960 [01:25<00:49, 296.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26209/40960 [01:25<00:49, 296.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26263/40960 [01:26<00:51, 287.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26263/40960 [01:26<00:51, 287.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26326/40960 [01:26<00:49, 295.04batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26326/40960 [01:26<00:49, 295.04batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26387/40960 [01:26<00:49, 294.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  64%|▋| 26387/40960 [01:26<00:49, 294.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26451/40960 [01:26<00:48, 301.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26451/40960 [01:26<00:48, 301.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26512/40960 [01:26<00:47, 302.42batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26512/40960 [01:26<00:47, 302.42batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 26571/40960 [01:27<00:48, 299.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26571/40960 [01:27<00:48, 299.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26634/40960 [01:27<00:47, 302.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26634/40960 [01:27<00:47, 302.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26699/40960 [01:27<00:46, 308.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26699/40960 [01:27<00:46, 308.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26761/40960 [01:27<00:46, 308.14batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26761/40960 [01:27<00:46, 308.14batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26822/40960 [01:27<00:46, 307.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  65%|▋| 26822/40960 [01:27<00:46, 307.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 26878/40960 [01:28<00:47, 298.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 26878/40960 [01:28<00:47, 298.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 26938/40960 [01:28<00:47, 298.23batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 26938/40960 [01:28<00:47, 298.23batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 26998/40960 [01:28<00:46, 298.46batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 26998/40960 [01:28<00:46, 298.46batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 27061/40960 [01:28<00:46, 301.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 27061/40960 [01:28<00:46, 301.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 27126/40960 [01:28<00:44, 308.17batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 27126/40960 [01:28<00:44, 308.17batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 27191/40960 [01:29<00:44, 312.79batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  66%|▋| 27191/40960 [01:29<00:44, 312.79batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27254/40960 [01:29<00:43, 312.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27254/40960 [01:29<00:43, 312.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27309/40960 [01:29<00:45, 299.63batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27309/40960 [01:29<00:45, 299.63batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27370/40960 [01:29<00:45, 299.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27370/40960 [01:29<00:45, 299.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27434/40960 [01:29<00:44, 305.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27434/40960 [01:29<00:44, 305.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27496/40960 [01:30<00:44, 305.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27496/40960 [01:30<00:44, 305.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27558/40960 [01:30<00:43, 305.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27558/40960 [01:30<00:43, 305.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27618/40960 [01:30<00:44, 303.06batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  67%|▋| 27618/40960 [01:30<00:44, 303.06batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27677/40960 [01:30<00:44, 300.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27677/40960 [01:30<00:44, 300.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27741/40960 [01:30<00:43, 305.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27741/40960 [01:30<00:43, 305.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27801/40960 [01:31<00:43, 302.17batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27801/40960 [01:31<00:43, 302.17batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27857/40960 [01:31<00:44, 295.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27857/40960 [01:31<00:44, 295.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27914/40960 [01:31<00:44, 291.66batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27914/40960 [01:31<00:44, 291.66batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27978/40960 [01:31<00:43, 298.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 27978/40960 [01:31<00:43, 298.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 28043/40960 [01:31<00:42, 305.13batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  68%|▋| 28043/40960 [01:31<00:42, 305.13batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28103/40960 [01:32<00:42, 303.39batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28103/40960 [01:32<00:42, 303.39batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28169/40960 [01:32<00:41, 310.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28169/40960 [01:32<00:41, 310.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28232/40960 [01:32<00:40, 311.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28232/40960 [01:32<00:40, 311.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28294/40960 [01:32<00:40, 310.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28294/40960 [01:32<00:40, 310.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28361/40960 [01:32<00:39, 317.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28361/40960 [01:32<00:39, 317.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28427/40960 [01:33<00:39, 319.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  69%|▋| 28427/40960 [01:33<00:39, 319.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28486/40960 [01:33<00:40, 311.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28486/40960 [01:33<00:40, 311.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28546/40960 [01:33<00:40, 307.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28546/40960 [01:33<00:40, 307.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28606/40960 [01:33<00:40, 303.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28606/40960 [01:33<00:40, 303.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28663/40960 [01:33<00:41, 296.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28663/40960 [01:33<00:41, 296.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28728/40960 [01:34<00:40, 304.24batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28728/40960 [01:34<00:40, 304.24batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28788/40960 [01:34<00:40, 301.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28788/40960 [01:34<00:40, 301.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28851/40960 [01:34<00:39, 305.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  70%|▋| 28851/40960 [01:34<00:39, 305.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 28917/40960 [01:34<00:38, 311.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 28917/40960 [01:34<00:38, 311.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 28984/40960 [01:34<00:37, 317.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 28984/40960 [01:34<00:37, 317.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 29047/40960 [01:35<00:37, 316.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 29047/40960 [01:35<00:37, 316.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 29111/40960 [01:35<00:37, 316.70batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 29111/40960 [01:35<00:37, 316.70batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 29179/40960 [01:35<00:36, 322.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 29179/40960 [01:35<00:36, 322.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 29246/40960 [01:35<00:35, 326.08batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  71%|▋| 29246/40960 [01:35<00:35, 326.08batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29311/40960 [01:35<00:35, 325.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|▋| 29311/40960 [01:35<00:35, 325.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29379/40960 [01:36<00:35, 328.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29379/40960 [01:36<00:35, 328.81batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29445/40960 [01:36<00:35, 328.83batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29445/40960 [01:36<00:35, 328.83batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29506/40960 [01:36<00:35, 320.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29506/40960 [01:36<00:35, 320.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29570/40960 [01:36<00:35, 320.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29570/40960 [01:36<00:35, 320.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29631/40960 [01:36<00:36, 314.10batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29631/40960 [01:36<00:36, 314.10batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29684/40960 [01:37<00:37, 298.79batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  72%|▋| 29684/40960 [01:37<00:37, 298.79batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29742/40960 [01:37<00:38, 294.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29742/40960 [01:37<00:38, 294.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29806/40960 [01:37<00:37, 301.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29806/40960 [01:37<00:37, 301.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29868/40960 [01:37<00:36, 302.08batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29868/40960 [01:37<00:36, 302.08batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29925/40960 [01:37<00:37, 295.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29925/40960 [01:37<00:37, 295.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29984/40960 [01:38<00:37, 294.04batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 29984/40960 [01:38<00:37, 294.04batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 30041/40960 [01:38<00:37, 289.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 30041/40960 [01:38<00:37, 289.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 30098/40960 [01:38<00:37, 287.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  73%|▋| 30098/40960 [01:38<00:37, 287.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30160/40960 [01:38<00:36, 293.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30160/40960 [01:38<00:36, 293.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30221/40960 [01:38<00:36, 296.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30221/40960 [01:38<00:36, 296.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30289/40960 [01:39<00:34, 308.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30289/40960 [01:39<00:34, 308.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30348/40960 [01:39<00:34, 303.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30348/40960 [01:39<00:34, 303.88batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30406/40960 [01:39<00:35, 298.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30406/40960 [01:39<00:35, 298.60batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30468/40960 [01:39<00:34, 301.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  74%|▋| 30468/40960 [01:39<00:34, 301.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▋| 30526/40960 [01:39<00:35, 297.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▋| 30526/40960 [01:39<00:35, 297.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▋| 30586/40960 [01:40<00:34, 297.02batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▋| 30586/40960 [01:40<00:34, 297.02batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▋| 30640/40960 [01:40<00:35, 288.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▋| 30640/40960 [01:40<00:35, 288.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▋| 30692/40960 [01:40<00:36, 278.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▋| 30692/40960 [01:40<00:36, 278.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▊| 30760/40960 [01:40<00:34, 296.46batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▊| 30760/40960 [01:40<00:34, 296.46batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▊| 30826/40960 [01:40<00:33, 306.03batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▊| 30826/40960 [01:40<00:33, 306.03batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▊| 30892/40960 [01:41<00:32, 312.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  75%|▊| 30892/40960 [01:41<00:32, 312.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 30960/40960 [01:41<00:31, 319.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 30960/40960 [01:41<00:31, 319.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31028/40960 [01:41<00:30, 324.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31028/40960 [01:41<00:30, 324.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31096/40960 [01:41<00:30, 327.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31096/40960 [01:41<00:30, 327.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31150/40960 [01:41<00:31, 310.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31150/40960 [01:41<00:31, 310.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31201/40960 [01:42<00:33, 293.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31201/40960 [01:42<00:33, 293.82batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31268/40960 [01:42<00:31, 305.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  76%|▊| 31268/40960 [01:42<00:31, 305.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31336/40960 [01:42<00:30, 315.16batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31336/40960 [01:42<00:30, 315.16batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31405/40960 [01:42<00:29, 322.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31405/40960 [01:42<00:29, 322.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31470/40960 [01:42<00:29, 322.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31470/40960 [01:42<00:29, 322.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31538/40960 [01:43<00:28, 326.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31538/40960 [01:43<00:28, 326.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31595/40960 [01:43<00:29, 313.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31595/40960 [01:43<00:29, 313.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31651/40960 [01:43<00:30, 302.38batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31651/40960 [01:43<00:30, 302.38batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31716/40960 [01:43<00:29, 308.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  77%|▊| 31716/40960 [01:43<00:29, 308.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 31779/40960 [01:43<00:29, 309.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 31779/40960 [01:43<00:29, 309.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 31843/40960 [01:44<00:29, 312.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 31843/40960 [01:44<00:29, 312.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 31909/40960 [01:44<00:28, 316.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 31909/40960 [01:44<00:28, 316.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 31974/40960 [01:44<00:28, 318.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 31974/40960 [01:44<00:28, 318.27batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 32040/40960 [01:44<00:27, 321.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 32040/40960 [01:44<00:27, 321.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|▊| 32107/40960 [01:44<00:27, 324.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  78%|▊| 32107/40960 [01:45<00:27, 324.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32170/40960 [01:45<00:27, 320.69batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32170/40960 [01:45<00:27, 320.69batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32235/40960 [01:45<00:27, 320.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32235/40960 [01:45<00:27, 320.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32293/40960 [01:45<00:27, 310.73batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32293/40960 [01:45<00:27, 310.73batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32359/40960 [01:45<00:27, 316.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32359/40960 [01:45<00:27, 316.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32426/40960 [01:46<00:26, 320.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32426/40960 [01:46<00:26, 320.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32492/40960 [01:46<00:26, 322.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32492/40960 [01:46<00:26, 322.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32556/40960 [01:46<00:26, 321.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  79%|▊| 32556/40960 [01:46<00:26, 321.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32616/40960 [01:46<00:26, 314.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32616/40960 [01:46<00:26, 314.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32675/40960 [01:46<00:26, 308.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32675/40960 [01:46<00:26, 308.33batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32742/40960 [01:47<00:26, 315.84batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32742/40960 [01:47<00:26, 315.84batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32798/40960 [01:47<00:26, 303.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32798/40960 [01:47<00:26, 303.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32853/40960 [01:47<00:27, 294.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32853/40960 [01:47<00:27, 294.19batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32916/40960 [01:47<00:26, 299.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  80%|▊| 32916/40960 [01:47<00:26, 299.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 32978/40960 [01:47<00:26, 301.31batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 32978/40960 [01:47<00:26, 301.31batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33044/40960 [01:48<00:25, 309.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33044/40960 [01:48<00:25, 309.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33102/40960 [01:48<00:25, 303.22batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33102/40960 [01:48<00:25, 303.22batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33163/40960 [01:48<00:25, 302.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33163/40960 [01:48<00:25, 302.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33230/40960 [01:48<00:24, 312.14batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33230/40960 [01:48<00:24, 312.14batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33293/40960 [01:48<00:24, 312.14batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33293/40960 [01:48<00:24, 312.14batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33359/40960 [01:49<00:23, 316.83batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  81%|▊| 33359/40960 [01:49<00:23, 316.83batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33422/40960 [01:49<00:23, 315.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33422/40960 [01:49<00:23, 315.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33480/40960 [01:49<00:24, 306.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33480/40960 [01:49<00:24, 306.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33538/40960 [01:49<00:24, 301.42batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33538/40960 [01:49<00:24, 301.42batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33595/40960 [01:49<00:24, 295.36batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33595/40960 [01:49<00:24, 295.36batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33656/40960 [01:50<00:24, 298.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33656/40960 [01:50<00:24, 298.01batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33717/40960 [01:50<00:24, 300.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33717/40960 [01:50<00:24, 300.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33782/40960 [01:50<00:23, 306.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  82%|▊| 33782/40960 [01:50<00:23, 306.86batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 33849/40960 [01:50<00:22, 314.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 33849/40960 [01:50<00:22, 314.45batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 33913/40960 [01:50<00:22, 314.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 33913/40960 [01:50<00:22, 314.92batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 33980/40960 [01:51<00:21, 319.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 33980/40960 [01:51<00:21, 319.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 34045/40960 [01:51<00:21, 319.98batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 34045/40960 [01:51<00:21, 319.98batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 34103/40960 [01:51<00:22, 309.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 34103/40960 [01:51<00:22, 309.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 34162/40960 [01:51<00:22, 303.66batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  83%|▊| 34162/40960 [01:51<00:22, 303.66batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34227/40960 [01:51<00:21, 308.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34227/40960 [01:51<00:21, 308.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34289/40960 [01:52<00:21, 308.02batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34289/40960 [01:52<00:21, 308.02batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34356/40960 [01:52<00:20, 315.47batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34356/40960 [01:52<00:20, 315.47batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34422/40960 [01:52<00:20, 319.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34422/40960 [01:52<00:20, 319.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34488/40960 [01:52<00:20, 321.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34488/40960 [01:52<00:20, 321.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34547/40960 [01:52<00:20, 312.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34547/40960 [01:52<00:20, 312.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34607/40960 [01:53<00:20, 307.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  84%|▊| 34607/40960 [01:53<00:20, 307.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34664/40960 [01:53<00:21, 299.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34664/40960 [01:53<00:21, 299.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34719/40960 [01:53<00:21, 291.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34719/40960 [01:53<00:21, 291.97batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34777/40960 [01:53<00:21, 290.85batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34777/40960 [01:53<00:21, 290.85batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34841/40960 [01:53<00:20, 298.14batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34841/40960 [01:53<00:20, 298.14batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34900/40960 [01:54<00:20, 296.00batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34900/40960 [01:54<00:20, 296.00batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34965/40960 [01:54<00:19, 303.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 34965/40960 [01:54<00:19, 303.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 35014/40960 [01:54<00:20, 285.58batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  85%|▊| 35014/40960 [01:54<00:20, 285.58batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35078/40960 [01:54<00:19, 294.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35078/40960 [01:54<00:19, 294.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35140/40960 [01:54<00:19, 298.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35140/40960 [01:54<00:19, 298.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35205/40960 [01:55<00:18, 305.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35205/40960 [01:55<00:18, 305.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35272/40960 [01:55<00:18, 312.84batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35272/40960 [01:55<00:18, 312.84batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35335/40960 [01:55<00:17, 312.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35335/40960 [01:55<00:17, 312.87batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35392/40960 [01:55<00:18, 304.16batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  86%|▊| 35392/40960 [01:55<00:18, 304.16batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35456/40960 [01:55<00:17, 307.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35456/40960 [01:55<00:17, 307.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35523/40960 [01:56<00:17, 315.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35523/40960 [01:56<00:17, 315.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35589/40960 [01:56<00:16, 318.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35589/40960 [01:56<00:16, 318.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35647/40960 [01:56<00:17, 309.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35647/40960 [01:56<00:17, 309.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35713/40960 [01:56<00:16, 315.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35713/40960 [01:56<00:16, 315.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35780/40960 [01:56<00:16, 320.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  87%|▊| 35780/40960 [01:56<00:16, 320.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 35841/40960 [01:57<00:16, 315.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 35841/40960 [01:57<00:16, 315.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 35907/40960 [01:57<00:15, 319.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 35907/40960 [01:57<00:15, 319.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 35960/40960 [01:57<00:16, 300.36batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 35960/40960 [01:57<00:16, 300.36batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 36012/40960 [01:57<00:17, 287.98batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 36012/40960 [01:57<00:17, 287.98batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 36078/40960 [01:57<00:16, 299.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 36078/40960 [01:57<00:16, 299.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 36144/40960 [01:58<00:15, 308.42batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 36144/40960 [01:58<00:15, 308.42batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 36205/40960 [01:58<00:15, 307.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  88%|▉| 36205/40960 [01:58<00:15, 307.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36271/40960 [01:58<00:14, 312.83batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36271/40960 [01:58<00:14, 312.83batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36336/40960 [01:58<00:14, 315.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36336/40960 [01:58<00:14, 315.93batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36402/40960 [01:58<00:14, 319.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36402/40960 [01:58<00:14, 319.80batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36463/40960 [01:59<00:14, 315.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36463/40960 [01:59<00:14, 315.05batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36526/40960 [01:59<00:14, 314.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36526/40960 [01:59<00:14, 314.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36587/40960 [01:59<00:14, 311.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36587/40960 [01:59<00:14, 311.29batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36633/40960 [01:59<00:15, 286.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  89%|▉| 36633/40960 [01:59<00:15, 286.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36693/40960 [01:59<00:14, 290.52batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36693/40960 [01:59<00:14, 290.52batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36756/40960 [02:00<00:14, 297.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36756/40960 [02:00<00:14, 297.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36818/40960 [02:00<00:13, 300.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36818/40960 [02:00<00:13, 300.30batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36879/40960 [02:00<00:13, 300.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36879/40960 [02:00<00:13, 300.41batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36948/40960 [02:00<00:12, 312.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 36948/40960 [02:00<00:12, 312.50batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 37004/40960 [02:00<00:13, 301.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 37004/40960 [02:00<00:13, 301.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 37062/40960 [02:01<00:13, 296.63batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  90%|▉| 37062/40960 [02:01<00:13, 296.63batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37128/40960 [02:01<00:12, 306.38batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37128/40960 [02:01<00:12, 306.38batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37186/40960 [02:01<00:12, 300.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37186/40960 [02:01<00:12, 300.32batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37244/40960 [02:01<00:12, 295.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37244/40960 [02:01<00:12, 295.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37310/40960 [02:01<00:11, 305.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37310/40960 [02:01<00:11, 305.44batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37375/40960 [02:02<00:11, 311.17batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37375/40960 [02:02<00:11, 311.17batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37434/40960 [02:02<00:11, 305.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  91%|▉| 37434/40960 [02:02<00:11, 305.96batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37493/40960 [02:02<00:11, 302.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37493/40960 [02:02<00:11, 302.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37559/40960 [02:02<00:10, 309.49batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37559/40960 [02:02<00:10, 309.49batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37616/40960 [02:02<00:11, 302.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37616/40960 [02:02<00:11, 302.15batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37673/40960 [02:03<00:11, 296.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37673/40960 [02:03<00:11, 296.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37736/40960 [02:03<00:10, 300.71batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37736/40960 [02:03<00:10, 300.71batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37798/40960 [02:03<00:10, 302.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37798/40960 [02:03<00:10, 302.51batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37859/40960 [02:03<00:10, 302.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  92%|▉| 37859/40960 [02:03<00:10, 302.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 37919/40960 [02:03<00:10, 300.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 37919/40960 [02:03<00:10, 300.89batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 37980/40960 [02:04<00:09, 301.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 37980/40960 [02:04<00:09, 301.28batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38036/40960 [02:04<00:09, 294.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38036/40960 [02:04<00:09, 294.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38091/40960 [02:04<00:09, 287.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38091/40960 [02:04<00:09, 287.95batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38152/40960 [02:04<00:09, 292.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38152/40960 [02:04<00:09, 292.57batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38218/40960 [02:04<00:09, 303.52batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38218/40960 [02:04<00:09, 303.52batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38275/40960 [02:05<00:09, 297.23batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  93%|▉| 38275/40960 [02:05<00:09, 297.23batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38331/40960 [02:05<00:09, 291.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38331/40960 [02:05<00:09, 291.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38390/40960 [02:05<00:08, 291.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38390/40960 [02:05<00:08, 291.67batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38452/40960 [02:05<00:08, 295.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38452/40960 [02:05<00:08, 295.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38515/40960 [02:05<00:08, 300.73batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38515/40960 [02:05<00:08, 300.73batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38567/40960 [02:06<00:08, 286.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38567/40960 [02:06<00:08, 286.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38625/40960 [02:06<00:08, 287.69batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38625/40960 [02:06<00:08, 287.69batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38684/40960 [02:06<00:07, 288.58batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  94%|▉| 38684/40960 [02:06<00:07, 288.58batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38744/40960 [02:06<00:07, 290.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38744/40960 [02:06<00:07, 290.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38803/40960 [02:06<00:07, 291.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38803/40960 [02:06<00:07, 291.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38863/40960 [02:07<00:07, 293.36batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38863/40960 [02:07<00:07, 293.36batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38918/40960 [02:07<00:07, 286.61batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38918/40960 [02:07<00:07, 286.61batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38975/40960 [02:07<00:06, 285.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 38975/40960 [02:07<00:06, 285.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 39039/40960 [02:07<00:06, 295.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 39039/40960 [02:07<00:06, 295.59batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 39104/40960 [02:07<00:06, 303.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  95%|▉| 39104/40960 [02:08<00:06, 303.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39169/40960 [02:08<00:05, 308.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39169/40960 [02:08<00:05, 308.48batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39226/40960 [02:08<00:05, 300.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39226/40960 [02:08<00:05, 300.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39285/40960 [02:08<00:05, 297.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39285/40960 [02:08<00:05, 297.91batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39350/40960 [02:08<00:05, 305.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39350/40960 [02:08<00:05, 305.77batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39416/40960 [02:09<00:04, 312.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39416/40960 [02:09<00:04, 312.43batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39482/40960 [02:09<00:04, 316.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  96%|▉| 39482/40960 [02:09<00:04, 316.72batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39547/40960 [02:09<00:04, 318.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39547/40960 [02:09<00:04, 318.76batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39613/40960 [02:09<00:04, 321.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39613/40960 [02:09<00:04, 321.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39678/40960 [02:09<00:03, 322.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39678/40960 [02:09<00:03, 322.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39739/40960 [02:10<00:03, 316.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39739/40960 [02:10<00:03, 316.56batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39802/40960 [02:10<00:03, 314.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39802/40960 [02:10<00:03, 314.74batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39868/40960 [02:10<00:03, 318.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39868/40960 [02:10<00:03, 318.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39931/40960 [02:10<00:03, 316.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  97%|▉| 39931/40960 [02:10<00:03, 316.21batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 39995/40960 [02:10<00:03, 316.31batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 39995/40960 [02:10<00:03, 316.31batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40051/40960 [02:11<00:02, 303.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40051/40960 [02:11<00:02, 303.99batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40114/40960 [02:11<00:02, 306.63batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40114/40960 [02:11<00:02, 306.63batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40177/40960 [02:11<00:02, 309.10batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40177/40960 [02:11<00:02, 309.10batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40241/40960 [02:11<00:02, 311.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40241/40960 [02:11<00:02, 311.53batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  98%|▉| 40300/40960 [02:11<00:02, 305.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40300/40960 [02:11<00:02, 305.09batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40352/40960 [02:12<00:02, 290.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40352/40960 [02:12<00:02, 290.62batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40413/40960 [02:12<00:01, 293.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40413/40960 [02:12<00:01, 293.65batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40475/40960 [02:12<00:01, 297.52batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40475/40960 [02:12<00:01, 297.52batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40537/40960 [02:12<00:01, 300.24batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40537/40960 [02:12<00:01, 300.24batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40602/40960 [02:12<00:01, 306.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40602/40960 [02:12<00:01, 306.40batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40668/40960 [02:13<00:00, 312.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40668/40960 [02:13<00:00, 312.54batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40732/40960 [02:13<00:00, 313.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training:  99%|▉| 40732/40960 [02:13<00:00, 313.07batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training: 100%|▉| 40795/40960 [02:13<00:00, 312.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training: 100%|▉| 40795/40960 [02:13<00:00, 312.75batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training: 100%|▉| 40862/40960 [02:13<00:00, 318.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training: 100%|▉| 40862/40960 [02:13<00:00, 318.11batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training: 100%|▉| 40922/40960 [02:13<00:00, 311.55batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "Training: 100%|▉| 40922/40960 [02:13<00:00, 311.55batches/s, l2_loss: 0.0270 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:02:18.247008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  27%|▎| 7/26 [12:57<37:32, 118.57s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 19:02:20.891967: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:02:23.592637: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                                | 1/40960 [00:00<9:41:27,  1.17batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<9:41:27,  1.17batches/s, l2_loss: 0.0139 - round_loss: \u001b[A\n",
      "Training:   0%| | 88/40960 [00:01<06:11, 109.90batches/s, l2_loss: 0.0139 - round_loss: \u001b[A\n",
      "Training:   0%| | 88/40960 [00:01<06:11, 109.90batches/s, l2_loss: 0.0208 - round_loss: \u001b[A\n",
      "Training:   0%| | 172/40960 [00:01<03:33, 191.45batches/s, l2_loss: 0.0208 - round_loss:\u001b[A\n",
      "Training:   0%| | 172/40960 [00:01<03:33, 191.45batches/s, l2_loss: 0.0259 - round_loss:\u001b[A\n",
      "Training:   1%| | 256/40960 [00:01<02:40, 253.29batches/s, l2_loss: 0.0259 - round_loss:\u001b[A\n",
      "Training:   1%| | 256/40960 [00:01<02:40, 253.29batches/s, l2_loss: 0.0236 - round_loss:\u001b[A\n",
      "Training:   1%| | 346/40960 [00:01<02:11, 308.39batches/s, l2_loss: 0.0236 - round_loss:\u001b[A\n",
      "Training:   1%| | 346/40960 [00:01<02:11, 308.39batches/s, l2_loss: 0.0240 - round_loss:\u001b[A\n",
      "Training:   1%| | 438/40960 [00:01<01:55, 351.01batches/s, l2_loss: 0.0240 - round_loss:\u001b[A\n",
      "Training:   1%| | 438/40960 [00:01<01:55, 351.01batches/s, l2_loss: 0.0228 - round_loss:\u001b[A\n",
      "Training:   1%| | 521/40960 [00:02<01:49, 369.22batches/s, l2_loss: 0.0228 - round_loss:\u001b[A\n",
      "Training:   1%| | 521/40960 [00:02<01:49, 369.22batches/s, l2_loss: 0.0234 - round_loss:\u001b[A\n",
      "Training:   1%| | 605/40960 [00:02<01:45, 382.90batches/s, l2_loss: 0.0234 - round_loss:\u001b[A\n",
      "Training:   1%| | 605/40960 [00:02<01:45, 382.90batches/s, l2_loss: 0.0239 - round_loss:\u001b[A\n",
      "Training:   2%| | 693/40960 [00:02<01:41, 398.68batches/s, l2_loss: 0.0239 - round_loss:\u001b[A\n",
      "Training:   2%| | 693/40960 [00:02<01:41, 398.68batches/s, l2_loss: 0.0233 - round_loss:\u001b[A\n",
      "Training:   2%| | 783/40960 [00:02<01:37, 413.65batches/s, l2_loss: 0.0233 - round_loss:\u001b[A\n",
      "Training:   2%| | 783/40960 [00:02<01:37, 413.65batches/s, l2_loss: 0.0234 - round_loss:\u001b[A\n",
      "Training:   2%| | 869/40960 [00:02<01:36, 417.31batches/s, l2_loss: 0.0234 - round_loss:\u001b[A\n",
      "Training:   2%| | 869/40960 [00:02<01:36, 417.31batches/s, l2_loss: 0.0231 - round_loss:\u001b[A\n",
      "Training:   2%| | 956/40960 [00:03<01:34, 421.29batches/s, l2_loss: 0.0231 - round_loss:\u001b[A\n",
      "Training:   2%| | 956/40960 [00:03<01:34, 421.29batches/s, l2_loss: 0.0238 - round_loss:\u001b[A\n",
      "Training:   3%| | 1037/40960 [00:03<01:35, 416.25batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:   3%| | 1037/40960 [00:03<01:35, 416.25batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:   3%| | 1118/40960 [00:03<01:36, 411.74batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:   3%| | 1118/40960 [00:03<01:36, 411.74batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   3%| | 1210/40960 [00:03<01:33, 424.90batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   3%| | 1210/40960 [00:03<01:33, 424.90batches/s, l2_loss: 0.0232 - round_loss\u001b[A\n",
      "Training:   3%| | 1304/40960 [00:03<01:30, 438.04batches/s, l2_loss: 0.0232 - round_loss\u001b[A\n",
      "Training:   3%| | 1304/40960 [00:03<01:30, 438.04batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:   3%| | 1391/40960 [00:04<01:30, 436.33batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:   3%| | 1391/40960 [00:04<01:30, 436.33batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   4%| | 1476/40960 [00:04<01:31, 432.18batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   4%| | 1476/40960 [00:04<01:31, 432.18batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   4%| | 1570/40960 [00:04<01:28, 443.32batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   4%| | 1570/40960 [00:04<01:28, 443.32batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   4%| | 1663/40960 [00:04<01:27, 449.20batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   4%| | 1663/40960 [00:04<01:27, 449.20batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   4%| | 1754/40960 [00:04<01:26, 450.84batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   4%| | 1754/40960 [00:04<01:26, 450.84batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   5%| | 1846/40960 [00:05<01:26, 453.06batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   5%| | 1846/40960 [00:05<01:26, 453.06batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:   5%| | 1939/40960 [00:05<01:25, 456.40batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:   5%| | 1939/40960 [00:05<01:25, 456.40batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:   5%| | 2032/40960 [00:05<01:25, 457.83batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:   5%| | 2032/40960 [00:05<01:25, 457.83batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   5%| | 2127/40960 [00:05<01:23, 462.89batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   5%| | 2127/40960 [00:05<01:23, 462.89batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:   5%| | 2222/40960 [00:05<01:23, 466.25batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:   5%| | 2222/40960 [00:05<01:23, 466.25batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   6%| | 2317/40960 [00:06<01:22, 467.80batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   6%| | 2317/40960 [00:06<01:22, 467.80batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   6%| | 2409/40960 [00:06<01:22, 464.69batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%| | 2409/40960 [00:06<01:22, 464.69batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   6%| | 2502/40960 [00:06<01:22, 463.63batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   6%| | 2502/40960 [00:06<01:22, 463.63batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   6%| | 2595/40960 [00:06<01:22, 463.59batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   6%| | 2595/40960 [00:06<01:22, 463.59batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   7%| | 2689/40960 [00:06<01:22, 465.03batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   7%| | 2689/40960 [00:06<01:22, 465.03batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   7%| | 2784/40960 [00:07<01:21, 466.84batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   7%| | 2784/40960 [00:07<01:21, 466.84batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   7%| | 2877/40960 [00:07<01:21, 465.00batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   7%| | 2877/40960 [00:07<01:21, 465.00batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:   7%| | 2969/40960 [00:07<01:21, 463.47batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:   7%| | 2969/40960 [00:07<01:21, 463.47batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:   7%| | 3061/40960 [00:07<01:22, 461.24batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:   7%| | 3061/40960 [00:07<01:22, 461.24batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   8%| | 3154/40960 [00:07<01:21, 461.60batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   8%| | 3154/40960 [00:07<01:21, 461.60batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   8%| | 3245/40960 [00:08<01:22, 459.58batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   8%| | 3245/40960 [00:08<01:22, 459.58batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   8%| | 3338/40960 [00:08<01:21, 461.07batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   8%| | 3338/40960 [00:08<01:21, 461.07batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   8%| | 3431/40960 [00:08<01:21, 461.84batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   8%| | 3431/40960 [00:08<01:21, 461.84batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   9%| | 3525/40960 [00:08<01:20, 463.43batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:   9%| | 3525/40960 [00:08<01:20, 463.43batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   9%| | 3620/40960 [00:08<01:20, 465.55batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   9%| | 3620/40960 [00:08<01:20, 465.55batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   9%| | 3714/40960 [00:09<01:19, 465.98batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   9%| | 3714/40960 [00:09<01:19, 465.98batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   9%| | 3809/40960 [00:09<01:19, 468.55batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:   9%| | 3809/40960 [00:09<01:19, 468.55batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  10%| | 3904/40960 [00:09<01:18, 469.53batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  10%| | 3904/40960 [00:09<01:18, 469.53batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  10%| | 3998/40960 [00:09<01:18, 468.23batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  10%| | 3998/40960 [00:09<01:18, 468.23batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  10%| | 4092/40960 [00:09<01:18, 467.96batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  10%| | 4092/40960 [00:09<01:18, 467.96batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  10%| | 4186/40960 [00:10<01:18, 468.27batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  10%| | 4186/40960 [00:10<01:18, 468.27batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:  10%| | 4280/40960 [00:10<01:18, 467.66batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:  10%| | 4280/40960 [00:10<01:18, 467.66batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  11%| | 4371/40960 [00:10<01:19, 462.50batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  11%| | 4371/40960 [00:10<01:19, 462.50batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  11%| | 4449/40960 [00:10<01:22, 440.20batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  11%| | 4449/40960 [00:10<01:22, 440.20batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  11%| | 4534/40960 [00:10<01:23, 434.80batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  11%| | 4534/40960 [00:10<01:23, 434.80batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  11%| | 4625/40960 [00:11<01:22, 440.20batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  11%| | 4625/40960 [00:11<01:22, 440.20batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:  12%| | 4711/40960 [00:11<01:23, 436.13batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:  12%| | 4711/40960 [00:11<01:23, 436.13batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  12%| | 4801/40960 [00:11<01:22, 439.56batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  12%| | 4801/40960 [00:11<01:22, 439.56batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  12%| | 4886/40960 [00:11<01:23, 434.60batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  12%| | 4886/40960 [00:11<01:23, 434.60batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  12%| | 4969/40960 [00:11<01:23, 428.71batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  12%| | 4969/40960 [00:11<01:23, 428.71batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  12%| | 5058/40960 [00:12<01:22, 433.10batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  12%| | 5058/40960 [00:12<01:22, 433.10batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5152/40960 [00:12<01:20, 443.74batches/s, l2_loss: 0.0236 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5152/40960 [00:12<01:20, 443.74batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5240/40960 [00:12<01:20, 442.55batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5240/40960 [00:12<01:20, 442.55batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5326/40960 [00:12<01:21, 438.75batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5326/40960 [00:12<01:21, 438.75batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5419/40960 [00:12<01:19, 446.05batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5419/40960 [00:12<01:19, 446.05batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5505/40960 [00:13<01:20, 440.39batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5505/40960 [00:13<01:20, 440.39batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5587/40960 [00:13<01:22, 430.14batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5587/40960 [00:13<01:22, 430.14batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5676/40960 [00:13<01:21, 433.59batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5676/40960 [00:13<01:21, 433.59batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5768/40960 [00:13<01:19, 441.27batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5768/40960 [00:13<01:19, 441.27batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5860/40960 [00:13<01:18, 445.92batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5860/40960 [00:13<01:18, 445.92batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5951/40960 [00:14<01:18, 448.01batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5951/40960 [00:14<01:18, 448.01batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6045/40960 [00:14<01:16, 453.58batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6045/40960 [00:14<01:16, 453.58batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6138/40960 [00:14<01:16, 456.08batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6138/40960 [00:14<01:16, 456.08batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6230/40960 [00:14<01:16, 456.09batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6230/40960 [00:14<01:16, 456.09batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6324/40960 [00:14<01:15, 459.54batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6324/40960 [00:14<01:15, 459.54batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6408/40960 [00:15<01:17, 446.72batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6408/40960 [00:15<01:17, 446.72batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|▏| 6494/40960 [00:15<01:18, 441.10batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6494/40960 [00:15<01:18, 441.10batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6587/40960 [00:15<01:16, 447.78batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6587/40960 [00:15<01:16, 447.78batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6678/40960 [00:15<01:16, 449.82batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6678/40960 [00:15<01:16, 449.82batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6772/40960 [00:15<01:15, 454.77batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6772/40960 [00:15<01:15, 454.77batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6867/40960 [00:16<01:14, 460.58batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6867/40960 [00:16<01:14, 460.58batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6960/40960 [00:16<01:13, 460.94batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6960/40960 [00:16<01:13, 460.94batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7046/40960 [00:16<01:15, 451.15batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7046/40960 [00:16<01:15, 451.15batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7132/40960 [00:16<01:16, 443.98batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7132/40960 [00:16<01:16, 443.98batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7224/40960 [00:16<01:15, 448.03batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7224/40960 [00:16<01:15, 448.03batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7310/40960 [00:17<01:16, 441.49batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7310/40960 [00:17<01:16, 441.49batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7394/40960 [00:17<01:17, 434.80batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7394/40960 [00:17<01:17, 434.80batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7485/40960 [00:17<01:15, 440.64batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7485/40960 [00:17<01:15, 440.64batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7575/40960 [00:17<01:15, 443.27batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7575/40960 [00:17<01:15, 443.27batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7668/40960 [00:17<01:14, 449.65batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7668/40960 [00:17<01:14, 449.65batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7762/40960 [00:18<01:12, 455.65batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7762/40960 [00:18<01:12, 455.65batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7847/40960 [00:18<01:14, 445.79batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7847/40960 [00:18<01:14, 445.79batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7930/40960 [00:18<01:15, 436.14batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7930/40960 [00:18<01:15, 436.14batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8020/40960 [00:18<01:14, 439.93batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8020/40960 [00:18<01:14, 439.93batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8113/40960 [00:18<01:13, 447.03batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8113/40960 [00:18<01:13, 447.03batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8204/40960 [00:19<01:12, 449.28batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8204/40960 [00:19<01:12, 449.28batches/s, l2_loss: 0.0214 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8287/40960 [00:19<01:14, 437.83batches/s, l2_loss: 0.0214 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8287/40960 [00:19<01:14, 437.83batches/s, l2_loss: 0.0258 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8371/40960 [00:19<01:15, 431.30batches/s, l2_loss: 0.0258 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8371/40960 [00:19<01:15, 431.30batches/s, l2_loss: 0.0226 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8458/40960 [00:19<01:15, 431.29batches/s, l2_loss: 0.0226 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8458/40960 [00:19<01:15, 431.29batches/s, l2_loss: 0.0231 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8543/40960 [00:19<01:15, 429.39batches/s, l2_loss: 0.0231 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8543/40960 [00:19<01:15, 429.39batches/s, l2_loss: 0.0232 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8621/40960 [00:20<01:17, 416.78batches/s, l2_loss: 0.0232 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8621/40960 [00:20<01:17, 416.78batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8698/40960 [00:20<01:19, 407.20batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8698/40960 [00:20<01:19, 407.20batches/s, l2_loss: 0.0231 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8778/40960 [00:20<01:19, 404.73batches/s, l2_loss: 0.0231 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8778/40960 [00:20<01:19, 404.73batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8858/40960 [00:20<01:19, 402.89batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8858/40960 [00:20<01:19, 402.89batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8934/40960 [00:20<01:21, 395.03batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8934/40960 [00:20<01:21, 395.03batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9010/40960 [00:21<01:21, 390.05batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9010/40960 [00:21<01:21, 390.05batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9094/40960 [00:21<01:20, 398.21batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9094/40960 [00:21<01:20, 398.21batches/s, l2_loss: 0.0233 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9180/40960 [00:21<01:18, 406.97batches/s, l2_loss: 0.0233 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9180/40960 [00:21<01:18, 406.97batches/s, l2_loss: 0.0228 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9268/40960 [00:21<01:16, 416.61batches/s, l2_loss: 0.0228 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9268/40960 [00:21<01:16, 416.61batches/s, l2_loss: 0.0231 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9345/40960 [00:21<01:17, 406.50batches/s, l2_loss: 0.0231 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9345/40960 [00:21<01:17, 406.50batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9421/40960 [00:22<01:19, 398.01batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9421/40960 [00:22<01:19, 398.01batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9496/40960 [00:22<01:20, 390.30batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9496/40960 [00:22<01:20, 390.30batches/s, l2_loss: 0.0233 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9570/40960 [00:22<01:21, 384.11batches/s, l2_loss: 0.0233 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9570/40960 [00:22<01:21, 384.11batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9647/40960 [00:22<01:21, 383.32batches/s, l2_loss: 0.0235 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9647/40960 [00:22<01:21, 383.32batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9729/40960 [00:22<01:19, 390.52batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9729/40960 [00:22<01:19, 390.52batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9812/40960 [00:23<01:18, 397.42batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9812/40960 [00:23<01:18, 397.42batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9895/40960 [00:23<01:17, 401.57batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9895/40960 [00:23<01:17, 401.57batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9977/40960 [00:23<01:16, 403.80batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9977/40960 [00:23<01:16, 403.80batches/s, l2_loss: 0.0233 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10058/40960 [00:23<01:16, 402.94batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  25%|▏| 10058/40960 [00:23<01:16, 402.94batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  25%|▏| 10140/40960 [00:23<01:16, 403.89batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  25%|▏| 10140/40960 [00:23<01:16, 403.89batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  25%|▏| 10221/40960 [00:24<01:16, 403.61batches/s, l2_loss: 0.0234 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▏| 10221/40960 [00:24<01:16, 403.61batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  25%|▎| 10305/40960 [00:24<01:15, 407.75batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  25%|▎| 10305/40960 [00:24<01:15, 407.75batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  25%|▎| 10390/40960 [00:24<01:14, 411.89batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  25%|▎| 10390/40960 [00:24<01:14, 411.89batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  26%|▎| 10474/40960 [00:24<01:13, 414.01batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  26%|▎| 10474/40960 [00:24<01:13, 414.01batches/s, l2_loss: 0.0235 - round_los\u001b[A\n",
      "Training:  26%|▎| 10557/40960 [00:24<01:13, 414.14batches/s, l2_loss: 0.0235 - round_los\u001b[A\n",
      "Training:  26%|▎| 10557/40960 [00:24<01:13, 414.14batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  26%|▎| 10640/40960 [00:25<01:13, 413.09batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  26%|▎| 10640/40960 [00:25<01:13, 413.09batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  26%|▎| 10722/40960 [00:25<01:13, 411.94batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  26%|▎| 10722/40960 [00:25<01:13, 411.94batches/s, l2_loss: 0.0232 - round_los\u001b[A\n",
      "Training:  26%|▎| 10801/40960 [00:25<01:14, 406.76batches/s, l2_loss: 0.0232 - round_los\u001b[A\n",
      "Training:  26%|▎| 10801/40960 [00:25<01:14, 406.76batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  27%|▎| 10875/40960 [00:25<01:16, 394.65batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  27%|▎| 10875/40960 [00:25<01:16, 394.65batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  27%|▎| 10956/40960 [00:25<01:15, 397.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  27%|▎| 10956/40960 [00:25<01:15, 397.52batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  27%|▎| 11041/40960 [00:26<01:13, 405.05batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  27%|▎| 11041/40960 [00:26<01:13, 405.05batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  27%|▎| 11114/40960 [00:26<01:16, 392.64batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  27%|▎| 11114/40960 [00:26<01:16, 392.64batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  27%|▎| 11191/40960 [00:26<01:16, 389.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  27%|▎| 11191/40960 [00:26<01:16, 389.93batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  28%|▎| 11274/40960 [00:26<01:14, 396.36batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  28%|▎| 11274/40960 [00:26<01:14, 396.36batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  28%|▎| 11358/40960 [00:26<01:13, 402.73batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  28%|▎| 11358/40960 [00:26<01:13, 402.73batches/s, l2_loss: 0.0235 - round_los\u001b[A\n",
      "Training:  28%|▎| 11442/40960 [00:27<01:12, 407.50batches/s, l2_loss: 0.0235 - round_los\u001b[A\n",
      "Training:  28%|▎| 11442/40960 [00:27<01:12, 407.50batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  28%|▎| 11526/40960 [00:27<01:11, 410.61batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  28%|▎| 11526/40960 [00:27<01:11, 410.61batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  28%|▎| 11611/40960 [00:27<01:10, 413.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  28%|▎| 11611/40960 [00:27<01:10, 413.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  29%|▎| 11694/40960 [00:27<01:10, 412.72batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  29%|▎| 11694/40960 [00:27<01:10, 412.72batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  29%|▎| 11779/40960 [00:27<01:10, 415.74batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  29%|▎| 11779/40960 [00:27<01:10, 415.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  29%|▎| 11865/40960 [00:28<01:09, 419.34batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  29%|▎| 11865/40960 [00:28<01:09, 419.34batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  29%|▎| 11951/40960 [00:28<01:08, 422.35batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  29%|▎| 11951/40960 [00:28<01:08, 422.35batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  29%|▎| 12037/40960 [00:28<01:08, 423.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  29%|▎| 12037/40960 [00:28<01:08, 423.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  30%|▎| 12114/40960 [00:28<01:10, 411.87batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  30%|▎| 12114/40960 [00:28<01:10, 411.87batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  30%|▎| 12192/40960 [00:28<01:11, 404.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  30%|▎| 12192/40960 [00:29<01:11, 404.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  30%|▎| 12274/40960 [00:29<01:10, 405.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  30%|▎| 12274/40960 [00:29<01:10, 405.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  30%|▎| 12348/40960 [00:29<01:12, 394.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  30%|▎| 12348/40960 [00:29<01:12, 394.92batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  30%|▎| 12425/40960 [00:29<01:12, 391.20batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  30%|▎| 12425/40960 [00:29<01:12, 391.20batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  31%|▎| 12503/40960 [00:29<01:13, 389.50batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  31%|▎| 12503/40960 [00:29<01:13, 389.50batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  31%|▎| 12584/40960 [00:30<01:12, 392.57batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  31%|▎| 12584/40960 [00:30<01:12, 392.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  31%|▎| 12659/40960 [00:30<01:13, 386.11batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  31%|▎| 12659/40960 [00:30<01:13, 386.11batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  31%|▎| 12734/40960 [00:30<01:13, 382.78batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  31%|▎| 12734/40960 [00:30<01:13, 382.78batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  31%|▎| 12809/40960 [00:30<01:14, 379.98batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  31%|▎| 12809/40960 [00:30<01:14, 379.98batches/s, l2_loss: 0.0235 - round_los\u001b[A\n",
      "Training:  31%|▎| 12881/40960 [00:30<01:15, 372.97batches/s, l2_loss: 0.0235 - round_los\u001b[A\n",
      "Training:  31%|▎| 12881/40960 [00:30<01:15, 372.97batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  32%|▎| 12963/40960 [00:31<01:12, 383.99batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  32%|▎| 12963/40960 [00:31<01:12, 383.99batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  32%|▎| 13049/40960 [00:31<01:10, 396.98batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  32%|▎| 13049/40960 [00:31<01:10, 396.98batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  32%|▎| 13119/40960 [00:31<01:12, 382.49batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  32%|▎| 13119/40960 [00:31<01:12, 382.49batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  32%|▎| 13195/40960 [00:31<01:12, 380.83batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  32%|▎| 13195/40960 [00:31<01:12, 380.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  32%|▎| 13276/40960 [00:31<01:11, 387.97batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  32%|▎| 13276/40960 [00:31<01:11, 387.97batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  33%|▎| 13361/40960 [00:32<01:09, 398.56batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  33%|▎| 13361/40960 [00:32<01:09, 398.56batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  33%|▎| 13443/40960 [00:32<01:08, 401.27batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  33%|▎| 13443/40960 [00:32<01:08, 401.27batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  33%|▎| 13528/40960 [00:32<01:07, 408.14batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  33%|▎| 13528/40960 [00:32<01:07, 408.14batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  33%|▎| 13613/40960 [00:32<01:06, 412.17batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  33%|▎| 13613/40960 [00:32<01:06, 412.17batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  33%|▎| 13696/40960 [00:32<01:06, 412.71batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  33%|▎| 13696/40960 [00:32<01:06, 412.71batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 13775/40960 [00:33<01:06, 406.18batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 13775/40960 [00:33<01:06, 406.18batches/s, l2_loss: 0.0234 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|▎| 13854/40960 [00:33<01:07, 401.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 13854/40960 [00:33<01:07, 401.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 13937/40960 [00:33<01:06, 404.25batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 13937/40960 [00:33<01:06, 404.25batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 14024/40960 [00:33<01:05, 412.07batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 14024/40960 [00:33<01:05, 412.07batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 14110/40960 [00:33<01:04, 417.03batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  34%|▎| 14110/40960 [00:33<01:04, 417.03batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  35%|▎| 14197/40960 [00:34<01:03, 421.72batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  35%|▎| 14197/40960 [00:34<01:03, 421.72batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  35%|▎| 14273/40960 [00:34<01:05, 409.00batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  35%|▎| 14273/40960 [00:34<01:05, 409.00batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  35%|▎| 14346/40960 [00:34<01:07, 394.29batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  35%|▎| 14346/40960 [00:34<01:07, 394.29batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  35%|▎| 14420/40960 [00:34<01:08, 386.82batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  35%|▎| 14420/40960 [00:34<01:08, 386.82batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  35%|▎| 14503/40960 [00:34<01:07, 393.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  35%|▎| 14503/40960 [00:34<01:07, 393.81batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  36%|▎| 14584/40960 [00:35<01:06, 396.65batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  36%|▎| 14584/40960 [00:35<01:06, 396.65batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  36%|▎| 14666/40960 [00:35<01:05, 399.58batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  36%|▎| 14666/40960 [00:35<01:05, 399.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  36%|▎| 14752/40960 [00:35<01:04, 407.64batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  36%|▎| 14752/40960 [00:35<01:04, 407.64batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  36%|▎| 14838/40960 [00:35<01:03, 413.82batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  36%|▎| 14838/40960 [00:35<01:03, 413.82batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  36%|▎| 14924/40960 [00:35<01:02, 418.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  36%|▎| 14924/40960 [00:35<01:02, 418.45batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  37%|▎| 15006/40960 [00:36<01:02, 415.58batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  37%|▎| 15006/40960 [00:36<01:02, 415.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  37%|▎| 15084/40960 [00:36<01:03, 407.54batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  37%|▎| 15084/40960 [00:36<01:03, 407.54batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  37%|▎| 15168/40960 [00:36<01:02, 410.84batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  37%|▎| 15168/40960 [00:36<01:02, 410.84batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  37%|▎| 15250/40960 [00:36<01:02, 409.63batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  37%|▎| 15250/40960 [00:36<01:02, 409.63batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  37%|▎| 15331/40960 [00:36<01:02, 407.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  37%|▎| 15331/40960 [00:36<01:02, 407.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  38%|▍| 15412/40960 [00:37<01:02, 405.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  38%|▍| 15412/40960 [00:37<01:02, 405.74batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  38%|▍| 15494/40960 [00:37<01:02, 405.74batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  38%|▍| 15494/40960 [00:37<01:02, 405.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  38%|▍| 15577/40960 [00:37<01:02, 408.33batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  38%|▍| 15577/40960 [00:37<01:02, 408.33batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  38%|▍| 15660/40960 [00:37<01:01, 409.53batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  38%|▍| 15660/40960 [00:37<01:01, 409.53batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  38%|▍| 15742/40960 [00:37<01:01, 409.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  38%|▍| 15742/40960 [00:37<01:01, 409.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  39%|▍| 15827/40960 [00:38<01:00, 413.72batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  39%|▍| 15827/40960 [00:38<01:00, 413.72batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  39%|▍| 15911/40960 [00:38<01:00, 414.73batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  39%|▍| 15911/40960 [00:38<01:00, 414.73batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  39%|▍| 15995/40960 [00:38<00:59, 416.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  39%|▍| 15995/40960 [00:38<00:59, 416.15batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  39%|▍| 16081/40960 [00:38<00:59, 419.89batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  39%|▍| 16081/40960 [00:38<00:59, 419.89batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  39%|▍| 16164/40960 [00:38<00:59, 418.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  39%|▍| 16164/40960 [00:38<00:59, 418.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  40%|▍| 16248/40960 [00:39<00:59, 418.25batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  40%|▍| 16248/40960 [00:39<00:59, 418.25batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  40%|▍| 16334/40960 [00:39<00:58, 421.67batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  40%|▍| 16334/40960 [00:39<00:58, 421.67batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  40%|▍| 16416/40960 [00:39<00:58, 417.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  40%|▍| 16416/40960 [00:39<00:58, 417.95batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  40%|▍| 16488/40960 [00:39<01:01, 400.46batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  40%|▍| 16488/40960 [00:39<01:01, 400.46batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  40%|▍| 16565/40960 [00:39<01:01, 394.55batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  40%|▍| 16565/40960 [00:39<01:01, 394.55batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  41%|▍| 16651/40960 [00:40<01:00, 404.18batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  41%|▍| 16651/40960 [00:40<01:00, 404.18batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  41%|▍| 16737/40960 [00:40<00:58, 410.75batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  41%|▍| 16737/40960 [00:40<00:58, 410.75batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  41%|▍| 16823/40960 [00:40<00:57, 416.29batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  41%|▍| 16823/40960 [00:40<00:57, 416.29batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  41%|▍| 16908/40960 [00:40<00:57, 418.22batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  41%|▍| 16908/40960 [00:40<00:57, 418.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  41%|▍| 16979/40960 [00:40<01:00, 399.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  41%|▍| 16979/40960 [00:40<01:00, 399.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  42%|▍| 17054/40960 [00:41<01:01, 391.50batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  42%|▍| 17054/40960 [00:41<01:01, 391.50batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  42%|▍| 17131/40960 [00:41<01:01, 388.13batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  42%|▍| 17131/40960 [00:41<01:01, 388.13batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  42%|▍| 17207/40960 [00:41<01:01, 384.66batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  42%|▍| 17207/40960 [00:41<01:01, 384.66batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  42%|▍| 17287/40960 [00:41<01:00, 388.77batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  42%|▍| 17287/40960 [00:41<01:00, 388.77batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  42%|▍| 17369/40960 [00:41<00:59, 393.67batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  42%|▍| 17369/40960 [00:41<00:59, 393.67batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  43%|▍| 17452/40960 [00:42<00:58, 399.49batches/s, l2_loss: 0.0234 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17452/40960 [00:42<00:58, 399.49batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  43%|▍| 17536/40960 [00:42<00:57, 404.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  43%|▍| 17536/40960 [00:42<00:57, 404.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  43%|▍| 17622/40960 [00:42<00:56, 410.98batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  43%|▍| 17622/40960 [00:42<00:56, 410.98batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  43%|▍| 17705/40960 [00:42<00:56, 411.75batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  43%|▍| 17705/40960 [00:42<00:56, 411.75batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  43%|▍| 17789/40960 [00:42<00:56, 413.49batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  43%|▍| 17789/40960 [00:42<00:56, 413.49batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  44%|▍| 17874/40960 [00:43<00:55, 416.24batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  44%|▍| 17874/40960 [00:43<00:55, 416.24batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  44%|▍| 17959/40960 [00:43<00:55, 417.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  44%|▍| 17959/40960 [00:43<00:55, 417.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  44%|▍| 18038/40960 [00:43<00:55, 409.66batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  44%|▍| 18038/40960 [00:43<00:55, 409.66batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  44%|▍| 18112/40960 [00:43<00:57, 397.80batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  44%|▍| 18112/40960 [00:43<00:57, 397.80batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  44%|▍| 18193/40960 [00:43<00:56, 399.95batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  44%|▍| 18193/40960 [00:43<00:56, 399.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18266/40960 [00:44<00:58, 389.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18266/40960 [00:44<00:58, 389.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18342/40960 [00:44<00:58, 385.10batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18342/40960 [00:44<00:58, 385.10batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18424/40960 [00:44<00:57, 391.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18424/40960 [00:44<00:57, 391.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18511/40960 [00:44<00:55, 403.53batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18511/40960 [00:44<00:55, 403.53batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18592/40960 [00:44<00:55, 402.55batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  45%|▍| 18592/40960 [00:44<00:55, 402.55batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  46%|▍| 18672/40960 [00:45<00:55, 401.68batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  46%|▍| 18672/40960 [00:45<00:55, 401.68batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  46%|▍| 18749/40960 [00:45<00:56, 396.37batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  46%|▍| 18749/40960 [00:45<00:56, 396.37batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  46%|▍| 18832/40960 [00:45<00:55, 400.86batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  46%|▍| 18832/40960 [00:45<00:55, 400.86batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  46%|▍| 18918/40960 [00:45<00:53, 409.33batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  46%|▍| 18918/40960 [00:45<00:53, 409.33batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  46%|▍| 18999/40960 [00:45<00:53, 407.32batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  46%|▍| 18999/40960 [00:45<00:53, 407.32batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  47%|▍| 19078/40960 [00:46<00:54, 402.57batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  47%|▍| 19078/40960 [00:46<00:54, 402.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  47%|▍| 19159/40960 [00:46<00:54, 402.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  47%|▍| 19159/40960 [00:46<00:54, 402.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  47%|▍| 19234/40960 [00:46<00:55, 393.85batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  47%|▍| 19234/40960 [00:46<00:55, 393.85batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  47%|▍| 19309/40960 [00:46<00:55, 387.45batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  47%|▍| 19309/40960 [00:46<00:55, 387.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  47%|▍| 19394/40960 [00:46<00:54, 398.21batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  47%|▍| 19394/40960 [00:46<00:54, 398.21batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  48%|▍| 19477/40960 [00:47<00:53, 402.99batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  48%|▍| 19477/40960 [00:47<00:53, 402.99batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  48%|▍| 19564/40960 [00:47<00:51, 411.88batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  48%|▍| 19564/40960 [00:47<00:51, 411.88batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  48%|▍| 19651/40960 [00:47<00:50, 417.90batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  48%|▍| 19651/40960 [00:47<00:50, 417.90batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  48%|▍| 19732/40960 [00:47<00:51, 413.65batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  48%|▍| 19732/40960 [00:47<00:51, 413.65batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  48%|▍| 19816/40960 [00:47<00:50, 415.11batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  48%|▍| 19816/40960 [00:47<00:50, 415.11batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 19897/40960 [00:48<00:51, 411.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 19897/40960 [00:48<00:51, 411.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 19975/40960 [00:48<00:51, 404.05batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 19975/40960 [00:48<00:51, 404.05batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 20055/40960 [00:48<00:51, 402.47batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 20055/40960 [00:48<00:51, 402.47batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 20125/40960 [00:48<00:53, 386.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 20125/40960 [00:48<00:53, 386.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 20202/40960 [00:48<00:53, 385.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  49%|▍| 20202/40960 [00:48<00:53, 385.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▍| 20289/40960 [00:49<00:51, 399.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▍| 20289/40960 [00:49<00:51, 399.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▍| 20377/40960 [00:49<00:50, 410.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▍| 20377/40960 [00:49<00:50, 410.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▍| 20458/40960 [00:49<00:50, 407.68batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▍| 20458/40960 [00:49<00:50, 407.68batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▌| 20538/40960 [00:49<00:50, 404.68batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▌| 20538/40960 [00:49<00:50, 404.68batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▌| 20620/40960 [00:49<00:50, 405.11batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  50%|▌| 20620/40960 [00:49<00:50, 405.11batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  51%|▌| 20697/40960 [00:50<00:50, 398.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  51%|▌| 20697/40960 [00:50<00:50, 398.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  51%|▌| 20776/40960 [00:50<00:50, 396.26batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  51%|▌| 20776/40960 [00:50<00:50, 396.26batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  51%|▌| 20859/40960 [00:50<00:50, 401.02batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  51%|▌| 20859/40960 [00:50<00:50, 401.02batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  51%|▌| 20938/40960 [00:50<00:50, 397.96batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  51%|▌| 20938/40960 [00:50<00:50, 397.96batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  51%|▌| 21020/40960 [00:50<00:49, 400.94batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  51%|▌| 21020/40960 [00:50<00:49, 400.94batches/s, l2_loss: 0.0234 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21104/40960 [00:51<00:48, 406.13batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21104/40960 [00:51<00:48, 406.13batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21184/40960 [00:51<00:48, 403.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21184/40960 [00:51<00:48, 403.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21261/40960 [00:51<00:49, 397.72batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21261/40960 [00:51<00:49, 397.72batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21342/40960 [00:51<00:49, 399.48batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21342/40960 [00:51<00:49, 399.48batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21420/40960 [00:51<00:49, 395.30batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21420/40960 [00:51<00:49, 395.30batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21496/40960 [00:52<00:49, 390.39batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  52%|▌| 21496/40960 [00:52<00:49, 390.39batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  53%|▌| 21579/40960 [00:52<00:48, 397.54batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  53%|▌| 21579/40960 [00:52<00:48, 397.54batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  53%|▌| 21664/40960 [00:52<00:47, 405.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  53%|▌| 21664/40960 [00:52<00:47, 405.59batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  53%|▌| 21750/40960 [00:52<00:46, 411.77batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  53%|▌| 21750/40960 [00:52<00:46, 411.77batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  53%|▌| 21837/40960 [00:52<00:45, 417.33batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  53%|▌| 21837/40960 [00:52<00:45, 417.33batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  54%|▌| 21919/40960 [00:53<00:45, 414.73batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  54%|▌| 21919/40960 [00:53<00:45, 414.73batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 21995/40960 [00:53<00:46, 404.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 21995/40960 [00:53<00:46, 404.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 22073/40960 [00:53<00:47, 399.17batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 22073/40960 [00:53<00:47, 399.17batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 22159/40960 [00:53<00:46, 408.03batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 22159/40960 [00:53<00:46, 408.03batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 22242/40960 [00:53<00:45, 410.00batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 22242/40960 [00:53<00:45, 410.00batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 22321/40960 [00:54<00:46, 404.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  54%|▌| 22321/40960 [00:54<00:46, 404.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  55%|▌| 22409/40960 [00:54<00:44, 414.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  55%|▌| 22409/40960 [00:54<00:44, 414.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  55%|▌| 22493/40960 [00:54<00:44, 415.35batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  55%|▌| 22493/40960 [00:54<00:44, 415.35batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  55%|▌| 22573/40960 [00:54<00:44, 410.71batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  55%|▌| 22573/40960 [00:54<00:44, 410.71batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  55%|▌| 22651/40960 [00:54<00:45, 403.73batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  55%|▌| 22651/40960 [00:54<00:45, 403.73batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  55%|▌| 22728/40960 [00:55<00:45, 397.08batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  55%|▌| 22728/40960 [00:55<00:45, 397.08batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  56%|▌| 22808/40960 [00:55<00:45, 396.38batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  56%|▌| 22808/40960 [00:55<00:45, 396.38batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  56%|▌| 22882/40960 [00:55<00:46, 388.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  56%|▌| 22882/40960 [00:55<00:46, 388.51batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  56%|▌| 22955/40960 [00:55<00:47, 380.88batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  56%|▌| 22955/40960 [00:55<00:47, 380.88batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  56%|▌| 23035/40960 [00:55<00:46, 385.99batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  56%|▌| 23035/40960 [00:55<00:46, 385.99batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  56%|▌| 23119/40960 [00:56<00:45, 395.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  56%|▌| 23119/40960 [00:56<00:45, 395.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  57%|▌| 23197/40960 [00:56<00:45, 392.99batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  57%|▌| 23197/40960 [00:56<00:45, 392.99batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  57%|▌| 23276/40960 [00:56<00:45, 392.78batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  57%|▌| 23276/40960 [00:56<00:45, 392.78batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  57%|▌| 23354/40960 [00:56<00:44, 391.29batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  57%|▌| 23354/40960 [00:56<00:44, 391.29batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  57%|▌| 23431/40960 [00:56<00:45, 389.06batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  57%|▌| 23431/40960 [00:56<00:45, 389.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  57%|▌| 23514/40960 [00:57<00:44, 395.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  57%|▌| 23514/40960 [00:57<00:44, 395.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  58%|▌| 23599/40960 [00:57<00:42, 404.44batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  58%|▌| 23599/40960 [00:57<00:42, 404.44batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  58%|▌| 23677/40960 [00:57<00:43, 398.69batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  58%|▌| 23677/40960 [00:57<00:43, 398.69batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  58%|▌| 23752/40960 [00:57<00:44, 390.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  58%|▌| 23752/40960 [00:57<00:44, 390.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  58%|▌| 23832/40960 [00:57<00:43, 392.30batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  58%|▌| 23832/40960 [00:57<00:43, 392.30batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  58%|▌| 23915/40960 [00:58<00:42, 398.65batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  58%|▌| 23915/40960 [00:58<00:42, 398.65batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  59%|▌| 24002/40960 [00:58<00:41, 408.57batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  59%|▌| 24002/40960 [00:58<00:41, 408.57batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  59%|▌| 24089/40960 [00:58<00:40, 415.98batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  59%|▌| 24089/40960 [00:58<00:40, 415.98batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  59%|▌| 24174/40960 [00:58<00:40, 417.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  59%|▌| 24174/40960 [00:58<00:40, 417.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  59%|▌| 24256/40960 [00:58<00:40, 414.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  59%|▌| 24256/40960 [00:58<00:40, 414.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  59%|▌| 24338/40960 [00:59<00:40, 412.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  59%|▌| 24338/40960 [00:59<00:40, 412.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  60%|▌| 24422/40960 [00:59<00:39, 413.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  60%|▌| 24422/40960 [00:59<00:39, 413.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  60%|▌| 24509/40960 [00:59<00:39, 419.50batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  60%|▌| 24509/40960 [00:59<00:39, 419.50batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  60%|▌| 24594/40960 [00:59<00:38, 420.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  60%|▌| 24594/40960 [00:59<00:38, 420.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  60%|▌| 24678/40960 [00:59<00:38, 419.98batches/s, l2_loss: 0.0234 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 24678/40960 [00:59<00:38, 419.98batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  60%|▌| 24765/40960 [01:00<00:38, 423.81batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  60%|▌| 24765/40960 [01:00<00:38, 423.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  61%|▌| 24850/40960 [01:00<00:38, 422.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  61%|▌| 24850/40960 [01:00<00:38, 422.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  61%|▌| 24932/40960 [01:00<00:38, 418.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  61%|▌| 24932/40960 [01:00<00:38, 418.74batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  61%|▌| 25016/40960 [01:00<00:38, 418.97batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  61%|▌| 25016/40960 [01:00<00:38, 418.97batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  61%|▌| 25101/40960 [01:00<00:37, 420.25batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  61%|▌| 25101/40960 [01:00<00:37, 420.25batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  61%|▌| 25185/40960 [01:01<00:37, 419.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  61%|▌| 25185/40960 [01:01<00:37, 419.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  62%|▌| 25270/40960 [01:01<00:37, 420.85batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  62%|▌| 25270/40960 [01:01<00:37, 420.85batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  62%|▌| 25356/40960 [01:01<00:36, 422.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  62%|▌| 25356/40960 [01:01<00:36, 422.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  62%|▌| 25442/40960 [01:01<00:36, 424.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  62%|▌| 25442/40960 [01:01<00:36, 424.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  62%|▌| 25528/40960 [01:01<00:36, 424.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  62%|▌| 25528/40960 [01:01<00:36, 424.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25613/40960 [01:02<00:36, 424.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25613/40960 [01:02<00:36, 424.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25694/40960 [01:02<00:36, 418.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25694/40960 [01:02<00:36, 418.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25767/40960 [01:02<00:37, 401.47batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25767/40960 [01:02<00:37, 401.47batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25848/40960 [01:02<00:37, 402.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25848/40960 [01:02<00:37, 402.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25931/40960 [01:02<00:37, 404.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  63%|▋| 25931/40960 [01:02<00:37, 404.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26016/40960 [01:03<00:36, 410.17batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26016/40960 [01:03<00:36, 410.17batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26101/40960 [01:03<00:35, 414.03batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26101/40960 [01:03<00:35, 414.03batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26178/40960 [01:03<00:36, 405.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26178/40960 [01:03<00:36, 405.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26258/40960 [01:03<00:36, 403.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26258/40960 [01:03<00:36, 403.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26337/40960 [01:03<00:36, 400.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26337/40960 [01:03<00:36, 400.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26419/40960 [01:04<00:36, 401.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  64%|▋| 26419/40960 [01:04<00:36, 401.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26493/40960 [01:04<00:36, 391.27batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26493/40960 [01:04<00:36, 391.27batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26569/40960 [01:04<00:37, 387.86batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26569/40960 [01:04<00:37, 387.86batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26651/40960 [01:04<00:36, 394.16batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26651/40960 [01:04<00:36, 394.16batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26728/40960 [01:05<00:36, 391.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26728/40960 [01:05<00:36, 391.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26813/40960 [01:05<00:35, 399.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  65%|▋| 26813/40960 [01:05<00:35, 399.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  66%|▋| 26898/40960 [01:05<00:34, 405.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  66%|▋| 26898/40960 [01:05<00:34, 405.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  66%|▋| 26969/40960 [01:05<00:35, 389.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  66%|▋| 26969/40960 [01:05<00:35, 389.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  66%|▋| 27039/40960 [01:05<00:36, 376.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  66%|▋| 27039/40960 [01:05<00:36, 376.46batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  66%|▋| 27122/40960 [01:06<00:35, 386.79batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  66%|▋| 27122/40960 [01:06<00:35, 386.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  66%|▋| 27205/40960 [01:06<00:34, 394.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  66%|▋| 27205/40960 [01:06<00:34, 394.95batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  67%|▋| 27285/40960 [01:06<00:34, 395.81batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  67%|▋| 27285/40960 [01:06<00:34, 395.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  67%|▋| 27367/40960 [01:06<00:34, 399.75batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  67%|▋| 27367/40960 [01:06<00:34, 399.75batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  67%|▋| 27451/40960 [01:06<00:33, 405.24batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  67%|▋| 27451/40960 [01:06<00:33, 405.24batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  67%|▋| 27535/40960 [01:07<00:32, 409.07batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  67%|▋| 27535/40960 [01:07<00:32, 409.07batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  67%|▋| 27618/40960 [01:07<00:32, 410.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  67%|▋| 27618/40960 [01:07<00:32, 410.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  68%|▋| 27704/40960 [01:07<00:31, 415.01batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  68%|▋| 27704/40960 [01:07<00:31, 415.01batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  68%|▋| 27781/40960 [01:07<00:32, 405.81batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  68%|▋| 27781/40960 [01:07<00:32, 405.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  68%|▋| 27855/40960 [01:07<00:33, 394.00batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  68%|▋| 27855/40960 [01:07<00:33, 394.00batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  68%|▋| 27938/40960 [01:08<00:32, 399.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  68%|▋| 27938/40960 [01:08<00:32, 399.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  68%|▋| 28011/40960 [01:08<00:33, 388.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  68%|▋| 28011/40960 [01:08<00:33, 388.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  69%|▋| 28081/40960 [01:08<00:34, 376.08batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  69%|▋| 28081/40960 [01:08<00:34, 376.08batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  69%|▋| 28153/40960 [01:08<00:34, 370.67batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  69%|▋| 28153/40960 [01:08<00:34, 370.67batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  69%|▋| 28232/40960 [01:08<00:33, 377.78batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  69%|▋| 28232/40960 [01:08<00:33, 377.78batches/s, l2_loss: 0.0233 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|▋| 28311/40960 [01:09<00:33, 382.19batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  69%|▋| 28311/40960 [01:09<00:33, 382.19batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  69%|▋| 28388/40960 [01:09<00:32, 382.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  69%|▋| 28388/40960 [01:09<00:32, 382.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28473/40960 [01:09<00:31, 394.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28473/40960 [01:09<00:31, 394.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28553/40960 [01:09<00:31, 395.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28553/40960 [01:09<00:31, 395.79batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28632/40960 [01:09<00:31, 394.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28632/40960 [01:09<00:31, 394.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28708/40960 [01:10<00:31, 390.29batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28708/40960 [01:10<00:31, 390.29batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28789/40960 [01:10<00:30, 393.27batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28789/40960 [01:10<00:30, 393.27batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28869/40960 [01:10<00:30, 395.00batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  70%|▋| 28869/40960 [01:10<00:30, 395.00batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  71%|▋| 28947/40960 [01:10<00:30, 393.06batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  71%|▋| 28947/40960 [01:10<00:30, 393.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  71%|▋| 29030/40960 [01:10<00:29, 399.29batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  71%|▋| 29030/40960 [01:10<00:29, 399.29batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  71%|▋| 29111/40960 [01:11<00:29, 400.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  71%|▋| 29111/40960 [01:11<00:29, 400.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  71%|▋| 29188/40960 [01:11<00:29, 394.65batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  71%|▋| 29188/40960 [01:11<00:29, 394.65batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  71%|▋| 29267/40960 [01:11<00:29, 394.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  71%|▋| 29267/40960 [01:11<00:29, 394.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29346/40960 [01:11<00:29, 394.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29346/40960 [01:11<00:29, 394.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29424/40960 [01:11<00:29, 391.98batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29424/40960 [01:11<00:29, 391.98batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29507/40960 [01:12<00:28, 398.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29507/40960 [01:12<00:28, 398.57batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29585/40960 [01:12<00:28, 395.37batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29585/40960 [01:12<00:28, 395.37batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29663/40960 [01:12<00:28, 393.09batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  72%|▋| 29663/40960 [01:12<00:28, 393.09batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  73%|▋| 29743/40960 [01:12<00:28, 394.10batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  73%|▋| 29743/40960 [01:12<00:28, 394.10batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  73%|▋| 29825/40960 [01:12<00:27, 398.09batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  73%|▋| 29825/40960 [01:12<00:27, 398.09batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  73%|▋| 29908/40960 [01:13<00:27, 402.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  73%|▋| 29908/40960 [01:13<00:27, 402.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  73%|▋| 29992/40960 [01:13<00:26, 407.37batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  73%|▋| 29992/40960 [01:13<00:26, 407.37batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  73%|▋| 30076/40960 [01:13<00:26, 409.97batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  73%|▋| 30076/40960 [01:13<00:26, 409.97batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  74%|▋| 30158/40960 [01:13<00:26, 409.26batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  74%|▋| 30158/40960 [01:13<00:26, 409.26batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  74%|▋| 30239/40960 [01:13<00:26, 407.18batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  74%|▋| 30239/40960 [01:13<00:26, 407.18batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  74%|▋| 30317/40960 [01:14<00:26, 401.92batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  74%|▋| 30317/40960 [01:14<00:26, 401.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  74%|▋| 30398/40960 [01:14<00:26, 401.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  74%|▋| 30398/40960 [01:14<00:26, 401.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  74%|▋| 30481/40960 [01:14<00:25, 404.73batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  74%|▋| 30481/40960 [01:14<00:25, 404.73batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  75%|▋| 30561/40960 [01:14<00:25, 403.20batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  75%|▋| 30561/40960 [01:14<00:25, 403.20batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  75%|▋| 30645/40960 [01:14<00:25, 407.36batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  75%|▋| 30645/40960 [01:14<00:25, 407.36batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  75%|▋| 30718/40960 [01:15<00:26, 393.52batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  75%|▋| 30718/40960 [01:15<00:26, 393.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  75%|▊| 30794/40960 [01:15<00:26, 388.87batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  75%|▊| 30794/40960 [01:15<00:26, 388.87batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  75%|▊| 30879/40960 [01:15<00:25, 398.34batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  75%|▊| 30879/40960 [01:15<00:25, 398.34batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 30957/40960 [01:15<00:25, 395.18batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 30957/40960 [01:15<00:25, 395.18batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 31030/40960 [01:15<00:25, 385.48batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 31030/40960 [01:15<00:25, 385.48batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 31101/40960 [01:16<00:26, 376.34batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 31101/40960 [01:16<00:26, 376.34batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 31183/40960 [01:16<00:25, 385.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 31183/40960 [01:16<00:25, 385.74batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 31265/40960 [01:16<00:24, 392.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  76%|▊| 31265/40960 [01:16<00:24, 392.51batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  77%|▊| 31347/40960 [01:16<00:24, 397.44batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  77%|▊| 31347/40960 [01:16<00:24, 397.44batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  77%|▊| 31423/40960 [01:16<00:24, 391.22batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  77%|▊| 31423/40960 [01:16<00:24, 391.22batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  77%|▊| 31501/40960 [01:17<00:24, 390.53batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  77%|▊| 31501/40960 [01:17<00:24, 390.53batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  77%|▊| 31581/40960 [01:17<00:23, 392.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  77%|▊| 31581/40960 [01:17<00:23, 392.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  77%|▊| 31667/40960 [01:17<00:23, 403.66batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  77%|▊| 31667/40960 [01:17<00:23, 403.66batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  77%|▊| 31740/40960 [01:17<00:23, 391.10batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  77%|▊| 31740/40960 [01:17<00:23, 391.10batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 31819/40960 [01:17<00:23, 391.71batches/s, l2_loss: 0.0234 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|▊| 31819/40960 [01:17<00:23, 391.71batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 31901/40960 [01:18<00:22, 395.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 31901/40960 [01:18<00:22, 395.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 31979/40960 [01:18<00:22, 394.01batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 31979/40960 [01:18<00:22, 394.01batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 32056/40960 [01:18<00:22, 390.32batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 32056/40960 [01:18<00:22, 390.32batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 32134/40960 [01:18<00:22, 389.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  78%|▊| 32134/40960 [01:18<00:22, 389.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  79%|▊| 32218/40960 [01:18<00:21, 398.66batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  79%|▊| 32218/40960 [01:18<00:21, 398.66batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  79%|▊| 32302/40960 [01:19<00:21, 404.56batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  79%|▊| 32302/40960 [01:19<00:21, 404.56batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  79%|▊| 32384/40960 [01:19<00:21, 405.01batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  79%|▊| 32384/40960 [01:19<00:21, 405.01batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  79%|▊| 32467/40960 [01:19<00:20, 407.76batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  79%|▊| 32467/40960 [01:19<00:20, 407.76batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  79%|▊| 32553/40960 [01:19<00:20, 412.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  79%|▊| 32553/40960 [01:19<00:20, 412.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  80%|▊| 32639/40960 [01:19<00:19, 417.19batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  80%|▊| 32639/40960 [01:19<00:19, 417.19batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  80%|▊| 32721/40960 [01:20<00:19, 414.86batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  80%|▊| 32721/40960 [01:20<00:19, 414.86batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  80%|▊| 32804/40960 [01:20<00:19, 414.14batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  80%|▊| 32804/40960 [01:20<00:19, 414.14batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  80%|▊| 32889/40960 [01:20<00:19, 417.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  80%|▊| 32889/40960 [01:20<00:19, 417.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 32973/40960 [01:20<00:19, 416.50batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 32973/40960 [01:20<00:19, 416.50batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 33059/40960 [01:20<00:18, 419.70batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 33059/40960 [01:20<00:18, 419.70batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 33145/40960 [01:21<00:18, 421.49batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 33145/40960 [01:21<00:18, 421.49batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 33230/40960 [01:21<00:18, 421.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 33230/40960 [01:21<00:18, 421.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 33317/40960 [01:21<00:18, 423.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  81%|▊| 33317/40960 [01:21<00:18, 423.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  82%|▊| 33403/40960 [01:21<00:17, 425.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  82%|▊| 33403/40960 [01:21<00:17, 425.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  82%|▊| 33486/40960 [01:21<00:17, 421.20batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  82%|▊| 33486/40960 [01:21<00:17, 421.20batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  82%|▊| 33567/40960 [01:22<00:17, 416.35batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  82%|▊| 33567/40960 [01:22<00:17, 416.35batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  82%|▊| 33646/40960 [01:22<00:17, 409.58batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  82%|▊| 33646/40960 [01:22<00:17, 409.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  82%|▊| 33728/40960 [01:22<00:17, 409.25batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  82%|▊| 33728/40960 [01:22<00:17, 409.25batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  83%|▊| 33812/40960 [01:22<00:17, 412.46batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  83%|▊| 33812/40960 [01:22<00:17, 412.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  83%|▊| 33888/40960 [01:22<00:17, 401.85batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  83%|▊| 33888/40960 [01:22<00:17, 401.85batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  83%|▊| 33970/40960 [01:23<00:17, 403.42batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  83%|▊| 33970/40960 [01:23<00:17, 403.42batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  83%|▊| 34047/40960 [01:23<00:17, 397.68batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  83%|▊| 34047/40960 [01:23<00:17, 397.68batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  83%|▊| 34116/40960 [01:23<00:17, 381.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  83%|▊| 34116/40960 [01:23<00:17, 381.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  83%|▊| 34185/40960 [01:23<00:18, 369.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  83%|▊| 34185/40960 [01:23<00:18, 369.15batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  84%|▊| 34265/40960 [01:23<00:17, 377.55batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  84%|▊| 34265/40960 [01:23<00:17, 377.55batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  84%|▊| 34339/40960 [01:24<00:17, 374.54batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  84%|▊| 34339/40960 [01:24<00:17, 374.54batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  84%|▊| 34421/40960 [01:24<00:16, 385.12batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  84%|▊| 34421/40960 [01:24<00:16, 385.12batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  84%|▊| 34505/40960 [01:24<00:16, 395.49batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  84%|▊| 34505/40960 [01:24<00:16, 395.49batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  84%|▊| 34582/40960 [01:24<00:16, 391.31batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  84%|▊| 34582/40960 [01:24<00:16, 391.31batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  85%|▊| 34645/40960 [01:24<00:17, 367.40batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  85%|▊| 34645/40960 [01:24<00:17, 367.40batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  85%|▊| 34714/40960 [01:25<00:17, 359.78batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  85%|▊| 34714/40960 [01:25<00:17, 359.78batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  85%|▊| 34775/40960 [01:25<00:18, 342.60batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  85%|▊| 34775/40960 [01:25<00:18, 342.60batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  85%|▊| 34841/40960 [01:25<00:18, 338.58batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  85%|▊| 34841/40960 [01:25<00:18, 338.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  85%|▊| 34923/40960 [01:25<00:16, 359.44batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  85%|▊| 34923/40960 [01:25<00:16, 359.44batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  85%|▊| 35001/40960 [01:25<00:16, 367.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  85%|▊| 35001/40960 [01:25<00:16, 367.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  86%|▊| 35068/40960 [01:26<00:16, 356.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  86%|▊| 35068/40960 [01:26<00:16, 356.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  86%|▊| 35142/40960 [01:26<00:16, 359.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  86%|▊| 35142/40960 [01:26<00:16, 359.81batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  86%|▊| 35224/40960 [01:26<00:15, 373.59batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  86%|▊| 35224/40960 [01:26<00:15, 373.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  86%|▊| 35303/40960 [01:26<00:14, 379.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  86%|▊| 35303/40960 [01:26<00:14, 379.23batches/s, l2_loss: 0.0234 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|▊| 35379/40960 [01:26<00:14, 377.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  86%|▊| 35379/40960 [01:26<00:14, 377.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35441/40960 [01:27<00:15, 356.72batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35441/40960 [01:27<00:15, 356.72batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35520/40960 [01:27<00:14, 367.19batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35520/40960 [01:27<00:14, 367.19batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35592/40960 [01:27<00:14, 364.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35592/40960 [01:27<00:14, 364.46batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35663/40960 [01:27<00:14, 361.31batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35663/40960 [01:27<00:14, 361.31batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35736/40960 [01:27<00:14, 362.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35736/40960 [01:27<00:14, 362.06batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35808/40960 [01:28<00:14, 361.36batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  87%|▊| 35808/40960 [01:28<00:14, 361.36batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 35890/40960 [01:28<00:13, 374.70batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 35890/40960 [01:28<00:13, 374.70batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 35973/40960 [01:28<00:12, 386.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 35973/40960 [01:28<00:12, 386.22batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 36056/40960 [01:28<00:12, 393.65batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 36056/40960 [01:28<00:12, 393.65batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 36141/40960 [01:28<00:11, 402.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 36141/40960 [01:28<00:11, 402.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 36228/40960 [01:29<00:11, 411.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  88%|▉| 36228/40960 [01:29<00:11, 411.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  89%|▉| 36308/40960 [01:29<00:11, 407.05batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  89%|▉| 36308/40960 [01:29<00:11, 407.05batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  89%|▉| 36392/40960 [01:29<00:11, 410.32batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  89%|▉| 36392/40960 [01:29<00:11, 410.32batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  89%|▉| 36466/40960 [01:29<00:11, 397.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  89%|▉| 36466/40960 [01:29<00:11, 397.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  89%|▉| 36549/40960 [01:29<00:10, 402.64batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  89%|▉| 36549/40960 [01:29<00:10, 402.64batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  89%|▉| 36621/40960 [01:30<00:11, 389.70batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  89%|▉| 36621/40960 [01:30<00:11, 389.70batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  90%|▉| 36702/40960 [01:30<00:10, 392.96batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  90%|▉| 36702/40960 [01:30<00:10, 392.96batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  90%|▉| 36786/40960 [01:30<00:10, 400.97batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  90%|▉| 36786/40960 [01:30<00:10, 400.97batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  90%|▉| 36862/40960 [01:30<00:10, 393.91batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  90%|▉| 36862/40960 [01:30<00:10, 393.91batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  90%|▉| 36941/40960 [01:30<00:10, 393.34batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  90%|▉| 36941/40960 [01:30<00:10, 393.34batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  90%|▉| 37009/40960 [01:31<00:10, 377.17batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  90%|▉| 37009/40960 [01:31<00:10, 377.17batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  91%|▉| 37083/40960 [01:31<00:10, 374.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  91%|▉| 37083/40960 [01:31<00:10, 374.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  91%|▉| 37153/40960 [01:31<00:10, 366.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  91%|▉| 37153/40960 [01:31<00:10, 366.92batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  91%|▉| 37237/40960 [01:31<00:09, 382.41batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  91%|▉| 37237/40960 [01:31<00:09, 382.41batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  91%|▉| 37320/40960 [01:31<00:09, 391.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  91%|▉| 37320/40960 [01:31<00:09, 391.83batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  91%|▉| 37405/40960 [01:32<00:08, 400.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  91%|▉| 37405/40960 [01:32<00:08, 400.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  92%|▉| 37489/40960 [01:32<00:08, 405.39batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  92%|▉| 37489/40960 [01:32<00:08, 405.39batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  92%|▉| 37572/40960 [01:32<00:08, 407.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  92%|▉| 37572/40960 [01:32<00:08, 407.52batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  92%|▉| 37657/40960 [01:32<00:08, 412.03batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  92%|▉| 37657/40960 [01:32<00:08, 412.03batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  92%|▉| 37739/40960 [01:32<00:07, 410.70batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  92%|▉| 37739/40960 [01:32<00:07, 410.70batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  92%|▉| 37823/40960 [01:33<00:07, 412.48batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  92%|▉| 37823/40960 [01:33<00:07, 412.48batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 37910/40960 [01:33<00:07, 418.02batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 37910/40960 [01:33<00:07, 418.02batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 37994/40960 [01:33<00:07, 417.36batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 37994/40960 [01:33<00:07, 417.36batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 38078/40960 [01:33<00:06, 417.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 38078/40960 [01:33<00:06, 417.92batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 38163/40960 [01:33<00:06, 419.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 38163/40960 [01:33<00:06, 419.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 38246/40960 [01:34<00:06, 416.85batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  93%|▉| 38246/40960 [01:34<00:06, 416.85batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  94%|▉| 38334/40960 [01:34<00:06, 423.04batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  94%|▉| 38334/40960 [01:34<00:06, 423.04batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  94%|▉| 38422/40960 [01:34<00:05, 427.90batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  94%|▉| 38422/40960 [01:34<00:05, 427.90batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  94%|▉| 38503/40960 [01:34<00:05, 420.58batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  94%|▉| 38503/40960 [01:34<00:05, 420.58batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  94%|▉| 38591/40960 [01:34<00:05, 425.56batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  94%|▉| 38591/40960 [01:34<00:05, 425.56batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  94%|▉| 38675/40960 [01:35<00:05, 423.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  94%|▉| 38675/40960 [01:35<00:05, 423.84batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 38762/40960 [01:35<00:05, 425.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 38762/40960 [01:35<00:05, 425.95batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 38847/40960 [01:35<00:04, 424.44batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 38847/40960 [01:35<00:04, 424.44batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 38929/40960 [01:35<00:04, 419.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 38929/40960 [01:35<00:04, 419.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 39012/40960 [01:35<00:04, 417.54batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 39012/40960 [01:35<00:04, 417.54batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 39098/40960 [01:36<00:04, 420.78batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  95%|▉| 39098/40960 [01:36<00:04, 420.78batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  96%|▉| 39180/40960 [01:36<00:04, 416.53batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  96%|▉| 39180/40960 [01:36<00:04, 416.53batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  96%|▉| 39260/40960 [01:36<00:04, 411.19batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  96%|▉| 39260/40960 [01:36<00:04, 411.19batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  96%|▉| 39344/40960 [01:36<00:03, 413.33batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  96%|▉| 39344/40960 [01:36<00:03, 413.33batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  96%|▉| 39428/40960 [01:36<00:03, 414.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  96%|▉| 39428/40960 [01:36<00:03, 414.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  96%|▉| 39513/40960 [01:37<00:03, 417.29batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  96%|▉| 39513/40960 [01:37<00:03, 417.29batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  97%|▉| 39600/40960 [01:37<00:03, 421.81batches/s, l2_loss: 0.0233 - round_los\u001b[A\n",
      "Training:  97%|▉| 39600/40960 [01:37<00:03, 421.81batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  97%|▉| 39686/40960 [01:37<00:03, 423.48batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  97%|▉| 39686/40960 [01:37<00:03, 423.48batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  97%|▉| 39771/40960 [01:37<00:02, 423.44batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  97%|▉| 39771/40960 [01:37<00:02, 423.44batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  97%|▉| 39853/40960 [01:37<00:02, 418.11batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  97%|▉| 39853/40960 [01:37<00:02, 418.11batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 39939/40960 [01:38<00:02, 421.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 39939/40960 [01:38<00:02, 421.45batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 40023/40960 [01:38<00:02, 419.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 40023/40960 [01:38<00:02, 419.59batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 40108/40960 [01:38<00:02, 420.54batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 40108/40960 [01:38<00:02, 420.54batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 40189/40960 [01:38<00:01, 415.21batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 40189/40960 [01:38<00:01, 415.21batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 40272/40960 [01:38<00:01, 415.07batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  98%|▉| 40272/40960 [01:39<00:01, 415.07batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40355/40960 [01:39<00:01, 414.01batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40355/40960 [01:39<00:01, 414.01batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40439/40960 [01:39<00:01, 415.38batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40439/40960 [01:39<00:01, 415.38batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40524/40960 [01:39<00:01, 417.27batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40524/40960 [01:39<00:01, 417.27batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40606/40960 [01:39<00:00, 414.16batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40606/40960 [01:39<00:00, 414.16batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40686/40960 [01:40<00:00, 408.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training:  99%|▉| 40686/40960 [01:40<00:00, 408.93batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training: 100%|▉| 40769/40960 [01:40<00:00, 409.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training: 100%|▉| 40769/40960 [01:40<00:00, 409.43batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training: 100%|▉| 40854/40960 [01:40<00:00, 413.60batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training: 100%|▉| 40854/40960 [01:40<00:00, 413.60batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training: 100%|▉| 40939/40960 [01:40<00:00, 416.18batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "Training: 100%|▉| 40939/40960 [01:40<00:00, 416.18batches/s, l2_loss: 0.0234 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:04:03.728563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  31%|▎| 8/26 [14:42<34:11, 113.99s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 19:04:05.089749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:04:12.017579: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<25:21:00,  2.23s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<25:21:00,  2.23s/batches, l2_loss: 0.0547 - round_loss:\u001b[A\n",
      "Training:   0%| | 61/40960 [00:02<19:47, 34.46batches/s, l2_loss: 0.0547 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 61/40960 [00:02<19:47, 34.46batches/s, l2_loss: 0.0893 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 129/40960 [00:02<08:50, 77.00batches/s, l2_loss: 0.0893 - round_loss: \u001b[A\n",
      "Training:   0%| | 129/40960 [00:02<08:50, 77.00batches/s, l2_loss: 0.0988 - round_loss: \u001b[A\n",
      "Training:   0%| | 190/40960 [00:02<05:55, 114.59batches/s, l2_loss: 0.0988 - round_loss:\u001b[A\n",
      "Training:   0%| | 190/40960 [00:02<05:55, 114.59batches/s, l2_loss: 0.0994 - round_loss:\u001b[A\n",
      "Training:   1%| | 242/40960 [00:03<04:46, 142.23batches/s, l2_loss: 0.0994 - round_loss:\u001b[A\n",
      "Training:   1%| | 242/40960 [00:03<04:46, 142.23batches/s, l2_loss: 0.0983 - round_loss:\u001b[A\n",
      "Training:   1%| | 300/40960 [00:03<03:54, 173.31batches/s, l2_loss: 0.0983 - round_loss:\u001b[A\n",
      "Training:   1%| | 300/40960 [00:03<03:54, 173.31batches/s, l2_loss: 0.0946 - round_loss:\u001b[A\n",
      "Training:   1%| | 352/40960 [00:03<03:30, 193.23batches/s, l2_loss: 0.0946 - round_loss:\u001b[A\n",
      "Training:   1%| | 352/40960 [00:03<03:30, 193.23batches/s, l2_loss: 0.0981 - round_loss:\u001b[A\n",
      "Training:   1%| | 408/40960 [00:03<03:09, 214.52batches/s, l2_loss: 0.0981 - round_loss:\u001b[A\n",
      "Training:   1%| | 408/40960 [00:03<03:09, 214.52batches/s, l2_loss: 0.0980 - round_loss:\u001b[A\n",
      "Training:   1%| | 446/40960 [00:03<03:15, 207.25batches/s, l2_loss: 0.0980 - round_loss:\u001b[A\n",
      "Training:   1%| | 446/40960 [00:03<03:15, 207.25batches/s, l2_loss: 0.0985 - round_loss:\u001b[A\n",
      "Training:   1%| | 501/40960 [00:04<02:59, 225.44batches/s, l2_loss: 0.0985 - round_loss:\u001b[A\n",
      "Training:   1%| | 501/40960 [00:04<02:59, 225.44batches/s, l2_loss: 0.0995 - round_loss:\u001b[A\n",
      "Training:   1%| | 557/40960 [00:04<02:48, 239.70batches/s, l2_loss: 0.0995 - round_loss:\u001b[A\n",
      "Training:   1%| | 557/40960 [00:04<02:48, 239.70batches/s, l2_loss: 0.0970 - round_loss:\u001b[A\n",
      "Training:   2%| | 620/40960 [00:04<02:34, 260.72batches/s, l2_loss: 0.0970 - round_loss:\u001b[A\n",
      "Training:   2%| | 620/40960 [00:04<02:34, 260.72batches/s, l2_loss: 0.0973 - round_loss:\u001b[A\n",
      "Training:   2%| | 685/40960 [00:04<02:24, 278.54batches/s, l2_loss: 0.0973 - round_loss:\u001b[A\n",
      "Training:   2%| | 685/40960 [00:04<02:24, 278.54batches/s, l2_loss: 0.1003 - round_loss:\u001b[A\n",
      "Training:   2%| | 747/40960 [00:04<02:19, 287.43batches/s, l2_loss: 0.1003 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%| | 747/40960 [00:04<02:19, 287.43batches/s, l2_loss: 0.0976 - round_loss:\u001b[A\n",
      "Training:   2%| | 808/40960 [00:05<02:17, 291.03batches/s, l2_loss: 0.0976 - round_loss:\u001b[A\n",
      "Training:   2%| | 808/40960 [00:05<02:17, 291.03batches/s, l2_loss: 0.0977 - round_loss:\u001b[A\n",
      "Training:   2%| | 869/40960 [00:05<02:16, 294.67batches/s, l2_loss: 0.0977 - round_loss:\u001b[A\n",
      "Training:   2%| | 869/40960 [00:05<02:16, 294.67batches/s, l2_loss: 0.0977 - round_loss:\u001b[A\n",
      "Training:   2%| | 930/40960 [00:05<02:14, 296.75batches/s, l2_loss: 0.0977 - round_loss:\u001b[A\n",
      "Training:   2%| | 930/40960 [00:05<02:14, 296.75batches/s, l2_loss: 0.0987 - round_loss:\u001b[A\n",
      "Training:   2%| | 990/40960 [00:05<02:14, 296.83batches/s, l2_loss: 0.0987 - round_loss:\u001b[A\n",
      "Training:   2%| | 990/40960 [00:05<02:14, 296.83batches/s, l2_loss: 0.0984 - round_loss:\u001b[A\n",
      "Training:   3%| | 1054/40960 [00:05<02:12, 301.61batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   3%| | 1054/40960 [00:05<02:12, 301.61batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:   3%| | 1104/40960 [00:06<02:19, 284.98batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:   3%| | 1104/40960 [00:06<02:19, 284.98batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:   3%| | 1165/40960 [00:06<02:18, 287.78batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:   3%| | 1165/40960 [00:06<02:18, 287.78batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   3%| | 1217/40960 [00:06<02:22, 279.19batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   3%| | 1217/40960 [00:06<02:22, 279.19batches/s, l2_loss: 0.0975 - round_loss\u001b[A\n",
      "Training:   3%| | 1274/40960 [00:06<02:21, 279.93batches/s, l2_loss: 0.0975 - round_loss\u001b[A\n",
      "Training:   3%| | 1274/40960 [00:06<02:21, 279.93batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:   3%| | 1327/40960 [00:06<02:24, 274.09batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:   3%| | 1327/40960 [00:06<02:24, 274.09batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:   3%| | 1377/40960 [00:07<02:29, 265.41batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:   3%| | 1377/40960 [00:07<02:29, 265.41batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   3%| | 1429/40960 [00:07<02:30, 262.55batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   3%| | 1429/40960 [00:07<02:30, 262.55batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:   4%| | 1491/40960 [00:07<02:22, 276.01batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:   4%| | 1491/40960 [00:07<02:22, 276.01batches/s, l2_loss: 0.0973 - round_loss\u001b[A\n",
      "Training:   4%| | 1555/40960 [00:07<02:16, 288.33batches/s, l2_loss: 0.0973 - round_loss\u001b[A\n",
      "Training:   4%| | 1555/40960 [00:07<02:16, 288.33batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:   4%| | 1612/40960 [00:07<02:17, 286.76batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:   4%| | 1612/40960 [00:07<02:17, 286.76batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:   4%| | 1670/40960 [00:08<02:16, 287.49batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:   4%| | 1670/40960 [00:08<02:16, 287.49batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   4%| | 1727/40960 [00:08<02:17, 285.32batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   4%| | 1727/40960 [00:08<02:17, 285.32batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:   4%| | 1782/40960 [00:08<02:18, 281.92batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:   4%| | 1782/40960 [00:08<02:18, 281.92batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   4%| | 1829/40960 [00:08<02:26, 267.50batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   4%| | 1829/40960 [00:08<02:26, 267.50batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:   5%| | 1883/40960 [00:08<02:26, 267.43batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:   5%| | 1883/40960 [00:08<02:26, 267.43batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:   5%| | 1937/40960 [00:09<02:25, 267.78batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:   5%| | 1937/40960 [00:09<02:25, 267.78batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   5%| | 1999/40960 [00:09<02:19, 279.49batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   5%| | 1999/40960 [00:09<02:19, 279.49batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:   5%| | 2060/40960 [00:09<02:15, 286.91batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:   5%| | 2060/40960 [00:09<02:15, 286.91batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:   5%| | 2117/40960 [00:09<02:16, 284.53batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:   5%| | 2117/40960 [00:09<02:16, 284.53batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   5%| | 2177/40960 [00:09<02:14, 288.75batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   5%| | 2177/40960 [00:09<02:14, 288.75batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   5%| | 2240/40960 [00:10<02:10, 296.51batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   5%| | 2240/40960 [00:10<02:10, 296.51batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:   6%| | 2302/40960 [00:10<02:09, 298.86batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:   6%| | 2302/40960 [00:10<02:09, 298.86batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   6%| | 2359/40960 [00:10<02:11, 293.73batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   6%| | 2359/40960 [00:10<02:11, 293.73batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   6%| | 2422/40960 [00:10<02:08, 299.08batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   6%| | 2422/40960 [00:10<02:08, 299.08batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   6%| | 2473/40960 [00:10<02:15, 284.91batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   6%| | 2473/40960 [00:10<02:15, 284.91batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   6%| | 2525/40960 [00:11<02:18, 276.78batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   6%| | 2525/40960 [00:11<02:18, 276.78batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:   6%| | 2588/40960 [00:11<02:13, 287.65batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:   6%| | 2588/40960 [00:11<02:13, 287.65batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   6%| | 2647/40960 [00:11<02:12, 288.64batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   6%| | 2647/40960 [00:11<02:12, 288.64batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   7%| | 2705/40960 [00:11<02:12, 288.12batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   7%| | 2705/40960 [00:11<02:12, 288.12batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   7%| | 2763/40960 [00:11<02:12, 288.28batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   7%| | 2763/40960 [00:11<02:12, 288.28batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   7%| | 2825/40960 [00:12<02:09, 294.48batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   7%| | 2825/40960 [00:12<02:09, 294.48batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   7%| | 2887/40960 [00:12<02:07, 298.53batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   7%| | 2887/40960 [00:12<02:07, 298.53batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:   7%| | 2949/40960 [00:12<02:06, 300.92batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:   7%| | 2949/40960 [00:12<02:06, 300.92batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   7%| | 3010/40960 [00:12<02:05, 301.87batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   7%| | 3010/40960 [00:12<02:05, 301.87batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   7%| | 3071/40960 [00:12<02:05, 302.63batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:   7%| | 3071/40960 [00:12<02:05, 302.63batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:   8%| | 3132/40960 [00:13<02:05, 302.52batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:   8%| | 3132/40960 [00:13<02:05, 302.52batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:   8%| | 3187/40960 [00:13<02:08, 293.18batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:   8%| | 3187/40960 [00:13<02:08, 293.18batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:   8%| | 3252/40960 [00:13<02:04, 301.92batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:   8%| | 3252/40960 [00:13<02:04, 301.92batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   8%| | 3314/40960 [00:13<02:03, 304.33batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   8%| | 3314/40960 [00:13<02:03, 304.33batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3377/40960 [00:13<02:02, 307.31batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:   8%| | 3377/40960 [00:13<02:02, 307.31batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:   8%| | 3441/40960 [00:14<02:00, 310.71batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:   8%| | 3441/40960 [00:14<02:00, 310.71batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   9%| | 3502/40960 [00:14<02:01, 307.49batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   9%| | 3502/40960 [00:14<02:01, 307.49batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   9%| | 3558/40960 [00:14<02:05, 298.63batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   9%| | 3558/40960 [00:14<02:05, 298.63batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   9%| | 3618/40960 [00:14<02:05, 298.51batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   9%| | 3618/40960 [00:14<02:05, 298.51batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   9%| | 3679/40960 [00:14<02:04, 300.24batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:   9%| | 3679/40960 [00:14<02:04, 300.24batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   9%| | 3739/40960 [00:15<02:04, 298.84batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:   9%| | 3739/40960 [00:15<02:04, 298.84batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:   9%| | 3800/40960 [00:15<02:03, 300.26batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:   9%| | 3800/40960 [00:15<02:03, 300.26batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:   9%| | 3861/40960 [00:15<02:03, 301.19batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:   9%| | 3861/40960 [00:15<02:03, 301.19batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  10%| | 3918/40960 [00:15<02:05, 294.42batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  10%| | 3918/40960 [00:15<02:05, 294.42batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  10%| | 3977/40960 [00:15<02:05, 294.14batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  10%| | 3977/40960 [00:15<02:05, 294.14batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  10%| | 4037/40960 [00:16<02:05, 295.35batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  10%| | 4037/40960 [00:16<02:05, 295.35batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  10%| | 4096/40960 [00:16<02:05, 294.85batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  10%| | 4096/40960 [00:16<02:05, 294.85batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  10%| | 4136/40960 [00:16<02:18, 265.56batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  10%| | 4136/40960 [00:16<02:18, 265.56batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  10%| | 4191/40960 [00:16<02:17, 268.36batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  10%| | 4191/40960 [00:16<02:17, 268.36batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  10%| | 4244/40960 [00:16<02:17, 266.36batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  10%| | 4244/40960 [00:16<02:17, 266.36batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  10%| | 4298/40960 [00:17<02:17, 267.09batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  10%| | 4298/40960 [00:17<02:17, 267.09batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  11%| | 4354/40960 [00:17<02:15, 269.42batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  11%| | 4354/40960 [00:17<02:15, 269.42batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  11%| | 4403/40960 [00:17<02:20, 259.94batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  11%| | 4403/40960 [00:17<02:20, 259.94batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  11%| | 4464/40960 [00:17<02:13, 272.52batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  11%| | 4464/40960 [00:17<02:13, 272.52batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  11%| | 4525/40960 [00:17<02:09, 282.03batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  11%| | 4525/40960 [00:17<02:09, 282.03batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  11%| | 4586/40960 [00:18<02:06, 287.90batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  11%| | 4586/40960 [00:18<02:06, 287.90batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  11%| | 4651/40960 [00:18<02:01, 298.40batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  11%| | 4651/40960 [00:18<02:01, 298.40batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  11%| | 4707/40960 [00:18<02:04, 291.48batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  11%| | 4707/40960 [00:18<02:04, 291.48batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  12%| | 4764/40960 [00:18<02:05, 288.48batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  12%| | 4764/40960 [00:18<02:05, 288.48batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  12%| | 4815/40960 [00:18<02:10, 276.72batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  12%| | 4815/40960 [00:19<02:10, 276.72batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  12%| | 4865/40960 [00:19<02:14, 268.72batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  12%| | 4865/40960 [00:19<02:14, 268.72batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  12%| | 4917/40960 [00:19<02:15, 265.33batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  12%| | 4917/40960 [00:19<02:15, 265.33batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  12%| | 4978/40960 [00:19<02:10, 275.70batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  12%| | 4978/40960 [00:19<02:10, 275.70batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  12%| | 5035/40960 [00:19<02:09, 277.89batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  12%| | 5035/40960 [00:19<02:09, 277.89batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  12%| | 5099/40960 [00:20<02:03, 289.56batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  12%| | 5099/40960 [00:20<02:03, 289.56batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5163/40960 [00:20<02:00, 297.93batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5163/40960 [00:20<02:00, 297.93batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5224/40960 [00:20<01:59, 299.62batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5224/40960 [00:20<01:59, 299.62batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5286/40960 [00:20<01:57, 302.53batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5286/40960 [00:20<01:57, 302.53batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5342/40960 [00:20<02:00, 295.18batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5342/40960 [00:20<02:00, 295.18batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5405/40960 [00:21<01:58, 300.41batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5405/40960 [00:21<01:58, 300.41batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5465/40960 [00:21<01:58, 299.33batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5465/40960 [00:21<01:58, 299.33batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5519/40960 [00:21<02:02, 288.64batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5519/40960 [00:21<02:02, 288.64batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5566/40960 [00:21<02:10, 270.87batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5566/40960 [00:21<02:10, 270.87batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5616/40960 [00:21<02:13, 264.46batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5616/40960 [00:21<02:13, 264.46batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5676/40960 [00:22<02:08, 274.17batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5676/40960 [00:22<02:08, 274.17batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5729/40960 [00:22<02:09, 271.18batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5729/40960 [00:22<02:09, 271.18batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5790/40960 [00:22<02:05, 280.08batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5790/40960 [00:22<02:05, 280.08batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5848/40960 [00:22<02:04, 281.42batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5848/40960 [00:22<02:04, 281.42batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5905/40960 [00:22<02:04, 280.95batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|▏| 5905/40960 [00:22<02:04, 280.95batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5966/40960 [00:23<02:01, 287.65batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5966/40960 [00:23<02:01, 287.65batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6018/40960 [00:23<02:05, 278.94batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6018/40960 [00:23<02:05, 278.94batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6071/40960 [00:23<02:07, 273.48batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6071/40960 [00:23<02:07, 273.48batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6119/40960 [00:23<02:12, 262.08batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6119/40960 [00:23<02:12, 262.08batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6178/40960 [00:23<02:08, 270.82batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6178/40960 [00:23<02:08, 270.82batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6231/40960 [00:24<02:09, 268.95batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6231/40960 [00:24<02:09, 268.95batches/s, l2_loss: 0.0978 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6286/40960 [00:24<02:08, 270.13batches/s, l2_loss: 0.0978 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6286/40960 [00:24<02:08, 270.13batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6345/40960 [00:24<02:05, 276.14batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6345/40960 [00:24<02:05, 276.14batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6400/40960 [00:24<02:05, 274.97batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6400/40960 [00:24<02:05, 274.97batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6455/40960 [00:24<02:06, 273.84batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6455/40960 [00:24<02:06, 273.84batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6507/40960 [00:25<02:08, 268.22batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6507/40960 [00:25<02:08, 268.22batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6565/40960 [00:25<02:05, 274.56batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6565/40960 [00:25<02:05, 274.56batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6620/40960 [00:25<02:05, 273.98batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6620/40960 [00:25<02:05, 273.98batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6673/40960 [00:25<02:06, 271.26batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6673/40960 [00:25<02:06, 271.26batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6727/40960 [00:25<02:06, 270.14batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6727/40960 [00:25<02:06, 270.14batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6776/40960 [00:26<02:10, 262.04batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6776/40960 [00:26<02:10, 262.04batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6831/40960 [00:26<02:09, 264.20batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6831/40960 [00:26<02:09, 264.20batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6881/40960 [00:26<02:11, 259.95batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6881/40960 [00:26<02:11, 259.95batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6934/40960 [00:26<02:10, 261.20batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6934/40960 [00:26<02:10, 261.20batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6990/40960 [00:26<02:08, 265.17batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6990/40960 [00:26<02:08, 265.17batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7048/40960 [00:27<02:04, 271.31batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7048/40960 [00:27<02:04, 271.31batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7106/40960 [00:27<02:02, 276.80batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7106/40960 [00:27<02:02, 276.80batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7168/40960 [00:27<01:58, 285.79batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7168/40960 [00:27<01:58, 285.79batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7232/40960 [00:27<01:53, 295.87batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7232/40960 [00:27<01:53, 295.87batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7294/40960 [00:27<01:52, 299.01batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7294/40960 [00:27<01:52, 299.01batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7347/40960 [00:28<01:56, 287.69batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7347/40960 [00:28<01:56, 287.69batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7406/40960 [00:28<01:56, 288.71batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7406/40960 [00:28<01:56, 288.71batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:28<01:54, 292.43batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:28<01:54, 292.43batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7528/40960 [00:28<01:53, 294.86batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7528/40960 [00:28<01:53, 294.86batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7588/40960 [00:28<01:53, 295.15batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7588/40960 [00:28<01:53, 295.15batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7649/40960 [00:29<01:52, 297.27batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7649/40960 [00:29<01:52, 297.27batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7711/40960 [00:29<01:50, 299.68batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7711/40960 [00:29<01:50, 299.68batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7775/40960 [00:29<01:48, 304.79batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7775/40960 [00:29<01:48, 304.79batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7827/40960 [00:29<01:53, 291.17batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7827/40960 [00:29<01:53, 291.17batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7866/40960 [00:29<02:07, 260.52batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7866/40960 [00:29<02:07, 260.52batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7925/40960 [00:30<02:02, 269.40batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7925/40960 [00:30<02:02, 269.40batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7986/40960 [00:30<01:58, 278.93batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7986/40960 [00:30<01:58, 278.93batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8050/40960 [00:30<01:53, 290.59batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8050/40960 [00:30<01:53, 290.59batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8111/40960 [00:30<01:51, 294.01batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8111/40960 [00:30<01:51, 294.01batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8163/40960 [00:30<01:55, 282.88batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8163/40960 [00:30<01:55, 282.88batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8222/40960 [00:31<01:54, 286.14batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8222/40960 [00:31<01:54, 286.14batches/s, l2_loss: 0.1030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8281/40960 [00:31<01:53, 288.69batches/s, l2_loss: 0.1030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8281/40960 [00:31<01:53, 288.69batches/s, l2_loss: 0.1009 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8344/40960 [00:31<01:50, 295.47batches/s, l2_loss: 0.1009 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8344/40960 [00:31<01:50, 295.47batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8403/40960 [00:31<01:50, 294.80batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8403/40960 [00:31<01:50, 294.80batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|▏| 8462/40960 [00:31<01:50, 294.60batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8462/40960 [00:31<01:50, 294.60batches/s, l2_loss: 0.0975 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8524/40960 [00:32<01:48, 298.39batches/s, l2_loss: 0.0975 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8524/40960 [00:32<01:48, 298.39batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8581/40960 [00:32<01:50, 293.02batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8581/40960 [00:32<01:50, 293.02batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8640/40960 [00:32<01:50, 292.80batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8640/40960 [00:32<01:50, 292.80batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8696/40960 [00:32<01:51, 288.81batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8696/40960 [00:32<01:51, 288.81batches/s, l2_loss: 0.0955 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8752/40960 [00:32<01:53, 284.58batches/s, l2_loss: 0.0955 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8752/40960 [00:32<01:53, 284.58batches/s, l2_loss: 0.0974 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8810/40960 [00:33<01:52, 286.07batches/s, l2_loss: 0.0974 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8810/40960 [00:33<01:52, 286.07batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8870/40960 [00:33<01:50, 290.14batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8870/40960 [00:33<01:50, 290.14batches/s, l2_loss: 0.0956 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8930/40960 [00:33<01:49, 292.75batches/s, l2_loss: 0.0956 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8930/40960 [00:33<01:49, 292.75batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8984/40960 [00:33<01:51, 285.69batches/s, l2_loss: 0.0979 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8984/40960 [00:33<01:51, 285.69batches/s, l2_loss: 0.0969 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9042/40960 [00:33<01:51, 286.18batches/s, l2_loss: 0.0969 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9042/40960 [00:33<01:51, 286.18batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9102/40960 [00:34<01:49, 289.72batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9102/40960 [00:34<01:49, 289.72batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9163/40960 [00:34<01:48, 292.96batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9163/40960 [00:34<01:48, 292.96batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9218/40960 [00:34<01:50, 286.71batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9218/40960 [00:34<01:50, 286.71batches/s, l2_loss: 0.0973 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9268/40960 [00:34<01:55, 274.29batches/s, l2_loss: 0.0973 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9268/40960 [00:34<01:55, 274.29batches/s, l2_loss: 0.0969 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9319/40960 [00:34<01:58, 267.85batches/s, l2_loss: 0.0969 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9319/40960 [00:34<01:58, 267.85batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9376/40960 [00:35<01:56, 272.23batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9376/40960 [00:35<01:56, 272.23batches/s, l2_loss: 0.0972 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9426/40960 [00:35<01:59, 263.49batches/s, l2_loss: 0.0972 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9426/40960 [00:35<01:59, 263.49batches/s, l2_loss: 0.0976 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9483/40960 [00:35<01:56, 269.27batches/s, l2_loss: 0.0976 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9483/40960 [00:35<01:56, 269.27batches/s, l2_loss: 0.0975 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9533/40960 [00:35<01:59, 263.12batches/s, l2_loss: 0.0975 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9533/40960 [00:35<01:59, 263.12batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9585/40960 [00:35<02:00, 261.32batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9585/40960 [00:35<02:00, 261.32batches/s, l2_loss: 0.0973 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9644/40960 [00:36<01:55, 270.33batches/s, l2_loss: 0.0973 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9644/40960 [00:36<01:55, 270.33batches/s, l2_loss: 0.0971 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9700/40960 [00:36<01:54, 272.88batches/s, l2_loss: 0.0971 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9700/40960 [00:36<01:54, 272.88batches/s, l2_loss: 0.0977 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9753/40960 [00:36<01:55, 269.62batches/s, l2_loss: 0.0977 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9753/40960 [00:36<01:55, 269.62batches/s, l2_loss: 0.0977 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9802/40960 [00:36<01:59, 261.82batches/s, l2_loss: 0.0977 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9802/40960 [00:36<01:59, 261.82batches/s, l2_loss: 0.0975 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9856/40960 [00:36<01:58, 262.69batches/s, l2_loss: 0.0975 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9856/40960 [00:36<01:58, 262.69batches/s, l2_loss: 0.0974 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9911/40960 [00:37<01:56, 265.49batches/s, l2_loss: 0.0974 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9911/40960 [00:37<01:56, 265.49batches/s, l2_loss: 0.0976 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9968/40960 [00:37<01:54, 270.44batches/s, l2_loss: 0.0976 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9968/40960 [00:37<01:54, 270.44batches/s, l2_loss: 0.0971 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10018/40960 [00:37<01:57, 263.06batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  24%|▏| 10018/40960 [00:37<01:57, 263.06batches/s, l2_loss: 0.0979 - round_los\u001b[A\n",
      "Training:  25%|▏| 10076/40960 [00:37<01:54, 270.12batches/s, l2_loss: 0.0979 - round_los\u001b[A\n",
      "Training:  25%|▏| 10076/40960 [00:37<01:54, 270.12batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  25%|▏| 10135/40960 [00:37<01:51, 276.36batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  25%|▏| 10135/40960 [00:37<01:51, 276.36batches/s, l2_loss: 0.0977 - round_los\u001b[A\n",
      "Training:  25%|▏| 10193/40960 [00:38<01:49, 280.12batches/s, l2_loss: 0.0977 - round_los\u001b[A\n",
      "Training:  25%|▏| 10193/40960 [00:38<01:49, 280.12batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  25%|▎| 10247/40960 [00:38<01:51, 276.16batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  25%|▎| 10247/40960 [00:38<01:51, 276.16batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  25%|▎| 10305/40960 [00:38<01:49, 278.91batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  25%|▎| 10305/40960 [00:38<01:49, 278.91batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  25%|▎| 10362/40960 [00:38<01:49, 279.42batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  25%|▎| 10362/40960 [00:38<01:49, 279.42batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  25%|▎| 10420/40960 [00:39<01:48, 282.09batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  25%|▎| 10420/40960 [00:39<01:48, 282.09batches/s, l2_loss: 0.0970 - round_los\u001b[A\n",
      "Training:  26%|▎| 10476/40960 [00:39<01:48, 281.25batches/s, l2_loss: 0.0970 - round_los\u001b[A\n",
      "Training:  26%|▎| 10476/40960 [00:39<01:48, 281.25batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  26%|▎| 10533/40960 [00:39<01:47, 282.29batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  26%|▎| 10533/40960 [00:39<01:47, 282.29batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  26%|▎| 10587/40960 [00:39<01:49, 277.78batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  26%|▎| 10587/40960 [00:39<01:49, 277.78batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  26%|▎| 10648/40960 [00:39<01:46, 285.37batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  26%|▎| 10648/40960 [00:39<01:46, 285.37batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  26%|▎| 10703/40960 [00:40<01:47, 281.12batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  26%|▎| 10703/40960 [00:40<01:47, 281.12batches/s, l2_loss: 0.0979 - round_los\u001b[A\n",
      "Training:  26%|▎| 10760/40960 [00:40<01:47, 280.63batches/s, l2_loss: 0.0979 - round_los\u001b[A\n",
      "Training:  26%|▎| 10760/40960 [00:40<01:47, 280.63batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  26%|▎| 10806/40960 [00:40<01:54, 262.88batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  26%|▎| 10806/40960 [00:40<01:54, 262.88batches/s, l2_loss: 0.0979 - round_los\u001b[A\n",
      "Training:  27%|▎| 10861/40960 [00:40<01:53, 264.39batches/s, l2_loss: 0.0979 - round_los\u001b[A\n",
      "Training:  27%|▎| 10861/40960 [00:40<01:53, 264.39batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  27%|▎| 10917/40960 [00:40<01:52, 267.49batches/s, l2_loss: 0.0975 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|▎| 10917/40960 [00:40<01:52, 267.49batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  27%|▎| 10956/40960 [00:41<02:03, 243.60batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  27%|▎| 10956/40960 [00:41<02:03, 243.60batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  27%|▎| 11010/40960 [00:41<01:59, 250.62batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  27%|▎| 11010/40960 [00:41<01:59, 250.62batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  27%|▎| 11061/40960 [00:41<01:58, 251.66batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  27%|▎| 11061/40960 [00:41<01:58, 251.66batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  27%|▎| 11109/40960 [00:41<02:00, 247.68batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  27%|▎| 11109/40960 [00:41<02:00, 247.68batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  27%|▎| 11156/40960 [00:41<02:02, 242.88batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  27%|▎| 11156/40960 [00:41<02:02, 242.88batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  27%|▎| 11208/40960 [00:42<02:00, 247.91batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  27%|▎| 11208/40960 [00:42<02:00, 247.91batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  28%|▎| 11265/40960 [00:42<01:55, 257.41batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  28%|▎| 11265/40960 [00:42<01:55, 257.41batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  28%|▎| 11321/40960 [00:42<01:52, 263.45batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  28%|▎| 11321/40960 [00:42<01:52, 263.45batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  28%|▎| 11379/40960 [00:42<01:49, 270.46batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  28%|▎| 11379/40960 [00:42<01:49, 270.46batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  28%|▎| 11435/40960 [00:42<01:48, 273.20batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  28%|▎| 11435/40960 [00:42<01:48, 273.20batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  28%|▎| 11492/40960 [00:43<01:46, 275.94batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  28%|▎| 11492/40960 [00:43<01:46, 275.94batches/s, l2_loss: 0.0970 - round_los\u001b[A\n",
      "Training:  28%|▎| 11553/40960 [00:43<01:43, 284.12batches/s, l2_loss: 0.0970 - round_los\u001b[A\n",
      "Training:  28%|▎| 11553/40960 [00:43<01:43, 284.12batches/s, l2_loss: 0.0977 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:43<01:47, 272.92batches/s, l2_loss: 0.0977 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:43<01:47, 272.92batches/s, l2_loss: 0.0977 - round_los\u001b[A\n",
      "Training:  28%|▎| 11664/40960 [00:43<01:43, 281.92batches/s, l2_loss: 0.0977 - round_los\u001b[A\n",
      "Training:  28%|▎| 11664/40960 [00:43<01:43, 281.92batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  29%|▎| 11726/40960 [00:43<01:41, 289.10batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  29%|▎| 11726/40960 [00:43<01:41, 289.10batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  29%|▎| 11783/40960 [00:44<01:41, 287.53batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  29%|▎| 11783/40960 [00:44<01:41, 287.53batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  29%|▎| 11841/40960 [00:44<01:41, 287.76batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  29%|▎| 11841/40960 [00:44<01:41, 287.76batches/s, l2_loss: 0.0969 - round_los\u001b[A\n",
      "Training:  29%|▎| 11901/40960 [00:44<01:39, 291.11batches/s, l2_loss: 0.0969 - round_los\u001b[A\n",
      "Training:  29%|▎| 11901/40960 [00:44<01:39, 291.11batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  29%|▎| 11960/40960 [00:44<01:39, 291.47batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  29%|▎| 11960/40960 [00:44<01:39, 291.47batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  29%|▎| 11995/40960 [00:44<01:53, 255.65batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  29%|▎| 11995/40960 [00:44<01:53, 255.65batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  29%|▎| 12052/40960 [00:45<01:49, 263.35batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  29%|▎| 12052/40960 [00:45<01:49, 263.35batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  30%|▎| 12112/40960 [00:45<01:45, 273.61batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  30%|▎| 12112/40960 [00:45<01:45, 273.61batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  30%|▎| 12172/40960 [00:45<01:42, 280.40batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  30%|▎| 12172/40960 [00:45<01:42, 280.40batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  30%|▎| 12229/40960 [00:45<01:42, 280.06batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  30%|▎| 12229/40960 [00:45<01:42, 280.06batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  30%|▎| 12282/40960 [00:45<01:44, 274.76batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  30%|▎| 12282/40960 [00:45<01:44, 274.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  30%|▎| 12337/40960 [00:46<01:44, 273.59batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  30%|▎| 12337/40960 [00:46<01:44, 273.59batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  30%|▎| 12397/40960 [00:46<01:41, 280.71batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  30%|▎| 12397/40960 [00:46<01:41, 280.71batches/s, l2_loss: 0.0969 - round_los\u001b[A\n",
      "Training:  30%|▎| 12458/40960 [00:46<01:39, 286.59batches/s, l2_loss: 0.0969 - round_los\u001b[A\n",
      "Training:  30%|▎| 12458/40960 [00:46<01:39, 286.59batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  31%|▎| 12518/40960 [00:46<01:38, 290.21batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  31%|▎| 12518/40960 [00:46<01:38, 290.21batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  31%|▎| 12578/40960 [00:46<01:37, 292.12batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  31%|▎| 12578/40960 [00:46<01:37, 292.12batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  31%|▎| 12636/40960 [00:47<01:37, 290.44batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  31%|▎| 12636/40960 [00:47<01:37, 290.44batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  31%|▎| 12694/40960 [00:47<01:37, 289.27batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  31%|▎| 12694/40960 [00:47<01:37, 289.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  31%|▎| 12753/40960 [00:47<01:37, 290.76batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  31%|▎| 12753/40960 [00:47<01:37, 290.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  31%|▎| 12811/40960 [00:47<01:37, 289.85batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  31%|▎| 12811/40960 [00:47<01:37, 289.85batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  31%|▎| 12866/40960 [00:47<01:38, 285.39batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  31%|▎| 12866/40960 [00:47<01:38, 285.39batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  32%|▎| 12921/40960 [00:48<01:39, 281.92batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  32%|▎| 12921/40960 [00:48<01:39, 281.92batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  32%|▎| 12971/40960 [00:48<01:43, 270.99batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  32%|▎| 12971/40960 [00:48<01:43, 270.99batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  32%|▎| 13019/40960 [00:48<01:47, 260.59batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  32%|▎| 13019/40960 [00:48<01:47, 260.59batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  32%|▎| 13070/40960 [00:48<01:48, 257.43batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  32%|▎| 13070/40960 [00:48<01:48, 257.43batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  32%|▎| 13126/40960 [00:48<01:45, 263.28batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  32%|▎| 13126/40960 [00:48<01:45, 263.28batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  32%|▎| 13185/40960 [00:49<01:42, 271.26batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  32%|▎| 13185/40960 [00:49<01:42, 271.26batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  32%|▎| 13235/40960 [00:49<01:44, 264.91batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  32%|▎| 13235/40960 [00:49<01:44, 264.91batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  32%|▎| 13292/40960 [00:49<01:42, 270.11batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  32%|▎| 13292/40960 [00:49<01:42, 270.11batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  33%|▎| 13353/40960 [00:49<01:38, 280.13batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  33%|▎| 13353/40960 [00:49<01:38, 280.13batches/s, l2_loss: 0.0976 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|▎| 13411/40960 [00:49<01:37, 282.74batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  33%|▎| 13411/40960 [00:49<01:37, 282.74batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  33%|▎| 13474/40960 [00:50<01:34, 291.73batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  33%|▎| 13474/40960 [00:50<01:34, 291.73batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  33%|▎| 13525/40960 [00:50<01:38, 279.69batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  33%|▎| 13525/40960 [00:50<01:38, 279.69batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  33%|▎| 13584/40960 [00:50<01:36, 283.61batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  33%|▎| 13584/40960 [00:50<01:36, 283.61batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  33%|▎| 13644/40960 [00:50<01:35, 287.49batches/s, l2_loss: 0.0976 - round_los\u001b[A\n",
      "Training:  33%|▎| 13644/40960 [00:50<01:35, 287.49batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  33%|▎| 13706/40960 [00:50<01:32, 293.69batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  33%|▎| 13706/40960 [00:50<01:32, 293.69batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  34%|▎| 13765/40960 [00:51<01:32, 293.31batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  34%|▎| 13765/40960 [00:51<01:32, 293.31batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  34%|▎| 13824/40960 [00:51<01:32, 293.01batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  34%|▎| 13824/40960 [00:51<01:32, 293.01batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  34%|▎| 13883/40960 [00:51<01:32, 293.27batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  34%|▎| 13883/40960 [00:51<01:32, 293.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  34%|▎| 13941/40960 [00:51<01:32, 290.79batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  34%|▎| 13941/40960 [00:51<01:32, 290.79batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  34%|▎| 13999/40960 [00:51<01:32, 290.55batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  34%|▎| 13999/40960 [00:51<01:32, 290.55batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  34%|▎| 14059/40960 [00:52<01:31, 292.82batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  34%|▎| 14059/40960 [00:52<01:31, 292.82batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  34%|▎| 14122/40960 [00:52<01:30, 298.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  34%|▎| 14122/40960 [00:52<01:30, 298.17batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14179/40960 [00:52<01:31, 294.12batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14179/40960 [00:52<01:31, 294.12batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  35%|▎| 14241/40960 [00:52<01:29, 298.86batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  35%|▎| 14241/40960 [00:52<01:29, 298.86batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  35%|▎| 14301/40960 [00:52<01:29, 298.69batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  35%|▎| 14301/40960 [00:52<01:29, 298.69batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14361/40960 [00:53<01:29, 297.70batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14361/40960 [00:53<01:29, 297.70batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14421/40960 [00:53<01:29, 297.92batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14421/40960 [00:53<01:29, 297.92batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14468/40960 [00:53<01:35, 278.56batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14468/40960 [00:53<01:35, 278.56batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14524/40960 [00:53<01:34, 278.29batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  35%|▎| 14524/40960 [00:53<01:34, 278.29batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  36%|▎| 14580/40960 [00:53<01:35, 277.18batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  36%|▎| 14580/40960 [00:53<01:35, 277.18batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  36%|▎| 14637/40960 [00:54<01:34, 279.40batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  36%|▎| 14637/40960 [00:54<01:34, 279.40batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  36%|▎| 14684/40960 [00:54<01:38, 265.99batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  36%|▎| 14684/40960 [00:54<01:38, 265.99batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  36%|▎| 14721/40960 [00:54<01:48, 241.08batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  36%|▎| 14721/40960 [00:54<01:48, 241.08batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  36%|▎| 14778/40960 [00:54<01:43, 253.81batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  36%|▎| 14778/40960 [00:54<01:43, 253.81batches/s, l2_loss: 0.0970 - round_los\u001b[A\n",
      "Training:  36%|▎| 14836/40960 [00:54<01:39, 263.87batches/s, l2_loss: 0.0970 - round_los\u001b[A\n",
      "Training:  36%|▎| 14836/40960 [00:54<01:39, 263.87batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:55<01:35, 272.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:55<01:35, 272.80batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  37%|▎| 14952/40960 [00:55<01:34, 275.94batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  37%|▎| 14952/40960 [00:55<01:34, 275.94batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15011/40960 [00:55<01:32, 281.18batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15011/40960 [00:55<01:32, 281.18batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15072/40960 [00:55<01:29, 287.77batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15072/40960 [00:55<01:29, 287.77batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  37%|▎| 15127/40960 [00:55<01:31, 283.06batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  37%|▎| 15127/40960 [00:55<01:31, 283.06batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15169/40960 [00:56<01:39, 259.58batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15169/40960 [00:56<01:39, 259.58batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  37%|▎| 15226/40960 [00:56<01:36, 265.84batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  37%|▎| 15226/40960 [00:56<01:36, 265.84batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15270/40960 [00:56<01:42, 251.68batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15270/40960 [00:56<01:42, 251.68batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15325/40960 [00:56<01:39, 257.88batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  37%|▎| 15325/40960 [00:56<01:39, 257.88batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  38%|▍| 15376/40960 [00:56<01:40, 255.48batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  38%|▍| 15376/40960 [00:56<01:40, 255.48batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  38%|▍| 15425/40960 [00:57<01:41, 250.95batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  38%|▍| 15425/40960 [00:57<01:41, 250.95batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  38%|▍| 15474/40960 [00:57<01:42, 248.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  38%|▍| 15474/40960 [00:57<01:42, 248.45batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  38%|▍| 15527/40960 [00:57<01:40, 252.17batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  38%|▍| 15527/40960 [00:57<01:40, 252.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  38%|▍| 15580/40960 [00:57<01:39, 255.98batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  38%|▍| 15580/40960 [00:57<01:39, 255.98batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  38%|▍| 15639/40960 [00:57<01:34, 267.54batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  38%|▍| 15639/40960 [00:57<01:34, 267.54batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  38%|▍| 15698/40960 [00:58<01:31, 275.26batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  38%|▍| 15698/40960 [00:58<01:31, 275.26batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  38%|▍| 15758/40960 [00:58<01:29, 282.01batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  38%|▍| 15758/40960 [00:58<01:29, 282.01batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  39%|▍| 15818/40960 [00:58<01:27, 286.39batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  39%|▍| 15818/40960 [00:58<01:27, 286.39batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  39%|▍| 15878/40960 [00:58<01:26, 289.37batches/s, l2_loss: 0.0974 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|▍| 15878/40960 [00:58<01:26, 289.37batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  39%|▍| 15935/40960 [00:58<01:27, 286.72batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  39%|▍| 15935/40960 [00:59<01:27, 286.72batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  39%|▍| 15994/40960 [00:59<01:26, 288.19batches/s, l2_loss: 0.0975 - round_los\u001b[A\n",
      "Training:  39%|▍| 15994/40960 [00:59<01:26, 288.19batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  39%|▍| 16053/40960 [00:59<01:26, 289.10batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  39%|▍| 16053/40960 [00:59<01:26, 289.10batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  39%|▍| 16115/40960 [00:59<01:24, 294.83batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  39%|▍| 16115/40960 [00:59<01:24, 294.83batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  39%|▍| 16177/40960 [00:59<01:23, 298.09batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  39%|▍| 16177/40960 [00:59<01:23, 298.09batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  40%|▍| 16236/40960 [01:00<01:23, 296.15batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  40%|▍| 16236/40960 [01:00<01:23, 296.15batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  40%|▍| 16291/40960 [01:00<01:25, 288.95batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  40%|▍| 16291/40960 [01:00<01:25, 288.95batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  40%|▍| 16342/40960 [01:00<01:28, 278.52batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  40%|▍| 16342/40960 [01:00<01:28, 278.52batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  40%|▍| 16404/40960 [01:00<01:25, 286.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  40%|▍| 16404/40960 [01:00<01:25, 286.80batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  40%|▍| 16464/40960 [01:00<01:24, 290.17batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  40%|▍| 16464/40960 [01:00<01:24, 290.17batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  40%|▍| 16526/40960 [01:01<01:22, 294.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  40%|▍| 16526/40960 [01:01<01:22, 294.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  40%|▍| 16588/40960 [01:01<01:21, 299.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  40%|▍| 16588/40960 [01:01<01:21, 299.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  41%|▍| 16642/40960 [01:01<01:23, 289.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  41%|▍| 16642/40960 [01:01<01:23, 289.64batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  41%|▍| 16699/40960 [01:01<01:24, 288.15batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  41%|▍| 16699/40960 [01:01<01:24, 288.15batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  41%|▍| 16761/40960 [01:01<01:22, 293.41batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  41%|▍| 16761/40960 [01:01<01:22, 293.41batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  41%|▍| 16820/40960 [01:02<01:22, 293.60batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  41%|▍| 16820/40960 [01:02<01:22, 293.60batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  41%|▍| 16881/40960 [01:02<01:21, 296.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  41%|▍| 16881/40960 [01:02<01:21, 296.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  41%|▍| 16941/40960 [01:02<01:20, 297.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  41%|▍| 16941/40960 [01:02<01:20, 297.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  42%|▍| 17000/40960 [01:02<01:21, 295.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  42%|▍| 17000/40960 [01:02<01:21, 295.75batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  42%|▍| 17055/40960 [01:02<01:22, 288.78batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  42%|▍| 17055/40960 [01:02<01:22, 288.78batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  42%|▍| 17109/40960 [01:03<01:24, 283.15batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  42%|▍| 17109/40960 [01:03<01:24, 283.15batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  42%|▍| 17165/40960 [01:03<01:24, 281.68batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  42%|▍| 17165/40960 [01:03<01:24, 281.68batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  42%|▍| 17217/40960 [01:03<01:26, 274.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  42%|▍| 17217/40960 [01:03<01:26, 274.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  42%|▍| 17275/40960 [01:03<01:24, 278.76batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  42%|▍| 17275/40960 [01:03<01:24, 278.76batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  42%|▍| 17334/40960 [01:03<01:23, 282.56batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  42%|▍| 17334/40960 [01:03<01:23, 282.56batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  42%|▍| 17393/40960 [01:04<01:22, 285.37batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  42%|▍| 17393/40960 [01:04<01:22, 285.37batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  43%|▍| 17453/40960 [01:04<01:21, 289.15batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  43%|▍| 17453/40960 [01:04<01:21, 289.15batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  43%|▍| 17514/40960 [01:04<01:19, 293.56batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  43%|▍| 17514/40960 [01:04<01:19, 293.56batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  43%|▍| 17571/40960 [01:04<01:20, 290.35batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  43%|▍| 17571/40960 [01:04<01:20, 290.35batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  43%|▍| 17629/40960 [01:04<01:20, 289.97batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  43%|▍| 17629/40960 [01:04<01:20, 289.97batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  43%|▍| 17668/40960 [01:05<01:29, 261.44batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  43%|▍| 17668/40960 [01:05<01:29, 261.44batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  43%|▍| 17719/40960 [01:05<01:30, 257.05batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  43%|▍| 17719/40960 [01:05<01:30, 257.05batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  43%|▍| 17774/40960 [01:05<01:28, 261.82batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  43%|▍| 17774/40960 [01:05<01:28, 261.82batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  44%|▍| 17829/40960 [01:05<01:27, 264.80batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  44%|▍| 17829/40960 [01:05<01:27, 264.80batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  44%|▍| 17878/40960 [01:05<01:29, 258.06batches/s, l2_loss: 0.0974 - round_los\u001b[A\n",
      "Training:  44%|▍| 17878/40960 [01:05<01:29, 258.06batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  44%|▍| 17933/40960 [01:06<01:27, 262.60batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  44%|▍| 17933/40960 [01:06<01:27, 262.60batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  44%|▍| 17990/40960 [01:06<01:25, 268.58batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  44%|▍| 17990/40960 [01:06<01:25, 268.58batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  44%|▍| 18046/40960 [01:06<01:24, 271.10batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  44%|▍| 18046/40960 [01:06<01:24, 271.10batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  44%|▍| 18108/40960 [01:06<01:20, 282.37batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  44%|▍| 18108/40960 [01:06<01:20, 282.37batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  44%|▍| 18171/40960 [01:06<01:18, 290.79batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  44%|▍| 18171/40960 [01:06<01:18, 290.79batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  45%|▍| 18231/40960 [01:07<01:17, 292.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  45%|▍| 18231/40960 [01:07<01:17, 292.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  45%|▍| 18290/40960 [01:07<01:17, 293.20batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  45%|▍| 18290/40960 [01:07<01:17, 293.20batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18349/40960 [01:07<01:17, 293.49batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18349/40960 [01:07<01:17, 293.49batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18406/40960 [01:07<01:17, 290.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18406/40960 [01:07<01:17, 290.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 18463/40960 [01:07<01:18, 288.24batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  45%|▍| 18463/40960 [01:07<01:18, 288.24batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18517/40960 [01:08<01:19, 282.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18517/40960 [01:08<01:19, 282.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18575/40960 [01:08<01:18, 283.55batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18575/40960 [01:08<01:18, 283.55batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18621/40960 [01:08<01:24, 265.61batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  45%|▍| 18621/40960 [01:08<01:24, 265.61batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  46%|▍| 18679/40960 [01:08<01:21, 272.25batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  46%|▍| 18679/40960 [01:08<01:21, 272.25batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 18740/40960 [01:08<01:19, 280.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 18740/40960 [01:08<01:19, 280.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 18799/40960 [01:09<01:17, 284.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 18799/40960 [01:09<01:17, 284.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 18858/40960 [01:09<01:17, 286.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 18858/40960 [01:09<01:17, 286.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 18919/40960 [01:09<01:15, 291.06batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 18919/40960 [01:09<01:15, 291.06batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  46%|▍| 18972/40960 [01:09<01:17, 282.39batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  46%|▍| 18972/40960 [01:09<01:17, 282.39batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 19031/40960 [01:09<01:16, 285.00batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  46%|▍| 19031/40960 [01:09<01:16, 285.00batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  47%|▍| 19091/40960 [01:10<01:15, 289.30batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  47%|▍| 19091/40960 [01:10<01:15, 289.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  47%|▍| 19149/40960 [01:10<01:15, 288.31batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  47%|▍| 19149/40960 [01:10<01:15, 288.31batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  47%|▍| 19210/40960 [01:10<01:14, 292.26batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  47%|▍| 19210/40960 [01:10<01:14, 292.26batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  47%|▍| 19269/40960 [01:10<01:14, 291.98batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  47%|▍| 19269/40960 [01:10<01:14, 291.98batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  47%|▍| 19327/40960 [01:10<01:14, 291.21batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  47%|▍| 19327/40960 [01:10<01:14, 291.21batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  47%|▍| 19378/40960 [01:11<01:17, 280.28batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  47%|▍| 19378/40960 [01:11<01:17, 280.28batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  47%|▍| 19438/40960 [01:11<01:15, 285.56batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  47%|▍| 19438/40960 [01:11<01:15, 285.56batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  48%|▍| 19499/40960 [01:11<01:13, 290.28batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  48%|▍| 19499/40960 [01:11<01:13, 290.28batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  48%|▍| 19558/40960 [01:11<01:13, 291.14batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  48%|▍| 19558/40960 [01:11<01:13, 291.14batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  48%|▍| 19618/40960 [01:11<01:12, 292.67batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  48%|▍| 19618/40960 [01:11<01:12, 292.67batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  48%|▍| 19678/40960 [01:12<01:12, 294.50batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  48%|▍| 19678/40960 [01:12<01:12, 294.50batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  48%|▍| 19741/40960 [01:12<01:10, 299.86batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  48%|▍| 19741/40960 [01:12<01:10, 299.86batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  48%|▍| 19801/40960 [01:12<01:10, 299.84batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  48%|▍| 19801/40960 [01:12<01:10, 299.84batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  48%|▍| 19860/40960 [01:12<01:10, 297.18batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  48%|▍| 19860/40960 [01:12<01:10, 297.18batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 19921/40960 [01:12<01:10, 298.22batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 19921/40960 [01:12<01:10, 298.22batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 19979/40960 [01:13<01:11, 295.35batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 19979/40960 [01:13<01:11, 295.35batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 20038/40960 [01:13<01:10, 294.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 20038/40960 [01:13<01:10, 294.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 20097/40960 [01:13<01:10, 294.64batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 20097/40960 [01:13<01:10, 294.64batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 20154/40960 [01:13<01:11, 291.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 20154/40960 [01:13<01:11, 291.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 20215/40960 [01:13<01:10, 294.21batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  49%|▍| 20215/40960 [01:13<01:10, 294.21batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  49%|▍| 20268/40960 [01:14<01:12, 284.58batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  49%|▍| 20268/40960 [01:14<01:12, 284.58batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▍| 20328/40960 [01:14<01:11, 287.90batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▍| 20328/40960 [01:14<01:11, 287.90batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▍| 20383/40960 [01:14<01:12, 283.72batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▍| 20383/40960 [01:14<01:12, 283.72batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▍| 20443/40960 [01:14<01:11, 287.00batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▍| 20443/40960 [01:14<01:11, 287.00batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▌| 20500/40960 [01:14<01:11, 285.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▌| 20500/40960 [01:14<01:11, 285.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▌| 20561/40960 [01:15<01:10, 290.96batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▌| 20561/40960 [01:15<01:10, 290.96batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▌| 20622/40960 [01:15<01:09, 294.67batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  50%|▌| 20622/40960 [01:15<01:09, 294.67batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  50%|▌| 20684/40960 [01:15<01:08, 298.03batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  50%|▌| 20684/40960 [01:15<01:08, 298.03batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  51%|▌| 20746/40960 [01:15<01:07, 301.06batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  51%|▌| 20746/40960 [01:15<01:07, 301.06batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 20803/40960 [01:15<01:08, 295.14batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 20803/40960 [01:15<01:08, 295.14batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 20864/40960 [01:16<01:07, 297.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 20864/40960 [01:16<01:07, 297.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 20926/40960 [01:16<01:06, 300.05batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 20926/40960 [01:16<01:06, 300.05batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 20987/40960 [01:16<01:06, 301.13batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 20987/40960 [01:16<01:06, 301.13batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  51%|▌| 21046/40960 [01:16<01:06, 298.64batches/s, l2_loss: 0.0972 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|▌| 21046/40960 [01:16<01:06, 298.64batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  52%|▌| 21108/40960 [01:16<01:05, 301.50batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  52%|▌| 21108/40960 [01:16<01:05, 301.50batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  52%|▌| 21168/40960 [01:17<01:05, 300.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  52%|▌| 21168/40960 [01:17<01:05, 300.51batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  52%|▌| 21228/40960 [01:17<01:05, 299.74batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  52%|▌| 21228/40960 [01:17<01:05, 299.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  52%|▌| 21286/40960 [01:17<01:06, 296.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  52%|▌| 21286/40960 [01:17<01:06, 296.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  52%|▌| 21343/40960 [01:17<01:07, 291.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  52%|▌| 21343/40960 [01:17<01:07, 291.85batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  52%|▌| 21401/40960 [01:17<01:07, 290.24batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  52%|▌| 21401/40960 [01:17<01:07, 290.24batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  52%|▌| 21460/40960 [01:18<01:06, 291.51batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  52%|▌| 21460/40960 [01:18<01:06, 291.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  53%|▌| 21521/40960 [01:18<01:06, 294.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  53%|▌| 21521/40960 [01:18<01:06, 294.32batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  53%|▌| 21579/40960 [01:18<01:06, 291.94batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  53%|▌| 21579/40960 [01:18<01:06, 291.94batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  53%|▌| 21639/40960 [01:18<01:05, 293.38batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  53%|▌| 21639/40960 [01:18<01:05, 293.38batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  53%|▌| 21701/40960 [01:18<01:04, 297.89batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  53%|▌| 21701/40960 [01:18<01:04, 297.89batches/s, l2_loss: 0.0970 - round_los\u001b[A\n",
      "Training:  53%|▌| 21762/40960 [01:19<01:04, 299.59batches/s, l2_loss: 0.0970 - round_los\u001b[A\n",
      "Training:  53%|▌| 21762/40960 [01:19<01:04, 299.59batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  53%|▌| 21817/40960 [01:19<01:05, 291.23batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  53%|▌| 21817/40960 [01:19<01:05, 291.23batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  53%|▌| 21876/40960 [01:19<01:05, 291.33batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  53%|▌| 21876/40960 [01:19<01:05, 291.33batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 21934/40960 [01:19<01:05, 290.60batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 21934/40960 [01:19<01:05, 290.60batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 21988/40960 [01:19<01:06, 283.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 21988/40960 [01:19<01:06, 283.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 22042/40960 [01:20<01:07, 279.05batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 22042/40960 [01:20<01:07, 279.05batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  54%|▌| 22096/40960 [01:20<01:08, 275.95batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  54%|▌| 22096/40960 [01:20<01:08, 275.95batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 22153/40960 [01:20<01:07, 278.04batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 22153/40960 [01:20<01:07, 278.04batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  54%|▌| 22203/40960 [01:20<01:09, 268.01batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  54%|▌| 22203/40960 [01:20<01:09, 268.01batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  54%|▌| 22262/40960 [01:20<01:07, 275.40batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  54%|▌| 22262/40960 [01:20<01:07, 275.40batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 22321/40960 [01:21<01:06, 280.28batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  54%|▌| 22321/40960 [01:21<01:06, 280.28batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22381/40960 [01:21<01:04, 286.09batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22381/40960 [01:21<01:04, 286.09batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22438/40960 [01:21<01:05, 284.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22438/40960 [01:21<01:05, 284.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22491/40960 [01:21<01:06, 277.65batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22491/40960 [01:21<01:06, 277.65batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  55%|▌| 22550/40960 [01:21<01:05, 282.73batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  55%|▌| 22550/40960 [01:22<01:05, 282.73batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  55%|▌| 22609/40960 [01:22<01:04, 286.09batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  55%|▌| 22609/40960 [01:22<01:04, 286.09batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22661/40960 [01:22<01:05, 277.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22661/40960 [01:22<01:05, 277.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22719/40960 [01:22<01:05, 280.33batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  55%|▌| 22719/40960 [01:22<01:05, 280.33batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 22780/40960 [01:22<01:03, 287.29batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 22780/40960 [01:22<01:03, 287.29batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 22842/40960 [01:23<01:01, 292.73batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 22842/40960 [01:23<01:01, 292.73batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  56%|▌| 22905/40960 [01:23<01:00, 298.01batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  56%|▌| 22905/40960 [01:23<01:00, 298.01batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 22963/40960 [01:23<01:01, 294.49batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 22963/40960 [01:23<01:01, 294.49batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  56%|▌| 23024/40960 [01:23<01:00, 296.01batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  56%|▌| 23024/40960 [01:23<01:00, 296.01batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 23080/40960 [01:23<01:01, 291.16batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 23080/40960 [01:23<01:01, 291.16batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 23131/40960 [01:24<01:03, 279.45batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  56%|▌| 23131/40960 [01:24<01:03, 279.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  57%|▌| 23186/40960 [01:24<01:04, 277.62batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  57%|▌| 23186/40960 [01:24<01:04, 277.62batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  57%|▌| 23241/40960 [01:24<01:04, 276.46batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  57%|▌| 23241/40960 [01:24<01:04, 276.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  57%|▌| 23293/40960 [01:24<01:05, 270.32batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  57%|▌| 23293/40960 [01:24<01:05, 270.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  57%|▌| 23351/40960 [01:24<01:03, 275.91batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  57%|▌| 23351/40960 [01:24<01:03, 275.91batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  57%|▌| 23410/40960 [01:25<01:02, 280.35batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  57%|▌| 23410/40960 [01:25<01:02, 280.35batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  57%|▌| 23471/40960 [01:25<01:00, 287.48batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  57%|▌| 23471/40960 [01:25<01:00, 287.48batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  57%|▌| 23518/40960 [01:25<01:04, 268.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  57%|▌| 23518/40960 [01:25<01:04, 268.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23572/40960 [01:25<01:04, 268.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23572/40960 [01:25<01:04, 268.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|▌| 23633/40960 [01:25<01:02, 278.14batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23633/40960 [01:25<01:02, 278.14batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23692/40960 [01:26<01:01, 282.53batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23692/40960 [01:26<01:01, 282.53batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  58%|▌| 23751/40960 [01:26<01:00, 285.31batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  58%|▌| 23751/40960 [01:26<01:00, 285.31batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23802/40960 [01:26<01:02, 274.98batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23802/40960 [01:26<01:02, 274.98batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23860/40960 [01:26<01:01, 278.93batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23860/40960 [01:26<01:01, 278.93batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23916/40960 [01:26<01:01, 278.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  58%|▌| 23916/40960 [01:26<01:01, 278.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 23962/40960 [01:27<01:04, 263.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 23962/40960 [01:27<01:04, 263.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 24017/40960 [01:27<01:03, 266.16batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 24017/40960 [01:27<01:03, 266.16batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 24071/40960 [01:27<01:03, 266.69batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 24071/40960 [01:27<01:03, 266.69batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  59%|▌| 24132/40960 [01:27<01:00, 277.85batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  59%|▌| 24132/40960 [01:27<01:00, 277.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 24188/40960 [01:27<01:00, 278.17batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 24188/40960 [01:27<01:00, 278.17batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 24239/40960 [01:28<01:01, 270.52batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  59%|▌| 24239/40960 [01:28<01:01, 270.52batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  59%|▌| 24297/40960 [01:28<01:00, 276.02batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  59%|▌| 24297/40960 [01:28<01:00, 276.02batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  59%|▌| 24352/40960 [01:28<01:00, 274.57batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  59%|▌| 24352/40960 [01:28<01:00, 274.57batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  60%|▌| 24409/40960 [01:28<00:59, 277.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  60%|▌| 24409/40960 [01:28<00:59, 277.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  60%|▌| 24467/40960 [01:28<00:58, 280.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  60%|▌| 24467/40960 [01:28<00:58, 280.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  60%|▌| 24522/40960 [01:29<00:58, 278.78batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  60%|▌| 24522/40960 [01:29<00:58, 278.78batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  60%|▌| 24576/40960 [01:29<00:59, 276.09batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  60%|▌| 24576/40960 [01:29<00:59, 276.09batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  60%|▌| 24632/40960 [01:29<00:58, 277.17batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  60%|▌| 24632/40960 [01:29<00:58, 277.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  60%|▌| 24694/40960 [01:29<00:56, 285.59batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  60%|▌| 24694/40960 [01:29<00:56, 285.59batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  60%|▌| 24753/40960 [01:29<00:56, 287.39batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  60%|▌| 24753/40960 [01:29<00:56, 287.39batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  61%|▌| 24809/40960 [01:30<00:56, 284.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  61%|▌| 24809/40960 [01:30<00:56, 284.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  61%|▌| 24868/40960 [01:30<00:55, 287.53batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  61%|▌| 24868/40960 [01:30<00:55, 287.53batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  61%|▌| 24924/40960 [01:30<00:56, 284.00batches/s, l2_loss: 0.0973 - round_los\u001b[A\n",
      "Training:  61%|▌| 24924/40960 [01:30<00:56, 284.00batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  61%|▌| 24974/40960 [01:30<00:58, 273.22batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  61%|▌| 24974/40960 [01:30<00:58, 273.22batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  61%|▌| 25030/40960 [01:30<00:58, 274.57batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  61%|▌| 25030/40960 [01:30<00:58, 274.57batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  61%|▌| 25087/40960 [01:31<00:57, 276.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  61%|▌| 25087/40960 [01:31<00:57, 276.85batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  61%|▌| 25142/40960 [01:31<00:57, 275.00batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  61%|▌| 25142/40960 [01:31<00:57, 275.00batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25199/40960 [01:31<00:56, 277.50batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25199/40960 [01:31<00:56, 277.50batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  62%|▌| 25255/40960 [01:31<00:56, 276.66batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  62%|▌| 25255/40960 [01:31<00:56, 276.66batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25315/40960 [01:31<00:55, 283.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25315/40960 [01:31<00:55, 283.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25377/40960 [01:32<00:53, 290.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25377/40960 [01:32<00:53, 290.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25435/40960 [01:32<00:53, 289.53batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25435/40960 [01:32<00:53, 289.53batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  62%|▌| 25493/40960 [01:32<00:53, 288.96batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  62%|▌| 25493/40960 [01:32<00:53, 288.96batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25554/40960 [01:32<00:52, 292.81batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  62%|▌| 25554/40960 [01:32<00:52, 292.81batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  63%|▋| 25615/40960 [01:32<00:51, 295.92batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  63%|▋| 25615/40960 [01:32<00:51, 295.92batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25674/40960 [01:33<00:51, 295.41batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25674/40960 [01:33<00:51, 295.41batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25736/40960 [01:33<00:50, 299.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25736/40960 [01:33<00:50, 299.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25797/40960 [01:33<00:50, 299.97batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25797/40960 [01:33<00:50, 299.97batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25858/40960 [01:33<00:50, 300.67batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25858/40960 [01:33<00:50, 300.67batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25919/40960 [01:33<00:50, 300.55batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25919/40960 [01:33<00:50, 300.55batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25977/40960 [01:34<00:50, 297.27batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  63%|▋| 25977/40960 [01:34<00:50, 297.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  64%|▋| 26037/40960 [01:34<00:50, 297.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  64%|▋| 26037/40960 [01:34<00:50, 297.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  64%|▋| 26096/40960 [01:34<00:50, 296.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  64%|▋| 26096/40960 [01:34<00:50, 296.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  64%|▋| 26149/40960 [01:34<00:52, 284.73batches/s, l2_loss: 0.0972 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|▋| 26149/40960 [01:34<00:52, 284.73batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  64%|▋| 26205/40960 [01:34<00:52, 282.60batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  64%|▋| 26205/40960 [01:34<00:52, 282.60batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  64%|▋| 26260/40960 [01:35<00:52, 279.79batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  64%|▋| 26260/40960 [01:35<00:52, 279.79batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  64%|▋| 26317/40960 [01:35<00:52, 281.15batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  64%|▋| 26317/40960 [01:35<00:52, 281.15batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  64%|▋| 26376/40960 [01:35<00:51, 285.21batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  64%|▋| 26376/40960 [01:35<00:51, 285.21batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  65%|▋| 26432/40960 [01:35<00:51, 280.92batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  65%|▋| 26432/40960 [01:35<00:51, 280.92batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  65%|▋| 26490/40960 [01:35<00:51, 283.15batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  65%|▋| 26490/40960 [01:35<00:51, 283.15batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  65%|▋| 26548/40960 [01:36<00:50, 284.95batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  65%|▋| 26548/40960 [01:36<00:50, 284.95batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  65%|▋| 26606/40960 [01:36<00:50, 285.48batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  65%|▋| 26606/40960 [01:36<00:50, 285.48batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  65%|▋| 26665/40960 [01:36<00:49, 288.16batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  65%|▋| 26665/40960 [01:36<00:49, 288.16batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  65%|▋| 26723/40960 [01:36<00:49, 288.50batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  65%|▋| 26723/40960 [01:36<00:49, 288.50batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  65%|▋| 26782/40960 [01:36<00:48, 289.91batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  65%|▋| 26782/40960 [01:36<00:48, 289.91batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  66%|▋| 26836/40960 [01:37<00:49, 283.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  66%|▋| 26836/40960 [01:37<00:49, 283.76batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 26888/40960 [01:37<00:50, 276.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 26888/40960 [01:37<00:50, 276.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  66%|▋| 26947/40960 [01:37<00:49, 281.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  66%|▋| 26947/40960 [01:37<00:49, 281.17batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 27004/40960 [01:37<00:49, 280.93batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 27004/40960 [01:37<00:49, 280.93batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 27065/40960 [01:37<00:48, 287.45batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 27065/40960 [01:37<00:48, 287.45batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 27128/40960 [01:38<00:46, 295.18batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 27128/40960 [01:38<00:46, 295.18batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 27171/40960 [01:38<00:51, 268.39batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  66%|▋| 27171/40960 [01:38<00:51, 268.39batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  66%|▋| 27225/40960 [01:38<00:51, 267.54batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  66%|▋| 27225/40960 [01:38<00:51, 267.54batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  67%|▋| 27286/40960 [01:38<00:49, 278.28batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  67%|▋| 27286/40960 [01:38<00:49, 278.28batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  67%|▋| 27341/40960 [01:38<00:49, 275.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  67%|▋| 27341/40960 [01:38<00:49, 275.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  67%|▋| 27397/40960 [01:39<00:48, 276.90batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  67%|▋| 27397/40960 [01:39<00:48, 276.90batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  67%|▋| 27457/40960 [01:39<00:47, 283.60batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  67%|▋| 27457/40960 [01:39<00:47, 283.60batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  67%|▋| 27513/40960 [01:39<00:47, 281.09batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  67%|▋| 27513/40960 [01:39<00:47, 281.09batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  67%|▋| 27574/40960 [01:39<00:46, 288.20batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  67%|▋| 27574/40960 [01:39<00:46, 288.20batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  67%|▋| 27628/40960 [01:39<00:47, 282.70batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  67%|▋| 27628/40960 [01:39<00:47, 282.70batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  68%|▋| 27687/40960 [01:40<00:46, 286.36batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  68%|▋| 27687/40960 [01:40<00:46, 286.36batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  68%|▋| 27746/40960 [01:40<00:45, 288.92batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  68%|▋| 27746/40960 [01:40<00:45, 288.92batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  68%|▋| 27803/40960 [01:40<00:45, 286.05batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  68%|▋| 27803/40960 [01:40<00:45, 286.05batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  68%|▋| 27857/40960 [01:40<00:46, 280.71batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  68%|▋| 27857/40960 [01:40<00:46, 280.71batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  68%|▋| 27914/40960 [01:40<00:46, 280.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  68%|▋| 27914/40960 [01:40<00:46, 280.75batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  68%|▋| 27970/40960 [01:41<00:46, 280.09batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  68%|▋| 27970/40960 [01:41<00:46, 280.09batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  68%|▋| 28021/40960 [01:41<00:47, 272.31batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  68%|▋| 28021/40960 [01:41<00:47, 272.31batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  69%|▋| 28069/40960 [01:41<00:49, 262.22batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  69%|▋| 28069/40960 [01:41<00:49, 262.22batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  69%|▋| 28117/40960 [01:41<00:50, 254.99batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  69%|▋| 28117/40960 [01:41<00:50, 254.99batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28167/40960 [01:41<00:50, 253.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28167/40960 [01:41<00:50, 253.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28225/40960 [01:42<00:48, 263.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28225/40960 [01:42<00:48, 263.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28281/40960 [01:42<00:47, 267.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28281/40960 [01:42<00:47, 267.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28340/40960 [01:42<00:46, 274.22batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28340/40960 [01:42<00:46, 274.22batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28386/40960 [01:42<00:48, 260.19batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  69%|▋| 28386/40960 [01:42<00:48, 260.19batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  69%|▋| 28437/40960 [01:42<00:48, 258.05batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  69%|▋| 28437/40960 [01:42<00:48, 258.05batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  70%|▋| 28497/40960 [01:43<00:46, 270.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  70%|▋| 28497/40960 [01:43<00:46, 270.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  70%|▋| 28544/40960 [01:43<00:47, 259.56batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  70%|▋| 28544/40960 [01:43<00:47, 259.56batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  70%|▋| 28604/40960 [01:43<00:45, 270.43batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  70%|▋| 28604/40960 [01:43<00:45, 270.43batches/s, l2_loss: 0.0972 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28664/40960 [01:43<00:44, 278.43batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  70%|▋| 28664/40960 [01:43<00:44, 278.43batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  70%|▋| 28724/40960 [01:43<00:43, 284.42batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  70%|▋| 28724/40960 [01:43<00:43, 284.42batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  70%|▋| 28783/40960 [01:44<00:42, 286.83batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  70%|▋| 28783/40960 [01:44<00:42, 286.83batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  70%|▋| 28843/40960 [01:44<00:41, 289.48batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  70%|▋| 28843/40960 [01:44<00:41, 289.48batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  71%|▋| 28901/40960 [01:44<00:41, 288.25batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  71%|▋| 28901/40960 [01:44<00:41, 288.25batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  71%|▋| 28962/40960 [01:44<00:41, 292.36batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  71%|▋| 28962/40960 [01:44<00:41, 292.36batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  71%|▋| 29023/40960 [01:45<00:40, 294.87batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  71%|▋| 29023/40960 [01:45<00:40, 294.87batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  71%|▋| 29083/40960 [01:45<00:40, 296.24batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  71%|▋| 29083/40960 [01:45<00:40, 296.24batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  71%|▋| 29142/40960 [01:45<00:39, 295.79batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  71%|▋| 29142/40960 [01:45<00:39, 295.79batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  71%|▋| 29201/40960 [01:45<00:39, 294.97batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  71%|▋| 29201/40960 [01:45<00:39, 294.97batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  71%|▋| 29253/40960 [01:45<00:41, 284.00batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  71%|▋| 29253/40960 [01:45<00:41, 284.00batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29307/40960 [01:46<00:41, 279.18batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29307/40960 [01:46<00:41, 279.18batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29367/40960 [01:46<00:40, 285.25batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29367/40960 [01:46<00:40, 285.25batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29424/40960 [01:46<00:40, 285.11batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29424/40960 [01:46<00:40, 285.11batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  72%|▋| 29478/40960 [01:46<00:40, 280.39batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  72%|▋| 29478/40960 [01:46<00:40, 280.39batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29535/40960 [01:46<00:40, 281.21batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29535/40960 [01:46<00:40, 281.21batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29591/40960 [01:47<00:40, 280.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29591/40960 [01:47<00:40, 280.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29650/40960 [01:47<00:39, 284.75batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  72%|▋| 29650/40960 [01:47<00:39, 284.75batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 29710/40960 [01:47<00:38, 288.51batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 29710/40960 [01:47<00:38, 288.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  73%|▋| 29770/40960 [01:47<00:38, 291.13batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  73%|▋| 29770/40960 [01:47<00:38, 291.13batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  73%|▋| 29831/40960 [01:47<00:37, 294.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  73%|▋| 29831/40960 [01:47<00:37, 294.32batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 29892/40960 [01:48<00:37, 297.16batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 29892/40960 [01:48<00:37, 297.16batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 29953/40960 [01:48<00:36, 299.21batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 29953/40960 [01:48<00:36, 299.21batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 30012/40960 [01:48<00:36, 296.98batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 30012/40960 [01:48<00:36, 296.98batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 30070/40960 [01:48<00:36, 294.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  73%|▋| 30070/40960 [01:48<00:36, 294.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30128/40960 [01:48<00:36, 292.92batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30128/40960 [01:48<00:36, 292.92batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30183/40960 [01:49<00:37, 286.14batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30183/40960 [01:49<00:37, 286.14batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  74%|▋| 30242/40960 [01:49<00:37, 287.05batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  74%|▋| 30242/40960 [01:49<00:37, 287.05batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  74%|▋| 30294/40960 [01:49<00:38, 278.06batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  74%|▋| 30294/40960 [01:49<00:38, 278.06batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30347/40960 [01:49<00:38, 273.13batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30347/40960 [01:49<00:38, 273.13batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30401/40960 [01:49<00:38, 271.16batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30401/40960 [01:49<00:38, 271.16batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30458/40960 [01:50<00:38, 274.83batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  74%|▋| 30458/40960 [01:50<00:38, 274.83batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▋| 30517/40960 [01:50<00:37, 279.95batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▋| 30517/40960 [01:50<00:37, 279.95batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▋| 30578/40960 [01:50<00:36, 286.82batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▋| 30578/40960 [01:50<00:36, 286.82batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▋| 30635/40960 [01:50<00:36, 285.19batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▋| 30635/40960 [01:50<00:36, 285.19batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▋| 30698/40960 [01:50<00:35, 292.93batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▋| 30698/40960 [01:50<00:35, 292.93batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▊| 30759/40960 [01:51<00:34, 296.24batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▊| 30759/40960 [01:51<00:34, 296.24batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▊| 30820/40960 [01:51<00:34, 297.95batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▊| 30820/40960 [01:51<00:34, 297.95batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▊| 30882/40960 [01:51<00:33, 301.03batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  75%|▊| 30882/40960 [01:51<00:33, 301.03batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  76%|▊| 30940/40960 [01:51<00:33, 296.08batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  76%|▊| 30940/40960 [01:51<00:33, 296.08batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  76%|▊| 31000/40960 [01:51<00:33, 296.91batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  76%|▊| 31000/40960 [01:51<00:33, 296.91batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  76%|▊| 31056/40960 [01:52<00:34, 291.14batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  76%|▊| 31056/40960 [01:52<00:34, 291.14batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  76%|▊| 31114/40960 [01:52<00:33, 290.42batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  76%|▊| 31114/40960 [01:52<00:33, 290.42batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  76%|▊| 31173/40960 [01:52<00:33, 290.54batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  76%|▊| 31173/40960 [01:52<00:33, 290.54batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  76%|▊| 31231/40960 [01:52<00:33, 289.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31231/40960 [01:52<00:33, 289.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  76%|▊| 31283/40960 [01:52<00:34, 278.83batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  76%|▊| 31283/40960 [01:52<00:34, 278.83batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31338/40960 [01:53<00:34, 277.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31338/40960 [01:53<00:34, 277.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31396/40960 [01:53<00:34, 280.79batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31396/40960 [01:53<00:34, 280.79batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  77%|▊| 31454/40960 [01:53<00:33, 282.66batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  77%|▊| 31454/40960 [01:53<00:33, 282.66batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  77%|▊| 31496/40960 [01:53<00:36, 259.71batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  77%|▊| 31496/40960 [01:53<00:36, 259.71batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31530/40960 [01:53<00:40, 233.00batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31530/40960 [01:53<00:40, 233.00batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31584/40960 [01:54<00:38, 243.73batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31584/40960 [01:54<00:38, 243.73batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31636/40960 [01:54<00:37, 247.66batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31636/40960 [01:54<00:37, 247.66batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31679/40960 [01:54<00:39, 236.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  77%|▊| 31679/40960 [01:54<00:39, 236.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  77%|▊| 31724/40960 [01:54<00:39, 231.35batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  77%|▊| 31724/40960 [01:54<00:39, 231.35batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  78%|▊| 31766/40960 [01:54<00:41, 224.02batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  78%|▊| 31766/40960 [01:54<00:41, 224.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 31822/40960 [01:55<00:38, 239.84batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 31822/40960 [01:55<00:38, 239.84batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 31884/40960 [01:55<00:34, 259.54batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 31884/40960 [01:55<00:34, 259.54batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 31945/40960 [01:55<00:33, 272.84batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 31945/40960 [01:55<00:33, 272.84batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 32003/40960 [01:55<00:32, 276.91batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 32003/40960 [01:55<00:32, 276.91batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  78%|▊| 32063/40960 [01:55<00:31, 283.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  78%|▊| 32063/40960 [01:55<00:31, 283.45batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 32120/40960 [01:56<00:31, 282.26batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  78%|▊| 32120/40960 [01:56<00:31, 282.26batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  79%|▊| 32175/40960 [01:56<00:31, 279.31batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  79%|▊| 32175/40960 [01:56<00:31, 279.31batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  79%|▊| 32236/40960 [01:56<00:30, 285.79batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  79%|▊| 32236/40960 [01:56<00:30, 285.79batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  79%|▊| 32294/40960 [01:56<00:30, 285.41batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  79%|▊| 32294/40960 [01:56<00:30, 285.41batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  79%|▊| 32351/40960 [01:56<00:30, 284.61batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  79%|▊| 32351/40960 [01:56<00:30, 284.61batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  79%|▊| 32411/40960 [01:57<00:29, 289.17batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  79%|▊| 32411/40960 [01:57<00:29, 289.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  79%|▊| 32465/40960 [01:57<00:30, 282.31batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  79%|▊| 32465/40960 [01:57<00:30, 282.31batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  79%|▊| 32516/40960 [01:57<00:30, 273.79batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  79%|▊| 32516/40960 [01:57<00:30, 273.79batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  80%|▊| 32572/40960 [01:57<00:30, 275.19batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  80%|▊| 32572/40960 [01:57<00:30, 275.19batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  80%|▊| 32633/40960 [01:57<00:29, 283.23batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  80%|▊| 32633/40960 [01:57<00:29, 283.23batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  80%|▊| 32692/40960 [01:58<00:28, 286.61batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  80%|▊| 32692/40960 [01:58<00:28, 286.61batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  80%|▊| 32751/40960 [01:58<00:28, 288.62batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  80%|▊| 32751/40960 [01:58<00:28, 288.62batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  80%|▊| 32808/40960 [01:58<00:28, 287.02batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  80%|▊| 32808/40960 [01:58<00:28, 287.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  80%|▊| 32869/40960 [01:58<00:27, 291.45batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  80%|▊| 32869/40960 [01:58<00:27, 291.45batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  80%|▊| 32924/40960 [01:58<00:28, 286.09batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  80%|▊| 32924/40960 [01:58<00:28, 286.09batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  81%|▊| 32978/40960 [01:59<00:28, 280.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  81%|▊| 32978/40960 [01:59<00:28, 280.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  81%|▊| 33035/40960 [01:59<00:28, 280.83batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  81%|▊| 33035/40960 [01:59<00:28, 280.83batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  81%|▊| 33094/40960 [01:59<00:27, 283.75batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  81%|▊| 33094/40960 [01:59<00:27, 283.75batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  81%|▊| 33153/40960 [01:59<00:27, 286.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  81%|▊| 33153/40960 [01:59<00:27, 286.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  81%|▊| 33211/40960 [01:59<00:27, 286.13batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  81%|▊| 33211/40960 [01:59<00:27, 286.13batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  81%|▊| 33268/40960 [02:00<00:27, 284.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  81%|▊| 33268/40960 [02:00<00:27, 284.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  81%|▊| 33330/40960 [02:00<00:26, 290.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  81%|▊| 33330/40960 [02:00<00:26, 290.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  82%|▊| 33390/40960 [02:00<00:25, 293.16batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  82%|▊| 33390/40960 [02:00<00:25, 293.16batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33450/40960 [02:00<00:25, 293.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33450/40960 [02:00<00:25, 293.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33512/40960 [02:00<00:25, 297.65batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33512/40960 [02:00<00:25, 297.65batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  82%|▊| 33567/40960 [02:01<00:25, 290.29batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  82%|▊| 33567/40960 [02:01<00:25, 290.29batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33624/40960 [02:01<00:25, 288.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33624/40960 [02:01<00:25, 288.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33684/40960 [02:01<00:25, 290.58batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33684/40960 [02:01<00:25, 290.58batches/s, l2_loss: 0.0972 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|▊| 33744/40960 [02:01<00:24, 292.03batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  82%|▊| 33744/40960 [02:01<00:24, 292.03batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  83%|▊| 33805/40960 [02:01<00:24, 294.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  83%|▊| 33805/40960 [02:01<00:24, 294.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  83%|▊| 33860/40960 [02:02<00:24, 288.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  83%|▊| 33860/40960 [02:02<00:24, 288.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  83%|▊| 33908/40960 [02:02<00:25, 272.68batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  83%|▊| 33908/40960 [02:02<00:25, 272.68batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  83%|▊| 33970/40960 [02:02<00:24, 282.57batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  83%|▊| 33970/40960 [02:02<00:24, 282.57batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  83%|▊| 34029/40960 [02:02<00:24, 285.13batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  83%|▊| 34029/40960 [02:02<00:24, 285.13batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  83%|▊| 34087/40960 [02:02<00:24, 285.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  83%|▊| 34087/40960 [02:02<00:24, 285.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  83%|▊| 34142/40960 [02:03<00:24, 281.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  83%|▊| 34142/40960 [02:03<00:24, 281.47batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34202/40960 [02:03<00:23, 286.57batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34202/40960 [02:03<00:23, 286.57batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34261/40960 [02:03<00:23, 288.82batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34261/40960 [02:03<00:23, 288.82batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34320/40960 [02:03<00:22, 289.81batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34320/40960 [02:03<00:22, 289.81batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34379/40960 [02:03<00:22, 290.38batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34379/40960 [02:03<00:22, 290.38batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34435/40960 [02:04<00:22, 286.84batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34435/40960 [02:04<00:22, 286.84batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34494/40960 [02:04<00:22, 288.69batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34494/40960 [02:04<00:22, 288.69batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34554/40960 [02:04<00:21, 291.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  84%|▊| 34554/40960 [02:04<00:21, 291.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34612/40960 [02:04<00:21, 290.05batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34612/40960 [02:04<00:21, 290.05batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34669/40960 [02:04<00:21, 287.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34669/40960 [02:04<00:21, 287.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34730/40960 [02:05<00:21, 292.56batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34730/40960 [02:05<00:21, 292.56batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  85%|▊| 34790/40960 [02:05<00:20, 294.23batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  85%|▊| 34790/40960 [02:05<00:20, 294.23batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34848/40960 [02:05<00:20, 292.88batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34848/40960 [02:05<00:20, 292.88batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  85%|▊| 34908/40960 [02:05<00:20, 294.50batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  85%|▊| 34908/40960 [02:05<00:20, 294.50batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34968/40960 [02:05<00:20, 295.03batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  85%|▊| 34968/40960 [02:06<00:20, 295.03batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35023/40960 [02:06<00:20, 288.56batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35023/40960 [02:06<00:20, 288.56batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35080/40960 [02:06<00:20, 286.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35080/40960 [02:06<00:20, 286.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35140/40960 [02:06<00:20, 289.59batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35140/40960 [02:06<00:20, 289.59batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35198/40960 [02:06<00:19, 288.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35198/40960 [02:06<00:19, 288.76batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35254/40960 [02:07<00:20, 285.27batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35254/40960 [02:07<00:20, 285.27batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35310/40960 [02:07<00:20, 282.19batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35310/40960 [02:07<00:20, 282.19batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  86%|▊| 35364/40960 [02:07<00:20, 275.20batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  86%|▊| 35364/40960 [02:07<00:20, 275.20batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35416/40960 [02:07<00:20, 269.98batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  86%|▊| 35416/40960 [02:07<00:20, 269.98batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35476/40960 [02:07<00:19, 278.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35476/40960 [02:07<00:19, 278.17batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35532/40960 [02:08<00:19, 278.54batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35532/40960 [02:08<00:19, 278.54batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35593/40960 [02:08<00:18, 286.33batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35593/40960 [02:08<00:18, 286.33batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35649/40960 [02:08<00:18, 283.36batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35649/40960 [02:08<00:18, 283.36batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35695/40960 [02:08<00:19, 266.32batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35695/40960 [02:08<00:19, 266.32batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35749/40960 [02:08<00:19, 267.22batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35749/40960 [02:08<00:19, 267.22batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35808/40960 [02:09<00:18, 275.40batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  87%|▊| 35808/40960 [02:09<00:18, 275.40batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 35865/40960 [02:09<00:18, 277.44batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 35865/40960 [02:09<00:18, 277.44batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 35918/40960 [02:09<00:18, 273.53batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 35918/40960 [02:09<00:18, 273.53batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  88%|▉| 35973/40960 [02:09<00:18, 272.61batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  88%|▉| 35973/40960 [02:09<00:18, 272.61batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 36031/40960 [02:09<00:17, 276.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 36031/40960 [02:09<00:17, 276.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 36086/40960 [02:10<00:17, 275.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 36086/40960 [02:10<00:17, 275.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 36140/40960 [02:10<00:17, 273.15batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 36140/40960 [02:10<00:17, 273.15batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 36197/40960 [02:10<00:17, 275.56batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  88%|▉| 36197/40960 [02:10<00:17, 275.56batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  89%|▉| 36254/40960 [02:10<00:16, 277.46batches/s, l2_loss: 0.0972 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36254/40960 [02:10<00:16, 277.46batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36315/40960 [02:10<00:16, 284.61batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36315/40960 [02:10<00:16, 284.61batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  89%|▉| 36371/40960 [02:11<00:16, 281.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  89%|▉| 36371/40960 [02:11<00:16, 281.80batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36431/40960 [02:11<00:15, 286.90batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36431/40960 [02:11<00:15, 286.90batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36489/40960 [02:11<00:15, 287.09batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36489/40960 [02:11<00:15, 287.09batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36548/40960 [02:11<00:15, 289.07batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36548/40960 [02:11<00:15, 289.07batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36608/40960 [02:11<00:14, 292.14batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  89%|▉| 36608/40960 [02:11<00:14, 292.14batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36669/40960 [02:12<00:14, 294.71batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36669/40960 [02:12<00:14, 294.71batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  90%|▉| 36729/40960 [02:12<00:14, 296.18batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  90%|▉| 36729/40960 [02:12<00:14, 296.18batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36783/40960 [02:12<00:14, 287.28batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36783/40960 [02:12<00:14, 287.28batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36841/40960 [02:12<00:14, 288.00batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36841/40960 [02:12<00:14, 288.00batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36901/40960 [02:12<00:13, 290.52batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36901/40960 [02:12<00:13, 290.52batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36960/40960 [02:13<00:13, 290.96batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 36960/40960 [02:13<00:13, 290.96batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 37021/40960 [02:13<00:13, 294.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  90%|▉| 37021/40960 [02:13<00:13, 294.64batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37081/40960 [02:13<00:13, 294.69batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37081/40960 [02:13<00:13, 294.69batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37142/40960 [02:13<00:12, 297.40batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37142/40960 [02:13<00:12, 297.40batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37199/40960 [02:13<00:12, 293.01batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37199/40960 [02:13<00:12, 293.01batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  91%|▉| 37259/40960 [02:14<00:12, 295.06batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  91%|▉| 37259/40960 [02:14<00:12, 295.06batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37319/40960 [02:14<00:12, 295.27batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37319/40960 [02:14<00:12, 295.27batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37379/40960 [02:14<00:12, 295.98batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37379/40960 [02:14<00:12, 295.98batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37439/40960 [02:14<00:11, 295.80batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  91%|▉| 37439/40960 [02:14<00:11, 295.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  92%|▉| 37498/40960 [02:14<00:11, 294.88batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  92%|▉| 37498/40960 [02:14<00:11, 294.88batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  92%|▉| 37557/40960 [02:15<00:11, 294.03batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  92%|▉| 37557/40960 [02:15<00:11, 294.03batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  92%|▉| 37618/40960 [02:15<00:11, 296.19batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  92%|▉| 37618/40960 [02:15<00:11, 296.19batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  92%|▉| 37666/40960 [02:15<00:11, 278.68batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  92%|▉| 37666/40960 [02:15<00:11, 278.68batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  92%|▉| 37719/40960 [02:15<00:11, 274.18batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  92%|▉| 37719/40960 [02:15<00:11, 274.18batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  92%|▉| 37775/40960 [02:15<00:11, 275.75batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  92%|▉| 37775/40960 [02:15<00:11, 275.75batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  92%|▉| 37835/40960 [02:16<00:11, 282.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  92%|▉| 37835/40960 [02:16<00:11, 282.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  93%|▉| 37897/40960 [02:16<00:10, 290.74batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  93%|▉| 37897/40960 [02:16<00:10, 290.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  93%|▉| 37958/40960 [02:16<00:10, 294.82batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  93%|▉| 37958/40960 [02:16<00:10, 294.82batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  93%|▉| 38018/40960 [02:16<00:09, 295.94batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  93%|▉| 38018/40960 [02:16<00:09, 295.94batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  93%|▉| 38079/40960 [02:16<00:09, 297.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  93%|▉| 38079/40960 [02:16<00:09, 297.32batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  93%|▉| 38139/40960 [02:17<00:09, 297.91batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  93%|▉| 38139/40960 [02:17<00:09, 297.91batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  93%|▉| 38194/40960 [02:17<00:09, 289.53batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  93%|▉| 38194/40960 [02:17<00:09, 289.53batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  93%|▉| 38251/40960 [02:17<00:09, 286.86batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  93%|▉| 38251/40960 [02:17<00:09, 286.86batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  94%|▉| 38310/40960 [02:17<00:09, 287.60batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  94%|▉| 38310/40960 [02:17<00:09, 287.60batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  94%|▉| 38369/40960 [02:17<00:08, 289.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  94%|▉| 38369/40960 [02:17<00:08, 289.51batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  94%|▉| 38421/40960 [02:18<00:09, 280.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  94%|▉| 38421/40960 [02:18<00:09, 280.47batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  94%|▉| 38474/40960 [02:18<00:09, 274.76batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  94%|▉| 38474/40960 [02:18<00:09, 274.76batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  94%|▉| 38528/40960 [02:18<00:08, 272.00batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  94%|▉| 38528/40960 [02:18<00:08, 272.00batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  94%|▉| 38583/40960 [02:18<00:08, 272.65batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  94%|▉| 38583/40960 [02:18<00:08, 272.65batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  94%|▉| 38641/40960 [02:18<00:08, 277.66batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  94%|▉| 38641/40960 [02:18<00:08, 277.66batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  94%|▉| 38701/40960 [02:19<00:07, 283.06batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  94%|▉| 38701/40960 [02:19<00:07, 283.06batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 38760/40960 [02:19<00:07, 285.04batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 38760/40960 [02:19<00:07, 285.04batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 38817/40960 [02:19<00:07, 284.34batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 38817/40960 [02:19<00:07, 284.34batches/s, l2_loss: 0.0971 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 38867/40960 [02:19<00:07, 271.91batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  95%|▉| 38867/40960 [02:19<00:07, 271.91batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  95%|▉| 38921/40960 [02:19<00:07, 270.62batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  95%|▉| 38921/40960 [02:19<00:07, 270.62batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 38973/40960 [02:20<00:07, 267.21batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 38973/40960 [02:20<00:07, 267.21batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 39026/40960 [02:20<00:07, 265.37batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 39026/40960 [02:20<00:07, 265.37batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 39078/40960 [02:20<00:07, 262.73batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  95%|▉| 39078/40960 [02:20<00:07, 262.73batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39129/40960 [02:20<00:07, 260.05batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39129/40960 [02:20<00:07, 260.05batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  96%|▉| 39186/40960 [02:20<00:06, 267.08batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  96%|▉| 39186/40960 [02:20<00:06, 267.08batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39245/40960 [02:21<00:06, 275.35batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39245/40960 [02:21<00:06, 275.35batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39293/40960 [02:21<00:06, 264.68batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39293/40960 [02:21<00:06, 264.68batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39344/40960 [02:21<00:06, 261.49batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39344/40960 [02:21<00:06, 261.49batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39401/40960 [02:21<00:05, 268.31batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39401/40960 [02:21<00:05, 268.31batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39452/40960 [02:21<00:05, 263.79batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  96%|▉| 39452/40960 [02:21<00:05, 263.79batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  96%|▉| 39514/40960 [02:22<00:05, 277.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  96%|▉| 39514/40960 [02:22<00:05, 277.27batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39564/40960 [02:22<00:05, 267.80batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39564/40960 [02:22<00:05, 267.80batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  97%|▉| 39613/40960 [02:22<00:05, 260.77batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  97%|▉| 39613/40960 [02:22<00:05, 260.77batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  97%|▉| 39665/40960 [02:22<00:04, 260.23batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  97%|▉| 39665/40960 [02:22<00:04, 260.23batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39718/40960 [02:22<00:04, 260.23batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39718/40960 [02:22<00:04, 260.23batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39771/40960 [02:23<00:04, 261.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39771/40960 [02:23<00:04, 261.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39822/40960 [02:23<00:04, 258.04batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39822/40960 [02:23<00:04, 258.04batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39875/40960 [02:23<00:04, 259.69batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39875/40960 [02:23<00:04, 259.69batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39928/40960 [02:23<00:03, 260.98batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  97%|▉| 39928/40960 [02:23<00:03, 260.98batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 39981/40960 [02:23<00:03, 261.02batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 39981/40960 [02:23<00:03, 261.02batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  98%|▉| 40034/40960 [02:24<00:03, 261.95batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  98%|▉| 40034/40960 [02:24<00:03, 261.95batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 40088/40960 [02:24<00:03, 263.34batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 40088/40960 [02:24<00:03, 263.34batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 40146/40960 [02:24<00:03, 270.99batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 40146/40960 [02:24<00:03, 270.99batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 40200/40960 [02:24<00:02, 270.28batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 40200/40960 [02:24<00:02, 270.28batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  98%|▉| 40259/40960 [02:24<00:02, 277.11batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  98%|▉| 40259/40960 [02:24<00:02, 277.11batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 40319/40960 [02:25<00:02, 283.03batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  98%|▉| 40319/40960 [02:25<00:02, 283.03batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  99%|▉| 40374/40960 [02:25<00:02, 279.89batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  99%|▉| 40374/40960 [02:25<00:02, 279.89batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  99%|▉| 40430/40960 [02:25<00:01, 278.73batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  99%|▉| 40430/40960 [02:25<00:01, 278.73batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  99%|▉| 40479/40960 [02:25<00:01, 268.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  99%|▉| 40479/40960 [02:25<00:01, 268.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  99%|▉| 40531/40960 [02:25<00:01, 264.83batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  99%|▉| 40531/40960 [02:25<00:01, 264.83batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  99%|▉| 40585/40960 [02:26<00:01, 265.30batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training:  99%|▉| 40585/40960 [02:26<00:01, 265.30batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  99%|▉| 40637/40960 [02:26<00:01, 262.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  99%|▉| 40637/40960 [02:26<00:01, 262.74batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  99%|▉| 40690/40960 [02:26<00:01, 262.43batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  99%|▉| 40690/40960 [02:26<00:01, 262.43batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  99%|▉| 40740/40960 [02:26<00:00, 257.87batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training:  99%|▉| 40740/40960 [02:26<00:00, 257.87batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training: 100%|▉| 40792/40960 [02:26<00:00, 257.45batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training: 100%|▉| 40792/40960 [02:26<00:00, 257.45batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training: 100%|▉| 40845/40960 [02:27<00:00, 259.11batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training: 100%|▉| 40845/40960 [02:27<00:00, 259.11batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training: 100%|▉| 40899/40960 [02:27<00:00, 261.68batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "Training: 100%|▉| 40899/40960 [02:27<00:00, 261.68batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training: 100%|▉| 40953/40960 [02:27<00:00, 262.58batches/s, l2_loss: 0.0971 - round_los\u001b[A\n",
      "Training: 100%|▉| 40953/40960 [02:27<00:00, 262.58batches/s, l2_loss: 0.0972 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:06:38.056527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  35%|▎| 9/26 [17:18<36:03, 127.24s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-08 19:06:41.447676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:06:48.287036: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<26:05:35,  2.29s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<26:05:35,  2.29s/batches, l2_loss: 0.0137 - round_loss:\u001b[A\n",
      "Training:   0%| | 61/40960 [00:02<20:18, 33.58batches/s, l2_loss: 0.0137 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 61/40960 [00:02<20:18, 33.58batches/s, l2_loss: 0.0325 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 121/40960 [00:02<09:44, 69.91batches/s, l2_loss: 0.0325 - round_loss: \u001b[A\n",
      "Training:   0%| | 121/40960 [00:02<09:44, 69.91batches/s, l2_loss: 0.0335 - round_loss: \u001b[A\n",
      "Training:   0%| | 181/40960 [00:02<06:20, 107.22batches/s, l2_loss: 0.0335 - round_loss:\u001b[A\n",
      "Training:   0%| | 181/40960 [00:02<06:20, 107.22batches/s, l2_loss: 0.0305 - round_loss:\u001b[A\n",
      "Training:   1%| | 241/40960 [00:03<04:44, 143.27batches/s, l2_loss: 0.0305 - round_loss:\u001b[A\n",
      "Training:   1%| | 241/40960 [00:03<04:44, 143.27batches/s, l2_loss: 0.0314 - round_loss:\u001b[A\n",
      "Training:   1%| | 295/40960 [00:03<03:59, 170.08batches/s, l2_loss: 0.0314 - round_loss:\u001b[A\n",
      "Training:   1%| | 295/40960 [00:03<03:59, 170.08batches/s, l2_loss: 0.0318 - round_loss:\u001b[A\n",
      "Training:   1%| | 350/40960 [00:03<03:29, 194.22batches/s, l2_loss: 0.0318 - round_loss:\u001b[A\n",
      "Training:   1%| | 350/40960 [00:03<03:29, 194.22batches/s, l2_loss: 0.0333 - round_loss:\u001b[A\n",
      "Training:   1%| | 404/40960 [00:03<03:10, 212.87batches/s, l2_loss: 0.0333 - round_loss:\u001b[A\n",
      "Training:   1%| | 404/40960 [00:03<03:10, 212.87batches/s, l2_loss: 0.0331 - round_loss:\u001b[A\n",
      "Training:   1%| | 460/40960 [00:03<02:56, 229.64batches/s, l2_loss: 0.0331 - round_loss:\u001b[A\n",
      "Training:   1%| | 460/40960 [00:03<02:56, 229.64batches/s, l2_loss: 0.0320 - round_loss:\u001b[A\n",
      "Training:   1%| | 519/40960 [00:04<02:43, 247.29batches/s, l2_loss: 0.0320 - round_loss:\u001b[A\n",
      "Training:   1%| | 519/40960 [00:04<02:43, 247.29batches/s, l2_loss: 0.0337 - round_loss:\u001b[A\n",
      "Training:   1%| | 580/40960 [00:04<02:33, 262.24batches/s, l2_loss: 0.0337 - round_loss:\u001b[A\n",
      "Training:   1%| | 580/40960 [00:04<02:33, 262.24batches/s, l2_loss: 0.0326 - round_loss:\u001b[A\n",
      "Training:   2%| | 641/40960 [00:04<02:27, 273.53batches/s, l2_loss: 0.0326 - round_loss:\u001b[A\n",
      "Training:   2%| | 641/40960 [00:04<02:27, 273.53batches/s, l2_loss: 0.0325 - round_loss:\u001b[A\n",
      "Training:   2%| | 701/40960 [00:04<02:23, 281.04batches/s, l2_loss: 0.0325 - round_loss:\u001b[A\n",
      "Training:   2%| | 701/40960 [00:04<02:23, 281.04batches/s, l2_loss: 0.0324 - round_loss:\u001b[A\n",
      "Training:   2%| | 757/40960 [00:04<02:23, 279.38batches/s, l2_loss: 0.0324 - round_loss:\u001b[A\n",
      "Training:   2%| | 757/40960 [00:04<02:23, 279.38batches/s, l2_loss: 0.0328 - round_loss:\u001b[A\n",
      "Training:   2%| | 815/40960 [00:05<02:22, 281.34batches/s, l2_loss: 0.0328 - round_loss:\u001b[A\n",
      "Training:   2%| | 815/40960 [00:05<02:22, 281.34batches/s, l2_loss: 0.0325 - round_loss:\u001b[A\n",
      "Training:   2%| | 874/40960 [00:05<02:20, 284.79batches/s, l2_loss: 0.0325 - round_loss:\u001b[A\n",
      "Training:   2%| | 874/40960 [00:05<02:20, 284.79batches/s, l2_loss: 0.0328 - round_loss:\u001b[A\n",
      "Training:   2%| | 933/40960 [00:05<02:19, 287.58batches/s, l2_loss: 0.0328 - round_loss:\u001b[A\n",
      "Training:   2%| | 933/40960 [00:05<02:19, 287.58batches/s, l2_loss: 0.0330 - round_loss:\u001b[A\n",
      "Training:   2%| | 992/40960 [00:05<02:18, 289.58batches/s, l2_loss: 0.0330 - round_loss:\u001b[A\n",
      "Training:   2%| | 992/40960 [00:05<02:18, 289.58batches/s, l2_loss: 0.0325 - round_loss:\u001b[A\n",
      "Training:   3%| | 1052/40960 [00:05<02:16, 291.92batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   3%| | 1052/40960 [00:05<02:16, 291.92batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   3%| | 1114/40960 [00:06<02:14, 296.23batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   3%| | 1114/40960 [00:06<02:14, 296.23batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   3%| | 1174/40960 [00:06<02:13, 297.23batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   3%| | 1174/40960 [00:06<02:13, 297.23batches/s, l2_loss: 0.0327 - round_loss\u001b[A\n",
      "Training:   3%| | 1237/40960 [00:06<02:11, 301.41batches/s, l2_loss: 0.0327 - round_loss\u001b[A\n",
      "Training:   3%| | 1237/40960 [00:06<02:11, 301.41batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   3%| | 1299/40960 [00:06<02:10, 303.83batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   3%| | 1299/40960 [00:06<02:10, 303.83batches/s, l2_loss: 0.0327 - round_loss\u001b[A\n",
      "Training:   3%| | 1362/40960 [00:06<02:09, 306.34batches/s, l2_loss: 0.0327 - round_loss\u001b[A\n",
      "Training:   3%| | 1362/40960 [00:06<02:09, 306.34batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   3%| | 1425/40960 [00:07<02:08, 308.56batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   3%| | 1425/40960 [00:07<02:08, 308.56batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   4%| | 1487/40960 [00:07<02:07, 308.91batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   4%| | 1487/40960 [00:07<02:07, 308.91batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:   4%| | 1549/40960 [00:07<02:07, 308.63batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:   4%| | 1549/40960 [00:07<02:07, 308.63batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   4%| | 1609/40960 [00:07<02:08, 305.50batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   4%| | 1609/40960 [00:07<02:08, 305.50batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   4%| | 1650/40960 [00:07<02:23, 274.56batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   4%| | 1650/40960 [00:07<02:23, 274.56batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   4%| | 1708/40960 [00:08<02:20, 278.96batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   4%| | 1708/40960 [00:08<02:20, 278.96batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   4%| | 1768/40960 [00:08<02:17, 284.10batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   4%| | 1768/40960 [00:08<02:17, 284.10batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   4%| | 1830/40960 [00:08<02:14, 291.47batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   4%| | 1830/40960 [00:08<02:14, 291.47batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   5%| | 1893/40960 [00:08<02:11, 298.19batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   5%| | 1893/40960 [00:08<02:11, 298.19batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   5%| | 1953/40960 [00:08<02:10, 298.32batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   5%| | 1953/40960 [00:08<02:10, 298.32batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   5%| | 2014/40960 [00:09<02:10, 299.30batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   5%| | 2014/40960 [00:09<02:10, 299.30batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   5%| | 2076/40960 [00:09<02:08, 301.47batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   5%| | 2076/40960 [00:09<02:08, 301.47batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   5%| | 2137/40960 [00:09<02:08, 302.38batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   5%| | 2137/40960 [00:09<02:08, 302.38batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   5%| | 2197/40960 [00:09<02:08, 301.65batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   5%| | 2197/40960 [00:09<02:08, 301.65batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   5%| | 2250/40960 [00:09<02:13, 290.24batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:   5%| | 2250/40960 [00:09<02:13, 290.24batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   6%| | 2311/40960 [00:10<02:11, 293.87batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:   6%| | 2311/40960 [00:10<02:11, 293.87batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   6%| | 2368/40960 [00:10<02:12, 290.38batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   6%| | 2368/40960 [00:10<02:12, 290.38batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   6%| | 2432/40960 [00:10<02:09, 298.09batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   6%| | 2432/40960 [00:10<02:09, 298.09batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   6%| | 2492/40960 [00:10<02:08, 298.48batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%| | 2492/40960 [00:10<02:08, 298.48batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   6%| | 2552/40960 [00:10<02:08, 298.61batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   6%| | 2552/40960 [00:10<02:08, 298.61batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   6%| | 2611/40960 [00:11<02:08, 297.45batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   6%| | 2611/40960 [00:11<02:08, 297.45batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   7%| | 2672/40960 [00:11<02:08, 298.47batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   7%| | 2672/40960 [00:11<02:08, 298.47batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   7%| | 2734/40960 [00:11<02:07, 300.68batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   7%| | 2734/40960 [00:11<02:07, 300.68batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   7%| | 2793/40960 [00:11<02:07, 298.62batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   7%| | 2793/40960 [00:11<02:07, 298.62batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   7%| | 2857/40960 [00:11<02:05, 304.76batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   7%| | 2857/40960 [00:11<02:05, 304.76batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   7%| | 2920/40960 [00:12<02:03, 307.39batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   7%| | 2920/40960 [00:12<02:03, 307.39batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   7%| | 2977/40960 [00:12<02:07, 298.78batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   7%| | 2977/40960 [00:12<02:07, 298.78batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   7%| | 3037/40960 [00:12<02:07, 298.56batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   7%| | 3037/40960 [00:12<02:07, 298.56batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   8%| | 3098/40960 [00:12<02:06, 300.01batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:   8%| | 3098/40960 [00:12<02:06, 300.01batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   8%| | 3159/40960 [00:12<02:05, 301.03batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   8%| | 3159/40960 [00:12<02:05, 301.03batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   8%| | 3220/40960 [00:13<02:05, 301.34batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   8%| | 3220/40960 [00:13<02:05, 301.34batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   8%| | 3279/40960 [00:13<02:06, 298.10batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   8%| | 3279/40960 [00:13<02:06, 298.10batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:   8%| | 3339/40960 [00:13<02:06, 296.95batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:   8%| | 3339/40960 [00:13<02:06, 296.95batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   8%| | 3392/40960 [00:13<02:10, 287.09batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   8%| | 3392/40960 [00:13<02:10, 287.09batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   8%| | 3456/40960 [00:13<02:06, 295.79batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   8%| | 3456/40960 [00:13<02:06, 295.79batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   9%| | 3519/40960 [00:14<02:04, 300.20batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   9%| | 3519/40960 [00:14<02:04, 300.20batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   9%| | 3581/40960 [00:14<02:03, 302.13batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   9%| | 3581/40960 [00:14<02:03, 302.13batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   9%| | 3643/40960 [00:14<02:03, 303.38batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   9%| | 3643/40960 [00:14<02:03, 303.38batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   9%| | 3703/40960 [00:14<02:04, 300.35batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:   9%| | 3703/40960 [00:14<02:04, 300.35batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   9%| | 3761/40960 [00:14<02:05, 295.57batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   9%| | 3761/40960 [00:15<02:05, 295.57batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   9%| | 3822/40960 [00:15<02:04, 297.45batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   9%| | 3822/40960 [00:15<02:04, 297.45batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   9%| | 3880/40960 [00:15<02:06, 294.20batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:   9%| | 3880/40960 [00:15<02:06, 294.20batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 3935/40960 [00:15<02:08, 287.96batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 3935/40960 [00:15<02:08, 287.96batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 3990/40960 [00:15<02:10, 283.31batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 3990/40960 [00:15<02:10, 283.31batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 4049/40960 [00:16<02:09, 285.89batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 4049/40960 [00:16<02:09, 285.89batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 4109/40960 [00:16<02:07, 289.07batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 4109/40960 [00:16<02:07, 289.07batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:  10%| | 4167/40960 [00:16<02:07, 289.25batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:  10%| | 4167/40960 [00:16<02:07, 289.25batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:  10%| | 4229/40960 [00:16<02:04, 295.30batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:  10%| | 4229/40960 [00:16<02:04, 295.30batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 4281/40960 [00:16<02:09, 284.30batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  10%| | 4281/40960 [00:16<02:09, 284.30batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  11%| | 4338/40960 [00:17<02:09, 282.88batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  11%| | 4338/40960 [00:17<02:09, 282.88batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  11%| | 4403/40960 [00:17<02:04, 294.63batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  11%| | 4403/40960 [00:17<02:04, 294.63batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:  11%| | 4467/40960 [00:17<02:01, 301.31batches/s, l2_loss: 0.0323 - round_loss\u001b[A\n",
      "Training:  11%| | 4467/40960 [00:17<02:01, 301.31batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  11%| | 4528/40960 [00:17<02:00, 301.56batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  11%| | 4528/40960 [00:17<02:00, 301.56batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  11%| | 4587/40960 [00:17<02:01, 298.98batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  11%| | 4587/40960 [00:17<02:01, 298.98batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  11%| | 4648/40960 [00:18<02:00, 300.52batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  11%| | 4648/40960 [00:18<02:00, 300.52batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  12%| | 4711/40960 [00:18<01:59, 304.48batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  12%| | 4711/40960 [00:18<01:59, 304.48batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  12%| | 4774/40960 [00:18<01:57, 307.45batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  12%| | 4774/40960 [00:18<01:57, 307.45batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  12%| | 4822/40960 [00:18<02:06, 285.17batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  12%| | 4822/40960 [00:18<02:06, 285.17batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  12%| | 4872/40960 [00:18<02:11, 273.51batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  12%| | 4872/40960 [00:18<02:11, 273.51batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 4915/40960 [00:19<02:21, 254.09batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 4915/40960 [00:19<02:21, 254.09batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 4961/40960 [00:19<02:27, 244.84batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 4961/40960 [00:19<02:27, 244.84batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 5010/40960 [00:19<02:26, 244.59batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 5010/40960 [00:19<02:26, 244.59batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 5057/40960 [00:19<02:30, 239.22batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 5057/40960 [00:19<02:30, 239.22batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%| | 5116/40960 [00:19<02:20, 255.32batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  12%| | 5116/40960 [00:19<02:20, 255.32batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5175/40960 [00:20<02:14, 266.80batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5175/40960 [00:20<02:14, 266.80batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5239/40960 [00:20<02:06, 282.54batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5239/40960 [00:20<02:06, 282.54batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5292/40960 [00:20<02:08, 277.04batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5292/40960 [00:20<02:08, 277.04batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5334/40960 [00:20<02:18, 256.89batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5334/40960 [00:20<02:18, 256.89batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5393/40960 [00:20<02:12, 267.52batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5393/40960 [00:20<02:12, 267.52batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5451/40960 [00:21<02:09, 273.95batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5451/40960 [00:21<02:09, 273.95batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5515/40960 [00:21<02:03, 286.77batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5515/40960 [00:21<02:03, 286.77batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5576/40960 [00:21<02:01, 291.83batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5576/40960 [00:21<02:01, 291.83batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5636/40960 [00:21<02:00, 293.63batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5636/40960 [00:21<02:00, 293.63batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5697/40960 [00:21<01:59, 295.74batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5697/40960 [00:21<01:59, 295.74batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5756/40960 [00:22<01:59, 295.49batches/s, l2_loss: 0.0322 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5756/40960 [00:22<01:59, 295.49batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5820/40960 [00:22<01:56, 302.06batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5820/40960 [00:22<01:56, 302.06batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5878/40960 [00:22<01:57, 297.85batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5878/40960 [00:22<01:57, 297.85batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5932/40960 [00:22<02:01, 289.33batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5932/40960 [00:22<02:01, 289.33batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5992/40960 [00:22<01:59, 291.52batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5992/40960 [00:22<01:59, 291.52batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6045/40960 [00:23<02:03, 282.75batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6045/40960 [00:23<02:03, 282.75batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6103/40960 [00:23<02:02, 284.35batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6103/40960 [00:23<02:02, 284.35batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6155/40960 [00:23<02:05, 276.90batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6155/40960 [00:23<02:05, 276.90batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6200/40960 [00:23<02:13, 259.61batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6200/40960 [00:23<02:13, 259.61batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6251/40960 [00:23<02:14, 257.60batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6251/40960 [00:23<02:14, 257.60batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6305/40960 [00:24<02:13, 260.45batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6305/40960 [00:24<02:13, 260.45batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6364/40960 [00:24<02:07, 270.72batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6364/40960 [00:24<02:07, 270.72batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6407/40960 [00:24<02:16, 253.23batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6407/40960 [00:24<02:16, 253.23batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6464/40960 [00:24<02:11, 262.24batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6464/40960 [00:24<02:11, 262.24batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6518/40960 [00:24<02:10, 263.68batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6518/40960 [00:24<02:10, 263.68batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6577/40960 [00:25<02:05, 272.93batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6577/40960 [00:25<02:05, 272.93batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6634/40960 [00:25<02:04, 275.80batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6634/40960 [00:25<02:04, 275.80batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6693/40960 [00:25<02:02, 280.37batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6693/40960 [00:25<02:02, 280.37batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6755/40960 [00:25<01:58, 288.33batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6755/40960 [00:25<01:58, 288.33batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6814/40960 [00:25<01:58, 288.80batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6814/40960 [00:25<01:58, 288.80batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6874/40960 [00:26<01:57, 291.03batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6874/40960 [00:26<01:57, 291.03batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6937/40960 [00:26<01:54, 298.00batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6937/40960 [00:26<01:54, 298.00batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6996/40960 [00:26<01:54, 296.89batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6996/40960 [00:26<01:54, 296.89batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7057/40960 [00:26<01:53, 298.48batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7057/40960 [00:26<01:53, 298.48batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7121/40960 [00:26<01:51, 303.53batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7121/40960 [00:26<01:51, 303.53batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7181/40960 [00:27<01:51, 302.14batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7181/40960 [00:27<01:51, 302.14batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7243/40960 [00:27<01:51, 302.95batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7243/40960 [00:27<01:51, 302.95batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7305/40960 [00:27<01:50, 304.52batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7305/40960 [00:27<01:50, 304.52batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7348/40960 [00:27<02:01, 277.11batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7348/40960 [00:27<02:01, 277.11batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7394/40960 [00:27<02:08, 261.39batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7394/40960 [00:27<02:08, 261.39batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7454/40960 [00:28<02:03, 272.12batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7454/40960 [00:28<02:03, 272.12batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7513/40960 [00:28<02:00, 278.39batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7513/40960 [00:28<02:00, 278.39batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7575/40960 [00:28<01:56, 286.17batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7575/40960 [00:28<01:56, 286.17batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7636/40960 [00:28<01:54, 290.73batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|▏| 7636/40960 [00:28<01:54, 290.73batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7695/40960 [00:28<01:54, 291.36batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7695/40960 [00:28<01:54, 291.36batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7752/40960 [00:29<01:54, 288.95batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7752/40960 [00:29<01:54, 288.95batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7806/40960 [00:29<01:57, 283.04batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7806/40960 [00:29<01:57, 283.04batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7862/40960 [00:29<01:57, 282.13batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7862/40960 [00:29<01:57, 282.13batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7915/40960 [00:29<01:59, 276.86batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7915/40960 [00:29<01:59, 276.86batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7978/40960 [00:29<01:54, 287.47batches/s, l2_loss: 0.0320 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7978/40960 [00:29<01:54, 287.47batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8033/40960 [00:30<01:57, 281.22batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8033/40960 [00:30<01:57, 281.22batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8089/40960 [00:30<01:57, 280.11batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8089/40960 [00:30<01:57, 280.11batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8150/40960 [00:30<01:54, 286.50batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8150/40960 [00:30<01:54, 286.50batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8209/40960 [00:30<01:53, 287.60batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8209/40960 [00:30<01:53, 287.60batches/s, l2_loss: 0.0216 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8268/40960 [00:30<01:53, 288.12batches/s, l2_loss: 0.0216 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8268/40960 [00:30<01:53, 288.12batches/s, l2_loss: 0.0348 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8326/40960 [00:31<01:53, 287.63batches/s, l2_loss: 0.0348 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8326/40960 [00:31<01:53, 287.63batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8378/40960 [00:31<01:56, 279.15batches/s, l2_loss: 0.0325 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8378/40960 [00:31<01:56, 279.15batches/s, l2_loss: 0.0346 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8432/40960 [00:31<01:57, 276.28batches/s, l2_loss: 0.0346 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8432/40960 [00:31<01:57, 276.28batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8488/40960 [00:31<01:57, 277.06batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8488/40960 [00:31<01:57, 277.06batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8547/40960 [00:31<01:54, 281.90batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8547/40960 [00:31<01:54, 281.90batches/s, l2_loss: 0.0311 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8606/40960 [00:32<01:53, 284.14batches/s, l2_loss: 0.0311 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8606/40960 [00:32<01:53, 284.14batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8666/40960 [00:32<01:52, 287.99batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8666/40960 [00:32<01:52, 287.99batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8725/40960 [00:32<01:51, 288.96batches/s, l2_loss: 0.0319 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8725/40960 [00:32<01:51, 288.96batches/s, l2_loss: 0.0310 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8784/40960 [00:32<01:50, 290.17batches/s, l2_loss: 0.0310 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8784/40960 [00:32<01:50, 290.17batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8843/40960 [00:32<01:50, 290.90batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8843/40960 [00:32<01:50, 290.90batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8900/40960 [00:33<01:51, 288.28batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8900/40960 [00:33<01:51, 288.28batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8958/40960 [00:33<01:50, 288.35batches/s, l2_loss: 0.0321 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8958/40960 [00:33<01:50, 288.35batches/s, l2_loss: 0.0314 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9014/40960 [00:33<01:52, 284.59batches/s, l2_loss: 0.0314 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9014/40960 [00:33<01:52, 284.59batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9070/40960 [00:33<01:53, 282.11batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9070/40960 [00:33<01:53, 282.11batches/s, l2_loss: 0.0317 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9127/40960 [00:33<01:53, 281.67batches/s, l2_loss: 0.0317 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9127/40960 [00:33<01:53, 281.67batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9186/40960 [00:34<01:51, 284.46batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9186/40960 [00:34<01:51, 284.46batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9242/40960 [00:34<01:52, 282.94batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9242/40960 [00:34<01:52, 282.94batches/s, l2_loss: 0.0313 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9302/40960 [00:34<01:50, 286.78batches/s, l2_loss: 0.0313 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9302/40960 [00:34<01:50, 286.78batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9356/40960 [00:34<01:52, 281.21batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9356/40960 [00:34<01:52, 281.21batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9410/40960 [00:34<01:53, 277.59batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9410/40960 [00:34<01:53, 277.59batches/s, l2_loss: 0.0312 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9456/40960 [00:35<01:59, 262.72batches/s, l2_loss: 0.0312 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9456/40960 [00:35<01:59, 262.72batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9508/40960 [00:35<02:00, 260.30batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9508/40960 [00:35<02:00, 260.30batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9565/40960 [00:35<01:57, 266.94batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9565/40960 [00:35<01:57, 266.94batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9622/40960 [00:35<01:55, 270.54batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9622/40960 [00:35<01:55, 270.54batches/s, l2_loss: 0.0314 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9679/40960 [00:36<01:54, 274.09batches/s, l2_loss: 0.0314 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9679/40960 [00:36<01:54, 274.09batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9737/40960 [00:36<01:52, 278.68batches/s, l2_loss: 0.0316 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9737/40960 [00:36<01:52, 278.68batches/s, l2_loss: 0.0313 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9792/40960 [00:36<01:52, 276.78batches/s, l2_loss: 0.0313 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9792/40960 [00:36<01:52, 276.78batches/s, l2_loss: 0.0311 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9844/40960 [00:36<01:54, 271.71batches/s, l2_loss: 0.0311 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9844/40960 [00:36<01:54, 271.71batches/s, l2_loss: 0.0312 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9903/40960 [00:36<01:51, 278.25batches/s, l2_loss: 0.0312 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9903/40960 [00:36<01:51, 278.25batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9963/40960 [00:37<01:49, 283.37batches/s, l2_loss: 0.0315 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9963/40960 [00:37<01:49, 283.37batches/s, l2_loss: 0.0313 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10021/40960 [00:37<01:48, 284.28batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  24%|▏| 10021/40960 [00:37<01:48, 284.28batches/s, l2_loss: 0.0316 - round_los\u001b[A\n",
      "Training:  25%|▏| 10080/40960 [00:37<01:47, 286.36batches/s, l2_loss: 0.0316 - round_los\u001b[A\n",
      "Training:  25%|▏| 10080/40960 [00:37<01:47, 286.36batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  25%|▏| 10138/40960 [00:37<01:47, 286.87batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  25%|▏| 10138/40960 [00:37<01:47, 286.87batches/s, l2_loss: 0.0312 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▏| 10195/40960 [00:37<01:47, 285.89batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  25%|▏| 10195/40960 [00:37<01:47, 285.89batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  25%|▎| 10252/40960 [00:38<01:48, 284.21batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  25%|▎| 10252/40960 [00:38<01:48, 284.21batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  25%|▎| 10299/40960 [00:38<01:53, 269.18batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  25%|▎| 10299/40960 [00:38<01:53, 269.18batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  25%|▎| 10353/40960 [00:38<01:54, 267.57batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  25%|▎| 10353/40960 [00:38<01:54, 267.57batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  25%|▎| 10393/40960 [00:38<02:03, 247.25batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  25%|▎| 10393/40960 [00:38<02:03, 247.25batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10448/40960 [00:38<02:00, 253.97batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10448/40960 [00:38<02:00, 253.97batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  26%|▎| 10500/40960 [00:39<01:59, 254.32batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  26%|▎| 10500/40960 [00:39<01:59, 254.32batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  26%|▎| 10555/40960 [00:39<01:56, 260.23batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  26%|▎| 10555/40960 [00:39<01:56, 260.23batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  26%|▎| 10608/40960 [00:39<01:56, 261.21batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  26%|▎| 10608/40960 [00:39<01:56, 261.21batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10658/40960 [00:39<01:57, 257.75batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10658/40960 [00:39<01:57, 257.75batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10714/40960 [00:39<01:54, 264.00batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10714/40960 [00:39<01:54, 264.00batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10768/40960 [00:40<01:53, 265.09batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10768/40960 [00:40<01:53, 265.09batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10815/40960 [00:40<01:57, 255.88batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  26%|▎| 10815/40960 [00:40<01:57, 255.88batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  27%|▎| 10867/40960 [00:40<01:57, 256.64batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  27%|▎| 10867/40960 [00:40<01:57, 256.64batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  27%|▎| 10918/40960 [00:40<01:57, 255.76batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  27%|▎| 10918/40960 [00:40<01:57, 255.76batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  27%|▎| 10969/40960 [00:40<01:58, 253.80batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  27%|▎| 10969/40960 [00:40<01:58, 253.80batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  27%|▎| 11021/40960 [00:41<01:57, 255.45batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  27%|▎| 11021/40960 [00:41<01:57, 255.45batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  27%|▎| 11074/40960 [00:41<01:55, 258.16batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  27%|▎| 11074/40960 [00:41<01:55, 258.16batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  27%|▎| 11115/40960 [00:41<02:04, 240.36batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  27%|▎| 11115/40960 [00:41<02:04, 240.36batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  27%|▎| 11156/40960 [00:41<02:10, 228.60batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  27%|▎| 11156/40960 [00:41<02:10, 228.60batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  27%|▎| 11209/40960 [00:41<02:04, 238.46batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  27%|▎| 11209/40960 [00:41<02:04, 238.46batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11266/40960 [00:42<01:58, 251.54batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11266/40960 [00:42<01:58, 251.54batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  28%|▎| 11326/40960 [00:42<01:51, 265.56batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  28%|▎| 11326/40960 [00:42<01:51, 265.56batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11385/40960 [00:42<01:48, 273.46batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11385/40960 [00:42<01:48, 273.46batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  28%|▎| 11442/40960 [00:42<01:47, 275.62batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  28%|▎| 11442/40960 [00:42<01:47, 275.62batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  28%|▎| 11493/40960 [00:42<01:49, 268.85batches/s, l2_loss: 0.0315 - round_los\u001b[A\n",
      "Training:  28%|▎| 11493/40960 [00:42<01:49, 268.85batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11537/40960 [00:43<01:56, 253.50batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11537/40960 [00:43<01:56, 253.50batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11581/40960 [00:43<02:01, 241.52batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11581/40960 [00:43<02:01, 241.52batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11629/40960 [00:43<02:01, 240.63batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  28%|▎| 11629/40960 [00:43<02:01, 240.63batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 11682/40960 [00:43<01:58, 246.57batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 11682/40960 [00:43<01:58, 246.57batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 11740/40960 [00:43<01:52, 259.15batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 11740/40960 [00:43<01:52, 259.15batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 11797/40960 [00:44<01:49, 266.19batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 11797/40960 [00:44<01:49, 266.19batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  29%|▎| 11853/40960 [00:44<01:48, 269.27batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  29%|▎| 11853/40960 [00:44<01:48, 269.27batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  29%|▎| 11909/40960 [00:44<01:46, 272.33batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  29%|▎| 11909/40960 [00:44<01:46, 272.33batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 11967/40960 [00:44<01:44, 276.90batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 11967/40960 [00:44<01:44, 276.90batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 12025/40960 [00:44<01:43, 280.63batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  29%|▎| 12025/40960 [00:44<01:43, 280.63batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  29%|▎| 12080/40960 [00:45<01:44, 277.04batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  29%|▎| 12080/40960 [00:45<01:44, 277.04batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12138/40960 [00:45<01:43, 279.71batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12138/40960 [00:45<01:43, 279.71batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12198/40960 [00:45<01:41, 284.74batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12198/40960 [00:45<01:41, 284.74batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12257/40960 [00:45<01:39, 287.13batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12257/40960 [00:45<01:39, 287.13batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  30%|▎| 12314/40960 [00:45<01:40, 285.04batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  30%|▎| 12314/40960 [00:45<01:40, 285.04batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12373/40960 [00:46<01:39, 287.76batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12373/40960 [00:46<01:39, 287.76batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  30%|▎| 12435/40960 [00:46<01:37, 293.18batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  30%|▎| 12435/40960 [00:46<01:37, 293.18batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12487/40960 [00:46<01:40, 281.94batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  30%|▎| 12487/40960 [00:46<01:40, 281.94batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12534/40960 [00:46<01:46, 267.79batches/s, l2_loss: 0.0313 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|▎| 12534/40960 [00:46<01:46, 267.79batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12592/40960 [00:46<01:43, 273.28batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12592/40960 [00:46<01:43, 273.28batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12650/40960 [00:47<01:41, 278.17batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12650/40960 [00:47<01:41, 278.17batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  31%|▎| 12707/40960 [00:47<01:41, 279.25batches/s, l2_loss: 0.0314 - round_los\u001b[A\n",
      "Training:  31%|▎| 12707/40960 [00:47<01:41, 279.25batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12764/40960 [00:47<01:40, 280.22batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12764/40960 [00:47<01:40, 280.22batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12823/40960 [00:47<01:39, 283.42batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12823/40960 [00:47<01:39, 283.42batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12880/40960 [00:47<01:39, 283.39batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  31%|▎| 12880/40960 [00:47<01:39, 283.39batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 12941/40960 [00:48<01:37, 288.36batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 12941/40960 [00:48<01:37, 288.36batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 13002/40960 [00:48<01:35, 292.11batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 13002/40960 [00:48<01:35, 292.11batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  32%|▎| 13063/40960 [00:48<01:34, 294.78batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  32%|▎| 13063/40960 [00:48<01:34, 294.78batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 13122/40960 [00:48<01:34, 294.16batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 13122/40960 [00:48<01:34, 294.16batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 13181/40960 [00:48<01:34, 294.11batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 13181/40960 [00:48<01:34, 294.11batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 13242/40960 [00:49<01:33, 296.13batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  32%|▎| 13242/40960 [00:49<01:33, 296.13batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  32%|▎| 13302/40960 [00:49<01:33, 296.54batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  32%|▎| 13302/40960 [00:49<01:33, 296.54batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  33%|▎| 13355/40960 [00:49<01:36, 285.76batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  33%|▎| 13355/40960 [00:49<01:36, 285.76batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13410/40960 [00:49<01:37, 281.17batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13410/40960 [00:49<01:37, 281.17batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13464/40960 [00:49<01:39, 276.80batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13464/40960 [00:49<01:39, 276.80batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13521/40960 [00:50<01:38, 278.71batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13521/40960 [00:50<01:38, 278.71batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13568/40960 [00:50<01:43, 265.67batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13568/40960 [00:50<01:43, 265.67batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13620/40960 [00:50<01:43, 263.44batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13620/40960 [00:50<01:43, 263.44batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13673/40960 [00:50<01:44, 262.32batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  33%|▎| 13673/40960 [00:50<01:44, 262.32batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13724/40960 [00:50<01:44, 259.98batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13724/40960 [00:50<01:44, 259.98batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13774/40960 [00:51<01:46, 256.13batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13774/40960 [00:51<01:46, 256.13batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13823/40960 [00:51<01:48, 251.18batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13823/40960 [00:51<01:48, 251.18batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13883/40960 [00:51<01:42, 264.83batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13883/40960 [00:51<01:42, 264.83batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13938/40960 [00:51<01:41, 267.41batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 13938/40960 [00:51<01:41, 267.41batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  34%|▎| 13993/40960 [00:51<01:40, 269.59batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  34%|▎| 13993/40960 [00:51<01:40, 269.59batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 14045/40960 [00:52<01:40, 266.69batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 14045/40960 [00:52<01:40, 266.69batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 14098/40960 [00:52<01:41, 265.26batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  34%|▎| 14098/40960 [00:52<01:41, 265.26batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14157/40960 [00:52<01:38, 273.26batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14157/40960 [00:52<01:38, 273.26batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14218/40960 [00:52<01:34, 281.82batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14218/40960 [00:52<01:34, 281.82batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14275/40960 [00:52<01:34, 281.56batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14275/40960 [00:52<01:34, 281.56batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  35%|▎| 14330/40960 [00:53<01:35, 278.89batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  35%|▎| 14330/40960 [00:53<01:35, 278.89batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14392/40960 [00:53<01:32, 286.78batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14392/40960 [00:53<01:32, 286.78batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14448/40960 [00:53<01:33, 283.40batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14448/40960 [00:53<01:33, 283.40batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14503/40960 [00:53<01:34, 279.71batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  35%|▎| 14503/40960 [00:53<01:34, 279.71batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14561/40960 [00:53<01:33, 282.29batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14561/40960 [00:53<01:33, 282.29batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14618/40960 [00:54<01:33, 282.37batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14618/40960 [00:54<01:33, 282.37batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14677/40960 [00:54<01:32, 284.59batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14677/40960 [00:54<01:32, 284.59batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  36%|▎| 14734/40960 [00:54<01:32, 283.81batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  36%|▎| 14734/40960 [00:54<01:32, 283.81batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14789/40960 [00:54<01:33, 281.07batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14789/40960 [00:54<01:33, 281.07batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  36%|▎| 14848/40960 [00:54<01:31, 284.18batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  36%|▎| 14848/40960 [00:55<01:31, 284.18batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14905/40960 [00:55<01:31, 284.36batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  36%|▎| 14905/40960 [00:55<01:31, 284.36batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 14960/40960 [00:55<01:32, 280.94batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 14960/40960 [00:55<01:32, 280.94batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 15018/40960 [00:55<01:31, 282.82batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 15018/40960 [00:55<01:31, 282.82batches/s, l2_loss: 0.0312 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15065/40960 [00:55<01:37, 266.59batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  37%|▎| 15065/40960 [00:55<01:37, 266.59batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 15114/40960 [00:56<01:39, 259.85batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 15114/40960 [00:56<01:39, 259.85batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 15166/40960 [00:56<01:39, 259.06batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 15166/40960 [00:56<01:39, 259.06batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 15226/40960 [00:56<01:35, 270.29batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  37%|▎| 15226/40960 [00:56<01:35, 270.29batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  37%|▎| 15284/40960 [00:56<01:33, 274.98batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  37%|▎| 15284/40960 [00:56<01:33, 274.98batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  37%|▎| 15341/40960 [00:56<01:32, 277.67batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  37%|▎| 15341/40960 [00:56<01:32, 277.67batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15396/40960 [00:57<01:32, 276.75batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15396/40960 [00:57<01:32, 276.75batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15452/40960 [00:57<01:32, 276.39batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15452/40960 [00:57<01:32, 276.39batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15511/40960 [00:57<01:30, 281.29batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15511/40960 [00:57<01:30, 281.29batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15566/40960 [00:57<01:31, 277.09batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15566/40960 [00:57<01:31, 277.09batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15621/40960 [00:57<01:32, 275.28batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15621/40960 [00:57<01:32, 275.28batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15681/40960 [00:58<01:29, 281.80batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15681/40960 [00:58<01:29, 281.80batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15742/40960 [00:58<01:27, 288.36batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  38%|▍| 15742/40960 [00:58<01:27, 288.36batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  39%|▍| 15802/40960 [00:58<01:26, 290.68batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  39%|▍| 15802/40960 [00:58<01:26, 290.68batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  39%|▍| 15861/40960 [00:58<01:26, 289.92batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  39%|▍| 15861/40960 [00:58<01:26, 289.92batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  39%|▍| 15907/40960 [00:58<01:32, 271.72batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  39%|▍| 15907/40960 [00:58<01:32, 271.72batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  39%|▍| 15963/40960 [00:59<01:31, 273.08batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  39%|▍| 15963/40960 [00:59<01:31, 273.08batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  39%|▍| 16020/40960 [00:59<01:30, 276.58batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  39%|▍| 16020/40960 [00:59<01:30, 276.58batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  39%|▍| 16078/40960 [00:59<01:28, 279.70batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  39%|▍| 16078/40960 [00:59<01:28, 279.70batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  39%|▍| 16137/40960 [00:59<01:27, 282.69batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  39%|▍| 16137/40960 [00:59<01:27, 282.69batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16195/40960 [00:59<01:27, 284.45batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16195/40960 [00:59<01:27, 284.45batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16255/40960 [01:00<01:25, 288.49batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16255/40960 [01:00<01:25, 288.49batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16316/40960 [01:00<01:24, 292.60batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16316/40960 [01:00<01:24, 292.60batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16369/40960 [01:00<01:26, 284.30batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16369/40960 [01:00<01:26, 284.30batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  40%|▍| 16414/40960 [01:00<01:32, 264.12batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  40%|▍| 16414/40960 [01:00<01:32, 264.12batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16472/40960 [01:00<01:30, 271.47batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16472/40960 [01:00<01:30, 271.47batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  40%|▍| 16524/40960 [01:01<01:31, 267.30batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  40%|▍| 16524/40960 [01:01<01:31, 267.30batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16577/40960 [01:01<01:31, 266.62batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  40%|▍| 16577/40960 [01:01<01:31, 266.62batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16633/40960 [01:01<01:30, 269.48batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16633/40960 [01:01<01:30, 269.48batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16683/40960 [01:01<01:32, 262.23batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16683/40960 [01:01<01:32, 262.23batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16738/40960 [01:01<01:31, 265.89batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16738/40960 [01:01<01:31, 265.89batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16795/40960 [01:02<01:29, 270.34batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16795/40960 [01:02<01:29, 270.34batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16851/40960 [01:02<01:28, 272.11batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  41%|▍| 16851/40960 [01:02<01:28, 272.11batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  41%|▍| 16912/40960 [01:02<01:25, 281.52batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  41%|▍| 16912/40960 [01:02<01:25, 281.52batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  41%|▍| 16967/40960 [01:02<01:26, 278.47batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  41%|▍| 16967/40960 [01:02<01:26, 278.47batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  42%|▍| 17029/40960 [01:02<01:23, 287.43batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  42%|▍| 17029/40960 [01:02<01:23, 287.43batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17088/40960 [01:03<01:22, 288.32batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17088/40960 [01:03<01:22, 288.32batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17145/40960 [01:03<01:23, 286.46batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17145/40960 [01:03<01:23, 286.46batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17202/40960 [01:03<01:23, 285.19batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17202/40960 [01:03<01:23, 285.19batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17257/40960 [01:03<01:24, 281.44batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17257/40960 [01:03<01:24, 281.44batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17311/40960 [01:03<01:25, 277.76batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17311/40960 [01:03<01:25, 277.76batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17369/40960 [01:04<01:24, 280.38batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  42%|▍| 17369/40960 [01:04<01:24, 280.38batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17425/40960 [01:04<01:24, 279.17batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17425/40960 [01:04<01:24, 279.17batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17481/40960 [01:04<01:24, 279.10batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17481/40960 [01:04<01:24, 279.10batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  43%|▍| 17539/40960 [01:04<01:23, 282.11batches/s, l2_loss: 0.0313 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17539/40960 [01:04<01:23, 282.11batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17599/40960 [01:04<01:21, 287.12batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17599/40960 [01:04<01:21, 287.12batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17654/40960 [01:05<01:22, 282.56batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17654/40960 [01:05<01:22, 282.56batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17713/40960 [01:05<01:21, 285.02batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17713/40960 [01:05<01:21, 285.02batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17772/40960 [01:05<01:20, 286.76batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  43%|▍| 17772/40960 [01:05<01:20, 286.76batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 17831/40960 [01:05<01:20, 288.36batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 17831/40960 [01:05<01:20, 288.36batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  44%|▍| 17882/40960 [01:05<01:23, 277.54batches/s, l2_loss: 0.0313 - round_los\u001b[A\n",
      "Training:  44%|▍| 17882/40960 [01:05<01:23, 277.54batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 17926/40960 [01:06<01:28, 259.60batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 17926/40960 [01:06<01:28, 259.60batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 17970/40960 [01:06<01:33, 246.26batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 17970/40960 [01:06<01:33, 246.26batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 18023/40960 [01:06<01:31, 251.47batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 18023/40960 [01:06<01:31, 251.47batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 18081/40960 [01:06<01:27, 262.54batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 18081/40960 [01:06<01:27, 262.54batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 18136/40960 [01:06<01:26, 264.90batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 18136/40960 [01:06<01:26, 264.90batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 18195/40960 [01:07<01:23, 272.83batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  44%|▍| 18195/40960 [01:07<01:23, 272.83batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18252/40960 [01:07<01:22, 276.30batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18252/40960 [01:07<01:22, 276.30batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18309/40960 [01:07<01:21, 278.15batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18309/40960 [01:07<01:21, 278.15batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18370/40960 [01:07<01:19, 285.64batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18370/40960 [01:07<01:19, 285.64batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18427/40960 [01:07<01:19, 283.97batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18427/40960 [01:07<01:19, 283.97batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18488/40960 [01:08<01:17, 289.75batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18488/40960 [01:08<01:17, 289.75batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18544/40960 [01:08<01:18, 285.29batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18544/40960 [01:08<01:18, 285.29batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18602/40960 [01:08<01:18, 286.26batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  45%|▍| 18602/40960 [01:08<01:18, 286.26batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18661/40960 [01:08<01:17, 287.80batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18661/40960 [01:08<01:17, 287.80batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18722/40960 [01:08<01:16, 292.47batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18722/40960 [01:08<01:16, 292.47batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18781/40960 [01:09<01:15, 292.27batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18781/40960 [01:09<01:15, 292.27batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18840/40960 [01:09<01:15, 292.92batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18840/40960 [01:09<01:15, 292.92batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18898/40960 [01:09<01:15, 291.42batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18898/40960 [01:09<01:15, 291.42batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18955/40960 [01:09<01:16, 287.85batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 18955/40960 [01:09<01:16, 287.85batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 19010/40960 [01:09<01:17, 283.95batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  46%|▍| 19010/40960 [01:09<01:17, 283.95batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19066/40960 [01:10<01:17, 282.57batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19066/40960 [01:10<01:17, 282.57batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19125/40960 [01:10<01:16, 285.42batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19125/40960 [01:10<01:16, 285.42batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19179/40960 [01:10<01:17, 280.69batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19179/40960 [01:10<01:17, 280.69batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19234/40960 [01:10<01:18, 277.64batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19234/40960 [01:10<01:18, 277.64batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19288/40960 [01:10<01:19, 273.96batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19288/40960 [01:10<01:19, 273.96batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19343/40960 [01:11<01:19, 273.13batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19343/40960 [01:11<01:19, 273.13batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19402/40960 [01:11<01:17, 277.70batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  47%|▍| 19402/40960 [01:11<01:17, 277.70batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19460/40960 [01:11<01:16, 280.53batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19460/40960 [01:11<01:16, 280.53batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19521/40960 [01:11<01:14, 287.30batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19521/40960 [01:11<01:14, 287.30batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19576/40960 [01:11<01:15, 283.36batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19576/40960 [01:11<01:15, 283.36batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  48%|▍| 19635/40960 [01:12<01:14, 286.25batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  48%|▍| 19635/40960 [01:12<01:14, 286.25batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19691/40960 [01:12<01:14, 284.28batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19691/40960 [01:12<01:14, 284.28batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19748/40960 [01:12<01:14, 283.98batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19748/40960 [01:12<01:14, 283.98batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19806/40960 [01:12<01:14, 285.20batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19806/40960 [01:12<01:14, 285.20batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19863/40960 [01:12<01:14, 285.04batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  48%|▍| 19863/40960 [01:12<01:14, 285.04batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 19922/40960 [01:13<01:13, 287.85batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 19922/40960 [01:13<01:13, 287.85batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 19983/40960 [01:13<01:11, 292.77batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 19983/40960 [01:13<01:11, 292.77batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20041/40960 [01:13<01:11, 290.74batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20041/40960 [01:13<01:11, 290.74batches/s, l2_loss: 0.0312 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|▍| 20099/40960 [01:13<01:12, 289.64batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20099/40960 [01:13<01:12, 289.64batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20156/40960 [01:13<01:12, 287.57batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20156/40960 [01:13<01:12, 287.57batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20210/40960 [01:14<01:13, 282.27batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20210/40960 [01:14<01:13, 282.27batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20267/40960 [01:14<01:13, 282.33batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  49%|▍| 20267/40960 [01:14<01:13, 282.33batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  50%|▍| 20323/40960 [01:14<01:13, 281.59batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  50%|▍| 20323/40960 [01:14<01:13, 281.59batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▍| 20383/40960 [01:14<01:11, 286.46batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▍| 20383/40960 [01:14<01:11, 286.46batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▍| 20434/40960 [01:14<01:14, 276.44batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▍| 20434/40960 [01:14<01:14, 276.44batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▌| 20487/40960 [01:15<01:15, 272.61batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▌| 20487/40960 [01:15<01:15, 272.61batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▌| 20544/40960 [01:15<01:13, 275.93batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▌| 20544/40960 [01:15<01:13, 275.93batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▌| 20594/40960 [01:15<01:16, 267.01batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▌| 20594/40960 [01:15<01:16, 267.01batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▌| 20647/40960 [01:15<01:16, 265.34batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  50%|▌| 20647/40960 [01:15<01:16, 265.34batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20701/40960 [01:15<01:16, 266.10batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20701/40960 [01:15<01:16, 266.10batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20756/40960 [01:16<01:15, 267.64batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20756/40960 [01:16<01:15, 267.64batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20810/40960 [01:16<01:15, 267.95batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20810/40960 [01:16<01:15, 267.95batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20864/40960 [01:16<01:14, 268.22batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20864/40960 [01:16<01:14, 268.22batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20919/40960 [01:16<01:14, 270.15batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20919/40960 [01:16<01:14, 270.15batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20973/40960 [01:16<01:14, 269.77batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 20973/40960 [01:17<01:14, 269.77batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 21025/40960 [01:17<01:15, 265.73batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 21025/40960 [01:17<01:15, 265.73batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 21080/40960 [01:17<01:14, 267.33batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  51%|▌| 21080/40960 [01:17<01:14, 267.33batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21136/40960 [01:17<01:13, 270.46batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21136/40960 [01:17<01:13, 270.46batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21192/40960 [01:17<01:12, 272.23batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21192/40960 [01:17<01:12, 272.23batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  52%|▌| 21246/40960 [01:18<01:12, 270.45batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  52%|▌| 21246/40960 [01:18<01:12, 270.45batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21303/40960 [01:18<01:11, 274.25batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21303/40960 [01:18<01:11, 274.25batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21357/40960 [01:18<01:12, 272.04batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21357/40960 [01:18<01:12, 272.04batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21412/40960 [01:18<01:11, 271.96batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21412/40960 [01:18<01:11, 271.96batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21464/40960 [01:18<01:12, 267.23batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  52%|▌| 21464/40960 [01:18<01:12, 267.23batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21517/40960 [01:19<01:13, 265.35batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21517/40960 [01:19<01:13, 265.35batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21569/40960 [01:19<01:13, 263.58batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21569/40960 [01:19<01:13, 263.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  53%|▌| 21623/40960 [01:19<01:12, 265.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  53%|▌| 21623/40960 [01:19<01:12, 265.42batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21680/40960 [01:19<01:11, 271.08batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21680/40960 [01:19<01:11, 271.08batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21739/40960 [01:19<01:09, 278.01batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21739/40960 [01:19<01:09, 278.01batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21798/40960 [01:20<01:08, 281.73batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  53%|▌| 21798/40960 [01:20<01:08, 281.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  53%|▌| 21854/40960 [01:20<01:08, 280.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  53%|▌| 21854/40960 [01:20<01:08, 280.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  53%|▌| 21907/40960 [01:20<01:09, 274.61batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  53%|▌| 21907/40960 [01:20<01:09, 274.61batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 21965/40960 [01:20<01:08, 278.97batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 21965/40960 [01:20<01:08, 278.97batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22019/40960 [01:20<01:08, 276.12batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22019/40960 [01:20<01:08, 276.12batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22078/40960 [01:21<01:07, 281.75batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22078/40960 [01:21<01:07, 281.75batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22131/40960 [01:21<01:08, 276.08batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22131/40960 [01:21<01:08, 276.08batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22182/40960 [01:21<01:09, 269.48batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22182/40960 [01:21<01:09, 269.48batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22237/40960 [01:21<01:09, 270.20batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  54%|▌| 22237/40960 [01:21<01:09, 270.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [01:21<01:07, 276.85batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [01:21<01:07, 276.85batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22357/40960 [01:22<01:05, 284.86batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22357/40960 [01:22<01:05, 284.86batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22419/40960 [01:22<01:03, 291.86batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22419/40960 [01:22<01:03, 291.86batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22476/40960 [01:22<01:04, 288.68batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22476/40960 [01:22<01:04, 288.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  55%|▌| 22540/40960 [01:22<01:01, 297.17batches/s, l2_loss: 0.0311 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22540/40960 [01:22<01:01, 297.17batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22595/40960 [01:22<01:03, 290.05batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22595/40960 [01:22<01:03, 290.05batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22640/40960 [01:23<01:07, 270.42batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22640/40960 [01:23<01:07, 270.42batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [01:23<01:09, 261.83batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [01:23<01:09, 261.83batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 22744/40960 [01:23<01:08, 265.47batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 22744/40960 [01:23<01:08, 265.47batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  56%|▌| 22797/40960 [01:23<01:08, 265.32batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  56%|▌| 22797/40960 [01:23<01:08, 265.32batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 22854/40960 [01:23<01:07, 270.10batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 22854/40960 [01:23<01:07, 270.10batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 22911/40960 [01:24<01:06, 273.44batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 22911/40960 [01:24<01:06, 273.44batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 22964/40960 [01:24<01:06, 270.69batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 22964/40960 [01:24<01:06, 270.69batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  56%|▌| 23019/40960 [01:24<01:06, 271.54batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  56%|▌| 23019/40960 [01:24<01:06, 271.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 23062/40960 [01:24<01:10, 253.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 23062/40960 [01:24<01:10, 253.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 23119/40960 [01:24<01:08, 262.08batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  56%|▌| 23119/40960 [01:24<01:08, 262.08batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23161/40960 [01:25<01:12, 245.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23161/40960 [01:25<01:12, 245.21batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  57%|▌| 23201/40960 [01:25<01:17, 230.31batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  57%|▌| 23201/40960 [01:25<01:17, 230.31batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23243/40960 [01:25<01:19, 223.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23243/40960 [01:25<01:19, 223.50batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  57%|▌| 23292/40960 [01:25<01:17, 228.77batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  57%|▌| 23292/40960 [01:25<01:17, 228.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23343/40960 [01:25<01:14, 235.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23343/40960 [01:25<01:14, 235.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23399/40960 [01:26<01:10, 248.55batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23399/40960 [01:26<01:10, 248.55batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23452/40960 [01:26<01:09, 252.96batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23452/40960 [01:26<01:09, 252.96batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23507/40960 [01:26<01:07, 259.37batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  57%|▌| 23507/40960 [01:26<01:07, 259.37batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23564/40960 [01:26<01:05, 265.72batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23564/40960 [01:26<01:05, 265.72batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23616/40960 [01:26<01:05, 263.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23616/40960 [01:26<01:05, 263.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23675/40960 [01:27<01:03, 272.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23675/40960 [01:27<01:03, 272.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23731/40960 [01:27<01:02, 273.75batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23731/40960 [01:27<01:02, 273.75batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23781/40960 [01:27<01:04, 265.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23781/40960 [01:27<01:04, 265.58batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  58%|▌| 23836/40960 [01:27<01:04, 267.54batches/s, l2_loss: 0.0312 - round_los\u001b[A\n",
      "Training:  58%|▌| 23836/40960 [01:27<01:04, 267.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23889/40960 [01:27<01:04, 265.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23889/40960 [01:27<01:04, 265.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23944/40960 [01:28<01:03, 268.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  58%|▌| 23944/40960 [01:28<01:03, 268.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 23997/40960 [01:28<01:03, 267.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 23997/40960 [01:28<01:03, 267.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24052/40960 [01:28<01:02, 268.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24052/40960 [01:28<01:02, 268.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24107/40960 [01:28<01:02, 270.32batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24107/40960 [01:28<01:02, 270.32batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24164/40960 [01:28<01:01, 274.43batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24164/40960 [01:28<01:01, 274.43batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24218/40960 [01:29<01:01, 272.81batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24218/40960 [01:29<01:01, 272.81batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24272/40960 [01:29<01:01, 271.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24272/40960 [01:29<01:01, 271.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24324/40960 [01:29<01:02, 267.16batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  59%|▌| 24324/40960 [01:29<01:02, 267.16batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24384/40960 [01:29<01:00, 275.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24384/40960 [01:29<01:00, 275.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24438/40960 [01:29<01:00, 272.60batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24438/40960 [01:29<01:00, 272.60batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24490/40960 [01:30<01:01, 268.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24490/40960 [01:30<01:01, 268.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24544/40960 [01:30<01:01, 268.27batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24544/40960 [01:30<01:01, 268.27batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24597/40960 [01:30<01:01, 265.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24597/40960 [01:30<01:01, 265.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24654/40960 [01:30<01:00, 269.90batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24654/40960 [01:30<01:00, 269.90batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24713/40960 [01:30<00:58, 276.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24713/40960 [01:30<00:58, 276.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24769/40960 [01:31<00:58, 275.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  60%|▌| 24769/40960 [01:31<00:58, 275.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 24819/40960 [01:31<01:00, 267.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 24819/40960 [01:31<01:00, 267.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 24876/40960 [01:31<00:59, 271.37batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 24876/40960 [01:31<00:59, 271.37batches/s, l2_loss: 0.0311 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 24938/40960 [01:31<00:56, 281.79batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 24938/40960 [01:31<00:56, 281.79batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 24998/40960 [01:31<00:55, 286.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 24998/40960 [01:31<00:55, 286.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 25051/40960 [01:32<00:56, 279.89batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 25051/40960 [01:32<00:56, 279.89batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 25104/40960 [01:32<00:57, 274.28batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 25104/40960 [01:32<00:57, 274.28batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 25156/40960 [01:32<00:58, 269.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  61%|▌| 25156/40960 [01:32<00:58, 269.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25208/40960 [01:32<00:59, 266.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25208/40960 [01:32<00:59, 266.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25264/40960 [01:32<00:58, 270.06batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25264/40960 [01:32<00:58, 270.06batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25320/40960 [01:33<00:57, 272.17batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25320/40960 [01:33<00:57, 272.17batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25373/40960 [01:33<00:57, 269.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25373/40960 [01:33<00:57, 269.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25425/40960 [01:33<00:58, 266.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25425/40960 [01:33<00:58, 266.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25479/40960 [01:33<00:57, 267.39batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25479/40960 [01:33<00:57, 267.39batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25539/40960 [01:33<00:55, 276.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25539/40960 [01:33<00:55, 276.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25592/40960 [01:34<00:56, 272.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  62%|▌| 25592/40960 [01:34<00:56, 272.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25650/40960 [01:34<00:55, 277.18batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25650/40960 [01:34<00:55, 277.18batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25706/40960 [01:34<00:54, 277.47batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25706/40960 [01:34<00:54, 277.47batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25766/40960 [01:34<00:53, 282.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25766/40960 [01:34<00:53, 282.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25820/40960 [01:34<00:54, 278.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25820/40960 [01:34<00:54, 278.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25872/40960 [01:35<00:55, 272.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25872/40960 [01:35<00:55, 272.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25930/40960 [01:35<00:54, 275.75batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25930/40960 [01:35<00:54, 275.75batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25984/40960 [01:35<00:54, 273.36batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  63%|▋| 25984/40960 [01:35<00:54, 273.36batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26041/40960 [01:35<00:53, 276.43batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26041/40960 [01:35<00:53, 276.43batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26101/40960 [01:35<00:52, 282.78batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26101/40960 [01:35<00:52, 282.78batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26149/40960 [01:36<00:55, 268.85batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26149/40960 [01:36<00:55, 268.85batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26203/40960 [01:36<00:54, 268.55batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26203/40960 [01:36<00:54, 268.55batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26258/40960 [01:36<00:54, 269.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26258/40960 [01:36<00:54, 269.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26314/40960 [01:36<00:53, 271.56batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26314/40960 [01:36<00:53, 271.56batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26369/40960 [01:36<00:53, 272.55batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  64%|▋| 26369/40960 [01:36<00:53, 272.55batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26423/40960 [01:37<00:53, 270.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26423/40960 [01:37<00:53, 270.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26479/40960 [01:37<00:53, 272.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26479/40960 [01:37<00:53, 272.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26532/40960 [01:37<00:53, 269.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26532/40960 [01:37<00:53, 269.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26586/40960 [01:37<00:53, 268.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26586/40960 [01:37<00:53, 268.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26637/40960 [01:37<00:54, 264.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26637/40960 [01:37<00:54, 264.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26696/40960 [01:38<00:52, 272.93batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26696/40960 [01:38<00:52, 272.93batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26754/40960 [01:38<00:51, 277.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26754/40960 [01:38<00:51, 277.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26809/40960 [01:38<00:51, 275.51batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  65%|▋| 26809/40960 [01:38<00:51, 275.51batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 26861/40960 [01:38<00:52, 270.05batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 26861/40960 [01:38<00:52, 270.05batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 26908/40960 [01:39<00:54, 256.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 26908/40960 [01:39<00:54, 256.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 26959/40960 [01:39<00:54, 255.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 26959/40960 [01:39<00:54, 255.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27016/40960 [01:39<00:52, 263.35batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27016/40960 [01:39<00:52, 263.35batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27068/40960 [01:39<00:53, 261.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27068/40960 [01:39<00:53, 261.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27115/40960 [01:39<00:54, 253.27batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27115/40960 [01:39<00:54, 253.27batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27168/40960 [01:40<00:53, 255.63batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27168/40960 [01:40<00:53, 255.63batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27216/40960 [01:40<00:54, 250.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  66%|▋| 27216/40960 [01:40<00:54, 250.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27271/40960 [01:40<00:53, 257.09batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27271/40960 [01:40<00:53, 257.09batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27325/40960 [01:40<00:52, 260.06batches/s, l2_loss: 0.0311 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|▋| 27325/40960 [01:40<00:52, 260.06batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27378/40960 [01:40<00:51, 261.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27378/40960 [01:40<00:51, 261.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27435/40960 [01:41<00:50, 267.51batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27435/40960 [01:41<00:50, 267.51batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27488/40960 [01:41<00:50, 266.33batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27488/40960 [01:41<00:50, 266.33batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27547/40960 [01:41<00:49, 273.64batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27547/40960 [01:41<00:49, 273.64batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27606/40960 [01:41<00:47, 279.63batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  67%|▋| 27606/40960 [01:41<00:47, 279.63batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27659/40960 [01:41<00:48, 273.80batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27659/40960 [01:41<00:48, 273.80batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27713/40960 [01:42<00:48, 272.33batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27713/40960 [01:42<00:48, 272.33batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27767/40960 [01:42<00:48, 271.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27767/40960 [01:42<00:48, 271.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27827/40960 [01:42<00:46, 279.53batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27827/40960 [01:42<00:46, 279.53batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27882/40960 [01:42<00:47, 276.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27882/40960 [01:42<00:47, 276.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27939/40960 [01:42<00:46, 278.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27939/40960 [01:42<00:46, 278.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27995/40960 [01:43<00:46, 278.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 27995/40960 [01:43<00:46, 278.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 28049/40960 [01:43<00:46, 275.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  68%|▋| 28049/40960 [01:43<00:46, 275.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28102/40960 [01:43<00:47, 271.93batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28102/40960 [01:43<00:47, 271.93batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28157/40960 [01:43<00:47, 271.81batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28157/40960 [01:43<00:47, 271.81batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28216/40960 [01:43<00:45, 278.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28216/40960 [01:43<00:45, 278.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28278/40960 [01:44<00:44, 287.88batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28278/40960 [01:44<00:44, 287.88batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28337/40960 [01:44<00:43, 289.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28337/40960 [01:44<00:43, 289.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28387/40960 [01:44<00:45, 277.01batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28387/40960 [01:44<00:45, 277.01batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28438/40960 [01:44<00:46, 269.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  69%|▋| 28438/40960 [01:44<00:46, 269.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28497/40960 [01:44<00:45, 276.38batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28497/40960 [01:44<00:45, 276.38batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28554/40960 [01:45<00:44, 278.02batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28554/40960 [01:45<00:44, 278.02batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28608/40960 [01:45<00:44, 275.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28608/40960 [01:45<00:44, 275.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28660/40960 [01:45<00:45, 270.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28660/40960 [01:45<00:45, 270.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28710/40960 [01:45<00:46, 263.87batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28710/40960 [01:45<00:46, 263.87batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28759/40960 [01:45<00:47, 258.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28759/40960 [01:45<00:47, 258.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28813/40960 [01:46<00:46, 260.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28813/40960 [01:46<00:46, 260.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28867/40960 [01:46<00:46, 262.75batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  70%|▋| 28867/40960 [01:46<00:46, 262.75batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 28925/40960 [01:46<00:44, 270.18batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 28925/40960 [01:46<00:44, 270.18batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 28985/40960 [01:46<00:43, 278.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 28985/40960 [01:46<00:43, 278.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29040/40960 [01:46<00:43, 275.93batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29040/40960 [01:46<00:43, 275.93batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29091/40960 [01:47<00:44, 269.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29091/40960 [01:47<00:44, 269.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29141/40960 [01:47<00:44, 263.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29141/40960 [01:47<00:44, 263.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29193/40960 [01:47<00:44, 261.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29193/40960 [01:47<00:44, 261.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29241/40960 [01:47<00:45, 255.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  71%|▋| 29241/40960 [01:47<00:45, 255.21batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29294/40960 [01:47<00:45, 257.28batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29294/40960 [01:47<00:45, 257.28batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29350/40960 [01:48<00:44, 262.22batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29350/40960 [01:48<00:44, 262.22batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29404/40960 [01:48<00:43, 264.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29404/40960 [01:48<00:43, 264.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29456/40960 [01:48<00:43, 261.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29456/40960 [01:48<00:43, 261.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29508/40960 [01:48<00:43, 260.99batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29508/40960 [01:48<00:43, 260.99batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29562/40960 [01:48<00:43, 262.78batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29562/40960 [01:48<00:43, 262.78batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29616/40960 [01:49<00:42, 264.76batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29616/40960 [01:49<00:42, 264.76batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29669/40960 [01:49<00:42, 264.22batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  72%|▋| 29669/40960 [01:49<00:42, 264.22batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29727/40960 [01:49<00:41, 271.25batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29727/40960 [01:49<00:41, 271.25batches/s, l2_loss: 0.0311 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|▋| 29781/40960 [01:49<00:41, 270.14batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29781/40960 [01:49<00:41, 270.14batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29839/40960 [01:49<00:40, 275.06batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29839/40960 [01:49<00:40, 275.06batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29898/40960 [01:50<00:39, 279.92batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29898/40960 [01:50<00:39, 279.92batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29956/40960 [01:50<00:38, 282.66batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 29956/40960 [01:50<00:38, 282.66batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 30012/40960 [01:50<00:39, 280.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 30012/40960 [01:50<00:39, 280.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 30071/40960 [01:50<00:38, 283.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  73%|▋| 30071/40960 [01:50<00:38, 283.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30124/40960 [01:50<00:39, 277.39batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30124/40960 [01:50<00:39, 277.39batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30176/40960 [01:51<00:39, 271.44batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30176/40960 [01:51<00:39, 271.44batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30224/40960 [01:51<00:41, 261.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30224/40960 [01:51<00:41, 261.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30276/40960 [01:51<00:41, 259.17batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30276/40960 [01:51<00:41, 259.17batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30329/40960 [01:51<00:40, 259.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30329/40960 [01:51<00:40, 259.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30379/40960 [01:51<00:41, 255.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30379/40960 [01:51<00:41, 255.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30426/40960 [01:52<00:42, 248.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30426/40960 [01:52<00:42, 248.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30474/40960 [01:52<00:42, 245.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  74%|▋| 30474/40960 [01:52<00:42, 245.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▋| 30531/40960 [01:52<00:40, 257.19batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▋| 30531/40960 [01:52<00:40, 257.19batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▋| 30590/40960 [01:52<00:38, 267.16batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▋| 30590/40960 [01:52<00:38, 267.16batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▋| 30641/40960 [01:52<00:39, 263.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▋| 30641/40960 [01:52<00:39, 263.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▋| 30693/40960 [01:53<00:39, 262.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▋| 30693/40960 [01:53<00:39, 262.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▊| 30748/40960 [01:53<00:38, 265.96batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▊| 30748/40960 [01:53<00:38, 265.96batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▊| 30805/40960 [01:53<00:37, 270.53batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▊| 30805/40960 [01:53<00:37, 270.53batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▊| 30861/40960 [01:53<00:36, 273.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▊| 30861/40960 [01:53<00:36, 273.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▊| 30916/40960 [01:53<00:36, 272.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  75%|▊| 30916/40960 [01:53<00:36, 272.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 30978/40960 [01:54<00:35, 282.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 30978/40960 [01:54<00:35, 282.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31034/40960 [01:54<00:35, 280.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31034/40960 [01:54<00:35, 280.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31088/40960 [01:54<00:35, 276.82batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31088/40960 [01:54<00:35, 276.82batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31133/40960 [01:54<00:37, 260.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31133/40960 [01:54<00:37, 260.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31191/40960 [01:54<00:36, 268.89batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31191/40960 [01:54<00:36, 268.89batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31232/40960 [01:55<00:39, 248.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31232/40960 [01:55<00:39, 248.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31271/40960 [01:55<00:41, 231.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31271/40960 [01:55<00:41, 231.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31321/40960 [01:55<00:40, 236.60batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  76%|▊| 31321/40960 [01:55<00:40, 236.60batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31371/40960 [01:55<00:40, 239.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31371/40960 [01:55<00:40, 239.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31424/40960 [01:55<00:38, 246.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31424/40960 [01:55<00:38, 246.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31483/40960 [01:56<00:36, 259.85batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31483/40960 [01:56<00:36, 259.85batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31535/40960 [01:56<00:36, 259.44batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31535/40960 [01:56<00:36, 259.44batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31592/40960 [01:56<00:35, 266.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31592/40960 [01:56<00:35, 266.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31653/40960 [01:56<00:33, 276.83batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31653/40960 [01:56<00:33, 276.83batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31705/40960 [01:56<00:34, 270.79batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  77%|▊| 31705/40960 [01:56<00:34, 270.79batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31760/40960 [01:57<00:33, 271.66batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31760/40960 [01:57<00:33, 271.66batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31817/40960 [01:57<00:33, 275.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31817/40960 [01:57<00:33, 275.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31878/40960 [01:57<00:32, 282.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31878/40960 [01:57<00:32, 282.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31938/40960 [01:57<00:31, 287.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31938/40960 [01:57<00:31, 287.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31990/40960 [01:57<00:32, 278.37batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 31990/40960 [01:57<00:32, 278.37batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 32042/40960 [01:58<00:32, 272.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 32042/40960 [01:58<00:32, 272.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 32098/40960 [01:58<00:32, 273.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 32098/40960 [01:58<00:32, 273.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  78%|▊| 32153/40960 [01:58<00:32, 273.47batches/s, l2_loss: 0.0311 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|▊| 32153/40960 [01:58<00:32, 273.47batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32202/40960 [01:58<00:33, 263.72batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32202/40960 [01:58<00:33, 263.72batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32248/40960 [01:58<00:34, 253.05batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32248/40960 [01:58<00:34, 253.05batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32302/40960 [01:59<00:33, 257.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32302/40960 [01:59<00:33, 257.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32357/40960 [01:59<00:32, 261.55batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32357/40960 [01:59<00:32, 261.55batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32411/40960 [01:59<00:32, 263.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32411/40960 [01:59<00:32, 263.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32466/40960 [01:59<00:31, 265.65batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32466/40960 [01:59<00:31, 265.65batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32524/40960 [02:00<00:31, 271.51batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  79%|▊| 32524/40960 [02:00<00:31, 271.51batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32578/40960 [02:00<00:31, 270.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32578/40960 [02:00<00:31, 270.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32633/40960 [02:00<00:30, 271.33batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32633/40960 [02:00<00:30, 271.33batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32692/40960 [02:00<00:29, 278.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32692/40960 [02:00<00:29, 278.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32743/40960 [02:00<00:30, 271.06batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32743/40960 [02:00<00:30, 271.06batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32800/40960 [02:01<00:29, 274.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32800/40960 [02:01<00:29, 274.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32856/40960 [02:01<00:29, 275.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32856/40960 [02:01<00:29, 275.00batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32911/40960 [02:01<00:29, 274.36batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32911/40960 [02:01<00:29, 274.36batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32967/40960 [02:01<00:28, 276.02batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  80%|▊| 32967/40960 [02:01<00:28, 276.02batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33024/40960 [02:01<00:28, 278.04batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33024/40960 [02:01<00:28, 278.04batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33079/40960 [02:02<00:28, 276.52batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33079/40960 [02:02<00:28, 276.52batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33135/40960 [02:02<00:28, 276.89batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33135/40960 [02:02<00:28, 276.89batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33190/40960 [02:02<00:28, 275.36batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33190/40960 [02:02<00:28, 275.36batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33240/40960 [02:02<00:28, 267.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33240/40960 [02:02<00:28, 267.49batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33292/40960 [02:02<00:28, 264.52batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33292/40960 [02:02<00:28, 264.52batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33344/40960 [02:03<00:29, 262.19batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  81%|▊| 33344/40960 [02:03<00:29, 262.19batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33401/40960 [02:03<00:28, 268.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33401/40960 [02:03<00:28, 268.68batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33462/40960 [02:03<00:26, 278.92batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33462/40960 [02:03<00:26, 278.92batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33519/40960 [02:03<00:26, 279.94batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33519/40960 [02:03<00:26, 279.94batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33576/40960 [02:03<00:26, 280.43batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33576/40960 [02:03<00:26, 280.43batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33635/40960 [02:04<00:25, 284.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33635/40960 [02:04<00:25, 284.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33696/40960 [02:04<00:25, 289.45batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33696/40960 [02:04<00:25, 289.45batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33754/40960 [02:04<00:24, 289.04batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  82%|▊| 33754/40960 [02:04<00:24, 289.04batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 33811/40960 [02:04<00:24, 286.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 33811/40960 [02:04<00:24, 286.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 33869/40960 [02:04<00:24, 286.93batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 33869/40960 [02:04<00:24, 286.93batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 33927/40960 [02:05<00:24, 287.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 33927/40960 [02:05<00:24, 287.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 33983/40960 [02:05<00:24, 284.38batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 33983/40960 [02:05<00:24, 284.38batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 34045/40960 [02:05<00:23, 291.94batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 34045/40960 [02:05<00:23, 291.94batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 34108/40960 [02:05<00:22, 298.32batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 34108/40960 [02:05<00:22, 298.32batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 34166/40960 [02:05<00:23, 295.12batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  83%|▊| 34166/40960 [02:05<00:23, 295.12batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34221/40960 [02:06<00:23, 288.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34221/40960 [02:06<00:23, 288.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34273/40960 [02:06<00:24, 278.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34273/40960 [02:06<00:24, 278.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34327/40960 [02:06<00:24, 274.48batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34327/40960 [02:06<00:24, 274.48batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34381/40960 [02:06<00:24, 272.61batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34381/40960 [02:06<00:24, 272.61batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34437/40960 [02:06<00:23, 274.31batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34437/40960 [02:06<00:23, 274.31batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34495/40960 [02:07<00:23, 278.92batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34495/40960 [02:07<00:23, 278.92batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34553/40960 [02:07<00:22, 282.19batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34553/40960 [02:07<00:22, 282.19batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34609/40960 [02:07<00:22, 280.87batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  84%|▊| 34609/40960 [02:07<00:22, 280.87batches/s, l2_loss: 0.0311 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34663/40960 [02:07<00:22, 276.80batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34663/40960 [02:07<00:22, 276.80batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34722/40960 [02:07<00:22, 280.82batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34722/40960 [02:07<00:22, 280.82batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34771/40960 [02:08<00:23, 268.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34771/40960 [02:08<00:23, 268.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34826/40960 [02:08<00:22, 269.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34826/40960 [02:08<00:22, 269.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34882/40960 [02:08<00:22, 271.17batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34882/40960 [02:08<00:22, 271.17batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34939/40960 [02:08<00:21, 274.80batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34939/40960 [02:08<00:21, 274.80batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34991/40960 [02:08<00:22, 269.99batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  85%|▊| 34991/40960 [02:08<00:22, 269.99batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35045/40960 [02:09<00:21, 269.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35045/40960 [02:09<00:21, 269.57batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35103/40960 [02:09<00:21, 275.46batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35103/40960 [02:09<00:21, 275.46batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35155/40960 [02:09<00:21, 270.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35155/40960 [02:09<00:21, 270.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35202/40960 [02:09<00:22, 259.69batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35202/40960 [02:09<00:22, 259.69batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35255/40960 [02:09<00:21, 261.16batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35255/40960 [02:09<00:21, 261.16batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35312/40960 [02:10<00:21, 268.19batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35312/40960 [02:10<00:21, 268.19batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35365/40960 [02:10<00:21, 266.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35365/40960 [02:10<00:21, 266.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35413/40960 [02:10<00:21, 257.84batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  86%|▊| 35413/40960 [02:10<00:21, 257.84batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35470/40960 [02:10<00:20, 265.74batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35470/40960 [02:10<00:20, 265.74batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35524/40960 [02:10<00:20, 266.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35524/40960 [02:10<00:20, 266.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [02:11<00:19, 271.44batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [02:11<00:19, 271.44batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35640/40960 [02:11<00:19, 277.99batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35640/40960 [02:11<00:19, 277.99batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35693/40960 [02:11<00:19, 274.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35693/40960 [02:11<00:19, 274.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35744/40960 [02:11<00:19, 267.52batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35744/40960 [02:11<00:19, 267.52batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35800/40960 [02:11<00:19, 270.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  87%|▊| 35800/40960 [02:11<00:19, 270.73batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 35860/40960 [02:12<00:18, 278.32batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 35860/40960 [02:12<00:18, 278.32batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 35915/40960 [02:12<00:18, 276.76batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 35915/40960 [02:12<00:18, 276.76batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 35969/40960 [02:12<00:18, 274.18batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 35969/40960 [02:12<00:18, 274.18batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 36027/40960 [02:12<00:17, 277.35batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 36027/40960 [02:12<00:17, 277.35batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 36083/40960 [02:12<00:17, 277.13batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 36083/40960 [02:12<00:17, 277.13batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 36139/40960 [02:13<00:17, 277.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 36139/40960 [02:13<00:17, 277.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 36194/40960 [02:13<00:17, 276.47batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  88%|▉| 36194/40960 [02:13<00:17, 276.47batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  89%|▉| 36251/40960 [02:13<00:16, 278.59batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  89%|▉| 36251/40960 [02:13<00:16, 278.59batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36304/40960 [02:13<00:17, 273.39batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36304/40960 [02:13<00:17, 273.39batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36359/40960 [02:13<00:16, 272.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36359/40960 [02:13<00:16, 272.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36412/40960 [02:14<00:16, 269.87batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36412/40960 [02:14<00:16, 269.87batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36472/40960 [02:14<00:16, 278.12batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36472/40960 [02:14<00:16, 278.12batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36526/40960 [02:14<00:16, 274.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36526/40960 [02:14<00:16, 274.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36586/40960 [02:14<00:15, 280.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36586/40960 [02:14<00:15, 280.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36644/40960 [02:14<00:15, 282.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  89%|▉| 36644/40960 [02:14<00:15, 282.77batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36697/40960 [02:15<00:15, 276.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36697/40960 [02:15<00:15, 276.70batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36754/40960 [02:15<00:15, 278.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36754/40960 [02:15<00:15, 278.24batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36809/40960 [02:15<00:15, 275.86batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36809/40960 [02:15<00:15, 275.86batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36861/40960 [02:15<00:15, 270.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36861/40960 [02:15<00:15, 270.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36913/40960 [02:15<00:15, 265.96batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36913/40960 [02:15<00:15, 265.96batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36969/40960 [02:16<00:14, 268.90batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  90%|▉| 36969/40960 [02:16<00:14, 268.90batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  90%|▉| 37028/40960 [02:16<00:14, 275.97batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  90%|▉| 37028/40960 [02:16<00:14, 275.97batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37083/40960 [02:16<00:14, 275.17batches/s, l2_loss: 0.0311 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|▉| 37083/40960 [02:16<00:14, 275.17batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  91%|▉| 37140/40960 [02:16<00:13, 277.50batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  91%|▉| 37140/40960 [02:16<00:13, 277.50batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37198/40960 [02:16<00:13, 279.56batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37198/40960 [02:16<00:13, 279.56batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  91%|▉| 37249/40960 [02:17<00:13, 272.01batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  91%|▉| 37249/40960 [02:17<00:13, 272.01batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37300/40960 [02:17<00:13, 265.63batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37300/40960 [02:17<00:13, 265.63batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37357/40960 [02:17<00:13, 271.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37357/40960 [02:17<00:13, 271.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37409/40960 [02:17<00:13, 266.48batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37409/40960 [02:17<00:13, 266.48batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37458/40960 [02:17<00:13, 259.71batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37458/40960 [02:17<00:13, 259.71batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  92%|▉| 37507/40960 [02:18<00:13, 254.37batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  92%|▉| 37507/40960 [02:18<00:13, 254.37batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37561/40960 [02:18<00:13, 257.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37561/40960 [02:18<00:13, 257.11batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37608/40960 [02:18<00:13, 248.97batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37608/40960 [02:18<00:13, 248.97batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  92%|▉| 37654/40960 [02:18<00:13, 243.18batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  92%|▉| 37654/40960 [02:18<00:13, 243.18batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37702/40960 [02:18<00:13, 241.59batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37702/40960 [02:18<00:13, 241.59batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  92%|▉| 37752/40960 [02:19<00:13, 243.05batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  92%|▉| 37752/40960 [02:19<00:13, 243.05batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37800/40960 [02:19<00:13, 241.84batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37800/40960 [02:19<00:13, 241.84batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37856/40960 [02:19<00:12, 251.59batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  92%|▉| 37856/40960 [02:19<00:12, 251.59batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  93%|▉| 37911/40960 [02:19<00:11, 258.47batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  93%|▉| 37911/40960 [02:19<00:11, 258.47batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 37966/40960 [02:19<00:11, 262.90batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 37966/40960 [02:19<00:11, 262.90batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 38018/40960 [02:20<00:11, 261.60batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 38018/40960 [02:20<00:11, 261.60batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 38072/40960 [02:20<00:10, 263.91batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 38072/40960 [02:20<00:10, 263.91batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 38127/40960 [02:20<00:10, 265.82batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 38127/40960 [02:20<00:10, 265.82batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 38177/40960 [02:20<00:10, 259.18batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  93%|▉| 38177/40960 [02:20<00:10, 259.18batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  93%|▉| 38230/40960 [02:20<00:10, 259.75batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  93%|▉| 38230/40960 [02:21<00:10, 259.75batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  93%|▉| 38279/40960 [02:21<00:10, 254.58batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  93%|▉| 38279/40960 [02:21<00:10, 254.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  94%|▉| 38329/40960 [02:21<00:10, 252.51batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  94%|▉| 38329/40960 [02:21<00:10, 252.51batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  94%|▉| 38382/40960 [02:21<00:10, 255.89batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  94%|▉| 38382/40960 [02:21<00:10, 255.89batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  94%|▉| 38439/40960 [02:21<00:09, 264.39batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  94%|▉| 38439/40960 [02:21<00:09, 264.39batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  94%|▉| 38492/40960 [02:22<00:09, 264.38batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  94%|▉| 38492/40960 [02:22<00:09, 264.38batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  94%|▉| 38550/40960 [02:22<00:08, 270.82batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  94%|▉| 38550/40960 [02:22<00:08, 270.82batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  94%|▉| 38608/40960 [02:22<00:08, 275.22batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  94%|▉| 38608/40960 [02:22<00:08, 275.22batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  94%|▉| 38656/40960 [02:22<00:08, 264.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  94%|▉| 38656/40960 [02:22<00:08, 264.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  95%|▉| 38714/40960 [02:22<00:08, 270.67batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  95%|▉| 38714/40960 [02:22<00:08, 270.67batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  95%|▉| 38771/40960 [02:23<00:07, 274.64batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  95%|▉| 38771/40960 [02:23<00:07, 274.64batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  95%|▉| 38828/40960 [02:23<00:07, 276.03batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  95%|▉| 38828/40960 [02:23<00:07, 276.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  95%|▉| 38880/40960 [02:23<00:07, 271.25batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  95%|▉| 38880/40960 [02:23<00:07, 271.25batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  95%|▉| 38930/40960 [02:23<00:07, 263.62batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  95%|▉| 38930/40960 [02:23<00:07, 263.62batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  95%|▉| 38980/40960 [02:23<00:07, 258.39batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  95%|▉| 38980/40960 [02:23<00:07, 258.39batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  95%|▉| 39035/40960 [02:24<00:07, 261.96batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  95%|▉| 39035/40960 [02:24<00:07, 261.96batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  95%|▉| 39089/40960 [02:24<00:07, 263.20batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  95%|▉| 39089/40960 [02:24<00:07, 263.20batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  96%|▉| 39143/40960 [02:24<00:06, 264.47batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  96%|▉| 39143/40960 [02:24<00:06, 264.47batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39198/40960 [02:24<00:06, 267.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39198/40960 [02:24<00:06, 267.15batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  96%|▉| 39258/40960 [02:24<00:06, 276.14batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  96%|▉| 39258/40960 [02:24<00:06, 276.14batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39317/40960 [02:25<00:05, 280.84batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39317/40960 [02:25<00:05, 280.84batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39371/40960 [02:25<00:05, 276.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39371/40960 [02:25<00:05, 276.34batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39426/40960 [02:25<00:05, 275.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39426/40960 [02:25<00:05, 275.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|▉| 39481/40960 [02:25<00:05, 274.53batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  96%|▉| 39481/40960 [02:25<00:05, 274.53batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39536/40960 [02:25<00:05, 273.40batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39536/40960 [02:25<00:05, 273.40batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39596/40960 [02:26<00:04, 280.86batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39596/40960 [02:26<00:04, 280.86batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39653/40960 [02:26<00:04, 280.90batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39653/40960 [02:26<00:04, 280.90batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  97%|▉| 39704/40960 [02:26<00:04, 271.56batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  97%|▉| 39704/40960 [02:26<00:04, 271.56batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  97%|▉| 39755/40960 [02:26<00:04, 266.30batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  97%|▉| 39755/40960 [02:26<00:04, 266.30batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39809/40960 [02:26<00:04, 267.08batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39809/40960 [02:26<00:04, 267.08batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39866/40960 [02:27<00:04, 271.26batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39866/40960 [02:27<00:04, 271.26batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39922/40960 [02:27<00:03, 273.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  97%|▉| 39922/40960 [02:27<00:03, 273.20batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 39977/40960 [02:27<00:03, 273.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 39977/40960 [02:27<00:03, 273.03batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40032/40960 [02:27<00:03, 273.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40032/40960 [02:27<00:03, 273.15batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40085/40960 [02:27<00:03, 269.58batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40085/40960 [02:27<00:03, 269.58batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  98%|▉| 40136/40960 [02:28<00:03, 263.86batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training:  98%|▉| 40136/40960 [02:28<00:03, 263.86batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40186/40960 [02:28<00:02, 259.02batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40186/40960 [02:28<00:02, 259.02batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40240/40960 [02:28<00:02, 262.26batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40240/40960 [02:28<00:02, 262.26batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40299/40960 [02:28<00:02, 271.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  98%|▉| 40299/40960 [02:28<00:02, 271.42batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40359/40960 [02:28<00:02, 279.14batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40359/40960 [02:28<00:02, 279.14batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40414/40960 [02:29<00:01, 276.79batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40414/40960 [02:29<00:01, 276.79batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40468/40960 [02:29<00:01, 273.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40468/40960 [02:29<00:01, 273.41batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40521/40960 [02:29<00:01, 270.87batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40521/40960 [02:29<00:01, 270.87batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40575/40960 [02:29<00:01, 269.48batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40575/40960 [02:29<00:01, 269.48batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40635/40960 [02:29<00:01, 277.90batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40635/40960 [02:29<00:01, 277.90batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40692/40960 [02:30<00:00, 278.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40692/40960 [02:30<00:00, 278.54batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40745/40960 [02:30<00:00, 273.81batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "Training:  99%|▉| 40745/40960 [02:30<00:00, 273.81batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training: 100%|▉| 40799/40960 [02:30<00:00, 271.91batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training: 100%|▉| 40799/40960 [02:30<00:00, 271.91batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training: 100%|▉| 40853/40960 [02:30<00:00, 270.92batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training: 100%|▉| 40853/40960 [02:30<00:00, 270.92batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training: 100%|▉| 40913/40960 [02:30<00:00, 279.22batches/s, l2_loss: 0.0310 - round_los\u001b[A\n",
      "Training: 100%|▉| 40913/40960 [02:30<00:00, 279.22batches/s, l2_loss: 0.0311 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:09:17.655531: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  38%|▍| 10/26 [19:58<36:35, 137.22s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:09:21.016885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:09:27.907702: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<25:31:56,  2.24s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<25:31:56,  2.24s/batches, l2_loss: 0.0337 - round_loss:\u001b[A\n",
      "Training:   0%| | 56/40960 [00:02<21:43, 31.38batches/s, l2_loss: 0.0337 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 56/40960 [00:02<21:43, 31.38batches/s, l2_loss: 0.0596 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 108/40960 [00:02<10:48, 62.96batches/s, l2_loss: 0.0596 - round_loss: \u001b[A\n",
      "Training:   0%| | 108/40960 [00:02<10:48, 62.96batches/s, l2_loss: 0.0783 - round_loss: \u001b[A\n",
      "Training:   0%| | 169/40960 [00:02<06:36, 102.80batches/s, l2_loss: 0.0783 - round_loss:\u001b[A\n",
      "Training:   0%| | 169/40960 [00:02<06:36, 102.80batches/s, l2_loss: 0.0695 - round_loss:\u001b[A\n",
      "Training:   1%| | 228/40960 [00:03<04:52, 139.14batches/s, l2_loss: 0.0695 - round_loss:\u001b[A\n",
      "Training:   1%| | 228/40960 [00:03<04:52, 139.14batches/s, l2_loss: 0.0693 - round_loss:\u001b[A\n",
      "Training:   1%| | 285/40960 [00:03<03:59, 169.94batches/s, l2_loss: 0.0693 - round_loss:\u001b[A\n",
      "Training:   1%| | 285/40960 [00:03<03:59, 169.94batches/s, l2_loss: 0.0701 - round_loss:\u001b[A\n",
      "Training:   1%| | 345/40960 [00:03<03:22, 200.10batches/s, l2_loss: 0.0701 - round_loss:\u001b[A\n",
      "Training:   1%| | 345/40960 [00:03<03:22, 200.10batches/s, l2_loss: 0.0742 - round_loss:\u001b[A\n",
      "Training:   1%| | 404/40960 [00:03<03:01, 223.46batches/s, l2_loss: 0.0742 - round_loss:\u001b[A\n",
      "Training:   1%| | 404/40960 [00:03<03:01, 223.46batches/s, l2_loss: 0.0728 - round_loss:\u001b[A\n",
      "Training:   1%| | 456/40960 [00:03<02:53, 232.94batches/s, l2_loss: 0.0728 - round_loss:\u001b[A\n",
      "Training:   1%| | 456/40960 [00:03<02:53, 232.94batches/s, l2_loss: 0.0714 - round_loss:\u001b[A\n",
      "Training:   1%| | 513/40960 [00:04<02:44, 246.62batches/s, l2_loss: 0.0714 - round_loss:\u001b[A\n",
      "Training:   1%| | 513/40960 [00:04<02:44, 246.62batches/s, l2_loss: 0.0734 - round_loss:\u001b[A\n",
      "Training:   1%| | 569/40960 [00:04<02:38, 254.82batches/s, l2_loss: 0.0734 - round_loss:\u001b[A\n",
      "Training:   1%| | 569/40960 [00:04<02:38, 254.82batches/s, l2_loss: 0.0715 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%| | 627/40960 [00:04<02:32, 264.09batches/s, l2_loss: 0.0715 - round_loss:\u001b[A\n",
      "Training:   2%| | 627/40960 [00:04<02:32, 264.09batches/s, l2_loss: 0.0732 - round_loss:\u001b[A\n",
      "Training:   2%| | 691/40960 [00:04<02:23, 280.07batches/s, l2_loss: 0.0732 - round_loss:\u001b[A\n",
      "Training:   2%| | 691/40960 [00:04<02:23, 280.07batches/s, l2_loss: 0.0745 - round_loss:\u001b[A\n",
      "Training:   2%| | 750/40960 [00:04<02:21, 283.34batches/s, l2_loss: 0.0745 - round_loss:\u001b[A\n",
      "Training:   2%| | 750/40960 [00:04<02:21, 283.34batches/s, l2_loss: 0.0738 - round_loss:\u001b[A\n",
      "Training:   2%| | 808/40960 [00:05<02:21, 284.77batches/s, l2_loss: 0.0738 - round_loss:\u001b[A\n",
      "Training:   2%| | 808/40960 [00:05<02:21, 284.77batches/s, l2_loss: 0.0725 - round_loss:\u001b[A\n",
      "Training:   2%| | 866/40960 [00:05<02:20, 284.87batches/s, l2_loss: 0.0725 - round_loss:\u001b[A\n",
      "Training:   2%| | 866/40960 [00:05<02:20, 284.87batches/s, l2_loss: 0.0719 - round_loss:\u001b[A\n",
      "Training:   2%| | 916/40960 [00:05<02:26, 273.86batches/s, l2_loss: 0.0719 - round_loss:\u001b[A\n",
      "Training:   2%| | 916/40960 [00:05<02:26, 273.86batches/s, l2_loss: 0.0730 - round_loss:\u001b[A\n",
      "Training:   2%| | 974/40960 [00:05<02:23, 278.18batches/s, l2_loss: 0.0730 - round_loss:\u001b[A\n",
      "Training:   2%| | 974/40960 [00:05<02:23, 278.18batches/s, l2_loss: 0.0719 - round_loss:\u001b[A\n",
      "Training:   3%| | 1035/40960 [00:05<02:19, 285.95batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:   3%| | 1035/40960 [00:05<02:19, 285.95batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   3%| | 1098/40960 [00:06<02:15, 294.38batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   3%| | 1098/40960 [00:06<02:15, 294.38batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   3%| | 1158/40960 [00:06<02:14, 295.03batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   3%| | 1158/40960 [00:06<02:14, 295.03batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   3%| | 1213/40960 [00:06<02:17, 288.93batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   3%| | 1213/40960 [00:06<02:17, 288.93batches/s, l2_loss: 0.0744 - round_loss\u001b[A\n",
      "Training:   3%| | 1274/40960 [00:06<02:15, 292.43batches/s, l2_loss: 0.0744 - round_loss\u001b[A\n",
      "Training:   3%| | 1274/40960 [00:06<02:15, 292.43batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   3%| | 1336/40960 [00:06<02:13, 296.31batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   3%| | 1336/40960 [00:06<02:13, 296.31batches/s, l2_loss: 0.0741 - round_loss\u001b[A\n",
      "Training:   3%| | 1393/40960 [00:07<02:15, 292.22batches/s, l2_loss: 0.0741 - round_loss\u001b[A\n",
      "Training:   3%| | 1393/40960 [00:07<02:15, 292.22batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   4%| | 1454/40960 [00:07<02:13, 295.17batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   4%| | 1454/40960 [00:07<02:13, 295.17batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   4%| | 1514/40960 [00:07<02:13, 296.08batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   4%| | 1514/40960 [00:07<02:13, 296.08batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   4%| | 1573/40960 [00:07<02:13, 295.33batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   4%| | 1573/40960 [00:07<02:13, 295.33batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   4%| | 1635/40960 [00:07<02:11, 298.74batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   4%| | 1635/40960 [00:07<02:11, 298.74batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   4%| | 1695/40960 [00:08<02:11, 298.20batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   4%| | 1695/40960 [00:08<02:11, 298.20batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   4%| | 1757/40960 [00:08<02:10, 300.60batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   4%| | 1757/40960 [00:08<02:10, 300.60batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   4%| | 1815/40960 [00:08<02:11, 297.10batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   4%| | 1815/40960 [00:08<02:11, 297.10batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   5%| | 1874/40960 [00:08<02:12, 295.17batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   5%| | 1874/40960 [00:08<02:12, 295.17batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   5%| | 1929/40960 [00:08<02:15, 288.23batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   5%| | 1929/40960 [00:08<02:15, 288.23batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   5%| | 1992/40960 [00:09<02:12, 295.13batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   5%| | 1992/40960 [00:09<02:12, 295.13batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   5%| | 2050/40960 [00:09<02:12, 292.63batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   5%| | 2050/40960 [00:09<02:12, 292.63batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   5%| | 2112/40960 [00:09<02:10, 296.77batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   5%| | 2112/40960 [00:09<02:10, 296.77batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   5%| | 2173/40960 [00:09<02:09, 298.60batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   5%| | 2173/40960 [00:09<02:09, 298.60batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   5%| | 2236/40960 [00:09<02:07, 303.00batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   5%| | 2236/40960 [00:09<02:07, 303.00batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   6%| | 2293/40960 [00:10<02:10, 296.49batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   6%| | 2293/40960 [00:10<02:10, 296.49batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   6%| | 2351/40960 [00:10<02:11, 293.58batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   6%| | 2351/40960 [00:10<02:11, 293.58batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   6%| | 2409/40960 [00:10<02:11, 292.48batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   6%| | 2409/40960 [00:10<02:11, 292.48batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   6%| | 2467/40960 [00:10<02:12, 291.43batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   6%| | 2467/40960 [00:10<02:12, 291.43batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   6%| | 2520/40960 [00:10<02:16, 282.53batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   6%| | 2520/40960 [00:10<02:16, 282.53batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   6%| | 2574/40960 [00:11<02:17, 278.66batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   6%| | 2574/40960 [00:11<02:17, 278.66batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   6%| | 2632/40960 [00:11<02:16, 281.67batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   6%| | 2632/40960 [00:11<02:16, 281.67batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   7%| | 2691/40960 [00:11<02:14, 284.39batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   7%| | 2691/40960 [00:11<02:14, 284.39batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   7%| | 2749/40960 [00:11<02:13, 285.58batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   7%| | 2749/40960 [00:11<02:13, 285.58batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   7%| | 2809/40960 [00:11<02:11, 289.43batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   7%| | 2809/40960 [00:11<02:11, 289.43batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   7%| | 2863/40960 [00:12<02:14, 282.81batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   7%| | 2863/40960 [00:12<02:14, 282.81batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   7%| | 2915/40960 [00:12<02:18, 274.60batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   7%| | 2915/40960 [00:12<02:18, 274.60batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   7%| | 2971/40960 [00:12<02:18, 275.08batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   7%| | 2971/40960 [00:12<02:18, 275.08batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   7%| | 3033/40960 [00:12<02:13, 284.40batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   7%| | 3033/40960 [00:12<02:13, 284.40batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   8%| | 3095/40960 [00:12<02:09, 291.64batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   8%| | 3095/40960 [00:12<02:09, 291.64batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   8%| | 3157/40960 [00:13<02:07, 296.15batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   8%| | 3157/40960 [00:13<02:07, 296.15batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   8%| | 3219/40960 [00:13<02:06, 299.02batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3219/40960 [00:13<02:06, 299.02batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   8%| | 3279/40960 [00:13<02:06, 298.68batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   8%| | 3279/40960 [00:13<02:06, 298.68batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   8%| | 3336/40960 [00:13<02:07, 294.35batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   8%| | 3336/40960 [00:13<02:07, 294.35batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   8%| | 3400/40960 [00:13<02:04, 300.93batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   8%| | 3400/40960 [00:13<02:04, 300.93batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   8%| | 3457/40960 [00:14<02:07, 295.15batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   8%| | 3457/40960 [00:14<02:07, 295.15batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   9%| | 3513/40960 [00:14<02:09, 289.67batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   9%| | 3513/40960 [00:14<02:09, 289.67batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   9%| | 3570/40960 [00:14<02:10, 287.10batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   9%| | 3570/40960 [00:14<02:10, 287.10batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   9%| | 3626/40960 [00:14<02:11, 283.72batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   9%| | 3626/40960 [00:14<02:11, 283.72batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   9%| | 3682/40960 [00:14<02:12, 282.25batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   9%| | 3682/40960 [00:14<02:12, 282.25batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   9%| | 3742/40960 [00:15<02:09, 287.30batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   9%| | 3742/40960 [00:15<02:09, 287.30batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   9%| | 3800/40960 [00:15<02:09, 288.00batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   9%| | 3800/40960 [00:15<02:09, 288.00batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   9%| | 3858/40960 [00:15<02:08, 288.58batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   9%| | 3858/40960 [00:15<02:08, 288.58batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 3915/40960 [00:15<02:08, 287.19batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 3915/40960 [00:15<02:08, 287.19batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  10%| | 3974/40960 [00:15<02:07, 289.08batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  10%| | 3974/40960 [00:15<02:07, 289.08batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  10%| | 4035/40960 [00:16<02:05, 293.57batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  10%| | 4035/40960 [00:16<02:05, 293.57batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  10%| | 4092/40960 [00:16<02:07, 289.87batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  10%| | 4092/40960 [00:16<02:07, 289.87batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 4150/40960 [00:16<02:07, 288.69batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 4150/40960 [00:16<02:07, 288.69batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  10%| | 4205/40960 [00:16<02:09, 284.58batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  10%| | 4205/40960 [00:16<02:09, 284.58batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  10%| | 4266/40960 [00:16<02:06, 290.32batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  10%| | 4266/40960 [00:16<02:06, 290.32batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  11%| | 4323/40960 [00:17<02:06, 288.67batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  11%| | 4323/40960 [00:17<02:06, 288.67batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  11%| | 4381/40960 [00:17<02:06, 288.71batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  11%| | 4381/40960 [00:17<02:06, 288.71batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  11%| | 4443/40960 [00:17<02:03, 294.92batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  11%| | 4443/40960 [00:17<02:03, 294.92batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  11%| | 4503/40960 [00:17<02:03, 295.68batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  11%| | 4503/40960 [00:17<02:03, 295.68batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  11%| | 4563/40960 [00:17<02:02, 296.84batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  11%| | 4563/40960 [00:17<02:02, 296.84batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  11%| | 4623/40960 [00:18<02:02, 297.06batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  11%| | 4623/40960 [00:18<02:02, 297.06batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  11%| | 4683/40960 [00:18<02:02, 296.62batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  11%| | 4683/40960 [00:18<02:02, 296.62batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  12%| | 4743/40960 [00:18<02:01, 297.06batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  12%| | 4743/40960 [00:18<02:01, 297.06batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 4802/40960 [00:18<02:01, 296.39batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 4802/40960 [00:18<02:01, 296.39batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  12%| | 4859/40960 [00:18<02:03, 292.58batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  12%| | 4859/40960 [00:18<02:03, 292.58batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 4918/40960 [00:19<02:03, 291.99batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 4918/40960 [00:19<02:03, 291.99batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 4978/40960 [00:19<02:02, 293.75batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 4978/40960 [00:19<02:02, 293.75batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 5039/40960 [00:19<02:01, 295.62batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 5039/40960 [00:19<02:01, 295.62batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 5097/40960 [00:19<02:02, 293.22batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 5097/40960 [00:19<02:02, 293.22batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5157/40960 [00:19<02:01, 294.68batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5157/40960 [00:19<02:01, 294.68batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5217/40960 [00:20<02:01, 295.27batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5217/40960 [00:20<02:01, 295.27batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5279/40960 [00:20<01:59, 298.93batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5279/40960 [00:20<01:59, 298.93batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5341/40960 [00:20<01:57, 302.02batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5341/40960 [00:20<01:57, 302.02batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5396/40960 [00:20<02:01, 293.37batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5396/40960 [00:20<02:01, 293.37batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5454/40960 [00:21<02:02, 291.03batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5454/40960 [00:21<02:02, 291.03batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5514/40960 [00:21<02:00, 293.10batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5514/40960 [00:21<02:00, 293.10batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5574/40960 [00:21<02:00, 294.12batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5574/40960 [00:21<02:00, 294.12batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5635/40960 [00:21<01:59, 296.63batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5635/40960 [00:21<01:59, 296.63batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5693/40960 [00:21<01:59, 294.01batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5693/40960 [00:21<01:59, 294.01batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5749/40960 [00:22<02:01, 289.74batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5749/40960 [00:22<02:01, 289.74batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5808/40960 [00:22<02:00, 290.91batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5808/40960 [00:22<02:00, 290.91batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|▏| 5864/40960 [00:22<02:02, 287.31batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5864/40960 [00:22<02:02, 287.31batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5924/40960 [00:22<02:00, 290.25batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5924/40960 [00:22<02:00, 290.25batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5983/40960 [00:22<02:00, 290.62batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5983/40960 [00:22<02:00, 290.62batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6041/40960 [00:23<02:00, 289.33batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6041/40960 [00:23<02:00, 289.33batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6102/40960 [00:23<01:58, 293.52batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6102/40960 [00:23<01:58, 293.52batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6154/40960 [00:23<02:03, 282.95batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6154/40960 [00:23<02:03, 282.95batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6208/40960 [00:23<02:05, 277.60batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6208/40960 [00:23<02:05, 277.60batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6270/40960 [00:23<02:01, 286.31batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6270/40960 [00:23<02:01, 286.31batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6334/40960 [00:24<01:56, 296.07batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6334/40960 [00:24<01:56, 296.07batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6396/40960 [00:24<01:55, 299.95batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6396/40960 [00:24<01:55, 299.95batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6459/40960 [00:24<01:53, 303.41batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6459/40960 [00:24<01:53, 303.41batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6519/40960 [00:24<01:54, 301.03batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6519/40960 [00:24<01:54, 301.03batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6575/40960 [00:24<01:56, 294.05batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6575/40960 [00:24<01:56, 294.05batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6628/40960 [00:25<02:00, 285.18batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6628/40960 [00:25<02:00, 285.18batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6684/40960 [00:25<02:01, 282.73batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6684/40960 [00:25<02:01, 282.73batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6739/40960 [00:25<02:02, 280.09batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6739/40960 [00:25<02:02, 280.09batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6798/40960 [00:25<02:00, 283.82batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6798/40960 [00:25<02:00, 283.82batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6859/40960 [00:25<01:58, 288.74batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6859/40960 [00:25<01:58, 288.74batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6916/40960 [00:26<01:58, 287.16batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6916/40960 [00:26<01:58, 287.16batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6976/40960 [00:26<01:57, 289.83batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6976/40960 [00:26<01:57, 289.83batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7035/40960 [00:26<01:56, 290.82batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7035/40960 [00:26<01:56, 290.82batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7096/40960 [00:26<01:55, 294.02batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7096/40960 [00:26<01:55, 294.02batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7147/40960 [00:26<02:00, 280.25batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7147/40960 [00:26<02:00, 280.25batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7202/40960 [00:27<02:01, 278.19batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7202/40960 [00:27<02:01, 278.19batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7253/40960 [00:27<02:04, 269.82batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7253/40960 [00:27<02:04, 269.82batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7307/40960 [00:27<02:05, 269.00batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7307/40960 [00:27<02:05, 269.00batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7361/40960 [00:27<02:04, 269.17batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7361/40960 [00:27<02:04, 269.17batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7415/40960 [00:27<02:04, 268.63batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7415/40960 [00:27<02:04, 268.63batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7479/40960 [00:28<01:58, 283.02batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7479/40960 [00:28<01:58, 283.02batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7535/40960 [00:28<01:59, 280.78batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7535/40960 [00:28<01:59, 280.78batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7592/40960 [00:28<01:58, 280.64batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7592/40960 [00:28<01:58, 280.64batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7650/40960 [00:28<01:57, 282.44batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7650/40960 [00:28<01:57, 282.44batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7711/40960 [00:28<01:55, 288.35batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7711/40960 [00:28<01:55, 288.35batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7772/40960 [00:29<01:53, 293.21batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7772/40960 [00:29<01:53, 293.21batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7832/40960 [00:29<01:52, 294.48batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7832/40960 [00:29<01:52, 294.48batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7889/40960 [00:29<01:53, 291.26batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7889/40960 [00:29<01:53, 291.26batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7947/40960 [00:29<01:53, 290.85batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7947/40960 [00:29<01:53, 290.85batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8007/40960 [00:29<01:52, 293.16batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8007/40960 [00:29<01:52, 293.16batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8067/40960 [00:30<01:51, 294.54batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8067/40960 [00:30<01:51, 294.54batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8122/40960 [00:30<01:53, 288.66batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8122/40960 [00:30<01:53, 288.66batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8182/40960 [00:30<01:52, 291.95batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8182/40960 [00:30<01:52, 291.95batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8230/40960 [00:30<01:59, 274.94batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8230/40960 [00:30<01:59, 274.94batches/s, l2_loss: 0.0615 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8281/40960 [00:30<02:01, 267.98batches/s, l2_loss: 0.0615 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8281/40960 [00:30<02:01, 267.98batches/s, l2_loss: 0.0559 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8338/40960 [00:31<02:00, 271.52batches/s, l2_loss: 0.0559 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8338/40960 [00:31<02:00, 271.52batches/s, l2_loss: 0.0669 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8392/40960 [00:31<02:00, 269.81batches/s, l2_loss: 0.0669 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 8392/40960 [00:31<02:00, 269.81batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8450/40960 [00:31<01:58, 274.61batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8450/40960 [00:31<01:58, 274.61batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8505/40960 [00:31<01:58, 274.32batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8505/40960 [00:31<01:58, 274.32batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8555/40960 [00:31<02:01, 266.20batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8555/40960 [00:31<02:01, 266.20batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8604/40960 [00:32<02:04, 259.14batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8604/40960 [00:32<02:04, 259.14batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8658/40960 [00:32<02:03, 262.06batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8658/40960 [00:32<02:03, 262.06batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8713/40960 [00:32<02:01, 264.68batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8713/40960 [00:32<02:01, 264.68batches/s, l2_loss: 0.0710 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8770/40960 [00:32<01:59, 269.92batches/s, l2_loss: 0.0710 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8770/40960 [00:32<01:59, 269.92batches/s, l2_loss: 0.0702 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8826/40960 [00:32<01:58, 272.18batches/s, l2_loss: 0.0702 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8826/40960 [00:32<01:58, 272.18batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8874/40960 [00:33<02:02, 261.80batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8874/40960 [00:33<02:02, 261.80batches/s, l2_loss: 0.0698 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8927/40960 [00:33<02:02, 261.95batches/s, l2_loss: 0.0698 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8927/40960 [00:33<02:02, 261.95batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8978/40960 [00:33<02:03, 259.41batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8978/40960 [00:33<02:03, 259.41batches/s, l2_loss: 0.0704 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9025/40960 [00:33<02:06, 252.09batches/s, l2_loss: 0.0704 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9025/40960 [00:33<02:06, 252.09batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9075/40960 [00:33<02:07, 250.24batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9075/40960 [00:33<02:07, 250.24batches/s, l2_loss: 0.0708 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9128/40960 [00:34<02:05, 253.65batches/s, l2_loss: 0.0708 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9128/40960 [00:34<02:05, 253.65batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9186/40960 [00:34<02:00, 263.45batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9186/40960 [00:34<02:00, 263.45batches/s, l2_loss: 0.0705 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9242/40960 [00:34<01:58, 267.91batches/s, l2_loss: 0.0705 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9242/40960 [00:34<01:58, 267.91batches/s, l2_loss: 0.0707 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9297/40960 [00:34<01:57, 268.92batches/s, l2_loss: 0.0707 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9297/40960 [00:34<01:57, 268.92batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9354/40960 [00:34<01:55, 273.05batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9354/40960 [00:34<01:55, 273.05batches/s, l2_loss: 0.0711 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9413/40960 [00:35<01:52, 279.22batches/s, l2_loss: 0.0711 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9413/40960 [00:35<01:52, 279.22batches/s, l2_loss: 0.0708 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9463/40960 [00:35<01:56, 269.47batches/s, l2_loss: 0.0708 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9463/40960 [00:35<01:56, 269.47batches/s, l2_loss: 0.0711 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9516/40960 [00:35<01:57, 267.63batches/s, l2_loss: 0.0711 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9516/40960 [00:35<01:57, 267.63batches/s, l2_loss: 0.0710 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9568/40960 [00:35<01:58, 264.94batches/s, l2_loss: 0.0710 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9568/40960 [00:35<01:58, 264.94batches/s, l2_loss: 0.0704 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9620/40960 [00:35<01:59, 263.15batches/s, l2_loss: 0.0704 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9620/40960 [00:35<01:59, 263.15batches/s, l2_loss: 0.0706 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9674/40960 [00:36<01:58, 264.83batches/s, l2_loss: 0.0706 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9674/40960 [00:36<01:58, 264.83batches/s, l2_loss: 0.0706 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9726/40960 [00:36<01:59, 261.95batches/s, l2_loss: 0.0706 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9726/40960 [00:36<01:59, 261.95batches/s, l2_loss: 0.0700 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9782/40960 [00:36<01:57, 265.99batches/s, l2_loss: 0.0700 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9782/40960 [00:36<01:57, 265.99batches/s, l2_loss: 0.0704 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9836/40960 [00:36<01:56, 266.80batches/s, l2_loss: 0.0704 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9836/40960 [00:36<01:56, 266.80batches/s, l2_loss: 0.0711 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9894/40960 [00:36<01:53, 273.31batches/s, l2_loss: 0.0711 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9894/40960 [00:36<01:53, 273.31batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9950/40960 [00:37<01:53, 274.26batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9950/40960 [00:37<01:53, 274.26batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10007/40960 [00:37<01:51, 277.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  24%|▏| 10007/40960 [00:37<01:51, 277.31batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  25%|▏| 10063/40960 [00:37<01:51, 277.25batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  25%|▏| 10063/40960 [00:37<01:51, 277.25batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  25%|▏| 10120/40960 [00:37<01:50, 279.18batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  25%|▏| 10120/40960 [00:37<01:50, 279.18batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  25%|▏| 10177/40960 [00:37<01:49, 279.96batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  25%|▏| 10177/40960 [00:37<01:49, 279.96batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  25%|▏| 10229/40960 [00:38<01:52, 272.46batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  25%|▏| 10229/40960 [00:38<01:52, 272.46batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  25%|▎| 10279/40960 [00:38<01:55, 265.49batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  25%|▎| 10279/40960 [00:38<01:55, 265.49batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  25%|▎| 10334/40960 [00:38<01:54, 268.26batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  25%|▎| 10334/40960 [00:38<01:54, 268.26batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  25%|▎| 10389/40960 [00:38<01:53, 270.03batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  25%|▎| 10389/40960 [00:38<01:53, 270.03batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  26%|▎| 10447/40960 [00:38<01:50, 275.96batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  26%|▎| 10447/40960 [00:38<01:50, 275.96batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  26%|▎| 10502/40960 [00:39<01:50, 275.62batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  26%|▎| 10502/40960 [00:39<01:50, 275.62batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  26%|▎| 10558/40960 [00:39<01:50, 275.40batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  26%|▎| 10558/40960 [00:39<01:50, 275.40batches/s, l2_loss: 0.0702 - round_los\u001b[A\n",
      "Training:  26%|▎| 10616/40960 [00:39<01:49, 278.35batches/s, l2_loss: 0.0702 - round_los\u001b[A\n",
      "Training:  26%|▎| 10616/40960 [00:39<01:49, 278.35batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  26%|▎| 10669/40960 [00:39<01:50, 273.88batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  26%|▎| 10669/40960 [00:39<01:50, 273.88batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  26%|▎| 10730/40960 [00:39<01:47, 282.10batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  26%|▎| 10730/40960 [00:39<01:47, 282.10batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  26%|▎| 10789/40960 [00:40<01:45, 285.71batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  26%|▎| 10789/40960 [00:40<01:45, 285.71batches/s, l2_loss: 0.0713 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10844/40960 [00:40<01:46, 282.36batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  26%|▎| 10844/40960 [00:40<01:46, 282.36batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  27%|▎| 10898/40960 [00:40<01:48, 277.78batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  27%|▎| 10898/40960 [00:40<01:48, 277.78batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  27%|▎| 10952/40960 [00:40<01:49, 274.91batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  27%|▎| 10952/40960 [00:40<01:49, 274.91batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  27%|▎| 11006/40960 [00:40<01:49, 272.77batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  27%|▎| 11006/40960 [00:40<01:49, 272.77batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  27%|▎| 11062/40960 [00:41<01:48, 274.93batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  27%|▎| 11062/40960 [00:41<01:48, 274.93batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  27%|▎| 11113/40960 [00:41<01:51, 268.86batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  27%|▎| 11113/40960 [00:41<01:51, 268.86batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  27%|▎| 11167/40960 [00:41<01:51, 268.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  27%|▎| 11167/40960 [00:41<01:51, 268.35batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  27%|▎| 11223/40960 [00:41<01:49, 271.20batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  27%|▎| 11223/40960 [00:41<01:49, 271.20batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  28%|▎| 11277/40960 [00:41<01:49, 270.17batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  28%|▎| 11277/40960 [00:41<01:49, 270.17batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  28%|▎| 11328/40960 [00:42<01:51, 264.85batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  28%|▎| 11328/40960 [00:42<01:51, 264.85batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  28%|▎| 11386/40960 [00:42<01:48, 271.58batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  28%|▎| 11386/40960 [00:42<01:48, 271.58batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  28%|▎| 11445/40960 [00:42<01:46, 278.02batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  28%|▎| 11445/40960 [00:42<01:46, 278.02batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  28%|▎| 11498/40960 [00:42<01:47, 273.06batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  28%|▎| 11498/40960 [00:42<01:47, 273.06batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  28%|▎| 11549/40960 [00:42<01:49, 267.43batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  28%|▎| 11549/40960 [00:42<01:49, 267.43batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:43<01:49, 267.64batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:43<01:49, 267.64batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  28%|▎| 11662/40960 [00:43<01:46, 275.32batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  28%|▎| 11662/40960 [00:43<01:46, 275.32batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  29%|▎| 11719/40960 [00:43<01:45, 278.07batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  29%|▎| 11719/40960 [00:43<01:45, 278.07batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  29%|▎| 11777/40960 [00:43<01:44, 280.58batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  29%|▎| 11777/40960 [00:43<01:44, 280.58batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  29%|▎| 11836/40960 [00:43<01:42, 283.79batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  29%|▎| 11836/40960 [00:44<01:42, 283.79batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  29%|▎| 11897/40960 [00:44<01:40, 289.21batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  29%|▎| 11897/40960 [00:44<01:40, 289.21batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  29%|▎| 11954/40960 [00:44<01:41, 286.42batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  29%|▎| 11954/40960 [00:44<01:41, 286.42batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  29%|▎| 12007/40960 [00:44<01:43, 279.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  29%|▎| 12007/40960 [00:44<01:43, 279.65batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  29%|▎| 12065/40960 [00:44<01:42, 281.76batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  29%|▎| 12065/40960 [00:44<01:42, 281.76batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  30%|▎| 12122/40960 [00:45<01:42, 281.74batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  30%|▎| 12122/40960 [00:45<01:42, 281.74batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  30%|▎| 12177/40960 [00:45<01:43, 278.58batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  30%|▎| 12177/40960 [00:45<01:43, 278.58batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  30%|▎| 12230/40960 [00:45<01:44, 274.24batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  30%|▎| 12230/40960 [00:45<01:44, 274.24batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  30%|▎| 12285/40960 [00:45<01:44, 274.34batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  30%|▎| 12285/40960 [00:45<01:44, 274.34batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  30%|▎| 12339/40960 [00:45<01:45, 272.23batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  30%|▎| 12339/40960 [00:45<01:45, 272.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  30%|▎| 12397/40960 [00:46<01:43, 276.95batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  30%|▎| 12397/40960 [00:46<01:43, 276.95batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  30%|▎| 12454/40960 [00:46<01:42, 278.61batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  30%|▎| 12454/40960 [00:46<01:42, 278.61batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  31%|▎| 12505/40960 [00:46<01:44, 271.31batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  31%|▎| 12505/40960 [00:46<01:44, 271.31batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  31%|▎| 12556/40960 [00:46<01:46, 265.54batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  31%|▎| 12556/40960 [00:46<01:46, 265.54batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  31%|▎| 12612/40960 [00:46<01:45, 268.31batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  31%|▎| 12612/40960 [00:46<01:45, 268.31batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  31%|▎| 12672/40960 [00:47<01:42, 276.19batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  31%|▎| 12672/40960 [00:47<01:42, 276.19batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  31%|▎| 12725/40960 [00:47<01:43, 271.52batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  31%|▎| 12725/40960 [00:47<01:43, 271.52batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  31%|▎| 12772/40960 [00:47<01:48, 260.05batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  31%|▎| 12772/40960 [00:47<01:48, 260.05batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  31%|▎| 12829/40960 [00:47<01:45, 267.24batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  31%|▎| 12829/40960 [00:47<01:45, 267.24batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  31%|▎| 12878/40960 [00:47<01:47, 260.57batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  31%|▎| 12878/40960 [00:47<01:47, 260.57batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  32%|▎| 12933/40960 [00:48<01:46, 263.89batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  32%|▎| 12933/40960 [00:48<01:46, 263.89batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  32%|▎| 12983/40960 [00:48<01:47, 259.06batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  32%|▎| 12983/40960 [00:48<01:47, 259.06batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  32%|▎| 13035/40960 [00:48<01:47, 259.19batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  32%|▎| 13035/40960 [00:48<01:47, 259.19batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  32%|▎| 13090/40960 [00:48<01:45, 263.80batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  32%|▎| 13090/40960 [00:48<01:45, 263.80batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  32%|▎| 13145/40960 [00:48<01:44, 265.92batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  32%|▎| 13145/40960 [00:48<01:44, 265.92batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  32%|▎| 13203/40960 [00:49<01:42, 271.99batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  32%|▎| 13203/40960 [00:49<01:42, 271.99batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  32%|▎| 13262/40960 [00:49<01:39, 277.54batches/s, l2_loss: 0.0708 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 13262/40960 [00:49<01:39, 277.54batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  33%|▎| 13319/40960 [00:49<01:39, 279.16batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  33%|▎| 13319/40960 [00:49<01:39, 279.16batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  33%|▎| 13377/40960 [00:49<01:37, 281.85batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  33%|▎| 13377/40960 [00:49<01:37, 281.85batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  33%|▎| 13435/40960 [00:49<01:36, 284.02batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  33%|▎| 13435/40960 [00:49<01:36, 284.02batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  33%|▎| 13481/40960 [00:50<01:42, 267.37batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  33%|▎| 13481/40960 [00:50<01:42, 267.37batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  33%|▎| 13535/40960 [00:50<01:42, 267.68batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  33%|▎| 13535/40960 [00:50<01:42, 267.68batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  33%|▎| 13595/40960 [00:50<01:39, 276.30batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  33%|▎| 13595/40960 [00:50<01:39, 276.30batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  33%|▎| 13655/40960 [00:50<01:36, 282.92batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  33%|▎| 13655/40960 [00:50<01:36, 282.92batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  33%|▎| 13709/40960 [00:50<01:37, 278.85batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  33%|▎| 13709/40960 [00:50<01:37, 278.85batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  34%|▎| 13765/40960 [00:51<01:37, 278.31batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  34%|▎| 13765/40960 [00:51<01:37, 278.31batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  34%|▎| 13814/40960 [00:51<01:41, 266.87batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  34%|▎| 13814/40960 [00:51<01:41, 266.87batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  34%|▎| 13866/40960 [00:51<01:42, 264.49batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  34%|▎| 13866/40960 [00:51<01:42, 264.49batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  34%|▎| 13923/40960 [00:51<01:40, 269.94batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  34%|▎| 13923/40960 [00:51<01:40, 269.94batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  34%|▎| 13980/40960 [00:51<01:38, 273.81batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  34%|▎| 13980/40960 [00:51<01:38, 273.81batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  34%|▎| 14037/40960 [00:52<01:37, 276.73batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  34%|▎| 14037/40960 [00:52<01:37, 276.73batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  34%|▎| 14098/40960 [00:52<01:34, 284.67batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  34%|▎| 14098/40960 [00:52<01:34, 284.67batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  35%|▎| 14155/40960 [00:52<01:34, 283.96batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  35%|▎| 14155/40960 [00:52<01:34, 283.96batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  35%|▎| 14209/40960 [00:52<01:35, 279.28batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  35%|▎| 14209/40960 [00:52<01:35, 279.28batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  35%|▎| 14262/40960 [00:52<01:37, 274.28batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  35%|▎| 14262/40960 [00:52<01:37, 274.28batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  35%|▎| 14314/40960 [00:53<01:39, 268.73batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  35%|▎| 14314/40960 [00:53<01:39, 268.73batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  35%|▎| 14365/40960 [00:53<01:41, 263.20batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  35%|▎| 14365/40960 [00:53<01:41, 263.20batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  35%|▎| 14422/40960 [00:53<01:38, 269.18batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  35%|▎| 14422/40960 [00:53<01:38, 269.18batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  35%|▎| 14481/40960 [00:53<01:36, 275.76batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  35%|▎| 14481/40960 [00:53<01:36, 275.76batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  35%|▎| 14537/40960 [00:53<01:35, 276.05batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  35%|▎| 14537/40960 [00:53<01:35, 276.05batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  36%|▎| 14585/40960 [00:54<01:39, 264.47batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  36%|▎| 14585/40960 [00:54<01:39, 264.47batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  36%|▎| 14637/40960 [00:54<01:40, 261.95batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  36%|▎| 14637/40960 [00:54<01:40, 261.95batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  36%|▎| 14697/40960 [00:54<01:36, 273.27batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  36%|▎| 14697/40960 [00:54<01:36, 273.27batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  36%|▎| 14754/40960 [00:54<01:34, 276.58batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  36%|▎| 14754/40960 [00:54<01:34, 276.58batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  36%|▎| 14794/40960 [00:54<01:43, 253.44batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  36%|▎| 14794/40960 [00:54<01:43, 253.44batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  36%|▎| 14842/40960 [00:55<01:45, 247.85batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  36%|▎| 14842/40960 [00:55<01:45, 247.85batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:55<01:43, 252.55batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:55<01:43, 252.55batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  36%|▎| 14947/40960 [00:55<01:42, 254.48batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  36%|▎| 14947/40960 [00:55<01:42, 254.48batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  37%|▎| 15000/40960 [00:55<01:40, 257.29batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  37%|▎| 15000/40960 [00:55<01:40, 257.29batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  37%|▎| 15052/40960 [00:55<01:40, 257.89batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  37%|▎| 15052/40960 [00:55<01:40, 257.89batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  37%|▎| 15105/40960 [00:56<01:39, 258.66batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  37%|▎| 15105/40960 [00:56<01:39, 258.66batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  37%|▎| 15161/40960 [00:56<01:37, 264.65batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  37%|▎| 15161/40960 [00:56<01:37, 264.65batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  37%|▎| 15220/40960 [00:56<01:34, 273.12batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  37%|▎| 15220/40960 [00:56<01:34, 273.12batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  37%|▎| 15279/40960 [00:56<01:32, 278.40batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  37%|▎| 15279/40960 [00:56<01:32, 278.40batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  37%|▎| 15332/40960 [00:56<01:33, 273.70batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  37%|▎| 15332/40960 [00:56<01:33, 273.70batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  38%|▍| 15392/40960 [00:57<01:31, 280.60batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  38%|▍| 15392/40960 [00:57<01:31, 280.60batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  38%|▍| 15448/40960 [00:57<01:31, 280.10batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  38%|▍| 15448/40960 [00:57<01:31, 280.10batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  38%|▍| 15501/40960 [00:57<01:32, 274.60batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  38%|▍| 15501/40960 [00:57<01:32, 274.60batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  38%|▍| 15555/40960 [00:57<01:33, 272.95batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  38%|▍| 15555/40960 [00:57<01:33, 272.95batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  38%|▍| 15611/40960 [00:57<01:32, 273.56batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  38%|▍| 15611/40960 [00:57<01:32, 273.56batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  38%|▍| 15663/40960 [00:58<01:34, 268.64batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  38%|▍| 15663/40960 [00:58<01:34, 268.64batches/s, l2_loss: 0.0706 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|▍| 15711/40960 [00:58<01:37, 260.10batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  38%|▍| 15711/40960 [00:58<01:37, 260.10batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  38%|▍| 15766/40960 [00:58<01:35, 263.48batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  38%|▍| 15766/40960 [00:58<01:35, 263.48batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  39%|▍| 15819/40960 [00:58<01:35, 263.71batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  39%|▍| 15819/40960 [00:58<01:35, 263.71batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  39%|▍| 15874/40960 [00:58<01:34, 265.99batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  39%|▍| 15874/40960 [00:58<01:34, 265.99batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  39%|▍| 15932/40960 [00:59<01:32, 271.72batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  39%|▍| 15932/40960 [00:59<01:32, 271.72batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  39%|▍| 15988/40960 [00:59<01:31, 273.62batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  39%|▍| 15988/40960 [00:59<01:31, 273.62batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  39%|▍| 16046/40960 [00:59<01:29, 277.46batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  39%|▍| 16046/40960 [00:59<01:29, 277.46batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  39%|▍| 16099/40960 [00:59<01:31, 273.15batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  39%|▍| 16099/40960 [00:59<01:31, 273.15batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  39%|▍| 16155/40960 [00:59<01:30, 274.59batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  39%|▍| 16155/40960 [00:59<01:30, 274.59batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  40%|▍| 16206/40960 [01:00<01:32, 267.77batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  40%|▍| 16206/40960 [01:00<01:32, 267.77batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  40%|▍| 16262/40960 [01:00<01:31, 271.02batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  40%|▍| 16262/40960 [01:00<01:31, 271.02batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  40%|▍| 16321/40960 [01:00<01:28, 276.97batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  40%|▍| 16321/40960 [01:00<01:28, 276.97batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  40%|▍| 16379/40960 [01:00<01:27, 279.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  40%|▍| 16379/40960 [01:00<01:27, 279.88batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  40%|▍| 16433/40960 [01:00<01:28, 276.41batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  40%|▍| 16433/40960 [01:00<01:28, 276.41batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  40%|▍| 16485/40960 [01:01<01:30, 270.89batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  40%|▍| 16485/40960 [01:01<01:30, 270.89batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  40%|▍| 16541/40960 [01:01<01:29, 272.79batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  40%|▍| 16541/40960 [01:01<01:29, 272.79batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  41%|▍| 16597/40960 [01:01<01:28, 274.60batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  41%|▍| 16597/40960 [01:01<01:28, 274.60batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  41%|▍| 16658/40960 [01:01<01:25, 283.28batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  41%|▍| 16658/40960 [01:01<01:25, 283.28batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  41%|▍| 16718/40960 [01:01<01:24, 286.65batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  41%|▍| 16718/40960 [01:01<01:24, 286.65batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  41%|▍| 16773/40960 [01:02<01:25, 281.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  41%|▍| 16773/40960 [01:02<01:25, 281.88batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  41%|▍| 16825/40960 [01:02<01:27, 275.01batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  41%|▍| 16825/40960 [01:02<01:27, 275.01batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  41%|▍| 16879/40960 [01:02<01:28, 271.84batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  41%|▍| 16879/40960 [01:02<01:28, 271.84batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  41%|▍| 16938/40960 [01:02<01:26, 278.54batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  41%|▍| 16938/40960 [01:02<01:26, 278.54batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  41%|▍| 16996/40960 [01:02<01:25, 281.75batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  41%|▍| 16996/40960 [01:02<01:25, 281.75batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  42%|▍| 17052/40960 [01:03<01:25, 280.09batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  42%|▍| 17052/40960 [01:03<01:25, 280.09batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  42%|▍| 17107/40960 [01:03<01:25, 278.30batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  42%|▍| 17107/40960 [01:03<01:25, 278.30batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  42%|▍| 17163/40960 [01:03<01:25, 278.00batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  42%|▍| 17163/40960 [01:03<01:25, 278.00batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  42%|▍| 17223/40960 [01:03<01:23, 283.68batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  42%|▍| 17223/40960 [01:03<01:23, 283.68batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  42%|▍| 17280/40960 [01:03<01:23, 283.13batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  42%|▍| 17280/40960 [01:03<01:23, 283.13batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  42%|▍| 17335/40960 [01:04<01:24, 280.38batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  42%|▍| 17335/40960 [01:04<01:24, 280.38batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  42%|▍| 17392/40960 [01:04<01:23, 280.85batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  42%|▍| 17392/40960 [01:04<01:23, 280.85batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  43%|▍| 17443/40960 [01:04<01:26, 271.76batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  43%|▍| 17443/40960 [01:04<01:26, 271.76batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  43%|▍| 17496/40960 [01:04<01:27, 268.95batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  43%|▍| 17496/40960 [01:04<01:27, 268.95batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  43%|▍| 17555/40960 [01:04<01:24, 276.13batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  43%|▍| 17555/40960 [01:04<01:24, 276.13batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  43%|▍| 17614/40960 [01:05<01:22, 281.60batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  43%|▍| 17614/40960 [01:05<01:22, 281.60batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  43%|▍| 17675/40960 [01:05<01:21, 287.41batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  43%|▍| 17675/40960 [01:05<01:21, 287.41batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  43%|▍| 17727/40960 [01:05<01:23, 279.08batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  43%|▍| 17727/40960 [01:05<01:23, 279.08batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  43%|▍| 17777/40960 [01:05<01:25, 269.75batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  43%|▍| 17777/40960 [01:05<01:25, 269.75batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 17824/40960 [01:05<01:29, 258.40batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 17824/40960 [01:06<01:29, 258.40batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 17878/40960 [01:06<01:28, 260.51batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 17878/40960 [01:06<01:28, 260.51batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  44%|▍| 17930/40960 [01:06<01:28, 259.13batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  44%|▍| 17930/40960 [01:06<01:28, 259.13batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 17977/40960 [01:06<01:31, 251.62batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 17977/40960 [01:06<01:31, 251.62batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  44%|▍| 18035/40960 [01:06<01:27, 263.02batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  44%|▍| 18035/40960 [01:06<01:27, 263.02batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 18093/40960 [01:07<01:24, 270.76batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 18093/40960 [01:07<01:24, 270.76batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  44%|▍| 18152/40960 [01:07<01:22, 277.93batches/s, l2_loss: 0.0706 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 18152/40960 [01:07<01:22, 277.93batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  44%|▍| 18209/40960 [01:07<01:21, 279.12batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  44%|▍| 18209/40960 [01:07<01:21, 279.12batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18266/40960 [01:07<01:21, 280.03batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18266/40960 [01:07<01:21, 280.03batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18317/40960 [01:07<01:23, 271.48batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18317/40960 [01:07<01:23, 271.48batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18371/40960 [01:08<01:23, 269.70batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18371/40960 [01:08<01:23, 269.70batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  45%|▍| 18426/40960 [01:08<01:23, 270.58batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  45%|▍| 18426/40960 [01:08<01:23, 270.58batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18479/40960 [01:08<01:23, 268.10batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18479/40960 [01:08<01:23, 268.10batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18528/40960 [01:08<01:25, 261.08batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18528/40960 [01:08<01:25, 261.08batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18579/40960 [01:08<01:26, 258.34batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  45%|▍| 18579/40960 [01:08<01:26, 258.34batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  45%|▍| 18635/40960 [01:09<01:24, 264.01batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  45%|▍| 18635/40960 [01:09<01:24, 264.01batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  46%|▍| 18694/40960 [01:09<01:21, 272.62batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  46%|▍| 18694/40960 [01:09<01:21, 272.62batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  46%|▍| 18745/40960 [01:09<01:23, 265.64batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  46%|▍| 18745/40960 [01:09<01:23, 265.64batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  46%|▍| 18799/40960 [01:09<01:23, 266.58batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  46%|▍| 18799/40960 [01:09<01:23, 266.58batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  46%|▍| 18845/40960 [01:09<01:26, 255.45batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  46%|▍| 18845/40960 [01:09<01:26, 255.45batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  46%|▍| 18896/40960 [01:10<01:26, 254.73batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  46%|▍| 18896/40960 [01:10<01:26, 254.73batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  46%|▍| 18949/40960 [01:10<01:25, 257.12batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  46%|▍| 18949/40960 [01:10<01:25, 257.12batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  46%|▍| 19007/40960 [01:10<01:22, 265.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  46%|▍| 19007/40960 [01:10<01:22, 265.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19061/40960 [01:10<01:22, 265.88batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19061/40960 [01:10<01:22, 265.88batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19116/40960 [01:10<01:21, 267.58batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19116/40960 [01:10<01:21, 267.58batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19174/40960 [01:11<01:19, 273.38batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19174/40960 [01:11<01:19, 273.38batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19233/40960 [01:11<01:17, 279.25batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19233/40960 [01:11<01:17, 279.25batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  47%|▍| 19290/40960 [01:11<01:17, 280.59batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  47%|▍| 19290/40960 [01:11<01:17, 280.59batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19346/40960 [01:11<01:17, 279.96batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19346/40960 [01:11<01:17, 279.96batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19404/40960 [01:11<01:16, 282.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  47%|▍| 19404/40960 [01:11<01:16, 282.23batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  48%|▍| 19457/40960 [01:12<01:17, 277.01batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  48%|▍| 19457/40960 [01:12<01:17, 277.01batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  48%|▍| 19511/40960 [01:12<01:18, 274.31batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  48%|▍| 19511/40960 [01:12<01:18, 274.31batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  48%|▍| 19570/40960 [01:12<01:16, 279.15batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  48%|▍| 19570/40960 [01:12<01:16, 279.15batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  48%|▍| 19627/40960 [01:12<01:16, 280.15batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  48%|▍| 19627/40960 [01:12<01:16, 280.15batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  48%|▍| 19681/40960 [01:12<01:17, 275.90batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  48%|▍| 19681/40960 [01:12<01:17, 275.90batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  48%|▍| 19734/40960 [01:13<01:18, 271.53batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  48%|▍| 19734/40960 [01:13<01:18, 271.53batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  48%|▍| 19789/40960 [01:13<01:17, 271.47batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  48%|▍| 19789/40960 [01:13<01:17, 271.47batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  48%|▍| 19842/40960 [01:13<01:18, 268.50batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  48%|▍| 19842/40960 [01:13<01:18, 268.50batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  49%|▍| 19899/40960 [01:13<01:17, 272.57batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  49%|▍| 19899/40960 [01:13<01:17, 272.57batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  49%|▍| 19957/40960 [01:13<01:15, 276.74batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  49%|▍| 19957/40960 [01:13<01:15, 276.74batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  49%|▍| 20012/40960 [01:14<01:16, 275.58batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  49%|▍| 20012/40960 [01:14<01:16, 275.58batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  49%|▍| 20065/40960 [01:14<01:16, 272.32batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  49%|▍| 20065/40960 [01:14<01:16, 272.32batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  49%|▍| 20121/40960 [01:14<01:15, 274.53batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  49%|▍| 20121/40960 [01:14<01:15, 274.53batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  49%|▍| 20176/40960 [01:14<01:16, 273.28batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  49%|▍| 20176/40960 [01:14<01:16, 273.28batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  49%|▍| 20231/40960 [01:14<01:16, 272.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  49%|▍| 20231/40960 [01:14<01:16, 272.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▍| 20284/40960 [01:15<01:16, 270.26batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▍| 20284/40960 [01:15<01:16, 270.26batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▍| 20342/40960 [01:15<01:14, 275.46batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▍| 20342/40960 [01:15<01:14, 275.46batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  50%|▍| 20397/40960 [01:15<01:14, 274.64batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  50%|▍| 20397/40960 [01:15<01:14, 274.64batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▍| 20457/40960 [01:15<01:12, 281.54batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▍| 20457/40960 [01:15<01:12, 281.54batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▌| 20511/40960 [01:15<01:13, 277.39batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▌| 20511/40960 [01:15<01:13, 277.39batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  50%|▌| 20569/40960 [01:16<01:12, 279.71batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  50%|▌| 20569/40960 [01:16<01:12, 279.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 20628/40960 [01:16<01:11, 284.10batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  50%|▌| 20628/40960 [01:16<01:11, 284.10batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  51%|▌| 20685/40960 [01:16<01:11, 283.14batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  51%|▌| 20685/40960 [01:16<01:11, 283.14batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20744/40960 [01:16<01:10, 286.03batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20744/40960 [01:16<01:10, 286.03batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20799/40960 [01:16<01:11, 281.57batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20799/40960 [01:16<01:11, 281.57batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20855/40960 [01:17<01:11, 280.18batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20855/40960 [01:17<01:11, 280.18batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20915/40960 [01:17<01:10, 285.47batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20915/40960 [01:17<01:10, 285.47batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20966/40960 [01:17<01:12, 276.08batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 20966/40960 [01:17<01:12, 276.08batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  51%|▌| 21023/40960 [01:17<01:11, 277.23batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  51%|▌| 21023/40960 [01:17<01:11, 277.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 21078/40960 [01:17<01:11, 276.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  51%|▌| 21078/40960 [01:17<01:11, 276.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21136/40960 [01:18<01:10, 280.17batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21136/40960 [01:18<01:10, 280.17batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  52%|▌| 21193/40960 [01:18<01:10, 281.43batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  52%|▌| 21193/40960 [01:18<01:10, 281.43batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21252/40960 [01:18<01:09, 284.76batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21252/40960 [01:18<01:09, 284.76batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21311/40960 [01:18<01:08, 287.65batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21311/40960 [01:18<01:08, 287.65batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21365/40960 [01:18<01:09, 281.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21365/40960 [01:18<01:09, 281.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21422/40960 [01:19<01:09, 281.76batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  52%|▌| 21422/40960 [01:19<01:09, 281.76batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  52%|▌| 21477/40960 [01:19<01:09, 279.15batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  52%|▌| 21477/40960 [01:19<01:09, 279.15batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  53%|▌| 21533/40960 [01:19<01:09, 278.54batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  53%|▌| 21533/40960 [01:19<01:09, 278.54batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  53%|▌| 21589/40960 [01:19<01:09, 277.73batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  53%|▌| 21589/40960 [01:19<01:09, 277.73batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  53%|▌| 21647/40960 [01:19<01:08, 280.29batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  53%|▌| 21647/40960 [01:19<01:08, 280.29batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  53%|▌| 21703/40960 [01:20<01:08, 279.74batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  53%|▌| 21703/40960 [01:20<01:08, 279.74batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  53%|▌| 21761/40960 [01:20<01:07, 282.58batches/s, l2_loss: 0.0707 - round_los\u001b[A\n",
      "Training:  53%|▌| 21761/40960 [01:20<01:07, 282.58batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  53%|▌| 21809/40960 [01:20<01:11, 269.34batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  53%|▌| 21809/40960 [01:20<01:11, 269.34batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  53%|▌| 21865/40960 [01:20<01:10, 270.99batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  53%|▌| 21865/40960 [01:20<01:10, 270.99batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 21919/40960 [01:20<01:10, 270.26batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 21919/40960 [01:20<01:10, 270.26batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  54%|▌| 21975/40960 [01:21<01:09, 272.78batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  54%|▌| 21975/40960 [01:21<01:09, 272.78batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  54%|▌| 22033/40960 [01:21<01:08, 277.34batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  54%|▌| 22033/40960 [01:21<01:08, 277.34batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 22087/40960 [01:21<01:08, 273.96batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 22087/40960 [01:21<01:08, 273.96batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 22141/40960 [01:21<01:09, 272.30batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 22141/40960 [01:21<01:09, 272.30batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 22197/40960 [01:21<01:08, 273.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 22197/40960 [01:21<01:08, 273.71batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  54%|▌| 22255/40960 [01:22<01:07, 278.06batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  54%|▌| 22255/40960 [01:22<01:07, 278.06batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 22314/40960 [01:22<01:06, 282.42batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  54%|▌| 22314/40960 [01:22<01:06, 282.42batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  55%|▌| 22373/40960 [01:22<01:04, 285.97batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  55%|▌| 22373/40960 [01:22<01:04, 285.97batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  55%|▌| 22432/40960 [01:22<01:04, 287.32batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  55%|▌| 22432/40960 [01:22<01:04, 287.32batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  55%|▌| 22484/40960 [01:22<01:06, 278.23batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  55%|▌| 22484/40960 [01:22<01:06, 278.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  55%|▌| 22534/40960 [01:23<01:08, 269.07batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  55%|▌| 22534/40960 [01:23<01:08, 269.07batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  55%|▌| 22590/40960 [01:23<01:07, 271.75batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  55%|▌| 22590/40960 [01:23<01:07, 271.75batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  55%|▌| 22648/40960 [01:23<01:06, 276.85batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  55%|▌| 22648/40960 [01:23<01:06, 276.85batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  55%|▌| 22707/40960 [01:23<01:04, 282.25batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  55%|▌| 22707/40960 [01:23<01:04, 282.25batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  56%|▌| 22765/40960 [01:23<01:03, 284.43batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  56%|▌| 22765/40960 [01:23<01:03, 284.43batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  56%|▌| 22822/40960 [01:24<01:03, 283.98batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  56%|▌| 22822/40960 [01:24<01:03, 283.98batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  56%|▌| 22876/40960 [01:24<01:04, 278.35batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  56%|▌| 22876/40960 [01:24<01:04, 278.35batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  56%|▌| 22931/40960 [01:24<01:05, 277.23batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  56%|▌| 22931/40960 [01:24<01:05, 277.23batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  56%|▌| 22980/40960 [01:24<01:07, 266.70batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  56%|▌| 22980/40960 [01:24<01:07, 266.70batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  56%|▌| 23035/40960 [01:24<01:06, 268.06batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  56%|▌| 23035/40960 [01:24<01:06, 268.06batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  56%|▌| 23090/40960 [01:25<01:06, 269.60batches/s, l2_loss: 0.0706 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|▌| 23090/40960 [01:25<01:06, 269.60batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23145/40960 [01:25<01:05, 270.84batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23145/40960 [01:25<01:05, 270.84batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  57%|▌| 23203/40960 [01:25<01:04, 275.17batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  57%|▌| 23203/40960 [01:25<01:04, 275.17batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23256/40960 [01:25<01:05, 271.84batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23256/40960 [01:25<01:05, 271.84batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23308/40960 [01:25<01:06, 267.41batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23308/40960 [01:25<01:06, 267.41batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23363/40960 [01:26<01:05, 269.44batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23363/40960 [01:26<01:05, 269.44batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23420/40960 [01:26<01:04, 272.60batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23420/40960 [01:26<01:04, 272.60batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23476/40960 [01:26<01:03, 273.53batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  57%|▌| 23476/40960 [01:26<01:03, 273.53batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  57%|▌| 23527/40960 [01:26<01:05, 267.36batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  57%|▌| 23527/40960 [01:26<01:05, 267.36batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23580/40960 [01:26<01:05, 265.56batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23580/40960 [01:26<01:05, 265.56batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23638/40960 [01:27<01:03, 272.32batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23638/40960 [01:27<01:03, 272.32batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23696/40960 [01:27<01:02, 276.48batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23696/40960 [01:27<01:02, 276.48batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23746/40960 [01:27<01:04, 268.39batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23746/40960 [01:27<01:04, 268.39batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23794/40960 [01:27<01:06, 259.40batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23794/40960 [01:27<01:06, 259.40batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23847/40960 [01:27<01:05, 260.84batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23847/40960 [01:27<01:05, 260.84batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23903/40960 [01:28<01:04, 266.16batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23903/40960 [01:28<01:04, 266.16batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23960/40960 [01:28<01:02, 270.69batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  58%|▌| 23960/40960 [01:28<01:02, 270.69batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24016/40960 [01:28<01:02, 273.05batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24016/40960 [01:28<01:02, 273.05batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  59%|▌| 24076/40960 [01:28<01:00, 280.00batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  59%|▌| 24076/40960 [01:28<01:00, 280.00batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24135/40960 [01:29<00:59, 283.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24135/40960 [01:29<00:59, 283.88batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  59%|▌| 24194/40960 [01:29<00:58, 286.38batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  59%|▌| 24194/40960 [01:29<00:58, 286.38batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24254/40960 [01:29<00:57, 289.03batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24254/40960 [01:29<00:57, 289.03batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24309/40960 [01:29<00:58, 284.40batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24309/40960 [01:29<00:58, 284.40batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24366/40960 [01:29<00:58, 283.91batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  59%|▌| 24366/40960 [01:29<00:58, 283.91batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  60%|▌| 24426/40960 [01:30<00:57, 287.61batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  60%|▌| 24426/40960 [01:30<00:57, 287.61batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  60%|▌| 24482/40960 [01:30<00:57, 284.29batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  60%|▌| 24482/40960 [01:30<00:57, 284.29batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  60%|▌| 24534/40960 [01:30<00:59, 276.05batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  60%|▌| 24534/40960 [01:30<00:59, 276.05batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  60%|▌| 24590/40960 [01:30<00:59, 276.71batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  60%|▌| 24590/40960 [01:30<00:59, 276.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  60%|▌| 24646/40960 [01:30<00:58, 276.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  60%|▌| 24646/40960 [01:30<00:58, 276.71batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  60%|▌| 24706/40960 [01:31<00:57, 282.33batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  60%|▌| 24706/40960 [01:31<00:57, 282.33batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  60%|▌| 24763/40960 [01:31<00:57, 282.92batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  60%|▌| 24763/40960 [01:31<00:57, 282.92batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 24818/40960 [01:31<00:57, 279.31batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 24818/40960 [01:31<00:57, 279.31batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 24873/40960 [01:31<00:57, 277.44batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 24873/40960 [01:31<00:57, 277.44batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 24925/40960 [01:31<00:58, 272.08batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 24925/40960 [01:31<00:58, 272.08batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 24975/40960 [01:32<01:00, 265.06batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 24975/40960 [01:32<01:00, 265.06batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 25029/40960 [01:32<00:59, 266.42batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 25029/40960 [01:32<00:59, 266.42batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 25083/40960 [01:32<00:59, 267.10batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 25083/40960 [01:32<00:59, 267.10batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 25140/40960 [01:32<00:58, 271.18batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  61%|▌| 25140/40960 [01:32<00:58, 271.18batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25198/40960 [01:32<00:57, 276.12batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25198/40960 [01:32<00:57, 276.12batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25254/40960 [01:33<00:56, 275.90batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25254/40960 [01:33<00:56, 275.90batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  62%|▌| 25309/40960 [01:33<00:56, 275.19batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  62%|▌| 25309/40960 [01:33<00:56, 275.19batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25363/40960 [01:33<00:57, 272.77batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25363/40960 [01:33<00:57, 272.77batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25419/40960 [01:33<00:56, 274.83batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25419/40960 [01:33<00:56, 274.83batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25478/40960 [01:33<00:55, 280.83batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25478/40960 [01:33<00:55, 280.83batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25528/40960 [01:34<00:56, 271.32batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25528/40960 [01:34<00:56, 271.32batches/s, l2_loss: 0.0705 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|▌| 25580/40960 [01:34<00:57, 266.79batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  62%|▌| 25580/40960 [01:34<00:57, 266.79batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25641/40960 [01:34<00:55, 277.77batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25641/40960 [01:34<00:55, 277.77batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25700/40960 [01:34<00:53, 282.67batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25700/40960 [01:34<00:53, 282.67batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  63%|▋| 25753/40960 [01:34<00:55, 275.84batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  63%|▋| 25753/40960 [01:34<00:55, 275.84batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25812/40960 [01:35<00:53, 280.99batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25812/40960 [01:35<00:53, 280.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  63%|▋| 25871/40960 [01:35<00:53, 284.14batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  63%|▋| 25871/40960 [01:35<00:53, 284.14batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25924/40960 [01:35<00:54, 277.58batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25924/40960 [01:35<00:54, 277.58batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25976/40960 [01:35<00:55, 271.55batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  63%|▋| 25976/40960 [01:35<00:55, 271.55batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26033/40960 [01:35<00:54, 274.66batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26033/40960 [01:35<00:54, 274.66batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  64%|▋| 26088/40960 [01:36<00:54, 274.48batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  64%|▋| 26088/40960 [01:36<00:54, 274.48batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  64%|▋| 26141/40960 [01:36<00:54, 270.74batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  64%|▋| 26141/40960 [01:36<00:54, 270.74batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26196/40960 [01:36<00:54, 271.02batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26196/40960 [01:36<00:54, 271.02batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26250/40960 [01:36<00:54, 270.62batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26250/40960 [01:36<00:54, 270.62batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26306/40960 [01:36<00:53, 272.57batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26306/40960 [01:36<00:53, 272.57batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  64%|▋| 26365/40960 [01:37<00:52, 277.87batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  64%|▋| 26365/40960 [01:37<00:52, 277.87batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26419/40960 [01:37<00:52, 275.11batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  64%|▋| 26419/40960 [01:37<00:52, 275.11batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26478/40960 [01:37<00:51, 280.36batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26478/40960 [01:37<00:51, 280.36batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26536/40960 [01:37<00:51, 282.44batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26536/40960 [01:37<00:51, 282.44batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26589/40960 [01:37<00:51, 277.17batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26589/40960 [01:37<00:51, 277.17batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26647/40960 [01:38<00:51, 280.32batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26647/40960 [01:38<00:51, 280.32batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26705/40960 [01:38<00:50, 282.39batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26705/40960 [01:38<00:50, 282.39batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26764/40960 [01:38<00:49, 286.06batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  65%|▋| 26764/40960 [01:38<00:49, 286.06batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  65%|▋| 26817/40960 [01:38<00:50, 279.17batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  65%|▋| 26817/40960 [01:38<00:50, 279.17batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 26873/40960 [01:38<00:50, 279.23batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 26873/40960 [01:38<00:50, 279.23batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 26930/40960 [01:39<00:49, 280.70batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 26930/40960 [01:39<00:49, 280.70batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 26986/40960 [01:39<00:49, 280.37batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 26986/40960 [01:39<00:49, 280.37batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 27041/40960 [01:39<00:49, 278.66batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 27041/40960 [01:39<00:49, 278.66batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 27098/40960 [01:39<00:49, 279.49batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 27098/40960 [01:39<00:49, 279.49batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 27156/40960 [01:39<00:48, 281.97batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 27156/40960 [01:39<00:48, 281.97batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 27210/40960 [01:40<00:49, 278.28batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  66%|▋| 27210/40960 [01:40<00:49, 278.28batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27265/40960 [01:40<00:49, 276.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27265/40960 [01:40<00:49, 276.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27322/40960 [01:40<00:49, 278.28batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27322/40960 [01:40<00:49, 278.28batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27379/40960 [01:40<00:48, 279.65batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27379/40960 [01:40<00:48, 279.65batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27431/40960 [01:40<00:49, 272.38batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27431/40960 [01:40<00:49, 272.38batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27484/40960 [01:41<00:49, 269.95batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27484/40960 [01:41<00:49, 269.95batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27535/40960 [01:41<00:50, 264.55batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27535/40960 [01:41<00:50, 264.55batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27588/40960 [01:41<00:50, 264.25batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27588/40960 [01:41<00:50, 264.25batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27640/40960 [01:41<00:50, 261.41batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  67%|▋| 27640/40960 [01:41<00:50, 261.41batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  68%|▋| 27692/40960 [01:41<00:51, 259.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  68%|▋| 27692/40960 [01:41<00:51, 259.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  68%|▋| 27747/40960 [01:42<00:50, 264.00batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  68%|▋| 27747/40960 [01:42<00:50, 264.00batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  68%|▋| 27803/40960 [01:42<00:49, 267.71batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  68%|▋| 27803/40960 [01:42<00:49, 267.71batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  68%|▋| 27861/40960 [01:42<00:47, 274.31batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  68%|▋| 27861/40960 [01:42<00:47, 274.31batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  68%|▋| 27921/40960 [01:42<00:46, 280.87batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  68%|▋| 27921/40960 [01:42<00:46, 280.87batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  68%|▋| 27979/40960 [01:42<00:45, 283.41batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  68%|▋| 27979/40960 [01:42<00:45, 283.41batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  68%|▋| 28035/40960 [01:43<00:45, 282.03batches/s, l2_loss: 0.0704 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|▋| 28035/40960 [01:43<00:45, 282.03batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28090/40960 [01:43<00:45, 279.84batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28090/40960 [01:43<00:45, 279.84batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28145/40960 [01:43<00:46, 278.28batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28145/40960 [01:43<00:46, 278.28batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28204/40960 [01:43<00:45, 282.53batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28204/40960 [01:43<00:45, 282.53batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28257/40960 [01:43<00:45, 276.19batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28257/40960 [01:43<00:45, 276.19batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28315/40960 [01:44<00:45, 279.40batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  69%|▋| 28315/40960 [01:44<00:45, 279.40batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  69%|▋| 28372/40960 [01:44<00:44, 280.42batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  69%|▋| 28372/40960 [01:44<00:44, 280.42batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  69%|▋| 28430/40960 [01:44<00:44, 282.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  69%|▋| 28430/40960 [01:44<00:44, 282.06batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28488/40960 [01:44<00:43, 284.03batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28488/40960 [01:44<00:43, 284.03batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28546/40960 [01:44<00:43, 284.70batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28546/40960 [01:44<00:43, 284.70batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28597/40960 [01:45<00:45, 274.21batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28597/40960 [01:45<00:45, 274.21batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  70%|▋| 28650/40960 [01:45<00:45, 271.48batches/s, l2_loss: 0.0706 - round_los\u001b[A\n",
      "Training:  70%|▋| 28650/40960 [01:45<00:45, 271.48batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28702/40960 [01:45<00:45, 266.86batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28702/40960 [01:45<00:45, 266.86batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  70%|▋| 28750/40960 [01:45<00:47, 258.65batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  70%|▋| 28750/40960 [01:45<00:47, 258.65batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  70%|▋| 28800/40960 [01:45<00:47, 254.81batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  70%|▋| 28800/40960 [01:45<00:47, 254.81batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28858/40960 [01:46<00:45, 265.05batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  70%|▋| 28858/40960 [01:46<00:45, 265.05batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 28913/40960 [01:46<00:44, 267.96batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 28913/40960 [01:46<00:44, 267.96batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 28966/40960 [01:46<00:44, 266.96batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 28966/40960 [01:46<00:44, 266.96batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  71%|▋| 29024/40960 [01:46<00:43, 273.57batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  71%|▋| 29024/40960 [01:46<00:43, 273.57batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 29078/40960 [01:46<00:43, 271.08batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 29078/40960 [01:46<00:43, 271.08batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 29131/40960 [01:47<00:44, 268.58batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 29131/40960 [01:47<00:44, 268.58batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  71%|▋| 29182/40960 [01:47<00:44, 263.81batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  71%|▋| 29182/40960 [01:47<00:44, 263.81batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 29231/40960 [01:47<00:45, 257.95batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 29231/40960 [01:47<00:45, 257.95batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 29283/40960 [01:47<00:45, 257.14batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  71%|▋| 29283/40960 [01:47<00:45, 257.14batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29340/40960 [01:47<00:43, 265.18batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29340/40960 [01:47<00:43, 265.18batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29395/40960 [01:48<00:43, 267.43batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29395/40960 [01:48<00:43, 267.43batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  72%|▋| 29451/40960 [01:48<00:42, 269.65batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  72%|▋| 29451/40960 [01:48<00:42, 269.65batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29503/40960 [01:48<00:43, 265.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29503/40960 [01:48<00:43, 265.88batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29556/40960 [01:48<00:42, 265.59batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29556/40960 [01:48<00:42, 265.59batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  72%|▋| 29615/40960 [01:48<00:41, 273.02batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  72%|▋| 29615/40960 [01:48<00:41, 273.02batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29671/40960 [01:49<00:41, 275.07batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  72%|▋| 29671/40960 [01:49<00:41, 275.07batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  73%|▋| 29721/40960 [01:49<00:42, 266.15batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  73%|▋| 29721/40960 [01:49<00:42, 266.15batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 29777/40960 [01:49<00:41, 269.88batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 29777/40960 [01:49<00:41, 269.88batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 29836/40960 [01:49<00:40, 277.34batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 29836/40960 [01:49<00:40, 277.34batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 29895/40960 [01:49<00:39, 281.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 29895/40960 [01:49<00:39, 281.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 29955/40960 [01:50<00:38, 286.45batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 29955/40960 [01:50<00:38, 286.45batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 30013/40960 [01:50<00:38, 286.73batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 30013/40960 [01:50<00:38, 286.73batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 30069/40960 [01:50<00:38, 284.15batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  73%|▋| 30069/40960 [01:50<00:38, 284.15batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  74%|▋| 30126/40960 [01:50<00:38, 284.33batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  74%|▋| 30126/40960 [01:50<00:38, 284.33batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30184/40960 [01:50<00:37, 285.91batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30184/40960 [01:50<00:37, 285.91batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  74%|▋| 30237/40960 [01:51<00:38, 278.89batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  74%|▋| 30237/40960 [01:51<00:38, 278.89batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30295/40960 [01:51<00:37, 281.47batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30295/40960 [01:51<00:37, 281.47batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  74%|▋| 30349/40960 [01:51<00:38, 277.17batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  74%|▋| 30349/40960 [01:51<00:38, 277.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30401/40960 [01:51<00:38, 271.70batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30401/40960 [01:51<00:38, 271.70batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30456/40960 [01:51<00:38, 271.49batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30456/40960 [01:51<00:38, 271.49batches/s, l2_loss: 0.0704 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|▋| 30508/40960 [01:52<00:38, 268.00batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  74%|▋| 30508/40960 [01:52<00:38, 268.00batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▋| 30560/40960 [01:52<00:39, 265.27batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▋| 30560/40960 [01:52<00:39, 265.27batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▋| 30617/40960 [01:52<00:38, 269.81batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▋| 30617/40960 [01:52<00:38, 269.81batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  75%|▋| 30671/40960 [01:52<00:38, 268.79batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  75%|▋| 30671/40960 [01:52<00:38, 268.79batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▊| 30730/40960 [01:52<00:37, 276.48batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▊| 30730/40960 [01:53<00:37, 276.48batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▊| 30788/40960 [01:53<00:36, 279.02batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▊| 30788/40960 [01:53<00:36, 279.02batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▊| 30833/40960 [01:53<00:38, 262.18batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  75%|▊| 30833/40960 [01:53<00:38, 262.18batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  75%|▊| 30891/40960 [01:53<00:37, 269.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  75%|▊| 30891/40960 [01:53<00:37, 269.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 30943/40960 [01:53<00:37, 266.68batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 30943/40960 [01:53<00:37, 266.68batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 30997/40960 [01:54<00:37, 266.95batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 30997/40960 [01:54<00:37, 266.95batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  76%|▊| 31049/40960 [01:54<00:37, 264.03batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  76%|▊| 31049/40960 [01:54<00:37, 264.03batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  76%|▊| 31107/40960 [01:54<00:36, 270.91batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  76%|▊| 31107/40960 [01:54<00:36, 270.91batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 31156/40960 [01:54<00:37, 263.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 31156/40960 [01:54<00:37, 263.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 31204/40960 [01:54<00:38, 255.18batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 31204/40960 [01:54<00:38, 255.18batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 31262/40960 [01:55<00:36, 264.90batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 31262/40960 [01:55<00:36, 264.90batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 31320/40960 [01:55<00:35, 272.21batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  76%|▊| 31320/40960 [01:55<00:35, 272.21batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31372/40960 [01:55<00:35, 268.28batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31372/40960 [01:55<00:35, 268.28batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31428/40960 [01:55<00:35, 271.76batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31428/40960 [01:55<00:35, 271.76batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  77%|▊| 31483/40960 [01:55<00:34, 272.43batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  77%|▊| 31483/40960 [01:55<00:34, 272.43batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31538/40960 [01:56<00:34, 272.27batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31538/40960 [01:56<00:34, 272.27batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31593/40960 [01:56<00:34, 272.92batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31593/40960 [01:56<00:34, 272.92batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  77%|▊| 31647/40960 [01:56<00:34, 270.92batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  77%|▊| 31647/40960 [01:56<00:34, 270.92batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31706/40960 [01:56<00:33, 277.30batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  77%|▊| 31706/40960 [01:56<00:33, 277.30batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 31761/40960 [01:56<00:33, 275.16batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 31761/40960 [01:56<00:33, 275.16batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 31809/40960 [01:57<00:34, 263.35batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 31809/40960 [01:57<00:34, 263.35batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 31866/40960 [01:57<00:33, 269.11batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 31866/40960 [01:57<00:33, 269.11batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 31921/40960 [01:57<00:33, 270.58batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 31921/40960 [01:57<00:33, 270.58batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  78%|▊| 31978/40960 [01:57<00:32, 273.83batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  78%|▊| 31978/40960 [01:57<00:32, 273.83batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 32033/40960 [01:57<00:32, 273.77batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 32033/40960 [01:57<00:32, 273.77batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 32086/40960 [01:58<00:32, 270.35batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 32086/40960 [01:58<00:32, 270.35batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 32143/40960 [01:58<00:32, 273.60batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  78%|▊| 32143/40960 [01:58<00:32, 273.60batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32195/40960 [01:58<00:32, 268.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32195/40960 [01:58<00:32, 268.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32249/40960 [01:58<00:32, 267.91batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32249/40960 [01:58<00:32, 267.91batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32303/40960 [01:58<00:32, 267.70batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32303/40960 [01:58<00:32, 267.70batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32359/40960 [01:59<00:31, 270.10batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32359/40960 [01:59<00:31, 270.10batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32414/40960 [01:59<00:31, 270.60batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32414/40960 [01:59<00:31, 270.60batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  79%|▊| 32470/40960 [01:59<00:31, 273.14batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  79%|▊| 32470/40960 [01:59<00:31, 273.14batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32521/40960 [01:59<00:31, 266.73batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  79%|▊| 32521/40960 [01:59<00:31, 266.73batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32575/40960 [01:59<00:31, 267.26batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32575/40960 [01:59<00:31, 267.26batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32627/40960 [02:00<00:31, 264.14batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32627/40960 [02:00<00:31, 264.14batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32683/40960 [02:00<00:30, 267.94batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32683/40960 [02:00<00:30, 267.94batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  80%|▊| 32738/40960 [02:00<00:30, 269.74batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  80%|▊| 32738/40960 [02:00<00:30, 269.74batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  80%|▊| 32796/40960 [02:00<00:29, 275.40batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  80%|▊| 32796/40960 [02:00<00:29, 275.40batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32854/40960 [02:00<00:29, 278.62batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32854/40960 [02:00<00:29, 278.62batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32908/40960 [02:01<00:29, 275.67batches/s, l2_loss: 0.0704 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32908/40960 [02:01<00:29, 275.67batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32959/40960 [02:01<00:29, 269.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  80%|▊| 32959/40960 [02:01<00:29, 269.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33009/40960 [02:01<00:30, 263.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33009/40960 [02:01<00:30, 263.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33064/40960 [02:01<00:29, 265.82batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33064/40960 [02:01<00:29, 265.82batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33123/40960 [02:01<00:28, 273.95batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33123/40960 [02:01<00:28, 273.95batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33179/40960 [02:02<00:28, 275.59batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33179/40960 [02:02<00:28, 275.59batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33235/40960 [02:02<00:28, 275.46batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33235/40960 [02:02<00:28, 275.46batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  81%|▊| 33288/40960 [02:02<00:28, 272.28batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  81%|▊| 33288/40960 [02:02<00:28, 272.28batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33344/40960 [02:02<00:27, 273.52batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  81%|▊| 33344/40960 [02:02<00:27, 273.52batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  82%|▊| 33399/40960 [02:02<00:27, 273.24batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  82%|▊| 33399/40960 [02:02<00:27, 273.24batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33454/40960 [02:03<00:27, 271.25batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33454/40960 [02:03<00:27, 271.25batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33506/40960 [02:03<00:27, 267.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33506/40960 [02:03<00:27, 267.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33562/40960 [02:03<00:27, 270.87batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33562/40960 [02:03<00:27, 270.87batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  82%|▊| 33617/40960 [02:03<00:27, 271.57batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  82%|▊| 33617/40960 [02:03<00:27, 271.57batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33675/40960 [02:03<00:26, 275.71batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33675/40960 [02:03<00:26, 275.71batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33729/40960 [02:04<00:26, 273.20batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33729/40960 [02:04<00:26, 273.20batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33780/40960 [02:04<00:26, 267.37batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  82%|▊| 33780/40960 [02:04<00:26, 267.37batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 33831/40960 [02:04<00:27, 262.24batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 33831/40960 [02:04<00:27, 262.24batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  83%|▊| 33883/40960 [02:04<00:27, 260.43batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  83%|▊| 33883/40960 [02:04<00:27, 260.43batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 33939/40960 [02:04<00:26, 264.83batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 33939/40960 [02:04<00:26, 264.83batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 33988/40960 [02:05<00:26, 258.71batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 33988/40960 [02:05<00:26, 258.71batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 34040/40960 [02:05<00:26, 258.81batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 34040/40960 [02:05<00:26, 258.81batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 34099/40960 [02:05<00:25, 269.39batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 34099/40960 [02:05<00:25, 269.39batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 34156/40960 [02:05<00:24, 273.66batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  83%|▊| 34156/40960 [02:05<00:24, 273.66batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34211/40960 [02:05<00:24, 272.66batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34211/40960 [02:05<00:24, 272.66batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  84%|▊| 34268/40960 [02:06<00:24, 275.39batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  84%|▊| 34268/40960 [02:06<00:24, 275.39batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34322/40960 [02:06<00:24, 273.29batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34322/40960 [02:06<00:24, 273.29batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34366/40960 [02:06<00:25, 256.94batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34366/40960 [02:06<00:25, 256.94batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34418/40960 [02:06<00:25, 256.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34418/40960 [02:06<00:25, 256.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34464/40960 [02:06<00:26, 248.38batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34464/40960 [02:06<00:26, 248.38batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34511/40960 [02:07<00:26, 243.01batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34511/40960 [02:07<00:26, 243.01batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34566/40960 [02:07<00:25, 251.71batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  84%|▊| 34566/40960 [02:07<00:25, 251.71batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34619/40960 [02:07<00:24, 254.24batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34619/40960 [02:07<00:24, 254.24batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34669/40960 [02:07<00:24, 252.49batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34669/40960 [02:07<00:24, 252.49batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34711/40960 [02:07<00:26, 238.62batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34711/40960 [02:07<00:26, 238.62batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34752/40960 [02:08<00:27, 228.09batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34752/40960 [02:08<00:27, 228.09batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34798/40960 [02:08<00:27, 228.14batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34798/40960 [02:08<00:27, 228.14batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34856/40960 [02:08<00:24, 245.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34856/40960 [02:08<00:24, 245.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34912/40960 [02:08<00:23, 255.16batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34912/40960 [02:08<00:23, 255.16batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34967/40960 [02:08<00:23, 260.29batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  85%|▊| 34967/40960 [02:08<00:23, 260.29batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  85%|▊| 35020/40960 [02:09<00:22, 260.63batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  85%|▊| 35020/40960 [02:09<00:22, 260.63batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35077/40960 [02:09<00:21, 267.58batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35077/40960 [02:09<00:21, 267.58batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35129/40960 [02:09<00:22, 264.97batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35129/40960 [02:09<00:22, 264.97batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35185/40960 [02:09<00:21, 269.34batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35185/40960 [02:09<00:21, 269.34batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35236/40960 [02:09<00:21, 264.98batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35236/40960 [02:09<00:21, 264.98batches/s, l2_loss: 0.0704 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|▊| 35284/40960 [02:10<00:22, 256.77batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35284/40960 [02:10<00:22, 256.77batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35332/40960 [02:10<00:22, 250.32batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35332/40960 [02:10<00:22, 250.32batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35384/40960 [02:10<00:22, 252.08batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  86%|▊| 35384/40960 [02:10<00:22, 252.08batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35437/40960 [02:10<00:21, 255.54batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35437/40960 [02:10<00:21, 255.54batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35493/40960 [02:10<00:20, 261.90batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35493/40960 [02:10<00:20, 261.90batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35549/40960 [02:11<00:20, 266.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35549/40960 [02:11<00:20, 266.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35608/40960 [02:11<00:19, 273.96batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35608/40960 [02:11<00:19, 273.96batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35664/40960 [02:11<00:19, 274.39batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35664/40960 [02:11<00:19, 274.39batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35718/40960 [02:11<00:19, 273.08batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35718/40960 [02:11<00:19, 273.08batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35775/40960 [02:11<00:18, 276.33batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35775/40960 [02:11<00:18, 276.33batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35826/40960 [02:12<00:19, 269.03batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  87%|▊| 35826/40960 [02:12<00:19, 269.03batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 35879/40960 [02:12<00:19, 267.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 35879/40960 [02:12<00:19, 267.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 35937/40960 [02:12<00:18, 273.85batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 35937/40960 [02:12<00:18, 273.85batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 35991/40960 [02:12<00:18, 271.54batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 35991/40960 [02:12<00:18, 271.54batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 36046/40960 [02:12<00:18, 270.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 36046/40960 [02:12<00:18, 270.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 36104/40960 [02:13<00:17, 275.92batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 36104/40960 [02:13<00:17, 275.92batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 36163/40960 [02:13<00:17, 281.45batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 36163/40960 [02:13<00:17, 281.45batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 36220/40960 [02:13<00:16, 281.33batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  88%|▉| 36220/40960 [02:13<00:16, 281.33batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36274/40960 [02:13<00:16, 277.74batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36274/40960 [02:13<00:16, 277.74batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36327/40960 [02:13<00:16, 273.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36327/40960 [02:13<00:16, 273.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36379/40960 [02:14<00:17, 268.79batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36379/40960 [02:14<00:17, 268.79batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36429/40960 [02:14<00:17, 262.37batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36429/40960 [02:14<00:17, 262.37batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36491/40960 [02:14<00:16, 275.26batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36491/40960 [02:14<00:16, 275.26batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36547/40960 [02:14<00:15, 276.38batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36547/40960 [02:14<00:15, 276.38batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36602/40960 [02:15<00:15, 275.41batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36602/40960 [02:15<00:15, 275.41batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36656/40960 [02:15<00:15, 273.20batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  89%|▉| 36656/40960 [02:15<00:15, 273.20batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36710/40960 [02:15<00:15, 271.79batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36710/40960 [02:15<00:15, 271.79batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36763/40960 [02:15<00:15, 269.05batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36763/40960 [02:15<00:15, 269.05batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36817/40960 [02:15<00:15, 267.80batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36817/40960 [02:15<00:15, 267.80batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36872/40960 [02:16<00:15, 268.82batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36872/40960 [02:16<00:15, 268.82batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36928/40960 [02:16<00:14, 271.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36928/40960 [02:16<00:14, 271.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36985/40960 [02:16<00:14, 274.28batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 36985/40960 [02:16<00:14, 274.28batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 37042/40960 [02:16<00:14, 276.26batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  90%|▉| 37042/40960 [02:16<00:14, 276.26batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37096/40960 [02:16<00:14, 273.77batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37096/40960 [02:16<00:14, 273.77batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37149/40960 [02:17<00:14, 270.24batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37149/40960 [02:17<00:14, 270.24batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37205/40960 [02:17<00:13, 271.19batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37205/40960 [02:17<00:13, 271.19batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37264/40960 [02:17<00:13, 277.40batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37264/40960 [02:17<00:13, 277.40batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37321/40960 [02:17<00:13, 279.34batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37321/40960 [02:17<00:13, 279.34batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37372/40960 [02:17<00:13, 271.09batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37372/40960 [02:17<00:13, 271.09batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37425/40960 [02:18<00:13, 268.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37425/40960 [02:18<00:13, 268.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37477/40960 [02:18<00:13, 264.94batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  91%|▉| 37477/40960 [02:18<00:13, 264.94batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37528/40960 [02:18<00:13, 261.35batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37528/40960 [02:18<00:13, 261.35batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37587/40960 [02:18<00:12, 270.04batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37587/40960 [02:18<00:12, 270.04batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37642/40960 [02:18<00:12, 270.70batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37642/40960 [02:18<00:12, 270.70batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37696/40960 [02:19<00:12, 269.37batches/s, l2_loss: 0.0704 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37696/40960 [02:19<00:12, 269.37batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37752/40960 [02:19<00:11, 272.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37752/40960 [02:19<00:11, 272.17batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37806/40960 [02:19<00:11, 270.60batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37806/40960 [02:19<00:11, 270.60batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37858/40960 [02:19<00:11, 267.29batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  92%|▉| 37858/40960 [02:19<00:11, 267.29batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 37907/40960 [02:19<00:11, 260.55batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 37907/40960 [02:19<00:11, 260.55batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 37961/40960 [02:20<00:11, 262.90batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 37961/40960 [02:20<00:11, 262.90batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  93%|▉| 38020/40960 [02:20<00:10, 271.49batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  93%|▉| 38020/40960 [02:20<00:10, 271.49batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38072/40960 [02:20<00:10, 267.87batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38072/40960 [02:20<00:10, 267.87batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38125/40960 [02:20<00:10, 265.97batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38125/40960 [02:20<00:10, 265.97batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38184/40960 [02:20<00:10, 273.38batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38184/40960 [02:20<00:10, 273.38batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38240/40960 [02:21<00:09, 275.11batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38240/40960 [02:21<00:09, 275.11batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38296/40960 [02:21<00:09, 275.35batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  93%|▉| 38296/40960 [02:21<00:09, 275.35batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38352/40960 [02:21<00:09, 276.33batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38352/40960 [02:21<00:09, 276.33batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38409/40960 [02:21<00:09, 278.28batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38409/40960 [02:21<00:09, 278.28batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38466/40960 [02:21<00:08, 279.52batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38466/40960 [02:21<00:08, 279.52batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  94%|▉| 38522/40960 [02:22<00:08, 278.45batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  94%|▉| 38522/40960 [02:22<00:08, 278.45batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38574/40960 [02:22<00:08, 272.22batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38574/40960 [02:22<00:08, 272.22batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  94%|▉| 38628/40960 [02:22<00:08, 270.56batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  94%|▉| 38628/40960 [02:22<00:08, 270.56batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38680/40960 [02:22<00:08, 266.91batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  94%|▉| 38680/40960 [02:22<00:08, 266.91batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38735/40960 [02:22<00:08, 268.69batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38735/40960 [02:22<00:08, 268.69batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38788/40960 [02:23<00:08, 265.23batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38788/40960 [02:23<00:08, 265.23batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38844/40960 [02:23<00:07, 268.44batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38844/40960 [02:23<00:07, 268.44batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38899/40960 [02:23<00:07, 269.15batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38899/40960 [02:23<00:07, 269.15batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38955/40960 [02:23<00:07, 272.20batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 38955/40960 [02:23<00:07, 272.20batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 39015/40960 [02:23<00:06, 279.77batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 39015/40960 [02:23<00:06, 279.77batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 39070/40960 [02:24<00:06, 277.78batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  95%|▉| 39070/40960 [02:24<00:06, 277.78batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39127/40960 [02:24<00:06, 279.76batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39127/40960 [02:24<00:06, 279.76batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39181/40960 [02:24<00:06, 276.10batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39181/40960 [02:24<00:06, 276.10batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39231/40960 [02:24<00:06, 267.00batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39231/40960 [02:24<00:06, 267.00batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39282/40960 [02:24<00:06, 262.74batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39282/40960 [02:24<00:06, 262.74batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39337/40960 [02:25<00:06, 265.67batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39337/40960 [02:25<00:06, 265.67batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39394/40960 [02:25<00:05, 271.07batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39394/40960 [02:25<00:05, 271.07batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39447/40960 [02:25<00:05, 268.14batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39447/40960 [02:25<00:05, 268.14batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39501/40960 [02:25<00:05, 268.68batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  96%|▉| 39501/40960 [02:25<00:05, 268.68batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39558/40960 [02:25<00:05, 272.46batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39558/40960 [02:25<00:05, 272.46batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39614/40960 [02:26<00:04, 274.03batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39614/40960 [02:26<00:04, 274.03batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39669/40960 [02:26<00:04, 274.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39669/40960 [02:26<00:04, 274.06batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39725/40960 [02:26<00:04, 275.55batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39725/40960 [02:26<00:04, 275.55batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39782/40960 [02:26<00:04, 277.86batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39782/40960 [02:26<00:04, 277.86batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39840/40960 [02:26<00:03, 280.30batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39840/40960 [02:26<00:03, 280.30batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39898/40960 [02:27<00:03, 282.02batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39898/40960 [02:27<00:03, 282.02batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 39952/40960 [02:27<00:03, 278.02batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 39952/40960 [02:27<00:03, 278.02batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40008/40960 [02:27<00:03, 277.78batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40008/40960 [02:27<00:03, 277.78batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40059/40960 [02:27<00:03, 269.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40059/40960 [02:27<00:03, 269.51batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40114/40960 [02:27<00:03, 270.50batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40114/40960 [02:27<00:03, 270.50batches/s, l2_loss: 0.0704 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40159/40960 [02:28<00:03, 255.09batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40159/40960 [02:28<00:03, 255.09batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40203/40960 [02:28<00:03, 243.40batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40203/40960 [02:28<00:03, 243.40batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40246/40960 [02:28<00:03, 233.96batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40246/40960 [02:28<00:03, 233.96batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40294/40960 [02:28<00:02, 235.47batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40294/40960 [02:28<00:02, 235.47batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40344/40960 [02:28<00:02, 238.45batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  98%|▉| 40344/40960 [02:28<00:02, 238.45batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  99%|▉| 40400/40960 [02:29<00:02, 250.57batches/s, l2_loss: 0.0705 - round_los\u001b[A\n",
      "Training:  99%|▉| 40400/40960 [02:29<00:02, 250.57batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40451/40960 [02:29<00:02, 251.69batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40451/40960 [02:29<00:02, 251.69batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40498/40960 [02:29<00:01, 246.62batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40498/40960 [02:29<00:01, 246.62batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40548/40960 [02:29<00:01, 247.24batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40548/40960 [02:29<00:01, 247.24batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40598/40960 [02:29<00:01, 246.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40598/40960 [02:29<00:01, 246.99batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40648/40960 [02:30<00:01, 247.41batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40648/40960 [02:30<00:01, 247.41batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40698/40960 [02:30<00:01, 247.12batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40698/40960 [02:30<00:01, 247.12batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40749/40960 [02:30<00:00, 248.97batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training:  99%|▉| 40749/40960 [02:30<00:00, 248.97batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training: 100%|▉| 40804/40960 [02:30<00:00, 256.62batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training: 100%|▉| 40804/40960 [02:30<00:00, 256.62batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training: 100%|▉| 40858/40960 [02:30<00:00, 260.18batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training: 100%|▉| 40858/40960 [02:30<00:00, 260.18batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training: 100%|▉| 40914/40960 [02:31<00:00, 265.18batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "Training: 100%|▉| 40914/40960 [02:31<00:00, 265.18batches/s, l2_loss: 0.0704 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:11:57.468182: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  42%|▍| 11/26 [22:37<36:02, 144.15s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:12:00.872715: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:12:03.565855: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<10:53:18,  1.04batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:53:18,  1.04batches/s, l2_loss: 0.0186 - round_loss:\u001b[A\n",
      "Training:   0%| | 96/40960 [00:01<06:11, 109.91batches/s, l2_loss: 0.0186 - round_loss: \u001b[A\n",
      "Training:   0%| | 96/40960 [00:01<06:11, 109.91batches/s, l2_loss: 0.0343 - round_loss: \u001b[A\n",
      "Training:   0%| | 190/40960 [00:01<03:25, 198.46batches/s, l2_loss: 0.0343 - round_loss:\u001b[A\n",
      "Training:   0%| | 190/40960 [00:01<03:25, 198.46batches/s, l2_loss: 0.0295 - round_loss:\u001b[A\n",
      "Training:   1%| | 274/40960 [00:01<02:39, 255.44batches/s, l2_loss: 0.0295 - round_loss:\u001b[A\n",
      "Training:   1%| | 274/40960 [00:01<02:39, 255.44batches/s, l2_loss: 0.0323 - round_loss:\u001b[A\n",
      "Training:   1%| | 358/40960 [00:01<02:15, 299.69batches/s, l2_loss: 0.0323 - round_loss:\u001b[A\n",
      "Training:   1%| | 358/40960 [00:01<02:15, 299.69batches/s, l2_loss: 0.0312 - round_loss:\u001b[A\n",
      "Training:   1%| | 449/40960 [00:01<01:58, 342.28batches/s, l2_loss: 0.0312 - round_loss:\u001b[A\n",
      "Training:   1%| | 449/40960 [00:01<01:58, 342.28batches/s, l2_loss: 0.0321 - round_loss:\u001b[A\n",
      "Training:   1%| | 542/40960 [00:02<01:47, 376.14batches/s, l2_loss: 0.0321 - round_loss:\u001b[A\n",
      "Training:   1%| | 542/40960 [00:02<01:47, 376.14batches/s, l2_loss: 0.0309 - round_loss:\u001b[A\n",
      "Training:   2%| | 635/40960 [00:02<01:40, 400.72batches/s, l2_loss: 0.0309 - round_loss:\u001b[A\n",
      "Training:   2%| | 635/40960 [00:02<01:40, 400.72batches/s, l2_loss: 0.0310 - round_loss:\u001b[A\n",
      "Training:   2%| | 726/40960 [00:02<01:36, 415.26batches/s, l2_loss: 0.0310 - round_loss:\u001b[A\n",
      "Training:   2%| | 726/40960 [00:02<01:36, 415.26batches/s, l2_loss: 0.0310 - round_loss:\u001b[A\n",
      "Training:   2%| | 815/40960 [00:02<01:34, 423.80batches/s, l2_loss: 0.0310 - round_loss:\u001b[A\n",
      "Training:   2%| | 815/40960 [00:02<01:34, 423.80batches/s, l2_loss: 0.0304 - round_loss:\u001b[A\n",
      "Training:   2%| | 900/40960 [00:02<01:34, 423.96batches/s, l2_loss: 0.0304 - round_loss:\u001b[A\n",
      "Training:   2%| | 900/40960 [00:02<01:34, 423.96batches/s, l2_loss: 0.0309 - round_loss:\u001b[A\n",
      "Training:   2%| | 982/40960 [00:03<01:35, 419.38batches/s, l2_loss: 0.0309 - round_loss:\u001b[A\n",
      "Training:   2%| | 982/40960 [00:03<01:35, 419.38batches/s, l2_loss: 0.0309 - round_loss:\u001b[A\n",
      "Training:   3%| | 1064/40960 [00:03<01:35, 416.14batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   3%| | 1064/40960 [00:03<01:35, 416.14batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:   3%| | 1134/40960 [00:03<01:40, 395.52batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:   3%| | 1134/40960 [00:03<01:40, 395.52batches/s, l2_loss: 0.0310 - round_loss\u001b[A\n",
      "Training:   3%| | 1227/40960 [00:03<01:35, 415.62batches/s, l2_loss: 0.0310 - round_loss\u001b[A\n",
      "Training:   3%| | 1227/40960 [00:03<01:35, 415.62batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   3%| | 1321/40960 [00:03<01:31, 431.57batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   3%| | 1321/40960 [00:03<01:31, 431.57batches/s, l2_loss: 0.0311 - round_loss\u001b[A\n",
      "Training:   3%| | 1411/40960 [00:04<01:30, 436.02batches/s, l2_loss: 0.0311 - round_loss\u001b[A\n",
      "Training:   3%| | 1411/40960 [00:04<01:30, 436.02batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   4%| | 1502/40960 [00:04<01:29, 440.44batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   4%| | 1502/40960 [00:04<01:29, 440.44batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   4%| | 1595/40960 [00:04<01:28, 447.14batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   4%| | 1595/40960 [00:04<01:28, 447.14batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   4%| | 1688/40960 [00:04<01:26, 452.01batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   4%| | 1688/40960 [00:04<01:26, 452.01batches/s, l2_loss: 0.0312 - round_loss\u001b[A\n",
      "Training:   4%| | 1782/40960 [00:04<01:25, 456.14batches/s, l2_loss: 0.0312 - round_loss\u001b[A\n",
      "Training:   4%| | 1782/40960 [00:04<01:25, 456.14batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   5%| | 1875/40960 [00:05<01:25, 457.21batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   5%| | 1875/40960 [00:05<01:25, 457.21batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 1971/40960 [00:05<01:24, 463.01batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   5%| | 1971/40960 [00:05<01:24, 463.01batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   5%| | 2067/40960 [00:05<01:23, 467.40batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   5%| | 2067/40960 [00:05<01:23, 467.40batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   5%| | 2162/40960 [00:05<01:22, 469.33batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   5%| | 2162/40960 [00:05<01:22, 469.33batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   6%| | 2258/40960 [00:05<01:22, 471.05batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   6%| | 2258/40960 [00:05<01:22, 471.05batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   6%| | 2352/40960 [00:06<01:22, 469.79batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   6%| | 2352/40960 [00:06<01:22, 469.79batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   6%| | 2447/40960 [00:06<01:21, 471.22batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   6%| | 2447/40960 [00:06<01:21, 471.22batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   6%| | 2541/40960 [00:06<01:21, 469.31batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   6%| | 2541/40960 [00:06<01:21, 469.31batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   6%| | 2637/40960 [00:06<01:21, 471.84batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   6%| | 2637/40960 [00:06<01:21, 471.84batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   7%| | 2734/40960 [00:06<01:20, 474.98batches/s, l2_loss: 0.0308 - round_loss\u001b[A\n",
      "Training:   7%| | 2734/40960 [00:06<01:20, 474.98batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   7%| | 2830/40960 [00:07<01:20, 475.08batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   7%| | 2830/40960 [00:07<01:20, 475.08batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   7%| | 2926/40960 [00:07<01:20, 475.28batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   7%| | 2926/40960 [00:07<01:20, 475.28batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   7%| | 3023/40960 [00:07<01:19, 477.59batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   7%| | 3023/40960 [00:07<01:19, 477.59batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   8%| | 3117/40960 [00:07<01:19, 473.92batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   8%| | 3117/40960 [00:07<01:19, 473.92batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   8%| | 3212/40960 [00:08<01:19, 473.23batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   8%| | 3212/40960 [00:08<01:19, 473.23batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   8%| | 3306/40960 [00:08<01:19, 471.23batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:   8%| | 3306/40960 [00:08<01:19, 471.23batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   8%| | 3401/40960 [00:08<01:19, 472.05batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   8%| | 3401/40960 [00:08<01:19, 472.05batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   9%| | 3497/40960 [00:08<01:19, 473.69batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   9%| | 3497/40960 [00:08<01:19, 473.69batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   9%| | 3594/40960 [00:08<01:18, 476.81batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   9%| | 3594/40960 [00:08<01:18, 476.81batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   9%| | 3690/40960 [00:09<01:18, 476.66batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   9%| | 3690/40960 [00:09<01:18, 476.66batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   9%| | 3786/40960 [00:09<01:17, 477.38batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:   9%| | 3786/40960 [00:09<01:17, 477.38batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   9%| | 3883/40960 [00:09<01:17, 478.52batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:   9%| | 3883/40960 [00:09<01:17, 478.52batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  10%| | 3980/40960 [00:09<01:17, 479.15batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  10%| | 3980/40960 [00:09<01:17, 479.15batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  10%| | 4076/40960 [00:09<01:17, 478.13batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  10%| | 4076/40960 [00:09<01:17, 478.13batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  10%| | 4169/40960 [00:10<01:17, 473.47batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  10%| | 4169/40960 [00:10<01:17, 473.47batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  10%| | 4263/40960 [00:10<01:17, 472.39batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  10%| | 4263/40960 [00:10<01:17, 472.39batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  11%| | 4358/40960 [00:10<01:17, 473.01batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  11%| | 4358/40960 [00:10<01:17, 473.01batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  11%| | 4454/40960 [00:10<01:17, 473.83batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  11%| | 4454/40960 [00:10<01:17, 473.83batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  11%| | 4550/40960 [00:10<01:16, 474.55batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  11%| | 4550/40960 [00:10<01:16, 474.55batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  11%| | 4644/40960 [00:11<01:16, 473.09batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  11%| | 4644/40960 [00:11<01:16, 473.09batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 4740/40960 [00:11<01:16, 474.75batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 4740/40960 [00:11<01:16, 474.75batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 4834/40960 [00:11<01:16, 473.12batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 4834/40960 [00:11<01:16, 473.12batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 4924/40960 [00:11<01:17, 465.76batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 4924/40960 [00:11<01:17, 465.76batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 5017/40960 [00:11<01:17, 465.10batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 5017/40960 [00:11<01:17, 465.10batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 5108/40960 [00:12<01:17, 461.32batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  12%| | 5108/40960 [00:12<01:17, 461.32batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5203/40960 [00:12<01:17, 464.34batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5203/40960 [00:12<01:17, 464.34batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5294/40960 [00:12<01:17, 461.21batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5294/40960 [00:12<01:17, 461.21batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5386/40960 [00:12<01:17, 460.01batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5386/40960 [00:12<01:17, 460.01batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5479/40960 [00:12<01:16, 460.98batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5479/40960 [00:12<01:16, 460.98batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5570/40960 [00:13<01:17, 458.15batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5570/40960 [00:13<01:17, 458.15batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5659/40960 [00:13<01:17, 453.28batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5659/40960 [00:13<01:17, 453.28batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5747/40960 [00:13<01:18, 448.73batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5747/40960 [00:13<01:18, 448.73batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5842/40960 [00:13<01:17, 455.69batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5842/40960 [00:13<01:17, 455.69batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5929/40960 [00:13<01:18, 448.53batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5929/40960 [00:13<01:18, 448.53batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6013/40960 [00:14<01:19, 438.61batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6013/40960 [00:14<01:19, 438.61batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6098/40960 [00:14<01:20, 433.31batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 6098/40960 [00:14<01:20, 433.31batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6186/40960 [00:14<01:20, 434.08batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6186/40960 [00:14<01:20, 434.08batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6276/40960 [00:14<01:19, 438.16batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6276/40960 [00:14<01:19, 438.16batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6364/40960 [00:14<01:18, 438.02batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6364/40960 [00:14<01:18, 438.02batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6459/40960 [00:15<01:17, 448.00batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6459/40960 [00:15<01:17, 448.00batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6549/40960 [00:15<01:16, 447.89batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6549/40960 [00:15<01:16, 447.89batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6633/40960 [00:15<01:18, 438.94batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6633/40960 [00:15<01:18, 438.94batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6721/40960 [00:15<01:18, 437.98batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6721/40960 [00:15<01:18, 437.98batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6815/40960 [00:15<01:16, 446.97batches/s, l2_loss: 0.0306 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6815/40960 [00:15<01:16, 446.97batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6910/40960 [00:16<01:14, 455.33batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6910/40960 [00:16<01:14, 455.33batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7003/40960 [00:16<01:14, 457.15batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7003/40960 [00:16<01:14, 457.15batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7097/40960 [00:16<01:13, 460.77batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7097/40960 [00:16<01:13, 460.77batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7190/40960 [00:16<01:13, 461.84batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7190/40960 [00:16<01:13, 461.84batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7280/40960 [00:16<01:13, 458.18batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7280/40960 [00:16<01:13, 458.18batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7375/40960 [00:17<01:12, 462.24batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7375/40960 [00:17<01:12, 462.24batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:17<01:12, 460.98batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:17<01:12, 460.98batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7557/40960 [00:17<01:12, 457.66batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7557/40960 [00:17<01:12, 457.66batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7647/40960 [00:17<01:13, 454.21batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7647/40960 [00:17<01:13, 454.21batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7741/40960 [00:17<01:12, 458.91batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7741/40960 [00:17<01:12, 458.91batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7832/40960 [00:18<01:12, 456.75batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7832/40960 [00:18<01:12, 456.75batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7927/40960 [00:18<01:11, 460.72batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7927/40960 [00:18<01:11, 460.72batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8022/40960 [00:18<01:10, 464.73batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8022/40960 [00:18<01:10, 464.73batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8116/40960 [00:18<01:10, 464.73batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8116/40960 [00:18<01:10, 464.73batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8194/40960 [00:18<01:14, 441.13batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8194/40960 [00:18<01:14, 441.13batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8270/40960 [00:19<01:17, 421.68batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8270/40960 [00:19<01:17, 421.68batches/s, l2_loss: 0.0248 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8348/40960 [00:19<01:19, 411.52batches/s, l2_loss: 0.0248 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8348/40960 [00:19<01:19, 411.52batches/s, l2_loss: 0.0290 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8421/40960 [00:19<01:22, 396.32batches/s, l2_loss: 0.0290 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8421/40960 [00:19<01:22, 396.32batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8499/40960 [00:19<01:22, 393.74batches/s, l2_loss: 0.0309 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8499/40960 [00:19<01:22, 393.74batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8585/40960 [00:19<01:20, 404.16batches/s, l2_loss: 0.0307 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8585/40960 [00:19<01:20, 404.16batches/s, l2_loss: 0.0299 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8671/40960 [00:20<01:18, 411.78batches/s, l2_loss: 0.0299 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8671/40960 [00:20<01:18, 411.78batches/s, l2_loss: 0.0303 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8757/40960 [00:20<01:17, 416.50batches/s, l2_loss: 0.0303 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8757/40960 [00:20<01:17, 416.50batches/s, l2_loss: 0.0299 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8840/40960 [00:20<01:17, 415.92batches/s, l2_loss: 0.0299 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8840/40960 [00:20<01:17, 415.92batches/s, l2_loss: 0.0300 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8922/40960 [00:20<01:17, 414.09batches/s, l2_loss: 0.0300 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8922/40960 [00:20<01:17, 414.09batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9007/40960 [00:20<01:16, 416.20batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9007/40960 [00:20<01:16, 416.20batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9091/40960 [00:21<01:16, 416.18batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9091/40960 [00:21<01:16, 416.18batches/s, l2_loss: 0.0301 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9177/40960 [00:21<01:15, 419.02batches/s, l2_loss: 0.0301 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9177/40960 [00:21<01:15, 419.02batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9261/40960 [00:21<01:15, 417.94batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9261/40960 [00:21<01:15, 417.94batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9343/40960 [00:21<01:16, 415.36batches/s, l2_loss: 0.0305 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9343/40960 [00:21<01:16, 415.36batches/s, l2_loss: 0.0302 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9426/40960 [00:21<01:16, 414.63batches/s, l2_loss: 0.0302 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9426/40960 [00:21<01:16, 414.63batches/s, l2_loss: 0.0298 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9508/40960 [00:22<01:16, 412.19batches/s, l2_loss: 0.0298 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9508/40960 [00:22<01:16, 412.19batches/s, l2_loss: 0.0300 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9591/40960 [00:22<01:16, 412.46batches/s, l2_loss: 0.0300 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9591/40960 [00:22<01:16, 412.46batches/s, l2_loss: 0.0300 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9672/40960 [00:22<01:16, 409.48batches/s, l2_loss: 0.0300 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9672/40960 [00:22<01:16, 409.48batches/s, l2_loss: 0.0301 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9756/40960 [00:22<01:15, 412.28batches/s, l2_loss: 0.0301 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9756/40960 [00:22<01:15, 412.28batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9839/40960 [00:22<01:15, 411.98batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9839/40960 [00:22<01:15, 411.98batches/s, l2_loss: 0.0301 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9919/40960 [00:23<01:16, 407.34batches/s, l2_loss: 0.0301 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9919/40960 [00:23<01:16, 407.34batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|▏| 9996/40960 [00:23<01:17, 400.13batches/s, l2_loss: 0.0304 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9996/40960 [00:23<01:17, 400.13batches/s, l2_loss: 0.0300 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10080/40960 [00:23<01:16, 405.00batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  25%|▏| 10080/40960 [00:23<01:16, 405.00batches/s, l2_loss: 0.0303 - round_los\u001b[A\n",
      "Training:  25%|▏| 10166/40960 [00:23<01:14, 411.45batches/s, l2_loss: 0.0303 - round_los\u001b[A\n",
      "Training:  25%|▏| 10166/40960 [00:23<01:14, 411.45batches/s, l2_loss: 0.0302 - round_los\u001b[A\n",
      "Training:  25%|▎| 10248/40960 [00:23<01:14, 409.81batches/s, l2_loss: 0.0302 - round_los\u001b[A\n",
      "Training:  25%|▎| 10248/40960 [00:23<01:14, 409.81batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  25%|▎| 10325/40960 [00:24<01:16, 401.84batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  25%|▎| 10325/40960 [00:24<01:16, 401.84batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  25%|▎| 10408/40960 [00:24<01:15, 405.29batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  25%|▎| 10408/40960 [00:24<01:15, 405.29batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  26%|▎| 10493/40960 [00:24<01:14, 411.12batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  26%|▎| 10493/40960 [00:24<01:14, 411.12batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  26%|▎| 10579/40960 [00:24<01:12, 416.39batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  26%|▎| 10579/40960 [00:24<01:12, 416.39batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  26%|▎| 10663/40960 [00:24<01:12, 416.35batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  26%|▎| 10663/40960 [00:24<01:12, 416.35batches/s, l2_loss: 0.0303 - round_los\u001b[A\n",
      "Training:  26%|▎| 10746/40960 [00:25<01:12, 415.47batches/s, l2_loss: 0.0303 - round_los\u001b[A\n",
      "Training:  26%|▎| 10746/40960 [00:25<01:12, 415.47batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  26%|▎| 10821/40960 [00:25<01:14, 402.27batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  26%|▎| 10821/40960 [00:25<01:14, 402.27batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  27%|▎| 10897/40960 [00:25<01:15, 395.59batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  27%|▎| 10897/40960 [00:25<01:15, 395.59batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  27%|▎| 10975/40960 [00:25<01:16, 392.77batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  27%|▎| 10975/40960 [00:25<01:16, 392.77batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  27%|▎| 11051/40960 [00:25<01:16, 388.50batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  27%|▎| 11051/40960 [00:25<01:16, 388.50batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  27%|▎| 11136/40960 [00:26<01:14, 398.13batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  27%|▎| 11136/40960 [00:26<01:14, 398.13batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  27%|▎| 11214/40960 [00:26<01:15, 395.02batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  27%|▎| 11214/40960 [00:26<01:15, 395.02batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  28%|▎| 11286/40960 [00:26<01:17, 383.23batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  28%|▎| 11286/40960 [00:26<01:17, 383.23batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  28%|▎| 11365/40960 [00:26<01:16, 386.11batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  28%|▎| 11365/40960 [00:26<01:16, 386.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  28%|▎| 11450/40960 [00:26<01:14, 396.52batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  28%|▎| 11450/40960 [00:26<01:14, 396.52batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  28%|▎| 11527/40960 [00:27<01:15, 392.07batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  28%|▎| 11527/40960 [00:27<01:15, 392.07batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:27<01:15, 388.29batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:27<01:15, 388.29batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  29%|▎| 11685/40960 [00:27<01:14, 394.60batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  29%|▎| 11685/40960 [00:27<01:14, 394.60batches/s, l2_loss: 0.0302 - round_los\u001b[A\n",
      "Training:  29%|▎| 11769/40960 [00:27<01:12, 401.72batches/s, l2_loss: 0.0302 - round_los\u001b[A\n",
      "Training:  29%|▎| 11769/40960 [00:27<01:12, 401.72batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  29%|▎| 11852/40960 [00:27<01:11, 404.42batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  29%|▎| 11852/40960 [00:27<01:11, 404.42batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  29%|▎| 11930/40960 [00:28<01:12, 398.74batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  29%|▎| 11930/40960 [00:28<01:12, 398.74batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  29%|▎| 12011/40960 [00:28<01:12, 400.28batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  29%|▎| 12011/40960 [00:28<01:12, 400.28batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  30%|▎| 12098/40960 [00:28<01:10, 410.62batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  30%|▎| 12098/40960 [00:28<01:10, 410.62batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  30%|▎| 12185/40960 [00:28<01:08, 417.35batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  30%|▎| 12185/40960 [00:28<01:08, 417.35batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  30%|▎| 12270/40960 [00:28<01:08, 418.50batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  30%|▎| 12270/40960 [00:28<01:08, 418.50batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  30%|▎| 12350/40960 [00:29<01:09, 412.50batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  30%|▎| 12350/40960 [00:29<01:09, 412.50batches/s, l2_loss: 0.0302 - round_los\u001b[A\n",
      "Training:  30%|▎| 12427/40960 [00:29<01:10, 403.31batches/s, l2_loss: 0.0302 - round_los\u001b[A\n",
      "Training:  30%|▎| 12427/40960 [00:29<01:10, 403.31batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12506/40960 [00:29<01:11, 399.69batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12506/40960 [00:29<01:11, 399.69batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12589/40960 [00:29<01:10, 403.83batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12589/40960 [00:29<01:10, 403.83batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  31%|▎| 12659/40960 [00:29<01:12, 387.71batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  31%|▎| 12659/40960 [00:29<01:12, 387.71batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12737/40960 [00:30<01:12, 388.02batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12737/40960 [00:30<01:12, 388.02batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12820/40960 [00:30<01:11, 395.36batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12820/40960 [00:30<01:11, 395.36batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12900/40960 [00:30<01:10, 395.74batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  31%|▎| 12900/40960 [00:30<01:10, 395.74batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  32%|▎| 12984/40960 [00:30<01:09, 402.90batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  32%|▎| 12984/40960 [00:30<01:09, 402.90batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  32%|▎| 13067/40960 [00:30<01:08, 405.94batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  32%|▎| 13067/40960 [00:30<01:08, 405.94batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  32%|▎| 13151/40960 [00:31<01:07, 409.37batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  32%|▎| 13151/40960 [00:31<01:07, 409.37batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  32%|▎| 13237/40960 [00:31<01:06, 415.19batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  32%|▎| 13237/40960 [00:31<01:06, 415.19batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  33%|▎| 13320/40960 [00:31<01:06, 414.61batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  33%|▎| 13320/40960 [00:31<01:06, 414.61batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  33%|▎| 13402/40960 [00:31<01:06, 412.05batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  33%|▎| 13402/40960 [00:31<01:06, 412.05batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  33%|▎| 13486/40960 [00:31<01:06, 413.73batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  33%|▎| 13486/40960 [00:31<01:06, 413.73batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  33%|▎| 13571/40960 [00:32<01:05, 416.65batches/s, l2_loss: 0.0301 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|▎| 13571/40960 [00:32<01:05, 416.65batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  33%|▎| 13649/40960 [00:32<01:06, 408.29batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  33%|▎| 13649/40960 [00:32<01:06, 408.29batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  34%|▎| 13734/40960 [00:32<01:05, 412.87batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  34%|▎| 13734/40960 [00:32<01:05, 412.87batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  34%|▎| 13815/40960 [00:32<01:06, 408.72batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  34%|▎| 13815/40960 [00:32<01:06, 408.72batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  34%|▎| 13897/40960 [00:32<01:06, 407.84batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  34%|▎| 13897/40960 [00:32<01:06, 407.84batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  34%|▎| 13979/40960 [00:33<01:06, 408.41batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  34%|▎| 13979/40960 [00:33<01:06, 408.41batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  34%|▎| 14059/40960 [00:33<01:06, 405.43batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  34%|▎| 14059/40960 [00:33<01:06, 405.43batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  35%|▎| 14143/40960 [00:33<01:05, 408.96batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  35%|▎| 14143/40960 [00:33<01:05, 408.96batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  35%|▎| 14229/40960 [00:33<01:04, 414.62batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  35%|▎| 14229/40960 [00:33<01:04, 414.62batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  35%|▎| 14308/40960 [00:33<01:05, 407.76batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  35%|▎| 14308/40960 [00:33<01:05, 407.76batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  35%|▎| 14388/40960 [00:34<01:05, 404.09batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  35%|▎| 14388/40960 [00:34<01:05, 404.09batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  35%|▎| 14474/40960 [00:34<01:04, 410.48batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  35%|▎| 14474/40960 [00:34<01:04, 410.48batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14560/40960 [00:34<01:03, 415.20batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14560/40960 [00:34<01:03, 415.20batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14643/40960 [00:34<01:03, 414.00batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14643/40960 [00:34<01:03, 414.00batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14724/40960 [00:34<01:03, 411.03batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14724/40960 [00:34<01:03, 411.03batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14805/40960 [00:35<01:04, 408.30batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14805/40960 [00:35<01:04, 408.30batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14890/40960 [00:35<01:03, 412.03batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  36%|▎| 14890/40960 [00:35<01:03, 412.03batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  37%|▎| 14974/40960 [00:35<01:02, 413.13batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  37%|▎| 14974/40960 [00:35<01:02, 413.13batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  37%|▎| 15059/40960 [00:35<01:02, 415.93batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  37%|▎| 15059/40960 [00:35<01:02, 415.93batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  37%|▎| 15138/40960 [00:35<01:03, 409.45batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  37%|▎| 15138/40960 [00:35<01:03, 409.45batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  37%|▎| 15222/40960 [00:36<01:02, 411.75batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  37%|▎| 15222/40960 [00:36<01:02, 411.75batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  37%|▎| 15303/40960 [00:36<01:02, 409.57batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  37%|▎| 15303/40960 [00:36<01:02, 409.57batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  38%|▍| 15386/40960 [00:36<01:02, 410.13batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  38%|▍| 15386/40960 [00:36<01:02, 410.13batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  38%|▍| 15464/40960 [00:36<01:03, 402.70batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  38%|▍| 15464/40960 [00:36<01:03, 402.70batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  38%|▍| 15543/40960 [00:36<01:03, 400.31batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  38%|▍| 15543/40960 [00:36<01:03, 400.31batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  38%|▍| 15621/40960 [00:37<01:03, 396.61batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  38%|▍| 15621/40960 [00:37<01:03, 396.61batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  38%|▍| 15703/40960 [00:37<01:03, 399.65batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  38%|▍| 15703/40960 [00:37<01:03, 399.65batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  39%|▍| 15781/40960 [00:37<01:03, 396.56batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  39%|▍| 15781/40960 [00:37<01:03, 396.56batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  39%|▍| 15856/40960 [00:37<01:04, 388.71batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  39%|▍| 15856/40960 [00:37<01:04, 388.71batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  39%|▍| 15935/40960 [00:37<01:04, 390.48batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  39%|▍| 15935/40960 [00:37<01:04, 390.48batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  39%|▍| 16015/40960 [00:38<01:03, 392.11batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  39%|▍| 16015/40960 [00:38<01:03, 392.11batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  39%|▍| 16098/40960 [00:38<01:02, 397.81batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  39%|▍| 16098/40960 [00:38<01:02, 397.81batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  39%|▍| 16174/40960 [00:38<01:03, 391.53batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  39%|▍| 16174/40960 [00:38<01:03, 391.53batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  40%|▍| 16250/40960 [00:38<01:03, 387.76batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  40%|▍| 16250/40960 [00:38<01:03, 387.76batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  40%|▍| 16330/40960 [00:38<01:02, 391.23batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  40%|▍| 16330/40960 [00:38<01:02, 391.23batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  40%|▍| 16405/40960 [00:39<01:03, 385.73batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  40%|▍| 16405/40960 [00:39<01:03, 385.73batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  40%|▍| 16485/40960 [00:39<01:02, 388.84batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  40%|▍| 16485/40960 [00:39<01:02, 388.84batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  40%|▍| 16567/40960 [00:39<01:01, 394.77batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  40%|▍| 16567/40960 [00:39<01:01, 394.77batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  41%|▍| 16653/40960 [00:39<01:00, 404.87batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  41%|▍| 16653/40960 [00:39<01:00, 404.87batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  41%|▍| 16734/40960 [00:39<00:59, 404.21batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  41%|▍| 16734/40960 [00:39<00:59, 404.21batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  41%|▍| 16818/40960 [00:40<00:59, 408.31batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  41%|▍| 16818/40960 [00:40<00:59, 408.31batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  41%|▍| 16900/40960 [00:40<00:58, 408.71batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  41%|▍| 16900/40960 [00:40<00:58, 408.71batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  41%|▍| 16982/40960 [00:40<00:58, 407.39batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  41%|▍| 16982/40960 [00:40<00:58, 407.39batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  42%|▍| 17059/40960 [00:40<00:59, 400.43batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  42%|▍| 17059/40960 [00:40<00:59, 400.43batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  42%|▍| 17141/40960 [00:40<00:59, 401.81batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  42%|▍| 17141/40960 [00:41<00:59, 401.81batches/s, l2_loss: 0.0301 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|▍| 17222/40960 [00:41<00:58, 402.51batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  42%|▍| 17222/40960 [00:41<00:58, 402.51batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  42%|▍| 17300/40960 [00:41<00:59, 397.49batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  42%|▍| 17300/40960 [00:41<00:59, 397.49batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  42%|▍| 17380/40960 [00:41<00:59, 398.11batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  42%|▍| 17380/40960 [00:41<00:59, 398.11batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  43%|▍| 17467/40960 [00:41<00:57, 407.86batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  43%|▍| 17467/40960 [00:41<00:57, 407.86batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  43%|▍| 17550/40960 [00:42<00:57, 409.49batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  43%|▍| 17550/40960 [00:42<00:57, 409.49batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  43%|▍| 17634/40960 [00:42<00:56, 412.21batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  43%|▍| 17634/40960 [00:42<00:56, 412.21batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  43%|▍| 17716/40960 [00:42<00:56, 411.23batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  43%|▍| 17716/40960 [00:42<00:56, 411.23batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  43%|▍| 17803/40960 [00:42<00:55, 417.88batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  43%|▍| 17803/40960 [00:42<00:55, 417.88batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  44%|▍| 17891/40960 [00:42<00:54, 422.65batches/s, l2_loss: 0.0301 - round_los\u001b[A\n",
      "Training:  44%|▍| 17891/40960 [00:42<00:54, 422.65batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  44%|▍| 17973/40960 [00:43<00:55, 417.45batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  44%|▍| 17973/40960 [00:43<00:55, 417.45batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  44%|▍| 18050/40960 [00:43<00:56, 407.01batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  44%|▍| 18050/40960 [00:43<00:56, 407.01batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  44%|▍| 18130/40960 [00:43<00:56, 404.51batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  44%|▍| 18130/40960 [00:43<00:56, 404.51batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  44%|▍| 18208/40960 [00:43<00:56, 399.22batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  44%|▍| 18208/40960 [00:43<00:56, 399.22batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18284/40960 [00:43<00:57, 392.10batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18284/40960 [00:43<00:57, 392.10batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18365/40960 [00:44<00:57, 395.84batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18365/40960 [00:44<00:57, 395.84batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18451/40960 [00:44<00:55, 405.15batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18451/40960 [00:44<00:55, 405.15batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18530/40960 [00:44<00:55, 401.11batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18530/40960 [00:44<00:55, 401.11batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18609/40960 [00:44<00:56, 399.01batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  45%|▍| 18609/40960 [00:44<00:56, 399.01batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 18686/40960 [00:44<00:56, 394.27batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 18686/40960 [00:44<00:56, 394.27batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 18758/40960 [00:45<00:57, 383.75batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 18758/40960 [00:45<00:57, 383.75batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 18842/40960 [00:45<00:56, 394.57batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 18842/40960 [00:45<00:56, 394.57batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 18926/40960 [00:45<00:54, 401.04batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 18926/40960 [00:45<00:54, 401.04batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 19006/40960 [00:45<00:54, 399.83batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  46%|▍| 19006/40960 [00:45<00:54, 399.83batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19088/40960 [00:45<00:54, 402.58batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19088/40960 [00:45<00:54, 402.58batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19171/40960 [00:46<00:53, 404.96batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19171/40960 [00:46<00:53, 404.96batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19251/40960 [00:46<00:53, 402.09batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19251/40960 [00:46<00:53, 402.09batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19331/40960 [00:46<00:54, 400.30batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19331/40960 [00:46<00:54, 400.30batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19416/40960 [00:46<00:52, 406.66batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  47%|▍| 19416/40960 [00:46<00:52, 406.66batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19498/40960 [00:46<00:52, 407.18batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19498/40960 [00:46<00:52, 407.18batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19582/40960 [00:47<00:52, 410.40batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19582/40960 [00:47<00:52, 410.40batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19667/40960 [00:47<00:51, 413.44batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19667/40960 [00:47<00:51, 413.44batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19735/40960 [00:47<00:54, 391.46batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19735/40960 [00:47<00:54, 391.46batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19817/40960 [00:47<00:53, 395.93batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  48%|▍| 19817/40960 [00:47<00:53, 395.93batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 19895/40960 [00:47<00:53, 393.56batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 19895/40960 [00:47<00:53, 393.56batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 19966/40960 [00:48<00:55, 381.52batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 19966/40960 [00:48<00:55, 381.52batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 20045/40960 [00:48<00:54, 384.76batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 20045/40960 [00:48<00:54, 384.76batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 20131/40960 [00:48<00:52, 397.38batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 20131/40960 [00:48<00:52, 397.38batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 20211/40960 [00:48<00:52, 398.06batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  49%|▍| 20211/40960 [00:48<00:52, 398.06batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▍| 20295/40960 [00:48<00:51, 403.44batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▍| 20295/40960 [00:48<00:51, 403.44batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▍| 20379/40960 [00:49<00:50, 406.86batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▍| 20379/40960 [00:49<00:50, 406.86batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▍| 20459/40960 [00:49<00:50, 404.73batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▍| 20459/40960 [00:49<00:50, 404.73batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▌| 20538/40960 [00:49<00:50, 401.32batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▌| 20538/40960 [00:49<00:50, 401.32batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▌| 20625/40960 [00:49<00:49, 411.23batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  50%|▌| 20625/40960 [00:49<00:49, 411.23batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20707/40960 [00:49<00:49, 410.12batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20707/40960 [00:49<00:49, 410.12batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20786/40960 [00:50<00:49, 405.11batches/s, l2_loss: 0.0300 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|▌| 20786/40960 [00:50<00:49, 405.11batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20869/40960 [00:50<00:49, 406.75batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20869/40960 [00:50<00:49, 406.75batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20953/40960 [00:50<00:48, 409.59batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20953/40960 [00:50<00:48, 409.59batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 21033/40960 [00:50<00:49, 406.36batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  51%|▌| 21033/40960 [00:50<00:49, 406.36batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21118/40960 [00:50<00:48, 411.16batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21118/40960 [00:50<00:48, 411.16batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21197/40960 [00:51<00:48, 404.98batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21197/40960 [00:51<00:48, 404.98batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21271/40960 [00:51<00:50, 393.21batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21271/40960 [00:51<00:50, 393.21batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21336/40960 [00:51<00:52, 371.27batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21336/40960 [00:51<00:52, 371.27batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21402/40960 [00:51<00:54, 358.10batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21402/40960 [00:51<00:54, 358.10batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21458/40960 [00:51<00:58, 333.81batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  52%|▌| 21458/40960 [00:51<00:58, 333.81batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21510/40960 [00:52<01:02, 310.91batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21510/40960 [00:52<01:02, 310.91batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21576/40960 [00:52<01:01, 315.99batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21576/40960 [00:52<01:01, 315.99batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  53%|▌| 21651/40960 [00:52<00:57, 333.45batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  53%|▌| 21651/40960 [00:52<00:57, 333.45batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21730/40960 [00:52<00:54, 351.56batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21730/40960 [00:52<00:54, 351.56batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21812/40960 [00:52<00:51, 368.99batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21812/40960 [00:52<00:51, 368.99batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21882/40960 [00:53<00:52, 362.14batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  53%|▌| 21882/40960 [00:53<00:52, 362.14batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 21966/40960 [00:53<00:50, 378.43batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 21966/40960 [00:53<00:50, 378.43batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 22049/40960 [00:53<00:48, 388.33batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 22049/40960 [00:53<00:48, 388.33batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 22130/40960 [00:53<00:48, 392.12batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 22130/40960 [00:53<00:48, 392.12batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 22213/40960 [00:53<00:47, 397.82batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 22213/40960 [00:53<00:47, 397.82batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [00:54<00:46, 402.30batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [00:54<00:46, 402.30batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22378/40960 [00:54<00:46, 403.83batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22378/40960 [00:54<00:46, 403.83batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22456/40960 [00:54<00:46, 399.46batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22456/40960 [00:54<00:46, 399.46batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22532/40960 [00:54<00:46, 393.12batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22532/40960 [00:54<00:46, 393.12batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22613/40960 [00:54<00:46, 396.14batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22613/40960 [00:54<00:46, 396.14batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22696/40960 [00:55<00:45, 401.12batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  55%|▌| 22696/40960 [00:55<00:45, 401.12batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 22779/40960 [00:55<00:44, 405.22batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 22779/40960 [00:55<00:44, 405.22batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 22861/40960 [00:55<00:44, 406.14batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 22861/40960 [00:55<00:44, 406.14batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 22937/40960 [00:55<00:45, 397.93batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 22937/40960 [00:55<00:45, 397.93batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 23019/40960 [00:55<00:44, 400.17batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 23019/40960 [00:55<00:44, 400.17batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 23097/40960 [00:56<00:45, 395.88batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  56%|▌| 23097/40960 [00:56<00:45, 395.88batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23177/40960 [00:56<00:44, 396.96batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23177/40960 [00:56<00:44, 396.96batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23258/40960 [00:56<00:44, 399.30batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23258/40960 [00:56<00:44, 399.30batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23343/40960 [00:56<00:43, 406.37batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23343/40960 [00:56<00:43, 406.37batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23428/40960 [00:56<00:42, 411.06batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23428/40960 [00:56<00:42, 411.06batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23514/40960 [00:57<00:41, 415.83batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  57%|▌| 23514/40960 [00:57<00:41, 415.83batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  58%|▌| 23600/40960 [00:57<00:41, 419.23batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  58%|▌| 23600/40960 [00:57<00:41, 419.23batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  58%|▌| 23683/40960 [00:57<00:41, 417.65batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  58%|▌| 23683/40960 [00:57<00:41, 417.65batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  58%|▌| 23766/40960 [00:57<00:41, 416.18batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  58%|▌| 23766/40960 [00:57<00:41, 416.18batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  58%|▌| 23852/40960 [00:57<00:40, 419.03batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  58%|▌| 23852/40960 [00:57<00:40, 419.03batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  58%|▌| 23939/40960 [00:58<00:40, 423.17batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  58%|▌| 23939/40960 [00:58<00:40, 423.17batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24014/40960 [00:58<00:41, 407.63batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24014/40960 [00:58<00:41, 407.63batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24093/40960 [00:58<00:41, 402.45batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24093/40960 [00:58<00:41, 402.45batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24176/40960 [00:58<00:41, 405.65batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24176/40960 [00:58<00:41, 405.65batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24260/40960 [00:58<00:40, 409.21batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24260/40960 [00:58<00:40, 409.21batches/s, l2_loss: 0.0300 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|▌| 24345/40960 [00:59<00:40, 413.46batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  59%|▌| 24345/40960 [00:59<00:40, 413.46batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24429/40960 [00:59<00:39, 415.37batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24429/40960 [00:59<00:39, 415.37batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24515/40960 [00:59<00:39, 419.48batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24515/40960 [00:59<00:39, 419.48batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24598/40960 [00:59<00:39, 417.16batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24598/40960 [00:59<00:39, 417.16batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24665/40960 [00:59<00:41, 392.09batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24665/40960 [00:59<00:41, 392.09batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24748/40960 [01:00<00:40, 398.34batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  60%|▌| 24748/40960 [01:00<00:40, 398.34batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 24821/40960 [01:00<00:41, 387.77batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 24821/40960 [01:00<00:41, 387.77batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 24895/40960 [01:00<00:42, 382.41batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 24895/40960 [01:00<00:42, 382.41batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 24979/40960 [01:00<00:40, 392.63batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 24979/40960 [01:00<00:40, 392.63batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 25061/40960 [01:00<00:40, 396.78batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 25061/40960 [01:00<00:40, 396.78batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 25145/40960 [01:01<00:39, 403.33batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  61%|▌| 25145/40960 [01:01<00:39, 403.33batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25226/40960 [01:01<00:39, 403.38batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25226/40960 [01:01<00:39, 403.38batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25310/40960 [01:01<00:38, 407.74batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25310/40960 [01:01<00:38, 407.74batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25396/40960 [01:01<00:37, 411.54batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25396/40960 [01:01<00:37, 411.54batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25476/40960 [01:01<00:38, 406.99batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25476/40960 [01:01<00:38, 406.99batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25559/40960 [01:02<00:37, 409.19batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  62%|▌| 25559/40960 [01:02<00:37, 409.19batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25641/40960 [01:02<00:37, 408.48batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25641/40960 [01:02<00:37, 408.48batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25726/40960 [01:02<00:36, 412.64batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25726/40960 [01:02<00:36, 412.64batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25809/40960 [01:02<00:36, 412.84batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25809/40960 [01:02<00:36, 412.84batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25889/40960 [01:02<00:36, 407.89batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25889/40960 [01:02<00:36, 407.89batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25969/40960 [01:03<00:36, 405.51batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  63%|▋| 25969/40960 [01:03<00:36, 405.51batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26052/40960 [01:03<00:36, 407.93batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26052/40960 [01:03<00:36, 407.93batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26135/40960 [01:03<00:36, 409.09batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26135/40960 [01:03<00:36, 409.09batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26218/40960 [01:03<00:36, 409.27batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26218/40960 [01:03<00:36, 409.27batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26293/40960 [01:03<00:36, 398.76batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26293/40960 [01:03<00:36, 398.76batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26366/40960 [01:04<00:37, 388.26batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  64%|▋| 26366/40960 [01:04<00:37, 388.26batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26440/40960 [01:04<00:37, 382.69batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26440/40960 [01:04<00:37, 382.69batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26505/40960 [01:04<00:39, 364.20batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26505/40960 [01:04<00:39, 364.20batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26574/40960 [01:04<00:40, 357.91batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26574/40960 [01:04<00:40, 357.91batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  65%|▋| 26645/40960 [01:04<00:40, 356.18batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  65%|▋| 26645/40960 [01:04<00:40, 356.18batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26715/40960 [01:05<00:40, 353.65batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26715/40960 [01:05<00:40, 353.65batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26795/40960 [01:05<00:38, 366.70batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  65%|▋| 26795/40960 [01:05<00:38, 366.70batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  66%|▋| 26868/40960 [01:05<00:38, 366.15batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  66%|▋| 26868/40960 [01:05<00:38, 366.15batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  66%|▋| 26938/40960 [01:05<00:38, 360.05batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  66%|▋| 26938/40960 [01:05<00:38, 360.05batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  66%|▋| 27012/40960 [01:05<00:38, 362.08batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  66%|▋| 27012/40960 [01:05<00:38, 362.08batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  66%|▋| 27086/40960 [01:06<00:38, 364.00batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  66%|▋| 27086/40960 [01:06<00:38, 364.00batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  66%|▋| 27165/40960 [01:06<00:37, 372.19batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  66%|▋| 27165/40960 [01:06<00:37, 372.19batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27244/40960 [01:06<00:36, 377.93batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27244/40960 [01:06<00:36, 377.93batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27322/40960 [01:06<00:35, 380.92batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27322/40960 [01:06<00:35, 380.92batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27401/40960 [01:06<00:35, 384.48batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27401/40960 [01:06<00:35, 384.48batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27481/40960 [01:07<00:34, 388.17batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27481/40960 [01:07<00:34, 388.17batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27561/40960 [01:07<00:34, 391.08batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  67%|▋| 27561/40960 [01:07<00:34, 391.08batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  67%|▋| 27635/40960 [01:07<00:34, 384.09batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  67%|▋| 27635/40960 [01:07<00:34, 384.09batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  68%|▋| 27710/40960 [01:07<00:34, 380.02batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  68%|▋| 27710/40960 [01:07<00:34, 380.02batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  68%|▋| 27791/40960 [01:07<00:34, 386.21batches/s, l2_loss: 0.0300 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|▋| 27791/40960 [01:07<00:34, 386.21batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  68%|▋| 27866/40960 [01:08<00:34, 382.39batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  68%|▋| 27866/40960 [01:08<00:34, 382.39batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  68%|▋| 27942/40960 [01:08<00:34, 381.37batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  68%|▋| 27942/40960 [01:08<00:34, 381.37batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  68%|▋| 28024/40960 [01:08<00:33, 388.82batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  68%|▋| 28024/40960 [01:08<00:33, 388.82batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  69%|▋| 28109/40960 [01:08<00:32, 398.34batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  69%|▋| 28109/40960 [01:08<00:32, 398.34batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  69%|▋| 28195/40960 [01:08<00:31, 407.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  69%|▋| 28195/40960 [01:08<00:31, 407.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  69%|▋| 28281/40960 [01:09<00:30, 413.82batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  69%|▋| 28281/40960 [01:09<00:30, 413.82batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  69%|▋| 28363/40960 [01:09<00:30, 410.96batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  69%|▋| 28363/40960 [01:09<00:30, 410.96batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  69%|▋| 28437/40960 [01:09<00:31, 397.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  69%|▋| 28437/40960 [01:09<00:31, 397.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  70%|▋| 28511/40960 [01:09<00:32, 388.30batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  70%|▋| 28511/40960 [01:09<00:32, 388.30batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  70%|▋| 28593/40960 [01:09<00:31, 394.03batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  70%|▋| 28593/40960 [01:09<00:31, 394.03batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  70%|▋| 28674/40960 [01:10<00:31, 395.98batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  70%|▋| 28674/40960 [01:10<00:31, 395.98batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  70%|▋| 28756/40960 [01:10<00:30, 398.90batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  70%|▋| 28756/40960 [01:10<00:30, 398.90batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  70%|▋| 28839/40960 [01:10<00:30, 403.01batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  70%|▋| 28839/40960 [01:10<00:30, 403.01batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  71%|▋| 28924/40960 [01:10<00:29, 409.03batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  71%|▋| 28924/40960 [01:10<00:29, 409.03batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  71%|▋| 29006/40960 [01:10<00:29, 408.66batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  71%|▋| 29006/40960 [01:10<00:29, 408.66batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  71%|▋| 29086/40960 [01:11<00:29, 405.54batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  71%|▋| 29086/40960 [01:11<00:29, 405.54batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  71%|▋| 29172/40960 [01:11<00:28, 411.38batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  71%|▋| 29172/40960 [01:11<00:28, 411.38batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  71%|▋| 29250/40960 [01:11<00:28, 404.61batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  71%|▋| 29250/40960 [01:11<00:28, 404.61batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  72%|▋| 29329/40960 [01:11<00:29, 400.78batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  72%|▋| 29329/40960 [01:11<00:29, 400.78batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  72%|▋| 29410/40960 [01:11<00:28, 401.74batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  72%|▋| 29410/40960 [01:12<00:28, 401.74batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  72%|▋| 29491/40960 [01:12<00:28, 401.99batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  72%|▋| 29491/40960 [01:12<00:28, 401.99batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  72%|▋| 29574/40960 [01:12<00:28, 405.15batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  72%|▋| 29574/40960 [01:12<00:28, 405.15batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  72%|▋| 29657/40960 [01:12<00:27, 408.00batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  72%|▋| 29657/40960 [01:12<00:27, 408.00batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  73%|▋| 29739/40960 [01:12<00:27, 407.28batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  73%|▋| 29739/40960 [01:12<00:27, 407.28batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  73%|▋| 29823/40960 [01:13<00:27, 410.41batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  73%|▋| 29823/40960 [01:13<00:27, 410.41batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  73%|▋| 29907/40960 [01:13<00:26, 411.99batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  73%|▋| 29907/40960 [01:13<00:26, 411.99batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  73%|▋| 29988/40960 [01:13<00:26, 408.76batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  73%|▋| 29988/40960 [01:13<00:26, 408.76batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  73%|▋| 30071/40960 [01:13<00:26, 409.14batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  73%|▋| 30071/40960 [01:13<00:26, 409.14batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  74%|▋| 30153/40960 [01:13<00:26, 408.37batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  74%|▋| 30153/40960 [01:13<00:26, 408.37batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  74%|▋| 30239/40960 [01:14<00:25, 414.08batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  74%|▋| 30239/40960 [01:14<00:25, 414.08batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  74%|▋| 30323/40960 [01:14<00:25, 415.20batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  74%|▋| 30323/40960 [01:14<00:25, 415.20batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  74%|▋| 30404/40960 [01:14<00:25, 410.94batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  74%|▋| 30404/40960 [01:14<00:25, 410.94batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  74%|▋| 30485/40960 [01:14<00:25, 409.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  74%|▋| 30485/40960 [01:14<00:25, 409.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  75%|▋| 30567/40960 [01:14<00:25, 408.03batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  75%|▋| 30567/40960 [01:14<00:25, 408.03batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  75%|▋| 30648/40960 [01:15<00:25, 406.57batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  75%|▋| 30648/40960 [01:15<00:25, 406.57batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  75%|▊| 30731/40960 [01:15<00:25, 408.58batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  75%|▊| 30731/40960 [01:15<00:25, 408.58batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  75%|▊| 30807/40960 [01:15<00:25, 399.62batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  75%|▊| 30807/40960 [01:15<00:25, 399.62batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  75%|▊| 30879/40960 [01:15<00:26, 386.40batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  75%|▊| 30879/40960 [01:15<00:26, 386.40batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  76%|▊| 30955/40960 [01:15<00:26, 384.45batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  76%|▊| 30955/40960 [01:15<00:26, 384.45batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  76%|▊| 31035/40960 [01:16<00:25, 387.69batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  76%|▊| 31035/40960 [01:16<00:25, 387.69batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  76%|▊| 31114/40960 [01:16<00:25, 389.55batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  76%|▊| 31114/40960 [01:16<00:25, 389.55batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  76%|▊| 31193/40960 [01:16<00:24, 390.90batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  76%|▊| 31193/40960 [01:16<00:24, 390.90batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  76%|▊| 31279/40960 [01:16<00:24, 402.33batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  76%|▊| 31279/40960 [01:16<00:24, 402.33batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  77%|▊| 31365/40960 [01:16<00:23, 409.96batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  77%|▊| 31365/40960 [01:16<00:23, 409.96batches/s, l2_loss: 0.0299 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|▊| 31443/40960 [01:17<00:23, 403.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  77%|▊| 31443/40960 [01:17<00:23, 403.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  77%|▊| 31519/40960 [01:17<00:23, 395.79batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  77%|▊| 31519/40960 [01:17<00:23, 395.79batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  77%|▊| 31603/40960 [01:17<00:23, 402.97batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  77%|▊| 31603/40960 [01:17<00:23, 402.97batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  77%|▊| 31687/40960 [01:17<00:22, 407.70batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  77%|▊| 31687/40960 [01:17<00:22, 407.70batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 31767/40960 [01:17<00:22, 404.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 31767/40960 [01:17<00:22, 404.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 31845/40960 [01:18<00:22, 399.89batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 31845/40960 [01:18<00:22, 399.89batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 31921/40960 [01:18<00:22, 393.32batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 31921/40960 [01:18<00:22, 393.32batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 32000/40960 [01:18<00:22, 392.70batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 32000/40960 [01:18<00:22, 392.70batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 32085/40960 [01:18<00:22, 401.14batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  78%|▊| 32085/40960 [01:18<00:22, 401.14batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32171/40960 [01:18<00:21, 408.85batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32171/40960 [01:18<00:21, 408.85batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32257/40960 [01:19<00:20, 414.44batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32257/40960 [01:19<00:20, 414.44batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32339/40960 [01:19<00:20, 412.23batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32339/40960 [01:19<00:20, 412.23batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32419/40960 [01:19<00:20, 407.78batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32419/40960 [01:19<00:20, 407.78batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32497/40960 [01:19<00:21, 401.25batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  79%|▊| 32497/40960 [01:19<00:21, 401.25batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32580/40960 [01:19<00:20, 404.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32580/40960 [01:19<00:20, 404.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32661/40960 [01:20<00:20, 403.78batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32661/40960 [01:20<00:20, 403.78batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32741/40960 [01:20<00:20, 401.84batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32741/40960 [01:20<00:20, 401.84batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32812/40960 [01:20<00:21, 387.43batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32812/40960 [01:20<00:21, 387.43batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32888/40960 [01:20<00:21, 384.23batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32888/40960 [01:20<00:21, 384.23batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32970/40960 [01:20<00:20, 391.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  80%|▊| 32970/40960 [01:20<00:20, 391.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  81%|▊| 33050/40960 [01:21<00:20, 392.89batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  81%|▊| 33050/40960 [01:21<00:20, 392.89batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  81%|▊| 33132/40960 [01:21<00:19, 397.44batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  81%|▊| 33132/40960 [01:21<00:19, 397.44batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  81%|▊| 33216/40960 [01:21<00:19, 403.77batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  81%|▊| 33216/40960 [01:21<00:19, 403.77batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  81%|▊| 33301/40960 [01:21<00:18, 409.72batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  81%|▊| 33301/40960 [01:21<00:18, 409.72batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  81%|▊| 33381/40960 [01:21<00:18, 405.95batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  81%|▊| 33381/40960 [01:21<00:18, 405.95batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33458/40960 [01:22<00:18, 398.14batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33458/40960 [01:22<00:18, 398.14batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33528/40960 [01:22<00:19, 382.86batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33528/40960 [01:22<00:19, 382.86batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33606/40960 [01:22<00:19, 384.83batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33606/40960 [01:22<00:19, 384.83batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33687/40960 [01:22<00:18, 389.66batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33687/40960 [01:22<00:18, 389.66batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33759/40960 [01:22<00:18, 380.65batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  82%|▊| 33759/40960 [01:22<00:18, 380.65batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  83%|▊| 33839/40960 [01:23<00:18, 385.55batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  83%|▊| 33839/40960 [01:23<00:18, 385.55batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  83%|▊| 33911/40960 [01:23<00:18, 377.39batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  83%|▊| 33911/40960 [01:23<00:18, 377.39batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  83%|▊| 33985/40960 [01:23<00:18, 374.24batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  83%|▊| 33985/40960 [01:23<00:18, 374.24batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  83%|▊| 34064/40960 [01:23<00:18, 380.33batches/s, l2_loss: 0.0300 - round_los\u001b[A\n",
      "Training:  83%|▊| 34064/40960 [01:23<00:18, 380.33batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  83%|▊| 34144/40960 [01:23<00:17, 385.56batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  83%|▊| 34144/40960 [01:23<00:17, 385.56batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34223/40960 [01:24<00:17, 388.19batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34223/40960 [01:24<00:17, 388.19batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34294/40960 [01:24<00:17, 377.28batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34294/40960 [01:24<00:17, 377.28batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34362/40960 [01:24<00:18, 365.90batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34362/40960 [01:24<00:18, 365.90batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34427/40960 [01:24<00:18, 353.66batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34427/40960 [01:24<00:18, 353.66batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34490/40960 [01:24<00:18, 340.58batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34490/40960 [01:24<00:18, 340.58batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34555/40960 [01:25<00:19, 334.82batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  84%|▊| 34555/40960 [01:25<00:19, 334.82batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34635/40960 [01:25<00:17, 353.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34635/40960 [01:25<00:17, 353.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34718/40960 [01:25<00:16, 370.84batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34718/40960 [01:25<00:16, 370.84batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34788/40960 [01:25<00:16, 363.85batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34788/40960 [01:25<00:16, 363.85batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34869/40960 [01:25<00:16, 375.17batches/s, l2_loss: 0.0299 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34869/40960 [01:25<00:16, 375.17batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34946/40960 [01:26<00:15, 377.95batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  85%|▊| 34946/40960 [01:26<00:15, 377.95batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35030/40960 [01:26<00:15, 390.18batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35030/40960 [01:26<00:15, 390.18batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35111/40960 [01:26<00:14, 393.07batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35111/40960 [01:26<00:14, 393.07batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35192/40960 [01:26<00:14, 395.68batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35192/40960 [01:26<00:14, 395.68batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35275/40960 [01:26<00:14, 400.70batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35275/40960 [01:26<00:14, 400.70batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35356/40960 [01:27<00:13, 401.72batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  86%|▊| 35356/40960 [01:27<00:13, 401.72batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35438/40960 [01:27<00:13, 403.17batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35438/40960 [01:27<00:13, 403.17batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35521/40960 [01:27<00:13, 406.59batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35521/40960 [01:27<00:13, 406.59batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35602/40960 [01:27<00:13, 405.93batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35602/40960 [01:27<00:13, 405.93batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35684/40960 [01:27<00:12, 406.10batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35684/40960 [01:27<00:12, 406.10batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35768/40960 [01:28<00:12, 409.18batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  87%|▊| 35768/40960 [01:28<00:12, 409.18batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 35850/40960 [01:28<00:12, 409.09batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 35850/40960 [01:28<00:12, 409.09batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 35929/40960 [01:28<00:12, 404.74batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 35929/40960 [01:28<00:12, 404.74batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 36010/40960 [01:28<00:12, 404.79batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 36010/40960 [01:28<00:12, 404.79batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 36088/40960 [01:28<00:12, 398.98batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 36088/40960 [01:28<00:12, 398.98batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 36169/40960 [01:29<00:12, 399.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  88%|▉| 36169/40960 [01:29<00:12, 399.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36252/40960 [01:29<00:11, 403.72batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36252/40960 [01:29<00:11, 403.72batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36334/40960 [01:29<00:11, 405.23batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36334/40960 [01:29<00:11, 405.23batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36413/40960 [01:29<00:11, 401.47batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36413/40960 [01:29<00:11, 401.47batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36493/40960 [01:29<00:11, 399.95batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36493/40960 [01:29<00:11, 399.95batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36577/40960 [01:30<00:10, 404.59batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  89%|▉| 36577/40960 [01:30<00:10, 404.59batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36661/40960 [01:30<00:10, 407.68batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36661/40960 [01:30<00:10, 407.68batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36746/40960 [01:30<00:10, 412.59batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36746/40960 [01:30<00:10, 412.59batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36828/40960 [01:30<00:10, 410.85batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36828/40960 [01:30<00:10, 410.85batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36911/40960 [01:30<00:09, 411.41batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36911/40960 [01:30<00:09, 411.41batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36990/40960 [01:31<00:09, 406.49batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  90%|▉| 36990/40960 [01:31<00:09, 406.49batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37072/40960 [01:31<00:09, 406.43batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37072/40960 [01:31<00:09, 406.43batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37155/40960 [01:31<00:09, 408.18batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37155/40960 [01:31<00:09, 408.18batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37240/40960 [01:31<00:09, 411.84batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37240/40960 [01:31<00:09, 411.84batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37322/40960 [01:31<00:08, 410.19batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37322/40960 [01:31<00:08, 410.19batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37406/40960 [01:32<00:08, 412.71batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  91%|▉| 37406/40960 [01:32<00:08, 412.71batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37489/40960 [01:32<00:08, 413.36batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37489/40960 [01:32<00:08, 413.36batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37570/40960 [01:32<00:08, 410.59batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37570/40960 [01:32<00:08, 410.59batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37654/40960 [01:32<00:08, 412.34batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37654/40960 [01:32<00:08, 412.34batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37737/40960 [01:32<00:07, 412.82batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37737/40960 [01:32<00:07, 412.82batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37823/40960 [01:33<00:07, 417.64batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  92%|▉| 37823/40960 [01:33<00:07, 417.64batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 37906/40960 [01:33<00:07, 416.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 37906/40960 [01:33<00:07, 416.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 37989/40960 [01:33<00:07, 415.33batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 37989/40960 [01:33<00:07, 415.33batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 38072/40960 [01:33<00:06, 414.96batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 38072/40960 [01:33<00:06, 414.96batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 38159/40960 [01:33<00:06, 419.67batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 38159/40960 [01:33<00:06, 419.67batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 38238/40960 [01:34<00:06, 412.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  93%|▉| 38238/40960 [01:34<00:06, 412.11batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38322/40960 [01:34<00:06, 414.08batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38322/40960 [01:34<00:06, 414.08batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38408/40960 [01:34<00:06, 418.08batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38408/40960 [01:34<00:06, 418.08batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38491/40960 [01:34<00:05, 416.24batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38491/40960 [01:34<00:05, 416.24batches/s, l2_loss: 0.0299 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|▉| 38567/40960 [01:34<00:05, 403.93batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38567/40960 [01:34<00:05, 403.93batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38642/40960 [01:35<00:05, 394.28batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  94%|▉| 38642/40960 [01:35<00:05, 394.28batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 38723/40960 [01:35<00:05, 397.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 38723/40960 [01:35<00:05, 397.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 38803/40960 [01:35<00:05, 397.61batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 38803/40960 [01:35<00:05, 397.61batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 38886/40960 [01:35<00:05, 402.67batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 38886/40960 [01:35<00:05, 402.67batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 38972/40960 [01:35<00:04, 409.40batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 38972/40960 [01:35<00:04, 409.40batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 39058/40960 [01:36<00:04, 415.02batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  95%|▉| 39058/40960 [01:36<00:04, 415.02batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39141/40960 [01:36<00:04, 414.52batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39141/40960 [01:36<00:04, 414.52batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39222/40960 [01:36<00:04, 410.19batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39222/40960 [01:36<00:04, 410.19batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39307/40960 [01:36<00:03, 413.46batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39307/40960 [01:36<00:03, 413.46batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39390/40960 [01:36<00:03, 413.12batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39390/40960 [01:36<00:03, 413.12batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39476/40960 [01:37<00:03, 416.84batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  96%|▉| 39476/40960 [01:37<00:03, 416.84batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39561/40960 [01:37<00:03, 418.70batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39561/40960 [01:37<00:03, 418.70batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39643/40960 [01:37<00:03, 415.79batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39643/40960 [01:37<00:03, 415.79batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39726/40960 [01:37<00:02, 414.91batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39726/40960 [01:37<00:02, 414.91batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39810/40960 [01:37<00:02, 415.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39810/40960 [01:37<00:02, 415.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39895/40960 [01:38<00:02, 417.42batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  97%|▉| 39895/40960 [01:38<00:02, 417.42batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 39980/40960 [01:38<00:02, 418.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 39980/40960 [01:38<00:02, 418.48batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 40066/40960 [01:38<00:02, 421.74batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 40066/40960 [01:38<00:02, 421.74batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 40150/40960 [01:38<00:01, 420.52batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 40150/40960 [01:38<00:01, 420.52batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 40233/40960 [01:38<00:01, 418.14batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 40233/40960 [01:38<00:01, 418.14batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 40318/40960 [01:39<00:01, 419.73batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  98%|▉| 40318/40960 [01:39<00:01, 419.73batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40403/40960 [01:39<00:01, 421.00batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40403/40960 [01:39<00:01, 421.00batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40482/40960 [01:39<00:01, 412.38batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40482/40960 [01:39<00:01, 412.38batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40559/40960 [01:39<00:00, 403.29batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40559/40960 [01:39<00:00, 403.29batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40641/40960 [01:39<00:00, 404.15batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40641/40960 [01:39<00:00, 404.15batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40725/40960 [01:40<00:00, 408.13batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training:  99%|▉| 40725/40960 [01:40<00:00, 408.13batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training: 100%|▉| 40811/40960 [01:40<00:00, 413.19batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training: 100%|▉| 40811/40960 [01:40<00:00, 413.19batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training: 100%|▉| 40895/40960 [01:40<00:00, 415.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "Training: 100%|▉| 40895/40960 [01:40<00:00, 415.06batches/s, l2_loss: 0.0299 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:13:43.703427: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  46%|▍| 12/26 [24:22<30:47, 131.97s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:13:44.977125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:13:48.852511: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<14:44:56,  1.30s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<14:44:56,  1.30s/batches, l2_loss: 0.3585 - round_loss:\u001b[A\n",
      "Training:   0%| | 71/40960 [00:01<10:40, 63.80batches/s, l2_loss: 0.3585 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 71/40960 [00:01<10:40, 63.80batches/s, l2_loss: 0.0761 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 144/40960 [00:01<05:25, 125.40batches/s, l2_loss: 0.0761 - round_loss:\u001b[A\n",
      "Training:   0%| | 144/40960 [00:01<05:25, 125.40batches/s, l2_loss: 0.0683 - round_loss:\u001b[A\n",
      "Training:   1%| | 218/40960 [00:01<03:45, 180.58batches/s, l2_loss: 0.0683 - round_loss:\u001b[A\n",
      "Training:   1%| | 218/40960 [00:01<03:45, 180.58batches/s, l2_loss: 0.0700 - round_loss:\u001b[A\n",
      "Training:   1%| | 289/40960 [00:02<03:02, 222.40batches/s, l2_loss: 0.0700 - round_loss:\u001b[A\n",
      "Training:   1%| | 289/40960 [00:02<03:02, 222.40batches/s, l2_loss: 0.0722 - round_loss:\u001b[A\n",
      "Training:   1%| | 359/40960 [00:02<02:39, 254.93batches/s, l2_loss: 0.0722 - round_loss:\u001b[A\n",
      "Training:   1%| | 359/40960 [00:02<02:39, 254.93batches/s, l2_loss: 0.0711 - round_loss:\u001b[A\n",
      "Training:   1%| | 431/40960 [00:02<02:23, 282.65batches/s, l2_loss: 0.0711 - round_loss:\u001b[A\n",
      "Training:   1%| | 431/40960 [00:02<02:23, 282.65batches/s, l2_loss: 0.0697 - round_loss:\u001b[A\n",
      "Training:   1%| | 512/40960 [00:02<02:07, 316.10batches/s, l2_loss: 0.0697 - round_loss:\u001b[A\n",
      "Training:   1%| | 512/40960 [00:02<02:07, 316.10batches/s, l2_loss: 0.0697 - round_loss:\u001b[A\n",
      "Training:   1%| | 592/40960 [00:02<01:58, 339.37batches/s, l2_loss: 0.0697 - round_loss:\u001b[A\n",
      "Training:   1%| | 592/40960 [00:02<01:58, 339.37batches/s, l2_loss: 0.0692 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%| | 674/40960 [00:03<01:52, 358.97batches/s, l2_loss: 0.0692 - round_loss:\u001b[A\n",
      "Training:   2%| | 674/40960 [00:03<01:52, 358.97batches/s, l2_loss: 0.0695 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:03<01:50, 363.34batches/s, l2_loss: 0.0695 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:03<01:50, 363.34batches/s, l2_loss: 0.0702 - round_loss:\u001b[A\n",
      "Training:   2%| | 828/40960 [00:03<01:47, 372.24batches/s, l2_loss: 0.0702 - round_loss:\u001b[A\n",
      "Training:   2%| | 828/40960 [00:03<01:47, 372.24batches/s, l2_loss: 0.0680 - round_loss:\u001b[A\n",
      "Training:   2%| | 906/40960 [00:03<01:46, 376.91batches/s, l2_loss: 0.0680 - round_loss:\u001b[A\n",
      "Training:   2%| | 906/40960 [00:03<01:46, 376.91batches/s, l2_loss: 0.0694 - round_loss:\u001b[A\n",
      "Training:   2%| | 985/40960 [00:03<01:44, 381.54batches/s, l2_loss: 0.0694 - round_loss:\u001b[A\n",
      "Training:   2%| | 985/40960 [00:03<01:44, 381.54batches/s, l2_loss: 0.0693 - round_loss:\u001b[A\n",
      "Training:   3%| | 1066/40960 [00:04<01:42, 388.20batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   3%| | 1066/40960 [00:04<01:42, 388.20batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   3%| | 1149/40960 [00:04<01:40, 395.60batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   3%| | 1149/40960 [00:04<01:40, 395.60batches/s, l2_loss: 0.0696 - round_loss\u001b[A\n",
      "Training:   3%| | 1228/40960 [00:04<01:40, 395.34batches/s, l2_loss: 0.0696 - round_loss\u001b[A\n",
      "Training:   3%| | 1228/40960 [00:04<01:40, 395.34batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   3%| | 1305/40960 [00:04<01:41, 391.22batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   3%| | 1305/40960 [00:04<01:41, 391.22batches/s, l2_loss: 0.0695 - round_loss\u001b[A\n",
      "Training:   3%| | 1386/40960 [00:04<01:40, 394.78batches/s, l2_loss: 0.0695 - round_loss\u001b[A\n",
      "Training:   3%| | 1386/40960 [00:04<01:40, 394.78batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   4%| | 1469/40960 [00:05<01:38, 400.27batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   4%| | 1469/40960 [00:05<01:38, 400.27batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:   4%| | 1550/40960 [00:05<01:38, 401.54batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:   4%| | 1550/40960 [00:05<01:38, 401.54batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   4%| | 1630/40960 [00:05<01:38, 400.84batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   4%| | 1630/40960 [00:05<01:38, 400.84batches/s, l2_loss: 0.0698 - round_loss\u001b[A\n",
      "Training:   4%| | 1711/40960 [00:05<01:38, 400.37batches/s, l2_loss: 0.0698 - round_loss\u001b[A\n",
      "Training:   4%| | 1711/40960 [00:05<01:38, 400.37batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:   4%| | 1792/40960 [00:05<01:37, 400.87batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:   4%| | 1792/40960 [00:05<01:37, 400.87batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   5%| | 1866/40960 [00:06<01:40, 390.25batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   5%| | 1866/40960 [00:06<01:40, 390.25batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:   5%| | 1936/40960 [00:06<01:43, 378.08batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:   5%| | 1936/40960 [00:06<01:43, 378.08batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   5%| | 2006/40960 [00:06<01:45, 369.21batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   5%| | 2006/40960 [00:06<01:45, 369.21batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:   5%| | 2083/40960 [00:06<01:44, 373.78batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:   5%| | 2083/40960 [00:06<01:44, 373.78batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   5%| | 2166/40960 [00:06<01:40, 385.97batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   5%| | 2166/40960 [00:06<01:40, 385.97batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:   5%| | 2247/40960 [00:07<01:39, 390.18batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:   5%| | 2247/40960 [00:07<01:39, 390.18batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   6%| | 2331/40960 [00:07<01:36, 398.32batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   6%| | 2331/40960 [00:07<01:36, 398.32batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   6%| | 2410/40960 [00:07<01:37, 397.15batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   6%| | 2410/40960 [00:07<01:37, 397.15batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   6%| | 2484/40960 [00:07<01:38, 388.83batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   6%| | 2484/40960 [00:07<01:38, 388.83batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   6%| | 2561/40960 [00:07<01:39, 386.79batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   6%| | 2561/40960 [00:07<01:39, 386.79batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   6%| | 2641/40960 [00:08<01:38, 389.91batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   6%| | 2641/40960 [00:08<01:38, 389.91batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   7%| | 2722/40960 [00:08<01:37, 393.71batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   7%| | 2722/40960 [00:08<01:37, 393.71batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   7%| | 2806/40960 [00:08<01:35, 400.19batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   7%| | 2806/40960 [00:08<01:35, 400.19batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:   7%| | 2889/40960 [00:08<01:34, 404.04batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:   7%| | 2889/40960 [00:08<01:34, 404.04batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   7%| | 2971/40960 [00:08<01:33, 404.73batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   7%| | 2971/40960 [00:08<01:33, 404.73batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   7%| | 3040/40960 [00:09<01:38, 385.08batches/s, l2_loss: 0.0693 - round_loss\u001b[A\n",
      "Training:   7%| | 3040/40960 [00:09<01:38, 385.08batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:   8%| | 3118/40960 [00:09<01:37, 386.33batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:   8%| | 3118/40960 [00:09<01:37, 386.33batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:   8%| | 3198/40960 [00:09<01:36, 390.31batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:   8%| | 3198/40960 [00:09<01:36, 390.31batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:   8%| | 3272/40960 [00:09<01:38, 383.22batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:   8%| | 3272/40960 [00:09<01:38, 383.22batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   8%| | 3344/40960 [00:09<01:40, 375.63batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   8%| | 3344/40960 [00:09<01:40, 375.63batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   8%| | 3416/40960 [00:10<01:41, 370.21batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   8%| | 3416/40960 [00:10<01:41, 370.21batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   9%| | 3492/40960 [00:10<01:40, 372.84batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   9%| | 3492/40960 [00:10<01:40, 372.84batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   9%| | 3571/40960 [00:10<01:38, 378.29batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   9%| | 3571/40960 [00:10<01:38, 378.29batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   9%| | 3651/40960 [00:10<01:37, 384.19batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   9%| | 3651/40960 [00:10<01:37, 384.19batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   9%| | 3728/40960 [00:10<01:36, 384.00batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   9%| | 3728/40960 [00:10<01:36, 384.00batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   9%| | 3803/40960 [00:11<01:37, 379.95batches/s, l2_loss: 0.0691 - round_loss\u001b[A\n",
      "Training:   9%| | 3803/40960 [00:11<01:37, 379.95batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   9%| | 3876/40960 [00:11<01:39, 374.30batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:   9%| | 3876/40960 [00:11<01:39, 374.30batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:  10%| | 3945/40960 [00:11<01:41, 364.96batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:  10%| | 3945/40960 [00:11<01:41, 364.96batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:  10%| | 4007/40960 [00:11<01:46, 348.36batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:  10%| | 4007/40960 [00:11<01:46, 348.36batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:  10%| | 4068/40960 [00:11<01:50, 334.21batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 4068/40960 [00:11<01:50, 334.21batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:  10%| | 4130/40960 [00:12<01:52, 326.61batches/s, l2_loss: 0.0690 - round_loss\u001b[A\n",
      "Training:  10%| | 4130/40960 [00:12<01:52, 326.61batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  10%| | 4207/40960 [00:12<01:47, 343.25batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  10%| | 4207/40960 [00:12<01:47, 343.25batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  10%| | 4278/40960 [00:12<01:46, 345.59batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  10%| | 4278/40960 [00:12<01:46, 345.59batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  11%| | 4351/40960 [00:12<01:44, 350.90batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  11%| | 4351/40960 [00:12<01:44, 350.90batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  11%| | 4425/40960 [00:12<01:42, 355.63batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  11%| | 4425/40960 [00:12<01:42, 355.63batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  11%| | 4505/40960 [00:13<01:38, 368.33batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  11%| | 4505/40960 [00:13<01:38, 368.33batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  11%| | 4586/40960 [00:13<01:36, 378.02batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  11%| | 4586/40960 [00:13<01:36, 378.02batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  11%| | 4656/40960 [00:13<01:38, 368.86batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  11%| | 4656/40960 [00:13<01:38, 368.86batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  12%| | 4732/40960 [00:13<01:37, 371.90batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  12%| | 4732/40960 [00:13<01:37, 371.90batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  12%| | 4813/40960 [00:13<01:34, 381.31batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  12%| | 4813/40960 [00:13<01:34, 381.31batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  12%| | 4889/40960 [00:14<01:34, 379.80batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  12%| | 4889/40960 [00:14<01:34, 379.80batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  12%| | 4960/40960 [00:14<01:36, 371.85batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  12%| | 4960/40960 [00:14<01:36, 371.85batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  12%| | 5036/40960 [00:14<01:36, 373.13batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  12%| | 5036/40960 [00:14<01:36, 373.13batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  12%| | 5114/40960 [00:14<01:34, 378.09batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  12%| | 5114/40960 [00:14<01:34, 378.09batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5195/40960 [00:14<01:32, 385.80batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5195/40960 [00:14<01:32, 385.80batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5275/40960 [00:15<01:31, 389.52batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5275/40960 [00:15<01:31, 389.52batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5358/40960 [00:15<01:29, 395.97batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5358/40960 [00:15<01:29, 395.97batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5440/40960 [00:15<01:28, 399.62batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5440/40960 [00:15<01:28, 399.62batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5521/40960 [00:15<01:28, 400.00batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5521/40960 [00:15<01:28, 400.00batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5600/40960 [00:15<01:28, 397.44batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5600/40960 [00:15<01:28, 397.44batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5673/40960 [00:16<01:31, 386.77batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5673/40960 [00:16<01:31, 386.77batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5742/40960 [00:16<01:34, 374.05batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5742/40960 [00:16<01:34, 374.05batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5822/40960 [00:16<01:32, 381.34batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5822/40960 [00:16<01:32, 381.34batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5900/40960 [00:16<01:31, 383.73batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5900/40960 [00:16<01:31, 383.73batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5978/40960 [00:16<01:30, 384.83batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5978/40960 [00:16<01:30, 384.83batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6053/40960 [00:17<01:31, 380.64batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6053/40960 [00:17<01:31, 380.64batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6128/40960 [00:17<01:32, 377.62batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6128/40960 [00:17<01:32, 377.62batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6200/40960 [00:17<01:33, 371.01batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6200/40960 [00:17<01:33, 371.01batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6270/40960 [00:17<01:35, 363.83batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6270/40960 [00:17<01:35, 363.83batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6349/40960 [00:18<01:32, 372.61batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6349/40960 [00:18<01:32, 372.61batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6432/40960 [00:18<01:29, 384.24batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6432/40960 [00:18<01:29, 384.24batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6511/40960 [00:18<01:28, 387.32batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6511/40960 [00:18<01:28, 387.32batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6582/40960 [00:18<01:31, 376.64batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6582/40960 [00:18<01:31, 376.64batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6653/40960 [00:18<01:32, 369.62batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6653/40960 [00:18<01:32, 369.62batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6732/40960 [00:19<01:30, 377.11batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6732/40960 [00:19<01:30, 377.11batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6809/40960 [00:19<01:30, 379.32batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6809/40960 [00:19<01:30, 379.32batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6886/40960 [00:19<01:29, 380.38batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6886/40960 [00:19<01:29, 380.38batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6966/40960 [00:19<01:28, 384.88batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6966/40960 [00:19<01:28, 384.88batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7045/40960 [00:19<01:27, 387.20batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7045/40960 [00:19<01:27, 387.20batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7124/40960 [00:20<01:26, 389.12batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7124/40960 [00:20<01:26, 389.12batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7200/40960 [00:20<01:27, 386.15batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7200/40960 [00:20<01:27, 386.15batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7279/40960 [00:20<01:26, 388.62batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7279/40960 [00:20<01:26, 388.62batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7357/40960 [00:20<01:26, 388.99batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7357/40960 [00:20<01:26, 388.99batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7438/40960 [00:20<01:25, 392.57batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7438/40960 [00:20<01:25, 392.57batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|▏| 7511/40960 [00:21<01:27, 383.32batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7511/40960 [00:21<01:27, 383.32batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7585/40960 [00:21<01:28, 378.85batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7585/40960 [00:21<01:28, 378.85batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7660/40960 [00:21<01:28, 376.62batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7660/40960 [00:21<01:28, 376.62batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7731/40960 [00:21<01:29, 369.84batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7731/40960 [00:21<01:29, 369.84batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7807/40960 [00:21<01:28, 372.80batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7807/40960 [00:21<01:28, 372.80batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7887/40960 [00:22<01:26, 380.20batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7887/40960 [00:22<01:26, 380.20batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7963/40960 [00:22<01:26, 380.05batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7963/40960 [00:22<01:26, 380.05batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8044/40960 [00:22<01:25, 386.77batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8044/40960 [00:22<01:25, 386.77batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8126/40960 [00:22<01:23, 392.47batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8126/40960 [00:22<01:23, 392.47batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8200/40960 [00:22<01:25, 384.43batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8200/40960 [00:22<01:25, 384.43batches/s, l2_loss: 0.0474 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8264/40960 [00:23<01:29, 365.18batches/s, l2_loss: 0.0474 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8264/40960 [00:23<01:29, 365.18batches/s, l2_loss: 0.0586 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8335/40960 [00:23<01:30, 361.50batches/s, l2_loss: 0.0586 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8335/40960 [00:23<01:30, 361.50batches/s, l2_loss: 0.0662 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8402/40960 [00:23<01:32, 352.80batches/s, l2_loss: 0.0662 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8402/40960 [00:23<01:32, 352.80batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8468/40960 [00:23<01:33, 345.90batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8468/40960 [00:23<01:33, 345.90batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8541/40960 [00:23<01:32, 350.36batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8541/40960 [00:23<01:32, 350.36batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8613/40960 [00:24<01:31, 352.47batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8613/40960 [00:24<01:31, 352.47batches/s, l2_loss: 0.0669 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8683/40960 [00:24<01:31, 351.51batches/s, l2_loss: 0.0669 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8683/40960 [00:24<01:31, 351.51batches/s, l2_loss: 0.0671 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8755/40960 [00:24<01:30, 353.93batches/s, l2_loss: 0.0671 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8755/40960 [00:24<01:30, 353.93batches/s, l2_loss: 0.0666 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8828/40960 [00:24<01:30, 356.30batches/s, l2_loss: 0.0666 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8828/40960 [00:24<01:30, 356.30batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8897/40960 [00:24<01:30, 352.83batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8897/40960 [00:24<01:30, 352.83batches/s, l2_loss: 0.0671 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8969/40960 [00:25<01:30, 353.89batches/s, l2_loss: 0.0671 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8969/40960 [00:25<01:30, 353.89batches/s, l2_loss: 0.0674 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9038/40960 [00:25<01:30, 350.82batches/s, l2_loss: 0.0674 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9038/40960 [00:25<01:30, 350.82batches/s, l2_loss: 0.0665 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9110/40960 [00:25<01:30, 352.48batches/s, l2_loss: 0.0665 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9110/40960 [00:25<01:30, 352.48batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9181/40960 [00:25<01:29, 353.18batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9181/40960 [00:25<01:29, 353.18batches/s, l2_loss: 0.0668 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9256/40960 [00:25<01:28, 359.49batches/s, l2_loss: 0.0668 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9256/40960 [00:25<01:28, 359.49batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9324/40960 [00:26<01:29, 352.71batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9324/40960 [00:26<01:29, 352.71batches/s, l2_loss: 0.0681 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9390/40960 [00:26<01:31, 345.40batches/s, l2_loss: 0.0681 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9390/40960 [00:26<01:31, 345.40batches/s, l2_loss: 0.0672 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9456/40960 [00:26<01:32, 340.22batches/s, l2_loss: 0.0672 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9456/40960 [00:26<01:32, 340.22batches/s, l2_loss: 0.0670 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9521/40960 [00:26<01:33, 334.77batches/s, l2_loss: 0.0670 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9521/40960 [00:26<01:33, 334.77batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9588/40960 [00:26<01:33, 333.97batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9588/40960 [00:26<01:33, 333.97batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9655/40960 [00:27<01:33, 334.26batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9655/40960 [00:27<01:33, 334.26batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9720/40960 [00:27<01:34, 330.37batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9720/40960 [00:27<01:34, 330.37batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9788/40960 [00:27<01:33, 332.11batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9788/40960 [00:27<01:33, 332.11batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9854/40960 [00:27<01:33, 331.34batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9854/40960 [00:27<01:33, 331.34batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9915/40960 [00:27<01:36, 322.38batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9915/40960 [00:27<01:36, 322.38batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9974/40960 [00:28<01:39, 312.84batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9974/40960 [00:28<01:39, 312.84batches/s, l2_loss: 0.0673 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10043/40960 [00:28<01:36, 321.15batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  25%|▏| 10043/40960 [00:28<01:36, 321.15batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  25%|▏| 10120/40960 [00:28<01:30, 339.15batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  25%|▏| 10120/40960 [00:28<01:30, 339.15batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  25%|▏| 10193/40960 [00:28<01:28, 345.91batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  25%|▏| 10193/40960 [00:28<01:28, 345.91batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  25%|▎| 10266/40960 [00:28<01:27, 351.09batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  25%|▎| 10266/40960 [00:28<01:27, 351.09batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  25%|▎| 10338/40960 [00:29<01:26, 353.23batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  25%|▎| 10338/40960 [00:29<01:26, 353.23batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  25%|▎| 10411/40960 [00:29<01:25, 356.63batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  25%|▎| 10411/40960 [00:29<01:25, 356.63batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  26%|▎| 10480/40960 [00:29<01:26, 353.07batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  26%|▎| 10480/40960 [00:29<01:26, 353.07batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  26%|▎| 10547/40960 [00:29<01:27, 346.28batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  26%|▎| 10547/40960 [00:29<01:27, 346.28batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  26%|▎| 10615/40960 [00:29<01:28, 344.02batches/s, l2_loss: 0.0673 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10615/40960 [00:29<01:28, 344.02batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  26%|▎| 10685/40960 [00:30<01:27, 345.59batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  26%|▎| 10685/40960 [00:30<01:27, 345.59batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  26%|▎| 10754/40960 [00:30<01:27, 344.16batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  26%|▎| 10754/40960 [00:30<01:27, 344.16batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  26%|▎| 10824/40960 [00:30<01:27, 345.03batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  26%|▎| 10824/40960 [00:30<01:27, 345.03batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  27%|▎| 10889/40960 [00:30<01:28, 339.01batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  27%|▎| 10889/40960 [00:30<01:28, 339.01batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  27%|▎| 10956/40960 [00:30<01:29, 336.83batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  27%|▎| 10956/40960 [00:30<01:29, 336.83batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  27%|▎| 11027/40960 [00:31<01:27, 341.13batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  27%|▎| 11027/40960 [00:31<01:27, 341.13batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  27%|▎| 11100/40960 [00:31<01:26, 346.96batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  27%|▎| 11100/40960 [00:31<01:26, 346.96batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  27%|▎| 11171/40960 [00:31<01:25, 347.91batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  27%|▎| 11171/40960 [00:31<01:25, 347.91batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  27%|▎| 11241/40960 [00:31<01:25, 347.04batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  27%|▎| 11241/40960 [00:31<01:25, 347.04batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  28%|▎| 11313/40960 [00:31<01:24, 350.76batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  28%|▎| 11313/40960 [00:31<01:24, 350.76batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  28%|▎| 11379/40960 [00:32<01:25, 344.08batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  28%|▎| 11379/40960 [00:32<01:25, 344.08batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  28%|▎| 11429/40960 [00:32<01:33, 315.21batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  28%|▎| 11429/40960 [00:32<01:33, 315.21batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  28%|▎| 11501/40960 [00:32<01:29, 327.50batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  28%|▎| 11501/40960 [00:32<01:29, 327.50batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  28%|▎| 11573/40960 [00:32<01:27, 336.36batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  28%|▎| 11573/40960 [00:32<01:27, 336.36batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  28%|▎| 11646/40960 [00:32<01:25, 344.05batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  28%|▎| 11646/40960 [00:32<01:25, 344.05batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 11712/40960 [00:33<01:26, 338.93batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 11712/40960 [00:33<01:26, 338.93batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  29%|▎| 11782/40960 [00:33<01:25, 341.69batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  29%|▎| 11782/40960 [00:33<01:25, 341.69batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 11854/40960 [00:33<01:23, 346.65batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 11854/40960 [00:33<01:23, 346.65batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  29%|▎| 11929/40960 [00:33<01:22, 353.77batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  29%|▎| 11929/40960 [00:33<01:22, 353.77batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  29%|▎| 11997/40960 [00:33<01:22, 349.04batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  29%|▎| 11997/40960 [00:33<01:22, 349.04batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  29%|▎| 12067/40960 [00:34<01:22, 348.29batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  29%|▎| 12067/40960 [00:34<01:22, 348.29batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  30%|▎| 12138/40960 [00:34<01:22, 349.52batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  30%|▎| 12138/40960 [00:34<01:22, 349.52batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  30%|▎| 12213/40960 [00:34<01:20, 355.99batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  30%|▎| 12213/40960 [00:34<01:20, 355.99batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  30%|▎| 12287/40960 [00:34<01:19, 359.41batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  30%|▎| 12287/40960 [00:34<01:19, 359.41batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  30%|▎| 12360/40960 [00:34<01:19, 360.41batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  30%|▎| 12360/40960 [00:34<01:19, 360.41batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  30%|▎| 12434/40960 [00:35<01:18, 362.08batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  30%|▎| 12434/40960 [00:35<01:18, 362.08batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  31%|▎| 12508/40960 [00:35<01:18, 363.92batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  31%|▎| 12508/40960 [00:35<01:18, 363.92batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  31%|▎| 12583/40960 [00:35<01:17, 367.16batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  31%|▎| 12583/40960 [00:35<01:17, 367.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  31%|▎| 12657/40960 [00:35<01:17, 367.00batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  31%|▎| 12657/40960 [00:35<01:17, 367.00batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  31%|▎| 12732/40960 [00:35<01:16, 369.00batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  31%|▎| 12732/40960 [00:35<01:16, 369.00batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  31%|▎| 12806/40960 [00:36<01:16, 368.94batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  31%|▎| 12806/40960 [00:36<01:16, 368.94batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  31%|▎| 12879/40960 [00:36<01:16, 367.62batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  31%|▎| 12879/40960 [00:36<01:16, 367.62batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  32%|▎| 12950/40960 [00:36<01:17, 362.46batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  32%|▎| 12950/40960 [00:36<01:17, 362.46batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13022/40960 [00:36<01:17, 360.24batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13022/40960 [00:36<01:17, 360.24batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13096/40960 [00:36<01:16, 362.71batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13096/40960 [00:36<01:16, 362.71batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13169/40960 [00:37<01:16, 362.20batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13169/40960 [00:37<01:16, 362.20batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13240/40960 [00:37<01:17, 358.91batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13240/40960 [00:37<01:17, 358.91batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13312/40960 [00:37<01:17, 358.24batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13312/40960 [00:37<01:17, 358.24batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  33%|▎| 13385/40960 [00:37<01:16, 358.95batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  33%|▎| 13385/40960 [00:37<01:16, 358.95batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  33%|▎| 13459/40960 [00:37<01:16, 361.72batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  33%|▎| 13459/40960 [00:37<01:16, 361.72batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  33%|▎| 13528/40960 [00:38<01:16, 356.65batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  33%|▎| 13528/40960 [00:38<01:16, 356.65batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  33%|▎| 13600/40960 [00:38<01:16, 356.76batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  33%|▎| 13600/40960 [00:38<01:16, 356.76batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  33%|▎| 13671/40960 [00:38<01:16, 355.92batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  33%|▎| 13671/40960 [00:38<01:16, 355.92batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  34%|▎| 13746/40960 [00:38<01:15, 360.64batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  34%|▎| 13746/40960 [00:38<01:15, 360.64batches/s, l2_loss: 0.0676 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|▎| 13819/40960 [00:38<01:15, 360.76batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  34%|▎| 13819/40960 [00:38<01:15, 360.76batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  34%|▎| 13894/40960 [00:39<01:14, 364.76batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  34%|▎| 13894/40960 [00:39<01:14, 364.76batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  34%|▎| 13968/40960 [00:39<01:13, 365.48batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  34%|▎| 13968/40960 [00:39<01:13, 365.48batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  34%|▎| 14043/40960 [00:39<01:13, 367.79batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  34%|▎| 14043/40960 [00:39<01:13, 367.79batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  34%|▎| 14119/40960 [00:39<01:12, 371.26batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  34%|▎| 14119/40960 [00:39<01:12, 371.26batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  35%|▎| 14192/40960 [00:39<01:12, 368.96batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  35%|▎| 14192/40960 [00:39<01:12, 368.96batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  35%|▎| 14262/40960 [00:40<01:13, 362.66batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  35%|▎| 14262/40960 [00:40<01:13, 362.66batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  35%|▎| 14336/40960 [00:40<01:13, 363.96batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  35%|▎| 14336/40960 [00:40<01:13, 363.96batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  35%|▎| 14410/40960 [00:40<01:12, 365.37batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  35%|▎| 14410/40960 [00:40<01:12, 365.37batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  35%|▎| 14486/40960 [00:40<01:11, 368.79batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  35%|▎| 14486/40960 [00:40<01:11, 368.79batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  36%|▎| 14560/40960 [00:40<01:11, 368.78batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  36%|▎| 14560/40960 [00:40<01:11, 368.78batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  36%|▎| 14632/40960 [00:41<01:11, 366.12batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  36%|▎| 14632/40960 [00:41<01:11, 366.12batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  36%|▎| 14705/40960 [00:41<01:11, 364.69batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  36%|▎| 14705/40960 [00:41<01:11, 364.69batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  36%|▎| 14776/40960 [00:41<01:12, 361.75batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  36%|▎| 14776/40960 [00:41<01:12, 361.75batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  36%|▎| 14850/40960 [00:41<01:11, 363.84batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  36%|▎| 14850/40960 [00:41<01:11, 363.84batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  36%|▎| 14923/40960 [00:41<01:11, 363.14batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  36%|▎| 14923/40960 [00:41<01:11, 363.14batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  37%|▎| 14996/40960 [00:42<01:11, 362.32batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  37%|▎| 14996/40960 [00:42<01:11, 362.32batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  37%|▎| 15068/40960 [00:42<01:11, 360.66batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  37%|▎| 15068/40960 [00:42<01:11, 360.66batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  37%|▎| 15142/40960 [00:42<01:11, 362.17batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  37%|▎| 15142/40960 [00:42<01:11, 362.17batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  37%|▎| 15218/40960 [00:42<01:10, 366.76batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  37%|▎| 15218/40960 [00:42<01:10, 366.76batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  37%|▎| 15294/40960 [00:42<01:09, 370.48batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  37%|▎| 15294/40960 [00:42<01:09, 370.48batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  38%|▍| 15367/40960 [00:43<01:09, 367.74batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  38%|▍| 15367/40960 [00:43<01:09, 367.74batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  38%|▍| 15443/40960 [00:43<01:08, 370.74batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  38%|▍| 15443/40960 [00:43<01:08, 370.74batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  38%|▍| 15518/40960 [00:43<01:08, 371.83batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  38%|▍| 15518/40960 [00:43<01:08, 371.83batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  38%|▍| 15591/40960 [00:43<01:08, 368.68batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  38%|▍| 15591/40960 [00:43<01:08, 368.68batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  38%|▍| 15666/40960 [00:43<01:08, 370.07batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  38%|▍| 15666/40960 [00:43<01:08, 370.07batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  38%|▍| 15738/40960 [00:44<01:08, 366.60batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  38%|▍| 15738/40960 [00:44<01:08, 366.60batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  39%|▍| 15810/40960 [00:44<01:09, 364.25batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  39%|▍| 15810/40960 [00:44<01:09, 364.25batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  39%|▍| 15882/40960 [00:44<01:09, 361.89batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  39%|▍| 15882/40960 [00:44<01:09, 361.89batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  39%|▍| 15955/40960 [00:44<01:08, 362.72batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  39%|▍| 15955/40960 [00:44<01:08, 362.72batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  39%|▍| 16028/40960 [00:44<01:08, 362.01batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  39%|▍| 16028/40960 [00:44<01:08, 362.01batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  39%|▍| 16100/40960 [00:45<01:08, 360.56batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  39%|▍| 16100/40960 [00:45<01:08, 360.56batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  39%|▍| 16175/40960 [00:45<01:08, 363.75batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  39%|▍| 16175/40960 [00:45<01:08, 363.75batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16249/40960 [00:45<01:07, 364.95batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16249/40960 [00:45<01:07, 364.95batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16321/40960 [00:45<01:07, 362.73batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16321/40960 [00:45<01:07, 362.73batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16395/40960 [00:45<01:07, 363.69batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16395/40960 [00:45<01:07, 363.69batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16468/40960 [00:46<01:07, 363.53batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16468/40960 [00:46<01:07, 363.53batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16541/40960 [00:46<01:07, 363.01batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  40%|▍| 16541/40960 [00:46<01:07, 363.01batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  41%|▍| 16611/40960 [00:46<01:07, 358.58batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  41%|▍| 16611/40960 [00:46<01:07, 358.58batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16683/40960 [00:46<01:07, 357.86batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16683/40960 [00:46<01:07, 357.86batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16753/40960 [00:46<01:08, 355.06batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16753/40960 [00:46<01:08, 355.06batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16825/40960 [00:47<01:07, 355.27batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16825/40960 [00:47<01:07, 355.27batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16899/40960 [00:47<01:07, 358.75batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16899/40960 [00:47<01:07, 358.75batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16970/40960 [00:47<01:07, 356.82batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  41%|▍| 16970/40960 [00:47<01:07, 356.82batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  42%|▍| 17045/40960 [00:47<01:06, 360.99batches/s, l2_loss: 0.0674 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|▍| 17045/40960 [00:47<01:06, 360.99batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  42%|▍| 17120/40960 [00:48<01:05, 364.36batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  42%|▍| 17120/40960 [00:48<01:05, 364.36batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  42%|▍| 17193/40960 [00:48<01:05, 364.25batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  42%|▍| 17193/40960 [00:48<01:05, 364.25batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  42%|▍| 17264/40960 [00:48<01:05, 361.31batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  42%|▍| 17264/40960 [00:48<01:05, 361.31batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  42%|▍| 17338/40960 [00:48<01:05, 362.49batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  42%|▍| 17338/40960 [00:48<01:05, 362.49batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  43%|▍| 17410/40960 [00:48<01:05, 361.55batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  43%|▍| 17410/40960 [00:48<01:05, 361.55batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  43%|▍| 17484/40960 [00:49<01:04, 362.77batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  43%|▍| 17484/40960 [00:49<01:04, 362.77batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  43%|▍| 17558/40960 [00:49<01:04, 363.81batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  43%|▍| 17558/40960 [00:49<01:04, 363.81batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  43%|▍| 17630/40960 [00:49<01:04, 362.61batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  43%|▍| 17630/40960 [00:49<01:04, 362.61batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  43%|▍| 17703/40960 [00:49<01:04, 362.74batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  43%|▍| 17703/40960 [00:49<01:04, 362.74batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  43%|▍| 17776/40960 [00:49<01:04, 362.13batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  43%|▍| 17776/40960 [00:49<01:04, 362.13batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 17848/40960 [00:50<01:03, 361.47batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 17848/40960 [00:50<01:03, 361.47batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 17924/40960 [00:50<01:02, 366.60batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 17924/40960 [00:50<01:02, 366.60batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 17998/40960 [00:50<01:02, 366.11batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 17998/40960 [00:50<01:02, 366.11batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  44%|▍| 18072/40960 [00:50<01:02, 365.77batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  44%|▍| 18072/40960 [00:50<01:02, 365.77batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 18146/40960 [00:50<01:02, 365.71batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 18146/40960 [00:50<01:02, 365.71batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 18221/40960 [00:51<01:01, 367.36batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  44%|▍| 18221/40960 [00:51<01:01, 367.36batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  45%|▍| 18297/40960 [00:51<01:01, 370.24batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  45%|▍| 18297/40960 [00:51<01:01, 370.24batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  45%|▍| 18370/40960 [00:51<01:01, 367.36batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  45%|▍| 18370/40960 [00:51<01:01, 367.36batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  45%|▍| 18443/40960 [00:51<01:01, 365.52batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  45%|▍| 18443/40960 [00:51<01:01, 365.52batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  45%|▍| 18516/40960 [00:51<01:01, 365.01batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  45%|▍| 18516/40960 [00:51<01:01, 365.01batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  45%|▍| 18591/40960 [00:52<01:00, 366.83batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  45%|▍| 18591/40960 [00:52<01:00, 366.83batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18665/40960 [00:52<01:00, 367.23batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18665/40960 [00:52<01:00, 367.23batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18738/40960 [00:52<01:00, 365.30batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18738/40960 [00:52<01:00, 365.30batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18810/40960 [00:52<01:00, 363.52batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18810/40960 [00:52<01:00, 363.52batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18877/40960 [00:52<01:02, 354.24batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18877/40960 [00:52<01:02, 354.24batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18951/40960 [00:53<01:01, 358.88batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 18951/40960 [00:53<01:01, 358.88batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 19024/40960 [00:53<01:00, 359.94batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  46%|▍| 19024/40960 [00:53<01:00, 359.94batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  47%|▍| 19097/40960 [00:53<01:00, 360.57batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  47%|▍| 19097/40960 [00:53<01:00, 360.57batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  47%|▍| 19170/40960 [00:53<01:00, 361.63batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  47%|▍| 19170/40960 [00:53<01:00, 361.63batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  47%|▍| 19242/40960 [00:53<01:00, 359.58batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  47%|▍| 19242/40960 [00:53<01:00, 359.58batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  47%|▍| 19315/40960 [00:54<01:00, 359.88batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  47%|▍| 19315/40960 [00:54<01:00, 359.88batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  47%|▍| 19387/40960 [00:54<01:00, 359.51batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  47%|▍| 19387/40960 [00:54<01:00, 359.51batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  48%|▍| 19459/40960 [00:54<00:59, 359.11batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  48%|▍| 19459/40960 [00:54<00:59, 359.11batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19534/40960 [00:54<00:58, 363.53batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19534/40960 [00:54<00:58, 363.53batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19607/40960 [00:54<00:58, 363.72batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19607/40960 [00:54<00:58, 363.72batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19679/40960 [00:55<00:58, 362.38batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19679/40960 [00:55<00:58, 362.38batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19753/40960 [00:55<00:58, 364.55batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19753/40960 [00:55<00:58, 364.55batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19826/40960 [00:55<00:58, 364.17batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  48%|▍| 19826/40960 [00:55<00:58, 364.17batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 19900/40960 [00:55<00:57, 365.46batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 19900/40960 [00:55<00:57, 365.46batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 19972/40960 [00:55<00:57, 362.13batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 19972/40960 [00:55<00:57, 362.13batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 20044/40960 [00:56<00:57, 360.92batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 20044/40960 [00:56<00:57, 360.92batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 20118/40960 [00:56<00:57, 362.08batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 20118/40960 [00:56<00:57, 362.08batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 20191/40960 [00:56<00:57, 362.82batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 20191/40960 [00:56<00:57, 362.82batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 20269/40960 [00:56<00:55, 369.82batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  49%|▍| 20269/40960 [00:56<00:55, 369.82batches/s, l2_loss: 0.0673 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▍| 20338/40960 [00:56<00:56, 362.08batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▍| 20338/40960 [00:56<00:56, 362.08batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▍| 20412/40960 [00:57<00:56, 363.59batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▍| 20412/40960 [00:57<00:56, 363.59batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▌| 20484/40960 [00:57<00:56, 362.40batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▌| 20484/40960 [00:57<00:56, 362.40batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▌| 20558/40960 [00:57<00:56, 364.08batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▌| 20558/40960 [00:57<00:56, 364.08batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▌| 20630/40960 [00:57<00:56, 362.66batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  50%|▌| 20630/40960 [00:57<00:56, 362.66batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20704/40960 [00:57<00:55, 363.37batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20704/40960 [00:57<00:55, 363.37batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20776/40960 [00:58<00:55, 361.19batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20776/40960 [00:58<00:55, 361.19batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20848/40960 [00:58<00:55, 359.57batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20848/40960 [00:58<00:55, 359.57batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20920/40960 [00:58<00:55, 359.21batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20920/40960 [00:58<00:55, 359.21batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20990/40960 [00:58<00:56, 355.62batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 20990/40960 [00:58<00:56, 355.62batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 21062/40960 [00:58<00:55, 355.78batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  51%|▌| 21062/40960 [00:58<00:55, 355.78batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  52%|▌| 21135/40960 [00:59<00:55, 357.79batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  52%|▌| 21135/40960 [00:59<00:55, 357.79batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  52%|▌| 21207/40960 [00:59<00:55, 358.09batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  52%|▌| 21207/40960 [00:59<00:55, 358.09batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  52%|▌| 21280/40960 [00:59<00:54, 358.99batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  52%|▌| 21280/40960 [00:59<00:54, 358.99batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  52%|▌| 21353/40960 [00:59<00:54, 360.26batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  52%|▌| 21353/40960 [00:59<00:54, 360.26batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  52%|▌| 21424/40960 [00:59<00:54, 358.64batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  52%|▌| 21424/40960 [00:59<00:54, 358.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  52%|▌| 21496/40960 [01:00<00:54, 358.70batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  52%|▌| 21496/40960 [01:00<00:54, 358.70batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21569/40960 [01:00<00:53, 359.89batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21569/40960 [01:00<00:53, 359.89batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21643/40960 [01:00<00:53, 361.63batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21643/40960 [01:00<00:53, 361.63batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21717/40960 [01:00<00:52, 363.11batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21717/40960 [01:00<00:52, 363.11batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21788/40960 [01:00<00:53, 360.38batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21788/40960 [01:00<00:53, 360.38batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21862/40960 [01:01<00:52, 362.38batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  53%|▌| 21862/40960 [01:01<00:52, 362.38batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 21937/40960 [01:01<00:52, 365.64batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 21937/40960 [01:01<00:52, 365.64batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 22013/40960 [01:01<00:51, 368.83batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 22013/40960 [01:01<00:51, 368.83batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 22087/40960 [01:01<00:51, 368.80batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 22087/40960 [01:01<00:51, 368.80batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  54%|▌| 22159/40960 [01:01<00:51, 365.43batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  54%|▌| 22159/40960 [01:01<00:51, 365.43batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 22233/40960 [01:02<00:51, 366.15batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 22233/40960 [01:02<00:51, 366.15batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 22307/40960 [01:02<00:50, 366.05batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  54%|▌| 22307/40960 [01:02<00:50, 366.05batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  55%|▌| 22379/40960 [01:02<00:51, 363.88batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  55%|▌| 22379/40960 [01:02<00:51, 363.88batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  55%|▌| 22451/40960 [01:02<00:51, 362.63batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  55%|▌| 22451/40960 [01:02<00:51, 362.63batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  55%|▌| 22525/40960 [01:02<00:50, 364.77batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  55%|▌| 22525/40960 [01:02<00:50, 364.77batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  55%|▌| 22595/40960 [01:03<00:51, 359.00batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  55%|▌| 22595/40960 [01:03<00:51, 359.00batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  55%|▌| 22670/40960 [01:03<00:50, 363.31batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  55%|▌| 22670/40960 [01:03<00:50, 363.31batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  56%|▌| 22743/40960 [01:03<00:50, 363.55batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  56%|▌| 22743/40960 [01:03<00:50, 363.55batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  56%|▌| 22817/40960 [01:03<00:49, 365.31batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  56%|▌| 22817/40960 [01:03<00:49, 365.31batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  56%|▌| 22889/40960 [01:03<00:49, 362.69batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  56%|▌| 22889/40960 [01:03<00:49, 362.69batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  56%|▌| 22964/40960 [01:04<00:49, 365.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  56%|▌| 22964/40960 [01:04<00:49, 365.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  56%|▌| 23038/40960 [01:04<00:48, 366.02batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  56%|▌| 23038/40960 [01:04<00:48, 366.02batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  56%|▌| 23112/40960 [01:04<00:48, 366.66batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  56%|▌| 23112/40960 [01:04<00:48, 366.66batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  57%|▌| 23185/40960 [01:04<00:48, 365.73batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  57%|▌| 23185/40960 [01:04<00:48, 365.73batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  57%|▌| 23260/40960 [01:04<00:48, 367.75batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  57%|▌| 23260/40960 [01:04<00:48, 367.75batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  57%|▌| 23335/40960 [01:05<00:47, 369.45batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  57%|▌| 23335/40960 [01:05<00:47, 369.45batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  57%|▌| 23408/40960 [01:05<00:47, 367.00batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  57%|▌| 23408/40960 [01:05<00:47, 367.00batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  57%|▌| 23481/40960 [01:05<00:47, 365.77batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  57%|▌| 23481/40960 [01:05<00:47, 365.77batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  58%|▌| 23556/40960 [01:05<00:47, 367.94batches/s, l2_loss: 0.0673 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|▌| 23556/40960 [01:05<00:47, 367.94batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  58%|▌| 23630/40960 [01:05<00:47, 367.79batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  58%|▌| 23630/40960 [01:05<00:47, 367.79batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  58%|▌| 23703/40960 [01:06<00:47, 366.09batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  58%|▌| 23703/40960 [01:06<00:47, 366.09batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  58%|▌| 23774/40960 [01:06<00:47, 362.66batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  58%|▌| 23774/40960 [01:06<00:47, 362.66batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  58%|▌| 23849/40960 [01:06<00:46, 366.05batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  58%|▌| 23849/40960 [01:06<00:46, 366.05batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  58%|▌| 23924/40960 [01:06<00:46, 368.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  58%|▌| 23924/40960 [01:06<00:46, 368.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 23998/40960 [01:06<00:46, 367.82batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 23998/40960 [01:06<00:46, 367.82batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  59%|▌| 24072/40960 [01:07<00:46, 367.10batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  59%|▌| 24072/40960 [01:07<00:46, 367.10batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 24147/40960 [01:07<00:45, 369.04batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 24147/40960 [01:07<00:45, 369.04batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 24220/40960 [01:07<00:45, 366.87batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 24220/40960 [01:07<00:45, 366.87batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 24293/40960 [01:07<00:45, 366.03batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 24293/40960 [01:07<00:45, 366.03batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 24368/40960 [01:07<00:45, 367.42batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  59%|▌| 24368/40960 [01:07<00:45, 367.42batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  60%|▌| 24441/40960 [01:08<00:45, 365.85batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  60%|▌| 24441/40960 [01:08<00:45, 365.85batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  60%|▌| 24513/40960 [01:08<00:45, 364.00batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  60%|▌| 24513/40960 [01:08<00:45, 364.00batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  60%|▌| 24586/40960 [01:08<00:45, 363.43batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  60%|▌| 24586/40960 [01:08<00:45, 363.43batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  60%|▌| 24658/40960 [01:08<00:45, 361.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  60%|▌| 24658/40960 [01:08<00:45, 361.18batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  60%|▌| 24730/40960 [01:08<00:45, 360.65batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  60%|▌| 24730/40960 [01:08<00:45, 360.65batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  61%|▌| 24805/40960 [01:09<00:44, 363.60batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  61%|▌| 24805/40960 [01:09<00:44, 363.60batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  61%|▌| 24880/40960 [01:09<00:43, 366.49batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  61%|▌| 24880/40960 [01:09<00:43, 366.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  61%|▌| 24956/40960 [01:09<00:43, 370.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  61%|▌| 24956/40960 [01:09<00:43, 370.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  61%|▌| 25031/40960 [01:09<00:42, 371.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  61%|▌| 25031/40960 [01:09<00:42, 371.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  61%|▌| 25107/40960 [01:09<00:42, 372.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  61%|▌| 25107/40960 [01:09<00:42, 372.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  61%|▌| 25182/40960 [01:10<00:42, 372.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  61%|▌| 25182/40960 [01:10<00:42, 372.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  62%|▌| 25254/40960 [01:10<00:42, 368.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  62%|▌| 25254/40960 [01:10<00:42, 368.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  62%|▌| 25327/40960 [01:10<00:42, 367.38batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  62%|▌| 25327/40960 [01:10<00:42, 367.38batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  62%|▌| 25401/40960 [01:10<00:42, 367.75batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  62%|▌| 25401/40960 [01:10<00:42, 367.75batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  62%|▌| 25476/40960 [01:10<00:41, 368.72batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  62%|▌| 25476/40960 [01:10<00:41, 368.72batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  62%|▌| 25545/40960 [01:11<00:42, 360.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  62%|▌| 25545/40960 [01:11<00:42, 360.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25619/40960 [01:11<00:42, 362.13batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25619/40960 [01:11<00:42, 362.13batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25691/40960 [01:11<00:42, 361.45batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25691/40960 [01:11<00:42, 361.45batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  63%|▋| 25764/40960 [01:11<00:41, 362.12batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  63%|▋| 25764/40960 [01:11<00:41, 362.12batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25837/40960 [01:11<00:41, 362.85batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25837/40960 [01:11<00:41, 362.85batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25911/40960 [01:12<00:41, 363.92batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25911/40960 [01:12<00:41, 363.92batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25985/40960 [01:12<00:41, 364.54batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  63%|▋| 25985/40960 [01:12<00:41, 364.54batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  64%|▋| 26056/40960 [01:12<00:41, 361.56batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  64%|▋| 26056/40960 [01:12<00:41, 361.56batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  64%|▋| 26131/40960 [01:12<00:40, 364.51batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  64%|▋| 26131/40960 [01:12<00:40, 364.51batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  64%|▋| 26203/40960 [01:12<00:40, 361.71batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  64%|▋| 26203/40960 [01:12<00:40, 361.71batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  64%|▋| 26276/40960 [01:13<00:40, 362.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  64%|▋| 26276/40960 [01:13<00:40, 362.07batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  64%|▋| 26349/40960 [01:13<00:40, 362.48batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  64%|▋| 26349/40960 [01:13<00:40, 362.48batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26424/40960 [01:13<00:39, 366.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26424/40960 [01:13<00:39, 366.11batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  65%|▋| 26499/40960 [01:13<00:39, 368.00batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  65%|▋| 26499/40960 [01:13<00:39, 368.00batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26569/40960 [01:13<00:39, 361.19batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26569/40960 [01:13<00:39, 361.19batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26639/40960 [01:14<00:40, 356.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26639/40960 [01:14<00:40, 356.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26713/40960 [01:14<00:39, 360.08batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26713/40960 [01:14<00:39, 360.08batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26787/40960 [01:14<00:39, 362.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  65%|▋| 26787/40960 [01:14<00:39, 362.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|▋| 26856/40960 [01:14<00:39, 355.41batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 26856/40960 [01:14<00:39, 355.41batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 26923/40960 [01:14<00:40, 348.82batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 26923/40960 [01:14<00:40, 348.82batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 26990/40960 [01:15<00:40, 343.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 26990/40960 [01:15<00:40, 343.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 27063/40960 [01:15<00:39, 349.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 27063/40960 [01:15<00:39, 349.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 27138/40960 [01:15<00:38, 356.40batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 27138/40960 [01:15<00:38, 356.40batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 27212/40960 [01:15<00:38, 359.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  66%|▋| 27212/40960 [01:15<00:38, 359.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27277/40960 [01:15<00:39, 348.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27277/40960 [01:15<00:39, 348.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27339/40960 [01:16<00:40, 336.29batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27339/40960 [01:16<00:40, 336.29batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27410/40960 [01:16<00:39, 340.81batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27410/40960 [01:16<00:39, 340.81batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27484/40960 [01:16<00:38, 349.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27484/40960 [01:16<00:38, 349.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27553/40960 [01:16<00:38, 346.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27553/40960 [01:16<00:38, 346.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27626/40960 [01:16<00:37, 351.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  67%|▋| 27626/40960 [01:17<00:37, 351.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27700/40960 [01:17<00:37, 355.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27700/40960 [01:17<00:37, 355.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27774/40960 [01:17<00:36, 359.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27774/40960 [01:17<00:36, 359.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27849/40960 [01:17<00:36, 363.50batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27849/40960 [01:17<00:36, 363.50batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27922/40960 [01:17<00:35, 363.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27922/40960 [01:17<00:35, 363.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27996/40960 [01:18<00:35, 364.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  68%|▋| 27996/40960 [01:18<00:35, 364.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28069/40960 [01:18<00:35, 364.14batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28069/40960 [01:18<00:35, 364.14batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28141/40960 [01:18<00:35, 362.67batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28141/40960 [01:18<00:35, 362.67batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28213/40960 [01:18<00:35, 361.29batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28213/40960 [01:18<00:35, 361.29batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28284/40960 [01:18<00:35, 358.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28284/40960 [01:18<00:35, 358.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28357/40960 [01:19<00:35, 359.13batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28357/40960 [01:19<00:35, 359.13batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28430/40960 [01:19<00:34, 359.97batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  69%|▋| 28430/40960 [01:19<00:34, 359.97batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  70%|▋| 28502/40960 [01:19<00:34, 359.24batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  70%|▋| 28502/40960 [01:19<00:34, 359.24batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28577/40960 [01:19<00:34, 363.16batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28577/40960 [01:19<00:34, 363.16batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28651/40960 [01:19<00:33, 364.90batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28651/40960 [01:19<00:33, 364.90batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28723/40960 [01:20<00:33, 361.92batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28723/40960 [01:20<00:33, 361.92batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28793/40960 [01:20<00:33, 357.97batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28793/40960 [01:20<00:33, 357.97batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28867/40960 [01:20<00:33, 360.27batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  70%|▋| 28867/40960 [01:20<00:33, 360.27batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 28939/40960 [01:20<00:33, 360.14batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 28939/40960 [01:20<00:33, 360.14batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 29010/40960 [01:20<00:33, 358.01batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 29010/40960 [01:20<00:33, 358.01batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 29085/40960 [01:21<00:32, 362.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 29085/40960 [01:21<00:32, 362.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 29159/40960 [01:21<00:32, 363.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 29159/40960 [01:21<00:32, 363.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 29231/40960 [01:21<00:32, 360.66batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  71%|▋| 29231/40960 [01:21<00:32, 360.66batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29303/40960 [01:21<00:32, 360.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29303/40960 [01:21<00:32, 360.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29377/40960 [01:21<00:31, 362.27batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29377/40960 [01:21<00:31, 362.27batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29449/40960 [01:22<00:31, 360.27batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29449/40960 [01:22<00:31, 360.27batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29520/40960 [01:22<00:31, 358.37batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29520/40960 [01:22<00:31, 358.37batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29591/40960 [01:22<00:31, 356.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29591/40960 [01:22<00:31, 356.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29665/40960 [01:22<00:31, 360.55batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  72%|▋| 29665/40960 [01:22<00:31, 360.55batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 29741/40960 [01:22<00:30, 365.39batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 29741/40960 [01:22<00:30, 365.39batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 29814/40960 [01:23<00:30, 364.84batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 29814/40960 [01:23<00:30, 364.84batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 29886/40960 [01:23<00:30, 362.97batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 29886/40960 [01:23<00:30, 362.97batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 29960/40960 [01:23<00:30, 365.00batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 29960/40960 [01:23<00:30, 365.00batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  73%|▋| 30034/40960 [01:23<00:29, 366.43batches/s, l2_loss: 0.0672 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|▋| 30034/40960 [01:23<00:29, 366.43batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30108/40960 [01:23<00:29, 367.47batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30108/40960 [01:23<00:29, 367.47batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30182/40960 [01:24<00:29, 366.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30182/40960 [01:24<00:29, 366.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30255/40960 [01:24<00:29, 366.09batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30255/40960 [01:24<00:29, 366.09batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30330/40960 [01:24<00:28, 367.34batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30330/40960 [01:24<00:28, 367.34batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30403/40960 [01:24<00:28, 366.10batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30403/40960 [01:24<00:28, 366.10batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30478/40960 [01:24<00:28, 367.73batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  74%|▋| 30478/40960 [01:24<00:28, 367.73batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▋| 30551/40960 [01:25<00:28, 365.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▋| 30551/40960 [01:25<00:28, 365.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▋| 30624/40960 [01:25<00:28, 364.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▋| 30624/40960 [01:25<00:28, 364.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▋| 30695/40960 [01:25<00:28, 360.80batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▋| 30695/40960 [01:25<00:28, 360.80batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▊| 30767/40960 [01:25<00:28, 359.54batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▊| 30767/40960 [01:25<00:28, 359.54batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▊| 30841/40960 [01:25<00:27, 362.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▊| 30841/40960 [01:25<00:27, 362.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▊| 30915/40960 [01:26<00:27, 364.22batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  75%|▊| 30915/40960 [01:26<00:27, 364.22batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 30990/40960 [01:26<00:27, 366.72batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 30990/40960 [01:26<00:27, 366.72batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 31063/40960 [01:26<00:27, 365.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 31063/40960 [01:26<00:27, 365.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 31131/40960 [01:26<00:27, 357.02batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 31131/40960 [01:26<00:27, 357.02batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 31200/40960 [01:26<00:27, 350.35batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 31200/40960 [01:26<00:27, 350.35batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 31268/40960 [01:27<00:27, 346.75batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  76%|▊| 31268/40960 [01:27<00:27, 346.75batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31339/40960 [01:27<00:27, 348.99batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31339/40960 [01:27<00:27, 348.99batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31411/40960 [01:27<00:27, 350.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31411/40960 [01:27<00:27, 350.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31484/40960 [01:27<00:26, 353.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31484/40960 [01:27<00:26, 353.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31556/40960 [01:27<00:26, 354.29batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31556/40960 [01:27<00:26, 354.29batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31628/40960 [01:28<00:26, 355.36batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31628/40960 [01:28<00:26, 355.36batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31704/40960 [01:28<00:25, 361.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  77%|▊| 31704/40960 [01:28<00:25, 361.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 31777/40960 [01:28<00:25, 362.36batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 31777/40960 [01:28<00:25, 362.36batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 31851/40960 [01:28<00:25, 364.10batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 31851/40960 [01:28<00:25, 364.10batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 31924/40960 [01:28<00:24, 363.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 31924/40960 [01:28<00:24, 363.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 31997/40960 [01:29<00:24, 363.08batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 31997/40960 [01:29<00:24, 363.08batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 32070/40960 [01:29<00:24, 363.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 32070/40960 [01:29<00:24, 363.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 32143/40960 [01:29<00:24, 363.84batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  78%|▊| 32143/40960 [01:29<00:24, 363.84batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32216/40960 [01:29<00:24, 363.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32216/40960 [01:29<00:24, 363.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32287/40960 [01:29<00:24, 360.20batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32287/40960 [01:29<00:24, 360.20batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32362/40960 [01:30<00:23, 364.58batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32362/40960 [01:30<00:23, 364.58batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32437/40960 [01:30<00:23, 366.65batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32437/40960 [01:30<00:23, 366.65batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32511/40960 [01:30<00:23, 366.27batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  79%|▊| 32511/40960 [01:30<00:23, 366.27batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32585/40960 [01:30<00:22, 366.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32585/40960 [01:30<00:22, 366.86batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32661/40960 [01:30<00:22, 370.12batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32661/40960 [01:30<00:22, 370.12batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32732/40960 [01:31<00:22, 364.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32732/40960 [01:31<00:22, 364.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32805/40960 [01:31<00:22, 363.47batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32805/40960 [01:31<00:22, 363.47batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32878/40960 [01:31<00:22, 363.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32878/40960 [01:31<00:22, 363.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32951/40960 [01:31<00:22, 363.13batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  80%|▊| 32951/40960 [01:31<00:22, 363.13batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33027/40960 [01:31<00:21, 366.90batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33027/40960 [01:31<00:21, 366.90batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33102/40960 [01:32<00:21, 368.51batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33102/40960 [01:32<00:21, 368.51batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33176/40960 [01:32<00:21, 368.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33176/40960 [01:32<00:21, 368.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33251/40960 [01:32<00:20, 369.95batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33251/40960 [01:32<00:20, 369.95batches/s, l2_loss: 0.0672 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|▊| 33323/40960 [01:32<00:20, 365.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  81%|▊| 33323/40960 [01:32<00:20, 365.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33395/40960 [01:32<00:20, 363.99batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33395/40960 [01:32<00:20, 363.99batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33470/40960 [01:33<00:20, 366.38batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33470/40960 [01:33<00:20, 366.38batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33543/40960 [01:33<00:20, 365.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33543/40960 [01:33<00:20, 365.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33615/40960 [01:33<00:20, 363.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33615/40960 [01:33<00:20, 363.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33688/40960 [01:33<00:20, 363.19batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33688/40960 [01:33<00:20, 363.19batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33762/40960 [01:33<00:19, 364.55batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  82%|▊| 33762/40960 [01:33<00:19, 364.55batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 33834/40960 [01:34<00:19, 362.53batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 33834/40960 [01:34<00:19, 362.53batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 33908/40960 [01:34<00:19, 363.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 33908/40960 [01:34<00:19, 363.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 33980/40960 [01:34<00:19, 361.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 33980/40960 [01:34<00:19, 361.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 34052/40960 [01:34<00:19, 361.04batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 34052/40960 [01:34<00:19, 361.04batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 34126/40960 [01:34<00:18, 362.45batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 34126/40960 [01:34<00:18, 362.45batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 34200/40960 [01:35<00:18, 363.56batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  83%|▊| 34200/40960 [01:35<00:18, 363.56batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34272/40960 [01:35<00:18, 361.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34272/40960 [01:35<00:18, 361.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34347/40960 [01:35<00:18, 364.72batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34347/40960 [01:35<00:18, 364.72batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34421/40960 [01:35<00:17, 365.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34421/40960 [01:35<00:17, 365.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34494/40960 [01:35<00:17, 365.30batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34494/40960 [01:35<00:17, 365.30batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34568/40960 [01:36<00:17, 366.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  84%|▊| 34568/40960 [01:36<00:17, 366.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34640/40960 [01:36<00:17, 364.37batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34640/40960 [01:36<00:17, 364.37batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34714/40960 [01:36<00:17, 365.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34714/40960 [01:36<00:17, 365.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34784/40960 [01:36<00:17, 360.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34784/40960 [01:36<00:17, 360.49batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34858/40960 [01:36<00:16, 363.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34858/40960 [01:36<00:16, 363.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34932/40960 [01:37<00:16, 364.00batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 34932/40960 [01:37<00:16, 364.00batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 35008/40960 [01:37<00:16, 368.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  85%|▊| 35008/40960 [01:37<00:16, 368.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35081/40960 [01:37<00:16, 365.94batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35081/40960 [01:37<00:16, 365.94batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35154/40960 [01:37<00:15, 365.54batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35154/40960 [01:37<00:15, 365.54batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35228/40960 [01:37<00:15, 365.89batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35228/40960 [01:37<00:15, 365.89batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35305/40960 [01:38<00:15, 370.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35305/40960 [01:38<00:15, 370.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35379/40960 [01:38<00:15, 369.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  86%|▊| 35379/40960 [01:38<00:15, 369.59batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35453/40960 [01:38<00:14, 369.39batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35453/40960 [01:38<00:14, 369.39batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35527/40960 [01:38<00:14, 368.26batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35527/40960 [01:38<00:14, 368.26batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35603/40960 [01:38<00:14, 371.09batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35603/40960 [01:38<00:14, 371.09batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35677/40960 [01:39<00:14, 369.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35677/40960 [01:39<00:14, 369.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35748/40960 [01:39<00:14, 364.02batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35748/40960 [01:39<00:14, 364.02batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35821/40960 [01:39<00:14, 363.68batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  87%|▊| 35821/40960 [01:39<00:14, 363.68batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 35896/40960 [01:39<00:13, 366.88batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 35896/40960 [01:39<00:13, 366.88batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 35971/40960 [01:39<00:13, 368.53batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 35971/40960 [01:39<00:13, 368.53batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 36046/40960 [01:40<00:13, 369.23batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 36046/40960 [01:40<00:13, 369.23batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 36119/40960 [01:40<00:13, 366.95batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 36119/40960 [01:40<00:13, 366.95batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 36192/40960 [01:40<00:13, 365.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  88%|▉| 36192/40960 [01:40<00:13, 365.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36266/40960 [01:40<00:12, 366.30batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36266/40960 [01:40<00:12, 366.30batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36339/40960 [01:40<00:12, 365.74batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36339/40960 [01:40<00:12, 365.74batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36413/40960 [01:41<00:12, 366.48batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36413/40960 [01:41<00:12, 366.48batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36486/40960 [01:41<00:12, 365.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36486/40960 [01:41<00:12, 365.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36561/40960 [01:41<00:11, 366.91batches/s, l2_loss: 0.0672 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36561/40960 [01:41<00:11, 366.91batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36634/40960 [01:41<00:11, 365.97batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  89%|▉| 36634/40960 [01:41<00:11, 365.97batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  90%|▉| 36709/40960 [01:41<00:11, 367.98batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  90%|▉| 36709/40960 [01:41<00:11, 367.98batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  90%|▉| 36783/40960 [01:42<00:11, 367.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  90%|▉| 36783/40960 [01:42<00:11, 367.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  90%|▉| 36856/40960 [01:42<00:11, 366.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  90%|▉| 36856/40960 [01:42<00:11, 366.64batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  90%|▉| 36928/40960 [01:42<00:11, 363.43batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  90%|▉| 36928/40960 [01:42<00:11, 363.43batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  90%|▉| 37001/40960 [01:42<00:10, 363.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  90%|▉| 37001/40960 [01:42<00:10, 363.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37074/40960 [01:42<00:10, 363.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37074/40960 [01:42<00:10, 363.21batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37148/40960 [01:43<00:10, 363.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37148/40960 [01:43<00:10, 363.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37220/40960 [01:43<00:10, 362.28batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37220/40960 [01:43<00:10, 362.28batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37292/40960 [01:43<00:10, 360.04batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37292/40960 [01:43<00:10, 360.04batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37364/40960 [01:43<00:10, 359.40batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  91%|▉| 37364/40960 [01:43<00:10, 359.40batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  91%|▉| 37438/40960 [01:43<00:09, 361.43batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  91%|▉| 37438/40960 [01:43<00:09, 361.43batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37512/40960 [01:44<00:09, 363.02batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37512/40960 [01:44<00:09, 363.02batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37585/40960 [01:44<00:09, 362.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37585/40960 [01:44<00:09, 362.44batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37657/40960 [01:44<00:09, 361.34batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37657/40960 [01:44<00:09, 361.34batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37730/40960 [01:44<00:08, 361.84batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37730/40960 [01:44<00:08, 361.84batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37800/40960 [01:44<00:08, 358.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37800/40960 [01:44<00:08, 358.11batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37874/40960 [01:45<00:08, 360.36batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  92%|▉| 37874/40960 [01:45<00:08, 360.36batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 37949/40960 [01:45<00:08, 363.72batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 37949/40960 [01:45<00:08, 363.72batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 38021/40960 [01:45<00:08, 362.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 38021/40960 [01:45<00:08, 362.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 38095/40960 [01:45<00:07, 363.05batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 38095/40960 [01:45<00:07, 363.05batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 38167/40960 [01:46<00:07, 361.08batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 38167/40960 [01:46<00:07, 361.08batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 38241/40960 [01:46<00:07, 363.67batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  93%|▉| 38241/40960 [01:46<00:07, 363.67batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38314/40960 [01:46<00:07, 364.04batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38314/40960 [01:46<00:07, 364.04batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38387/40960 [01:46<00:07, 364.30batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38387/40960 [01:46<00:07, 364.30batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38461/40960 [01:46<00:06, 364.78batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38461/40960 [01:46<00:06, 364.78batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38533/40960 [01:47<00:06, 362.35batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38533/40960 [01:47<00:06, 362.35batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38605/40960 [01:47<00:06, 360.70batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38605/40960 [01:47<00:06, 360.70batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38677/40960 [01:47<00:06, 359.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38677/40960 [01:47<00:06, 359.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 38748/40960 [01:47<00:06, 357.98batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 38748/40960 [01:47<00:06, 357.98batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 38815/40960 [01:47<00:06, 349.54batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 38815/40960 [01:47<00:06, 349.54batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 38881/40960 [01:48<00:06, 342.93batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 38881/40960 [01:48<00:06, 342.93batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 38953/40960 [01:48<00:05, 346.99batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 38953/40960 [01:48<00:05, 346.99batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 39026/40960 [01:48<00:05, 351.77batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 39026/40960 [01:48<00:05, 351.77batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 39099/40960 [01:48<00:05, 354.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  95%|▉| 39099/40960 [01:48<00:05, 354.64batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  96%|▉| 39173/40960 [01:48<00:04, 359.15batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  96%|▉| 39173/40960 [01:48<00:04, 359.15batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  96%|▉| 39242/40960 [01:49<00:04, 353.66batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  96%|▉| 39242/40960 [01:49<00:04, 353.66batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  96%|▉| 39314/40960 [01:49<00:04, 354.19batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  96%|▉| 39314/40960 [01:49<00:04, 354.19batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  96%|▉| 39384/40960 [01:49<00:04, 352.65batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  96%|▉| 39384/40960 [01:49<00:04, 352.65batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  96%|▉| 39458/40960 [01:49<00:04, 357.61batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  96%|▉| 39458/40960 [01:49<00:04, 357.61batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39529/40960 [01:49<00:04, 355.28batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39529/40960 [01:49<00:04, 355.28batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39600/40960 [01:50<00:03, 354.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39600/40960 [01:50<00:03, 354.57batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39674/40960 [01:50<00:03, 358.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39674/40960 [01:50<00:03, 358.83batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39747/40960 [01:50<00:03, 359.55batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39747/40960 [01:50<00:03, 359.55batches/s, l2_loss: 0.0672 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39821/40960 [01:50<00:03, 362.61batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39821/40960 [01:50<00:03, 362.61batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39892/40960 [01:50<00:02, 359.38batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  97%|▉| 39892/40960 [01:50<00:02, 359.38batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 39965/40960 [01:51<00:02, 360.92batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 39965/40960 [01:51<00:02, 360.92batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40040/40960 [01:51<00:02, 364.79batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40040/40960 [01:51<00:02, 364.79batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [01:51<00:02, 366.41batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [01:51<00:02, 366.41batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40188/40960 [01:51<00:02, 364.70batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40188/40960 [01:51<00:02, 364.70batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40262/40960 [01:51<00:01, 365.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40262/40960 [01:51<00:01, 365.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40337/40960 [01:52<00:01, 367.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  98%|▉| 40337/40960 [01:52<00:01, 367.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  99%|▉| 40412/40960 [01:52<00:01, 369.16batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  99%|▉| 40412/40960 [01:52<00:01, 369.16batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  99%|▉| 40485/40960 [01:52<00:01, 366.76batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  99%|▉| 40485/40960 [01:52<00:01, 366.76batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  99%|▉| 40555/40960 [01:52<00:01, 358.48batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  99%|▉| 40555/40960 [01:52<00:01, 358.48batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  99%|▉| 40625/40960 [01:52<00:00, 355.53batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  99%|▉| 40625/40960 [01:52<00:00, 355.53batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  99%|▉| 40699/40960 [01:53<00:00, 359.46batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  99%|▉| 40699/40960 [01:53<00:00, 359.46batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training: 100%|▉| 40760/40960 [01:53<00:00, 342.40batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training: 100%|▉| 40760/40960 [01:53<00:00, 342.40batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training: 100%|▉| 40833/40960 [01:53<00:00, 348.45batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training: 100%|▉| 40833/40960 [01:53<00:00, 348.45batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training: 100%|▉| 40906/40960 [01:53<00:00, 352.94batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training: 100%|▉| 40906/40960 [01:53<00:00, 352.94batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:15:41.753189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  50%|▌| 13/26 [26:20<27:43, 127.97s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:15:43.743763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:15:46.392694: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<10:14:44,  1.11batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:14:44,  1.11batches/s, l2_loss: 0.0186 - round_loss:\u001b[A\n",
      "Training:   0%| | 92/40960 [00:01<06:10, 110.18batches/s, l2_loss: 0.0186 - round_loss: \u001b[A\n",
      "Training:   0%| | 92/40960 [00:01<06:10, 110.18batches/s, l2_loss: 0.0264 - round_loss: \u001b[A\n",
      "Training:   0%| | 184/40960 [00:01<03:24, 199.52batches/s, l2_loss: 0.0264 - round_loss:\u001b[A\n",
      "Training:   0%| | 184/40960 [00:01<03:24, 199.52batches/s, l2_loss: 0.0250 - round_loss:\u001b[A\n",
      "Training:   1%| | 275/40960 [00:01<02:32, 267.37batches/s, l2_loss: 0.0250 - round_loss:\u001b[A\n",
      "Training:   1%| | 275/40960 [00:01<02:32, 267.37batches/s, l2_loss: 0.0265 - round_loss:\u001b[A\n",
      "Training:   1%| | 367/40960 [00:01<02:06, 320.01batches/s, l2_loss: 0.0265 - round_loss:\u001b[A\n",
      "Training:   1%| | 367/40960 [00:01<02:06, 320.01batches/s, l2_loss: 0.0269 - round_loss:\u001b[A\n",
      "Training:   1%| | 455/40960 [00:01<01:54, 352.90batches/s, l2_loss: 0.0269 - round_loss:\u001b[A\n",
      "Training:   1%| | 455/40960 [00:01<01:54, 352.90batches/s, l2_loss: 0.0254 - round_loss:\u001b[A\n",
      "Training:   1%| | 539/40960 [00:02<01:48, 371.87batches/s, l2_loss: 0.0254 - round_loss:\u001b[A\n",
      "Training:   1%| | 539/40960 [00:02<01:48, 371.87batches/s, l2_loss: 0.0262 - round_loss:\u001b[A\n",
      "Training:   1%| | 614/40960 [00:02<01:48, 372.77batches/s, l2_loss: 0.0262 - round_loss:\u001b[A\n",
      "Training:   1%| | 614/40960 [00:02<01:48, 372.77batches/s, l2_loss: 0.0269 - round_loss:\u001b[A\n",
      "Training:   2%| | 694/40960 [00:02<01:45, 380.04batches/s, l2_loss: 0.0269 - round_loss:\u001b[A\n",
      "Training:   2%| | 694/40960 [00:02<01:45, 380.04batches/s, l2_loss: 0.0263 - round_loss:\u001b[A\n",
      "Training:   2%| | 785/40960 [00:02<01:40, 401.00batches/s, l2_loss: 0.0263 - round_loss:\u001b[A\n",
      "Training:   2%| | 785/40960 [00:02<01:40, 401.00batches/s, l2_loss: 0.0261 - round_loss:\u001b[A\n",
      "Training:   2%| | 875/40960 [00:02<01:36, 415.42batches/s, l2_loss: 0.0261 - round_loss:\u001b[A\n",
      "Training:   2%| | 875/40960 [00:02<01:36, 415.42batches/s, l2_loss: 0.0265 - round_loss:\u001b[A\n",
      "Training:   2%| | 966/40960 [00:03<01:33, 426.74batches/s, l2_loss: 0.0265 - round_loss:\u001b[A\n",
      "Training:   2%| | 966/40960 [00:03<01:33, 426.74batches/s, l2_loss: 0.0262 - round_loss:\u001b[A\n",
      "Training:   3%| | 1060/40960 [00:03<01:31, 438.37batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   3%| | 1060/40960 [00:03<01:31, 438.37batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:   3%| | 1153/40960 [00:03<01:29, 445.54batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:   3%| | 1153/40960 [00:03<01:29, 445.54batches/s, l2_loss: 0.0266 - round_loss\u001b[A\n",
      "Training:   3%| | 1245/40960 [00:03<01:28, 448.90batches/s, l2_loss: 0.0266 - round_loss\u001b[A\n",
      "Training:   3%| | 1245/40960 [00:03<01:28, 448.90batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   3%| | 1324/40960 [00:03<01:31, 431.06batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   3%| | 1324/40960 [00:03<01:31, 431.06batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   3%| | 1403/40960 [00:04<01:34, 419.60batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   3%| | 1403/40960 [00:04<01:34, 419.60batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   4%| | 1487/40960 [00:04<01:34, 419.23batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   4%| | 1487/40960 [00:04<01:34, 419.23batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   4%| | 1572/40960 [00:04<01:33, 420.23batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   4%| | 1572/40960 [00:04<01:33, 420.23batches/s, l2_loss: 0.0267 - round_loss\u001b[A\n",
      "Training:   4%| | 1653/40960 [00:04<01:34, 415.01batches/s, l2_loss: 0.0267 - round_loss\u001b[A\n",
      "Training:   4%| | 1653/40960 [00:04<01:34, 415.01batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   4%| | 1741/40960 [00:04<01:33, 421.62batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   4%| | 1741/40960 [00:04<01:33, 421.62batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   4%| | 1833/40960 [00:05<01:30, 432.83batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   4%| | 1833/40960 [00:05<01:30, 432.83batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 1922/40960 [00:05<01:29, 435.16batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   5%| | 1922/40960 [00:05<01:29, 435.16batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   5%| | 2006/40960 [00:05<01:30, 430.20batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   5%| | 2006/40960 [00:05<01:30, 430.20batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   5%| | 2092/40960 [00:05<01:30, 429.85batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   5%| | 2092/40960 [00:05<01:30, 429.85batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   5%| | 2181/40960 [00:05<01:29, 433.10batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   5%| | 2181/40960 [00:05<01:29, 433.10batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   6%| | 2270/40960 [00:06<01:28, 436.26batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   6%| | 2270/40960 [00:06<01:28, 436.26batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   6%| | 2364/40960 [00:06<01:26, 445.92batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   6%| | 2364/40960 [00:06<01:26, 445.92batches/s, l2_loss: 0.0265 - round_loss\u001b[A\n",
      "Training:   6%| | 2457/40960 [00:06<01:25, 451.54batches/s, l2_loss: 0.0265 - round_loss\u001b[A\n",
      "Training:   6%| | 2457/40960 [00:06<01:25, 451.54batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   6%| | 2543/40960 [00:06<01:26, 444.06batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   6%| | 2543/40960 [00:06<01:26, 444.06batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   6%| | 2630/40960 [00:06<01:26, 441.27batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   6%| | 2630/40960 [00:06<01:26, 441.27batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   7%| | 2723/40960 [00:07<01:25, 447.64batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   7%| | 2723/40960 [00:07<01:25, 447.64batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   7%| | 2809/40960 [00:07<01:26, 442.02batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   7%| | 2809/40960 [00:07<01:26, 442.02batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   7%| | 2893/40960 [00:07<01:27, 434.94batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   7%| | 2893/40960 [00:07<01:27, 434.94batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   7%| | 2980/40960 [00:07<01:27, 434.03batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   7%| | 2980/40960 [00:07<01:27, 434.03batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   7%| | 3066/40960 [00:07<01:27, 431.83batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   7%| | 3066/40960 [00:07<01:27, 431.83batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   8%| | 3151/40960 [00:08<01:27, 429.68batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   8%| | 3151/40960 [00:08<01:27, 429.68batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   8%| | 3242/40960 [00:08<01:26, 436.87batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   8%| | 3242/40960 [00:08<01:26, 436.87batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:   8%| | 3328/40960 [00:08<01:26, 433.36batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:   8%| | 3328/40960 [00:08<01:26, 433.36batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   8%| | 3414/40960 [00:08<01:26, 432.25batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   8%| | 3414/40960 [00:08<01:26, 432.25batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   9%| | 3503/40960 [00:08<01:25, 435.75batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   9%| | 3503/40960 [00:08<01:25, 435.75batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   9%| | 3591/40960 [00:09<01:25, 435.72batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   9%| | 3591/40960 [00:09<01:25, 435.72batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   9%| | 3682/40960 [00:09<01:24, 440.20batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:   9%| | 3682/40960 [00:09<01:24, 440.20batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   9%| | 3774/40960 [00:09<01:23, 445.84batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:   9%| | 3774/40960 [00:09<01:23, 445.84batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   9%| | 3862/40960 [00:09<01:23, 443.95batches/s, l2_loss: 0.0264 - round_loss\u001b[A\n",
      "Training:   9%| | 3862/40960 [00:09<01:23, 443.95batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  10%| | 3948/40960 [00:09<01:24, 439.24batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  10%| | 3948/40960 [00:09<01:24, 439.24batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  10%| | 4037/40960 [00:10<01:23, 439.89batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  10%| | 4037/40960 [00:10<01:23, 439.89batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  10%| | 4129/40960 [00:10<01:22, 444.72batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  10%| | 4129/40960 [00:10<01:22, 444.72batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  10%| | 4224/40960 [00:10<01:21, 452.35batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  10%| | 4224/40960 [00:10<01:21, 452.35batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  11%| | 4316/40960 [00:10<01:20, 454.43batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  11%| | 4316/40960 [00:10<01:20, 454.43batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  11%| | 4400/40960 [00:10<01:22, 443.28batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  11%| | 4400/40960 [00:10<01:22, 443.28batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  11%| | 4482/40960 [00:11<01:24, 433.04batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  11%| | 4482/40960 [00:11<01:24, 433.04batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  11%| | 4575/40960 [00:11<01:22, 441.49batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  11%| | 4575/40960 [00:11<01:22, 441.49batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  11%| | 4667/40960 [00:11<01:21, 446.61batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  11%| | 4667/40960 [00:11<01:21, 446.61batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  12%| | 4761/40960 [00:11<01:19, 453.12batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  12%| | 4761/40960 [00:11<01:19, 453.12batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  12%| | 4852/40960 [00:11<01:19, 453.28batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  12%| | 4852/40960 [00:11<01:19, 453.28batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  12%| | 4944/40960 [00:12<01:19, 454.97batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  12%| | 4944/40960 [00:12<01:19, 454.97batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  12%| | 5038/40960 [00:12<01:18, 459.02batches/s, l2_loss: 0.0263 - round_loss\u001b[A\n",
      "Training:  12%| | 5038/40960 [00:12<01:18, 459.02batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5132/40960 [00:12<01:17, 461.38batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5132/40960 [00:12<01:17, 461.38batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5226/40960 [00:12<01:17, 463.09batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5226/40960 [00:12<01:17, 463.09batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5317/40960 [00:12<01:17, 459.41batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5317/40960 [00:12<01:17, 459.41batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5392/40960 [00:13<01:21, 434.09batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5392/40960 [00:13<01:21, 434.09batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5475/40960 [00:13<01:22, 427.62batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5475/40960 [00:13<01:22, 427.62batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5562/40960 [00:13<01:22, 428.89batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5562/40960 [00:13<01:22, 428.89batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5651/40960 [00:13<01:21, 432.82batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5651/40960 [00:13<01:21, 432.82batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5740/40960 [00:13<01:21, 434.72batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5740/40960 [00:13<01:21, 434.72batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5830/40960 [00:14<01:20, 438.40batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|▏| 5830/40960 [00:14<01:20, 438.40batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5925/40960 [00:14<01:18, 448.63batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5925/40960 [00:14<01:18, 448.63batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6007/40960 [00:14<01:20, 436.57batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6007/40960 [00:14<01:20, 436.57batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6092/40960 [00:14<01:20, 432.98batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6092/40960 [00:14<01:20, 432.98batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6182/40960 [00:14<01:19, 437.91batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6182/40960 [00:14<01:19, 437.91batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6276/40960 [00:15<01:17, 446.41batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6276/40960 [00:15<01:17, 446.41batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6370/40960 [00:15<01:16, 452.22batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6370/40960 [00:15<01:16, 452.22batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6465/40960 [00:15<01:15, 458.08batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6465/40960 [00:15<01:15, 458.08batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6556/40960 [00:15<01:15, 456.09batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6556/40960 [00:15<01:15, 456.09batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6648/40960 [00:15<01:15, 456.26batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6648/40960 [00:15<01:15, 456.26batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6743/40960 [00:16<01:14, 460.96batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6743/40960 [00:16<01:14, 460.96batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6834/40960 [00:16<01:14, 458.61batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6834/40960 [00:16<01:14, 458.61batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6924/40960 [00:16<01:14, 454.92batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6924/40960 [00:16<01:14, 454.92batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7019/40960 [00:16<01:13, 460.71batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7019/40960 [00:16<01:13, 460.71batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7112/40960 [00:16<01:13, 461.62batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7112/40960 [00:16<01:13, 461.62batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7201/40960 [00:17<01:13, 456.41batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7201/40960 [00:17<01:13, 456.41batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7297/40960 [00:17<01:12, 462.84batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7297/40960 [00:17<01:12, 462.84batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7385/40960 [00:17<01:13, 455.66batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7385/40960 [00:17<01:13, 455.66batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7478/40960 [00:17<01:13, 457.45batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7478/40960 [00:17<01:13, 457.45batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7565/40960 [00:17<01:14, 449.51batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7565/40960 [00:17<01:14, 449.51batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7656/40960 [00:18<01:14, 449.96batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7656/40960 [00:18<01:14, 449.96batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7746/40960 [00:18<01:13, 449.12batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7746/40960 [00:18<01:13, 449.12batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7839/40960 [00:18<01:13, 452.76batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7839/40960 [00:18<01:13, 452.76batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7922/40960 [00:18<01:14, 441.34batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7922/40960 [00:18<01:14, 441.34batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8007/40960 [00:19<01:15, 435.02batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8007/40960 [00:19<01:15, 435.02batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8080/40960 [00:19<01:19, 413.89batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8080/40960 [00:19<01:19, 413.89batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8165/40960 [00:19<01:18, 415.70batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8165/40960 [00:19<01:18, 415.70batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8246/40960 [00:19<01:19, 412.05batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8246/40960 [00:19<01:19, 412.05batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8310/40960 [00:19<01:25, 383.79batches/s, l2_loss: 0.0274 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8310/40960 [00:19<01:25, 383.79batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8376/40960 [00:20<01:29, 365.95batches/s, l2_loss: 0.0270 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8376/40960 [00:20<01:29, 365.95batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8432/40960 [00:20<01:35, 339.47batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8432/40960 [00:20<01:35, 339.47batches/s, l2_loss: 0.0251 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8494/40960 [00:20<01:38, 330.13batches/s, l2_loss: 0.0251 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8494/40960 [00:20<01:38, 330.13batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8577/40960 [00:20<01:31, 354.29batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8577/40960 [00:20<01:31, 354.29batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8654/40960 [00:20<01:29, 362.94batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8654/40960 [00:20<01:29, 362.94batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8734/40960 [00:21<01:26, 373.05batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8734/40960 [00:21<01:26, 373.05batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8808/40960 [00:21<01:26, 371.60batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8808/40960 [00:21<01:26, 371.60batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8884/40960 [00:21<01:25, 373.60batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8884/40960 [00:21<01:25, 373.60batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8967/40960 [00:21<01:22, 385.73batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8967/40960 [00:21<01:22, 385.73batches/s, l2_loss: 0.0258 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9043/40960 [00:21<01:23, 383.50batches/s, l2_loss: 0.0258 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9043/40960 [00:21<01:23, 383.50batches/s, l2_loss: 0.0258 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9118/40960 [00:22<01:23, 379.67batches/s, l2_loss: 0.0258 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9118/40960 [00:22<01:23, 379.67batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9192/40960 [00:22<01:24, 375.86batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9192/40960 [00:22<01:24, 375.86batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9271/40960 [00:22<01:23, 381.06batches/s, l2_loss: 0.0262 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9271/40960 [00:22<01:23, 381.06batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9351/40960 [00:22<01:21, 386.18batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9351/40960 [00:22<01:21, 386.18batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9433/40960 [00:22<01:20, 392.98batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9433/40960 [00:22<01:20, 392.98batches/s, l2_loss: 0.0258 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9517/40960 [00:23<01:18, 400.36batches/s, l2_loss: 0.0258 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9517/40960 [00:23<01:18, 400.36batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|▏| 9599/40960 [00:23<01:17, 402.38batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9599/40960 [00:23<01:17, 402.38batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9678/40960 [00:23<01:18, 398.95batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9678/40960 [00:23<01:18, 398.95batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9759/40960 [00:23<01:18, 399.77batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9759/40960 [00:23<01:18, 399.77batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9831/40960 [00:23<01:20, 385.64batches/s, l2_loss: 0.0261 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9831/40960 [00:23<01:20, 385.64batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9910/40960 [00:24<01:20, 387.87batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9910/40960 [00:24<01:20, 387.87batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9995/40960 [00:24<01:17, 398.03batches/s, l2_loss: 0.0260 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9995/40960 [00:24<01:17, 398.03batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10082/40960 [00:24<01:15, 408.27batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  25%|▏| 10082/40960 [00:24<01:15, 408.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  25%|▏| 10167/40960 [00:24<01:14, 412.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  25%|▏| 10167/40960 [00:24<01:14, 412.22batches/s, l2_loss: 0.0257 - round_los\u001b[A\n",
      "Training:  25%|▎| 10246/40960 [00:24<01:15, 406.16batches/s, l2_loss: 0.0257 - round_los\u001b[A\n",
      "Training:  25%|▎| 10246/40960 [00:24<01:15, 406.16batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  25%|▎| 10326/40960 [00:25<01:15, 403.18batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  25%|▎| 10326/40960 [00:25<01:15, 403.18batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  25%|▎| 10410/40960 [00:25<01:15, 406.94batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  25%|▎| 10410/40960 [00:25<01:15, 406.94batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10497/40960 [00:25<01:13, 414.06batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10497/40960 [00:25<01:13, 414.06batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10580/40960 [00:25<01:13, 413.92batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10580/40960 [00:25<01:13, 413.92batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10663/40960 [00:25<01:13, 413.26batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10663/40960 [00:25<01:13, 413.26batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10743/40960 [00:26<01:14, 408.32batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10743/40960 [00:26<01:14, 408.32batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10822/40960 [00:26<01:14, 403.67batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  26%|▎| 10822/40960 [00:26<01:14, 403.67batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  27%|▎| 10901/40960 [00:26<01:15, 400.43batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  27%|▎| 10901/40960 [00:26<01:15, 400.43batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  27%|▎| 10982/40960 [00:26<01:14, 400.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  27%|▎| 10982/40960 [00:26<01:14, 400.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  27%|▎| 11059/40960 [00:26<01:15, 395.70batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  27%|▎| 11059/40960 [00:26<01:15, 395.70batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  27%|▎| 11138/40960 [00:27<01:15, 395.29batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  27%|▎| 11138/40960 [00:27<01:15, 395.29batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  27%|▎| 11222/40960 [00:27<01:13, 402.02batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  27%|▎| 11222/40960 [00:27<01:13, 402.02batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  28%|▎| 11299/40960 [00:27<01:14, 396.04batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  28%|▎| 11299/40960 [00:27<01:14, 396.04batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  28%|▎| 11385/40960 [00:27<01:12, 405.47batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  28%|▎| 11385/40960 [00:27<01:12, 405.47batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  28%|▎| 11471/40960 [00:27<01:11, 412.22batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  28%|▎| 11471/40960 [00:27<01:11, 412.22batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  28%|▎| 11554/40960 [00:28<01:11, 412.60batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  28%|▎| 11554/40960 [00:28<01:11, 412.60batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  28%|▎| 11638/40960 [00:28<01:10, 414.61batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  28%|▎| 11638/40960 [00:28<01:10, 414.61batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  29%|▎| 11721/40960 [00:28<01:10, 413.19batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  29%|▎| 11721/40960 [00:28<01:10, 413.19batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  29%|▎| 11798/40960 [00:28<01:12, 404.42batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  29%|▎| 11798/40960 [00:28<01:12, 404.42batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  29%|▎| 11877/40960 [00:28<01:12, 400.75batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  29%|▎| 11877/40960 [00:28<01:12, 400.75batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  29%|▎| 11956/40960 [00:29<01:12, 398.50batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  29%|▎| 11956/40960 [00:29<01:12, 398.50batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  29%|▎| 12037/40960 [00:29<01:12, 399.97batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  29%|▎| 12037/40960 [00:29<01:12, 399.97batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  30%|▎| 12120/40960 [00:29<01:11, 404.32batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  30%|▎| 12120/40960 [00:29<01:11, 404.32batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  30%|▎| 12198/40960 [00:29<01:12, 399.34batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  30%|▎| 12198/40960 [00:29<01:12, 399.34batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  30%|▎| 12274/40960 [00:29<01:12, 393.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  30%|▎| 12274/40960 [00:29<01:12, 393.27batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  30%|▎| 12354/40960 [00:30<01:12, 395.03batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  30%|▎| 12354/40960 [00:30<01:12, 395.03batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  30%|▎| 12438/40960 [00:30<01:10, 402.37batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  30%|▎| 12438/40960 [00:30<01:10, 402.37batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12521/40960 [00:30<01:10, 405.64batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12521/40960 [00:30<01:10, 405.64batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12598/40960 [00:30<01:11, 398.43batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12598/40960 [00:30<01:11, 398.43batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12677/40960 [00:30<01:11, 397.30batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12677/40960 [00:30<01:11, 397.30batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12760/40960 [00:31<01:10, 402.55batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12760/40960 [00:31<01:10, 402.55batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12845/40960 [00:31<01:08, 408.70batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  31%|▎| 12845/40960 [00:31<01:08, 408.70batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 12930/40960 [00:31<01:07, 413.49batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 12930/40960 [00:31<01:07, 413.49batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 13015/40960 [00:31<01:07, 416.43batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 13015/40960 [00:31<01:07, 416.43batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 13103/40960 [00:31<01:05, 422.50batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 13103/40960 [00:31<01:05, 422.50batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 13188/40960 [00:32<01:05, 421.88batches/s, l2_loss: 0.0259 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 13188/40960 [00:32<01:05, 421.88batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 13274/40960 [00:32<01:05, 423.81batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  32%|▎| 13274/40960 [00:32<01:05, 423.81batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  33%|▎| 13358/40960 [00:32<01:05, 422.22batches/s, l2_loss: 0.0260 - round_los\u001b[A\n",
      "Training:  33%|▎| 13358/40960 [00:32<01:05, 422.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  33%|▎| 13444/40960 [00:32<01:04, 423.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  33%|▎| 13444/40960 [00:32<01:04, 423.56batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  33%|▎| 13517/40960 [00:32<01:07, 405.03batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  33%|▎| 13517/40960 [00:32<01:07, 405.03batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  33%|▎| 13591/40960 [00:33<01:09, 394.40batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  33%|▎| 13591/40960 [00:33<01:09, 394.40batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  33%|▎| 13670/40960 [00:33<01:09, 393.93batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  33%|▎| 13670/40960 [00:33<01:09, 393.93batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  34%|▎| 13750/40960 [00:33<01:08, 395.63batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  34%|▎| 13750/40960 [00:33<01:08, 395.63batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  34%|▎| 13833/40960 [00:33<01:07, 401.31batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  34%|▎| 13833/40960 [00:33<01:07, 401.31batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  34%|▎| 13919/40960 [00:33<01:06, 409.64batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  34%|▎| 13919/40960 [00:33<01:06, 409.64batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  34%|▎| 14002/40960 [00:34<01:05, 410.49batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  34%|▎| 14002/40960 [00:34<01:05, 410.49batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  34%|▎| 14081/40960 [00:34<01:06, 404.53batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  34%|▎| 14081/40960 [00:34<01:06, 404.53batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  35%|▎| 14161/40960 [00:34<01:06, 402.92batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  35%|▎| 14161/40960 [00:34<01:06, 402.92batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  35%|▎| 14240/40960 [00:34<01:06, 400.12batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  35%|▎| 14240/40960 [00:34<01:06, 400.12batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  35%|▎| 14322/40960 [00:34<01:06, 402.59batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  35%|▎| 14322/40960 [00:34<01:06, 402.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  35%|▎| 14402/40960 [00:35<01:06, 400.58batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  35%|▎| 14402/40960 [00:35<01:06, 400.58batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  35%|▎| 14482/40960 [00:35<01:06, 399.39batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  35%|▎| 14482/40960 [00:35<01:06, 399.39batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  36%|▎| 14561/40960 [00:35<01:06, 397.99batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  36%|▎| 14561/40960 [00:35<01:06, 397.99batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  36%|▎| 14642/40960 [00:35<01:05, 398.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  36%|▎| 14642/40960 [00:35<01:05, 398.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  36%|▎| 14726/40960 [00:35<01:04, 404.91batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  36%|▎| 14726/40960 [00:35<01:04, 404.91batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  36%|▎| 14813/40960 [00:36<01:03, 413.07batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  36%|▎| 14813/40960 [00:36<01:03, 413.07batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  36%|▎| 14888/40960 [00:36<01:05, 400.71batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  36%|▎| 14888/40960 [00:36<01:05, 400.71batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  37%|▎| 14962/40960 [00:36<01:06, 391.24batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  37%|▎| 14962/40960 [00:36<01:06, 391.24batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  37%|▎| 15045/40960 [00:36<01:05, 397.14batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  37%|▎| 15045/40960 [00:36<01:05, 397.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  37%|▎| 15130/40960 [00:36<01:03, 405.24batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  37%|▎| 15130/40960 [00:36<01:03, 405.24batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  37%|▎| 15213/40960 [00:37<01:03, 407.07batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  37%|▎| 15213/40960 [00:37<01:03, 407.07batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  37%|▎| 15297/40960 [00:37<01:02, 410.82batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  37%|▎| 15297/40960 [00:37<01:02, 410.82batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15379/40960 [00:37<01:02, 409.68batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15379/40960 [00:37<01:02, 409.68batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15454/40960 [00:37<01:04, 398.42batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15454/40960 [00:37<01:04, 398.42batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15533/40960 [00:37<01:04, 396.20batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15533/40960 [00:37<01:04, 396.20batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  38%|▍| 15604/40960 [00:38<01:06, 383.30batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  38%|▍| 15604/40960 [00:38<01:06, 383.30batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15681/40960 [00:38<01:06, 382.84batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15681/40960 [00:38<01:06, 382.84batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15767/40960 [00:38<01:03, 396.71batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  38%|▍| 15767/40960 [00:38<01:03, 396.71batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  39%|▍| 15843/40960 [00:38<01:04, 390.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  39%|▍| 15843/40960 [00:38<01:04, 390.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  39%|▍| 15921/40960 [00:38<01:04, 389.77batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  39%|▍| 15921/40960 [00:38<01:04, 389.77batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  39%|▍| 15999/40960 [00:39<01:04, 388.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  39%|▍| 15999/40960 [00:39<01:04, 388.59batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  39%|▍| 16078/40960 [00:39<01:03, 389.93batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  39%|▍| 16078/40960 [00:39<01:03, 389.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  39%|▍| 16161/40960 [00:39<01:02, 397.37batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  39%|▍| 16161/40960 [00:39<01:02, 397.37batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  40%|▍| 16243/40960 [00:39<01:01, 400.91batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  40%|▍| 16243/40960 [00:39<01:01, 400.91batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  40%|▍| 16321/40960 [00:39<01:01, 397.47batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  40%|▍| 16321/40960 [00:39<01:01, 397.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  40%|▍| 16394/40960 [00:40<01:03, 387.65batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  40%|▍| 16394/40960 [00:40<01:03, 387.65batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  40%|▍| 16471/40960 [00:40<01:03, 386.78batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  40%|▍| 16471/40960 [00:40<01:03, 386.78batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  40%|▍| 16556/40960 [00:40<01:01, 397.57batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  40%|▍| 16556/40960 [00:40<01:01, 397.57batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  41%|▍| 16642/40960 [00:40<00:59, 406.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  41%|▍| 16642/40960 [00:40<00:59, 406.56batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  41%|▍| 16729/40960 [00:40<00:58, 413.71batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  41%|▍| 16729/40960 [00:40<00:58, 413.71batches/s, l2_loss: 0.0259 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|▍| 16809/40960 [00:41<00:58, 409.38batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  41%|▍| 16809/40960 [00:41<00:58, 409.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  41%|▍| 16894/40960 [00:41<00:58, 413.92batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  41%|▍| 16894/40960 [00:41<00:58, 413.92batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  41%|▍| 16980/40960 [00:41<00:57, 418.60batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  41%|▍| 16980/40960 [00:41<00:57, 418.60batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  42%|▍| 17064/40960 [00:41<00:57, 418.98batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  42%|▍| 17064/40960 [00:41<00:57, 418.98batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  42%|▍| 17150/40960 [00:41<00:56, 421.70batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  42%|▍| 17150/40960 [00:41<00:56, 421.70batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  42%|▍| 17234/40960 [00:42<00:56, 421.14batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  42%|▍| 17234/40960 [00:42<00:56, 421.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  42%|▍| 17316/40960 [00:42<00:56, 416.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  42%|▍| 17316/40960 [00:42<00:56, 416.87batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  42%|▍| 17390/40960 [00:42<00:58, 402.81batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  42%|▍| 17390/40960 [00:42<00:58, 402.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  43%|▍| 17461/40960 [00:42<01:00, 388.08batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  43%|▍| 17461/40960 [00:42<01:00, 388.08batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  43%|▍| 17535/40960 [00:42<01:01, 381.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  43%|▍| 17535/40960 [00:42<01:01, 381.66batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  43%|▍| 17615/40960 [00:43<01:00, 385.60batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  43%|▍| 17615/40960 [00:43<01:00, 385.60batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  43%|▍| 17697/40960 [00:43<00:59, 392.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  43%|▍| 17697/40960 [00:43<00:59, 392.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  43%|▍| 17781/40960 [00:43<00:57, 399.77batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  43%|▍| 17781/40960 [00:43<00:57, 399.77batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  44%|▍| 17866/40960 [00:43<00:56, 406.96batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  44%|▍| 17866/40960 [00:43<00:56, 406.96batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  44%|▍| 17952/40960 [00:43<00:55, 412.68batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  44%|▍| 17952/40960 [00:43<00:55, 412.68batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  44%|▍| 18037/40960 [00:44<00:55, 416.27batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  44%|▍| 18037/40960 [00:44<00:55, 416.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  44%|▍| 18121/40960 [00:44<00:54, 416.92batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  44%|▍| 18121/40960 [00:44<00:54, 416.92batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  44%|▍| 18199/40960 [00:44<00:55, 408.24batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  44%|▍| 18199/40960 [00:44<00:55, 408.24batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  45%|▍| 18274/40960 [00:44<00:57, 397.85batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  45%|▍| 18274/40960 [00:44<00:57, 397.85batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  45%|▍| 18356/40960 [00:44<00:56, 400.45batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  45%|▍| 18356/40960 [00:44<00:56, 400.45batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  45%|▍| 18443/40960 [00:45<00:54, 409.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  45%|▍| 18443/40960 [00:45<00:54, 409.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  45%|▍| 18515/40960 [00:45<00:56, 394.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  45%|▍| 18515/40960 [00:45<00:56, 394.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  45%|▍| 18600/40960 [00:45<00:55, 402.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  45%|▍| 18600/40960 [00:45<00:55, 402.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  46%|▍| 18686/40960 [00:45<00:54, 409.99batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  46%|▍| 18686/40960 [00:45<00:54, 409.99batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  46%|▍| 18768/40960 [00:45<00:54, 408.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  46%|▍| 18768/40960 [00:45<00:54, 408.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  46%|▍| 18845/40960 [00:46<00:55, 401.53batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  46%|▍| 18845/40960 [00:46<00:55, 401.53batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  46%|▍| 18926/40960 [00:46<00:54, 402.52batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  46%|▍| 18926/40960 [00:46<00:54, 402.52batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  46%|▍| 19009/40960 [00:46<00:54, 406.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  46%|▍| 19009/40960 [00:46<00:54, 406.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  47%|▍| 19094/40960 [00:46<00:53, 410.69batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  47%|▍| 19094/40960 [00:46<00:53, 410.69batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  47%|▍| 19177/40960 [00:46<00:52, 411.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  47%|▍| 19177/40960 [00:46<00:52, 411.89batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  47%|▍| 19260/40960 [00:47<00:52, 411.48batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  47%|▍| 19260/40960 [00:47<00:52, 411.48batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  47%|▍| 19336/40960 [00:47<00:53, 401.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  47%|▍| 19336/40960 [00:47<00:53, 401.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  47%|▍| 19415/40960 [00:47<00:53, 399.44batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  47%|▍| 19415/40960 [00:47<00:53, 399.44batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19499/40960 [00:47<00:53, 404.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19499/40960 [00:47<00:53, 404.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19582/40960 [00:47<00:52, 406.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19582/40960 [00:47<00:52, 406.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19667/40960 [00:48<00:51, 411.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19667/40960 [00:48<00:51, 411.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19749/40960 [00:48<00:51, 409.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19749/40960 [00:48<00:51, 409.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19832/40960 [00:48<00:51, 409.75batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  48%|▍| 19832/40960 [00:48<00:51, 409.75batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 19913/40960 [00:48<00:51, 407.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 19913/40960 [00:48<00:51, 407.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 19991/40960 [00:48<00:52, 401.71batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 19991/40960 [00:48<00:52, 401.71batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 20067/40960 [00:49<00:52, 394.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 20067/40960 [00:49<00:52, 394.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 20145/40960 [00:49<00:53, 392.19batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 20145/40960 [00:49<00:53, 392.19batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 20229/40960 [00:49<00:51, 399.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  49%|▍| 20229/40960 [00:49<00:51, 399.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▍| 20314/40960 [00:49<00:50, 405.95batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▍| 20314/40960 [00:49<00:50, 405.95batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▍| 20393/40960 [00:49<00:51, 402.39batches/s, l2_loss: 0.0258 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▍| 20393/40960 [00:49<00:51, 402.39batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▍| 20473/40960 [00:50<00:51, 400.36batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▍| 20473/40960 [00:50<00:51, 400.36batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▌| 20554/40960 [00:50<00:50, 400.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▌| 20554/40960 [00:50<00:50, 400.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▌| 20639/40960 [00:50<00:49, 407.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  50%|▌| 20639/40960 [00:50<00:49, 407.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  51%|▌| 20718/40960 [00:50<00:50, 403.35batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  51%|▌| 20718/40960 [00:50<00:50, 403.35batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  51%|▌| 20792/40960 [00:50<00:51, 393.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  51%|▌| 20792/40960 [00:50<00:51, 393.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  51%|▌| 20872/40960 [00:51<00:50, 394.95batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  51%|▌| 20872/40960 [00:51<00:50, 394.95batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  51%|▌| 20959/40960 [00:51<00:49, 406.29batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  51%|▌| 20959/40960 [00:51<00:49, 406.29batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  51%|▌| 21044/40960 [00:51<00:48, 410.62batches/s, l2_loss: 0.0259 - round_los\u001b[A\n",
      "Training:  51%|▌| 21044/40960 [00:51<00:48, 410.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21125/40960 [00:51<00:48, 408.77batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21125/40960 [00:51<00:48, 408.77batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21200/40960 [00:51<00:49, 398.34batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21200/40960 [00:51<00:49, 398.34batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21276/40960 [00:52<00:50, 392.02batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21276/40960 [00:52<00:50, 392.02batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21358/40960 [00:52<00:49, 396.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21358/40960 [00:52<00:49, 396.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21442/40960 [00:52<00:48, 403.03batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  52%|▌| 21442/40960 [00:52<00:48, 403.03batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21519/40960 [00:52<00:48, 397.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21519/40960 [00:52<00:48, 397.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21592/40960 [00:52<00:50, 386.74batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21592/40960 [00:52<00:50, 386.74batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21662/40960 [00:53<00:51, 375.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21662/40960 [00:53<00:51, 375.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21739/40960 [00:53<00:50, 377.41batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21739/40960 [00:53<00:50, 377.41batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21812/40960 [00:53<00:51, 373.68batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21812/40960 [00:53<00:51, 373.68batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21890/40960 [00:53<00:50, 377.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  53%|▌| 21890/40960 [00:53<00:50, 377.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 21962/40960 [00:53<00:51, 371.40batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 21962/40960 [00:54<00:51, 371.40batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 22038/40960 [00:54<00:50, 373.16batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 22038/40960 [00:54<00:50, 373.16batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 22116/40960 [00:54<00:50, 376.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 22116/40960 [00:54<00:50, 376.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 22190/40960 [00:54<00:50, 374.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 22190/40960 [00:54<00:50, 374.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 22267/40960 [00:54<00:49, 376.64batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  54%|▌| 22267/40960 [00:54<00:49, 376.64batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22340/40960 [00:55<00:49, 373.16batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22340/40960 [00:55<00:49, 373.16batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22413/40960 [00:55<00:50, 370.32batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22413/40960 [00:55<00:50, 370.32batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22492/40960 [00:55<00:48, 377.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22492/40960 [00:55<00:48, 377.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22573/40960 [00:55<00:47, 385.34batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22573/40960 [00:55<00:47, 385.34batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22649/40960 [00:55<00:47, 383.02batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22649/40960 [00:55<00:47, 383.02batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22720/40960 [00:56<00:48, 373.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  55%|▌| 22720/40960 [00:56<00:48, 373.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 22788/40960 [00:56<00:50, 362.36batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 22788/40960 [00:56<00:50, 362.36batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 22865/40960 [00:56<00:49, 368.79batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 22865/40960 [00:56<00:49, 368.79batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 22948/40960 [00:56<00:47, 382.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 22948/40960 [00:56<00:47, 382.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 23029/40960 [00:56<00:46, 388.63batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 23029/40960 [00:56<00:46, 388.63batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 23111/40960 [00:57<00:45, 394.45batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  56%|▌| 23111/40960 [00:57<00:45, 394.45batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23191/40960 [00:57<00:44, 395.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23191/40960 [00:57<00:44, 395.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23265/40960 [00:57<00:45, 386.88batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23265/40960 [00:57<00:45, 386.88batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23340/40960 [00:57<00:45, 383.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23340/40960 [00:57<00:45, 383.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23424/40960 [00:57<00:44, 393.78batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23424/40960 [00:57<00:44, 393.78batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23504/40960 [00:58<00:44, 395.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  57%|▌| 23504/40960 [00:58<00:44, 395.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23589/40960 [00:58<00:43, 402.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23589/40960 [00:58<00:43, 402.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23678/40960 [00:58<00:41, 414.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23678/40960 [00:58<00:41, 414.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23762/40960 [00:58<00:41, 416.30batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23762/40960 [00:58<00:41, 416.30batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23847/40960 [00:58<00:40, 417.82batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23847/40960 [00:58<00:40, 417.82batches/s, l2_loss: 0.0258 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|▌| 23923/40960 [00:59<00:41, 406.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  58%|▌| 23923/40960 [00:59<00:41, 406.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24000/40960 [00:59<00:42, 399.54batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24000/40960 [00:59<00:42, 399.54batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24085/40960 [00:59<00:41, 405.76batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24085/40960 [00:59<00:41, 405.76batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24163/40960 [00:59<00:42, 399.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24163/40960 [00:59<00:42, 399.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24239/40960 [00:59<00:42, 393.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24239/40960 [00:59<00:42, 393.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24320/40960 [01:00<00:41, 396.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  59%|▌| 24320/40960 [01:00<00:41, 396.84batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24401/40960 [01:00<00:41, 397.74batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24401/40960 [01:00<00:41, 397.74batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24481/40960 [01:00<00:41, 398.02batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24481/40960 [01:00<00:41, 398.02batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24561/40960 [01:00<00:41, 397.50batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24561/40960 [01:00<00:41, 397.50batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24638/40960 [01:00<00:41, 393.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24638/40960 [01:00<00:41, 393.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24710/40960 [01:01<00:42, 383.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  60%|▌| 24710/40960 [01:01<00:42, 383.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 24789/40960 [01:01<00:41, 386.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 24789/40960 [01:01<00:41, 386.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 24873/40960 [01:01<00:40, 396.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 24873/40960 [01:01<00:40, 396.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 24947/40960 [01:01<00:41, 387.69batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 24947/40960 [01:01<00:41, 387.69batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 25022/40960 [01:01<00:41, 382.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 25022/40960 [01:01<00:41, 382.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 25104/40960 [01:02<00:40, 390.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 25104/40960 [01:02<00:40, 390.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 25186/40960 [01:02<00:39, 396.32batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  61%|▌| 25186/40960 [01:02<00:39, 396.32batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  62%|▌| 25272/40960 [01:02<00:38, 405.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  62%|▌| 25272/40960 [01:02<00:38, 405.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  62%|▌| 25357/40960 [01:02<00:37, 411.11batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  62%|▌| 25357/40960 [01:02<00:37, 411.11batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  62%|▌| 25442/40960 [01:02<00:37, 415.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  62%|▌| 25442/40960 [01:02<00:37, 415.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  62%|▌| 25526/40960 [01:03<00:37, 416.01batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  62%|▌| 25526/40960 [01:03<00:37, 416.01batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25604/40960 [01:03<00:37, 406.41batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25604/40960 [01:03<00:37, 406.41batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25683/40960 [01:03<00:37, 403.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25683/40960 [01:03<00:37, 403.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25767/40960 [01:03<00:37, 407.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25767/40960 [01:03<00:37, 407.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25853/40960 [01:03<00:36, 413.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25853/40960 [01:03<00:36, 413.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25938/40960 [01:04<00:36, 416.09batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  63%|▋| 25938/40960 [01:04<00:36, 416.09batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26022/40960 [01:04<00:35, 416.58batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26022/40960 [01:04<00:35, 416.58batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26105/40960 [01:04<00:35, 415.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26105/40960 [01:04<00:35, 415.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26190/40960 [01:04<00:35, 418.24batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26190/40960 [01:04<00:35, 418.24batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26268/40960 [01:04<00:35, 408.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26268/40960 [01:04<00:35, 408.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26344/40960 [01:05<00:36, 399.96batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  64%|▋| 26344/40960 [01:05<00:36, 399.96batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26427/40960 [01:05<00:36, 403.64batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26427/40960 [01:05<00:36, 403.64batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26512/40960 [01:05<00:35, 409.94batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26512/40960 [01:05<00:35, 409.94batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26596/40960 [01:05<00:34, 412.60batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26596/40960 [01:05<00:34, 412.60batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26681/40960 [01:05<00:34, 416.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26681/40960 [01:05<00:34, 416.00batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26765/40960 [01:06<00:34, 416.07batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  65%|▋| 26765/40960 [01:06<00:34, 416.07batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 26847/40960 [01:06<00:34, 413.35batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 26847/40960 [01:06<00:34, 413.35batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 26929/40960 [01:06<00:34, 412.21batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 26929/40960 [01:06<00:34, 412.21batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 27011/40960 [01:06<00:33, 410.74batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 27011/40960 [01:06<00:33, 410.74batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 27094/40960 [01:06<00:33, 411.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 27094/40960 [01:06<00:33, 411.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 27178/40960 [01:07<00:33, 413.25batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  66%|▋| 27178/40960 [01:07<00:33, 413.25batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27264/40960 [01:07<00:32, 416.86batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27264/40960 [01:07<00:32, 416.86batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27348/40960 [01:07<00:32, 417.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27348/40960 [01:07<00:32, 417.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27433/40960 [01:07<00:32, 418.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27433/40960 [01:07<00:32, 418.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27519/40960 [01:07<00:31, 421.03batches/s, l2_loss: 0.0258 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|▋| 27519/40960 [01:07<00:31, 421.03batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27601/40960 [01:08<00:32, 417.23batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  67%|▋| 27601/40960 [01:08<00:32, 417.23batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 27687/40960 [01:08<00:31, 420.57batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 27687/40960 [01:08<00:31, 420.57batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 27769/40960 [01:08<00:31, 417.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 27769/40960 [01:08<00:31, 417.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 27854/40960 [01:08<00:31, 418.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 27854/40960 [01:08<00:31, 418.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 27938/40960 [01:08<00:31, 418.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 27938/40960 [01:08<00:31, 418.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 28022/40960 [01:09<00:30, 417.57batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  68%|▋| 28022/40960 [01:09<00:30, 417.57batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28105/40960 [01:09<00:30, 416.34batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28105/40960 [01:09<00:30, 416.34batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28192/40960 [01:09<00:30, 420.73batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28192/40960 [01:09<00:30, 420.73batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28277/40960 [01:09<00:30, 421.52batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28277/40960 [01:09<00:30, 421.52batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28360/40960 [01:09<00:30, 418.92batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28360/40960 [01:09<00:30, 418.92batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28440/40960 [01:10<00:30, 412.70batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  69%|▋| 28440/40960 [01:10<00:30, 412.70batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28512/40960 [01:10<00:31, 396.06batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28512/40960 [01:10<00:31, 396.06batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28587/40960 [01:10<00:31, 388.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28587/40960 [01:10<00:31, 388.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28672/40960 [01:10<00:30, 398.60batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28672/40960 [01:10<00:30, 398.60batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28753/40960 [01:10<00:30, 399.99batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28753/40960 [01:10<00:30, 399.99batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28835/40960 [01:11<00:30, 401.73batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  70%|▋| 28835/40960 [01:11<00:30, 401.73batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 28919/40960 [01:11<00:29, 406.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 28919/40960 [01:11<00:29, 406.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 28999/40960 [01:11<00:29, 404.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 28999/40960 [01:11<00:29, 404.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 29074/40960 [01:11<00:30, 394.30batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 29074/40960 [01:11<00:30, 394.30batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 29151/40960 [01:11<00:30, 390.17batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 29151/40960 [01:11<00:30, 390.17batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 29233/40960 [01:12<00:29, 395.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  71%|▋| 29233/40960 [01:12<00:29, 395.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29308/40960 [01:12<00:30, 388.31batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29308/40960 [01:12<00:30, 388.31batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29382/40960 [01:12<00:30, 381.48batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29382/40960 [01:12<00:30, 381.48batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29462/40960 [01:12<00:29, 386.73batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29462/40960 [01:12<00:29, 386.73batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29542/40960 [01:12<00:29, 390.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29542/40960 [01:12<00:29, 390.67batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29624/40960 [01:13<00:28, 395.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  72%|▋| 29624/40960 [01:13<00:28, 395.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 29705/40960 [01:13<00:28, 397.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 29705/40960 [01:13<00:28, 397.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 29788/40960 [01:13<00:27, 400.88batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 29788/40960 [01:13<00:27, 400.88batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 29865/40960 [01:13<00:28, 395.05batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 29865/40960 [01:13<00:28, 395.05batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 29939/40960 [01:13<00:28, 386.44batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 29939/40960 [01:13<00:28, 386.44batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 30024/40960 [01:14<00:27, 396.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  73%|▋| 30024/40960 [01:14<00:27, 396.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30109/40960 [01:14<00:26, 404.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30109/40960 [01:14<00:26, 404.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30191/40960 [01:14<00:26, 404.77batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30191/40960 [01:14<00:26, 404.77batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30278/40960 [01:14<00:25, 413.44batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30278/40960 [01:14<00:25, 413.44batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30355/40960 [01:14<00:26, 403.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30355/40960 [01:14<00:26, 403.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30431/40960 [01:15<00:26, 395.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30431/40960 [01:15<00:26, 395.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30515/40960 [01:15<00:25, 402.42batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  74%|▋| 30515/40960 [01:15<00:25, 402.42batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  75%|▋| 30600/40960 [01:15<00:25, 408.25batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  75%|▋| 30600/40960 [01:15<00:25, 408.25batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  75%|▋| 30685/40960 [01:15<00:24, 412.75batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  75%|▋| 30685/40960 [01:15<00:24, 412.75batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  75%|▊| 30770/40960 [01:15<00:24, 415.98batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  75%|▊| 30770/40960 [01:15<00:24, 415.98batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  75%|▊| 30854/40960 [01:16<00:24, 415.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  75%|▊| 30854/40960 [01:16<00:24, 415.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 30940/40960 [01:16<00:23, 419.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 30940/40960 [01:16<00:23, 419.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 31020/40960 [01:16<00:24, 412.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 31020/40960 [01:16<00:24, 412.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 31099/40960 [01:16<00:24, 406.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 31099/40960 [01:16<00:24, 406.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31178/40960 [01:16<00:24, 402.25batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 31178/40960 [01:16<00:24, 402.25batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 31260/40960 [01:17<00:23, 404.46batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  76%|▊| 31260/40960 [01:17<00:23, 404.46batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31335/40960 [01:17<00:24, 394.35batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31335/40960 [01:17<00:24, 394.35batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31411/40960 [01:17<00:24, 388.73batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31411/40960 [01:17<00:24, 388.73batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31489/40960 [01:17<00:24, 388.37batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31489/40960 [01:17<00:24, 388.37batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31566/40960 [01:17<00:24, 386.12batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31566/40960 [01:17<00:24, 386.12batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31644/40960 [01:18<00:24, 386.04batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31644/40960 [01:18<00:24, 386.04batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31714/40960 [01:18<00:24, 375.15batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  77%|▊| 31714/40960 [01:18<00:24, 375.15batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 31789/40960 [01:18<00:24, 373.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 31789/40960 [01:18<00:24, 373.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 31871/40960 [01:18<00:23, 383.48batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 31871/40960 [01:18<00:23, 383.48batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 31944/40960 [01:18<00:23, 376.79batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 31944/40960 [01:18<00:23, 376.79batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 32019/40960 [01:19<00:23, 375.17batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 32019/40960 [01:19<00:23, 375.17batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 32103/40960 [01:19<00:22, 387.88batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  78%|▊| 32103/40960 [01:19<00:22, 387.88batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32187/40960 [01:19<00:22, 397.15batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32187/40960 [01:19<00:22, 397.15batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32272/40960 [01:19<00:21, 405.46batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32272/40960 [01:19<00:21, 405.46batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32355/40960 [01:19<00:21, 406.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32355/40960 [01:19<00:21, 406.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32437/40960 [01:20<00:20, 406.96batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32437/40960 [01:20<00:20, 406.96batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32514/40960 [01:20<00:21, 400.06batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  79%|▊| 32514/40960 [01:20<00:21, 400.06batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32579/40960 [01:20<00:22, 376.53batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32579/40960 [01:20<00:22, 376.53batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32665/40960 [01:20<00:21, 391.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32665/40960 [01:20<00:21, 391.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32737/40960 [01:20<00:21, 381.26batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32737/40960 [01:20<00:21, 381.26batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32809/40960 [01:21<00:21, 373.70batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32809/40960 [01:21<00:21, 373.70batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32895/40960 [01:21<00:20, 389.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  80%|▊| 32895/40960 [01:21<00:20, 389.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 32979/40960 [01:21<00:20, 398.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 32979/40960 [01:21<00:20, 398.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33066/40960 [01:21<00:19, 407.88batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33066/40960 [01:21<00:19, 407.88batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33148/40960 [01:21<00:19, 408.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33148/40960 [01:21<00:19, 408.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33225/40960 [01:22<00:19, 399.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33225/40960 [01:22<00:19, 399.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33301/40960 [01:22<00:19, 392.76batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33301/40960 [01:22<00:19, 392.76batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33377/40960 [01:22<00:19, 387.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  81%|▊| 33377/40960 [01:22<00:19, 387.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33458/40960 [01:22<00:19, 392.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33458/40960 [01:22<00:19, 392.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33540/40960 [01:22<00:18, 396.50batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33540/40960 [01:22<00:18, 396.50batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33623/40960 [01:23<00:18, 400.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33623/40960 [01:23<00:18, 400.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33705/40960 [01:23<00:18, 402.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33705/40960 [01:23<00:18, 402.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33789/40960 [01:23<00:17, 407.08batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  82%|▊| 33789/40960 [01:23<00:17, 407.08batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  83%|▊| 33870/40960 [01:23<00:17, 406.39batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  83%|▊| 33870/40960 [01:23<00:17, 406.39batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  83%|▊| 33950/40960 [01:23<00:17, 403.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  83%|▊| 33950/40960 [01:23<00:17, 403.10batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  83%|▊| 34033/40960 [01:24<00:17, 405.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  83%|▊| 34033/40960 [01:24<00:17, 405.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  83%|▊| 34116/40960 [01:24<00:16, 407.74batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  83%|▊| 34116/40960 [01:24<00:16, 407.74batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34203/40960 [01:24<00:16, 414.85batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34203/40960 [01:24<00:16, 414.85batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34285/40960 [01:24<00:16, 413.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34285/40960 [01:24<00:16, 413.13batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34367/40960 [01:24<00:16, 411.48batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34367/40960 [01:24<00:16, 411.48batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34451/40960 [01:25<00:15, 412.91batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34451/40960 [01:25<00:15, 412.91batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34535/40960 [01:25<00:15, 414.86batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34535/40960 [01:25<00:15, 414.86batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34610/40960 [01:25<00:15, 402.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  84%|▊| 34610/40960 [01:25<00:15, 402.89batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 34688/40960 [01:25<00:15, 397.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34688/40960 [01:25<00:15, 397.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 34770/40960 [01:25<00:15, 400.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 34770/40960 [01:26<00:15, 400.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 34848/40960 [01:26<00:15, 397.25batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 34848/40960 [01:26<00:15, 397.25batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 34921/40960 [01:26<00:15, 387.61batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 34921/40960 [01:26<00:15, 387.61batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 35003/40960 [01:26<00:15, 394.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  85%|▊| 35003/40960 [01:26<00:15, 394.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35091/40960 [01:26<00:14, 406.69batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35091/40960 [01:26<00:14, 406.69batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35176/40960 [01:27<00:14, 411.18batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35176/40960 [01:27<00:14, 411.18batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35260/40960 [01:27<00:13, 412.64batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35260/40960 [01:27<00:13, 412.64batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35345/40960 [01:27<00:13, 416.21batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35345/40960 [01:27<00:13, 416.21batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35423/40960 [01:27<00:13, 407.80batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  86%|▊| 35423/40960 [01:27<00:13, 407.80batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35499/40960 [01:27<00:13, 398.61batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35499/40960 [01:27<00:13, 398.61batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35580/40960 [01:28<00:13, 400.05batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35580/40960 [01:28<00:13, 400.05batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35666/40960 [01:28<00:12, 408.68batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35666/40960 [01:28<00:12, 408.68batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35749/40960 [01:28<00:12, 410.31batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35749/40960 [01:28<00:12, 410.31batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35828/40960 [01:28<00:12, 404.32batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  87%|▊| 35828/40960 [01:28<00:12, 404.32batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 35899/40960 [01:28<00:12, 389.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 35899/40960 [01:28<00:12, 389.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 35978/40960 [01:29<00:12, 390.19batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 35978/40960 [01:29<00:12, 390.19batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 36056/40960 [01:29<00:12, 389.68batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 36056/40960 [01:29<00:12, 389.68batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 36137/40960 [01:29<00:12, 393.76batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 36137/40960 [01:29<00:12, 393.76batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 36221/40960 [01:29<00:11, 401.35batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  88%|▉| 36221/40960 [01:29<00:11, 401.35batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36308/40960 [01:29<00:11, 411.23batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36308/40960 [01:29<00:11, 411.23batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36388/40960 [01:30<00:11, 406.50batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36388/40960 [01:30<00:11, 406.50batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36473/40960 [01:30<00:10, 411.63batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36473/40960 [01:30<00:10, 411.63batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36559/40960 [01:30<00:10, 416.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36559/40960 [01:30<00:10, 416.22batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36646/40960 [01:30<00:10, 421.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  89%|▉| 36646/40960 [01:30<00:10, 421.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 36727/40960 [01:30<00:10, 415.65batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 36727/40960 [01:30<00:10, 415.65batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 36803/40960 [01:31<00:10, 404.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 36803/40960 [01:31<00:10, 404.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 36875/40960 [01:31<00:10, 390.17batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 36875/40960 [01:31<00:10, 390.17batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 36945/40960 [01:31<00:10, 377.43batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 36945/40960 [01:31<00:10, 377.43batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 37024/40960 [01:31<00:10, 382.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  90%|▉| 37024/40960 [01:31<00:10, 382.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37103/40960 [01:31<00:09, 386.03batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37103/40960 [01:31<00:09, 386.03batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37188/40960 [01:32<00:09, 396.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37188/40960 [01:32<00:09, 396.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37270/40960 [01:32<00:09, 400.63batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37270/40960 [01:32<00:09, 400.63batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37353/40960 [01:32<00:08, 404.01batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37353/40960 [01:32<00:08, 404.01batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37433/40960 [01:32<00:08, 402.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  91%|▉| 37433/40960 [01:32<00:08, 402.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37518/40960 [01:32<00:08, 408.75batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37518/40960 [01:32<00:08, 408.75batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37603/40960 [01:33<00:08, 412.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37603/40960 [01:33<00:08, 412.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37681/40960 [01:33<00:08, 405.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37681/40960 [01:33<00:08, 405.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37758/40960 [01:33<00:08, 398.70batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37758/40960 [01:33<00:08, 398.70batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37844/40960 [01:33<00:07, 407.04batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  92%|▉| 37844/40960 [01:33<00:07, 407.04batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 37930/40960 [01:33<00:07, 412.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 37930/40960 [01:33<00:07, 412.59batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 38015/40960 [01:34<00:07, 415.45batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 38015/40960 [01:34<00:07, 415.45batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 38098/40960 [01:34<00:06, 414.02batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 38098/40960 [01:34<00:06, 414.02batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 38175/40960 [01:34<00:06, 404.46batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 38175/40960 [01:34<00:06, 404.46batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 38253/40960 [01:34<00:06, 398.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  93%|▉| 38253/40960 [01:34<00:06, 398.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|▉| 38339/40960 [01:34<00:06, 407.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38339/40960 [01:34<00:06, 407.97batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [01:35<00:06, 412.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [01:35<00:06, 412.93batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38510/40960 [01:35<00:05, 417.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38510/40960 [01:35<00:05, 417.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38594/40960 [01:35<00:05, 416.99batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38594/40960 [01:35<00:05, 416.99batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38666/40960 [01:35<00:05, 399.69batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  94%|▉| 38666/40960 [01:35<00:05, 399.69batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 38741/40960 [01:35<00:05, 391.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 38741/40960 [01:35<00:05, 391.87batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 38817/40960 [01:36<00:05, 387.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 38817/40960 [01:36<00:05, 387.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 38902/40960 [01:36<00:05, 398.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 38902/40960 [01:36<00:05, 398.27batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 38988/40960 [01:36<00:04, 407.72batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 38988/40960 [01:36<00:04, 407.72batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 39069/40960 [01:36<00:04, 405.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  95%|▉| 39069/40960 [01:36<00:04, 405.81batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  96%|▉| 39143/40960 [01:36<00:04, 394.63batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  96%|▉| 39143/40960 [01:36<00:04, 394.63batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  96%|▉| 39223/40960 [01:37<00:04, 394.96batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  96%|▉| 39223/40960 [01:37<00:04, 394.96batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  96%|▉| 39308/40960 [01:37<00:04, 403.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  96%|▉| 39308/40960 [01:37<00:04, 403.66batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  96%|▉| 39396/40960 [01:37<00:03, 413.17batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  96%|▉| 39396/40960 [01:37<00:03, 413.17batches/s, l2_loss: 0.0257 - round_los\u001b[A\n",
      "Training:  96%|▉| 39474/40960 [01:37<00:03, 404.92batches/s, l2_loss: 0.0257 - round_los\u001b[A\n",
      "Training:  96%|▉| 39474/40960 [01:37<00:03, 404.92batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  97%|▉| 39550/40960 [01:37<00:03, 396.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  97%|▉| 39550/40960 [01:37<00:03, 396.14batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  97%|▉| 39627/40960 [01:38<00:03, 391.38batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  97%|▉| 39627/40960 [01:38<00:03, 391.38batches/s, l2_loss: 0.0257 - round_los\u001b[A\n",
      "Training:  97%|▉| 39695/40960 [01:38<00:03, 375.96batches/s, l2_loss: 0.0257 - round_los\u001b[A\n",
      "Training:  97%|▉| 39695/40960 [01:38<00:03, 375.96batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  97%|▉| 39772/40960 [01:38<00:03, 378.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  97%|▉| 39772/40960 [01:38<00:03, 378.47batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  97%|▉| 39856/40960 [01:38<00:02, 390.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  97%|▉| 39856/40960 [01:38<00:02, 390.28batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 39940/40960 [01:38<00:02, 398.18batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 39940/40960 [01:38<00:02, 398.18batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 40025/40960 [01:39<00:02, 405.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 40025/40960 [01:39<00:02, 405.83batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 40111/40960 [01:39<00:02, 411.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 40111/40960 [01:39<00:02, 411.51batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 40194/40960 [01:39<00:01, 412.08batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 40194/40960 [01:39<00:01, 412.08batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 40273/40960 [01:39<00:01, 406.07batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  98%|▉| 40273/40960 [01:39<00:01, 406.07batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40350/40960 [01:39<00:01, 399.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40350/40960 [01:39<00:01, 399.62batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40435/40960 [01:40<00:01, 407.18batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40435/40960 [01:40<00:01, 407.18batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40516/40960 [01:40<00:01, 406.37batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40516/40960 [01:40<00:01, 406.37batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40601/40960 [01:40<00:00, 410.98batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40601/40960 [01:40<00:00, 410.98batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40685/40960 [01:40<00:00, 413.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training:  99%|▉| 40685/40960 [01:40<00:00, 413.56batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training: 100%|▉| 40771/40960 [01:40<00:00, 417.95batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training: 100%|▉| 40771/40960 [01:40<00:00, 417.95batches/s, l2_loss: 0.0257 - round_los\u001b[A\n",
      "Training: 100%|▉| 40858/40960 [01:41<00:00, 423.05batches/s, l2_loss: 0.0257 - round_los\u001b[A\n",
      "Training: 100%|▉| 40858/40960 [01:41<00:00, 423.05batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training: 100%|▉| 40942/40960 [01:41<00:00, 420.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "Training: 100%|▉| 40942/40960 [01:41<00:00, 420.90batches/s, l2_loss: 0.0258 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:17:27.130257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  54%|▌| 14/26 [28:05<24:11, 120.93s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:17:28.402230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:17:33.675144: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<19:44:37,  1.74s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<19:44:37,  1.74s/batches, l2_loss: 0.0354 - round_loss:\u001b[A\n",
      "Training:   0%| | 71/40960 [00:01<13:39, 49.88batches/s, l2_loss: 0.0354 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 71/40960 [00:01<13:39, 49.88batches/s, l2_loss: 0.0732 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 140/40960 [00:02<06:50, 99.38batches/s, l2_loss: 0.0732 - round_loss: \u001b[A\n",
      "Training:   0%| | 140/40960 [00:02<06:50, 99.38batches/s, l2_loss: 0.0757 - round_loss: \u001b[A\n",
      "Training:   0%| | 202/40960 [00:02<04:51, 139.70batches/s, l2_loss: 0.0757 - round_loss:\u001b[A\n",
      "Training:   0%| | 202/40960 [00:02<04:51, 139.70batches/s, l2_loss: 0.0695 - round_loss:\u001b[A\n",
      "Training:   1%| | 266/40960 [00:02<03:48, 178.13batches/s, l2_loss: 0.0695 - round_loss:\u001b[A\n",
      "Training:   1%| | 266/40960 [00:02<03:48, 178.13batches/s, l2_loss: 0.0722 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%| | 326/40960 [00:02<03:17, 206.19batches/s, l2_loss: 0.0722 - round_loss:\u001b[A\n",
      "Training:   1%| | 326/40960 [00:02<03:17, 206.19batches/s, l2_loss: 0.0746 - round_loss:\u001b[A\n",
      "Training:   1%| | 385/40960 [00:02<02:58, 227.74batches/s, l2_loss: 0.0746 - round_loss:\u001b[A\n",
      "Training:   1%| | 385/40960 [00:02<02:58, 227.74batches/s, l2_loss: 0.0732 - round_loss:\u001b[A\n",
      "Training:   1%| | 441/40960 [00:03<02:48, 241.16batches/s, l2_loss: 0.0732 - round_loss:\u001b[A\n",
      "Training:   1%| | 441/40960 [00:03<02:48, 241.16batches/s, l2_loss: 0.0706 - round_loss:\u001b[A\n",
      "Training:   1%| | 499/40960 [00:03<02:39, 253.61batches/s, l2_loss: 0.0706 - round_loss:\u001b[A\n",
      "Training:   1%| | 499/40960 [00:03<02:39, 253.61batches/s, l2_loss: 0.0727 - round_loss:\u001b[A\n",
      "Training:   1%| | 554/40960 [00:03<02:35, 259.33batches/s, l2_loss: 0.0727 - round_loss:\u001b[A\n",
      "Training:   1%| | 554/40960 [00:03<02:35, 259.33batches/s, l2_loss: 0.0717 - round_loss:\u001b[A\n",
      "Training:   1%| | 612/40960 [00:03<02:32, 265.39batches/s, l2_loss: 0.0717 - round_loss:\u001b[A\n",
      "Training:   1%| | 612/40960 [00:03<02:32, 265.39batches/s, l2_loss: 0.0719 - round_loss:\u001b[A\n",
      "Training:   2%| | 653/40960 [00:03<02:43, 246.30batches/s, l2_loss: 0.0719 - round_loss:\u001b[A\n",
      "Training:   2%| | 653/40960 [00:03<02:43, 246.30batches/s, l2_loss: 0.0727 - round_loss:\u001b[A\n",
      "Training:   2%| | 712/40960 [00:04<02:34, 259.69batches/s, l2_loss: 0.0727 - round_loss:\u001b[A\n",
      "Training:   2%| | 712/40960 [00:04<02:34, 259.69batches/s, l2_loss: 0.0725 - round_loss:\u001b[A\n",
      "Training:   2%| | 774/40960 [00:04<02:26, 273.86batches/s, l2_loss: 0.0725 - round_loss:\u001b[A\n",
      "Training:   2%| | 774/40960 [00:04<02:26, 273.86batches/s, l2_loss: 0.0729 - round_loss:\u001b[A\n",
      "Training:   2%| | 836/40960 [00:04<02:21, 283.21batches/s, l2_loss: 0.0729 - round_loss:\u001b[A\n",
      "Training:   2%| | 836/40960 [00:04<02:21, 283.21batches/s, l2_loss: 0.0718 - round_loss:\u001b[A\n",
      "Training:   2%| | 892/40960 [00:04<02:22, 281.99batches/s, l2_loss: 0.0718 - round_loss:\u001b[A\n",
      "Training:   2%| | 892/40960 [00:04<02:22, 281.99batches/s, l2_loss: 0.0732 - round_loss:\u001b[A\n",
      "Training:   2%| | 955/40960 [00:04<02:17, 290.45batches/s, l2_loss: 0.0732 - round_loss:\u001b[A\n",
      "Training:   2%| | 955/40960 [00:04<02:17, 290.45batches/s, l2_loss: 0.0735 - round_loss:\u001b[A\n",
      "Training:   3%| | 1028/40960 [00:05<02:08, 311.67batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   3%| | 1028/40960 [00:05<02:08, 311.67batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   3%| | 1100/40960 [00:05<02:02, 324.68batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   3%| | 1100/40960 [00:05<02:02, 324.68batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   3%| | 1172/40960 [00:05<01:59, 334.27batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   3%| | 1172/40960 [00:05<01:59, 334.27batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   3%| | 1244/40960 [00:05<01:56, 341.47batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   3%| | 1244/40960 [00:05<01:56, 341.47batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   3%| | 1311/40960 [00:05<01:56, 339.01batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   3%| | 1311/40960 [00:05<01:56, 339.01batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   3%| | 1370/40960 [00:06<02:01, 325.31batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:   3%| | 1370/40960 [00:06<02:01, 325.31batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:   3%| | 1430/40960 [00:06<02:04, 316.26batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:   3%| | 1430/40960 [00:06<02:04, 316.26batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   4%| | 1501/40960 [00:06<02:00, 327.31batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   4%| | 1501/40960 [00:06<02:00, 327.31batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   4%| | 1575/40960 [00:06<01:55, 339.76batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   4%| | 1575/40960 [00:06<01:55, 339.76batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   4%| | 1640/40960 [00:06<01:57, 333.95batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   4%| | 1640/40960 [00:06<01:57, 333.95batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   4%| | 1707/40960 [00:07<01:57, 333.71batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   4%| | 1707/40960 [00:07<01:57, 333.71batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   4%| | 1774/40960 [00:07<01:57, 333.69batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   4%| | 1774/40960 [00:07<01:57, 333.69batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   4%| | 1840/40960 [00:07<01:57, 332.31batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   4%| | 1840/40960 [00:07<01:57, 332.31batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   5%| | 1908/40960 [00:07<01:57, 333.17batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   5%| | 1908/40960 [00:07<01:57, 333.17batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   5%| | 1974/40960 [00:07<01:57, 331.97batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   5%| | 1974/40960 [00:08<01:57, 331.97batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   5%| | 2042/40960 [00:08<01:56, 333.73batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   5%| | 2042/40960 [00:08<01:56, 333.73batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   5%| | 2114/40960 [00:08<01:53, 340.86batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   5%| | 2114/40960 [00:08<01:53, 340.86batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   5%| | 2186/40960 [00:08<01:51, 346.37batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   5%| | 2186/40960 [00:08<01:51, 346.37batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   5%| | 2251/40960 [00:08<01:54, 338.56batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:   5%| | 2251/40960 [00:08<01:54, 338.56batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   6%| | 2319/40960 [00:09<01:54, 338.65batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   6%| | 2319/40960 [00:09<01:54, 338.65batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   6%| | 2385/40960 [00:09<01:55, 334.73batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   6%| | 2385/40960 [00:09<01:55, 334.73batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   6%| | 2450/40960 [00:09<01:56, 330.90batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   6%| | 2450/40960 [00:09<01:56, 330.90batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   6%| | 2514/40960 [00:09<01:57, 326.67batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   6%| | 2514/40960 [00:09<01:57, 326.67batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   6%| | 2577/40960 [00:09<01:59, 322.55batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   6%| | 2577/40960 [00:09<01:59, 322.55batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   6%| | 2642/40960 [00:10<01:58, 323.24batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:   6%| | 2642/40960 [00:10<01:58, 323.24batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   7%| | 2712/40960 [00:10<01:55, 330.42batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   7%| | 2712/40960 [00:10<01:55, 330.42batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   7%| | 2781/40960 [00:10<01:54, 334.60batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   7%| | 2781/40960 [00:10<01:54, 334.60batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   7%| | 2841/40960 [00:10<01:57, 323.61batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:   7%| | 2841/40960 [00:10<01:57, 323.61batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   7%| | 2904/40960 [00:10<01:59, 319.50batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   7%| | 2904/40960 [00:10<01:59, 319.50batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   7%| | 2973/40960 [00:11<01:56, 327.02batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   7%| | 2973/40960 [00:11<01:56, 327.02batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   7%| | 3034/40960 [00:11<01:59, 318.48batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   7%| | 3034/40960 [00:11<01:59, 318.48batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   8%| | 3102/40960 [00:11<01:56, 324.26batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   8%| | 3102/40960 [00:11<01:56, 324.26batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   8%| | 3169/40960 [00:11<01:55, 326.17batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3169/40960 [00:11<01:55, 326.17batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   8%| | 3233/40960 [00:11<01:56, 324.17batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   8%| | 3233/40960 [00:11<01:56, 324.17batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   8%| | 3298/40960 [00:12<01:56, 323.50batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   8%| | 3298/40960 [00:12<01:56, 323.50batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   8%| | 3371/40960 [00:12<01:52, 334.49batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:   8%| | 3371/40960 [00:12<01:52, 334.49batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   8%| | 3441/40960 [00:12<01:50, 338.27batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   8%| | 3441/40960 [00:12<01:50, 338.27batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   9%| | 3514/40960 [00:12<01:48, 345.07batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   9%| | 3514/40960 [00:12<01:48, 345.07batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   9%| | 3575/40960 [00:12<01:52, 332.61batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   9%| | 3575/40960 [00:12<01:52, 332.61batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   9%| | 3646/40960 [00:13<01:50, 338.30batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:   9%| | 3646/40960 [00:13<01:50, 338.30batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   9%| | 3710/40960 [00:13<01:52, 331.66batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   9%| | 3710/40960 [00:13<01:52, 331.66batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   9%| | 3772/40960 [00:13<01:54, 324.96batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:   9%| | 3772/40960 [00:13<01:54, 324.96batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   9%| | 3842/40960 [00:13<01:51, 331.96batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:   9%| | 3842/40960 [00:13<01:51, 331.96batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 3910/40960 [00:13<01:51, 333.17batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 3910/40960 [00:13<01:51, 333.17batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 3976/40960 [00:14<01:51, 331.28batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 3976/40960 [00:14<01:51, 331.28batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 4040/40960 [00:14<01:52, 326.77batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  10%| | 4040/40960 [00:14<01:52, 326.77batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  10%| | 4107/40960 [00:14<01:52, 328.61batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  10%| | 4107/40960 [00:14<01:52, 328.61batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  10%| | 4177/40960 [00:14<01:50, 333.84batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  10%| | 4177/40960 [00:14<01:50, 333.84batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  10%| | 4247/40960 [00:14<01:48, 337.28batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  10%| | 4247/40960 [00:14<01:48, 337.28batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  11%| | 4316/40960 [00:15<01:47, 339.54batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  11%| | 4316/40960 [00:15<01:47, 339.54batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  11%| | 4386/40960 [00:15<01:46, 342.41batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  11%| | 4386/40960 [00:15<01:46, 342.41batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  11%| | 4450/40960 [00:15<01:48, 335.10batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  11%| | 4450/40960 [00:15<01:48, 335.10batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  11%| | 4514/40960 [00:15<01:50, 330.34batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  11%| | 4514/40960 [00:15<01:50, 330.34batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  11%| | 4581/40960 [00:15<01:49, 330.80batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  11%| | 4581/40960 [00:15<01:49, 330.80batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  11%| | 4653/40960 [00:16<01:47, 339.24batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  11%| | 4653/40960 [00:16<01:47, 339.24batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 4715/40960 [00:16<01:49, 329.51batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 4715/40960 [00:16<01:49, 329.51batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  12%| | 4778/40960 [00:16<01:51, 324.41batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  12%| | 4778/40960 [00:16<01:51, 324.41batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 4840/40960 [00:16<01:53, 318.54batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 4840/40960 [00:16<01:53, 318.54batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 4906/40960 [00:16<01:52, 320.96batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 4906/40960 [00:16<01:52, 320.96batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  12%| | 4974/40960 [00:17<01:50, 325.61batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  12%| | 4974/40960 [00:17<01:50, 325.61batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 5043/40960 [00:17<01:48, 330.70batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  12%| | 5043/40960 [00:17<01:48, 330.70batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 5108/40960 [00:17<01:49, 328.43batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 5108/40960 [00:17<01:49, 328.43batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5174/40960 [00:17<01:48, 328.79batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5174/40960 [00:17<01:48, 328.79batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5239/40960 [00:17<01:49, 327.50batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5239/40960 [00:17<01:49, 327.50batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5306/40960 [00:18<01:48, 328.65batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5306/40960 [00:18<01:48, 328.65batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5371/40960 [00:18<01:48, 326.51batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5371/40960 [00:18<01:48, 326.51batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5439/40960 [00:18<01:47, 329.75batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5439/40960 [00:18<01:47, 329.75batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5506/40960 [00:18<01:47, 331.31batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5506/40960 [00:18<01:47, 331.31batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5573/40960 [00:18<01:46, 332.36batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5573/40960 [00:18<01:46, 332.36batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5637/40960 [00:19<01:47, 327.61batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5637/40960 [00:19<01:47, 327.61batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5702/40960 [00:19<01:48, 325.71batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5702/40960 [00:19<01:48, 325.71batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5765/40960 [00:19<01:49, 322.46batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5765/40960 [00:19<01:49, 322.46batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5833/40960 [00:19<01:47, 327.43batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5833/40960 [00:19<01:47, 327.43batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5900/40960 [00:19<01:46, 329.62batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5900/40960 [00:19<01:46, 329.62batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5966/40960 [00:20<01:46, 328.57batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5966/40960 [00:20<01:46, 328.57batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6034/40960 [00:20<01:45, 330.56batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6034/40960 [00:20<01:45, 330.56batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6102/40960 [00:20<01:44, 333.30batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6102/40960 [00:20<01:44, 333.30batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 6170/40960 [00:20<01:44, 334.20batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6170/40960 [00:20<01:44, 334.20batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6236/40960 [00:20<01:44, 332.41batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6236/40960 [00:20<01:44, 332.41batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6300/40960 [00:21<01:45, 328.43batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6300/40960 [00:21<01:45, 328.43batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6364/40960 [00:21<01:46, 325.01batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6364/40960 [00:21<01:46, 325.01batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6428/40960 [00:21<01:46, 323.36batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6428/40960 [00:21<01:46, 323.36batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6493/40960 [00:21<01:46, 323.01batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6493/40960 [00:21<01:46, 323.01batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6559/40960 [00:21<01:46, 323.78batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6559/40960 [00:21<01:46, 323.78batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6622/40960 [00:22<01:47, 319.96batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6622/40960 [00:22<01:47, 319.96batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6688/40960 [00:22<01:46, 321.87batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6688/40960 [00:22<01:46, 321.87batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6754/40960 [00:22<01:45, 323.37batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6754/40960 [00:22<01:45, 323.37batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6821/40960 [00:22<01:44, 326.30batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6821/40960 [00:22<01:44, 326.30batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6889/40960 [00:22<01:43, 329.06batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6889/40960 [00:22<01:43, 329.06batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6957/40960 [00:23<01:42, 331.69batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6957/40960 [00:23<01:42, 331.69batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7022/40960 [00:23<01:43, 329.11batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7022/40960 [00:23<01:43, 329.11batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7090/40960 [00:23<01:41, 332.07batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7090/40960 [00:23<01:41, 332.07batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7159/40960 [00:23<01:40, 335.18batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7159/40960 [00:23<01:40, 335.18batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7229/40960 [00:23<01:39, 338.58batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7229/40960 [00:23<01:39, 338.58batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7298/40960 [00:24<01:38, 340.37batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7298/40960 [00:24<01:38, 340.37batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7367/40960 [00:24<01:38, 340.06batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7367/40960 [00:24<01:38, 340.06batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7427/40960 [00:24<01:42, 326.82batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7427/40960 [00:24<01:42, 326.82batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7493/40960 [00:24<01:42, 327.73batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7493/40960 [00:24<01:42, 327.73batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7560/40960 [00:24<01:41, 328.98batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7560/40960 [00:24<01:41, 328.98batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7629/40960 [00:25<01:40, 332.94batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7629/40960 [00:25<01:40, 332.94batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7697/40960 [00:25<01:39, 334.58batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7697/40960 [00:25<01:39, 334.58batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7760/40960 [00:25<01:41, 327.98batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7760/40960 [00:25<01:41, 327.98batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7821/40960 [00:25<01:43, 319.61batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7821/40960 [00:25<01:43, 319.61batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7889/40960 [00:25<01:41, 324.42batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7889/40960 [00:25<01:41, 324.42batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7962/40960 [00:26<01:38, 336.21batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7962/40960 [00:26<01:38, 336.21batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8015/40960 [00:26<01:44, 314.20batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8015/40960 [00:26<01:44, 314.20batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8086/40960 [00:26<01:40, 325.52batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8086/40960 [00:26<01:40, 325.52batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8156/40960 [00:26<01:38, 332.06batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8156/40960 [00:26<01:38, 332.06batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8222/40960 [00:26<01:39, 330.48batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8222/40960 [00:26<01:39, 330.48batches/s, l2_loss: 0.0799 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8286/40960 [00:27<01:39, 326.81batches/s, l2_loss: 0.0799 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8286/40960 [00:27<01:39, 326.81batches/s, l2_loss: 0.0768 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8347/40960 [00:27<01:42, 318.91batches/s, l2_loss: 0.0768 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8347/40960 [00:27<01:42, 318.91batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8407/40960 [00:27<01:44, 312.39batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8407/40960 [00:27<01:44, 312.39batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8470/40960 [00:27<01:43, 312.62batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8470/40960 [00:27<01:43, 312.62batches/s, l2_loss: 0.0710 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8536/40960 [00:27<01:42, 316.46batches/s, l2_loss: 0.0710 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8536/40960 [00:27<01:42, 316.46batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8604/40960 [00:28<01:40, 322.38batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8604/40960 [00:28<01:40, 322.38batches/s, l2_loss: 0.0694 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8668/40960 [00:28<01:40, 321.32batches/s, l2_loss: 0.0694 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8668/40960 [00:28<01:40, 321.32batches/s, l2_loss: 0.0705 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8735/40960 [00:28<01:39, 324.54batches/s, l2_loss: 0.0705 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8735/40960 [00:28<01:39, 324.54batches/s, l2_loss: 0.0703 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8801/40960 [00:28<01:38, 325.65batches/s, l2_loss: 0.0703 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8801/40960 [00:28<01:38, 325.65batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8861/40960 [00:28<01:41, 317.48batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8861/40960 [00:28<01:41, 317.48batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8919/40960 [00:29<01:43, 308.91batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8919/40960 [00:29<01:43, 308.91batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8985/40960 [00:29<01:41, 315.18batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8985/40960 [00:29<01:41, 315.18batches/s, l2_loss: 0.0706 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9049/40960 [00:29<01:41, 315.26batches/s, l2_loss: 0.0706 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|▏| 9049/40960 [00:29<01:41, 315.26batches/s, l2_loss: 0.0701 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9115/40960 [00:29<01:39, 319.15batches/s, l2_loss: 0.0701 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9115/40960 [00:29<01:39, 319.15batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9180/40960 [00:29<01:39, 320.17batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9180/40960 [00:29<01:39, 320.17batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9246/40960 [00:30<01:38, 321.81batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9246/40960 [00:30<01:38, 321.81batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9313/40960 [00:30<01:37, 324.37batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9313/40960 [00:30<01:37, 324.37batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9376/40960 [00:30<01:38, 320.94batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9376/40960 [00:30<01:38, 320.94batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9444/40960 [00:30<01:36, 325.62batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9444/40960 [00:30<01:36, 325.62batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9511/40960 [00:30<01:35, 328.10batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9511/40960 [00:30<01:35, 328.10batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9580/40960 [00:31<01:34, 332.36batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9580/40960 [00:31<01:34, 332.36batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9643/40960 [00:31<01:35, 326.78batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9643/40960 [00:31<01:35, 326.78batches/s, l2_loss: 0.0709 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9705/40960 [00:31<01:37, 321.38batches/s, l2_loss: 0.0709 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9705/40960 [00:31<01:37, 321.38batches/s, l2_loss: 0.0706 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9767/40960 [00:31<01:38, 317.10batches/s, l2_loss: 0.0706 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9767/40960 [00:31<01:38, 317.10batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9832/40960 [00:31<01:37, 318.51batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9832/40960 [00:31<01:37, 318.51batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9898/40960 [00:32<01:36, 320.59batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9898/40960 [00:32<01:36, 320.59batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9964/40960 [00:32<01:36, 322.31batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9964/40960 [00:32<01:36, 322.31batches/s, l2_loss: 0.0712 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10027/40960 [00:32<01:36, 319.15batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  24%|▏| 10027/40960 [00:32<01:36, 319.15batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  25%|▏| 10092/40960 [00:32<01:36, 320.56batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  25%|▏| 10092/40960 [00:32<01:36, 320.56batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  25%|▏| 10157/40960 [00:32<01:35, 321.36batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  25%|▏| 10157/40960 [00:32<01:35, 321.36batches/s, l2_loss: 0.0721 - round_los\u001b[A\n",
      "Training:  25%|▏| 10220/40960 [00:33<01:36, 318.54batches/s, l2_loss: 0.0721 - round_los\u001b[A\n",
      "Training:  25%|▏| 10220/40960 [00:33<01:36, 318.54batches/s, l2_loss: 0.0717 - round_los\u001b[A\n",
      "Training:  25%|▎| 10282/40960 [00:33<01:37, 315.49batches/s, l2_loss: 0.0717 - round_los\u001b[A\n",
      "Training:  25%|▎| 10282/40960 [00:33<01:37, 315.49batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  25%|▎| 10346/40960 [00:33<01:36, 315.76batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  25%|▎| 10346/40960 [00:33<01:36, 315.76batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  25%|▎| 10411/40960 [00:33<01:35, 318.38batches/s, l2_loss: 0.0710 - round_los\u001b[A\n",
      "Training:  25%|▎| 10411/40960 [00:33<01:35, 318.38batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  26%|▎| 10476/40960 [00:34<01:35, 320.11batches/s, l2_loss: 0.0708 - round_los\u001b[A\n",
      "Training:  26%|▎| 10476/40960 [00:34<01:35, 320.11batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  26%|▎| 10544/40960 [00:34<01:33, 324.87batches/s, l2_loss: 0.0709 - round_los\u001b[A\n",
      "Training:  26%|▎| 10544/40960 [00:34<01:33, 324.87batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  26%|▎| 10609/40960 [00:34<01:33, 323.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  26%|▎| 10609/40960 [00:34<01:33, 323.35batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  26%|▎| 10666/40960 [00:34<01:37, 310.77batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  26%|▎| 10666/40960 [00:34<01:37, 310.77batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  26%|▎| 10730/40960 [00:34<01:36, 312.95batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  26%|▎| 10730/40960 [00:34<01:36, 312.95batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  26%|▎| 10793/40960 [00:35<01:36, 312.66batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  26%|▎| 10793/40960 [00:35<01:36, 312.66batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  27%|▎| 10858/40960 [00:35<01:35, 315.63batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  27%|▎| 10858/40960 [00:35<01:35, 315.63batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  27%|▎| 10922/40960 [00:35<01:34, 316.85batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  27%|▎| 10922/40960 [00:35<01:34, 316.85batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  27%|▎| 10986/40960 [00:35<01:34, 317.56batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  27%|▎| 10986/40960 [00:35<01:34, 317.56batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  27%|▎| 11053/40960 [00:35<01:32, 321.75batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  27%|▎| 11053/40960 [00:35<01:32, 321.75batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  27%|▎| 11120/40960 [00:36<01:32, 324.13batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  27%|▎| 11120/40960 [00:36<01:32, 324.13batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  27%|▎| 11185/40960 [00:36<01:32, 323.32batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  27%|▎| 11185/40960 [00:36<01:32, 323.32batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  27%|▎| 11250/40960 [00:36<01:32, 322.80batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  27%|▎| 11250/40960 [00:36<01:32, 322.80batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  28%|▎| 11315/40960 [00:36<01:31, 323.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  28%|▎| 11315/40960 [00:36<01:31, 323.21batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  28%|▎| 11379/40960 [00:36<01:32, 321.44batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  28%|▎| 11379/40960 [00:36<01:32, 321.44batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  28%|▎| 11440/40960 [00:37<01:33, 316.14batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  28%|▎| 11440/40960 [00:37<01:33, 316.14batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  28%|▎| 11503/40960 [00:37<01:33, 314.43batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  28%|▎| 11503/40960 [00:37<01:33, 314.43batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  28%|▎| 11568/40960 [00:37<01:32, 316.18batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  28%|▎| 11568/40960 [00:37<01:32, 316.18batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  28%|▎| 11628/40960 [00:37<01:34, 311.14batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  28%|▎| 11628/40960 [00:37<01:34, 311.14batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  29%|▎| 11690/40960 [00:37<01:34, 310.63batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  29%|▎| 11690/40960 [00:37<01:34, 310.63batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  29%|▎| 11755/40960 [00:38<01:32, 314.13batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  29%|▎| 11755/40960 [00:38<01:32, 314.13batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  29%|▎| 11820/40960 [00:38<01:32, 316.37batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  29%|▎| 11820/40960 [00:38<01:32, 316.37batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  29%|▎| 11885/40960 [00:38<01:31, 318.29batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  29%|▎| 11885/40960 [00:38<01:31, 318.29batches/s, l2_loss: 0.0714 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|▎| 11951/40960 [00:38<01:30, 321.06batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  29%|▎| 11951/40960 [00:38<01:30, 321.06batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  29%|▎| 12016/40960 [00:38<01:29, 322.20batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  29%|▎| 12016/40960 [00:38<01:29, 322.20batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  29%|▎| 12081/40960 [00:39<01:29, 321.69batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  29%|▎| 12081/40960 [00:39<01:29, 321.69batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  30%|▎| 12146/40960 [00:39<01:29, 320.90batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  30%|▎| 12146/40960 [00:39<01:29, 320.90batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  30%|▎| 12210/40960 [00:39<01:30, 319.30batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  30%|▎| 12210/40960 [00:39<01:30, 319.30batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  30%|▎| 12277/40960 [00:39<01:28, 323.26batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  30%|▎| 12277/40960 [00:39<01:28, 323.26batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  30%|▎| 12343/40960 [00:39<01:28, 324.44batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  30%|▎| 12343/40960 [00:39<01:28, 324.44batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  30%|▎| 12407/40960 [00:40<01:28, 322.71batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  30%|▎| 12407/40960 [00:40<01:28, 322.71batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  30%|▎| 12472/40960 [00:40<01:28, 322.69batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  30%|▎| 12472/40960 [00:40<01:28, 322.69batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  31%|▎| 12538/40960 [00:40<01:27, 324.17batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  31%|▎| 12538/40960 [00:40<01:27, 324.17batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  31%|▎| 12603/40960 [00:40<01:27, 323.78batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  31%|▎| 12603/40960 [00:40<01:27, 323.78batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  31%|▎| 12668/40960 [00:40<01:27, 324.00batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  31%|▎| 12668/40960 [00:40<01:27, 324.00batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  31%|▎| 12733/40960 [00:41<01:27, 323.29batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  31%|▎| 12733/40960 [00:41<01:27, 323.29batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  31%|▎| 12800/40960 [00:41<01:26, 326.65batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  31%|▎| 12800/40960 [00:41<01:26, 326.65batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  31%|▎| 12864/40960 [00:41<01:26, 323.72batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  31%|▎| 12864/40960 [00:41<01:26, 323.72batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  32%|▎| 12931/40960 [00:41<01:25, 326.47batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  32%|▎| 12931/40960 [00:41<01:25, 326.47batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  32%|▎| 12998/40960 [00:41<01:25, 328.95batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  32%|▎| 12998/40960 [00:41<01:25, 328.95batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  32%|▎| 13064/40960 [00:42<01:25, 327.94batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  32%|▎| 13064/40960 [00:42<01:25, 327.94batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  32%|▎| 13128/40960 [00:42<01:25, 324.92batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  32%|▎| 13128/40960 [00:42<01:25, 324.92batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  32%|▎| 13195/40960 [00:42<01:24, 327.78batches/s, l2_loss: 0.0716 - round_los\u001b[A\n",
      "Training:  32%|▎| 13195/40960 [00:42<01:24, 327.78batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  32%|▎| 13261/40960 [00:42<01:24, 327.51batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  32%|▎| 13261/40960 [00:42<01:24, 327.51batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  33%|▎| 13328/40960 [00:42<01:23, 329.02batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  33%|▎| 13328/40960 [00:42<01:23, 329.02batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  33%|▎| 13395/40960 [00:43<01:23, 330.76batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  33%|▎| 13395/40960 [00:43<01:23, 330.76batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  33%|▎| 13462/40960 [00:43<01:22, 331.59batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  33%|▎| 13462/40960 [00:43<01:22, 331.59batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  33%|▎| 13521/40960 [00:43<01:25, 319.08batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  33%|▎| 13521/40960 [00:43<01:25, 319.08batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  33%|▎| 13585/40960 [00:43<01:25, 318.72batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  33%|▎| 13585/40960 [00:43<01:25, 318.72batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  33%|▎| 13651/40960 [00:43<01:25, 321.24batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  33%|▎| 13651/40960 [00:43<01:25, 321.24batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  33%|▎| 13718/40960 [00:44<01:23, 324.56batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  33%|▎| 13718/40960 [00:44<01:23, 324.56batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  34%|▎| 13784/40960 [00:44<01:23, 326.04batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  34%|▎| 13784/40960 [00:44<01:23, 326.04batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  34%|▎| 13850/40960 [00:44<01:22, 327.04batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  34%|▎| 13850/40960 [00:44<01:22, 327.04batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  34%|▎| 13916/40960 [00:44<01:22, 327.67batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  34%|▎| 13916/40960 [00:44<01:22, 327.67batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  34%|▎| 13982/40960 [00:44<01:22, 327.70batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  34%|▎| 13982/40960 [00:44<01:22, 327.70batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  34%|▎| 14044/40960 [00:45<01:23, 321.13batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  34%|▎| 14044/40960 [00:45<01:23, 321.13batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  34%|▎| 14100/40960 [00:45<01:27, 307.69batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  34%|▎| 14100/40960 [00:45<01:27, 307.69batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  35%|▎| 14156/40960 [00:45<01:29, 298.40batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  35%|▎| 14156/40960 [00:45<01:29, 298.40batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  35%|▎| 14218/40960 [00:45<01:28, 301.17batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  35%|▎| 14218/40960 [00:45<01:28, 301.17batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  35%|▎| 14278/40960 [00:45<01:28, 300.72batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  35%|▎| 14278/40960 [00:45<01:28, 300.72batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  35%|▎| 14343/40960 [00:46<01:26, 307.11batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  35%|▎| 14343/40960 [00:46<01:26, 307.11batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  35%|▎| 14408/40960 [00:46<01:25, 311.89batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  35%|▎| 14408/40960 [00:46<01:25, 311.89batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  35%|▎| 14477/40960 [00:46<01:22, 321.31batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  35%|▎| 14477/40960 [00:46<01:22, 321.31batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  35%|▎| 14539/40960 [00:46<01:23, 317.15batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  35%|▎| 14539/40960 [00:46<01:23, 317.15batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  36%|▎| 14599/40960 [00:46<01:24, 310.19batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  36%|▎| 14599/40960 [00:46<01:24, 310.19batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  36%|▎| 14663/40960 [00:47<01:24, 312.64batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  36%|▎| 14663/40960 [00:47<01:24, 312.64batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  36%|▎| 14729/40960 [00:47<01:22, 316.64batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  36%|▎| 14729/40960 [00:47<01:22, 316.64batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  36%|▎| 14793/40960 [00:47<01:22, 316.66batches/s, l2_loss: 0.0713 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|▎| 14793/40960 [00:47<01:22, 316.66batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  36%|▎| 14855/40960 [00:47<01:23, 313.31batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  36%|▎| 14855/40960 [00:47<01:23, 313.31batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  36%|▎| 14920/40960 [00:47<01:22, 316.26batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  36%|▎| 14920/40960 [00:47<01:22, 316.26batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  37%|▎| 14988/40960 [00:48<01:20, 321.95batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  37%|▎| 14988/40960 [00:48<01:20, 321.95batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  37%|▎| 15053/40960 [00:48<01:20, 322.44batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  37%|▎| 15053/40960 [00:48<01:20, 322.44batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  37%|▎| 15119/40960 [00:48<01:19, 323.34batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  37%|▎| 15119/40960 [00:48<01:19, 323.34batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  37%|▎| 15183/40960 [00:48<01:20, 321.25batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  37%|▎| 15183/40960 [00:48<01:20, 321.25batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  37%|▎| 15246/40960 [00:48<01:20, 318.55batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  37%|▎| 15246/40960 [00:48<01:20, 318.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  37%|▎| 15312/40960 [00:49<01:19, 321.38batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  37%|▎| 15312/40960 [00:49<01:19, 321.38batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15375/40960 [00:49<01:20, 319.06batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15375/40960 [00:49<01:20, 319.06batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15440/40960 [00:49<01:19, 319.92batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15440/40960 [00:49<01:19, 319.92batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  38%|▍| 15506/40960 [00:49<01:18, 322.64batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  38%|▍| 15506/40960 [00:49<01:18, 322.64batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15571/40960 [00:49<01:18, 322.00batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15571/40960 [00:49<01:18, 322.00batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15630/40960 [00:50<01:20, 313.50batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15630/40960 [00:50<01:20, 313.50batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  38%|▍| 15688/40960 [00:50<01:22, 305.00batches/s, l2_loss: 0.0715 - round_los\u001b[A\n",
      "Training:  38%|▍| 15688/40960 [00:50<01:22, 305.00batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15753/40960 [00:50<01:21, 309.61batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  38%|▍| 15753/40960 [00:50<01:21, 309.61batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  39%|▍| 15818/40960 [00:50<01:20, 312.96batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  39%|▍| 15818/40960 [00:50<01:20, 312.96batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  39%|▍| 15882/40960 [00:50<01:19, 314.12batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  39%|▍| 15882/40960 [00:50<01:19, 314.12batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  39%|▍| 15940/40960 [00:51<01:21, 306.89batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  39%|▍| 15940/40960 [00:51<01:21, 306.89batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  39%|▍| 16004/40960 [00:51<01:20, 310.06batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  39%|▍| 16004/40960 [00:51<01:20, 310.06batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  39%|▍| 16064/40960 [00:51<01:21, 305.74batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  39%|▍| 16064/40960 [00:51<01:21, 305.74batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  39%|▍| 16131/40960 [00:51<01:19, 313.97batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  39%|▍| 16131/40960 [00:51<01:19, 313.97batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16197/40960 [00:51<01:17, 317.61batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16197/40960 [00:51<01:17, 317.61batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16260/40960 [00:52<01:18, 315.71batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16260/40960 [00:52<01:18, 315.71batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  40%|▍| 16325/40960 [00:52<01:17, 318.44batches/s, l2_loss: 0.0714 - round_los\u001b[A\n",
      "Training:  40%|▍| 16325/40960 [00:52<01:17, 318.44batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16387/40960 [00:52<01:18, 314.90batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16387/40960 [00:52<01:18, 314.90batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16449/40960 [00:52<01:18, 312.68batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16449/40960 [00:52<01:18, 312.68batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16516/40960 [00:52<01:16, 319.00batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16516/40960 [00:52<01:16, 319.00batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16581/40960 [00:53<01:16, 319.55batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  40%|▍| 16581/40960 [00:53<01:16, 319.55batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  41%|▍| 16647/40960 [00:53<01:15, 322.34batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  41%|▍| 16647/40960 [00:53<01:15, 322.34batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  41%|▍| 16701/40960 [00:53<01:19, 305.27batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  41%|▍| 16701/40960 [00:53<01:19, 305.27batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  41%|▍| 16764/40960 [00:53<01:18, 307.09batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  41%|▍| 16764/40960 [00:53<01:18, 307.09batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  41%|▍| 16821/40960 [00:53<01:20, 300.34batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  41%|▍| 16821/40960 [00:53<01:20, 300.34batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  41%|▍| 16887/40960 [00:54<01:18, 308.49batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  41%|▍| 16887/40960 [00:54<01:18, 308.49batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  41%|▍| 16949/40960 [00:54<01:17, 308.45batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  41%|▍| 16949/40960 [00:54<01:17, 308.45batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  42%|▍| 17014/40960 [00:54<01:16, 312.46batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  42%|▍| 17014/40960 [00:54<01:16, 312.46batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  42%|▍| 17079/40960 [00:54<01:15, 315.44batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  42%|▍| 17079/40960 [00:54<01:15, 315.44batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  42%|▍| 17144/40960 [00:54<01:15, 316.96batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  42%|▍| 17144/40960 [00:54<01:15, 316.96batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  42%|▍| 17209/40960 [00:55<01:14, 319.25batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  42%|▍| 17209/40960 [00:55<01:14, 319.25batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  42%|▍| 17270/40960 [00:55<01:15, 313.27batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  42%|▍| 17270/40960 [00:55<01:15, 313.27batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  42%|▍| 17326/40960 [00:55<01:17, 303.30batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  42%|▍| 17326/40960 [00:55<01:17, 303.30batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  42%|▍| 17390/40960 [00:55<01:16, 307.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  42%|▍| 17390/40960 [00:55<01:16, 307.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  43%|▍| 17445/40960 [00:55<01:18, 297.69batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  43%|▍| 17445/40960 [00:55<01:18, 297.69batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  43%|▍| 17510/40960 [00:56<01:16, 305.40batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  43%|▍| 17510/40960 [00:56<01:16, 305.40batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  43%|▍| 17573/40960 [00:56<01:16, 307.03batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  43%|▍| 17573/40960 [00:56<01:16, 307.03batches/s, l2_loss: 0.0713 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17631/40960 [00:56<01:17, 301.71batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  43%|▍| 17631/40960 [00:56<01:17, 301.71batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  43%|▍| 17695/40960 [00:56<01:15, 307.16batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  43%|▍| 17695/40960 [00:56<01:15, 307.16batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  43%|▍| 17750/40960 [00:56<01:18, 296.36batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  43%|▍| 17750/40960 [00:56<01:18, 296.36batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  43%|▍| 17811/40960 [00:57<01:17, 297.51batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  43%|▍| 17811/40960 [00:57<01:17, 297.51batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 17870/40960 [00:57<01:17, 296.62batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 17870/40960 [00:57<01:17, 296.62batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 17932/40960 [00:57<01:16, 300.09batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 17932/40960 [00:57<01:16, 300.09batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 17997/40960 [00:57<01:14, 306.80batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 17997/40960 [00:57<01:14, 306.80batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  44%|▍| 18063/40960 [00:57<01:13, 312.92batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  44%|▍| 18063/40960 [00:58<01:13, 312.92batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 18124/40960 [00:58<01:13, 309.21batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 18124/40960 [00:58<01:13, 309.21batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 18187/40960 [00:58<01:13, 310.91batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  44%|▍| 18187/40960 [00:58<01:13, 310.91batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  45%|▍| 18253/40960 [00:58<01:12, 314.83batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  45%|▍| 18253/40960 [00:58<01:12, 314.83batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  45%|▍| 18312/40960 [00:58<01:13, 307.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  45%|▍| 18312/40960 [00:58<01:13, 307.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  45%|▍| 18378/40960 [00:59<01:12, 312.83batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  45%|▍| 18378/40960 [00:59<01:12, 312.83batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  45%|▍| 18442/40960 [00:59<01:11, 314.37batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  45%|▍| 18442/40960 [00:59<01:11, 314.37batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  45%|▍| 18499/40960 [00:59<01:13, 305.31batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  45%|▍| 18499/40960 [00:59<01:13, 305.31batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  45%|▍| 18562/40960 [00:59<01:12, 306.82batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  45%|▍| 18562/40960 [00:59<01:12, 306.82batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  45%|▍| 18625/40960 [00:59<01:12, 308.51batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  45%|▍| 18625/40960 [00:59<01:12, 308.51batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  46%|▍| 18689/40960 [01:00<01:11, 311.02batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  46%|▍| 18689/40960 [01:00<01:11, 311.02batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18752/40960 [01:00<01:11, 312.13batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18752/40960 [01:00<01:11, 312.13batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18815/40960 [01:00<01:11, 311.83batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18815/40960 [01:00<01:11, 311.83batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18865/40960 [01:00<01:15, 292.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18865/40960 [01:00<01:15, 292.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18919/40960 [01:00<01:17, 285.01batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18919/40960 [01:00<01:17, 285.01batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18984/40960 [01:01<01:14, 296.88batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  46%|▍| 18984/40960 [01:01<01:14, 296.88batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19049/40960 [01:01<01:11, 304.49batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19049/40960 [01:01<01:11, 304.49batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  47%|▍| 19108/40960 [01:01<01:12, 301.63batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  47%|▍| 19108/40960 [01:01<01:12, 301.63batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19172/40960 [01:01<01:11, 306.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19172/40960 [01:01<01:11, 306.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19236/40960 [01:01<01:10, 310.20batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19236/40960 [01:01<01:10, 310.20batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19302/40960 [01:02<01:08, 315.92batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19302/40960 [01:02<01:08, 315.92batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19369/40960 [01:02<01:07, 320.25batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  47%|▍| 19369/40960 [01:02<01:07, 320.25batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  47%|▍| 19433/40960 [01:02<01:07, 319.40batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  47%|▍| 19433/40960 [01:02<01:07, 319.40batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  48%|▍| 19494/40960 [01:02<01:08, 314.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  48%|▍| 19494/40960 [01:02<01:08, 314.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  48%|▍| 19560/40960 [01:02<01:07, 317.96batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  48%|▍| 19560/40960 [01:02<01:07, 317.96batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  48%|▍| 19622/40960 [01:03<01:07, 314.42batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  48%|▍| 19622/40960 [01:03<01:07, 314.42batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  48%|▍| 19687/40960 [01:03<01:07, 316.63batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  48%|▍| 19687/40960 [01:03<01:07, 316.63batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  48%|▍| 19750/40960 [01:03<01:07, 315.94batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  48%|▍| 19750/40960 [01:03<01:07, 315.94batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  48%|▍| 19811/40960 [01:03<01:07, 312.12batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  48%|▍| 19811/40960 [01:03<01:07, 312.12batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 19874/40960 [01:03<01:07, 312.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 19874/40960 [01:03<01:07, 312.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 19933/40960 [01:04<01:08, 306.47batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 19933/40960 [01:04<01:08, 306.47batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 19988/40960 [01:04<01:10, 295.92batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 19988/40960 [01:04<01:10, 295.92batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 20054/40960 [01:04<01:08, 305.59batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 20054/40960 [01:04<01:08, 305.59batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 20108/40960 [01:04<01:10, 294.54batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 20108/40960 [01:04<01:10, 294.54batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 20171/40960 [01:04<01:09, 300.56batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 20171/40960 [01:04<01:09, 300.56batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 20237/40960 [01:05<01:07, 308.66batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  49%|▍| 20237/40960 [01:05<01:07, 308.66batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▍| 20303/40960 [01:05<01:05, 314.12batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▍| 20303/40960 [01:05<01:05, 314.12batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▍| 20369/40960 [01:05<01:04, 318.85batches/s, l2_loss: 0.0712 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▍| 20369/40960 [01:05<01:04, 318.85batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▍| 20433/40960 [01:05<01:04, 317.89batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▍| 20433/40960 [01:05<01:04, 317.89batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▌| 20498/40960 [01:05<01:04, 318.84batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▌| 20498/40960 [01:05<01:04, 318.84batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▌| 20561/40960 [01:06<01:04, 317.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▌| 20561/40960 [01:06<01:04, 317.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▌| 20624/40960 [01:06<01:04, 315.17batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  50%|▌| 20624/40960 [01:06<01:04, 315.17batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20687/40960 [01:06<01:04, 314.01batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20687/40960 [01:06<01:04, 314.01batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20749/40960 [01:06<01:04, 311.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20749/40960 [01:06<01:04, 311.55batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  51%|▌| 20806/40960 [01:06<01:06, 302.36batches/s, l2_loss: 0.0713 - round_los\u001b[A\n",
      "Training:  51%|▌| 20806/40960 [01:06<01:06, 302.36batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20870/40960 [01:07<01:05, 306.19batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20870/40960 [01:07<01:05, 306.19batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20933/40960 [01:07<01:05, 307.57batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20933/40960 [01:07<01:05, 307.57batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20979/40960 [01:07<01:10, 282.97batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 20979/40960 [01:07<01:10, 282.97batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 21036/40960 [01:07<01:10, 281.85batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 21036/40960 [01:07<01:10, 281.85batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 21093/40960 [01:07<01:10, 282.73batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  51%|▌| 21093/40960 [01:07<01:10, 282.73batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21159/40960 [01:08<01:06, 295.60batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21159/40960 [01:08<01:06, 295.60batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21225/40960 [01:08<01:04, 305.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21225/40960 [01:08<01:04, 305.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21286/40960 [01:08<01:04, 303.58batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21286/40960 [01:08<01:04, 303.58batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21347/40960 [01:08<01:04, 303.35batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21347/40960 [01:08<01:04, 303.35batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21400/40960 [01:08<01:07, 289.37batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21400/40960 [01:08<01:07, 289.37batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21454/40960 [01:09<01:08, 283.59batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  52%|▌| 21454/40960 [01:09<01:08, 283.59batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21511/40960 [01:09<01:08, 282.87batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21511/40960 [01:09<01:08, 282.87batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21576/40960 [01:09<01:05, 295.30batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21576/40960 [01:09<01:05, 295.30batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  53%|▌| 21636/40960 [01:09<01:05, 296.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  53%|▌| 21636/40960 [01:09<01:05, 296.21batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21703/40960 [01:09<01:02, 306.82batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21703/40960 [01:09<01:02, 306.82batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21770/40960 [01:10<01:01, 314.22batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21770/40960 [01:10<01:01, 314.22batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21835/40960 [01:10<01:00, 316.72batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  53%|▌| 21835/40960 [01:10<01:00, 316.72batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  53%|▌| 21891/40960 [01:10<01:02, 304.17batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  53%|▌| 21891/40960 [01:10<01:02, 304.17batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 21946/40960 [01:10<01:04, 294.29batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 21946/40960 [01:10<01:04, 294.29batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 22009/40960 [01:10<01:03, 300.40batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 22009/40960 [01:10<01:03, 300.40batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 22068/40960 [01:11<01:03, 298.19batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 22068/40960 [01:11<01:03, 298.19batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 22131/40960 [01:11<01:02, 301.81batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 22131/40960 [01:11<01:02, 301.81batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 22193/40960 [01:11<01:01, 303.29batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  54%|▌| 22193/40960 [01:11<01:01, 303.29batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  54%|▌| 22259/40960 [01:11<01:00, 310.41batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  54%|▌| 22259/40960 [01:11<01:00, 310.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22324/40960 [01:11<00:59, 313.81batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22324/40960 [01:11<00:59, 313.81batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22390/40960 [01:12<00:58, 318.21batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22390/40960 [01:12<00:58, 318.21batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22451/40960 [01:12<00:58, 314.08batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22451/40960 [01:12<00:58, 314.08batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  55%|▌| 22514/40960 [01:12<00:58, 313.03batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  55%|▌| 22514/40960 [01:12<00:58, 313.03batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  55%|▌| 22576/40960 [01:12<00:59, 310.79batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  55%|▌| 22576/40960 [01:12<00:59, 310.79batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22640/40960 [01:12<00:58, 312.96batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22640/40960 [01:12<00:58, 312.96batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22705/40960 [01:13<00:57, 315.53batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  55%|▌| 22705/40960 [01:13<00:57, 315.53batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  56%|▌| 22771/40960 [01:13<00:56, 319.66batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  56%|▌| 22771/40960 [01:13<00:56, 319.66batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  56%|▌| 22836/40960 [01:13<00:56, 320.33batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  56%|▌| 22836/40960 [01:13<00:56, 320.33batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  56%|▌| 22895/40960 [01:13<00:57, 311.78batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  56%|▌| 22895/40960 [01:13<00:57, 311.78batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  56%|▌| 22960/40960 [01:13<00:57, 315.06batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  56%|▌| 22960/40960 [01:13<00:57, 315.06batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  56%|▌| 23028/40960 [01:14<00:55, 321.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  56%|▌| 23028/40960 [01:14<00:55, 321.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  56%|▌| 23094/40960 [01:14<00:55, 323.84batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  56%|▌| 23094/40960 [01:14<00:55, 323.84batches/s, l2_loss: 0.0712 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|▌| 23154/40960 [01:14<00:56, 316.46batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  57%|▌| 23154/40960 [01:14<00:56, 316.46batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  57%|▌| 23206/40960 [01:14<00:59, 297.57batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  57%|▌| 23206/40960 [01:14<00:59, 297.57batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  57%|▌| 23270/40960 [01:14<00:58, 303.86batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  57%|▌| 23270/40960 [01:14<00:58, 303.86batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  57%|▌| 23336/40960 [01:15<00:56, 310.80batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  57%|▌| 23336/40960 [01:15<00:56, 310.80batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  57%|▌| 23402/40960 [01:15<00:55, 315.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  57%|▌| 23402/40960 [01:15<00:55, 315.41batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  57%|▌| 23466/40960 [01:15<00:55, 315.42batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  57%|▌| 23466/40960 [01:15<00:55, 315.42batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  57%|▌| 23532/40960 [01:15<00:54, 319.55batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  57%|▌| 23532/40960 [01:15<00:54, 319.55batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  58%|▌| 23596/40960 [01:15<00:54, 318.89batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  58%|▌| 23596/40960 [01:15<00:54, 318.89batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23660/40960 [01:16<00:54, 317.98batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23660/40960 [01:16<00:54, 317.98batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23724/40960 [01:16<00:54, 317.96batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23724/40960 [01:16<00:54, 317.96batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23788/40960 [01:16<00:54, 317.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23788/40960 [01:16<00:54, 317.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23854/40960 [01:16<00:53, 320.92batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23854/40960 [01:16<00:53, 320.92batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23919/40960 [01:16<00:52, 322.06batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  58%|▌| 23919/40960 [01:16<00:52, 322.06batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 23984/40960 [01:17<00:52, 321.70batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 23984/40960 [01:17<00:52, 321.70batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 24048/40960 [01:17<00:52, 321.09batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 24048/40960 [01:17<00:52, 321.09batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  59%|▌| 24106/40960 [01:17<00:54, 309.22batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  59%|▌| 24106/40960 [01:17<00:54, 309.22batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 24171/40960 [01:17<00:53, 313.30batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 24171/40960 [01:17<00:53, 313.30batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 24236/40960 [01:17<00:52, 316.74batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 24236/40960 [01:17<00:52, 316.74batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 24303/40960 [01:18<00:51, 320.90batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  59%|▌| 24303/40960 [01:18<00:51, 320.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  59%|▌| 24370/40960 [01:18<00:51, 323.72batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  59%|▌| 24370/40960 [01:18<00:51, 323.72batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24431/40960 [01:18<00:52, 317.69batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24431/40960 [01:18<00:52, 317.69batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24493/40960 [01:18<00:52, 314.39batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24493/40960 [01:18<00:52, 314.39batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24557/40960 [01:18<00:52, 314.70batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24557/40960 [01:18<00:52, 314.70batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  60%|▌| 24619/40960 [01:19<00:52, 312.92batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  60%|▌| 24619/40960 [01:19<00:52, 312.92batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24682/40960 [01:19<00:52, 312.34batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24682/40960 [01:19<00:52, 312.34batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24750/40960 [01:19<00:50, 319.19batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  60%|▌| 24750/40960 [01:19<00:50, 319.19batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 24814/40960 [01:19<00:50, 318.66batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 24814/40960 [01:19<00:50, 318.66batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 24881/40960 [01:19<00:49, 323.23batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 24881/40960 [01:20<00:49, 323.23batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 24949/40960 [01:20<00:48, 327.36batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 24949/40960 [01:20<00:48, 327.36batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 25013/40960 [01:20<00:49, 324.67batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 25013/40960 [01:20<00:49, 324.67batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 25080/40960 [01:20<00:48, 326.95batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 25080/40960 [01:20<00:48, 326.95batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 25142/40960 [01:20<00:49, 321.85batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  61%|▌| 25142/40960 [01:20<00:49, 321.85batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25201/40960 [01:21<00:50, 311.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25201/40960 [01:21<00:50, 311.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25263/40960 [01:21<00:50, 310.68batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25263/40960 [01:21<00:50, 310.68batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25328/40960 [01:21<00:49, 314.15batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25328/40960 [01:21<00:49, 314.15batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25395/40960 [01:21<00:48, 319.47batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25395/40960 [01:21<00:48, 319.47batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25454/40960 [01:21<00:49, 311.86batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25454/40960 [01:21<00:49, 311.86batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25517/40960 [01:22<00:49, 311.05batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25517/40960 [01:22<00:49, 311.05batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25583/40960 [01:22<00:48, 315.94batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  62%|▌| 25583/40960 [01:22<00:48, 315.94batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25648/40960 [01:22<00:48, 318.45batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25648/40960 [01:22<00:48, 318.45batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  63%|▋| 25713/40960 [01:22<00:47, 319.93batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  63%|▋| 25713/40960 [01:22<00:47, 319.93batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25766/40960 [01:22<00:50, 303.49batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25766/40960 [01:22<00:50, 303.49batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25816/40960 [01:23<00:52, 287.27batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25816/40960 [01:23<00:52, 287.27batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25872/40960 [01:23<00:53, 284.12batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25872/40960 [01:23<00:53, 284.12batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  63%|▋| 25935/40960 [01:23<00:51, 292.16batches/s, l2_loss: 0.0711 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|▋| 25935/40960 [01:23<00:51, 292.16batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25996/40960 [01:23<00:50, 295.29batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  63%|▋| 25996/40960 [01:23<00:50, 295.29batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26054/40960 [01:23<00:50, 293.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26054/40960 [01:23<00:50, 293.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26116/40960 [01:24<00:50, 296.68batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26116/40960 [01:24<00:50, 296.68batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26172/40960 [01:24<00:50, 290.93batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26172/40960 [01:24<00:50, 290.93batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26237/40960 [01:24<00:48, 300.64batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26237/40960 [01:24<00:48, 300.64batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  64%|▋| 26300/40960 [01:24<00:48, 304.88batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  64%|▋| 26300/40960 [01:24<00:48, 304.88batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26358/40960 [01:24<00:48, 299.95batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  64%|▋| 26358/40960 [01:24<00:48, 299.95batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  64%|▋| 26416/40960 [01:25<00:49, 296.50batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  64%|▋| 26416/40960 [01:25<00:49, 296.50batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  65%|▋| 26481/40960 [01:25<00:47, 304.04batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  65%|▋| 26481/40960 [01:25<00:47, 304.04batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  65%|▋| 26538/40960 [01:25<00:48, 297.82batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  65%|▋| 26538/40960 [01:25<00:48, 297.82batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  65%|▋| 26597/40960 [01:25<00:48, 296.76batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  65%|▋| 26597/40960 [01:25<00:48, 296.76batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  65%|▋| 26657/40960 [01:25<00:48, 296.79batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  65%|▋| 26657/40960 [01:25<00:48, 296.79batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  65%|▋| 26713/40960 [01:26<00:48, 291.31batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  65%|▋| 26713/40960 [01:26<00:48, 291.31batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  65%|▋| 26777/40960 [01:26<00:47, 298.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  65%|▋| 26777/40960 [01:26<00:47, 298.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 26843/40960 [01:26<00:46, 306.86batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 26843/40960 [01:26<00:46, 306.86batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  66%|▋| 26906/40960 [01:26<00:45, 308.47batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  66%|▋| 26906/40960 [01:26<00:45, 308.47batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 26971/40960 [01:26<00:44, 312.12batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 26971/40960 [01:26<00:44, 312.12batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  66%|▋| 27032/40960 [01:27<00:44, 309.62batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  66%|▋| 27032/40960 [01:27<00:44, 309.62batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 27094/40960 [01:27<00:44, 308.86batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 27094/40960 [01:27<00:44, 308.86batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 27149/40960 [01:27<00:46, 297.95batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 27149/40960 [01:27<00:46, 297.95batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 27207/40960 [01:27<00:46, 295.52batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  66%|▋| 27207/40960 [01:27<00:46, 295.52batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27269/40960 [01:27<00:45, 299.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27269/40960 [01:27<00:45, 299.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27331/40960 [01:28<00:45, 301.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27331/40960 [01:28<00:45, 301.90batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  67%|▋| 27390/40960 [01:28<00:45, 298.77batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  67%|▋| 27390/40960 [01:28<00:45, 298.77batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27445/40960 [01:28<00:46, 290.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27445/40960 [01:28<00:46, 290.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27507/40960 [01:28<00:45, 295.62batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27507/40960 [01:28<00:45, 295.62batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  67%|▋| 27566/40960 [01:28<00:45, 293.92batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  67%|▋| 27566/40960 [01:28<00:45, 293.92batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27631/40960 [01:29<00:44, 302.61batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  67%|▋| 27631/40960 [01:29<00:44, 302.61batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  68%|▋| 27697/40960 [01:29<00:42, 310.49batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  68%|▋| 27697/40960 [01:29<00:42, 310.49batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  68%|▋| 27758/40960 [01:29<00:42, 307.98batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  68%|▋| 27758/40960 [01:29<00:42, 307.98batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  68%|▋| 27825/40960 [01:29<00:41, 315.24batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  68%|▋| 27825/40960 [01:29<00:41, 315.24batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  68%|▋| 27889/40960 [01:29<00:41, 316.13batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  68%|▋| 27889/40960 [01:29<00:41, 316.13batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  68%|▋| 27951/40960 [01:30<00:41, 312.71batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  68%|▋| 27951/40960 [01:30<00:41, 312.71batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  68%|▋| 28018/40960 [01:30<00:40, 318.08batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  68%|▋| 28018/40960 [01:30<00:40, 318.08batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  69%|▋| 28079/40960 [01:30<00:41, 313.56batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  69%|▋| 28079/40960 [01:30<00:41, 313.56batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  69%|▋| 28146/40960 [01:30<00:40, 319.66batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  69%|▋| 28146/40960 [01:30<00:40, 319.66batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  69%|▋| 28206/40960 [01:30<00:40, 313.22batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  69%|▋| 28206/40960 [01:30<00:40, 313.22batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  69%|▋| 28271/40960 [01:31<00:40, 315.32batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  69%|▋| 28271/40960 [01:31<00:40, 315.32batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  69%|▋| 28338/40960 [01:31<00:39, 320.72batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  69%|▋| 28338/40960 [01:31<00:39, 320.72batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  69%|▋| 28400/40960 [01:31<00:39, 317.12batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  69%|▋| 28400/40960 [01:31<00:39, 317.12batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  69%|▋| 28464/40960 [01:31<00:39, 317.92batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  69%|▋| 28464/40960 [01:31<00:39, 317.92batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  70%|▋| 28529/40960 [01:31<00:38, 319.60batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  70%|▋| 28529/40960 [01:31<00:38, 319.60batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28593/40960 [01:32<00:38, 319.57batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28593/40960 [01:32<00:38, 319.57batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28659/40960 [01:32<00:38, 322.09batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28659/40960 [01:32<00:38, 322.09batches/s, l2_loss: 0.0711 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28722/40960 [01:32<00:38, 319.55batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28722/40960 [01:32<00:38, 319.55batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28786/40960 [01:32<00:38, 319.39batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28786/40960 [01:32<00:38, 319.39batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28852/40960 [01:32<00:37, 321.50batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  70%|▋| 28852/40960 [01:32<00:37, 321.50batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 28916/40960 [01:33<00:37, 320.48batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 28916/40960 [01:33<00:37, 320.48batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 28979/40960 [01:33<00:37, 318.34batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 28979/40960 [01:33<00:37, 318.34batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29044/40960 [01:33<00:37, 319.84batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29044/40960 [01:33<00:37, 319.84batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29110/40960 [01:33<00:36, 322.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29110/40960 [01:33<00:36, 322.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29158/40960 [01:33<00:39, 297.75batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29158/40960 [01:33<00:39, 297.75batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29219/40960 [01:34<00:39, 299.75batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29219/40960 [01:34<00:39, 299.75batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29281/40960 [01:34<00:38, 301.75batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  71%|▋| 29281/40960 [01:34<00:38, 301.75batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  72%|▋| 29341/40960 [01:34<00:38, 300.51batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  72%|▋| 29341/40960 [01:34<00:38, 300.51batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  72%|▋| 29406/40960 [01:34<00:37, 306.52batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  72%|▋| 29406/40960 [01:34<00:37, 306.52batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  72%|▋| 29475/40960 [01:34<00:36, 317.71batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  72%|▋| 29475/40960 [01:34<00:36, 317.71batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  72%|▋| 29535/40960 [01:35<00:36, 311.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  72%|▋| 29535/40960 [01:35<00:36, 311.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  72%|▋| 29600/40960 [01:35<00:36, 315.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  72%|▋| 29600/40960 [01:35<00:36, 315.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  72%|▋| 29659/40960 [01:35<00:36, 307.85batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  72%|▋| 29659/40960 [01:35<00:36, 307.85batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29720/40960 [01:35<00:36, 305.53batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29720/40960 [01:35<00:36, 305.53batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29784/40960 [01:35<00:36, 309.50batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29784/40960 [01:35<00:36, 309.50batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29847/40960 [01:36<00:35, 310.77batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29847/40960 [01:36<00:35, 310.77batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29907/40960 [01:36<00:36, 306.68batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29907/40960 [01:36<00:36, 306.68batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29974/40960 [01:36<00:34, 314.15batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 29974/40960 [01:36<00:34, 314.15batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  73%|▋| 30036/40960 [01:36<00:34, 312.42batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  73%|▋| 30036/40960 [01:36<00:34, 312.42batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 30097/40960 [01:36<00:35, 309.66batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  73%|▋| 30097/40960 [01:36<00:35, 309.66batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  74%|▋| 30161/40960 [01:37<00:34, 312.50batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  74%|▋| 30161/40960 [01:37<00:34, 312.50batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  74%|▋| 30222/40960 [01:37<00:34, 309.97batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  74%|▋| 30222/40960 [01:37<00:34, 309.97batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  74%|▋| 30282/40960 [01:37<00:34, 305.83batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  74%|▋| 30282/40960 [01:37<00:34, 305.83batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  74%|▋| 30343/40960 [01:37<00:34, 305.53batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  74%|▋| 30343/40960 [01:37<00:34, 305.53batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  74%|▋| 30408/40960 [01:37<00:33, 311.04batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  74%|▋| 30408/40960 [01:37<00:33, 311.04batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  74%|▋| 30467/40960 [01:38<00:34, 305.78batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  74%|▋| 30467/40960 [01:38<00:34, 305.78batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▋| 30526/40960 [01:38<00:34, 300.95batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▋| 30526/40960 [01:38<00:34, 300.95batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▋| 30586/40960 [01:38<00:34, 300.42batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▋| 30586/40960 [01:38<00:34, 300.42batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▋| 30648/40960 [01:38<00:34, 302.47batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▋| 30648/40960 [01:38<00:34, 302.47batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▋| 30710/40960 [01:38<00:33, 304.30batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▋| 30710/40960 [01:38<00:33, 304.30batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▊| 30776/40960 [01:39<00:32, 310.53batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▊| 30776/40960 [01:39<00:32, 310.53batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▊| 30832/40960 [01:39<00:33, 301.28batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▊| 30832/40960 [01:39<00:33, 301.28batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▊| 30889/40960 [01:39<00:34, 294.67batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  75%|▊| 30889/40960 [01:39<00:34, 294.67batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 30943/40960 [01:39<00:34, 286.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 30943/40960 [01:39<00:34, 286.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31000/40960 [01:39<00:34, 285.27batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31000/40960 [01:39<00:34, 285.27batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31059/40960 [01:40<00:34, 287.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31059/40960 [01:40<00:34, 287.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31111/40960 [01:40<00:35, 278.57batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31111/40960 [01:40<00:35, 278.57batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31170/40960 [01:40<00:34, 282.46batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31170/40960 [01:40<00:34, 282.46batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  76%|▊| 31229/40960 [01:40<00:34, 284.69batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  76%|▊| 31229/40960 [01:40<00:34, 284.69batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31289/40960 [01:40<00:33, 288.17batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  76%|▊| 31289/40960 [01:40<00:33, 288.17batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31351/40960 [01:41<00:32, 294.51batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31351/40960 [01:41<00:32, 294.51batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31409/40960 [01:41<00:32, 293.03batches/s, l2_loss: 0.0711 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|▊| 31409/40960 [01:41<00:32, 293.03batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31465/40960 [01:41<00:32, 288.77batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31465/40960 [01:41<00:32, 288.77batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31525/40960 [01:41<00:32, 291.72batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31525/40960 [01:41<00:32, 291.72batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31583/40960 [01:41<00:32, 290.83batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31583/40960 [01:41<00:32, 290.83batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31646/40960 [01:42<00:31, 296.85batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31646/40960 [01:42<00:31, 296.85batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31712/40960 [01:42<00:30, 305.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  77%|▊| 31712/40960 [01:42<00:30, 305.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 31771/40960 [01:42<00:30, 302.36batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 31771/40960 [01:42<00:30, 302.36batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 31833/40960 [01:42<00:29, 304.48batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 31833/40960 [01:42<00:29, 304.48batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  78%|▊| 31899/40960 [01:42<00:29, 311.08batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  78%|▊| 31899/40960 [01:42<00:29, 311.08batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 31960/40960 [01:43<00:29, 309.19batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 31960/40960 [01:43<00:29, 309.19batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 32019/40960 [01:43<00:29, 304.69batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 32019/40960 [01:43<00:29, 304.69batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  78%|▊| 32082/40960 [01:43<00:28, 306.99batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  78%|▊| 32082/40960 [01:43<00:28, 306.99batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 32149/40960 [01:43<00:28, 314.32batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  78%|▊| 32149/40960 [01:43<00:28, 314.32batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  79%|▊| 32210/40960 [01:43<00:28, 310.61batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  79%|▊| 32210/40960 [01:43<00:28, 310.61batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  79%|▊| 32268/40960 [01:44<00:28, 304.02batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  79%|▊| 32268/40960 [01:44<00:28, 304.02batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  79%|▊| 32325/40960 [01:44<00:29, 297.75batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  79%|▊| 32325/40960 [01:44<00:29, 297.75batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  79%|▊| 32391/40960 [01:44<00:27, 306.49batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  79%|▊| 32391/40960 [01:44<00:27, 306.49batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  79%|▊| 32454/40960 [01:44<00:27, 308.07batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  79%|▊| 32454/40960 [01:44<00:27, 308.07batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  79%|▊| 32520/40960 [01:44<00:26, 314.19batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  79%|▊| 32520/40960 [01:44<00:26, 314.19batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32582/40960 [01:45<00:26, 312.02batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32582/40960 [01:45<00:26, 312.02batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32645/40960 [01:45<00:26, 312.55batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32645/40960 [01:45<00:26, 312.55batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32707/40960 [01:45<00:26, 311.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32707/40960 [01:45<00:26, 311.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32771/40960 [01:45<00:26, 313.74batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32771/40960 [01:45<00:26, 313.74batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32836/40960 [01:45<00:25, 316.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32836/40960 [01:45<00:25, 316.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32891/40960 [01:46<00:26, 302.87batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32891/40960 [01:46<00:26, 302.87batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32954/40960 [01:46<00:26, 306.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  80%|▊| 32954/40960 [01:46<00:26, 306.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33018/40960 [01:46<00:25, 310.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33018/40960 [01:46<00:25, 310.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33078/40960 [01:46<00:25, 306.41batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33078/40960 [01:46<00:25, 306.41batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33144/40960 [01:46<00:25, 312.48batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33144/40960 [01:47<00:25, 312.48batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33204/40960 [01:47<00:25, 308.14batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33204/40960 [01:47<00:25, 308.14batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  81%|▊| 33268/40960 [01:47<00:24, 311.58batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  81%|▊| 33268/40960 [01:47<00:24, 311.58batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33327/40960 [01:47<00:24, 305.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  81%|▊| 33327/40960 [01:47<00:24, 305.37batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  82%|▊| 33390/40960 [01:47<00:24, 308.12batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  82%|▊| 33390/40960 [01:47<00:24, 308.12batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33457/40960 [01:48<00:23, 315.24batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33457/40960 [01:48<00:23, 315.24batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33522/40960 [01:48<00:23, 317.72batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33522/40960 [01:48<00:23, 317.72batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33586/40960 [01:48<00:23, 317.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33586/40960 [01:48<00:23, 317.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33641/40960 [01:48<00:24, 304.64batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33641/40960 [01:48<00:24, 304.64batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33705/40960 [01:48<00:23, 309.09batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33705/40960 [01:48<00:23, 309.09batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33763/40960 [01:49<00:23, 302.58batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  82%|▊| 33763/40960 [01:49<00:23, 302.58batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 33822/40960 [01:49<00:23, 299.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 33822/40960 [01:49<00:23, 299.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 33882/40960 [01:49<00:23, 298.32batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 33882/40960 [01:49<00:23, 298.32batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 33939/40960 [01:49<00:23, 293.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 33939/40960 [01:49<00:23, 293.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 33996/40960 [01:49<00:23, 290.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 33996/40960 [01:49<00:23, 290.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 34056/40960 [01:50<00:23, 293.00batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 34056/40960 [01:50<00:23, 293.00batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 34121/40960 [01:50<00:22, 301.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 34121/40960 [01:50<00:22, 301.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 34185/40960 [01:50<00:22, 306.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  83%|▊| 34185/40960 [01:50<00:22, 306.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34249/40960 [01:50<00:21, 309.64batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34249/40960 [01:50<00:21, 309.64batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34314/40960 [01:50<00:21, 313.89batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34314/40960 [01:50<00:21, 313.89batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34382/40960 [01:51<00:20, 320.52batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34382/40960 [01:51<00:20, 320.52batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34435/40960 [01:51<00:21, 302.70batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34435/40960 [01:51<00:21, 302.70batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34498/40960 [01:51<00:21, 305.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34498/40960 [01:51<00:21, 305.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34560/40960 [01:51<00:20, 306.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  84%|▊| 34560/40960 [01:51<00:20, 306.26batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34626/40960 [01:51<00:20, 312.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34626/40960 [01:51<00:20, 312.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34694/40960 [01:52<00:19, 320.17batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34694/40960 [01:52<00:19, 320.17batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34757/40960 [01:52<00:19, 317.87batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34757/40960 [01:52<00:19, 317.87batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  85%|▊| 34815/40960 [01:52<00:19, 309.15batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  85%|▊| 34815/40960 [01:52<00:19, 309.15batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34877/40960 [01:52<00:19, 308.11batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34877/40960 [01:52<00:19, 308.11batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34938/40960 [01:52<00:19, 306.54batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 34938/40960 [01:52<00:19, 306.54batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 35004/40960 [01:53<00:19, 311.96batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  85%|▊| 35004/40960 [01:53<00:19, 311.96batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35069/40960 [01:53<00:18, 315.53batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35069/40960 [01:53<00:18, 315.53batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35126/40960 [01:53<00:19, 305.68batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35126/40960 [01:53<00:19, 305.68batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35189/40960 [01:53<00:18, 307.52batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35189/40960 [01:53<00:18, 307.52batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35248/40960 [01:53<00:18, 303.34batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35248/40960 [01:53<00:18, 303.34batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35308/40960 [01:54<00:18, 301.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35308/40960 [01:54<00:18, 301.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35374/40960 [01:54<00:18, 309.74batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  86%|▊| 35374/40960 [01:54<00:18, 309.74batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35443/40960 [01:54<00:17, 319.14batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35443/40960 [01:54<00:17, 319.14batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35509/40960 [01:54<00:16, 322.28batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35509/40960 [01:54<00:16, 322.28batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35573/40960 [01:54<00:16, 320.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35573/40960 [01:54<00:16, 320.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35636/40960 [01:55<00:16, 318.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35636/40960 [01:55<00:16, 318.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35701/40960 [01:55<00:16, 319.91batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35701/40960 [01:55<00:16, 319.91batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35760/40960 [01:55<00:16, 311.05batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  87%|▊| 35760/40960 [01:55<00:16, 311.05batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  87%|▊| 35823/40960 [01:55<00:16, 311.81batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  87%|▊| 35823/40960 [01:55<00:16, 311.81batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 35884/40960 [01:55<00:16, 308.85batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 35884/40960 [01:55<00:16, 308.85batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 35950/40960 [01:56<00:15, 314.33batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 35950/40960 [01:56<00:15, 314.33batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 36015/40960 [01:56<00:15, 317.08batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 36015/40960 [01:56<00:15, 317.08batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 36071/40960 [01:56<00:16, 304.84batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 36071/40960 [01:56<00:16, 304.84batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 36135/40960 [01:56<00:15, 308.22batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 36135/40960 [01:56<00:15, 308.22batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 36199/40960 [01:56<00:15, 311.08batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  88%|▉| 36199/40960 [01:56<00:15, 311.08batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36263/40960 [01:57<00:15, 312.51batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36263/40960 [01:57<00:15, 312.51batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36329/40960 [01:57<00:14, 316.89batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36329/40960 [01:57<00:14, 316.89batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36393/40960 [01:57<00:14, 316.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36393/40960 [01:57<00:14, 316.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36452/40960 [01:57<00:14, 309.38batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36452/40960 [01:57<00:14, 309.38batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36517/40960 [01:57<00:14, 313.04batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36517/40960 [01:57<00:14, 313.04batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36582/40960 [01:58<00:13, 315.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36582/40960 [01:58<00:13, 315.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36638/40960 [01:58<00:14, 304.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  89%|▉| 36638/40960 [01:58<00:14, 304.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36699/40960 [01:58<00:14, 303.22batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36699/40960 [01:58<00:14, 303.22batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36754/40960 [01:58<00:14, 293.57batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36754/40960 [01:58<00:14, 293.57batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36794/40960 [01:58<00:15, 265.25batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36794/40960 [01:58<00:15, 265.25batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36852/40960 [01:59<00:15, 271.84batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36852/40960 [01:59<00:15, 271.84batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36918/40960 [01:59<00:14, 288.38batches/s, l2_loss: 0.0711 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 36918/40960 [01:59<00:14, 288.38batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36982/40960 [01:59<00:13, 296.70batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 36982/40960 [01:59<00:13, 296.70batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 37041/40960 [01:59<00:13, 296.00batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  90%|▉| 37041/40960 [01:59<00:13, 296.00batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37102/40960 [01:59<00:12, 298.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37102/40960 [01:59<00:12, 298.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37166/40960 [02:00<00:12, 304.44batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37166/40960 [02:00<00:12, 304.44batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37231/40960 [02:00<00:12, 310.56batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37231/40960 [02:00<00:12, 310.56batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37293/40960 [02:00<00:11, 309.93batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37293/40960 [02:00<00:11, 309.93batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  91%|▉| 37354/40960 [02:00<00:11, 308.39batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  91%|▉| 37354/40960 [02:00<00:11, 308.39batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37420/40960 [02:00<00:11, 314.51batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  91%|▉| 37420/40960 [02:00<00:11, 314.51batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  92%|▉| 37479/40960 [02:01<00:11, 307.58batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  92%|▉| 37479/40960 [02:01<00:11, 307.58batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  92%|▉| 37543/40960 [02:01<00:11, 310.59batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  92%|▉| 37543/40960 [02:01<00:11, 310.59batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  92%|▉| 37603/40960 [02:01<00:10, 306.97batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  92%|▉| 37603/40960 [02:01<00:10, 306.97batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  92%|▉| 37667/40960 [02:01<00:10, 310.05batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  92%|▉| 37667/40960 [02:01<00:10, 310.05batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  92%|▉| 37729/40960 [02:01<00:10, 309.19batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  92%|▉| 37729/40960 [02:01<00:10, 309.19batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  92%|▉| 37790/40960 [02:02<00:10, 307.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  92%|▉| 37790/40960 [02:02<00:10, 307.37batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  92%|▉| 37852/40960 [02:02<00:10, 306.96batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  92%|▉| 37852/40960 [02:02<00:10, 306.96batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 37914/40960 [02:02<00:09, 307.81batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 37914/40960 [02:02<00:09, 307.81batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  93%|▉| 37972/40960 [02:02<00:09, 301.17batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  93%|▉| 37972/40960 [02:02<00:09, 301.17batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 38038/40960 [02:02<00:09, 308.41batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 38038/40960 [02:02<00:09, 308.41batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 38094/40960 [02:03<00:09, 298.43batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 38094/40960 [02:03<00:09, 298.43batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  93%|▉| 38155/40960 [02:03<00:09, 299.33batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  93%|▉| 38155/40960 [02:03<00:09, 299.33batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 38221/40960 [02:03<00:08, 307.33batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 38221/40960 [02:03<00:08, 307.33batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 38285/40960 [02:03<00:08, 309.98batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  93%|▉| 38285/40960 [02:03<00:08, 309.98batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  94%|▉| 38348/40960 [02:03<00:08, 311.15batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  94%|▉| 38348/40960 [02:03<00:08, 311.15batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  94%|▉| 38414/40960 [02:04<00:08, 315.94batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  94%|▉| 38414/40960 [02:04<00:08, 315.94batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  94%|▉| 38480/40960 [02:04<00:07, 318.90batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  94%|▉| 38480/40960 [02:04<00:07, 318.90batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  94%|▉| 38542/40960 [02:04<00:07, 315.69batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  94%|▉| 38542/40960 [02:04<00:07, 315.69batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  94%|▉| 38605/40960 [02:04<00:07, 314.36batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  94%|▉| 38605/40960 [02:04<00:07, 314.36batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  94%|▉| 38662/40960 [02:04<00:07, 305.39batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  94%|▉| 38662/40960 [02:04<00:07, 305.39batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 38727/40960 [02:05<00:07, 310.92batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 38727/40960 [02:05<00:07, 310.92batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 38790/40960 [02:05<00:06, 311.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 38790/40960 [02:05<00:06, 311.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 38851/40960 [02:05<00:06, 308.82batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 38851/40960 [02:05<00:06, 308.82batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  95%|▉| 38913/40960 [02:05<00:06, 309.14batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  95%|▉| 38913/40960 [02:05<00:06, 309.14batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 38979/40960 [02:05<00:06, 314.21batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 38979/40960 [02:05<00:06, 314.21batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  95%|▉| 39041/40960 [02:06<00:06, 312.27batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  95%|▉| 39041/40960 [02:06<00:06, 312.27batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 39105/40960 [02:06<00:05, 313.20batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  95%|▉| 39105/40960 [02:06<00:05, 313.20batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  96%|▉| 39170/40960 [02:06<00:05, 316.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  96%|▉| 39170/40960 [02:06<00:05, 316.65batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  96%|▉| 39232/40960 [02:06<00:05, 314.59batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  96%|▉| 39232/40960 [02:06<00:05, 314.59batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  96%|▉| 39292/40960 [02:06<00:05, 310.10batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  96%|▉| 39292/40960 [02:06<00:05, 310.10batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  96%|▉| 39348/40960 [02:07<00:05, 300.38batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  96%|▉| 39348/40960 [02:07<00:05, 300.38batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  96%|▉| 39403/40960 [02:07<00:05, 291.18batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  96%|▉| 39403/40960 [02:07<00:05, 291.18batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  96%|▉| 39463/40960 [02:07<00:05, 293.30batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  96%|▉| 39463/40960 [02:07<00:05, 293.30batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  96%|▉| 39522/40960 [02:07<00:04, 293.29batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  96%|▉| 39522/40960 [02:07<00:04, 293.29batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39580/40960 [02:07<00:04, 291.70batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39580/40960 [02:07<00:04, 291.70batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39639/40960 [02:08<00:04, 291.27batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39639/40960 [02:08<00:04, 291.27batches/s, l2_loss: 0.0711 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39700/40960 [02:08<00:04, 295.30batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39700/40960 [02:08<00:04, 295.30batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  97%|▉| 39762/40960 [02:08<00:03, 299.54batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  97%|▉| 39762/40960 [02:08<00:03, 299.54batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39823/40960 [02:08<00:03, 300.18batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39823/40960 [02:08<00:03, 300.18batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39886/40960 [02:08<00:03, 302.99batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  97%|▉| 39886/40960 [02:08<00:03, 302.99batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  98%|▉| 39939/40960 [02:09<00:03, 291.35batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  98%|▉| 39939/40960 [02:09<00:03, 291.35batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  98%|▉| 39993/40960 [02:09<00:03, 284.56batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  98%|▉| 39993/40960 [02:09<00:03, 284.56batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  98%|▉| 40057/40960 [02:09<00:03, 294.10batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  98%|▉| 40057/40960 [02:09<00:03, 294.10batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  98%|▉| 40122/40960 [02:09<00:02, 302.70batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  98%|▉| 40122/40960 [02:09<00:02, 302.70batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  98%|▉| 40186/40960 [02:09<00:02, 307.71batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  98%|▉| 40186/40960 [02:09<00:02, 307.71batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  98%|▉| 40249/40960 [02:10<00:02, 309.54batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  98%|▉| 40249/40960 [02:10<00:02, 309.54batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  98%|▉| 40315/40960 [02:10<00:02, 315.34batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  98%|▉| 40315/40960 [02:10<00:02, 315.34batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40376/40960 [02:10<00:01, 310.60batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40376/40960 [02:10<00:01, 310.60batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  99%|▉| 40424/40960 [02:10<00:01, 289.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  99%|▉| 40424/40960 [02:10<00:01, 289.37batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  99%|▉| 40485/40960 [02:10<00:01, 293.12batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training:  99%|▉| 40485/40960 [02:10<00:01, 293.12batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40540/40960 [02:11<00:01, 286.68batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40540/40960 [02:11<00:01, 286.68batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40597/40960 [02:11<00:01, 285.97batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40597/40960 [02:11<00:01, 285.97batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40661/40960 [02:11<00:01, 295.45batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40661/40960 [02:11<00:01, 295.45batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40726/40960 [02:11<00:00, 303.00batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training:  99%|▉| 40726/40960 [02:11<00:00, 303.00batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training: 100%|▉| 40790/40960 [02:11<00:00, 306.97batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training: 100%|▉| 40790/40960 [02:12<00:00, 306.97batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training: 100%|▉| 40851/40960 [02:12<00:00, 305.24batches/s, l2_loss: 0.0711 - round_los\u001b[A\n",
      "Training: 100%|▉| 40851/40960 [02:12<00:00, 305.24batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training: 100%|▉| 40913/40960 [02:12<00:00, 305.88batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "Training: 100%|▉| 40913/40960 [02:12<00:00, 305.88batches/s, l2_loss: 0.0712 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:19:44.927083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  58%|▌| 15/26 [30:24<23:10, 126.42s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:19:47.567362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A\n",
      "Training:   0%|                                | 1/40960 [00:00<9:59:01,  1.14batches/s]\u001b[A2025-06-08 19:19:50.237773: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%| | 1/40960 [00:00<9:59:01,  1.14batches/s, l2_loss: 0.0110 - round_loss: \u001b[A\n",
      "Training:   0%| | 78/40960 [00:01<07:09, 95.25batches/s, l2_loss: 0.0110 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 78/40960 [00:01<07:09, 95.25batches/s, l2_loss: 0.0224 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 153/40960 [00:01<04:03, 167.47batches/s, l2_loss: 0.0224 - round_loss:\u001b[A\n",
      "Training:   0%| | 153/40960 [00:01<04:03, 167.47batches/s, l2_loss: 0.0245 - round_loss:\u001b[A\n",
      "Training:   1%| | 223/40960 [00:01<03:08, 216.38batches/s, l2_loss: 0.0245 - round_loss:\u001b[A\n",
      "Training:   1%| | 223/40960 [00:01<03:08, 216.38batches/s, l2_loss: 0.0247 - round_loss:\u001b[A\n",
      "Training:   1%| | 271/40960 [00:01<03:02, 222.58batches/s, l2_loss: 0.0247 - round_loss:\u001b[A\n",
      "Training:   1%| | 271/40960 [00:01<03:02, 222.58batches/s, l2_loss: 0.0249 - round_loss:\u001b[A\n",
      "Training:   1%| | 349/40960 [00:01<02:30, 270.02batches/s, l2_loss: 0.0249 - round_loss:\u001b[A\n",
      "Training:   1%| | 349/40960 [00:01<02:30, 270.02batches/s, l2_loss: 0.0237 - round_loss:\u001b[A\n",
      "Training:   1%| | 440/40960 [00:02<02:05, 322.70batches/s, l2_loss: 0.0237 - round_loss:\u001b[A\n",
      "Training:   1%| | 440/40960 [00:02<02:05, 322.70batches/s, l2_loss: 0.0250 - round_loss:\u001b[A\n",
      "Training:   1%| | 522/40960 [00:02<01:56, 347.22batches/s, l2_loss: 0.0250 - round_loss:\u001b[A\n",
      "Training:   1%| | 522/40960 [00:02<01:56, 347.22batches/s, l2_loss: 0.0254 - round_loss:\u001b[A\n",
      "Training:   1%| | 602/40960 [00:02<01:51, 362.28batches/s, l2_loss: 0.0254 - round_loss:\u001b[A\n",
      "Training:   1%| | 602/40960 [00:02<01:51, 362.28batches/s, l2_loss: 0.0255 - round_loss:\u001b[A\n",
      "Training:   2%| | 689/40960 [00:02<01:45, 382.60batches/s, l2_loss: 0.0255 - round_loss:\u001b[A\n",
      "Training:   2%| | 689/40960 [00:02<01:45, 382.60batches/s, l2_loss: 0.0256 - round_loss:\u001b[A\n",
      "Training:   2%| | 775/40960 [00:02<01:41, 396.30batches/s, l2_loss: 0.0256 - round_loss:\u001b[A\n",
      "Training:   2%| | 775/40960 [00:02<01:41, 396.30batches/s, l2_loss: 0.0255 - round_loss:\u001b[A\n",
      "Training:   2%| | 862/40960 [00:03<01:38, 407.33batches/s, l2_loss: 0.0255 - round_loss:\u001b[A\n",
      "Training:   2%| | 862/40960 [00:03<01:38, 407.33batches/s, l2_loss: 0.0255 - round_loss:\u001b[A\n",
      "Training:   2%| | 953/40960 [00:03<01:35, 421.07batches/s, l2_loss: 0.0255 - round_loss:\u001b[A\n",
      "Training:   2%| | 953/40960 [00:03<01:35, 421.07batches/s, l2_loss: 0.0259 - round_loss:\u001b[A\n",
      "Training:   3%| | 1046/40960 [00:03<01:32, 433.65batches/s, l2_loss: 0.0259 - round_loss\u001b[A\n",
      "Training:   3%| | 1046/40960 [00:03<01:32, 433.65batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   3%| | 1134/40960 [00:03<01:31, 434.39batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   3%| | 1134/40960 [00:03<01:31, 434.39batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:   3%| | 1227/40960 [00:03<01:29, 442.30batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:   3%| | 1227/40960 [00:03<01:29, 442.30batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   3%| | 1319/40960 [00:04<01:28, 446.76batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   3%| | 1319/40960 [00:04<01:28, 446.76batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%| | 1404/40960 [00:04<01:30, 439.50batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   3%| | 1404/40960 [00:04<01:30, 439.50batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   4%| | 1477/40960 [00:04<01:34, 415.88batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   4%| | 1477/40960 [00:04<01:34, 415.88batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   4%| | 1563/40960 [00:04<01:33, 419.30batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   4%| | 1563/40960 [00:04<01:33, 419.30batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   4%| | 1652/40960 [00:04<01:32, 426.01batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   4%| | 1652/40960 [00:04<01:32, 426.01batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   4%| | 1744/40960 [00:05<01:30, 435.22batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   4%| | 1744/40960 [00:05<01:30, 435.22batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   4%| | 1836/40960 [00:05<01:28, 442.53batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   4%| | 1836/40960 [00:05<01:28, 442.53batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   5%| | 1930/40960 [00:05<01:26, 449.79batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   5%| | 1930/40960 [00:05<01:26, 449.79batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   5%| | 2022/40960 [00:05<01:26, 451.91batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   5%| | 2022/40960 [00:05<01:26, 451.91batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   5%| | 2116/40960 [00:05<01:24, 457.00batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   5%| | 2116/40960 [00:05<01:24, 457.00batches/s, l2_loss: 0.0256 - round_loss\u001b[A\n",
      "Training:   5%| | 2209/40960 [00:06<01:24, 458.70batches/s, l2_loss: 0.0256 - round_loss\u001b[A\n",
      "Training:   5%| | 2209/40960 [00:06<01:24, 458.70batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   6%| | 2302/40960 [00:06<01:23, 460.26batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   6%| | 2302/40960 [00:06<01:23, 460.26batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   6%| | 2395/40960 [00:06<01:23, 461.32batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   6%| | 2395/40960 [00:06<01:23, 461.32batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   6%| | 2483/40960 [00:06<01:24, 454.85batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   6%| | 2483/40960 [00:06<01:24, 454.85batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   6%| | 2576/40960 [00:06<01:23, 457.35batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   6%| | 2576/40960 [00:06<01:23, 457.35batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   7%| | 2667/40960 [00:07<01:23, 456.50batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   7%| | 2667/40960 [00:07<01:23, 456.50batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   7%| | 2755/40960 [00:07<01:24, 450.41batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:   7%| | 2755/40960 [00:07<01:24, 450.41batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   7%| | 2837/40960 [00:07<01:27, 438.07batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   7%| | 2837/40960 [00:07<01:27, 438.07batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   7%| | 2923/40960 [00:07<01:27, 435.17batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   7%| | 2923/40960 [00:07<01:27, 435.17batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   7%| | 3014/40960 [00:07<01:26, 440.51batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   7%| | 3014/40960 [00:07<01:26, 440.51batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   8%| | 3108/40960 [00:08<01:24, 448.75batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   8%| | 3108/40960 [00:08<01:24, 448.75batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   8%| | 3202/40960 [00:08<01:23, 454.27batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   8%| | 3202/40960 [00:08<01:23, 454.27batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   8%| | 3294/40960 [00:08<01:22, 454.86batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   8%| | 3294/40960 [00:08<01:22, 454.86batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   8%| | 3386/40960 [00:08<01:22, 455.59batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   8%| | 3386/40960 [00:08<01:22, 455.59batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   8%| | 3471/40960 [00:08<01:24, 445.92batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:   8%| | 3471/40960 [00:08<01:24, 445.92batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   9%| | 3559/40960 [00:09<01:24, 444.11batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   9%| | 3559/40960 [00:09<01:24, 444.11batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   9%| | 3651/40960 [00:09<01:23, 448.35batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   9%| | 3651/40960 [00:09<01:23, 448.35batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   9%| | 3745/40960 [00:09<01:22, 453.59batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   9%| | 3745/40960 [00:09<01:22, 453.59batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   9%| | 3841/40960 [00:09<01:20, 460.29batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:   9%| | 3841/40960 [00:09<01:20, 460.29batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  10%| | 3933/40960 [00:09<01:20, 459.16batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  10%| | 3933/40960 [00:09<01:20, 459.16batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  10%| | 4026/40960 [00:10<01:20, 459.67batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  10%| | 4026/40960 [00:10<01:20, 459.67batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  10%| | 4119/40960 [00:10<01:19, 461.19batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  10%| | 4119/40960 [00:10<01:19, 461.19batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  10%| | 4212/40960 [00:10<01:19, 461.56batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  10%| | 4212/40960 [00:10<01:19, 461.56batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  11%| | 4306/40960 [00:10<01:19, 463.06batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  11%| | 4306/40960 [00:10<01:19, 463.06batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  11%| | 4398/40960 [00:10<01:19, 461.10batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  11%| | 4398/40960 [00:10<01:19, 461.10batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  11%| | 4492/40960 [00:11<01:18, 462.71batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  11%| | 4492/40960 [00:11<01:18, 462.71batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  11%| | 4586/40960 [00:11<01:18, 463.70batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  11%| | 4586/40960 [00:11<01:18, 463.70batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  11%| | 4668/40960 [00:11<01:21, 447.65batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  11%| | 4668/40960 [00:11<01:21, 447.65batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  12%| | 4743/40960 [00:11<01:25, 425.18batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  12%| | 4743/40960 [00:11<01:25, 425.18batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  12%| | 4823/40960 [00:11<01:26, 417.61batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  12%| | 4823/40960 [00:11<01:26, 417.61batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  12%| | 4908/40960 [00:12<01:25, 419.47batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  12%| | 4908/40960 [00:12<01:25, 419.47batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  12%| | 5001/40960 [00:12<01:23, 432.81batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  12%| | 5001/40960 [00:12<01:23, 432.81batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  12%| | 5096/40960 [00:12<01:20, 444.33batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  12%| | 5096/40960 [00:12<01:20, 444.33batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5189/40960 [00:12<01:19, 450.47batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5189/40960 [00:12<01:19, 450.47batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5267/40960 [00:12<01:22, 432.30batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5267/40960 [00:12<01:22, 432.30batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5349/40960 [00:13<01:23, 425.56batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|▏| 5349/40960 [00:13<01:23, 425.56batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5440/40960 [00:13<01:21, 433.58batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5440/40960 [00:13<01:21, 433.58batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5535/40960 [00:13<01:19, 445.62batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5535/40960 [00:13<01:19, 445.62batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5625/40960 [00:13<01:19, 446.11batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5625/40960 [00:13<01:19, 446.11batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5718/40960 [00:13<01:18, 451.56batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5718/40960 [00:13<01:18, 451.56batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5809/40960 [00:14<01:17, 452.40batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5809/40960 [00:14<01:17, 452.40batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5901/40960 [00:14<01:17, 454.50batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5901/40960 [00:14<01:17, 454.50batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5993/40960 [00:14<01:16, 455.98batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5993/40960 [00:14<01:16, 455.98batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6085/40960 [00:14<01:16, 456.92batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6085/40960 [00:14<01:16, 456.92batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6177/40960 [00:14<01:15, 457.80batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6177/40960 [00:14<01:15, 457.80batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6272/40960 [00:15<01:15, 461.68batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6272/40960 [00:15<01:15, 461.68batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6366/40960 [00:15<01:14, 463.37batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6366/40960 [00:15<01:14, 463.37batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6458/40960 [00:15<01:14, 461.23batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6458/40960 [00:15<01:14, 461.23batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6552/40960 [00:15<01:14, 462.98batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6552/40960 [00:15<01:14, 462.98batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6645/40960 [00:15<01:14, 462.71batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6645/40960 [00:15<01:14, 462.71batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6738/40960 [00:16<01:13, 463.03batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6738/40960 [00:16<01:13, 463.03batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6832/40960 [00:16<01:13, 464.11batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6832/40960 [00:16<01:13, 464.11batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6926/40960 [00:16<01:13, 465.24batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6926/40960 [00:16<01:13, 465.24batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7018/40960 [00:16<01:13, 463.32batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7018/40960 [00:16<01:13, 463.32batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7112/40960 [00:16<01:12, 464.90batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7112/40960 [00:16<01:12, 464.90batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7207/40960 [00:17<01:12, 467.20batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7207/40960 [00:17<01:12, 467.20batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7301/40960 [00:17<01:12, 466.83batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7301/40960 [00:17<01:12, 466.83batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7394/40960 [00:17<01:12, 465.97batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7394/40960 [00:17<01:12, 465.97batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7488/40960 [00:17<01:11, 465.90batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7488/40960 [00:17<01:11, 465.90batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7581/40960 [00:17<01:11, 465.33batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7581/40960 [00:17<01:11, 465.33batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7674/40960 [00:18<01:11, 464.54batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7674/40960 [00:18<01:11, 464.54batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7769/40960 [00:18<01:11, 466.74batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7769/40960 [00:18<01:11, 466.74batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7864/40960 [00:18<01:10, 468.54batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7864/40960 [00:18<01:10, 468.54batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7957/40960 [00:18<01:10, 466.72batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7957/40960 [00:18<01:10, 466.72batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8048/40960 [00:18<01:11, 462.23batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8048/40960 [00:18<01:11, 462.23batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8141/40960 [00:19<01:11, 461.74batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8141/40960 [00:19<01:11, 461.74batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8229/40960 [00:19<01:12, 453.99batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8229/40960 [00:19<01:12, 453.99batches/s, l2_loss: 0.0179 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8313/40960 [00:19<01:13, 443.19batches/s, l2_loss: 0.0179 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8313/40960 [00:19<01:13, 443.19batches/s, l2_loss: 0.0257 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8398/40960 [00:19<01:14, 436.60batches/s, l2_loss: 0.0257 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8398/40960 [00:19<01:14, 436.60batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8478/40960 [00:19<01:16, 424.29batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8478/40960 [00:19<01:16, 424.29batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8560/40960 [00:20<01:17, 418.72batches/s, l2_loss: 0.0254 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8560/40960 [00:20<01:17, 418.72batches/s, l2_loss: 0.0249 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8644/40960 [00:20<01:17, 418.85batches/s, l2_loss: 0.0249 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8644/40960 [00:20<01:17, 418.85batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8731/40960 [00:20<01:16, 422.22batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8731/40960 [00:20<01:16, 422.22batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8814/40960 [00:20<01:16, 419.64batches/s, l2_loss: 0.0255 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8814/40960 [00:20<01:16, 419.64batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8897/40960 [00:20<01:16, 417.17batches/s, l2_loss: 0.0252 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8897/40960 [00:20<01:16, 417.17batches/s, l2_loss: 0.0245 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8981/40960 [00:21<01:16, 417.87batches/s, l2_loss: 0.0245 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8981/40960 [00:21<01:16, 417.87batches/s, l2_loss: 0.0251 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9063/40960 [00:21<01:16, 414.72batches/s, l2_loss: 0.0251 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9063/40960 [00:21<01:16, 414.72batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9146/40960 [00:21<01:16, 414.33batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9146/40960 [00:21<01:16, 414.33batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9231/40960 [00:21<01:16, 416.19batches/s, l2_loss: 0.0253 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9231/40960 [00:21<01:16, 416.19batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9314/40960 [00:21<01:16, 415.34batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9314/40960 [00:21<01:16, 415.34batches/s, l2_loss: 0.0251 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|▏| 9397/40960 [00:22<01:16, 414.20batches/s, l2_loss: 0.0251 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9397/40960 [00:22<01:16, 414.20batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9480/40960 [00:22<01:16, 413.19batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9480/40960 [00:22<01:16, 413.19batches/s, l2_loss: 0.0248 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9565/40960 [00:22<01:15, 415.46batches/s, l2_loss: 0.0248 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9565/40960 [00:22<01:15, 415.46batches/s, l2_loss: 0.0251 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9648/40960 [00:22<01:15, 415.03batches/s, l2_loss: 0.0251 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9648/40960 [00:22<01:15, 415.03batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9733/40960 [00:22<01:14, 417.33batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9733/40960 [00:23<01:14, 417.33batches/s, l2_loss: 0.0249 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9818/40960 [00:23<01:14, 419.12batches/s, l2_loss: 0.0249 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9818/40960 [00:23<01:14, 419.12batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9902/40960 [00:23<01:14, 419.04batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9902/40960 [00:23<01:14, 419.04batches/s, l2_loss: 0.0246 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9987/40960 [00:23<01:13, 419.59batches/s, l2_loss: 0.0246 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9987/40960 [00:23<01:13, 419.59batches/s, l2_loss: 0.0250 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10072/40960 [00:23<01:13, 419.64batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  25%|▏| 10072/40960 [00:23<01:13, 419.64batches/s, l2_loss: 0.0251 - round_los\u001b[A\n",
      "Training:  25%|▏| 10157/40960 [00:24<01:13, 421.04batches/s, l2_loss: 0.0251 - round_los\u001b[A\n",
      "Training:  25%|▏| 10157/40960 [00:24<01:13, 421.04batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  25%|▎| 10243/40960 [00:24<01:12, 423.59batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  25%|▎| 10243/40960 [00:24<01:12, 423.59batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  25%|▎| 10326/40960 [00:24<01:12, 420.68batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  25%|▎| 10326/40960 [00:24<01:12, 420.68batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  25%|▎| 10409/40960 [00:24<01:13, 417.64batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  25%|▎| 10409/40960 [00:24<01:13, 417.64batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  26%|▎| 10493/40960 [00:24<01:12, 417.61batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  26%|▎| 10493/40960 [00:24<01:12, 417.61batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  26%|▎| 10575/40960 [00:25<01:13, 415.27batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  26%|▎| 10575/40960 [00:25<01:13, 415.27batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  26%|▎| 10659/40960 [00:25<01:12, 415.55batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  26%|▎| 10659/40960 [00:25<01:12, 415.55batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  26%|▎| 10746/40960 [00:25<01:11, 420.79batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  26%|▎| 10746/40960 [00:25<01:11, 420.79batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  26%|▎| 10830/40960 [00:25<01:11, 419.84batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  26%|▎| 10830/40960 [00:25<01:11, 419.84batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  27%|▎| 10915/40960 [00:25<01:11, 420.26batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  27%|▎| 10915/40960 [00:25<01:11, 420.26batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  27%|▎| 10999/40960 [00:26<01:11, 419.77batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  27%|▎| 10999/40960 [00:26<01:11, 419.77batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  27%|▎| 11084/40960 [00:26<01:11, 420.70batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  27%|▎| 11084/40960 [00:26<01:11, 420.70batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  27%|▎| 11168/40960 [00:26<01:10, 420.33batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  27%|▎| 11168/40960 [00:26<01:10, 420.33batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  27%|▎| 11250/40960 [00:26<01:11, 415.81batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  27%|▎| 11250/40960 [00:26<01:11, 415.81batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  28%|▎| 11331/40960 [00:26<01:11, 412.56batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  28%|▎| 11331/40960 [00:26<01:11, 412.56batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  28%|▎| 11416/40960 [00:27<01:11, 415.06batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  28%|▎| 11416/40960 [00:27<01:11, 415.06batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  28%|▎| 11498/40960 [00:27<01:11, 413.08batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  28%|▎| 11498/40960 [00:27<01:11, 413.08batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  28%|▎| 11582/40960 [00:27<01:10, 414.34batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  28%|▎| 11582/40960 [00:27<01:10, 414.34batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  28%|▎| 11664/40960 [00:27<01:11, 411.91batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  28%|▎| 11664/40960 [00:27<01:11, 411.91batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  29%|▎| 11748/40960 [00:27<01:10, 412.98batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  29%|▎| 11748/40960 [00:27<01:10, 412.98batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  29%|▎| 11829/40960 [00:28<01:11, 409.48batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  29%|▎| 11829/40960 [00:28<01:11, 409.48batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  29%|▎| 11911/40960 [00:28<01:10, 409.40batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  29%|▎| 11911/40960 [00:28<01:10, 409.40batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  29%|▎| 11996/40960 [00:28<01:10, 412.76batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  29%|▎| 11996/40960 [00:28<01:10, 412.76batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  29%|▎| 12079/40960 [00:28<01:10, 411.83batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  29%|▎| 12079/40960 [00:28<01:10, 411.83batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  30%|▎| 12161/40960 [00:28<01:10, 410.27batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  30%|▎| 12161/40960 [00:28<01:10, 410.27batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  30%|▎| 12243/40960 [00:29<01:10, 410.11batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  30%|▎| 12243/40960 [00:29<01:10, 410.11batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  30%|▎| 12327/40960 [00:29<01:09, 411.87batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  30%|▎| 12327/40960 [00:29<01:09, 411.87batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  30%|▎| 12412/40960 [00:29<01:08, 414.97batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  30%|▎| 12412/40960 [00:29<01:08, 414.97batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  31%|▎| 12496/40960 [00:29<01:08, 415.41batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  31%|▎| 12496/40960 [00:29<01:08, 415.41batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  31%|▎| 12583/40960 [00:29<01:07, 420.65batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  31%|▎| 12583/40960 [00:29<01:07, 420.65batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  31%|▎| 12666/40960 [00:30<01:07, 418.02batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  31%|▎| 12666/40960 [00:30<01:07, 418.02batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  31%|▎| 12748/40960 [00:30<01:08, 414.60batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  31%|▎| 12748/40960 [00:30<01:08, 414.60batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  31%|▎| 12833/40960 [00:30<01:07, 417.18batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  31%|▎| 12833/40960 [00:30<01:07, 417.18batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  32%|▎| 12914/40960 [00:30<01:07, 413.50batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  32%|▎| 12914/40960 [00:30<01:07, 413.50batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  32%|▎| 12996/40960 [00:30<01:07, 411.71batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  32%|▎| 12996/40960 [00:30<01:07, 411.71batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  32%|▎| 13080/40960 [00:31<01:07, 413.97batches/s, l2_loss: 0.0250 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 13080/40960 [00:31<01:07, 413.97batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  32%|▎| 13161/40960 [00:31<01:07, 411.04batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  32%|▎| 13161/40960 [00:31<01:07, 411.04batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  32%|▎| 13246/40960 [00:31<01:06, 415.06batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  32%|▎| 13246/40960 [00:31<01:06, 415.06batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  33%|▎| 13332/40960 [00:31<01:06, 417.94batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  33%|▎| 13332/40960 [00:31<01:06, 417.94batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  33%|▎| 13418/40960 [00:31<01:05, 420.88batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  33%|▎| 13418/40960 [00:31<01:05, 420.88batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  33%|▎| 13504/40960 [00:32<01:04, 423.08batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  33%|▎| 13504/40960 [00:32<01:04, 423.08batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  33%|▎| 13582/40960 [00:32<01:06, 412.26batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  33%|▎| 13582/40960 [00:32<01:06, 412.26batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  33%|▎| 13664/40960 [00:32<01:06, 410.73batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  33%|▎| 13664/40960 [00:32<01:06, 410.73batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  34%|▎| 13745/40960 [00:32<01:06, 408.91batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  34%|▎| 13745/40960 [00:32<01:06, 408.91batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  34%|▎| 13830/40960 [00:32<01:05, 412.71batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  34%|▎| 13830/40960 [00:32<01:05, 412.71batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  34%|▎| 13916/40960 [00:33<01:04, 416.85batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  34%|▎| 13916/40960 [00:33<01:04, 416.85batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  34%|▎| 13998/40960 [00:33<01:05, 413.35batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  34%|▎| 13998/40960 [00:33<01:05, 413.35batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  34%|▎| 14081/40960 [00:33<01:05, 413.30batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  34%|▎| 14081/40960 [00:33<01:05, 413.30batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  35%|▎| 14165/40960 [00:33<01:04, 414.62batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  35%|▎| 14165/40960 [00:33<01:04, 414.62batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  35%|▎| 14251/40960 [00:33<01:03, 418.22batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  35%|▎| 14251/40960 [00:33<01:03, 418.22batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  35%|▎| 14330/40960 [00:34<01:04, 411.01batches/s, l2_loss: 0.0250 - round_los\u001b[A\n",
      "Training:  35%|▎| 14330/40960 [00:34<01:04, 411.01batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  35%|▎| 14414/40960 [00:34<01:04, 413.53batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  35%|▎| 14414/40960 [00:34<01:04, 413.53batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  35%|▎| 14500/40960 [00:34<01:03, 417.47batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  35%|▎| 14500/40960 [00:34<01:03, 417.47batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  36%|▎| 14583/40960 [00:34<01:03, 416.42batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  36%|▎| 14583/40960 [00:34<01:03, 416.42batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  36%|▎| 14668/40960 [00:34<01:02, 418.42batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  36%|▎| 14668/40960 [00:34<01:02, 418.42batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  36%|▎| 14749/40960 [00:35<01:03, 413.94batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  36%|▎| 14749/40960 [00:35<01:03, 413.94batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  36%|▎| 14832/40960 [00:35<01:03, 413.27batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  36%|▎| 14832/40960 [00:35<01:03, 413.27batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  36%|▎| 14918/40960 [00:35<01:02, 417.38batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  36%|▎| 14918/40960 [00:35<01:02, 417.38batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  37%|▎| 15002/40960 [00:35<01:02, 418.01batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  37%|▎| 15002/40960 [00:35<01:02, 418.01batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  37%|▎| 15089/40960 [00:35<01:01, 421.73batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  37%|▎| 15089/40960 [00:35<01:01, 421.73batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  37%|▎| 15176/40960 [00:36<01:00, 425.20batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  37%|▎| 15176/40960 [00:36<01:00, 425.20batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  37%|▎| 15261/40960 [00:36<01:00, 424.67batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  37%|▎| 15261/40960 [00:36<01:00, 424.67batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  37%|▎| 15345/40960 [00:36<01:00, 422.84batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  37%|▎| 15345/40960 [00:36<01:00, 422.84batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  38%|▍| 15430/40960 [00:36<01:00, 422.96batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  38%|▍| 15430/40960 [00:36<01:00, 422.96batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  38%|▍| 15515/40960 [00:36<01:00, 422.99batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  38%|▍| 15515/40960 [00:36<01:00, 422.99batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  38%|▍| 15595/40960 [00:37<01:01, 415.15batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  38%|▍| 15595/40960 [00:37<01:01, 415.15batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  38%|▍| 15679/40960 [00:37<01:00, 415.46batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  38%|▍| 15679/40960 [00:37<01:00, 415.46batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  38%|▍| 15759/40960 [00:37<01:01, 409.96batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  38%|▍| 15759/40960 [00:37<01:01, 409.96batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 15836/40960 [00:37<01:02, 401.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 15836/40960 [00:37<01:02, 401.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 15914/40960 [00:37<01:03, 397.10batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 15914/40960 [00:37<01:03, 397.10batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 15995/40960 [00:38<01:02, 398.50batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 15995/40960 [00:38<01:02, 398.50batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 16079/40960 [00:38<01:01, 404.77batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 16079/40960 [00:38<01:01, 404.77batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 16158/40960 [00:38<01:01, 400.84batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  39%|▍| 16158/40960 [00:38<01:01, 400.84batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  40%|▍| 16233/40960 [00:38<01:03, 391.71batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  40%|▍| 16233/40960 [00:38<01:03, 391.71batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  40%|▍| 16312/40960 [00:38<01:02, 392.20batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  40%|▍| 16312/40960 [00:38<01:02, 392.20batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  40%|▍| 16385/40960 [00:39<01:04, 382.97batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  40%|▍| 16385/40960 [00:39<01:04, 382.97batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  40%|▍| 16466/40960 [00:39<01:03, 388.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  40%|▍| 16466/40960 [00:39<01:03, 388.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  40%|▍| 16542/40960 [00:39<01:03, 384.96batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  40%|▍| 16542/40960 [00:39<01:03, 384.96batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  41%|▍| 16616/40960 [00:39<01:04, 380.24batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  41%|▍| 16616/40960 [00:39<01:04, 380.24batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  41%|▍| 16695/40960 [00:39<01:03, 383.42batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  41%|▍| 16695/40960 [00:39<01:03, 383.42batches/s, l2_loss: 0.0248 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|▍| 16780/40960 [00:40<01:01, 395.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  41%|▍| 16780/40960 [00:40<01:01, 395.70batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  41%|▍| 16864/40960 [00:40<00:59, 402.90batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  41%|▍| 16864/40960 [00:40<00:59, 402.90batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  41%|▍| 16943/40960 [00:40<00:59, 400.37batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  41%|▍| 16943/40960 [00:40<00:59, 400.37batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  42%|▍| 17019/40960 [00:40<01:00, 392.62batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  42%|▍| 17019/40960 [00:40<01:00, 392.62batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  42%|▍| 17089/40960 [00:40<01:03, 378.61batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  42%|▍| 17089/40960 [00:40<01:03, 378.61batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  42%|▍| 17172/40960 [00:41<01:01, 388.33batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  42%|▍| 17172/40960 [00:41<01:01, 388.33batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  42%|▍| 17250/40960 [00:41<01:01, 387.52batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  42%|▍| 17250/40960 [00:41<01:01, 387.52batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  42%|▍| 17327/40960 [00:41<01:01, 386.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  42%|▍| 17327/40960 [00:41<01:01, 386.70batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  42%|▍| 17407/40960 [00:41<01:00, 389.71batches/s, l2_loss: 0.0249 - round_los\u001b[A\n",
      "Training:  42%|▍| 17407/40960 [00:41<01:00, 389.71batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17491/40960 [00:41<00:59, 397.45batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17491/40960 [00:41<00:59, 397.45batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17574/40960 [00:42<00:58, 401.76batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17574/40960 [00:42<00:58, 401.76batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17654/40960 [00:42<00:58, 399.88batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17654/40960 [00:42<00:58, 399.88batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17731/40960 [00:42<00:58, 395.20batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17731/40960 [00:42<00:58, 395.20batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17809/40960 [00:42<00:58, 393.57batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  43%|▍| 17809/40960 [00:42<00:58, 393.57batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 17884/40960 [00:42<00:59, 387.12batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 17884/40960 [00:42<00:59, 387.12batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 17960/40960 [00:43<00:59, 384.66batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 17960/40960 [00:43<00:59, 384.66batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 18041/40960 [00:43<00:58, 389.45batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 18041/40960 [00:43<00:58, 389.45batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 18122/40960 [00:43<00:57, 393.98batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 18122/40960 [00:43<00:57, 393.98batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 18205/40960 [00:43<00:57, 399.14batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  44%|▍| 18205/40960 [00:43<00:57, 399.14batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18280/40960 [00:43<00:58, 389.88batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18280/40960 [00:43<00:58, 389.88batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18352/40960 [00:44<00:59, 380.54batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18352/40960 [00:44<00:59, 380.54batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18434/40960 [00:44<00:57, 388.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18434/40960 [00:44<00:57, 388.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18517/40960 [00:44<00:56, 395.38batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18517/40960 [00:44<00:56, 395.38batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18598/40960 [00:44<00:56, 397.95batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  45%|▍| 18598/40960 [00:44<00:56, 397.95batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 18681/40960 [00:44<00:55, 402.26batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 18681/40960 [00:44<00:55, 402.26batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 18763/40960 [00:45<00:54, 403.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 18763/40960 [00:45<00:54, 403.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 18844/40960 [00:45<00:54, 403.45batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 18844/40960 [00:45<00:54, 403.45batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 18928/40960 [00:45<00:54, 407.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 18928/40960 [00:45<00:54, 407.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 19006/40960 [00:45<00:54, 401.94batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  46%|▍| 19006/40960 [00:45<00:54, 401.94batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19083/40960 [00:45<00:55, 396.73batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19083/40960 [00:45<00:55, 396.73batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19155/40960 [00:46<00:56, 385.04batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19155/40960 [00:46<00:56, 385.04batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19228/40960 [00:46<00:57, 377.65batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19228/40960 [00:46<00:57, 377.65batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19306/40960 [00:46<00:56, 381.05batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19306/40960 [00:46<00:56, 381.05batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19389/40960 [00:46<00:55, 390.93batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  47%|▍| 19389/40960 [00:46<00:55, 390.93batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19472/40960 [00:46<00:54, 397.81batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19472/40960 [00:46<00:54, 397.81batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19555/40960 [00:47<00:53, 402.59batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19555/40960 [00:47<00:53, 402.59batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19638/40960 [00:47<00:52, 405.12batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19638/40960 [00:47<00:52, 405.12batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19721/40960 [00:47<00:52, 407.34batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19721/40960 [00:47<00:52, 407.34batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19806/40960 [00:47<00:51, 411.97batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  48%|▍| 19806/40960 [00:47<00:51, 411.97batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 19891/40960 [00:47<00:50, 414.41batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 19891/40960 [00:47<00:50, 414.41batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 19975/40960 [00:48<00:50, 415.65batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 19975/40960 [00:48<00:50, 415.65batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 20059/40960 [00:48<00:50, 415.84batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 20059/40960 [00:48<00:50, 415.84batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 20142/40960 [00:48<00:50, 415.08batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 20142/40960 [00:48<00:50, 415.08batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 20227/40960 [00:48<00:49, 416.81batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  49%|▍| 20227/40960 [00:48<00:49, 416.81batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  50%|▍| 20314/40960 [00:48<00:48, 421.40batches/s, l2_loss: 0.0248 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▍| 20314/40960 [00:48<00:48, 421.40batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  50%|▍| 20394/40960 [00:49<00:49, 414.73batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  50%|▍| 20394/40960 [00:49<00:49, 414.73batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  50%|▍| 20470/40960 [00:49<00:50, 403.93batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  50%|▍| 20470/40960 [00:49<00:50, 403.93batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  50%|▌| 20537/40960 [00:49<00:53, 382.40batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  50%|▌| 20537/40960 [00:49<00:53, 382.40batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  50%|▌| 20610/40960 [00:49<00:54, 375.98batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  50%|▌| 20610/40960 [00:49<00:54, 375.98batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 20695/40960 [00:49<00:51, 389.81batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 20695/40960 [00:49<00:51, 389.81batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 20772/40960 [00:50<00:52, 388.15batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 20772/40960 [00:50<00:52, 388.15batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 20843/40960 [00:50<00:53, 378.19batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 20843/40960 [00:50<00:53, 378.19batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 20921/40960 [00:50<00:52, 380.89batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 20921/40960 [00:50<00:52, 380.89batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 21004/40960 [00:50<00:51, 390.17batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 21004/40960 [00:50<00:51, 390.17batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 21087/40960 [00:50<00:50, 396.57batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  51%|▌| 21087/40960 [00:50<00:50, 396.57batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21170/40960 [00:51<00:49, 400.71batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21170/40960 [00:51<00:49, 400.71batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21249/40960 [00:51<00:49, 398.72batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21249/40960 [00:51<00:49, 398.72batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21329/40960 [00:51<00:49, 398.83batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21329/40960 [00:51<00:49, 398.83batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21408/40960 [00:51<00:49, 397.15batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21408/40960 [00:51<00:49, 397.15batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21489/40960 [00:51<00:48, 398.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  52%|▌| 21489/40960 [00:51<00:48, 398.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21570/40960 [00:52<00:48, 399.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21570/40960 [00:52<00:48, 399.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21652/40960 [00:52<00:47, 402.32batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21652/40960 [00:52<00:47, 402.32batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21731/40960 [00:52<00:48, 398.98batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21731/40960 [00:52<00:48, 398.98batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21810/40960 [00:52<00:48, 397.01batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21810/40960 [00:52<00:48, 397.01batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21883/40960 [00:52<00:49, 386.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  53%|▌| 21883/40960 [00:52<00:49, 386.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  54%|▌| 21964/40960 [00:53<00:48, 392.11batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  54%|▌| 21964/40960 [00:53<00:48, 392.11batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  54%|▌| 22048/40960 [00:53<00:47, 399.72batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  54%|▌| 22048/40960 [00:53<00:47, 399.72batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  54%|▌| 22132/40960 [00:53<00:46, 405.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  54%|▌| 22132/40960 [00:53<00:46, 405.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  54%|▌| 22213/40960 [00:53<00:46, 405.08batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  54%|▌| 22213/40960 [00:53<00:46, 405.08batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [00:53<00:45, 407.36batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [00:53<00:45, 407.36batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22378/40960 [00:54<00:45, 407.34batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22378/40960 [00:54<00:45, 407.34batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22464/40960 [00:54<00:44, 412.79batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22464/40960 [00:54<00:44, 412.79batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22542/40960 [00:54<00:45, 405.80batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22542/40960 [00:54<00:45, 405.80batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22622/40960 [00:54<00:45, 402.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22622/40960 [00:54<00:45, 402.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22699/40960 [00:54<00:45, 397.25batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  55%|▌| 22699/40960 [00:54<00:45, 397.25batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 22777/40960 [00:55<00:46, 394.39batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 22777/40960 [00:55<00:46, 394.39batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 22855/40960 [00:55<00:46, 392.49batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 22855/40960 [00:55<00:46, 392.49batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 22934/40960 [00:55<00:45, 392.80batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 22934/40960 [00:55<00:45, 392.80batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 23011/40960 [00:55<00:46, 389.08batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 23011/40960 [00:55<00:46, 389.08batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 23090/40960 [00:55<00:45, 390.70batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  56%|▌| 23090/40960 [00:56<00:45, 390.70batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  57%|▌| 23171/40960 [00:56<00:45, 394.22batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  57%|▌| 23171/40960 [00:56<00:45, 394.22batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  57%|▌| 23255/40960 [00:56<00:44, 401.28batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  57%|▌| 23255/40960 [00:56<00:44, 401.28batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  57%|▌| 23330/40960 [00:56<00:44, 392.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  57%|▌| 23330/40960 [00:56<00:44, 392.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  57%|▌| 23406/40960 [00:56<00:45, 388.43batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  57%|▌| 23406/40960 [00:56<00:45, 388.43batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  57%|▌| 23481/40960 [00:57<00:45, 383.15batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  57%|▌| 23481/40960 [00:57<00:45, 383.15batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  58%|▌| 23559/40960 [00:57<00:45, 384.26batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  58%|▌| 23559/40960 [00:57<00:45, 384.26batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  58%|▌| 23638/40960 [00:57<00:44, 386.23batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  58%|▌| 23638/40960 [00:57<00:44, 386.23batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  58%|▌| 23721/40960 [00:57<00:43, 393.82batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  58%|▌| 23721/40960 [00:57<00:43, 393.82batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  58%|▌| 23798/40960 [00:57<00:44, 389.93batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  58%|▌| 23798/40960 [00:57<00:44, 389.93batches/s, l2_loss: 0.0248 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|▌| 23873/40960 [00:58<00:44, 385.32batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  58%|▌| 23873/40960 [00:58<00:44, 385.32batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  58%|▌| 23951/40960 [00:58<00:44, 385.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  58%|▌| 23951/40960 [00:58<00:44, 385.44batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24032/40960 [00:58<00:43, 390.49batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24032/40960 [00:58<00:43, 390.49batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24113/40960 [00:58<00:42, 393.90batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24113/40960 [00:58<00:42, 393.90batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24189/40960 [00:58<00:43, 389.12batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24189/40960 [00:58<00:43, 389.12batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24265/40960 [00:59<00:43, 385.45batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24265/40960 [00:59<00:43, 385.45batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24342/40960 [00:59<00:43, 385.12batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  59%|▌| 24342/40960 [00:59<00:43, 385.12batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  60%|▌| 24418/40960 [00:59<00:43, 383.11batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  60%|▌| 24418/40960 [00:59<00:43, 383.11batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  60%|▌| 24496/40960 [00:59<00:42, 384.87batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  60%|▌| 24496/40960 [00:59<00:42, 384.87batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  60%|▌| 24575/40960 [00:59<00:42, 387.76batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  60%|▌| 24575/40960 [00:59<00:42, 387.76batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  60%|▌| 24654/40960 [01:00<00:41, 389.13batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  60%|▌| 24654/40960 [01:00<00:41, 389.13batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  60%|▌| 24731/40960 [01:00<00:41, 387.63batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  60%|▌| 24731/40960 [01:00<00:41, 387.63batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  61%|▌| 24808/40960 [01:00<00:41, 386.54batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  61%|▌| 24808/40960 [01:00<00:41, 386.54batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  61%|▌| 24885/40960 [01:00<00:41, 385.65batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  61%|▌| 24885/40960 [01:00<00:41, 385.65batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  61%|▌| 24968/40960 [01:00<00:40, 394.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  61%|▌| 24968/40960 [01:00<00:40, 394.29batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  61%|▌| 25050/40960 [01:01<00:39, 398.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  61%|▌| 25050/40960 [01:01<00:39, 398.67batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  61%|▌| 25132/40960 [01:01<00:39, 401.92batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  61%|▌| 25132/40960 [01:01<00:39, 401.92batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25213/40960 [01:01<00:39, 402.79batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25213/40960 [01:01<00:39, 402.79batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25297/40960 [01:01<00:38, 407.93batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25297/40960 [01:01<00:38, 407.93batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25380/40960 [01:01<00:37, 410.03batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25380/40960 [01:01<00:37, 410.03batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25461/40960 [01:02<00:37, 408.20batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25461/40960 [01:02<00:37, 408.20batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25541/40960 [01:02<00:38, 404.60batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  62%|▌| 25541/40960 [01:02<00:38, 404.60batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  63%|▋| 25621/40960 [01:02<00:38, 402.99batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  63%|▋| 25621/40960 [01:02<00:38, 402.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  63%|▋| 25705/40960 [01:02<00:37, 407.77batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  63%|▋| 25705/40960 [01:02<00:37, 407.77batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  63%|▋| 25789/40960 [01:02<00:36, 410.45batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  63%|▋| 25789/40960 [01:02<00:36, 410.45batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  63%|▋| 25873/40960 [01:03<00:36, 412.71batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  63%|▋| 25873/40960 [01:03<00:36, 412.71batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  63%|▋| 25953/40960 [01:03<00:36, 407.80batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  63%|▋| 25953/40960 [01:03<00:36, 407.80batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  64%|▋| 26036/40960 [01:03<00:36, 408.62batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  64%|▋| 26036/40960 [01:03<00:36, 408.62batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  64%|▋| 26117/40960 [01:03<00:36, 406.77batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  64%|▋| 26117/40960 [01:03<00:36, 406.77batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  64%|▋| 26195/40960 [01:03<00:36, 400.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  64%|▋| 26195/40960 [01:03<00:36, 400.67batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  64%|▋| 26278/40960 [01:04<00:36, 404.49batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  64%|▋| 26278/40960 [01:04<00:36, 404.49batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  64%|▋| 26361/40960 [01:04<00:35, 406.87batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  64%|▋| 26361/40960 [01:04<00:35, 406.87batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  65%|▋| 26441/40960 [01:04<00:35, 403.94batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  65%|▋| 26441/40960 [01:04<00:35, 403.94batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  65%|▋| 26522/40960 [01:04<00:35, 403.56batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  65%|▋| 26522/40960 [01:04<00:35, 403.56batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  65%|▋| 26605/40960 [01:04<00:35, 406.53batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  65%|▋| 26605/40960 [01:04<00:35, 406.53batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  65%|▋| 26691/40960 [01:05<00:34, 412.97batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  65%|▋| 26691/40960 [01:05<00:34, 412.97batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  65%|▋| 26773/40960 [01:05<00:34, 411.17batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  65%|▋| 26773/40960 [01:05<00:34, 411.17batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 26855/40960 [01:05<00:34, 410.05batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 26855/40960 [01:05<00:34, 410.05batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 26941/40960 [01:05<00:33, 415.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 26941/40960 [01:05<00:33, 415.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 27025/40960 [01:05<00:33, 415.83batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 27025/40960 [01:05<00:33, 415.83batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 27109/40960 [01:06<00:33, 416.92batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 27109/40960 [01:06<00:33, 416.92batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 27183/40960 [01:06<00:34, 401.33batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  66%|▋| 27183/40960 [01:06<00:34, 401.33batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  67%|▋| 27255/40960 [01:06<00:35, 388.88batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  67%|▋| 27255/40960 [01:06<00:35, 388.88batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  67%|▋| 27336/40960 [01:06<00:34, 392.47batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  67%|▋| 27336/40960 [01:06<00:34, 392.47batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  67%|▋| 27422/40960 [01:06<00:33, 402.83batches/s, l2_loss: 0.0247 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|▋| 27422/40960 [01:06<00:33, 402.83batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  67%|▋| 27504/40960 [01:07<00:33, 404.33batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  67%|▋| 27504/40960 [01:07<00:33, 404.33batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  67%|▋| 27584/40960 [01:07<00:33, 402.44batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  67%|▋| 27584/40960 [01:07<00:33, 402.44batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  68%|▋| 27668/40960 [01:07<00:32, 407.06batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  68%|▋| 27668/40960 [01:07<00:32, 407.06batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  68%|▋| 27753/40960 [01:07<00:32, 411.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  68%|▋| 27753/40960 [01:07<00:32, 411.52batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  68%|▋| 27835/40960 [01:07<00:32, 409.88batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  68%|▋| 27835/40960 [01:07<00:32, 409.88batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  68%|▋| 27915/40960 [01:08<00:32, 405.60batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  68%|▋| 27915/40960 [01:08<00:32, 405.60batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  68%|▋| 27990/40960 [01:08<00:32, 395.54batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  68%|▋| 27990/40960 [01:08<00:32, 395.54batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  69%|▋| 28065/40960 [01:08<00:33, 388.17batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  69%|▋| 28065/40960 [01:08<00:33, 388.17batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  69%|▋| 28138/40960 [01:08<00:33, 381.21batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  69%|▋| 28138/40960 [01:08<00:33, 381.21batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  69%|▋| 28216/40960 [01:08<00:33, 383.22batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  69%|▋| 28216/40960 [01:08<00:33, 383.22batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  69%|▋| 28299/40960 [01:09<00:32, 392.55batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  69%|▋| 28299/40960 [01:09<00:32, 392.55batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  69%|▋| 28383/40960 [01:09<00:31, 399.84batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  69%|▋| 28383/40960 [01:09<00:31, 399.84batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  69%|▋| 28467/40960 [01:09<00:30, 405.48batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  69%|▋| 28467/40960 [01:09<00:30, 405.48batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  70%|▋| 28552/40960 [01:09<00:30, 410.33batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  70%|▋| 28552/40960 [01:09<00:30, 410.33batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  70%|▋| 28639/40960 [01:09<00:29, 417.42batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  70%|▋| 28639/40960 [01:09<00:29, 417.42batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  70%|▋| 28726/40960 [01:10<00:28, 422.41batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  70%|▋| 28726/40960 [01:10<00:28, 422.41batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  70%|▋| 28814/40960 [01:10<00:28, 427.62batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  70%|▋| 28814/40960 [01:10<00:28, 427.62batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  71%|▋| 28901/40960 [01:10<00:28, 429.11batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  71%|▋| 28901/40960 [01:10<00:28, 429.11batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  71%|▋| 28984/40960 [01:10<00:28, 424.23batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  71%|▋| 28984/40960 [01:10<00:28, 424.23batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  71%|▋| 29066/40960 [01:10<00:28, 418.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  71%|▋| 29066/40960 [01:10<00:28, 418.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  71%|▋| 29152/40960 [01:11<00:28, 420.66batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  71%|▋| 29152/40960 [01:11<00:28, 420.66batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  71%|▋| 29235/40960 [01:11<00:28, 417.91batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  71%|▋| 29235/40960 [01:11<00:28, 417.91batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29320/40960 [01:11<00:27, 418.72batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29320/40960 [01:11<00:27, 418.72batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29404/40960 [01:11<00:27, 418.26batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29404/40960 [01:11<00:27, 418.26batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29488/40960 [01:11<00:27, 417.93batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29488/40960 [01:11<00:27, 417.93batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29573/40960 [01:12<00:27, 419.82batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29573/40960 [01:12<00:27, 419.82batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29660/40960 [01:12<00:26, 423.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  72%|▋| 29660/40960 [01:12<00:26, 423.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  73%|▋| 29745/40960 [01:12<00:26, 423.70batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  73%|▋| 29745/40960 [01:12<00:26, 423.70batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  73%|▋| 29826/40960 [01:12<00:26, 416.90batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  73%|▋| 29826/40960 [01:12<00:26, 416.90batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  73%|▋| 29911/40960 [01:12<00:26, 418.39batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  73%|▋| 29911/40960 [01:12<00:26, 418.39batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  73%|▋| 29998/40960 [01:13<00:25, 422.54batches/s, l2_loss: 0.0248 - round_los\u001b[A\n",
      "Training:  73%|▋| 29998/40960 [01:13<00:25, 422.54batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  73%|▋| 30084/40960 [01:13<00:25, 424.19batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  73%|▋| 30084/40960 [01:13<00:25, 424.19batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30167/40960 [01:13<00:25, 421.26batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30167/40960 [01:13<00:25, 421.26batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30253/40960 [01:13<00:25, 422.93batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30253/40960 [01:13<00:25, 422.93batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30336/40960 [01:13<00:25, 420.49batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30336/40960 [01:13<00:25, 420.49batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30421/40960 [01:14<00:24, 421.59batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30421/40960 [01:14<00:24, 421.59batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30506/40960 [01:14<00:24, 421.15batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  74%|▋| 30506/40960 [01:14<00:24, 421.15batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▋| 30590/40960 [01:14<00:24, 419.94batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▋| 30590/40960 [01:14<00:24, 419.94batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▋| 30675/40960 [01:14<00:24, 420.01batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▋| 30675/40960 [01:14<00:24, 420.01batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▊| 30760/40960 [01:14<00:24, 420.97batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▊| 30760/40960 [01:14<00:24, 420.97batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▊| 30845/40960 [01:15<00:23, 421.48batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▊| 30845/40960 [01:15<00:23, 421.48batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▊| 30907/40960 [01:15<00:26, 386.08batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  75%|▊| 30907/40960 [01:15<00:26, 386.08batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 30987/40960 [01:15<00:25, 389.95batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 30987/40960 [01:15<00:25, 389.95batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 31071/40960 [01:15<00:24, 398.77batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 31071/40960 [01:15<00:24, 398.77batches/s, l2_loss: 0.0247 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31156/40960 [01:15<00:24, 405.97batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 31156/40960 [01:15<00:24, 405.97batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 31242/40960 [01:16<00:23, 412.74batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 31242/40960 [01:16<00:23, 412.74batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 31329/40960 [01:16<00:22, 419.16batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  76%|▊| 31329/40960 [01:16<00:22, 419.16batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  77%|▊| 31415/40960 [01:16<00:22, 421.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  77%|▊| 31415/40960 [01:16<00:22, 421.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  77%|▊| 31501/40960 [01:16<00:22, 423.32batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  77%|▊| 31501/40960 [01:16<00:22, 423.32batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  77%|▊| 31585/40960 [01:16<00:22, 422.07batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  77%|▊| 31585/40960 [01:16<00:22, 422.07batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  77%|▊| 31670/40960 [01:17<00:22, 421.60batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  77%|▊| 31670/40960 [01:17<00:22, 421.60batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 31757/40960 [01:17<00:21, 425.46batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 31757/40960 [01:17<00:21, 425.46batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 31841/40960 [01:17<00:21, 422.51batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 31841/40960 [01:17<00:21, 422.51batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 31928/40960 [01:17<00:21, 425.03batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 31928/40960 [01:17<00:21, 425.03batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 32014/40960 [01:17<00:21, 425.93batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 32014/40960 [01:17<00:21, 425.93batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 32100/40960 [01:18<00:20, 426.62batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  78%|▊| 32100/40960 [01:18<00:20, 426.62batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32180/40960 [01:18<00:20, 418.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32180/40960 [01:18<00:20, 418.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32266/40960 [01:18<00:20, 421.90batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32266/40960 [01:18<00:20, 421.90batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32352/40960 [01:18<00:20, 423.02batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32352/40960 [01:18<00:20, 423.02batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32437/40960 [01:18<00:20, 422.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32437/40960 [01:18<00:20, 422.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32524/40960 [01:19<00:19, 425.42batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  79%|▊| 32524/40960 [01:19<00:19, 425.42batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32610/40960 [01:19<00:19, 426.25batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32610/40960 [01:19<00:19, 426.25batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32695/40960 [01:19<00:19, 424.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32695/40960 [01:19<00:19, 424.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32776/40960 [01:19<00:19, 418.43batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32776/40960 [01:19<00:19, 418.43batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32860/40960 [01:19<00:19, 417.61batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32860/40960 [01:19<00:19, 417.61batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32944/40960 [01:20<00:19, 417.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  80%|▊| 32944/40960 [01:20<00:19, 417.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33029/40960 [01:20<00:18, 419.84batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33029/40960 [01:20<00:18, 419.84batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33110/40960 [01:20<00:18, 414.67batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33110/40960 [01:20<00:18, 414.67batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33195/40960 [01:20<00:18, 416.70batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33195/40960 [01:20<00:18, 416.70batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33278/40960 [01:20<00:18, 414.84batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33278/40960 [01:20<00:18, 414.84batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33362/40960 [01:21<00:18, 415.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  81%|▊| 33362/40960 [01:21<00:18, 415.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33447/40960 [01:21<00:17, 417.57batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33447/40960 [01:21<00:17, 417.57batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33530/40960 [01:21<00:17, 416.71batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33530/40960 [01:21<00:17, 416.71batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33614/40960 [01:21<00:17, 416.84batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33614/40960 [01:21<00:17, 416.84batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33700/40960 [01:21<00:17, 420.74batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33700/40960 [01:21<00:17, 420.74batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33787/40960 [01:22<00:16, 423.75batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  82%|▊| 33787/40960 [01:22<00:16, 423.75batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  83%|▊| 33869/40960 [01:22<00:16, 418.24batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  83%|▊| 33869/40960 [01:22<00:16, 418.24batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  83%|▊| 33956/40960 [01:22<00:16, 422.19batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  83%|▊| 33956/40960 [01:22<00:16, 422.19batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  83%|▊| 34043/40960 [01:22<00:16, 425.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  83%|▊| 34043/40960 [01:22<00:16, 425.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  83%|▊| 34132/40960 [01:22<00:15, 430.17batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  83%|▊| 34132/40960 [01:22<00:15, 430.17batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34216/40960 [01:23<00:15, 426.96batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34216/40960 [01:23<00:15, 426.96batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34301/40960 [01:23<00:15, 425.73batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34301/40960 [01:23<00:15, 425.73batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34388/40960 [01:23<00:15, 427.07batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34388/40960 [01:23<00:15, 427.07batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34474/40960 [01:23<00:15, 427.28batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34474/40960 [01:23<00:15, 427.28batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34558/40960 [01:23<00:15, 423.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  84%|▊| 34558/40960 [01:23<00:15, 423.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34642/40960 [01:24<00:15, 421.04batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34642/40960 [01:24<00:15, 421.04batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34724/40960 [01:24<00:14, 416.92batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34724/40960 [01:24<00:14, 416.92batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34806/40960 [01:24<00:14, 413.55batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34806/40960 [01:24<00:14, 413.55batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34893/40960 [01:24<00:14, 419.69batches/s, l2_loss: 0.0247 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34893/40960 [01:24<00:14, 419.69batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34974/40960 [01:24<00:14, 415.03batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  85%|▊| 34974/40960 [01:24<00:14, 415.03batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35057/40960 [01:25<00:14, 413.89batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35057/40960 [01:25<00:14, 413.89batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35142/40960 [01:25<00:13, 415.83batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35142/40960 [01:25<00:13, 415.83batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35228/40960 [01:25<00:13, 418.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35228/40960 [01:25<00:13, 418.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35314/40960 [01:25<00:13, 420.90batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35314/40960 [01:25<00:13, 420.90batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35396/40960 [01:25<00:13, 416.95batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  86%|▊| 35396/40960 [01:25<00:13, 416.95batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35477/40960 [01:26<00:13, 412.53batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35477/40960 [01:26<00:13, 412.53batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35562/40960 [01:26<00:12, 415.33batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35562/40960 [01:26<00:12, 415.33batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35648/40960 [01:26<00:12, 418.36batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35648/40960 [01:26<00:12, 418.36batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35733/40960 [01:26<00:12, 419.72batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35733/40960 [01:26<00:12, 419.72batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35819/40960 [01:26<00:12, 422.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  87%|▊| 35819/40960 [01:26<00:12, 422.52batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 35897/40960 [01:27<00:12, 411.63batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 35897/40960 [01:27<00:12, 411.63batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 35971/40960 [01:27<00:12, 398.12batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 35971/40960 [01:27<00:12, 398.12batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 36053/40960 [01:27<00:12, 401.66batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 36053/40960 [01:27<00:12, 401.66batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 36134/40960 [01:27<00:12, 401.80batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 36134/40960 [01:27<00:12, 401.80batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 36216/40960 [01:27<00:11, 403.93batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  88%|▉| 36216/40960 [01:27<00:11, 403.93batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36300/40960 [01:28<00:11, 408.56batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36300/40960 [01:28<00:11, 408.56batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36385/40960 [01:28<00:11, 412.13batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36385/40960 [01:28<00:11, 412.13batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36469/40960 [01:28<00:10, 414.10batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36469/40960 [01:28<00:10, 414.10batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36553/40960 [01:28<00:10, 415.23batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36553/40960 [01:28<00:10, 415.23batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36635/40960 [01:28<00:10, 412.55batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  89%|▉| 36635/40960 [01:28<00:10, 412.55batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 36716/40960 [01:29<00:10, 409.63batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 36716/40960 [01:29<00:10, 409.63batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 36798/40960 [01:29<00:10, 408.45batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 36798/40960 [01:29<00:10, 408.45batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 36882/40960 [01:29<00:09, 411.28batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 36882/40960 [01:29<00:09, 411.28batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 36962/40960 [01:29<00:09, 406.77batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 36962/40960 [01:29<00:09, 406.77batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 37046/40960 [01:30<00:09, 409.91batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  90%|▉| 37046/40960 [01:30<00:09, 409.91batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37129/40960 [01:30<00:09, 411.37batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37129/40960 [01:30<00:09, 411.37batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37212/40960 [01:30<00:09, 412.39batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37212/40960 [01:30<00:09, 412.39batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37295/40960 [01:30<00:08, 412.72batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37295/40960 [01:30<00:08, 412.72batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37378/40960 [01:30<00:08, 412.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37378/40960 [01:30<00:08, 412.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37460/40960 [01:31<00:08, 412.02batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  91%|▉| 37460/40960 [01:31<00:08, 412.02batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37544/40960 [01:31<00:08, 412.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37544/40960 [01:31<00:08, 412.99batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37627/40960 [01:31<00:08, 412.28batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37627/40960 [01:31<00:08, 412.28batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37711/40960 [01:31<00:07, 414.51batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37711/40960 [01:31<00:07, 414.51batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37794/40960 [01:31<00:07, 414.38batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37794/40960 [01:31<00:07, 414.38batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37880/40960 [01:32<00:07, 418.20batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  92%|▉| 37880/40960 [01:32<00:07, 418.20batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 37962/40960 [01:32<00:07, 415.23batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 37962/40960 [01:32<00:07, 415.23batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 38047/40960 [01:32<00:06, 417.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 38047/40960 [01:32<00:06, 417.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 38130/40960 [01:32<00:06, 415.65batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 38130/40960 [01:32<00:06, 415.65batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 38208/40960 [01:32<00:06, 407.21batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 38208/40960 [01:32<00:06, 407.21batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 38279/40960 [01:33<00:06, 390.81batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  93%|▉| 38279/40960 [01:33<00:06, 390.81batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38354/40960 [01:33<00:06, 385.43batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38354/40960 [01:33<00:06, 385.43batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38437/40960 [01:33<00:06, 393.38batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38437/40960 [01:33<00:06, 393.38batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38518/40960 [01:33<00:06, 396.14batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38518/40960 [01:33<00:06, 396.14batches/s, l2_loss: 0.0247 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|▉| 38603/40960 [01:33<00:05, 404.12batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38603/40960 [01:33<00:05, 404.12batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38686/40960 [01:34<00:05, 407.27batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  94%|▉| 38686/40960 [01:34<00:05, 407.27batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 38760/40960 [01:34<00:05, 395.91batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 38760/40960 [01:34<00:05, 395.91batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 38838/40960 [01:34<00:05, 393.76batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 38838/40960 [01:34<00:05, 393.76batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 38914/40960 [01:34<00:05, 388.86batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 38914/40960 [01:34<00:05, 388.86batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 38987/40960 [01:34<00:05, 381.31batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 38987/40960 [01:34<00:05, 381.31batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 39059/40960 [01:35<00:05, 374.18batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  95%|▉| 39059/40960 [01:35<00:05, 374.18batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39132/40960 [01:35<00:04, 371.27batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39132/40960 [01:35<00:04, 371.27batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39212/40960 [01:35<00:04, 379.53batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39212/40960 [01:35<00:04, 379.53batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39296/40960 [01:35<00:04, 390.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39296/40960 [01:35<00:04, 390.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39378/40960 [01:35<00:03, 396.20batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39378/40960 [01:35<00:03, 396.20batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39462/40960 [01:36<00:03, 402.25batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  96%|▉| 39462/40960 [01:36<00:03, 402.25batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39547/40960 [01:36<00:03, 408.42batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39547/40960 [01:36<00:03, 408.42batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39627/40960 [01:36<00:03, 405.67batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39627/40960 [01:36<00:03, 405.67batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39708/40960 [01:36<00:03, 405.47batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39708/40960 [01:36<00:03, 405.47batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39792/40960 [01:36<00:02, 408.22batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39792/40960 [01:36<00:02, 408.22batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39876/40960 [01:37<00:02, 411.01batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  97%|▉| 39876/40960 [01:37<00:02, 411.01batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 39956/40960 [01:37<00:02, 406.24batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 39956/40960 [01:37<00:02, 406.24batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 40038/40960 [01:37<00:02, 406.09batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 40038/40960 [01:37<00:02, 406.09batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 40123/40960 [01:37<00:02, 410.90batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 40123/40960 [01:37<00:02, 410.90batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 40205/40960 [01:37<00:01, 410.61batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 40205/40960 [01:37<00:01, 410.61batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 40290/40960 [01:38<00:01, 414.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  98%|▉| 40290/40960 [01:38<00:01, 414.29batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40375/40960 [01:38<00:01, 417.16batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40375/40960 [01:38<00:01, 417.16batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40457/40960 [01:38<00:01, 414.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40457/40960 [01:38<00:01, 414.58batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40533/40960 [01:38<00:01, 403.81batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40533/40960 [01:38<00:01, 403.81batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40611/40960 [01:38<00:00, 398.65batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40611/40960 [01:38<00:00, 398.65batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40698/40960 [01:39<00:00, 409.17batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training:  99%|▉| 40698/40960 [01:39<00:00, 409.17batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training: 100%|▉| 40782/40960 [01:39<00:00, 411.78batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training: 100%|▉| 40782/40960 [01:39<00:00, 411.78batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training: 100%|▉| 40865/40960 [01:39<00:00, 412.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training: 100%|▉| 40865/40960 [01:39<00:00, 412.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training: 100%|▉| 40933/40960 [01:39<00:00, 389.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "Training: 100%|▉| 40933/40960 [01:39<00:00, 389.44batches/s, l2_loss: 0.0247 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:21:29.403502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  62%|▌| 16/26 [32:07<19:54, 119.43s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:21:30.773225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:21:37.572614: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<26:52:54,  2.36s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<26:52:54,  2.36s/batches, l2_loss: 0.0297 - round_loss:\u001b[A\n",
      "Training:   0%| | 60/40960 [00:02<21:10, 32.19batches/s, l2_loss: 0.0297 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 60/40960 [00:02<21:10, 32.19batches/s, l2_loss: 0.0578 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 120/40960 [00:02<10:01, 67.88batches/s, l2_loss: 0.0578 - round_loss: \u001b[A\n",
      "Training:   0%| | 120/40960 [00:02<10:01, 67.88batches/s, l2_loss: 0.0547 - round_loss: \u001b[A\n",
      "Training:   0%| | 183/40960 [00:02<06:20, 107.30batches/s, l2_loss: 0.0547 - round_loss:\u001b[A\n",
      "Training:   0%| | 183/40960 [00:02<06:20, 107.30batches/s, l2_loss: 0.0514 - round_loss:\u001b[A\n",
      "Training:   1%| | 244/40960 [00:03<04:42, 144.05batches/s, l2_loss: 0.0514 - round_loss:\u001b[A\n",
      "Training:   1%| | 244/40960 [00:03<04:42, 144.05batches/s, l2_loss: 0.0532 - round_loss:\u001b[A\n",
      "Training:   1%| | 305/40960 [00:03<03:48, 177.66batches/s, l2_loss: 0.0532 - round_loss:\u001b[A\n",
      "Training:   1%| | 305/40960 [00:03<03:48, 177.66batches/s, l2_loss: 0.0541 - round_loss:\u001b[A\n",
      "Training:   1%| | 365/40960 [00:03<03:17, 205.56batches/s, l2_loss: 0.0541 - round_loss:\u001b[A\n",
      "Training:   1%| | 365/40960 [00:03<03:17, 205.56batches/s, l2_loss: 0.0535 - round_loss:\u001b[A\n",
      "Training:   1%| | 427/40960 [00:03<02:55, 230.47batches/s, l2_loss: 0.0535 - round_loss:\u001b[A\n",
      "Training:   1%| | 427/40960 [00:03<02:55, 230.47batches/s, l2_loss: 0.0523 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%| | 469/40960 [00:03<03:00, 224.63batches/s, l2_loss: 0.0523 - round_loss:\u001b[A\n",
      "Training:   1%| | 469/40960 [00:03<03:00, 224.63batches/s, l2_loss: 0.0524 - round_loss:\u001b[A\n",
      "Training:   1%| | 530/40960 [00:04<02:44, 245.48batches/s, l2_loss: 0.0524 - round_loss:\u001b[A\n",
      "Training:   1%| | 530/40960 [00:04<02:44, 245.48batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   1%| | 592/40960 [00:04<02:33, 263.10batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   1%| | 592/40960 [00:04<02:33, 263.10batches/s, l2_loss: 0.0547 - round_loss:\u001b[A\n",
      "Training:   2%| | 655/40960 [00:04<02:25, 277.82batches/s, l2_loss: 0.0547 - round_loss:\u001b[A\n",
      "Training:   2%| | 655/40960 [00:04<02:25, 277.82batches/s, l2_loss: 0.0543 - round_loss:\u001b[A\n",
      "Training:   2%| | 701/40960 [00:04<02:33, 262.37batches/s, l2_loss: 0.0543 - round_loss:\u001b[A\n",
      "Training:   2%| | 701/40960 [00:04<02:33, 262.37batches/s, l2_loss: 0.0535 - round_loss:\u001b[A\n",
      "Training:   2%| | 756/40960 [00:04<02:31, 264.78batches/s, l2_loss: 0.0535 - round_loss:\u001b[A\n",
      "Training:   2%| | 756/40960 [00:04<02:31, 264.78batches/s, l2_loss: 0.0540 - round_loss:\u001b[A\n",
      "Training:   2%| | 817/40960 [00:05<02:25, 275.59batches/s, l2_loss: 0.0540 - round_loss:\u001b[A\n",
      "Training:   2%| | 817/40960 [00:05<02:25, 275.59batches/s, l2_loss: 0.0542 - round_loss:\u001b[A\n",
      "Training:   2%| | 878/40960 [00:05<02:21, 283.41batches/s, l2_loss: 0.0542 - round_loss:\u001b[A\n",
      "Training:   2%| | 878/40960 [00:05<02:21, 283.41batches/s, l2_loss: 0.0541 - round_loss:\u001b[A\n",
      "Training:   2%| | 936/40960 [00:05<02:20, 283.96batches/s, l2_loss: 0.0541 - round_loss:\u001b[A\n",
      "Training:   2%| | 936/40960 [00:05<02:20, 283.96batches/s, l2_loss: 0.0537 - round_loss:\u001b[A\n",
      "Training:   2%| | 996/40960 [00:05<02:18, 288.28batches/s, l2_loss: 0.0537 - round_loss:\u001b[A\n",
      "Training:   2%| | 996/40960 [00:05<02:18, 288.28batches/s, l2_loss: 0.0533 - round_loss:\u001b[A\n",
      "Training:   3%| | 1055/40960 [00:05<02:18, 288.86batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   3%| | 1055/40960 [00:06<02:18, 288.86batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   3%| | 1110/40960 [00:06<02:20, 283.37batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   3%| | 1110/40960 [00:06<02:20, 283.37batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1169/40960 [00:06<02:19, 286.14batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1169/40960 [00:06<02:19, 286.14batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   3%| | 1230/40960 [00:06<02:16, 291.37batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   3%| | 1230/40960 [00:06<02:16, 291.37batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   3%| | 1288/40960 [00:06<02:16, 289.82batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   3%| | 1288/40960 [00:06<02:16, 289.82batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   3%| | 1347/40960 [00:07<02:16, 289.52batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   3%| | 1347/40960 [00:07<02:16, 289.52batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   3%| | 1399/40960 [00:07<02:21, 280.26batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   3%| | 1399/40960 [00:07<02:21, 280.26batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   4%| | 1444/40960 [00:07<02:29, 263.49batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   4%| | 1444/40960 [00:07<02:29, 263.49batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   4%| | 1504/40960 [00:07<02:24, 273.93batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   4%| | 1504/40960 [00:07<02:24, 273.93batches/s, l2_loss: 0.0540 - round_loss\u001b[A\n",
      "Training:   4%| | 1559/40960 [00:07<02:24, 273.55batches/s, l2_loss: 0.0540 - round_loss\u001b[A\n",
      "Training:   4%| | 1559/40960 [00:07<02:24, 273.55batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   4%| | 1618/40960 [00:08<02:21, 278.69batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   4%| | 1618/40960 [00:08<02:21, 278.69batches/s, l2_loss: 0.0536 - round_loss\u001b[A\n",
      "Training:   4%| | 1675/40960 [00:08<02:20, 279.74batches/s, l2_loss: 0.0536 - round_loss\u001b[A\n",
      "Training:   4%| | 1675/40960 [00:08<02:20, 279.74batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   4%| | 1734/40960 [00:08<02:18, 283.56batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   4%| | 1734/40960 [00:08<02:18, 283.56batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   4%| | 1795/40960 [00:08<02:15, 288.47batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   4%| | 1795/40960 [00:08<02:15, 288.47batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   5%| | 1854/40960 [00:08<02:15, 288.86batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   5%| | 1854/40960 [00:08<02:15, 288.86batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   5%| | 1912/40960 [00:09<02:15, 288.28batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   5%| | 1912/40960 [00:09<02:15, 288.28batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   5%| | 1962/40960 [00:09<02:21, 275.95batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   5%| | 1962/40960 [00:09<02:21, 275.95batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2015/40960 [00:09<02:23, 271.40batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2015/40960 [00:09<02:23, 271.40batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   5%| | 2070/40960 [00:09<02:23, 271.66batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   5%| | 2070/40960 [00:09<02:23, 271.66batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2131/40960 [00:09<02:18, 280.84batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2131/40960 [00:09<02:18, 280.84batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   5%| | 2189/40960 [00:10<02:17, 281.93batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   5%| | 2189/40960 [00:10<02:17, 281.93batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2250/40960 [00:10<02:14, 287.34batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2250/40960 [00:10<02:14, 287.34batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   6%| | 2307/40960 [00:10<02:15, 285.96batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   6%| | 2307/40960 [00:10<02:15, 285.96batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   6%| | 2361/40960 [00:10<02:17, 280.61batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   6%| | 2361/40960 [00:10<02:17, 280.61batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   6%| | 2419/40960 [00:10<02:17, 280.68batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   6%| | 2419/40960 [00:10<02:17, 280.68batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   6%| | 2477/40960 [00:11<02:15, 283.27batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   6%| | 2477/40960 [00:11<02:15, 283.27batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   6%| | 2537/40960 [00:11<02:13, 287.81batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   6%| | 2537/40960 [00:11<02:13, 287.81batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   6%| | 2596/40960 [00:11<02:12, 288.51batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   6%| | 2596/40960 [00:11<02:12, 288.51batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   6%| | 2653/40960 [00:11<02:13, 286.38batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   6%| | 2653/40960 [00:11<02:13, 286.38batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   7%| | 2708/40960 [00:11<02:15, 282.50batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   7%| | 2708/40960 [00:11<02:15, 282.50batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   7%| | 2764/40960 [00:12<02:16, 280.59batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   7%| | 2764/40960 [00:12<02:16, 280.59batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   7%| | 2820/40960 [00:12<02:16, 279.86batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   7%| | 2820/40960 [00:12<02:16, 279.86batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   7%| | 2876/40960 [00:12<02:16, 279.78batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   7%| | 2876/40960 [00:12<02:16, 279.78batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   7%| | 2934/40960 [00:12<02:15, 281.61batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   7%| | 2934/40960 [00:12<02:15, 281.61batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   7%| | 2994/40960 [00:12<02:12, 286.20batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 2994/40960 [00:12<02:12, 286.20batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   7%| | 3054/40960 [00:13<02:11, 288.82batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   7%| | 3054/40960 [00:13<02:11, 288.82batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   8%| | 3110/40960 [00:13<02:12, 285.08batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   8%| | 3110/40960 [00:13<02:12, 285.08batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   8%| | 3161/40960 [00:13<02:16, 276.12batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   8%| | 3161/40960 [00:13<02:16, 276.12batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   8%| | 3215/40960 [00:13<02:18, 273.03batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   8%| | 3215/40960 [00:13<02:18, 273.03batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   8%| | 3265/40960 [00:13<02:21, 266.05batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   8%| | 3265/40960 [00:13<02:21, 266.05batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   8%| | 3323/40960 [00:14<02:17, 273.14batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   8%| | 3323/40960 [00:14<02:17, 273.14batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   8%| | 3374/40960 [00:14<02:20, 266.82batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   8%| | 3374/40960 [00:14<02:20, 266.82batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   8%| | 3424/40960 [00:14<02:23, 260.83batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   8%| | 3424/40960 [00:14<02:23, 260.83batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   9%| | 3482/40960 [00:14<02:19, 268.38batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   9%| | 3482/40960 [00:14<02:19, 268.38batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3541/40960 [00:14<02:15, 275.62batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3541/40960 [00:14<02:15, 275.62batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   9%| | 3599/40960 [00:15<02:14, 278.66batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   9%| | 3599/40960 [00:15<02:14, 278.66batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   9%| | 3652/40960 [00:15<02:16, 273.74batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   9%| | 3652/40960 [00:15<02:16, 273.74batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   9%| | 3695/40960 [00:15<02:26, 253.52batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   9%| | 3695/40960 [00:15<02:26, 253.52batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3739/40960 [00:15<02:33, 243.08batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3739/40960 [00:15<02:33, 243.08batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   9%| | 3799/40960 [00:15<02:23, 258.79batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   9%| | 3799/40960 [00:15<02:23, 258.79batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   9%| | 3853/40960 [00:16<02:21, 261.58batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   9%| | 3853/40960 [00:16<02:21, 261.58batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 3911/40960 [00:16<02:18, 267.46batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 3911/40960 [00:16<02:18, 267.46batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  10%| | 3967/40960 [00:16<02:16, 270.30batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  10%| | 3967/40960 [00:16<02:16, 270.30batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 4025/40960 [00:16<02:14, 275.53batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 4025/40960 [00:16<02:14, 275.53batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 4083/40960 [00:16<02:12, 278.55batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 4083/40960 [00:16<02:12, 278.55batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 4138/40960 [00:17<02:12, 277.05batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 4138/40960 [00:17<02:12, 277.05batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  10%| | 4198/40960 [00:17<02:10, 282.24batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  10%| | 4198/40960 [00:17<02:10, 282.24batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 4257/40960 [00:17<02:08, 284.60batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  10%| | 4257/40960 [00:17<02:08, 284.60batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  11%| | 4318/40960 [00:17<02:06, 290.18batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  11%| | 4318/40960 [00:17<02:06, 290.18batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  11%| | 4378/40960 [00:17<02:05, 292.08batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  11%| | 4378/40960 [00:17<02:05, 292.08batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  11%| | 4435/40960 [00:18<02:06, 288.97batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  11%| | 4435/40960 [00:18<02:06, 288.97batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  11%| | 4493/40960 [00:18<02:06, 288.43batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  11%| | 4493/40960 [00:18<02:06, 288.43batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  11%| | 4551/40960 [00:18<02:06, 288.04batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  11%| | 4551/40960 [00:18<02:06, 288.04batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  11%| | 4613/40960 [00:18<02:03, 294.14batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  11%| | 4613/40960 [00:18<02:03, 294.14batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  11%| | 4666/40960 [00:18<02:07, 283.83batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  11%| | 4666/40960 [00:18<02:07, 283.83batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  12%| | 4724/40960 [00:19<02:07, 284.89batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  12%| | 4724/40960 [00:19<02:07, 284.89batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  12%| | 4783/40960 [00:19<02:06, 286.34batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  12%| | 4783/40960 [00:19<02:06, 286.34batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  12%| | 4849/40960 [00:19<02:01, 298.06batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  12%| | 4849/40960 [00:19<02:01, 298.06batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  12%| | 4909/40960 [00:19<02:00, 298.01batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  12%| | 4909/40960 [00:19<02:00, 298.01batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  12%| | 4968/40960 [00:19<02:01, 296.89batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  12%| | 4968/40960 [00:19<02:01, 296.89batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  12%| | 5033/40960 [00:20<01:58, 304.45batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  12%| | 5033/40960 [00:20<01:58, 304.45batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  12%| | 5095/40960 [00:20<01:57, 305.96batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  12%| | 5095/40960 [00:20<01:57, 305.96batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5160/40960 [00:20<01:55, 310.87batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5160/40960 [00:20<01:55, 310.87batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5215/40960 [00:20<01:59, 299.56batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5215/40960 [00:20<01:59, 299.56batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5272/40960 [00:20<02:01, 294.12batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5272/40960 [00:20<02:01, 294.12batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5330/40960 [00:21<02:02, 292.00batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5330/40960 [00:21<02:02, 292.00batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5388/40960 [00:21<02:02, 290.50batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5388/40960 [00:21<02:02, 290.50batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5441/40960 [00:21<02:05, 282.11batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5441/40960 [00:21<02:05, 282.11batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5503/40960 [00:21<02:02, 290.10batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5503/40960 [00:21<02:02, 290.10batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|▏| 5559/40960 [00:21<02:03, 285.82batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5559/40960 [00:21<02:03, 285.82batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5621/40960 [00:22<02:01, 292.04batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5621/40960 [00:22<02:01, 292.04batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5675/40960 [00:22<02:04, 283.76batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5675/40960 [00:22<02:04, 283.76batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5733/40960 [00:22<02:03, 285.60batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5733/40960 [00:22<02:03, 285.60batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5790/40960 [00:22<02:03, 284.68batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5790/40960 [00:22<02:03, 284.68batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5847/40960 [00:22<02:03, 283.33batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5847/40960 [00:22<02:03, 283.33batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5900/40960 [00:23<02:07, 276.05batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5900/40960 [00:23<02:07, 276.05batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5949/40960 [00:23<02:11, 266.77batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5949/40960 [00:23<02:11, 266.77batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6006/40960 [00:23<02:08, 271.32batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6006/40960 [00:23<02:08, 271.32batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6066/40960 [00:23<02:04, 279.70batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6066/40960 [00:23<02:04, 279.70batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6127/40960 [00:23<02:01, 287.08batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6127/40960 [00:24<02:01, 287.08batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6190/40960 [00:24<01:57, 294.85batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6190/40960 [00:24<01:57, 294.85batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6254/40960 [00:24<01:55, 301.72batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6254/40960 [00:24<01:55, 301.72batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6297/40960 [00:24<02:05, 275.71batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6297/40960 [00:24<02:05, 275.71batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6331/40960 [00:24<02:22, 243.51batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6331/40960 [00:24<02:22, 243.51batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6392/40960 [00:25<02:12, 260.72batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6392/40960 [00:25<02:12, 260.72batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6454/40960 [00:25<02:05, 275.31batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6454/40960 [00:25<02:05, 275.31batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6513/40960 [00:25<02:03, 279.77batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6513/40960 [00:25<02:03, 279.77batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6567/40960 [00:25<02:04, 275.22batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6567/40960 [00:25<02:04, 275.22batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6622/40960 [00:25<02:05, 274.19batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6622/40960 [00:25<02:05, 274.19batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6677/40960 [00:26<02:05, 273.97batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6677/40960 [00:26<02:05, 273.97batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6726/40960 [00:26<02:09, 263.95batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6726/40960 [00:26<02:09, 263.95batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6779/40960 [00:26<02:09, 264.05batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6779/40960 [00:26<02:09, 264.05batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6830/40960 [00:26<02:11, 260.44batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6830/40960 [00:26<02:11, 260.44batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6887/40960 [00:26<02:07, 267.30batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6887/40960 [00:26<02:07, 267.30batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6944/40960 [00:27<02:05, 271.69batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6944/40960 [00:27<02:05, 271.69batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7001/40960 [00:27<02:03, 274.56batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7001/40960 [00:27<02:03, 274.56batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7057/40960 [00:27<02:03, 274.83batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7057/40960 [00:27<02:03, 274.83batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7106/40960 [00:27<02:07, 265.69batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7106/40960 [00:27<02:07, 265.69batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7160/40960 [00:27<02:06, 266.40batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7160/40960 [00:27<02:06, 266.40batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7216/40960 [00:28<02:05, 269.70batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7216/40960 [00:28<02:05, 269.70batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7273/40960 [00:28<02:03, 273.32batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7273/40960 [00:28<02:03, 273.32batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7325/40960 [00:28<02:05, 268.83batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7325/40960 [00:28<02:05, 268.83batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7375/40960 [00:28<02:08, 260.81batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7375/40960 [00:28<02:08, 260.81batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7435/40960 [00:28<02:03, 271.54batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7435/40960 [00:28<02:03, 271.54batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7496/40960 [00:29<01:58, 281.21batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7496/40960 [00:29<01:58, 281.21batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7551/40960 [00:29<02:00, 278.24batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7551/40960 [00:29<02:00, 278.24batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7612/40960 [00:29<01:56, 285.79batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7612/40960 [00:29<01:56, 285.79batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7657/40960 [00:29<02:04, 266.96batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7657/40960 [00:29<02:04, 266.96batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7695/40960 [00:29<02:17, 242.11batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7695/40960 [00:29<02:17, 242.11batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7753/40960 [00:30<02:09, 255.94batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7753/40960 [00:30<02:09, 255.94batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7795/40960 [00:30<02:17, 240.52batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7795/40960 [00:30<02:17, 240.52batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7843/40960 [00:30<02:18, 238.51batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7843/40960 [00:30<02:18, 238.51batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7900/40960 [00:30<02:11, 251.66batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7900/40960 [00:30<02:11, 251.66batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7963/40960 [00:30<02:02, 269.48batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|▏| 7963/40960 [00:30<02:02, 269.48batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8025/40960 [00:31<01:57, 280.49batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8025/40960 [00:31<01:57, 280.49batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8084/40960 [00:31<01:55, 284.52batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8084/40960 [00:31<01:55, 284.52batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8147/40960 [00:31<01:51, 293.53batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8147/40960 [00:31<01:51, 293.53batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8207/40960 [00:31<01:51, 294.23batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8207/40960 [00:31<01:51, 294.23batches/s, l2_loss: 0.0302 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8265/40960 [00:31<01:51, 292.65batches/s, l2_loss: 0.0302 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8265/40960 [00:31<01:51, 292.65batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8323/40960 [00:32<01:52, 290.93batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8323/40960 [00:32<01:52, 290.93batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8382/40960 [00:32<01:51, 291.24batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8382/40960 [00:32<01:51, 291.24batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8438/40960 [00:32<01:53, 287.35batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8438/40960 [00:32<01:53, 287.35batches/s, l2_loss: 0.0510 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8493/40960 [00:32<01:54, 283.60batches/s, l2_loss: 0.0510 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8493/40960 [00:32<01:54, 283.60batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8551/40960 [00:32<01:53, 284.82batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8551/40960 [00:32<01:53, 284.82batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8608/40960 [00:33<01:53, 284.18batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8608/40960 [00:33<01:53, 284.18batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8662/40960 [00:33<01:56, 278.29batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8662/40960 [00:33<01:56, 278.29batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8713/40960 [00:33<01:59, 269.78batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8713/40960 [00:33<01:59, 269.78batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8765/40960 [00:33<02:00, 266.43batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8765/40960 [00:33<02:00, 266.43batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8818/40960 [00:33<02:01, 265.29batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8818/40960 [00:33<02:01, 265.29batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8866/40960 [00:34<02:05, 256.62batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8866/40960 [00:34<02:05, 256.62batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8920/40960 [00:34<02:03, 260.22batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8920/40960 [00:34<02:03, 260.22batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8980/40960 [00:34<01:57, 271.62batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8980/40960 [00:34<01:57, 271.62batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9036/40960 [00:34<01:56, 273.28batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9036/40960 [00:34<01:56, 273.28batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9096/40960 [00:34<01:53, 280.34batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9096/40960 [00:34<01:53, 280.34batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9146/40960 [00:35<01:57, 271.15batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9146/40960 [00:35<01:57, 271.15batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9202/40960 [00:35<01:56, 273.48batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9202/40960 [00:35<01:56, 273.48batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9262/40960 [00:35<01:52, 280.61batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9262/40960 [00:35<01:52, 280.61batches/s, l2_loss: 0.0510 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9315/40960 [00:35<01:55, 274.95batches/s, l2_loss: 0.0510 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9315/40960 [00:35<01:55, 274.95batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9373/40960 [00:35<01:53, 278.20batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9373/40960 [00:35<01:53, 278.20batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9432/40960 [00:36<01:51, 283.09batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9432/40960 [00:36<01:51, 283.09batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9489/40960 [00:36<01:51, 282.89batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9489/40960 [00:36<01:51, 282.89batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9548/40960 [00:36<01:50, 285.47batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9548/40960 [00:36<01:50, 285.47batches/s, l2_loss: 0.0506 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9608/40960 [00:36<01:48, 288.50batches/s, l2_loss: 0.0506 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9608/40960 [00:36<01:48, 288.50batches/s, l2_loss: 0.0510 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9664/40960 [00:36<01:49, 285.63batches/s, l2_loss: 0.0510 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9664/40960 [00:36<01:49, 285.63batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9715/40960 [00:37<01:53, 275.41batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9715/40960 [00:37<01:53, 275.41batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9753/40960 [00:37<02:05, 249.13batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9753/40960 [00:37<02:05, 249.13batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9809/40960 [00:37<02:00, 257.64batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9809/40960 [00:37<02:00, 257.64batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9866/40960 [00:37<01:57, 265.57batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9866/40960 [00:37<01:57, 265.57batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9926/40960 [00:37<01:52, 274.92batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9926/40960 [00:37<01:52, 274.92batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9981/40960 [00:38<01:52, 274.58batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9981/40960 [00:38<01:52, 274.58batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10040/40960 [00:38<01:50, 279.16batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  25%|▏| 10040/40960 [00:38<01:50, 279.16batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  25%|▏| 10100/40960 [00:38<01:48, 284.50batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  25%|▏| 10100/40960 [00:38<01:48, 284.50batches/s, l2_loss: 0.0512 - round_los\u001b[A\n",
      "Training:  25%|▏| 10155/40960 [00:38<01:49, 280.27batches/s, l2_loss: 0.0512 - round_los\u001b[A\n",
      "Training:  25%|▏| 10155/40960 [00:38<01:49, 280.27batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  25%|▏| 10211/40960 [00:38<01:50, 279.33batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  25%|▏| 10211/40960 [00:38<01:50, 279.33batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  25%|▎| 10262/40960 [00:39<01:53, 271.40batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  25%|▎| 10262/40960 [00:39<01:53, 271.40batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  25%|▎| 10316/40960 [00:39<01:53, 270.89batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  25%|▎| 10316/40960 [00:39<01:53, 270.89batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  25%|▎| 10371/40960 [00:39<01:52, 271.72batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  25%|▎| 10371/40960 [00:39<01:52, 271.72batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  25%|▎| 10425/40960 [00:39<01:53, 270.16batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  25%|▎| 10425/40960 [00:39<01:53, 270.16batches/s, l2_loss: 0.0509 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10484/40960 [00:39<01:50, 276.41batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  26%|▎| 10484/40960 [00:39<01:50, 276.41batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  26%|▎| 10542/40960 [00:40<01:48, 279.37batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  26%|▎| 10542/40960 [00:40<01:48, 279.37batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  26%|▎| 10599/40960 [00:40<01:48, 280.29batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  26%|▎| 10599/40960 [00:40<01:48, 280.29batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  26%|▎| 10654/40960 [00:40<01:49, 277.36batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  26%|▎| 10654/40960 [00:40<01:49, 277.36batches/s, l2_loss: 0.0512 - round_los\u001b[A\n",
      "Training:  26%|▎| 10712/40960 [00:40<01:47, 281.06batches/s, l2_loss: 0.0512 - round_los\u001b[A\n",
      "Training:  26%|▎| 10712/40960 [00:40<01:47, 281.06batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  26%|▎| 10764/40960 [00:40<01:50, 274.34batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  26%|▎| 10764/40960 [00:40<01:50, 274.34batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  26%|▎| 10822/40960 [00:41<01:48, 278.69batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  26%|▎| 10822/40960 [00:41<01:48, 278.69batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  27%|▎| 10881/40960 [00:41<01:46, 282.61batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  27%|▎| 10881/40960 [00:41<01:46, 282.61batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  27%|▎| 10936/40960 [00:41<01:47, 278.97batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  27%|▎| 10936/40960 [00:41<01:47, 278.97batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  27%|▎| 10992/40960 [00:41<01:48, 276.66batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  27%|▎| 10992/40960 [00:41<01:48, 276.66batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  27%|▎| 11047/40960 [00:41<01:48, 275.00batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  27%|▎| 11047/40960 [00:41<01:48, 275.00batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  27%|▎| 11103/40960 [00:42<01:48, 276.21batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  27%|▎| 11103/40960 [00:42<01:48, 276.21batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  27%|▎| 11155/40960 [00:42<01:50, 270.06batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  27%|▎| 11155/40960 [00:42<01:50, 270.06batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  27%|▎| 11201/40960 [00:42<01:55, 256.66batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  27%|▎| 11201/40960 [00:42<01:55, 256.66batches/s, l2_loss: 0.0513 - round_los\u001b[A\n",
      "Training:  27%|▎| 11259/40960 [00:42<01:51, 266.28batches/s, l2_loss: 0.0513 - round_los\u001b[A\n",
      "Training:  27%|▎| 11259/40960 [00:42<01:51, 266.28batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  28%|▎| 11318/40960 [00:42<01:48, 274.13batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  28%|▎| 11318/40960 [00:42<01:48, 274.13batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  28%|▎| 11376/40960 [00:43<01:46, 277.46batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  28%|▎| 11376/40960 [00:43<01:46, 277.46batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  28%|▎| 11433/40960 [00:43<01:46, 278.08batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  28%|▎| 11433/40960 [00:43<01:46, 278.08batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  28%|▎| 11490/40960 [00:43<01:45, 279.28batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  28%|▎| 11490/40960 [00:43<01:45, 279.28batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  28%|▎| 11548/40960 [00:43<01:44, 281.70batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  28%|▎| 11548/40960 [00:43<01:44, 281.70batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:44<01:45, 278.38batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:44<01:45, 278.38batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  28%|▎| 11658/40960 [00:44<01:46, 276.40batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  28%|▎| 11658/40960 [00:44<01:46, 276.40batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  29%|▎| 11713/40960 [00:44<01:46, 274.76batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  29%|▎| 11713/40960 [00:44<01:46, 274.76batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  29%|▎| 11772/40960 [00:44<01:44, 279.45batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  29%|▎| 11772/40960 [00:44<01:44, 279.45batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  29%|▎| 11830/40960 [00:44<01:43, 282.47batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  29%|▎| 11830/40960 [00:44<01:43, 282.47batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  29%|▎| 11886/40960 [00:45<01:43, 280.15batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  29%|▎| 11886/40960 [00:45<01:43, 280.15batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  29%|▎| 11945/40960 [00:45<01:42, 283.87batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  29%|▎| 11945/40960 [00:45<01:42, 283.87batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  29%|▎| 12001/40960 [00:45<01:42, 282.22batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  29%|▎| 12001/40960 [00:45<01:42, 282.22batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  29%|▎| 12060/40960 [00:45<01:41, 285.35batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  29%|▎| 12060/40960 [00:45<01:41, 285.35batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  30%|▎| 12111/40960 [00:45<01:44, 275.91batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  30%|▎| 12111/40960 [00:45<01:44, 275.91batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  30%|▎| 12168/40960 [00:46<01:43, 277.83batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  30%|▎| 12168/40960 [00:46<01:43, 277.83batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  30%|▎| 12227/40960 [00:46<01:41, 282.02batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  30%|▎| 12227/40960 [00:46<01:41, 282.02batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  30%|▎| 12286/40960 [00:46<01:40, 285.33batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  30%|▎| 12286/40960 [00:46<01:40, 285.33batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  30%|▎| 12342/40960 [00:46<01:41, 283.26batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  30%|▎| 12342/40960 [00:46<01:41, 283.26batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  30%|▎| 12399/40960 [00:46<01:40, 283.17batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  30%|▎| 12399/40960 [00:46<01:40, 283.17batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  30%|▎| 12458/40960 [00:47<01:39, 286.49batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  30%|▎| 12458/40960 [00:47<01:39, 286.49batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12514/40960 [00:47<01:40, 282.53batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12514/40960 [00:47<01:40, 282.53batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12567/40960 [00:47<01:42, 275.72batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12567/40960 [00:47<01:42, 275.72batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12626/40960 [00:47<01:41, 280.45batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12626/40960 [00:47<01:41, 280.45batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  31%|▎| 12684/40960 [00:47<01:40, 282.38batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  31%|▎| 12684/40960 [00:47<01:40, 282.38batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12739/40960 [00:48<01:40, 279.46batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12739/40960 [00:48<01:40, 279.46batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  31%|▎| 12796/40960 [00:48<01:40, 280.45batches/s, l2_loss: 0.0511 - round_los\u001b[A\n",
      "Training:  31%|▎| 12796/40960 [00:48<01:40, 280.45batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12854/40960 [00:48<01:39, 282.01batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  31%|▎| 12854/40960 [00:48<01:39, 282.01batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  32%|▎| 12911/40960 [00:48<01:39, 281.41batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  32%|▎| 12911/40960 [00:48<01:39, 281.41batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  32%|▎| 12968/40960 [00:48<01:39, 280.55batches/s, l2_loss: 0.0509 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 12968/40960 [00:48<01:39, 280.55batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  32%|▎| 13024/40960 [00:49<01:39, 279.85batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  32%|▎| 13024/40960 [00:49<01:39, 279.85batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  32%|▎| 13082/40960 [00:49<01:38, 282.68batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  32%|▎| 13082/40960 [00:49<01:38, 282.68batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  32%|▎| 13137/40960 [00:49<01:39, 279.25batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  32%|▎| 13137/40960 [00:49<01:39, 279.25batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  32%|▎| 13190/40960 [00:49<01:41, 273.83batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  32%|▎| 13190/40960 [00:49<01:41, 273.83batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  32%|▎| 13238/40960 [00:49<01:45, 263.63batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  32%|▎| 13238/40960 [00:49<01:45, 263.63batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  32%|▎| 13296/40960 [00:50<01:42, 270.75batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  32%|▎| 13296/40960 [00:50<01:42, 270.75batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  33%|▎| 13349/40960 [00:50<01:42, 268.54batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  33%|▎| 13349/40960 [00:50<01:42, 268.54batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  33%|▎| 13403/40960 [00:50<01:42, 268.12batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  33%|▎| 13403/40960 [00:50<01:42, 268.12batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  33%|▎| 13459/40960 [00:50<01:41, 271.04batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  33%|▎| 13459/40960 [00:50<01:41, 271.04batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  33%|▎| 13516/40960 [00:50<01:40, 274.38batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  33%|▎| 13516/40960 [00:50<01:40, 274.38batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  33%|▎| 13572/40960 [00:51<01:39, 275.62batches/s, l2_loss: 0.0510 - round_los\u001b[A\n",
      "Training:  33%|▎| 13572/40960 [00:51<01:39, 275.62batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  33%|▎| 13622/40960 [00:51<01:42, 266.73batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  33%|▎| 13622/40960 [00:51<01:42, 266.73batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  33%|▎| 13677/40960 [00:51<01:41, 269.09batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  33%|▎| 13677/40960 [00:51<01:41, 269.09batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 13728/40960 [00:51<01:43, 263.56batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 13728/40960 [00:51<01:43, 263.56batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  34%|▎| 13781/40960 [00:51<01:43, 263.42batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  34%|▎| 13781/40960 [00:51<01:43, 263.42batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 13836/40960 [00:52<01:41, 266.40batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 13836/40960 [00:52<01:41, 266.40batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  34%|▎| 13891/40960 [00:52<01:41, 267.56batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  34%|▎| 13891/40960 [00:52<01:41, 267.56batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  34%|▎| 13945/40960 [00:52<01:40, 267.80batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  34%|▎| 13945/40960 [00:52<01:40, 267.80batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 14002/40960 [00:52<01:38, 272.51batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 14002/40960 [00:52<01:38, 272.51batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 14059/40960 [00:52<01:37, 275.39batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 14059/40960 [00:52<01:37, 275.39batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 14115/40960 [00:53<01:37, 276.03batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  34%|▎| 14115/40960 [00:53<01:37, 276.03batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  35%|▎| 14172/40960 [00:53<01:36, 278.66batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  35%|▎| 14172/40960 [00:53<01:36, 278.66batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  35%|▎| 14232/40960 [00:53<01:34, 284.17batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  35%|▎| 14232/40960 [00:53<01:34, 284.17batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  35%|▎| 14289/40960 [00:53<01:34, 283.59batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  35%|▎| 14289/40960 [00:53<01:34, 283.59batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  35%|▎| 14349/40960 [00:53<01:32, 288.34batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  35%|▎| 14349/40960 [00:53<01:32, 288.34batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  35%|▎| 14407/40960 [00:54<01:32, 287.62batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  35%|▎| 14407/40960 [00:54<01:32, 287.62batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  35%|▎| 14462/40960 [00:54<01:33, 281.94batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  35%|▎| 14462/40960 [00:54<01:33, 281.94batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  35%|▎| 14520/40960 [00:54<01:33, 283.42batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  35%|▎| 14520/40960 [00:54<01:33, 283.42batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  36%|▎| 14575/40960 [00:54<01:34, 280.61batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  36%|▎| 14575/40960 [00:54<01:34, 280.61batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  36%|▎| 14632/40960 [00:54<01:33, 281.48batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  36%|▎| 14632/40960 [00:54<01:33, 281.48batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  36%|▎| 14691/40960 [00:55<01:32, 284.94batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  36%|▎| 14691/40960 [00:55<01:32, 284.94batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  36%|▎| 14748/40960 [00:55<01:32, 283.50batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  36%|▎| 14748/40960 [00:55<01:32, 283.50batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  36%|▎| 14805/40960 [00:55<01:32, 283.08batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  36%|▎| 14805/40960 [00:55<01:32, 283.08batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  36%|▎| 14865/40960 [00:55<01:30, 286.98batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  36%|▎| 14865/40960 [00:55<01:30, 286.98batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  36%|▎| 14921/40960 [00:55<01:31, 283.23batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  36%|▎| 14921/40960 [00:55<01:31, 283.23batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  37%|▎| 14973/40960 [00:56<01:34, 274.86batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  37%|▎| 14973/40960 [00:56<01:34, 274.86batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15023/40960 [00:56<01:37, 266.36batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15023/40960 [00:56<01:37, 266.36batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15077/40960 [00:56<01:37, 265.98batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15077/40960 [00:56<01:37, 265.98batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15123/40960 [00:56<01:41, 254.65batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15123/40960 [00:56<01:41, 254.65batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15181/40960 [00:56<01:37, 264.36batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15181/40960 [00:56<01:37, 264.36batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15227/40960 [00:57<01:41, 253.88batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15227/40960 [00:57<01:41, 253.88batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15284/40960 [00:57<01:38, 261.93batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  37%|▎| 15284/40960 [00:57<01:38, 261.93batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  37%|▎| 15338/40960 [00:57<01:37, 263.19batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  37%|▎| 15338/40960 [00:57<01:37, 263.19batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  38%|▍| 15393/40960 [00:57<01:36, 265.67batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  38%|▍| 15393/40960 [00:57<01:36, 265.67batches/s, l2_loss: 0.0508 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|▍| 15448/40960 [00:57<01:35, 268.24batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15448/40960 [00:57<01:35, 268.24batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15500/40960 [00:58<01:36, 264.54batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15500/40960 [00:58<01:36, 264.54batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15551/40960 [00:58<01:37, 260.76batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15551/40960 [00:58<01:37, 260.76batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15594/40960 [00:58<01:42, 247.08batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15594/40960 [00:58<01:42, 247.08batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15646/40960 [00:58<01:41, 250.36batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15646/40960 [00:58<01:41, 250.36batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  38%|▍| 15703/40960 [00:58<01:37, 259.61batches/s, l2_loss: 0.0509 - round_los\u001b[A\n",
      "Training:  38%|▍| 15703/40960 [00:58<01:37, 259.61batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15760/40960 [00:59<01:34, 267.09batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  38%|▍| 15760/40960 [00:59<01:34, 267.09batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 15802/40960 [00:59<01:41, 246.71batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 15802/40960 [00:59<01:41, 246.71batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 15853/40960 [00:59<01:41, 248.40batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 15853/40960 [00:59<01:41, 248.40batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 15901/40960 [00:59<01:42, 245.08batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 15901/40960 [00:59<01:42, 245.08batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 15950/40960 [00:59<01:42, 244.50batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 15950/40960 [00:59<01:42, 244.50batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  39%|▍| 16002/40960 [01:00<01:40, 248.20batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  39%|▍| 16002/40960 [01:00<01:40, 248.20batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 16061/40960 [01:00<01:35, 262.05batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  39%|▍| 16061/40960 [01:00<01:35, 262.05batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  39%|▍| 16120/40960 [01:00<01:31, 270.72batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  39%|▍| 16120/40960 [01:00<01:31, 270.72batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  39%|▍| 16173/40960 [01:00<01:32, 267.90batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  39%|▍| 16173/40960 [01:00<01:32, 267.90batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  40%|▍| 16227/40960 [01:00<01:32, 268.51batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  40%|▍| 16227/40960 [01:00<01:32, 268.51batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  40%|▍| 16278/40960 [01:01<01:33, 263.00batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  40%|▍| 16278/40960 [01:01<01:33, 263.00batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  40%|▍| 16338/40960 [01:01<01:30, 273.31batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  40%|▍| 16338/40960 [01:01<01:30, 273.31batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  40%|▍| 16395/40960 [01:01<01:29, 275.25batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  40%|▍| 16395/40960 [01:01<01:29, 275.25batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  40%|▍| 16446/40960 [01:01<01:31, 268.66batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  40%|▍| 16446/40960 [01:01<01:31, 268.66batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  40%|▍| 16500/40960 [01:01<01:31, 268.62batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  40%|▍| 16500/40960 [01:02<01:31, 268.62batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  40%|▍| 16550/40960 [01:02<01:32, 262.50batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  40%|▍| 16550/40960 [01:02<01:32, 262.50batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  41%|▍| 16605/40960 [01:02<01:31, 265.05batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  41%|▍| 16605/40960 [01:02<01:31, 265.05batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16664/40960 [01:02<01:28, 273.31batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16664/40960 [01:02<01:28, 273.31batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  41%|▍| 16717/40960 [01:02<01:29, 270.49batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  41%|▍| 16717/40960 [01:02<01:29, 270.49batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16772/40960 [01:03<01:29, 270.86batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16772/40960 [01:03<01:29, 270.86batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16828/40960 [01:03<01:28, 273.59batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16828/40960 [01:03<01:28, 273.59batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16878/40960 [01:03<01:30, 266.24batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16878/40960 [01:03<01:30, 266.24batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16931/40960 [01:03<01:30, 265.17batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16931/40960 [01:03<01:30, 265.17batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16980/40960 [01:03<01:32, 257.98batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  41%|▍| 16980/40960 [01:03<01:32, 257.98batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17031/40960 [01:04<01:33, 256.30batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17031/40960 [01:04<01:33, 256.30batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  42%|▍| 17087/40960 [01:04<01:30, 262.67batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  42%|▍| 17087/40960 [01:04<01:30, 262.67batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  42%|▍| 17144/40960 [01:04<01:28, 268.98batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  42%|▍| 17144/40960 [01:04<01:28, 268.98batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17199/40960 [01:04<01:27, 270.27batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17199/40960 [01:04<01:27, 270.27batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17247/40960 [01:04<01:31, 260.45batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17247/40960 [01:04<01:31, 260.45batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17301/40960 [01:05<01:30, 262.13batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17301/40960 [01:05<01:30, 262.13batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17356/40960 [01:05<01:29, 264.46batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  42%|▍| 17356/40960 [01:05<01:29, 264.46batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17413/40960 [01:05<01:27, 269.96batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17413/40960 [01:05<01:27, 269.96batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17465/40960 [01:05<01:28, 266.68batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17465/40960 [01:05<01:28, 266.68batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17523/40960 [01:05<01:25, 273.04batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17523/40960 [01:05<01:25, 273.04batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17582/40960 [01:06<01:23, 279.23batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17582/40960 [01:06<01:23, 279.23batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17634/40960 [01:06<01:25, 272.19batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17634/40960 [01:06<01:25, 272.19batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17681/40960 [01:06<01:30, 257.84batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17681/40960 [01:06<01:30, 257.84batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17733/40960 [01:06<01:30, 257.64batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17733/40960 [01:06<01:30, 257.64batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  43%|▍| 17791/40960 [01:06<01:27, 266.26batches/s, l2_loss: 0.0507 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17791/40960 [01:06<01:27, 266.26batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 17841/40960 [01:07<01:28, 260.31batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 17841/40960 [01:07<01:28, 260.31batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 17891/40960 [01:07<01:29, 257.17batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 17891/40960 [01:07<01:29, 257.17batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 17945/40960 [01:07<01:28, 260.92batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 17945/40960 [01:07<01:28, 260.92batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 17998/40960 [01:07<01:27, 261.52batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 17998/40960 [01:07<01:27, 261.52batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 18043/40960 [01:07<01:31, 249.63batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 18043/40960 [01:07<01:31, 249.63batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 18091/40960 [01:08<01:32, 246.00batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 18091/40960 [01:08<01:32, 246.00batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 18148/40960 [01:08<01:28, 257.55batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 18148/40960 [01:08<01:28, 257.55batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 18202/40960 [01:08<01:27, 260.24batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  44%|▍| 18202/40960 [01:08<01:27, 260.24batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18258/40960 [01:08<01:25, 266.08batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18258/40960 [01:08<01:25, 266.08batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18307/40960 [01:08<01:27, 257.95batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18307/40960 [01:08<01:27, 257.95batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18359/40960 [01:09<01:28, 256.16batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18359/40960 [01:09<01:28, 256.16batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18407/40960 [01:09<01:29, 251.14batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18407/40960 [01:09<01:29, 251.14batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18466/40960 [01:09<01:25, 263.55batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18466/40960 [01:09<01:25, 263.55batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  45%|▍| 18525/40960 [01:09<01:22, 272.03batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  45%|▍| 18525/40960 [01:09<01:22, 272.03batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18584/40960 [01:09<01:20, 278.58batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  45%|▍| 18584/40960 [01:09<01:20, 278.58batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  45%|▍| 18635/40960 [01:10<01:22, 270.36batches/s, l2_loss: 0.0508 - round_los\u001b[A\n",
      "Training:  45%|▍| 18635/40960 [01:10<01:22, 270.36batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  46%|▍| 18691/40960 [01:10<01:21, 272.01batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  46%|▍| 18691/40960 [01:10<01:21, 272.01batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  46%|▍| 18747/40960 [01:10<01:21, 273.11batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  46%|▍| 18747/40960 [01:10<01:21, 273.11batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  46%|▍| 18803/40960 [01:10<01:20, 273.97batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  46%|▍| 18803/40960 [01:10<01:20, 273.97batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  46%|▍| 18859/40960 [01:10<01:20, 274.62batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  46%|▍| 18859/40960 [01:10<01:20, 274.62batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  46%|▍| 18914/40960 [01:11<01:20, 273.67batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  46%|▍| 18914/40960 [01:11<01:20, 273.67batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  46%|▍| 18973/40960 [01:11<01:18, 278.92batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  46%|▍| 18973/40960 [01:11<01:18, 278.92batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  46%|▍| 19032/40960 [01:11<01:17, 283.37batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  46%|▍| 19032/40960 [01:11<01:17, 283.37batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  47%|▍| 19088/40960 [01:11<01:17, 282.21batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  47%|▍| 19088/40960 [01:11<01:17, 282.21batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  47%|▍| 19147/40960 [01:11<01:16, 285.43batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  47%|▍| 19147/40960 [01:11<01:16, 285.43batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  47%|▍| 19206/40960 [01:12<01:15, 286.96batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  47%|▍| 19206/40960 [01:12<01:15, 286.96batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  47%|▍| 19259/40960 [01:12<01:17, 280.00batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  47%|▍| 19259/40960 [01:12<01:17, 280.00batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  47%|▍| 19313/40960 [01:12<01:18, 276.85batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  47%|▍| 19313/40960 [01:12<01:18, 276.85batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  47%|▍| 19366/40960 [01:12<01:19, 272.94batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  47%|▍| 19366/40960 [01:12<01:19, 272.94batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  47%|▍| 19419/40960 [01:12<01:19, 270.11batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  47%|▍| 19419/40960 [01:12<01:19, 270.11batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  48%|▍| 19465/40960 [01:13<01:23, 257.04batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  48%|▍| 19465/40960 [01:13<01:23, 257.04batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19514/40960 [01:13<01:24, 252.89batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19514/40960 [01:13<01:24, 252.89batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19565/40960 [01:13<01:25, 251.47batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19565/40960 [01:13<01:25, 251.47batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19620/40960 [01:13<01:22, 258.46batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19620/40960 [01:13<01:22, 258.46batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19677/40960 [01:13<01:20, 265.93batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19677/40960 [01:13<01:20, 265.93batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19726/40960 [01:14<01:22, 258.34batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19726/40960 [01:14<01:22, 258.34batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19782/40960 [01:14<01:20, 263.75batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19782/40960 [01:14<01:20, 263.75batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19843/40960 [01:14<01:16, 275.04batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  48%|▍| 19843/40960 [01:14<01:16, 275.04batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 19903/40960 [01:14<01:14, 282.39batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 19903/40960 [01:14<01:14, 282.39batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 19962/40960 [01:14<01:13, 284.82batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 19962/40960 [01:14<01:13, 284.82batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 20020/40960 [01:15<01:13, 285.89batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 20020/40960 [01:15<01:13, 285.89batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 20067/40960 [01:15<01:17, 270.70batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 20067/40960 [01:15<01:17, 270.70batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 20124/40960 [01:15<01:16, 273.60batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 20124/40960 [01:15<01:16, 273.60batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 20178/40960 [01:15<01:16, 272.08batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  49%|▍| 20178/40960 [01:15<01:16, 272.08batches/s, l2_loss: 0.0507 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|▍| 20234/40960 [01:15<01:15, 274.17batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  49%|▍| 20234/40960 [01:15<01:15, 274.17batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▍| 20292/40960 [01:16<01:14, 278.54batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▍| 20292/40960 [01:16<01:14, 278.54batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▍| 20351/40960 [01:16<01:12, 283.36batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▍| 20351/40960 [01:16<01:12, 283.36batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▍| 20408/40960 [01:16<01:12, 282.87batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▍| 20408/40960 [01:16<01:12, 282.87batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▍| 20449/40960 [01:16<01:19, 258.55batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▍| 20449/40960 [01:16<01:19, 258.55batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▌| 20495/40960 [01:16<01:21, 249.84batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▌| 20495/40960 [01:16<01:21, 249.84batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▌| 20554/40960 [01:17<01:17, 262.74batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▌| 20554/40960 [01:17<01:17, 262.74batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▌| 20612/40960 [01:17<01:15, 270.11batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▌| 20612/40960 [01:17<01:15, 270.11batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▌| 20662/40960 [01:17<01:17, 263.06batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  50%|▌| 20662/40960 [01:17<01:17, 263.06batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  51%|▌| 20698/40960 [01:17<01:25, 237.35batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  51%|▌| 20698/40960 [01:17<01:25, 237.35batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 20753/40960 [01:17<01:21, 247.50batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 20753/40960 [01:17<01:21, 247.50batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 20812/40960 [01:18<01:17, 260.76batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 20812/40960 [01:18<01:17, 260.76batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 20871/40960 [01:18<01:14, 270.64batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 20871/40960 [01:18<01:14, 270.64batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 20926/40960 [01:18<01:13, 271.31batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 20926/40960 [01:18<01:13, 271.31batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  51%|▌| 20985/40960 [01:18<01:11, 277.62batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  51%|▌| 20985/40960 [01:18<01:11, 277.62batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 21040/40960 [01:18<01:11, 276.78batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 21040/40960 [01:18<01:11, 276.78batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 21087/40960 [01:19<01:15, 263.90batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  51%|▌| 21087/40960 [01:19<01:15, 263.90batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21140/40960 [01:19<01:15, 262.68batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21140/40960 [01:19<01:15, 262.68batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21192/40960 [01:19<01:15, 260.78batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21192/40960 [01:19<01:15, 260.78batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21252/40960 [01:19<01:12, 271.23batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21252/40960 [01:19<01:12, 271.23batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21307/40960 [01:19<01:12, 271.90batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21307/40960 [01:19<01:12, 271.90batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21360/40960 [01:20<01:12, 268.68batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21360/40960 [01:20<01:12, 268.68batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21417/40960 [01:20<01:11, 273.42batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21417/40960 [01:20<01:11, 273.42batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21475/40960 [01:20<01:10, 277.34batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  52%|▌| 21475/40960 [01:20<01:10, 277.34batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21533/40960 [01:20<01:09, 280.49batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21533/40960 [01:20<01:09, 280.49batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21589/40960 [01:20<01:09, 278.52batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21589/40960 [01:20<01:09, 278.52batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21639/40960 [01:21<01:11, 270.00batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21639/40960 [01:21<01:11, 270.00batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21688/40960 [01:21<01:13, 260.90batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21688/40960 [01:21<01:13, 260.90batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21744/40960 [01:21<01:12, 265.16batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21744/40960 [01:21<01:12, 265.16batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  53%|▌| 21803/40960 [01:21<01:10, 273.33batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  53%|▌| 21803/40960 [01:21<01:10, 273.33batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21858/40960 [01:21<01:09, 273.45batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  53%|▌| 21858/40960 [01:21<01:09, 273.45batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  54%|▌| 21917/40960 [01:22<01:08, 278.60batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  54%|▌| 21917/40960 [01:22<01:08, 278.60batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 21978/40960 [01:22<01:06, 286.14batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 21978/40960 [01:22<01:06, 286.14batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 22031/40960 [01:22<01:07, 279.07batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 22031/40960 [01:22<01:07, 279.07batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  54%|▌| 22087/40960 [01:22<01:07, 278.15batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  54%|▌| 22087/40960 [01:22<01:07, 278.15batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  54%|▌| 22138/40960 [01:23<01:09, 270.44batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  54%|▌| 22138/40960 [01:23<01:09, 270.44batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 22192/40960 [01:23<01:10, 267.12batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 22192/40960 [01:23<01:10, 267.12batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 22248/40960 [01:23<01:09, 270.84batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 22248/40960 [01:23<01:09, 270.84batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 22307/40960 [01:23<01:07, 277.34batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  54%|▌| 22307/40960 [01:23<01:07, 277.34batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  55%|▌| 22367/40960 [01:23<01:05, 282.77batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  55%|▌| 22367/40960 [01:23<01:05, 282.77batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  55%|▌| 22425/40960 [01:24<01:05, 284.45batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  55%|▌| 22425/40960 [01:24<01:05, 284.45batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  55%|▌| 22477/40960 [01:24<01:06, 276.57batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  55%|▌| 22477/40960 [01:24<01:06, 276.57batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  55%|▌| 22532/40960 [01:24<01:07, 274.95batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  55%|▌| 22532/40960 [01:24<01:07, 274.95batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  55%|▌| 22582/40960 [01:24<01:08, 266.50batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  55%|▌| 22582/40960 [01:24<01:08, 266.50batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  55%|▌| 22637/40960 [01:24<01:08, 268.56batches/s, l2_loss: 0.0506 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22637/40960 [01:24<01:08, 268.56batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  55%|▌| 22694/40960 [01:25<01:06, 273.04batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  55%|▌| 22694/40960 [01:25<01:06, 273.04batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22745/40960 [01:25<01:08, 266.17batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22745/40960 [01:25<01:08, 266.17batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22795/40960 [01:25<01:09, 260.31batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22795/40960 [01:25<01:09, 260.31batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22850/40960 [01:25<01:08, 263.79batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22850/40960 [01:25<01:08, 263.79batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22907/40960 [01:25<01:07, 268.93batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22907/40960 [01:25<01:07, 268.93batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22965/40960 [01:26<01:05, 274.77batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 22965/40960 [01:26<01:05, 274.77batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 23021/40960 [01:26<01:04, 275.99batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 23021/40960 [01:26<01:04, 275.99batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 23078/40960 [01:26<01:04, 278.60batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 23078/40960 [01:26<01:04, 278.60batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 23136/40960 [01:26<01:03, 280.89batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  56%|▌| 23136/40960 [01:26<01:03, 280.89batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23190/40960 [01:26<01:04, 276.89batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23190/40960 [01:26<01:04, 276.89batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  57%|▌| 23246/40960 [01:27<01:04, 276.53batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  57%|▌| 23246/40960 [01:27<01:04, 276.53batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  57%|▌| 23300/40960 [01:27<01:04, 273.59batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  57%|▌| 23300/40960 [01:27<01:04, 273.59batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23355/40960 [01:27<01:04, 273.27batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23355/40960 [01:27<01:04, 273.27batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23412/40960 [01:27<01:03, 276.12batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23412/40960 [01:27<01:03, 276.12batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23466/40960 [01:27<01:04, 273.16batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23466/40960 [01:27<01:04, 273.16batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23517/40960 [01:28<01:05, 267.31batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  57%|▌| 23517/40960 [01:28<01:05, 267.31batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23574/40960 [01:28<01:03, 272.58batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23574/40960 [01:28<01:03, 272.58batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23624/40960 [01:28<01:05, 265.82batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23624/40960 [01:28<01:05, 265.82batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23683/40960 [01:28<01:03, 273.81batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23683/40960 [01:28<01:03, 273.81batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23739/40960 [01:28<01:02, 275.60batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23739/40960 [01:28<01:02, 275.60batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23795/40960 [01:29<01:02, 276.12batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23795/40960 [01:29<01:02, 276.12batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23850/40960 [01:29<01:02, 274.80batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23850/40960 [01:29<01:02, 274.80batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23909/40960 [01:29<01:00, 280.32batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23909/40960 [01:29<01:00, 280.32batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23961/40960 [01:29<01:02, 273.10batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  58%|▌| 23961/40960 [01:29<01:02, 273.10batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24017/40960 [01:29<01:01, 275.04batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24017/40960 [01:29<01:01, 275.04batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24074/40960 [01:30<01:00, 277.48batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24074/40960 [01:30<01:00, 277.48batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24126/40960 [01:30<01:02, 270.91batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24126/40960 [01:30<01:02, 270.91batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24183/40960 [01:30<01:01, 274.65batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24183/40960 [01:30<01:01, 274.65batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24238/40960 [01:30<01:01, 273.57batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24238/40960 [01:30<01:01, 273.57batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24296/40960 [01:30<00:59, 278.39batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24296/40960 [01:30<00:59, 278.39batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24356/40960 [01:31<00:58, 284.63batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  59%|▌| 24356/40960 [01:31<00:58, 284.63batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24418/40960 [01:31<00:56, 291.67batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24418/40960 [01:31<00:56, 291.67batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24470/40960 [01:31<00:58, 280.58batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24470/40960 [01:31<00:58, 280.58batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24510/40960 [01:31<01:04, 253.77batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24510/40960 [01:31<01:04, 253.77batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24565/40960 [01:31<01:03, 258.82batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24565/40960 [01:31<01:03, 258.82batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24622/40960 [01:32<01:01, 265.06batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24622/40960 [01:32<01:01, 265.06batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24680/40960 [01:32<00:59, 271.75batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24680/40960 [01:32<00:59, 271.75batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24741/40960 [01:32<00:57, 280.39batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  60%|▌| 24741/40960 [01:32<00:57, 280.39batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 24798/40960 [01:32<00:57, 280.83batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 24798/40960 [01:32<00:57, 280.83batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 24860/40960 [01:32<00:55, 288.30batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 24860/40960 [01:32<00:55, 288.30batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 24917/40960 [01:33<00:55, 286.49batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 24917/40960 [01:33<00:55, 286.49batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 24970/40960 [01:33<00:57, 278.96batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 24970/40960 [01:33<00:57, 278.96batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 25028/40960 [01:33<00:56, 280.76batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 25028/40960 [01:33<00:56, 280.76batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  61%|▌| 25086/40960 [01:33<00:56, 283.35batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  61%|▌| 25086/40960 [01:33<00:56, 283.35batches/s, l2_loss: 0.0505 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 25140/40960 [01:33<00:56, 279.07batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 25140/40960 [01:33<00:56, 279.07batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 25179/40960 [01:34<01:02, 252.75batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  61%|▌| 25179/40960 [01:34<01:02, 252.75batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25235/40960 [01:34<01:00, 260.55batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25235/40960 [01:34<01:00, 260.55batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25291/40960 [01:34<00:59, 265.52batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25291/40960 [01:34<00:59, 265.52batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25344/40960 [01:34<00:59, 263.45batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25344/40960 [01:34<00:59, 263.45batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25402/40960 [01:34<00:57, 270.70batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25402/40960 [01:34<00:57, 270.70batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25461/40960 [01:35<00:55, 276.81batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25461/40960 [01:35<00:55, 276.81batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25519/40960 [01:35<00:55, 279.72batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25519/40960 [01:35<00:55, 279.72batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25567/40960 [01:35<00:57, 266.22batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  62%|▌| 25567/40960 [01:35<00:57, 266.22batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  63%|▋| 25620/40960 [01:35<00:57, 265.74batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  63%|▋| 25620/40960 [01:35<00:57, 265.74batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  63%|▋| 25677/40960 [01:35<00:56, 271.05batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  63%|▋| 25677/40960 [01:35<00:56, 271.05batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  63%|▋| 25733/40960 [01:36<00:55, 272.24batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  63%|▋| 25733/40960 [01:36<00:55, 272.24batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  63%|▋| 25788/40960 [01:36<00:55, 272.53batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  63%|▋| 25788/40960 [01:36<00:55, 272.53batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  63%|▋| 25845/40960 [01:36<00:54, 275.53batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  63%|▋| 25845/40960 [01:36<00:54, 275.53batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  63%|▋| 25902/40960 [01:36<00:54, 277.20batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  63%|▋| 25902/40960 [01:36<00:54, 277.20batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  63%|▋| 25962/40960 [01:36<00:52, 283.43batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  63%|▋| 25962/40960 [01:36<00:52, 283.43batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26021/40960 [01:37<00:52, 285.49batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26021/40960 [01:37<00:52, 285.49batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  64%|▋| 26076/40960 [01:37<00:52, 281.81batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  64%|▋| 26076/40960 [01:37<00:52, 281.81batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26128/40960 [01:37<00:53, 275.07batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26128/40960 [01:37<00:53, 275.07batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26187/40960 [01:37<00:52, 280.66batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26187/40960 [01:37<00:52, 280.66batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26245/40960 [01:37<00:51, 283.09batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26245/40960 [01:37<00:51, 283.09batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26298/40960 [01:38<00:52, 276.89batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26298/40960 [01:38<00:52, 276.89batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26349/40960 [01:38<00:54, 270.25batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26349/40960 [01:38<00:54, 270.25batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26402/40960 [01:38<00:54, 267.70batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  64%|▋| 26402/40960 [01:38<00:54, 267.70batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  65%|▋| 26457/40960 [01:38<00:53, 268.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  65%|▋| 26457/40960 [01:38<00:53, 268.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  65%|▋| 26512/40960 [01:38<00:53, 268.86batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  65%|▋| 26512/40960 [01:38<00:53, 268.86batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  65%|▋| 26565/40960 [01:39<00:54, 266.57batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  65%|▋| 26565/40960 [01:39<00:54, 266.57batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  65%|▋| 26622/40960 [01:39<00:52, 271.00batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  65%|▋| 26622/40960 [01:39<00:52, 271.00batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  65%|▋| 26678/40960 [01:39<00:52, 272.86batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  65%|▋| 26678/40960 [01:39<00:52, 272.86batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  65%|▋| 26735/40960 [01:39<00:51, 275.10batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  65%|▋| 26735/40960 [01:39<00:51, 275.10batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  65%|▋| 26792/40960 [01:39<00:51, 277.11batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  65%|▋| 26792/40960 [01:39<00:51, 277.11batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 26846/40960 [01:40<00:51, 274.56batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 26846/40960 [01:40<00:51, 274.56batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 26882/40960 [01:40<00:57, 246.12batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 26882/40960 [01:40<00:57, 246.12batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 26933/40960 [01:40<00:56, 248.15batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 26933/40960 [01:40<00:56, 248.15batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 26984/40960 [01:40<00:56, 249.53batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 26984/40960 [01:40<00:56, 249.53batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  66%|▋| 27038/40960 [01:40<00:54, 254.73batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  66%|▋| 27038/40960 [01:40<00:54, 254.73batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 27092/40960 [01:41<00:53, 259.10batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 27092/40960 [01:41<00:53, 259.10batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 27147/40960 [01:41<00:52, 262.56batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 27147/40960 [01:41<00:52, 262.56batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 27201/40960 [01:41<00:52, 263.58batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  66%|▋| 27201/40960 [01:41<00:52, 263.58batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27255/40960 [01:41<00:51, 263.67batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27255/40960 [01:41<00:51, 263.67batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27306/40960 [01:42<00:52, 260.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27306/40960 [01:42<00:52, 260.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27363/40960 [01:42<00:50, 267.41batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27363/40960 [01:42<00:50, 267.41batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27413/40960 [01:42<00:51, 260.97batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27413/40960 [01:42<00:51, 260.97batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27456/40960 [01:42<00:54, 247.03batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27456/40960 [01:42<00:54, 247.03batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27490/40960 [01:42<01:00, 221.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|▋| 27490/40960 [01:42<01:00, 221.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27545/40960 [01:43<00:56, 236.75batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  67%|▋| 27545/40960 [01:43<00:56, 236.75batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  67%|▋| 27601/40960 [01:43<00:53, 249.40batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  67%|▋| 27601/40960 [01:43<00:53, 249.40batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  68%|▋| 27659/40960 [01:43<00:51, 260.49batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  68%|▋| 27659/40960 [01:43<00:51, 260.49batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27719/40960 [01:43<00:48, 271.45batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27719/40960 [01:43<00:48, 271.45batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27775/40960 [01:43<00:48, 273.08batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27775/40960 [01:43<00:48, 273.08batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27824/40960 [01:44<00:49, 263.80batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27824/40960 [01:44<00:49, 263.80batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27868/40960 [01:44<00:52, 249.58batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27868/40960 [01:44<00:52, 249.58batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27915/40960 [01:44<00:53, 243.64batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27915/40960 [01:44<00:53, 243.64batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27960/40960 [01:44<00:55, 235.24batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  68%|▋| 27960/40960 [01:44<00:55, 235.24batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  68%|▋| 28015/40960 [01:44<00:52, 246.14batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  68%|▋| 28015/40960 [01:44<00:52, 246.14batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28067/40960 [01:45<00:51, 249.08batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28067/40960 [01:45<00:51, 249.08batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  69%|▋| 28126/40960 [01:45<00:48, 262.64batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  69%|▋| 28126/40960 [01:45<00:48, 262.64batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28183/40960 [01:45<00:47, 267.59batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28183/40960 [01:45<00:47, 267.59batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28241/40960 [01:45<00:46, 273.13batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28241/40960 [01:45<00:46, 273.13batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28301/40960 [01:45<00:45, 280.35batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28301/40960 [01:45<00:45, 280.35batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28360/40960 [01:46<00:44, 284.37batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28360/40960 [01:46<00:44, 284.37batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28413/40960 [01:46<00:45, 277.29batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  69%|▋| 28413/40960 [01:46<00:45, 277.29batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28468/40960 [01:46<00:45, 275.82batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28468/40960 [01:46<00:45, 275.82batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28525/40960 [01:46<00:44, 278.39batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28525/40960 [01:46<00:44, 278.39batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28574/40960 [01:46<00:46, 267.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28574/40960 [01:46<00:46, 267.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28628/40960 [01:47<00:46, 267.90batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28628/40960 [01:47<00:46, 267.90batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28665/40960 [01:47<00:50, 241.47batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28665/40960 [01:47<00:50, 241.47batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28718/40960 [01:47<00:49, 248.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28718/40960 [01:47<00:49, 248.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28766/40960 [01:47<00:50, 243.63batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28766/40960 [01:47<00:50, 243.63batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28823/40960 [01:47<00:47, 255.54batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28823/40960 [01:47<00:47, 255.54batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28876/40960 [01:48<00:46, 257.71batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28876/40960 [01:48<00:46, 257.71batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 28934/40960 [01:48<00:45, 266.44batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 28934/40960 [01:48<00:45, 266.44batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 28987/40960 [01:48<00:45, 265.56batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 28987/40960 [01:48<00:45, 265.56batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29033/40960 [01:48<00:47, 252.65batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29033/40960 [01:48<00:47, 252.65batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29074/40960 [01:48<00:50, 236.86batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29074/40960 [01:48<00:50, 236.86batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29124/40960 [01:49<00:49, 240.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29124/40960 [01:49<00:49, 240.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29181/40960 [01:49<00:46, 252.97batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29181/40960 [01:49<00:46, 252.97batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29235/40960 [01:49<00:45, 256.93batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29235/40960 [01:49<00:45, 256.93batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29293/40960 [01:49<00:43, 265.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29293/40960 [01:49<00:43, 265.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29354/40960 [01:49<00:41, 276.34batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29354/40960 [01:49<00:41, 276.34batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29409/40960 [01:50<00:42, 274.95batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29409/40960 [01:50<00:42, 274.95batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29461/40960 [01:50<00:42, 269.12batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29461/40960 [01:50<00:42, 269.12batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29515/40960 [01:50<00:42, 268.91batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29515/40960 [01:50<00:42, 268.91batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29567/40960 [01:50<00:42, 265.61batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29567/40960 [01:50<00:42, 265.61batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29613/40960 [01:50<00:44, 252.27batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29613/40960 [01:50<00:44, 252.27batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29671/40960 [01:51<00:43, 262.31batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  72%|▋| 29671/40960 [01:51<00:43, 262.31batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29716/40960 [01:51<00:44, 250.76batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29716/40960 [01:51<00:44, 250.76batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29758/40960 [01:51<00:47, 236.80batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29758/40960 [01:51<00:47, 236.80batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29802/40960 [01:51<00:48, 231.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29802/40960 [01:51<00:48, 231.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|▋| 29841/40960 [01:51<00:50, 218.87batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29841/40960 [01:51<00:50, 218.87batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29890/40960 [01:52<00:48, 226.37batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29890/40960 [01:52<00:48, 226.37batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29943/40960 [01:52<00:46, 237.37batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29943/40960 [01:52<00:46, 237.37batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29993/40960 [01:52<00:45, 241.08batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 29993/40960 [01:52<00:45, 241.08batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 30049/40960 [01:52<00:43, 252.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 30049/40960 [01:52<00:43, 252.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 30101/40960 [01:52<00:42, 253.94batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  73%|▋| 30101/40960 [01:52<00:42, 253.94batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30152/40960 [01:53<00:42, 253.23batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30152/40960 [01:53<00:42, 253.23batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30207/40960 [01:53<00:41, 258.78batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30207/40960 [01:53<00:41, 258.78batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30265/40960 [01:53<00:39, 267.42batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30265/40960 [01:53<00:39, 267.42batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30322/40960 [01:53<00:39, 272.11batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30322/40960 [01:53<00:39, 272.11batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30376/40960 [01:53<00:39, 271.28batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30376/40960 [01:53<00:39, 271.28batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30431/40960 [01:54<00:38, 271.92batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30431/40960 [01:54<00:38, 271.92batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30485/40960 [01:54<00:38, 271.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  74%|▋| 30485/40960 [01:54<00:38, 271.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▋| 30537/40960 [01:54<00:39, 266.47batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▋| 30537/40960 [01:54<00:39, 266.47batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▋| 30591/40960 [01:54<00:38, 266.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▋| 30591/40960 [01:54<00:38, 266.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▋| 30644/40960 [01:54<00:38, 265.50batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▋| 30644/40960 [01:54<00:38, 265.50batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▋| 30701/40960 [01:55<00:37, 270.21batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▋| 30701/40960 [01:55<00:37, 270.21batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▊| 30757/40960 [01:55<00:37, 271.74batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▊| 30757/40960 [01:55<00:37, 271.74batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▊| 30815/40960 [01:55<00:36, 276.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▊| 30815/40960 [01:55<00:36, 276.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▊| 30877/40960 [01:55<00:35, 285.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  75%|▊| 30877/40960 [01:55<00:35, 285.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 30938/40960 [01:55<00:34, 290.82batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 30938/40960 [01:55<00:34, 290.82batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 30993/40960 [01:56<00:34, 286.10batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 30993/40960 [01:56<00:34, 286.10batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 31051/40960 [01:56<00:34, 287.07batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 31051/40960 [01:56<00:34, 287.07batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 31111/40960 [01:56<00:33, 290.11batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 31111/40960 [01:56<00:33, 290.11batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 31169/40960 [01:56<00:33, 289.03batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 31169/40960 [01:56<00:33, 289.03batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  76%|▊| 31225/40960 [01:56<00:34, 285.77batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  76%|▊| 31225/40960 [01:56<00:34, 285.77batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 31283/40960 [01:57<00:33, 286.40batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  76%|▊| 31283/40960 [01:57<00:33, 286.40batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31337/40960 [01:57<00:34, 281.03batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31337/40960 [01:57<00:34, 281.03batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31392/40960 [01:57<00:34, 277.01batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31392/40960 [01:57<00:34, 277.01batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31448/40960 [01:57<00:34, 276.88batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31448/40960 [01:57<00:34, 276.88batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31503/40960 [01:57<00:34, 275.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31503/40960 [01:57<00:34, 275.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31554/40960 [01:58<00:35, 268.17batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31554/40960 [01:58<00:35, 268.17batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31613/40960 [01:58<00:33, 275.09batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31613/40960 [01:58<00:33, 275.09batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31661/40960 [01:58<00:35, 262.86batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31661/40960 [01:58<00:35, 262.86batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31719/40960 [01:58<00:34, 270.04batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  77%|▊| 31719/40960 [01:58<00:34, 270.04batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 31779/40960 [01:59<00:33, 277.69batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 31779/40960 [01:59<00:33, 277.69batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 31840/40960 [01:59<00:32, 284.82batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 31840/40960 [01:59<00:32, 284.82batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 31895/40960 [01:59<00:32, 280.76batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 31895/40960 [01:59<00:32, 280.76batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 31952/40960 [01:59<00:32, 281.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 31952/40960 [01:59<00:32, 281.26batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 32010/40960 [01:59<00:31, 283.55batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 32010/40960 [01:59<00:31, 283.55batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 32070/40960 [02:00<00:30, 287.17batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 32070/40960 [02:00<00:30, 287.17batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 32129/40960 [02:00<00:30, 289.22batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  78%|▊| 32129/40960 [02:00<00:30, 289.22batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32185/40960 [02:00<00:30, 285.57batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32185/40960 [02:00<00:30, 285.57batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32244/40960 [02:00<00:30, 286.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32244/40960 [02:00<00:30, 286.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32291/40960 [02:00<00:32, 270.63batches/s, l2_loss: 0.0504 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|▊| 32291/40960 [02:00<00:32, 270.63batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32345/40960 [02:01<00:31, 269.77batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32345/40960 [02:01<00:31, 269.77batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32405/40960 [02:01<00:30, 277.54batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32405/40960 [02:01<00:30, 277.54batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32464/40960 [02:01<00:30, 281.66batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32464/40960 [02:01<00:30, 281.66batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32515/40960 [02:01<00:31, 270.24batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  79%|▊| 32515/40960 [02:01<00:31, 270.24batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32575/40960 [02:01<00:30, 277.93batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32575/40960 [02:01<00:30, 277.93batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32631/40960 [02:02<00:29, 277.89batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32631/40960 [02:02<00:29, 277.89batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  80%|▊| 32690/40960 [02:02<00:29, 282.04batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  80%|▊| 32690/40960 [02:02<00:29, 282.04batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  80%|▊| 32744/40960 [02:02<00:29, 276.34batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  80%|▊| 32744/40960 [02:02<00:29, 276.34batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32798/40960 [02:02<00:29, 273.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32798/40960 [02:02<00:29, 273.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32855/40960 [02:02<00:29, 275.15batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32855/40960 [02:02<00:29, 275.15batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32913/40960 [02:03<00:28, 279.38batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32913/40960 [02:03<00:28, 279.38batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32967/40960 [02:03<00:28, 276.59batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  80%|▊| 32967/40960 [02:03<00:28, 276.59batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  81%|▊| 33029/40960 [02:03<00:27, 285.45batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  81%|▊| 33029/40960 [02:03<00:27, 285.45batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  81%|▊| 33087/40960 [02:03<00:27, 285.58batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  81%|▊| 33087/40960 [02:03<00:27, 285.58batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  81%|▊| 33133/40960 [02:03<00:29, 267.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  81%|▊| 33133/40960 [02:03<00:29, 267.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  81%|▊| 33190/40960 [02:04<00:28, 271.54batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  81%|▊| 33190/40960 [02:04<00:28, 271.54batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  81%|▊| 33243/40960 [02:04<00:28, 268.91batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  81%|▊| 33243/40960 [02:04<00:28, 268.91batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  81%|▊| 33297/40960 [02:04<00:28, 268.70batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  81%|▊| 33297/40960 [02:04<00:28, 268.70batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  81%|▊| 33353/40960 [02:04<00:28, 271.51batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  81%|▊| 33353/40960 [02:04<00:28, 271.51batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  82%|▊| 33405/40960 [02:04<00:28, 267.11batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  82%|▊| 33405/40960 [02:04<00:28, 267.11batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  82%|▊| 33456/40960 [02:05<00:28, 262.24batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  82%|▊| 33456/40960 [02:05<00:28, 262.24batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  82%|▊| 33507/40960 [02:05<00:28, 259.48batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  82%|▊| 33507/40960 [02:05<00:28, 259.48batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  82%|▊| 33555/40960 [02:05<00:29, 252.43batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  82%|▊| 33555/40960 [02:05<00:29, 252.43batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  82%|▊| 33609/40960 [02:05<00:28, 256.17batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  82%|▊| 33609/40960 [02:05<00:28, 256.17batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  82%|▊| 33665/40960 [02:05<00:27, 262.79batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  82%|▊| 33665/40960 [02:05<00:27, 262.79batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  82%|▊| 33726/40960 [02:06<00:26, 274.28batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  82%|▊| 33726/40960 [02:06<00:26, 274.28batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  82%|▊| 33782/40960 [02:06<00:26, 275.96batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  82%|▊| 33782/40960 [02:06<00:26, 275.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 33842/40960 [02:06<00:25, 282.09batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 33842/40960 [02:06<00:25, 282.09batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  83%|▊| 33901/40960 [02:06<00:24, 285.13batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  83%|▊| 33901/40960 [02:06<00:24, 285.13batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 33949/40960 [02:06<00:25, 270.07batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 33949/40960 [02:06<00:25, 270.07batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 34007/40960 [02:07<00:25, 275.10batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 34007/40960 [02:07<00:25, 275.10batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 34061/40960 [02:07<00:25, 272.69batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 34061/40960 [02:07<00:25, 272.69batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 34110/40960 [02:07<00:26, 263.31batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 34110/40960 [02:07<00:26, 263.31batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 34154/40960 [02:07<00:27, 248.46batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  83%|▊| 34154/40960 [02:07<00:27, 248.46batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34211/40960 [02:07<00:26, 259.03batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34211/40960 [02:07<00:26, 259.03batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34267/40960 [02:08<00:25, 264.36batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34267/40960 [02:08<00:25, 264.36batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34326/40960 [02:08<00:24, 272.86batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34326/40960 [02:08<00:24, 272.86batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  84%|▊| 34384/40960 [02:08<00:23, 277.81batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  84%|▊| 34384/40960 [02:08<00:23, 277.81batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  84%|▊| 34436/40960 [02:08<00:23, 272.06batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  84%|▊| 34436/40960 [02:08<00:23, 272.06batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34496/40960 [02:08<00:23, 279.66batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34496/40960 [02:08<00:23, 279.66batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34558/40960 [02:09<00:22, 287.88batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  84%|▊| 34558/40960 [02:09<00:22, 287.88batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34614/40960 [02:09<00:22, 283.49batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34614/40960 [02:09<00:22, 283.49batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34668/40960 [02:09<00:22, 278.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34668/40960 [02:09<00:22, 278.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34721/40960 [02:09<00:22, 274.44batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34721/40960 [02:09<00:22, 274.44batches/s, l2_loss: 0.0503 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34781/40960 [02:09<00:21, 281.01batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34781/40960 [02:09<00:21, 281.01batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34835/40960 [02:10<00:22, 275.19batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34835/40960 [02:10<00:22, 275.19batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34887/40960 [02:10<00:22, 270.14batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34887/40960 [02:10<00:22, 270.14batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34939/40960 [02:10<00:22, 266.98batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34939/40960 [02:10<00:22, 266.98batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34983/40960 [02:10<00:23, 250.48batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  85%|▊| 34983/40960 [02:10<00:23, 250.48batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35027/40960 [02:10<00:24, 239.22batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35027/40960 [02:10<00:24, 239.22batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35082/40960 [02:11<00:23, 249.61batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35082/40960 [02:11<00:23, 249.61batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35135/40960 [02:11<00:23, 253.04batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35135/40960 [02:11<00:23, 253.04batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35177/40960 [02:11<00:24, 238.22batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35177/40960 [02:11<00:24, 238.22batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35228/40960 [02:11<00:23, 243.07batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35228/40960 [02:11<00:23, 243.07batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35279/40960 [02:11<00:23, 246.45batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35279/40960 [02:11<00:23, 246.45batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35318/40960 [02:12<00:24, 229.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35318/40960 [02:12<00:24, 229.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35372/40960 [02:12<00:23, 240.62batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35372/40960 [02:12<00:23, 240.62batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35423/40960 [02:12<00:22, 243.35batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  86%|▊| 35423/40960 [02:12<00:22, 243.35batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35456/40960 [02:12<00:25, 218.79batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35456/40960 [02:12<00:25, 218.79batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35501/40960 [02:12<00:24, 219.84batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35501/40960 [02:12<00:24, 219.84batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35556/40960 [02:13<00:22, 235.97batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35556/40960 [02:13<00:22, 235.97batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35611/40960 [02:13<00:21, 247.30batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35611/40960 [02:13<00:21, 247.30batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35670/40960 [02:13<00:20, 260.49batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35670/40960 [02:13<00:20, 260.49batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35729/40960 [02:13<00:19, 270.69batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35729/40960 [02:13<00:19, 270.69batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35783/40960 [02:13<00:19, 269.75batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35783/40960 [02:13<00:19, 269.75batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35833/40960 [02:14<00:19, 261.54batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  87%|▊| 35833/40960 [02:14<00:19, 261.54batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 35887/40960 [02:14<00:19, 263.50batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 35887/40960 [02:14<00:19, 263.50batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 35938/40960 [02:14<00:19, 259.90batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 35938/40960 [02:14<00:19, 259.90batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 35991/40960 [02:14<00:19, 260.53batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 35991/40960 [02:14<00:19, 260.53batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 36048/40960 [02:15<00:18, 266.87batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 36048/40960 [02:15<00:18, 266.87batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 36108/40960 [02:15<00:17, 276.29batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 36108/40960 [02:15<00:17, 276.29batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 36166/40960 [02:15<00:17, 279.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 36166/40960 [02:15<00:17, 279.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 36219/40960 [02:15<00:17, 273.78batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  88%|▉| 36219/40960 [02:15<00:17, 273.78batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36274/40960 [02:15<00:17, 273.93batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36274/40960 [02:15<00:17, 273.93batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36331/40960 [02:16<00:16, 276.17batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36331/40960 [02:16<00:16, 276.17batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36385/40960 [02:16<00:16, 274.09batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36385/40960 [02:16<00:16, 274.09batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36439/40960 [02:16<00:16, 271.72batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36439/40960 [02:16<00:16, 271.72batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36496/40960 [02:16<00:16, 275.48batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36496/40960 [02:16<00:16, 275.48batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36549/40960 [02:16<00:16, 271.71batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36549/40960 [02:16<00:16, 271.71batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36603/40960 [02:17<00:16, 270.67batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36603/40960 [02:17<00:16, 270.67batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36654/40960 [02:17<00:16, 265.72batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  89%|▉| 36654/40960 [02:17<00:16, 265.72batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36705/40960 [02:17<00:16, 261.56batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36705/40960 [02:17<00:16, 261.56batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36760/40960 [02:17<00:15, 265.04batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36760/40960 [02:17<00:15, 265.04batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36817/40960 [02:17<00:15, 270.93batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36817/40960 [02:17<00:15, 270.93batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36874/40960 [02:18<00:14, 274.80batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36874/40960 [02:18<00:14, 274.80batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36920/40960 [02:18<00:15, 258.29batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36920/40960 [02:18<00:15, 258.29batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36974/40960 [02:18<00:15, 261.02batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 36974/40960 [02:18<00:15, 261.02batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 37027/40960 [02:18<00:15, 261.75batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 37027/40960 [02:18<00:15, 261.75batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  90%|▉| 37067/40960 [02:18<00:16, 242.37batches/s, l2_loss: 0.0503 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 37067/40960 [02:18<00:16, 242.37batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37120/40960 [02:19<00:15, 247.73batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37120/40960 [02:19<00:15, 247.73batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37176/40960 [02:19<00:14, 257.02batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37176/40960 [02:19<00:14, 257.02batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37235/40960 [02:19<00:13, 267.12batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37235/40960 [02:19<00:13, 267.12batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37288/40960 [02:19<00:13, 265.57batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37288/40960 [02:19<00:13, 265.57batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37347/40960 [02:19<00:13, 273.76batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37347/40960 [02:19<00:13, 273.76batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37405/40960 [02:20<00:12, 277.72batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37405/40960 [02:20<00:12, 277.72batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37458/40960 [02:20<00:12, 272.50batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  91%|▉| 37458/40960 [02:20<00:12, 272.50batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37494/40960 [02:20<00:14, 243.05batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37494/40960 [02:20<00:14, 243.05batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37548/40960 [02:20<00:13, 250.57batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37548/40960 [02:20<00:13, 250.57batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37598/40960 [02:20<00:13, 249.64batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37598/40960 [02:20<00:13, 249.64batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37650/40960 [02:21<00:13, 252.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37650/40960 [02:21<00:13, 252.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37701/40960 [02:21<00:12, 252.61batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37701/40960 [02:21<00:12, 252.61batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37757/40960 [02:21<00:12, 260.44batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37757/40960 [02:21<00:12, 260.44batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37810/40960 [02:21<00:12, 261.10batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37810/40960 [02:21<00:12, 261.10batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37864/40960 [02:21<00:11, 262.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  92%|▉| 37864/40960 [02:21<00:11, 262.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 37914/40960 [02:22<00:11, 258.28batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 37914/40960 [02:22<00:11, 258.28batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 37965/40960 [02:22<00:11, 255.40batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 37965/40960 [02:22<00:11, 255.40batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38016/40960 [02:22<00:11, 254.45batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38016/40960 [02:22<00:11, 254.45batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38056/40960 [02:22<00:12, 235.49batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38056/40960 [02:22<00:12, 235.49batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38109/40960 [02:22<00:11, 243.34batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38109/40960 [02:22<00:11, 243.34batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38162/40960 [02:23<00:11, 248.08batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38162/40960 [02:23<00:11, 248.08batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38211/40960 [02:23<00:11, 246.94batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38211/40960 [02:23<00:11, 246.94batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38270/40960 [02:23<00:10, 260.15batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  93%|▉| 38270/40960 [02:23<00:10, 260.15batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38322/40960 [02:23<00:10, 257.35batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38322/40960 [02:23<00:10, 257.35batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38378/40960 [02:23<00:09, 262.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38378/40960 [02:23<00:09, 262.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38432/40960 [02:24<00:09, 263.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38432/40960 [02:24<00:09, 263.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38486/40960 [02:24<00:09, 265.13batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38486/40960 [02:24<00:09, 265.13batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38539/40960 [02:24<00:09, 264.42batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38539/40960 [02:24<00:09, 264.42batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38597/40960 [02:24<00:08, 271.13batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38597/40960 [02:24<00:08, 271.13batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38655/40960 [02:24<00:08, 276.58batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38655/40960 [02:24<00:08, 276.58batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38707/40960 [02:25<00:08, 271.29batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  94%|▉| 38707/40960 [02:25<00:08, 271.29batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38757/40960 [02:25<00:08, 264.22batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38757/40960 [02:25<00:08, 264.22batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38805/40960 [02:25<00:08, 256.35batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38805/40960 [02:25<00:08, 256.35batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38852/40960 [02:25<00:08, 247.74batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38852/40960 [02:25<00:08, 247.74batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38903/40960 [02:25<00:08, 248.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38903/40960 [02:25<00:08, 248.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38957/40960 [02:26<00:07, 254.79batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 38957/40960 [02:26<00:07, 254.79batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 39011/40960 [02:26<00:07, 258.09batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 39011/40960 [02:26<00:07, 258.09batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 39061/40960 [02:26<00:07, 254.29batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 39061/40960 [02:26<00:07, 254.29batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 39113/40960 [02:26<00:07, 255.69batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  95%|▉| 39113/40960 [02:26<00:07, 255.69batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39172/40960 [02:26<00:06, 266.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39172/40960 [02:26<00:06, 266.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39229/40960 [02:27<00:06, 271.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39229/40960 [02:27<00:06, 271.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39288/40960 [02:27<00:06, 278.07batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39288/40960 [02:27<00:06, 278.07batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39345/40960 [02:27<00:05, 279.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39345/40960 [02:27<00:05, 279.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39399/40960 [02:27<00:05, 274.88batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39399/40960 [02:27<00:05, 274.88batches/s, l2_loss: 0.0503 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|▉| 39448/40960 [02:27<00:05, 265.65batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39448/40960 [02:27<00:05, 265.65batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39494/40960 [02:28<00:05, 254.53batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39494/40960 [02:28<00:05, 254.53batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39535/40960 [02:28<00:05, 239.73batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39535/40960 [02:28<00:05, 239.73batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39583/40960 [02:28<00:05, 237.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39583/40960 [02:28<00:05, 237.00batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39614/40960 [02:28<00:06, 210.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39614/40960 [02:28<00:06, 210.96batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39662/40960 [02:28<00:05, 219.27batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39662/40960 [02:28<00:05, 219.27batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39716/40960 [02:29<00:05, 234.01batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39716/40960 [02:29<00:05, 234.01batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39761/40960 [02:29<00:05, 229.32batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39761/40960 [02:29<00:05, 229.32batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39795/40960 [02:29<00:05, 210.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39795/40960 [02:29<00:05, 210.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39846/40960 [02:29<00:05, 222.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39846/40960 [02:29<00:05, 222.47batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39901/40960 [02:29<00:04, 236.74batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  97%|▉| 39901/40960 [02:29<00:04, 236.74batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 39954/40960 [02:30<00:04, 244.56batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 39954/40960 [02:30<00:04, 244.56batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40006/40960 [02:30<00:03, 248.27batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40006/40960 [02:30<00:03, 248.27batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40055/40960 [02:30<00:03, 246.09batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40055/40960 [02:30<00:03, 246.09batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40112/40960 [02:30<00:03, 257.18batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40112/40960 [02:30<00:03, 257.18batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40155/40960 [02:30<00:03, 243.74batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40155/40960 [02:31<00:03, 243.74batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40208/40960 [02:31<00:03, 249.77batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40208/40960 [02:31<00:03, 249.77batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40268/40960 [02:31<00:02, 263.64batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40268/40960 [02:31<00:02, 263.64batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40326/40960 [02:31<00:02, 269.88batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  98%|▉| 40326/40960 [02:31<00:02, 269.88batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40379/40960 [02:31<00:02, 268.25batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40379/40960 [02:31<00:02, 268.25batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40431/40960 [02:32<00:01, 264.64batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40431/40960 [02:32<00:01, 264.64batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40486/40960 [02:32<00:01, 267.17batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40486/40960 [02:32<00:01, 267.17batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40544/40960 [02:32<00:01, 273.45batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40544/40960 [02:32<00:01, 273.45batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40605/40960 [02:32<00:01, 281.84batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40605/40960 [02:32<00:01, 281.84batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40664/40960 [02:32<00:01, 285.14batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40664/40960 [02:32<00:01, 285.14batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40720/40960 [02:33<00:00, 282.98batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  99%|▉| 40720/40960 [02:33<00:00, 282.98batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training: 100%|▉| 40774/40960 [02:33<00:00, 278.81batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training: 100%|▉| 40774/40960 [02:33<00:00, 278.81batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training: 100%|▉| 40831/40960 [02:33<00:00, 279.26batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training: 100%|▉| 40831/40960 [02:33<00:00, 279.26batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training: 100%|▉| 40886/40960 [02:33<00:00, 277.60batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training: 100%|▉| 40886/40960 [02:33<00:00, 277.60batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training: 100%|▉| 40944/40960 [02:33<00:00, 280.32batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training: 100%|▉| 40944/40960 [02:33<00:00, 280.32batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:24:09.594346: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  65%|▋| 17/26 [34:49<19:50, 132.27s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:24:12.890467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:24:19.498194: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<24:36:08,  2.16s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<24:36:08,  2.16s/batches, l2_loss: 0.1819 - round_loss:\u001b[A\n",
      "Training:   0%| | 56/40960 [00:02<21:00, 32.46batches/s, l2_loss: 0.1819 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 56/40960 [00:02<21:00, 32.46batches/s, l2_loss: 0.3207 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 110/40960 [00:02<10:15, 66.36batches/s, l2_loss: 0.3207 - round_loss: \u001b[A\n",
      "Training:   0%| | 110/40960 [00:02<10:15, 66.36batches/s, l2_loss: 0.3325 - round_loss: \u001b[A\n",
      "Training:   0%| | 171/40960 [00:02<06:22, 106.62batches/s, l2_loss: 0.3325 - round_loss:\u001b[A\n",
      "Training:   0%| | 171/40960 [00:02<06:22, 106.62batches/s, l2_loss: 0.2835 - round_loss:\u001b[A\n",
      "Training:   1%| | 232/40960 [00:02<04:40, 145.17batches/s, l2_loss: 0.2835 - round_loss:\u001b[A\n",
      "Training:   1%| | 232/40960 [00:02<04:40, 145.17batches/s, l2_loss: 0.3009 - round_loss:\u001b[A\n",
      "Training:   1%| | 288/40960 [00:03<03:53, 174.16batches/s, l2_loss: 0.3009 - round_loss:\u001b[A\n",
      "Training:   1%| | 288/40960 [00:03<03:53, 174.16batches/s, l2_loss: 0.3222 - round_loss:\u001b[A\n",
      "Training:   1%| | 345/40960 [00:03<03:22, 200.19batches/s, l2_loss: 0.3222 - round_loss:\u001b[A\n",
      "Training:   1%| | 345/40960 [00:03<03:22, 200.19batches/s, l2_loss: 0.3257 - round_loss:\u001b[A\n",
      "Training:   1%| | 404/40960 [00:03<03:01, 224.06batches/s, l2_loss: 0.3257 - round_loss:\u001b[A\n",
      "Training:   1%| | 404/40960 [00:03<03:01, 224.06batches/s, l2_loss: 0.3097 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%| | 460/40960 [00:03<02:50, 238.11batches/s, l2_loss: 0.3097 - round_loss:\u001b[A\n",
      "Training:   1%| | 460/40960 [00:03<02:50, 238.11batches/s, l2_loss: 0.3181 - round_loss:\u001b[A\n",
      "Training:   1%| | 520/40960 [00:03<02:39, 254.29batches/s, l2_loss: 0.3181 - round_loss:\u001b[A\n",
      "Training:   1%| | 520/40960 [00:03<02:39, 254.29batches/s, l2_loss: 0.3106 - round_loss:\u001b[A\n",
      "Training:   1%| | 582/40960 [00:04<02:29, 269.31batches/s, l2_loss: 0.3106 - round_loss:\u001b[A\n",
      "Training:   1%| | 582/40960 [00:04<02:29, 269.31batches/s, l2_loss: 0.3030 - round_loss:\u001b[A\n",
      "Training:   2%| | 640/40960 [00:04<02:26, 274.74batches/s, l2_loss: 0.3030 - round_loss:\u001b[A\n",
      "Training:   2%| | 640/40960 [00:04<02:26, 274.74batches/s, l2_loss: 0.3129 - round_loss:\u001b[A\n",
      "Training:   2%| | 702/40960 [00:04<02:21, 283.68batches/s, l2_loss: 0.3129 - round_loss:\u001b[A\n",
      "Training:   2%| | 702/40960 [00:04<02:21, 283.68batches/s, l2_loss: 0.3226 - round_loss:\u001b[A\n",
      "Training:   2%| | 763/40960 [00:04<02:19, 288.90batches/s, l2_loss: 0.3226 - round_loss:\u001b[A\n",
      "Training:   2%| | 763/40960 [00:04<02:19, 288.90batches/s, l2_loss: 0.3136 - round_loss:\u001b[A\n",
      "Training:   2%| | 822/40960 [00:04<02:18, 289.59batches/s, l2_loss: 0.3136 - round_loss:\u001b[A\n",
      "Training:   2%| | 822/40960 [00:04<02:18, 289.59batches/s, l2_loss: 0.3121 - round_loss:\u001b[A\n",
      "Training:   2%| | 884/40960 [00:05<02:15, 294.81batches/s, l2_loss: 0.3121 - round_loss:\u001b[A\n",
      "Training:   2%| | 884/40960 [00:05<02:15, 294.81batches/s, l2_loss: 0.3141 - round_loss:\u001b[A\n",
      "Training:   2%| | 948/40960 [00:05<02:12, 301.32batches/s, l2_loss: 0.3141 - round_loss:\u001b[A\n",
      "Training:   2%| | 948/40960 [00:05<02:12, 301.32batches/s, l2_loss: 0.3124 - round_loss:\u001b[A\n",
      "Training:   2%| | 1007/40960 [00:05<02:13, 298.19batches/s, l2_loss: 0.3124 - round_loss\u001b[A\n",
      "Training:   2%| | 1007/40960 [00:05<02:13, 298.19batches/s, l2_loss: 0.3122 - round_loss\u001b[A\n",
      "Training:   3%| | 1068/40960 [00:05<02:12, 300.16batches/s, l2_loss: 0.3122 - round_loss\u001b[A\n",
      "Training:   3%| | 1068/40960 [00:05<02:12, 300.16batches/s, l2_loss: 0.3161 - round_loss\u001b[A\n",
      "Training:   3%| | 1128/40960 [00:05<02:12, 300.11batches/s, l2_loss: 0.3161 - round_loss\u001b[A\n",
      "Training:   3%| | 1128/40960 [00:05<02:12, 300.11batches/s, l2_loss: 0.3132 - round_loss\u001b[A\n",
      "Training:   3%| | 1191/40960 [00:06<02:11, 303.25batches/s, l2_loss: 0.3132 - round_loss\u001b[A\n",
      "Training:   3%| | 1191/40960 [00:06<02:11, 303.25batches/s, l2_loss: 0.3122 - round_loss\u001b[A\n",
      "Training:   3%| | 1246/40960 [00:06<02:15, 294.02batches/s, l2_loss: 0.3122 - round_loss\u001b[A\n",
      "Training:   3%| | 1246/40960 [00:06<02:15, 294.02batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:   3%| | 1307/40960 [00:06<02:13, 297.08batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:   3%| | 1307/40960 [00:06<02:13, 297.08batches/s, l2_loss: 0.3099 - round_loss\u001b[A\n",
      "Training:   3%| | 1363/40960 [00:06<02:16, 290.46batches/s, l2_loss: 0.3099 - round_loss\u001b[A\n",
      "Training:   3%| | 1363/40960 [00:06<02:16, 290.46batches/s, l2_loss: 0.3103 - round_loss\u001b[A\n",
      "Training:   3%| | 1416/40960 [00:07<02:19, 282.59batches/s, l2_loss: 0.3103 - round_loss\u001b[A\n",
      "Training:   3%| | 1416/40960 [00:07<02:19, 282.59batches/s, l2_loss: 0.3131 - round_loss\u001b[A\n",
      "Training:   4%| | 1467/40960 [00:07<02:24, 273.25batches/s, l2_loss: 0.3131 - round_loss\u001b[A\n",
      "Training:   4%| | 1467/40960 [00:07<02:24, 273.25batches/s, l2_loss: 0.3129 - round_loss\u001b[A\n",
      "Training:   4%| | 1530/40960 [00:07<02:18, 284.72batches/s, l2_loss: 0.3129 - round_loss\u001b[A\n",
      "Training:   4%| | 1530/40960 [00:07<02:18, 284.72batches/s, l2_loss: 0.3111 - round_loss\u001b[A\n",
      "Training:   4%| | 1592/40960 [00:07<02:15, 290.93batches/s, l2_loss: 0.3111 - round_loss\u001b[A\n",
      "Training:   4%| | 1592/40960 [00:07<02:15, 290.93batches/s, l2_loss: 0.3111 - round_loss\u001b[A\n",
      "Training:   4%| | 1643/40960 [00:07<02:20, 279.49batches/s, l2_loss: 0.3111 - round_loss\u001b[A\n",
      "Training:   4%| | 1643/40960 [00:07<02:20, 279.49batches/s, l2_loss: 0.3124 - round_loss\u001b[A\n",
      "Training:   4%| | 1701/40960 [00:08<02:19, 281.96batches/s, l2_loss: 0.3124 - round_loss\u001b[A\n",
      "Training:   4%| | 1701/40960 [00:08<02:19, 281.96batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   4%| | 1759/40960 [00:08<02:18, 283.71batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   4%| | 1759/40960 [00:08<02:18, 283.71batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:   4%| | 1823/40960 [00:08<02:13, 293.99batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:   4%| | 1823/40960 [00:08<02:13, 293.99batches/s, l2_loss: 0.3111 - round_loss\u001b[A\n",
      "Training:   5%| | 1884/40960 [00:08<02:11, 296.72batches/s, l2_loss: 0.3111 - round_loss\u001b[A\n",
      "Training:   5%| | 1884/40960 [00:08<02:11, 296.72batches/s, l2_loss: 0.3111 - round_loss\u001b[A\n",
      "Training:   5%| | 1936/40960 [00:08<02:17, 283.38batches/s, l2_loss: 0.3111 - round_loss\u001b[A\n",
      "Training:   5%| | 1936/40960 [00:08<02:17, 283.38batches/s, l2_loss: 0.3103 - round_loss\u001b[A\n",
      "Training:   5%| | 1999/40960 [00:09<02:13, 291.38batches/s, l2_loss: 0.3103 - round_loss\u001b[A\n",
      "Training:   5%| | 1999/40960 [00:09<02:13, 291.38batches/s, l2_loss: 0.3078 - round_loss\u001b[A\n",
      "Training:   5%| | 2053/40960 [00:09<02:17, 283.63batches/s, l2_loss: 0.3078 - round_loss\u001b[A\n",
      "Training:   5%| | 2053/40960 [00:09<02:17, 283.63batches/s, l2_loss: 0.3108 - round_loss\u001b[A\n",
      "Training:   5%| | 2103/40960 [00:09<02:22, 271.75batches/s, l2_loss: 0.3108 - round_loss\u001b[A\n",
      "Training:   5%| | 2103/40960 [00:09<02:22, 271.75batches/s, l2_loss: 0.3120 - round_loss\u001b[A\n",
      "Training:   5%| | 2151/40960 [00:09<02:28, 260.98batches/s, l2_loss: 0.3120 - round_loss\u001b[A\n",
      "Training:   5%| | 2151/40960 [00:09<02:28, 260.98batches/s, l2_loss: 0.3110 - round_loss\u001b[A\n",
      "Training:   5%| | 2206/40960 [00:09<02:26, 265.01batches/s, l2_loss: 0.3110 - round_loss\u001b[A\n",
      "Training:   5%| | 2206/40960 [00:09<02:26, 265.01batches/s, l2_loss: 0.3103 - round_loss\u001b[A\n",
      "Training:   6%| | 2264/40960 [00:10<02:22, 271.62batches/s, l2_loss: 0.3103 - round_loss\u001b[A\n",
      "Training:   6%| | 2264/40960 [00:10<02:22, 271.62batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   6%| | 2326/40960 [00:10<02:16, 282.09batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   6%| | 2326/40960 [00:10<02:16, 282.09batches/s, l2_loss: 0.3109 - round_loss\u001b[A\n",
      "Training:   6%| | 2386/40960 [00:10<02:14, 287.34batches/s, l2_loss: 0.3109 - round_loss\u001b[A\n",
      "Training:   6%| | 2386/40960 [00:10<02:14, 287.34batches/s, l2_loss: 0.3081 - round_loss\u001b[A\n",
      "Training:   6%| | 2448/40960 [00:10<02:11, 293.00batches/s, l2_loss: 0.3081 - round_loss\u001b[A\n",
      "Training:   6%| | 2448/40960 [00:10<02:11, 293.00batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:   6%| | 2509/40960 [00:10<02:09, 296.14batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:   6%| | 2509/40960 [00:10<02:09, 296.14batches/s, l2_loss: 0.3102 - round_loss\u001b[A\n",
      "Training:   6%| | 2571/40960 [00:11<02:07, 300.04batches/s, l2_loss: 0.3102 - round_loss\u001b[A\n",
      "Training:   6%| | 2571/40960 [00:11<02:07, 300.04batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:   6%| | 2635/40960 [00:11<02:05, 304.36batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:   6%| | 2635/40960 [00:11<02:05, 304.36batches/s, l2_loss: 0.3097 - round_loss\u001b[A\n",
      "Training:   7%| | 2689/40960 [00:11<02:11, 291.75batches/s, l2_loss: 0.3097 - round_loss\u001b[A\n",
      "Training:   7%| | 2689/40960 [00:11<02:11, 291.75batches/s, l2_loss: 0.3105 - round_loss\u001b[A\n",
      "Training:   7%| | 2735/40960 [00:11<02:20, 271.92batches/s, l2_loss: 0.3105 - round_loss\u001b[A\n",
      "Training:   7%| | 2735/40960 [00:11<02:20, 271.92batches/s, l2_loss: 0.3105 - round_loss\u001b[A\n",
      "Training:   7%| | 2786/40960 [00:11<02:23, 266.40batches/s, l2_loss: 0.3105 - round_loss\u001b[A\n",
      "Training:   7%| | 2786/40960 [00:11<02:23, 266.40batches/s, l2_loss: 0.3107 - round_loss\u001b[A\n",
      "Training:   7%| | 2836/40960 [00:12<02:26, 259.42batches/s, l2_loss: 0.3107 - round_loss\u001b[A\n",
      "Training:   7%| | 2836/40960 [00:12<02:26, 259.42batches/s, l2_loss: 0.3096 - round_loss\u001b[A\n",
      "Training:   7%| | 2890/40960 [00:12<02:25, 261.43batches/s, l2_loss: 0.3096 - round_loss\u001b[A\n",
      "Training:   7%| | 2890/40960 [00:12<02:25, 261.43batches/s, l2_loss: 0.3107 - round_loss\u001b[A\n",
      "Training:   7%| | 2950/40960 [00:12<02:19, 271.50batches/s, l2_loss: 0.3107 - round_loss\u001b[A\n",
      "Training:   7%| | 2950/40960 [00:12<02:19, 271.50batches/s, l2_loss: 0.3100 - round_loss\u001b[A\n",
      "Training:   7%| | 3006/40960 [00:12<02:19, 272.93batches/s, l2_loss: 0.3100 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 3006/40960 [00:12<02:19, 272.93batches/s, l2_loss: 0.3101 - round_loss\u001b[A\n",
      "Training:   7%| | 3067/40960 [00:12<02:14, 282.43batches/s, l2_loss: 0.3101 - round_loss\u001b[A\n",
      "Training:   7%| | 3067/40960 [00:12<02:14, 282.43batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:   8%| | 3119/40960 [00:13<02:17, 274.30batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:   8%| | 3119/40960 [00:13<02:17, 274.30batches/s, l2_loss: 0.3106 - round_loss\u001b[A\n",
      "Training:   8%| | 3174/40960 [00:13<02:18, 273.22batches/s, l2_loss: 0.3106 - round_loss\u001b[A\n",
      "Training:   8%| | 3174/40960 [00:13<02:18, 273.22batches/s, l2_loss: 0.3096 - round_loss\u001b[A\n",
      "Training:   8%| | 3212/40960 [00:13<02:32, 246.95batches/s, l2_loss: 0.3096 - round_loss\u001b[A\n",
      "Training:   8%| | 3212/40960 [00:13<02:32, 246.95batches/s, l2_loss: 0.3098 - round_loss\u001b[A\n",
      "Training:   8%| | 3269/40960 [00:13<02:26, 257.95batches/s, l2_loss: 0.3098 - round_loss\u001b[A\n",
      "Training:   8%| | 3269/40960 [00:13<02:26, 257.95batches/s, l2_loss: 0.3083 - round_loss\u001b[A\n",
      "Training:   8%| | 3329/40960 [00:13<02:19, 270.31batches/s, l2_loss: 0.3083 - round_loss\u001b[A\n",
      "Training:   8%| | 3329/40960 [00:13<02:19, 270.31batches/s, l2_loss: 0.3100 - round_loss\u001b[A\n",
      "Training:   8%| | 3377/40960 [00:14<02:23, 261.08batches/s, l2_loss: 0.3100 - round_loss\u001b[A\n",
      "Training:   8%| | 3377/40960 [00:14<02:23, 261.08batches/s, l2_loss: 0.3108 - round_loss\u001b[A\n",
      "Training:   8%| | 3420/40960 [00:14<02:33, 244.74batches/s, l2_loss: 0.3108 - round_loss\u001b[A\n",
      "Training:   8%| | 3420/40960 [00:14<02:33, 244.74batches/s, l2_loss: 0.3103 - round_loss\u001b[A\n",
      "Training:   8%| | 3469/40960 [00:14<02:33, 243.63batches/s, l2_loss: 0.3103 - round_loss\u001b[A\n",
      "Training:   8%| | 3469/40960 [00:14<02:33, 243.63batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   9%| | 3508/40960 [00:14<02:43, 228.47batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   9%| | 3508/40960 [00:14<02:43, 228.47batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:   9%| | 3566/40960 [00:14<02:32, 245.62batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:   9%| | 3566/40960 [00:14<02:32, 245.62batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   9%| | 3630/40960 [00:15<02:19, 266.98batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   9%| | 3630/40960 [00:15<02:19, 266.98batches/s, l2_loss: 0.3107 - round_loss\u001b[A\n",
      "Training:   9%| | 3688/40960 [00:15<02:16, 272.90batches/s, l2_loss: 0.3107 - round_loss\u001b[A\n",
      "Training:   9%| | 3688/40960 [00:15<02:16, 272.90batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   9%| | 3746/40960 [00:15<02:14, 277.43batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:   9%| | 3746/40960 [00:15<02:14, 277.43batches/s, l2_loss: 0.3101 - round_loss\u001b[A\n",
      "Training:   9%| | 3797/40960 [00:15<02:17, 270.56batches/s, l2_loss: 0.3101 - round_loss\u001b[A\n",
      "Training:   9%| | 3797/40960 [00:15<02:17, 270.56batches/s, l2_loss: 0.3096 - round_loss\u001b[A\n",
      "Training:   9%| | 3856/40960 [00:15<02:13, 277.60batches/s, l2_loss: 0.3096 - round_loss\u001b[A\n",
      "Training:   9%| | 3856/40960 [00:15<02:13, 277.60batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:  10%| | 3915/40960 [00:16<02:11, 282.69batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:  10%| | 3915/40960 [00:16<02:11, 282.69batches/s, l2_loss: 0.3082 - round_loss\u001b[A\n",
      "Training:  10%| | 3976/40960 [00:16<02:08, 288.47batches/s, l2_loss: 0.3082 - round_loss\u001b[A\n",
      "Training:  10%| | 3976/40960 [00:16<02:08, 288.47batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:  10%| | 4029/40960 [00:16<02:11, 281.26batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:  10%| | 4029/40960 [00:16<02:11, 281.26batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:  10%| | 4082/40960 [00:16<02:14, 275.20batches/s, l2_loss: 0.3104 - round_loss\u001b[A\n",
      "Training:  10%| | 4082/40960 [00:16<02:14, 275.20batches/s, l2_loss: 0.3099 - round_loss\u001b[A\n",
      "Training:  10%| | 4133/40960 [00:16<02:17, 267.26batches/s, l2_loss: 0.3099 - round_loss\u001b[A\n",
      "Training:  10%| | 4133/40960 [00:16<02:17, 267.26batches/s, l2_loss: 0.3100 - round_loss\u001b[A\n",
      "Training:  10%| | 4194/40960 [00:17<02:12, 278.44batches/s, l2_loss: 0.3100 - round_loss\u001b[A\n",
      "Training:  10%| | 4194/40960 [00:17<02:12, 278.44batches/s, l2_loss: 0.3095 - round_loss\u001b[A\n",
      "Training:  10%| | 4251/40960 [00:17<02:11, 278.32batches/s, l2_loss: 0.3095 - round_loss\u001b[A\n",
      "Training:  10%| | 4251/40960 [00:17<02:11, 278.32batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:  11%| | 4308/40960 [00:17<02:11, 278.85batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:  11%| | 4308/40960 [00:17<02:11, 278.85batches/s, l2_loss: 0.3081 - round_loss\u001b[A\n",
      "Training:  11%| | 4356/40960 [00:17<02:18, 265.19batches/s, l2_loss: 0.3081 - round_loss\u001b[A\n",
      "Training:  11%| | 4356/40960 [00:17<02:18, 265.19batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:  11%| | 4405/40960 [00:17<02:21, 258.20batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:  11%| | 4405/40960 [00:17<02:21, 258.20batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:  11%| | 4458/40960 [00:18<02:20, 259.69batches/s, l2_loss: 0.3091 - round_loss\u001b[A\n",
      "Training:  11%| | 4458/40960 [00:18<02:20, 259.69batches/s, l2_loss: 0.3086 - round_loss\u001b[A\n",
      "Training:  11%| | 4511/40960 [00:18<02:20, 259.34batches/s, l2_loss: 0.3086 - round_loss\u001b[A\n",
      "Training:  11%| | 4511/40960 [00:18<02:20, 259.34batches/s, l2_loss: 0.3081 - round_loss\u001b[A\n",
      "Training:  11%| | 4573/40960 [00:18<02:12, 273.94batches/s, l2_loss: 0.3081 - round_loss\u001b[A\n",
      "Training:  11%| | 4573/40960 [00:18<02:12, 273.94batches/s, l2_loss: 0.3084 - round_loss\u001b[A\n",
      "Training:  11%| | 4634/40960 [00:18<02:08, 283.03batches/s, l2_loss: 0.3084 - round_loss\u001b[A\n",
      "Training:  11%| | 4634/40960 [00:18<02:08, 283.03batches/s, l2_loss: 0.3084 - round_loss\u001b[A\n",
      "Training:  11%| | 4696/40960 [00:18<02:04, 290.26batches/s, l2_loss: 0.3084 - round_loss\u001b[A\n",
      "Training:  11%| | 4696/40960 [00:18<02:04, 290.26batches/s, l2_loss: 0.3076 - round_loss\u001b[A\n",
      "Training:  12%| | 4752/40960 [00:19<02:06, 286.18batches/s, l2_loss: 0.3076 - round_loss\u001b[A\n",
      "Training:  12%| | 4752/40960 [00:19<02:06, 286.18batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:  12%| | 4812/40960 [00:19<02:05, 289.18batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:  12%| | 4812/40960 [00:19<02:05, 289.18batches/s, l2_loss: 0.3093 - round_loss\u001b[A\n",
      "Training:  12%| | 4872/40960 [00:19<02:03, 291.66batches/s, l2_loss: 0.3093 - round_loss\u001b[A\n",
      "Training:  12%| | 4872/40960 [00:19<02:03, 291.66batches/s, l2_loss: 0.3086 - round_loss\u001b[A\n",
      "Training:  12%| | 4927/40960 [00:19<02:05, 286.03batches/s, l2_loss: 0.3086 - round_loss\u001b[A\n",
      "Training:  12%| | 4927/40960 [00:19<02:05, 286.03batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  12%| | 4989/40960 [00:19<02:02, 293.09batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  12%| | 4989/40960 [00:19<02:02, 293.09batches/s, l2_loss: 0.3087 - round_loss\u001b[A\n",
      "Training:  12%| | 5040/40960 [00:20<02:08, 280.02batches/s, l2_loss: 0.3087 - round_loss\u001b[A\n",
      "Training:  12%| | 5040/40960 [00:20<02:08, 280.02batches/s, l2_loss: 0.3100 - round_loss\u001b[A\n",
      "Training:  12%| | 5096/40960 [00:20<02:08, 278.86batches/s, l2_loss: 0.3100 - round_loss\u001b[A\n",
      "Training:  12%| | 5096/40960 [00:20<02:08, 278.86batches/s, l2_loss: 0.3088 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5136/40960 [00:20<02:20, 255.35batches/s, l2_loss: 0.3088 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5136/40960 [00:20<02:20, 255.35batches/s, l2_loss: 0.3089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5190/40960 [00:20<02:18, 258.66batches/s, l2_loss: 0.3089 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5190/40960 [00:20<02:18, 258.66batches/s, l2_loss: 0.3088 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5246/40960 [00:20<02:15, 264.50batches/s, l2_loss: 0.3088 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5246/40960 [00:20<02:15, 264.50batches/s, l2_loss: 0.3084 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5296/40960 [00:21<02:18, 258.19batches/s, l2_loss: 0.3084 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5296/40960 [00:21<02:18, 258.19batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5349/40960 [00:21<02:17, 259.53batches/s, l2_loss: 0.3094 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5349/40960 [00:21<02:17, 259.53batches/s, l2_loss: 0.3088 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5395/40960 [00:21<02:22, 248.80batches/s, l2_loss: 0.3088 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5395/40960 [00:21<02:22, 248.80batches/s, l2_loss: 0.3086 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|▏| 5443/40960 [00:21<02:25, 244.74batches/s, l2_loss: 0.3086 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5443/40960 [00:21<02:25, 244.74batches/s, l2_loss: 0.3093 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5487/40960 [00:21<02:30, 234.94batches/s, l2_loss: 0.3093 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5487/40960 [00:21<02:30, 234.94batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5548/40960 [00:22<02:18, 254.91batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5548/40960 [00:22<02:18, 254.91batches/s, l2_loss: 0.3078 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5611/40960 [00:22<02:09, 272.22batches/s, l2_loss: 0.3078 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5611/40960 [00:22<02:09, 272.22batches/s, l2_loss: 0.3080 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5666/40960 [00:22<02:09, 272.78batches/s, l2_loss: 0.3080 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5666/40960 [00:22<02:09, 272.78batches/s, l2_loss: 0.3077 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5727/40960 [00:22<02:05, 281.24batches/s, l2_loss: 0.3077 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5727/40960 [00:22<02:05, 281.24batches/s, l2_loss: 0.3084 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5782/40960 [00:22<02:06, 278.31batches/s, l2_loss: 0.3084 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5782/40960 [00:23<02:06, 278.31batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5842/40960 [00:23<02:03, 284.45batches/s, l2_loss: 0.3085 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5842/40960 [00:23<02:03, 284.45batches/s, l2_loss: 0.3086 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5904/40960 [00:23<02:00, 291.22batches/s, l2_loss: 0.3086 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5904/40960 [00:23<02:00, 291.22batches/s, l2_loss: 0.3083 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5968/40960 [00:23<01:57, 298.71batches/s, l2_loss: 0.3083 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5968/40960 [00:23<01:57, 298.71batches/s, l2_loss: 0.3080 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6027/40960 [00:23<01:57, 297.31batches/s, l2_loss: 0.3080 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6027/40960 [00:23<01:57, 297.31batches/s, l2_loss: 0.3082 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6087/40960 [00:24<01:57, 296.09batches/s, l2_loss: 0.3082 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6087/40960 [00:24<01:57, 296.09batches/s, l2_loss: 0.3080 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6146/40960 [00:24<01:57, 295.36batches/s, l2_loss: 0.3080 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6146/40960 [00:24<01:57, 295.36batches/s, l2_loss: 0.3078 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6198/40960 [00:24<02:02, 283.26batches/s, l2_loss: 0.3078 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6198/40960 [00:24<02:02, 283.26batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6260/40960 [00:24<01:59, 290.99batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6260/40960 [00:24<01:59, 290.99batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6322/40960 [00:24<01:57, 295.35batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6322/40960 [00:24<01:57, 295.35batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6385/40960 [00:25<01:56, 297.97batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6385/40960 [00:25<01:56, 297.97batches/s, l2_loss: 0.3079 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6447/40960 [00:25<01:54, 300.41batches/s, l2_loss: 0.3079 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6447/40960 [00:25<01:54, 300.41batches/s, l2_loss: 0.3077 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6510/40960 [00:25<01:53, 304.21batches/s, l2_loss: 0.3077 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6510/40960 [00:25<01:53, 304.21batches/s, l2_loss: 0.3075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6560/40960 [00:25<01:59, 288.10batches/s, l2_loss: 0.3075 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6560/40960 [00:25<01:59, 288.10batches/s, l2_loss: 0.3073 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6613/40960 [00:25<02:02, 280.31batches/s, l2_loss: 0.3073 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6613/40960 [00:25<02:02, 280.31batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6673/40960 [00:26<01:59, 286.16batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6673/40960 [00:26<01:59, 286.16batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6734/40960 [00:26<01:57, 291.19batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6734/40960 [00:26<01:57, 291.19batches/s, l2_loss: 0.3083 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6796/40960 [00:26<01:55, 295.53batches/s, l2_loss: 0.3083 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6796/40960 [00:26<01:55, 295.53batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6855/40960 [00:26<01:55, 295.25batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6855/40960 [00:26<01:55, 295.25batches/s, l2_loss: 0.3065 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6913/40960 [00:26<01:55, 293.66batches/s, l2_loss: 0.3065 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6913/40960 [00:26<01:55, 293.66batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6968/40960 [00:27<01:58, 286.97batches/s, l2_loss: 0.3074 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6968/40960 [00:27<01:58, 286.97batches/s, l2_loss: 0.3075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7026/40960 [00:27<01:57, 287.66batches/s, l2_loss: 0.3075 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7026/40960 [00:27<01:57, 287.66batches/s, l2_loss: 0.3076 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7087/40960 [00:27<01:55, 292.51batches/s, l2_loss: 0.3076 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7087/40960 [00:27<01:55, 292.51batches/s, l2_loss: 0.3076 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7137/40960 [00:27<02:01, 278.64batches/s, l2_loss: 0.3076 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7137/40960 [00:27<02:01, 278.64batches/s, l2_loss: 0.3075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7193/40960 [00:27<02:01, 278.22batches/s, l2_loss: 0.3075 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7193/40960 [00:27<02:01, 278.22batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7247/40960 [00:28<02:02, 274.58batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7247/40960 [00:28<02:02, 274.58batches/s, l2_loss: 0.3070 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7296/40960 [00:28<02:07, 264.37batches/s, l2_loss: 0.3070 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7296/40960 [00:28<02:07, 264.37batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7346/40960 [00:28<02:09, 259.22batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7346/40960 [00:28<02:09, 259.22batches/s, l2_loss: 0.3070 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7399/40960 [00:28<02:09, 259.92batches/s, l2_loss: 0.3070 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7399/40960 [00:28<02:09, 259.92batches/s, l2_loss: 0.3071 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7455/40960 [00:28<02:06, 265.46batches/s, l2_loss: 0.3071 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7455/40960 [00:28<02:06, 265.46batches/s, l2_loss: 0.3066 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7509/40960 [00:29<02:05, 266.62batches/s, l2_loss: 0.3066 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7509/40960 [00:29<02:05, 266.62batches/s, l2_loss: 0.3063 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7568/40960 [00:29<02:01, 273.93batches/s, l2_loss: 0.3063 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7568/40960 [00:29<02:01, 273.93batches/s, l2_loss: 0.3068 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7620/40960 [00:29<02:03, 269.31batches/s, l2_loss: 0.3068 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7620/40960 [00:29<02:03, 269.31batches/s, l2_loss: 0.3077 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7682/40960 [00:29<01:58, 281.39batches/s, l2_loss: 0.3077 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7682/40960 [00:29<01:58, 281.39batches/s, l2_loss: 0.3069 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7744/40960 [00:29<01:54, 289.74batches/s, l2_loss: 0.3069 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7744/40960 [00:29<01:54, 289.74batches/s, l2_loss: 0.3075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7804/40960 [00:30<01:53, 292.54batches/s, l2_loss: 0.3075 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7804/40960 [00:30<01:53, 292.54batches/s, l2_loss: 0.3069 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7860/40960 [00:30<01:55, 287.37batches/s, l2_loss: 0.3069 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7860/40960 [00:30<01:55, 287.37batches/s, l2_loss: 0.3073 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7919/40960 [00:30<01:54, 289.39batches/s, l2_loss: 0.3073 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7919/40960 [00:30<01:54, 289.39batches/s, l2_loss: 0.3069 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7983/40960 [00:30<01:50, 297.60batches/s, l2_loss: 0.3069 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|▏| 7983/40960 [00:30<01:50, 297.60batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8047/40960 [00:30<01:48, 303.83batches/s, l2_loss: 0.3072 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8047/40960 [00:30<01:48, 303.83batches/s, l2_loss: 0.3065 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8093/40960 [00:31<01:56, 281.46batches/s, l2_loss: 0.3065 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8093/40960 [00:31<01:56, 281.46batches/s, l2_loss: 0.3064 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8156/40960 [00:31<01:52, 290.74batches/s, l2_loss: 0.3064 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8156/40960 [00:31<01:52, 290.74batches/s, l2_loss: 0.3057 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8209/40960 [00:31<01:56, 281.76batches/s, l2_loss: 0.3057 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8209/40960 [00:31<01:56, 281.76batches/s, l2_loss: 0.2141 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8260/40960 [00:31<01:59, 273.14batches/s, l2_loss: 0.2141 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8260/40960 [00:31<01:59, 273.14batches/s, l2_loss: 0.1938 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8310/40960 [00:31<02:03, 264.87batches/s, l2_loss: 0.1938 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8310/40960 [00:31<02:03, 264.87batches/s, l2_loss: 0.2780 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8369/40960 [00:32<01:59, 272.54batches/s, l2_loss: 0.2780 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8369/40960 [00:32<01:59, 272.54batches/s, l2_loss: 0.3038 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8409/40960 [00:32<02:10, 249.30batches/s, l2_loss: 0.3038 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8409/40960 [00:32<02:10, 249.30batches/s, l2_loss: 0.3157 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8452/40960 [00:32<02:16, 238.54batches/s, l2_loss: 0.3157 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8452/40960 [00:32<02:16, 238.54batches/s, l2_loss: 0.3002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8509/40960 [00:32<02:08, 252.06batches/s, l2_loss: 0.3002 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8509/40960 [00:32<02:08, 252.06batches/s, l2_loss: 0.3124 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8564/40960 [00:32<02:05, 257.95batches/s, l2_loss: 0.3124 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8564/40960 [00:32<02:05, 257.95batches/s, l2_loss: 0.3050 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8624/40960 [00:33<02:00, 269.15batches/s, l2_loss: 0.3050 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8624/40960 [00:33<02:00, 269.15batches/s, l2_loss: 0.2991 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8682/40960 [00:33<01:57, 274.68batches/s, l2_loss: 0.2991 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8682/40960 [00:33<01:57, 274.68batches/s, l2_loss: 0.2974 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8741/40960 [00:33<01:55, 279.99batches/s, l2_loss: 0.2974 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8741/40960 [00:33<01:55, 279.99batches/s, l2_loss: 0.2972 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8799/40960 [00:33<01:54, 281.77batches/s, l2_loss: 0.2972 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8799/40960 [00:33<01:54, 281.77batches/s, l2_loss: 0.2962 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8860/40960 [00:33<01:51, 287.95batches/s, l2_loss: 0.2962 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8860/40960 [00:33<01:51, 287.95batches/s, l2_loss: 0.3029 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8917/40960 [00:34<01:51, 286.93batches/s, l2_loss: 0.3029 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8917/40960 [00:34<01:51, 286.93batches/s, l2_loss: 0.3024 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8963/40960 [00:34<01:59, 268.32batches/s, l2_loss: 0.3024 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8963/40960 [00:34<01:59, 268.32batches/s, l2_loss: 0.3010 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9015/40960 [00:34<02:00, 265.27batches/s, l2_loss: 0.3010 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9015/40960 [00:34<02:00, 265.27batches/s, l2_loss: 0.2972 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9071/40960 [00:34<01:58, 269.52batches/s, l2_loss: 0.2972 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9071/40960 [00:34<01:58, 269.52batches/s, l2_loss: 0.3023 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9129/40960 [00:34<01:55, 274.49batches/s, l2_loss: 0.3023 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9129/40960 [00:34<01:55, 274.49batches/s, l2_loss: 0.3028 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9188/40960 [00:35<01:53, 279.44batches/s, l2_loss: 0.3028 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9188/40960 [00:35<01:53, 279.44batches/s, l2_loss: 0.3033 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9249/40960 [00:35<01:50, 286.22batches/s, l2_loss: 0.3033 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9249/40960 [00:35<01:50, 286.22batches/s, l2_loss: 0.2983 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9307/40960 [00:35<01:51, 285.07batches/s, l2_loss: 0.2983 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9307/40960 [00:35<01:51, 285.07batches/s, l2_loss: 0.2971 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9355/40960 [00:35<01:56, 270.76batches/s, l2_loss: 0.2971 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9355/40960 [00:35<01:56, 270.76batches/s, l2_loss: 0.3004 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9412/40960 [00:35<01:54, 274.84batches/s, l2_loss: 0.3004 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9412/40960 [00:35<01:54, 274.84batches/s, l2_loss: 0.3019 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9472/40960 [00:36<01:51, 281.54batches/s, l2_loss: 0.3019 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9472/40960 [00:36<01:51, 281.54batches/s, l2_loss: 0.3014 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9529/40960 [00:36<01:51, 281.48batches/s, l2_loss: 0.3014 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9529/40960 [00:36<01:51, 281.48batches/s, l2_loss: 0.2988 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9588/40960 [00:36<01:50, 284.98batches/s, l2_loss: 0.2988 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9588/40960 [00:36<01:50, 284.98batches/s, l2_loss: 0.3015 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9648/40960 [00:36<01:48, 288.19batches/s, l2_loss: 0.3015 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9648/40960 [00:36<01:48, 288.19batches/s, l2_loss: 0.3006 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9708/40960 [00:36<01:47, 290.57batches/s, l2_loss: 0.3006 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9708/40960 [00:36<01:47, 290.57batches/s, l2_loss: 0.3008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9766/40960 [00:37<01:47, 289.33batches/s, l2_loss: 0.3008 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9766/40960 [00:37<01:47, 289.33batches/s, l2_loss: 0.3023 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9816/40960 [00:37<01:52, 276.53batches/s, l2_loss: 0.3023 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9816/40960 [00:37<01:52, 276.53batches/s, l2_loss: 0.3034 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9854/40960 [00:37<02:04, 249.53batches/s, l2_loss: 0.3034 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9854/40960 [00:37<02:04, 249.53batches/s, l2_loss: 0.3014 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9903/40960 [00:37<02:05, 247.32batches/s, l2_loss: 0.3014 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9903/40960 [00:37<02:05, 247.32batches/s, l2_loss: 0.3007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9957/40960 [00:37<02:02, 252.88batches/s, l2_loss: 0.3007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9957/40960 [00:37<02:02, 252.88batches/s, l2_loss: 0.3017 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10011/40960 [00:38<02:00, 257.40batches/s, l2_loss: 0.3017 - round_los\u001b[A\n",
      "Training:  24%|▏| 10011/40960 [00:38<02:00, 257.40batches/s, l2_loss: 0.3036 - round_los\u001b[A\n",
      "Training:  25%|▏| 10067/40960 [00:38<01:57, 263.74batches/s, l2_loss: 0.3036 - round_los\u001b[A\n",
      "Training:  25%|▏| 10067/40960 [00:38<01:57, 263.74batches/s, l2_loss: 0.3029 - round_los\u001b[A\n",
      "Training:  25%|▏| 10127/40960 [00:38<01:52, 274.05batches/s, l2_loss: 0.3029 - round_los\u001b[A\n",
      "Training:  25%|▏| 10127/40960 [00:38<01:52, 274.05batches/s, l2_loss: 0.3038 - round_los\u001b[A\n",
      "Training:  25%|▏| 10186/40960 [00:38<01:49, 279.96batches/s, l2_loss: 0.3038 - round_los\u001b[A\n",
      "Training:  25%|▏| 10186/40960 [00:38<01:49, 279.96batches/s, l2_loss: 0.3034 - round_los\u001b[A\n",
      "Training:  25%|▎| 10246/40960 [00:38<01:47, 285.32batches/s, l2_loss: 0.3034 - round_los\u001b[A\n",
      "Training:  25%|▎| 10246/40960 [00:38<01:47, 285.32batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  25%|▎| 10304/40960 [00:39<01:47, 286.29batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  25%|▎| 10304/40960 [00:39<01:47, 286.29batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  25%|▎| 10364/40960 [00:39<01:45, 290.14batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  25%|▎| 10364/40960 [00:39<01:45, 290.14batches/s, l2_loss: 0.3013 - round_los\u001b[A\n",
      "Training:  25%|▎| 10424/40960 [00:39<01:44, 292.91batches/s, l2_loss: 0.3013 - round_los\u001b[A\n",
      "Training:  25%|▎| 10424/40960 [00:39<01:44, 292.91batches/s, l2_loss: 0.3013 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10485/40960 [00:39<01:42, 295.90batches/s, l2_loss: 0.3013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10485/40960 [00:39<01:42, 295.90batches/s, l2_loss: 0.3010 - round_los\u001b[A\n",
      "Training:  26%|▎| 10542/40960 [00:39<01:44, 292.24batches/s, l2_loss: 0.3010 - round_los\u001b[A\n",
      "Training:  26%|▎| 10542/40960 [00:39<01:44, 292.24batches/s, l2_loss: 0.3020 - round_los\u001b[A\n",
      "Training:  26%|▎| 10594/40960 [00:40<01:47, 281.96batches/s, l2_loss: 0.3020 - round_los\u001b[A\n",
      "Training:  26%|▎| 10594/40960 [00:40<01:47, 281.96batches/s, l2_loss: 0.3018 - round_los\u001b[A\n",
      "Training:  26%|▎| 10651/40960 [00:40<01:48, 279.09batches/s, l2_loss: 0.3018 - round_los\u001b[A\n",
      "Training:  26%|▎| 10651/40960 [00:40<01:48, 279.09batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  26%|▎| 10706/40960 [00:40<01:49, 276.43batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  26%|▎| 10706/40960 [00:40<01:49, 276.43batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  26%|▎| 10758/40960 [00:40<01:51, 269.74batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  26%|▎| 10758/40960 [00:40<01:51, 269.74batches/s, l2_loss: 0.3010 - round_los\u001b[A\n",
      "Training:  26%|▎| 10808/40960 [00:40<01:54, 262.45batches/s, l2_loss: 0.3010 - round_los\u001b[A\n",
      "Training:  26%|▎| 10808/40960 [00:40<01:54, 262.45batches/s, l2_loss: 0.3014 - round_los\u001b[A\n",
      "Training:  27%|▎| 10861/40960 [00:41<01:54, 262.37batches/s, l2_loss: 0.3014 - round_los\u001b[A\n",
      "Training:  27%|▎| 10861/40960 [00:41<01:54, 262.37batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  27%|▎| 10916/40960 [00:41<01:53, 264.93batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  27%|▎| 10916/40960 [00:41<01:53, 264.93batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  27%|▎| 10974/40960 [00:41<01:50, 272.13batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  27%|▎| 10974/40960 [00:41<01:50, 272.13batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  27%|▎| 11028/40960 [00:41<01:50, 271.31batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  27%|▎| 11028/40960 [00:41<01:50, 271.31batches/s, l2_loss: 0.3012 - round_los\u001b[A\n",
      "Training:  27%|▎| 11088/40960 [00:41<01:46, 279.69batches/s, l2_loss: 0.3012 - round_los\u001b[A\n",
      "Training:  27%|▎| 11088/40960 [00:41<01:46, 279.69batches/s, l2_loss: 0.3015 - round_los\u001b[A\n",
      "Training:  27%|▎| 11137/40960 [00:42<01:50, 268.98batches/s, l2_loss: 0.3015 - round_los\u001b[A\n",
      "Training:  27%|▎| 11137/40960 [00:42<01:50, 268.98batches/s, l2_loss: 0.3010 - round_los\u001b[A\n",
      "Training:  27%|▎| 11195/40960 [00:42<01:48, 275.07batches/s, l2_loss: 0.3010 - round_los\u001b[A\n",
      "Training:  27%|▎| 11195/40960 [00:42<01:48, 275.07batches/s, l2_loss: 0.3007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11255/40960 [00:42<01:45, 282.23batches/s, l2_loss: 0.3007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11255/40960 [00:42<01:45, 282.23batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11312/40960 [00:42<01:44, 282.41batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11312/40960 [00:42<01:44, 282.41batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11370/40960 [00:42<01:43, 284.55batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  28%|▎| 11370/40960 [00:42<01:43, 284.55batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11427/40960 [00:43<01:44, 283.86batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11427/40960 [00:43<01:44, 283.86batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11484/40960 [00:43<01:43, 283.74batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11484/40960 [00:43<01:43, 283.74batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11544/40960 [00:43<01:42, 287.25batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  28%|▎| 11544/40960 [00:43<01:42, 287.25batches/s, l2_loss: 0.3023 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:43<01:41, 289.39batches/s, l2_loss: 0.3023 - round_los\u001b[A\n",
      "Training:  28%|▎| 11603/40960 [00:43<01:41, 289.39batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  28%|▎| 11661/40960 [00:44<01:41, 288.63batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  28%|▎| 11661/40960 [00:44<01:41, 288.63batches/s, l2_loss: 0.3018 - round_los\u001b[A\n",
      "Training:  29%|▎| 11717/40960 [00:44<01:42, 285.06batches/s, l2_loss: 0.3018 - round_los\u001b[A\n",
      "Training:  29%|▎| 11717/40960 [00:44<01:42, 285.06batches/s, l2_loss: 0.3021 - round_los\u001b[A\n",
      "Training:  29%|▎| 11774/40960 [00:44<01:42, 283.75batches/s, l2_loss: 0.3021 - round_los\u001b[A\n",
      "Training:  29%|▎| 11774/40960 [00:44<01:42, 283.75batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11829/40960 [00:44<01:43, 280.85batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  29%|▎| 11829/40960 [00:44<01:43, 280.85batches/s, l2_loss: 0.3015 - round_los\u001b[A\n",
      "Training:  29%|▎| 11882/40960 [00:44<01:45, 276.11batches/s, l2_loss: 0.3015 - round_los\u001b[A\n",
      "Training:  29%|▎| 11882/40960 [00:44<01:45, 276.11batches/s, l2_loss: 0.3007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11937/40960 [00:45<01:45, 274.41batches/s, l2_loss: 0.3007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11937/40960 [00:45<01:45, 274.41batches/s, l2_loss: 0.3016 - round_los\u001b[A\n",
      "Training:  29%|▎| 11991/40960 [00:45<01:46, 272.54batches/s, l2_loss: 0.3016 - round_los\u001b[A\n",
      "Training:  29%|▎| 11991/40960 [00:45<01:46, 272.54batches/s, l2_loss: 0.3017 - round_los\u001b[A\n",
      "Training:  29%|▎| 12048/40960 [00:45<01:44, 275.82batches/s, l2_loss: 0.3017 - round_los\u001b[A\n",
      "Training:  29%|▎| 12048/40960 [00:45<01:44, 275.82batches/s, l2_loss: 0.3015 - round_los\u001b[A\n",
      "Training:  30%|▎| 12105/40960 [00:45<01:44, 277.30batches/s, l2_loss: 0.3015 - round_los\u001b[A\n",
      "Training:  30%|▎| 12105/40960 [00:45<01:44, 277.30batches/s, l2_loss: 0.3022 - round_los\u001b[A\n",
      "Training:  30%|▎| 12159/40960 [00:45<01:44, 274.40batches/s, l2_loss: 0.3022 - round_los\u001b[A\n",
      "Training:  30%|▎| 12159/40960 [00:45<01:44, 274.40batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  30%|▎| 12215/40960 [00:46<01:44, 275.29batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  30%|▎| 12215/40960 [00:46<01:44, 275.29batches/s, l2_loss: 0.3014 - round_los\u001b[A\n",
      "Training:  30%|▎| 12265/40960 [00:46<01:48, 265.51batches/s, l2_loss: 0.3014 - round_los\u001b[A\n",
      "Training:  30%|▎| 12265/40960 [00:46<01:48, 265.51batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12311/40960 [00:46<01:52, 254.56batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  30%|▎| 12311/40960 [00:46<01:52, 254.56batches/s, l2_loss: 0.3005 - round_los\u001b[A\n",
      "Training:  30%|▎| 12366/40960 [00:46<01:50, 259.11batches/s, l2_loss: 0.3005 - round_los\u001b[A\n",
      "Training:  30%|▎| 12366/40960 [00:46<01:50, 259.11batches/s, l2_loss: 0.3018 - round_los\u001b[A\n",
      "Training:  30%|▎| 12424/40960 [00:46<01:46, 268.19batches/s, l2_loss: 0.3018 - round_los\u001b[A\n",
      "Training:  30%|▎| 12424/40960 [00:46<01:46, 268.19batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  30%|▎| 12482/40960 [00:47<01:43, 274.38batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  30%|▎| 12482/40960 [00:47<01:43, 274.38batches/s, l2_loss: 0.3014 - round_los\u001b[A\n",
      "Training:  31%|▎| 12542/40960 [00:47<01:41, 281.16batches/s, l2_loss: 0.3014 - round_los\u001b[A\n",
      "Training:  31%|▎| 12542/40960 [00:47<01:41, 281.16batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  31%|▎| 12601/40960 [00:47<01:39, 284.50batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  31%|▎| 12601/40960 [00:47<01:39, 284.50batches/s, l2_loss: 0.3014 - round_los\u001b[A\n",
      "Training:  31%|▎| 12660/40960 [00:47<01:38, 287.30batches/s, l2_loss: 0.3014 - round_los\u001b[A\n",
      "Training:  31%|▎| 12660/40960 [00:47<01:38, 287.30batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12715/40960 [00:47<01:39, 283.57batches/s, l2_loss: 0.3008 - round_los\u001b[A\n",
      "Training:  31%|▎| 12715/40960 [00:47<01:39, 283.57batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  31%|▎| 12768/40960 [00:48<01:41, 276.74batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  31%|▎| 12768/40960 [00:48<01:41, 276.74batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  31%|▎| 12826/40960 [00:48<01:40, 280.64batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  31%|▎| 12826/40960 [00:48<01:40, 280.64batches/s, l2_loss: 0.3007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12883/40960 [00:48<01:39, 280.87batches/s, l2_loss: 0.3007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12883/40960 [00:48<01:39, 280.87batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  32%|▎| 12940/40960 [00:48<01:40, 280.20batches/s, l2_loss: 0.2996 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 12940/40960 [00:48<01:40, 280.20batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  32%|▎| 12996/40960 [00:48<01:39, 280.04batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  32%|▎| 12996/40960 [00:48<01:39, 280.04batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13052/40960 [00:49<01:39, 279.30batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  32%|▎| 13052/40960 [00:49<01:39, 279.30batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  32%|▎| 13104/40960 [00:49<01:42, 272.41batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  32%|▎| 13104/40960 [00:49<01:42, 272.41batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  32%|▎| 13155/40960 [00:49<01:44, 265.18batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  32%|▎| 13155/40960 [00:49<01:44, 265.18batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  32%|▎| 13210/40960 [00:49<01:44, 266.38batches/s, l2_loss: 0.3006 - round_los\u001b[A\n",
      "Training:  32%|▎| 13210/40960 [00:49<01:44, 266.38batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  32%|▎| 13265/40960 [00:49<01:43, 268.78batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  32%|▎| 13265/40960 [00:49<01:43, 268.78batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  33%|▎| 13324/40960 [00:50<01:40, 275.75batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  33%|▎| 13324/40960 [00:50<01:40, 275.75batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  33%|▎| 13381/40960 [00:50<01:39, 277.72batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  33%|▎| 13381/40960 [00:50<01:39, 277.72batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  33%|▎| 13440/40960 [00:50<01:37, 281.93batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  33%|▎| 13440/40960 [00:50<01:37, 281.93batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  33%|▎| 13500/40960 [00:50<01:36, 285.90batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  33%|▎| 13500/40960 [00:50<01:36, 285.90batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  33%|▎| 13553/40960 [00:50<01:38, 278.53batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  33%|▎| 13553/40960 [00:50<01:38, 278.53batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  33%|▎| 13614/40960 [00:51<01:35, 285.28batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  33%|▎| 13614/40960 [00:51<01:35, 285.28batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  33%|▎| 13674/40960 [00:51<01:34, 288.74batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  33%|▎| 13674/40960 [00:51<01:34, 288.74batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  34%|▎| 13725/40960 [00:51<01:38, 276.50batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  34%|▎| 13725/40960 [00:51<01:38, 276.50batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  34%|▎| 13778/40960 [00:51<01:39, 272.34batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  34%|▎| 13778/40960 [00:51<01:39, 272.34batches/s, l2_loss: 0.3005 - round_los\u001b[A\n",
      "Training:  34%|▎| 13834/40960 [00:51<01:39, 273.17batches/s, l2_loss: 0.3005 - round_los\u001b[A\n",
      "Training:  34%|▎| 13834/40960 [00:51<01:39, 273.17batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  34%|▎| 13894/40960 [00:52<01:36, 279.92batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  34%|▎| 13894/40960 [00:52<01:36, 279.92batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13947/40960 [00:52<01:38, 274.75batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  34%|▎| 13947/40960 [00:52<01:38, 274.75batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  34%|▎| 13998/40960 [00:52<01:40, 267.69batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  34%|▎| 13998/40960 [00:52<01:40, 267.69batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  34%|▎| 14054/40960 [00:52<01:39, 270.20batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  34%|▎| 14054/40960 [00:52<01:39, 270.20batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  34%|▎| 14111/40960 [00:52<01:37, 274.05batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  34%|▎| 14111/40960 [00:52<01:37, 274.05batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  35%|▎| 14166/40960 [00:53<01:37, 273.64batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  35%|▎| 14166/40960 [00:53<01:37, 273.64batches/s, l2_loss: 0.3005 - round_los\u001b[A\n",
      "Training:  35%|▎| 14219/40960 [00:53<01:38, 270.93batches/s, l2_loss: 0.3005 - round_los\u001b[A\n",
      "Training:  35%|▎| 14219/40960 [00:53<01:38, 270.93batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  35%|▎| 14277/40960 [00:53<01:36, 275.33batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  35%|▎| 14277/40960 [00:53<01:36, 275.33batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  35%|▎| 14332/40960 [00:53<01:36, 274.97batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  35%|▎| 14332/40960 [00:53<01:36, 274.97batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14390/40960 [00:53<01:35, 278.84batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14390/40960 [00:53<01:35, 278.84batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14445/40960 [00:54<01:35, 277.37batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  35%|▎| 14445/40960 [00:54<01:35, 277.37batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  35%|▎| 14492/40960 [00:54<01:40, 262.71batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  35%|▎| 14492/40960 [00:54<01:40, 262.71batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  36%|▎| 14542/40960 [00:54<01:42, 257.74batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  36%|▎| 14542/40960 [00:54<01:42, 257.74batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  36%|▎| 14593/40960 [00:54<01:43, 255.88batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  36%|▎| 14593/40960 [00:54<01:43, 255.88batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  36%|▎| 14643/40960 [00:54<01:43, 253.59batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  36%|▎| 14643/40960 [00:54<01:43, 253.59batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  36%|▎| 14697/40960 [00:55<01:42, 257.46batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  36%|▎| 14697/40960 [00:55<01:42, 257.46batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  36%|▎| 14745/40960 [00:55<01:44, 251.29batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  36%|▎| 14745/40960 [00:55<01:44, 251.29batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  36%|▎| 14797/40960 [00:55<01:43, 253.88batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  36%|▎| 14797/40960 [00:55<01:43, 253.88batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  36%|▎| 14852/40960 [00:55<01:40, 259.76batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  36%|▎| 14852/40960 [00:55<01:40, 259.76batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  36%|▎| 14904/40960 [00:55<01:40, 258.40batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  36%|▎| 14904/40960 [00:55<01:40, 258.40batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  37%|▎| 14954/40960 [00:56<01:41, 255.35batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  37%|▎| 14954/40960 [00:56<01:41, 255.35batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  37%|▎| 15008/40960 [00:56<01:40, 259.36batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  37%|▎| 15008/40960 [00:56<01:40, 259.36batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  37%|▎| 15064/40960 [00:56<01:37, 264.76batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  37%|▎| 15064/40960 [00:56<01:37, 264.76batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  37%|▎| 15118/40960 [00:56<01:37, 265.61batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  37%|▎| 15118/40960 [00:56<01:37, 265.61batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  37%|▎| 15177/40960 [00:56<01:34, 273.85batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  37%|▎| 15177/40960 [00:56<01:34, 273.85batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  37%|▎| 15237/40960 [00:57<01:31, 281.37batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  37%|▎| 15237/40960 [00:57<01:31, 281.37batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  37%|▎| 15293/40960 [00:57<01:31, 280.22batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  37%|▎| 15293/40960 [00:57<01:31, 280.22batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  37%|▎| 15352/40960 [00:57<01:30, 283.61batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  37%|▎| 15352/40960 [00:57<01:30, 283.61batches/s, l2_loss: 0.3000 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|▍| 15412/40960 [00:57<01:28, 287.98batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  38%|▍| 15412/40960 [00:57<01:28, 287.98batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  38%|▍| 15466/40960 [00:57<01:30, 282.61batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  38%|▍| 15466/40960 [00:57<01:30, 282.61batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  38%|▍| 15518/40960 [00:58<01:32, 275.36batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  38%|▍| 15518/40960 [00:58<01:32, 275.36batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  38%|▍| 15569/40960 [00:58<01:34, 268.15batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  38%|▍| 15569/40960 [00:58<01:34, 268.15batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  38%|▍| 15622/40960 [00:58<01:35, 266.10batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  38%|▍| 15622/40960 [00:58<01:35, 266.10batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15685/40960 [00:58<01:30, 279.60batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  38%|▍| 15685/40960 [00:58<01:30, 279.60batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  38%|▍| 15744/40960 [00:58<01:28, 283.97batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  38%|▍| 15744/40960 [00:58<01:28, 283.97batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  39%|▍| 15805/40960 [00:59<01:26, 289.88batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  39%|▍| 15805/40960 [00:59<01:26, 289.88batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  39%|▍| 15860/40960 [00:59<01:28, 285.18batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  39%|▍| 15860/40960 [00:59<01:28, 285.18batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  39%|▍| 15919/40960 [00:59<01:27, 287.04batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  39%|▍| 15919/40960 [00:59<01:27, 287.04batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  39%|▍| 15975/40960 [00:59<01:27, 284.47batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  39%|▍| 15975/40960 [00:59<01:27, 284.47batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  39%|▍| 16033/40960 [00:59<01:27, 284.95batches/s, l2_loss: 0.3002 - round_los\u001b[A\n",
      "Training:  39%|▍| 16033/40960 [00:59<01:27, 284.95batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  39%|▍| 16092/40960 [01:00<01:26, 287.35batches/s, l2_loss: 0.3001 - round_los\u001b[A\n",
      "Training:  39%|▍| 16092/40960 [01:00<01:26, 287.35batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  39%|▍| 16150/40960 [01:00<01:26, 287.36batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  39%|▍| 16150/40960 [01:00<01:26, 287.36batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  40%|▍| 16208/40960 [01:00<01:26, 287.56batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  40%|▍| 16208/40960 [01:00<01:26, 287.56batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  40%|▍| 16269/40960 [01:00<01:24, 292.06batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  40%|▍| 16269/40960 [01:00<01:24, 292.06batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  40%|▍| 16325/40960 [01:00<01:25, 287.39batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  40%|▍| 16325/40960 [01:00<01:25, 287.39batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  40%|▍| 16379/40960 [01:01<01:27, 281.62batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  40%|▍| 16379/40960 [01:01<01:27, 281.62batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  40%|▍| 16437/40960 [01:01<01:26, 283.08batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  40%|▍| 16437/40960 [01:01<01:26, 283.08batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  40%|▍| 16495/40960 [01:01<01:25, 284.64batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  40%|▍| 16495/40960 [01:01<01:25, 284.64batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  40%|▍| 16554/40960 [01:01<01:24, 287.45batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  40%|▍| 16554/40960 [01:01<01:24, 287.45batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  41%|▍| 16610/40960 [01:01<01:25, 284.59batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  41%|▍| 16610/40960 [01:01<01:25, 284.59batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  41%|▍| 16660/40960 [01:02<01:28, 273.52batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  41%|▍| 16660/40960 [01:02<01:28, 273.52batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  41%|▍| 16717/40960 [01:02<01:27, 276.53batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  41%|▍| 16717/40960 [01:02<01:27, 276.53batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  41%|▍| 16776/40960 [01:02<01:25, 281.90batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  41%|▍| 16776/40960 [01:02<01:25, 281.90batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  41%|▍| 16829/40960 [01:02<01:27, 276.68batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  41%|▍| 16829/40960 [01:02<01:27, 276.68batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  41%|▍| 16879/40960 [01:02<01:30, 267.23batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  41%|▍| 16879/40960 [01:02<01:30, 267.23batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  41%|▍| 16933/40960 [01:03<01:29, 267.21batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  41%|▍| 16933/40960 [01:03<01:29, 267.21batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  41%|▍| 16987/40960 [01:03<01:29, 267.84batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  41%|▍| 16987/40960 [01:03<01:29, 267.84batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  42%|▍| 17042/40960 [01:03<01:28, 269.17batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  42%|▍| 17042/40960 [01:03<01:28, 269.17batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  42%|▍| 17102/40960 [01:03<01:26, 277.37batches/s, l2_loss: 0.3000 - round_los\u001b[A\n",
      "Training:  42%|▍| 17102/40960 [01:03<01:26, 277.37batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  42%|▍| 17150/40960 [01:03<01:29, 265.43batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  42%|▍| 17150/40960 [01:04<01:29, 265.43batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  42%|▍| 17208/40960 [01:04<01:27, 272.63batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  42%|▍| 17208/40960 [01:04<01:27, 272.63batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  42%|▍| 17265/40960 [01:04<01:26, 275.31batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  42%|▍| 17265/40960 [01:04<01:26, 275.31batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  42%|▍| 17320/40960 [01:04<01:26, 274.30batches/s, l2_loss: 0.2999 - round_los\u001b[A\n",
      "Training:  42%|▍| 17320/40960 [01:04<01:26, 274.30batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  42%|▍| 17378/40960 [01:04<01:24, 278.93batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  42%|▍| 17378/40960 [01:04<01:24, 278.93batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  43%|▍| 17435/40960 [01:05<01:24, 279.14batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  43%|▍| 17435/40960 [01:05<01:24, 279.14batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  43%|▍| 17489/40960 [01:05<01:25, 275.42batches/s, l2_loss: 0.3003 - round_los\u001b[A\n",
      "Training:  43%|▍| 17489/40960 [01:05<01:25, 275.42batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  43%|▍| 17546/40960 [01:05<01:24, 277.19batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  43%|▍| 17546/40960 [01:05<01:24, 277.19batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  43%|▍| 17601/40960 [01:05<01:24, 276.08batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  43%|▍| 17601/40960 [01:05<01:24, 276.08batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  43%|▍| 17657/40960 [01:05<01:24, 276.41batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  43%|▍| 17657/40960 [01:05<01:24, 276.41batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  43%|▍| 17715/40960 [01:06<01:23, 279.64batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  43%|▍| 17715/40960 [01:06<01:23, 279.64batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  43%|▍| 17772/40960 [01:06<01:22, 280.84batches/s, l2_loss: 0.3004 - round_los\u001b[A\n",
      "Training:  43%|▍| 17772/40960 [01:06<01:22, 280.84batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  44%|▍| 17830/40960 [01:06<01:21, 282.97batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  44%|▍| 17830/40960 [01:06<01:21, 282.97batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  44%|▍| 17888/40960 [01:06<01:21, 284.61batches/s, l2_loss: 0.2992 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 17888/40960 [01:06<01:21, 284.61batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  44%|▍| 17947/40960 [01:06<01:20, 286.70batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  44%|▍| 17947/40960 [01:06<01:20, 286.70batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  44%|▍| 18007/40960 [01:07<01:19, 289.74batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  44%|▍| 18007/40960 [01:07<01:19, 289.74batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  44%|▍| 18064/40960 [01:07<01:19, 286.87batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  44%|▍| 18064/40960 [01:07<01:19, 286.87batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  44%|▍| 18122/40960 [01:07<01:19, 286.74batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  44%|▍| 18122/40960 [01:07<01:19, 286.74batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  44%|▍| 18180/40960 [01:07<01:19, 287.68batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  44%|▍| 18180/40960 [01:07<01:19, 287.68batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  45%|▍| 18232/40960 [01:07<01:21, 278.31batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  45%|▍| 18232/40960 [01:07<01:21, 278.31batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  45%|▍| 18291/40960 [01:08<01:20, 281.70batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  45%|▍| 18291/40960 [01:08<01:20, 281.70batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  45%|▍| 18349/40960 [01:08<01:19, 283.85batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  45%|▍| 18349/40960 [01:08<01:19, 283.85batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  45%|▍| 18410/40960 [01:08<01:17, 289.53batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  45%|▍| 18410/40960 [01:08<01:17, 289.53batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  45%|▍| 18470/40960 [01:08<01:17, 292.04batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  45%|▍| 18470/40960 [01:08<01:17, 292.04batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  45%|▍| 18527/40960 [01:08<01:17, 289.08batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  45%|▍| 18527/40960 [01:08<01:17, 289.08batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  45%|▍| 18587/40960 [01:09<01:16, 291.01batches/s, l2_loss: 0.2997 - round_los\u001b[A\n",
      "Training:  45%|▍| 18587/40960 [01:09<01:16, 291.01batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  46%|▍| 18647/40960 [01:09<01:15, 293.68batches/s, l2_loss: 0.2998 - round_los\u001b[A\n",
      "Training:  46%|▍| 18647/40960 [01:09<01:15, 293.68batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  46%|▍| 18696/40960 [01:09<01:20, 277.16batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  46%|▍| 18696/40960 [01:09<01:20, 277.16batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  46%|▍| 18753/40960 [01:09<01:19, 278.89batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  46%|▍| 18753/40960 [01:09<01:19, 278.89batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  46%|▍| 18815/40960 [01:09<01:17, 287.00batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  46%|▍| 18815/40960 [01:09<01:17, 287.00batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  46%|▍| 18870/40960 [01:10<01:18, 282.11batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  46%|▍| 18870/40960 [01:10<01:18, 282.11batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  46%|▍| 18926/40960 [01:10<01:18, 280.95batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  46%|▍| 18926/40960 [01:10<01:18, 280.95batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  46%|▍| 18987/40960 [01:10<01:16, 286.80batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  46%|▍| 18987/40960 [01:10<01:16, 286.80batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  46%|▍| 19045/40960 [01:10<01:16, 286.87batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  46%|▍| 19045/40960 [01:10<01:16, 286.87batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  47%|▍| 19102/40960 [01:10<01:16, 285.38batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  47%|▍| 19102/40960 [01:10<01:16, 285.38batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  47%|▍| 19160/40960 [01:11<01:16, 285.92batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  47%|▍| 19160/40960 [01:11<01:16, 285.92batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  47%|▍| 19218/40960 [01:11<01:15, 286.26batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  47%|▍| 19218/40960 [01:11<01:15, 286.26batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  47%|▍| 19277/40960 [01:11<01:15, 288.46batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  47%|▍| 19277/40960 [01:11<01:15, 288.46batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  47%|▍| 19336/40960 [01:11<01:14, 289.19batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  47%|▍| 19336/40960 [01:11<01:14, 289.19batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  47%|▍| 19396/40960 [01:11<01:14, 291.07batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  47%|▍| 19396/40960 [01:11<01:14, 291.07batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  47%|▍| 19454/40960 [01:12<01:14, 290.11batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  47%|▍| 19454/40960 [01:12<01:14, 290.11batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  48%|▍| 19513/40960 [01:12<01:13, 291.42batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  48%|▍| 19513/40960 [01:12<01:13, 291.42batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  48%|▍| 19574/40960 [01:12<01:12, 294.96batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  48%|▍| 19574/40960 [01:12<01:12, 294.96batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  48%|▍| 19633/40960 [01:12<01:12, 294.36batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  48%|▍| 19633/40960 [01:12<01:12, 294.36batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  48%|▍| 19691/40960 [01:12<01:12, 291.60batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  48%|▍| 19691/40960 [01:12<01:12, 291.60batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  48%|▍| 19753/40960 [01:13<01:11, 296.21batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  48%|▍| 19753/40960 [01:13<01:11, 296.21batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  48%|▍| 19813/40960 [01:13<01:11, 296.12batches/s, l2_loss: 0.2995 - round_los\u001b[A\n",
      "Training:  48%|▍| 19813/40960 [01:13<01:11, 296.12batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  49%|▍| 19871/40960 [01:13<01:11, 294.24batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  49%|▍| 19871/40960 [01:13<01:11, 294.24batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  49%|▍| 19927/40960 [01:13<01:12, 289.34batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  49%|▍| 19927/40960 [01:13<01:12, 289.34batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  49%|▍| 19985/40960 [01:13<01:12, 288.25batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  49%|▍| 19985/40960 [01:13<01:12, 288.25batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  49%|▍| 20039/40960 [01:14<01:14, 281.77batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  49%|▍| 20039/40960 [01:14<01:14, 281.77batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  49%|▍| 20097/40960 [01:14<01:13, 282.86batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  49%|▍| 20097/40960 [01:14<01:13, 282.86batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  49%|▍| 20158/40960 [01:14<01:12, 288.47batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  49%|▍| 20158/40960 [01:14<01:12, 288.47batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  49%|▍| 20208/40960 [01:14<01:15, 276.12batches/s, l2_loss: 0.2996 - round_los\u001b[A\n",
      "Training:  49%|▍| 20208/40960 [01:14<01:15, 276.12batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  49%|▍| 20264/40960 [01:14<01:14, 276.12batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  49%|▍| 20264/40960 [01:14<01:14, 276.12batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  50%|▍| 20322/40960 [01:15<01:13, 279.16batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  50%|▍| 20322/40960 [01:15<01:13, 279.16batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  50%|▍| 20381/40960 [01:15<01:12, 283.45batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  50%|▍| 20381/40960 [01:15<01:12, 283.45batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  50%|▍| 20433/40960 [01:15<01:14, 275.38batches/s, l2_loss: 0.2994 - round_los\u001b[A\n",
      "Training:  50%|▍| 20433/40960 [01:15<01:14, 275.38batches/s, l2_loss: 0.2992 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 20491/40960 [01:15<01:13, 278.97batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  50%|▌| 20491/40960 [01:15<01:13, 278.97batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  50%|▌| 20546/40960 [01:15<01:13, 276.82batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  50%|▌| 20546/40960 [01:15<01:13, 276.82batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  50%|▌| 20607/40960 [01:16<01:11, 284.47batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  50%|▌| 20607/40960 [01:16<01:11, 284.47batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  50%|▌| 20661/40960 [01:16<01:12, 279.40batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  50%|▌| 20661/40960 [01:16<01:12, 279.40batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  51%|▌| 20715/40960 [01:16<01:13, 274.96batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  51%|▌| 20715/40960 [01:16<01:13, 274.96batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  51%|▌| 20773/40960 [01:16<01:12, 278.95batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  51%|▌| 20773/40960 [01:16<01:12, 278.95batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  51%|▌| 20831/40960 [01:16<01:11, 281.05batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  51%|▌| 20831/40960 [01:16<01:11, 281.05batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  51%|▌| 20882/40960 [01:17<01:13, 271.48batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  51%|▌| 20882/40960 [01:17<01:13, 271.48batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  51%|▌| 20926/40960 [01:17<01:18, 256.19batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  51%|▌| 20926/40960 [01:17<01:18, 256.19batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  51%|▌| 20977/40960 [01:17<01:18, 255.72batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  51%|▌| 20977/40960 [01:17<01:18, 255.72batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  51%|▌| 21029/40960 [01:17<01:17, 256.00batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  51%|▌| 21029/40960 [01:17<01:17, 256.00batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  51%|▌| 21089/40960 [01:17<01:13, 268.83batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  51%|▌| 21089/40960 [01:17<01:13, 268.83batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  52%|▌| 21148/40960 [01:18<01:11, 276.31batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  52%|▌| 21148/40960 [01:18<01:11, 276.31batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  52%|▌| 21205/40960 [01:18<01:10, 278.51batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  52%|▌| 21205/40960 [01:18<01:10, 278.51batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  52%|▌| 21258/40960 [01:18<01:12, 273.52batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  52%|▌| 21258/40960 [01:18<01:12, 273.52batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  52%|▌| 21314/40960 [01:18<01:11, 275.07batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  52%|▌| 21314/40960 [01:18<01:11, 275.07batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  52%|▌| 21372/40960 [01:18<01:10, 278.89batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  52%|▌| 21372/40960 [01:18<01:10, 278.89batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  52%|▌| 21427/40960 [01:19<01:10, 276.97batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  52%|▌| 21427/40960 [01:19<01:10, 276.97batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  52%|▌| 21482/40960 [01:19<01:10, 275.60batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  52%|▌| 21482/40960 [01:19<01:10, 275.60batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  53%|▌| 21540/40960 [01:19<01:09, 279.82batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  53%|▌| 21540/40960 [01:19<01:09, 279.82batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  53%|▌| 21597/40960 [01:19<01:08, 281.32batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  53%|▌| 21597/40960 [01:19<01:08, 281.32batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  53%|▌| 21651/40960 [01:19<01:09, 276.77batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  53%|▌| 21651/40960 [01:19<01:09, 276.77batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  53%|▌| 21706/40960 [01:20<01:09, 276.04batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  53%|▌| 21706/40960 [01:20<01:09, 276.04batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  53%|▌| 21759/40960 [01:20<01:10, 271.71batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  53%|▌| 21759/40960 [01:20<01:10, 271.71batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  53%|▌| 21811/40960 [01:20<01:11, 267.70batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  53%|▌| 21811/40960 [01:20<01:11, 267.70batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  53%|▌| 21870/40960 [01:20<01:09, 274.76batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  53%|▌| 21870/40960 [01:20<01:09, 274.76batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  54%|▌| 21927/40960 [01:20<01:08, 277.36batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  54%|▌| 21927/40960 [01:20<01:08, 277.36batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  54%|▌| 21984/40960 [01:21<01:08, 278.57batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  54%|▌| 21984/40960 [01:21<01:08, 278.57batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  54%|▌| 22032/40960 [01:21<01:10, 266.99batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  54%|▌| 22032/40960 [01:21<01:10, 266.99batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  54%|▌| 22085/40960 [01:21<01:11, 265.54batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  54%|▌| 22085/40960 [01:21<01:11, 265.54batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  54%|▌| 22141/40960 [01:21<01:09, 269.24batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  54%|▌| 22141/40960 [01:21<01:09, 269.24batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  54%|▌| 22195/40960 [01:21<01:09, 269.38batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  54%|▌| 22195/40960 [01:21<01:09, 269.38batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  54%|▌| 22255/40960 [01:22<01:07, 277.49batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  54%|▌| 22255/40960 [01:22<01:07, 277.49batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  54%|▌| 22312/40960 [01:22<01:06, 279.22batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  54%|▌| 22312/40960 [01:22<01:06, 279.22batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  55%|▌| 22371/40960 [01:22<01:05, 283.80batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  55%|▌| 22371/40960 [01:22<01:05, 283.80batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  55%|▌| 22427/40960 [01:22<01:05, 282.30batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  55%|▌| 22427/40960 [01:22<01:05, 282.30batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  55%|▌| 22484/40960 [01:22<01:05, 282.72batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  55%|▌| 22484/40960 [01:22<01:05, 282.72batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  55%|▌| 22540/40960 [01:23<01:05, 280.40batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  55%|▌| 22540/40960 [01:23<01:05, 280.40batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  55%|▌| 22601/40960 [01:23<01:03, 287.35batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  55%|▌| 22601/40960 [01:23<01:03, 287.35batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  55%|▌| 22662/40960 [01:23<01:02, 291.84batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  55%|▌| 22662/40960 [01:23<01:02, 291.84batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  55%|▌| 22711/40960 [01:23<01:05, 276.58batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  55%|▌| 22711/40960 [01:23<01:05, 276.58batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  56%|▌| 22761/40960 [01:23<01:07, 268.37batches/s, l2_loss: 0.2993 - round_los\u001b[A\n",
      "Training:  56%|▌| 22761/40960 [01:23<01:07, 268.37batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  56%|▌| 22814/40960 [01:24<01:07, 267.20batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  56%|▌| 22814/40960 [01:24<01:07, 267.20batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  56%|▌| 22869/40960 [01:24<01:07, 268.02batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  56%|▌| 22869/40960 [01:24<01:07, 268.02batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  56%|▌| 22919/40960 [01:24<01:09, 260.82batches/s, l2_loss: 0.2986 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|▌| 22919/40960 [01:24<01:09, 260.82batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  56%|▌| 22970/40960 [01:24<01:09, 258.78batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  56%|▌| 22970/40960 [01:24<01:09, 258.78batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  56%|▌| 23029/40960 [01:24<01:06, 268.66batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  56%|▌| 23029/40960 [01:24<01:06, 268.66batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  56%|▌| 23081/40960 [01:25<01:07, 266.03batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  56%|▌| 23081/40960 [01:25<01:07, 266.03batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  56%|▌| 23137/40960 [01:25<01:05, 270.06batches/s, l2_loss: 0.2991 - round_los\u001b[A\n",
      "Training:  56%|▌| 23137/40960 [01:25<01:05, 270.06batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  57%|▌| 23195/40960 [01:25<01:04, 275.52batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  57%|▌| 23195/40960 [01:25<01:04, 275.52batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  57%|▌| 23255/40960 [01:25<01:02, 282.62batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  57%|▌| 23255/40960 [01:25<01:02, 282.62batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  57%|▌| 23310/40960 [01:25<01:03, 279.93batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  57%|▌| 23310/40960 [01:26<01:03, 279.93batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  57%|▌| 23365/40960 [01:26<01:03, 278.10batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  57%|▌| 23365/40960 [01:26<01:03, 278.10batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  57%|▌| 23417/40960 [01:26<01:04, 270.73batches/s, l2_loss: 0.2992 - round_los\u001b[A\n",
      "Training:  57%|▌| 23417/40960 [01:26<01:04, 270.73batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  57%|▌| 23471/40960 [01:26<01:04, 269.66batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  57%|▌| 23471/40960 [01:26<01:04, 269.66batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  57%|▌| 23527/40960 [01:26<01:03, 272.45batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  57%|▌| 23527/40960 [01:26<01:03, 272.45batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  58%|▌| 23582/40960 [01:27<01:03, 272.55batches/s, l2_loss: 0.2990 - round_los\u001b[A\n",
      "Training:  58%|▌| 23582/40960 [01:27<01:03, 272.55batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23640/40960 [01:27<01:02, 277.58batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23640/40960 [01:27<01:02, 277.58batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23699/40960 [01:27<01:01, 281.73batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23699/40960 [01:27<01:01, 281.73batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23758/40960 [01:27<01:00, 283.59batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23758/40960 [01:27<01:00, 283.59batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  58%|▌| 23818/40960 [01:27<00:59, 287.76batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  58%|▌| 23818/40960 [01:27<00:59, 287.76batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23877/40960 [01:28<00:59, 289.00batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23877/40960 [01:28<00:59, 289.00batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23910/40960 [01:28<01:07, 251.17batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  58%|▌| 23910/40960 [01:28<01:07, 251.17batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  59%|▌| 23969/40960 [01:28<01:04, 263.24batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  59%|▌| 23969/40960 [01:28<01:04, 263.24batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  59%|▌| 24029/40960 [01:28<01:01, 274.06batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  59%|▌| 24029/40960 [01:28<01:01, 274.06batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  59%|▌| 24082/40960 [01:28<01:02, 269.98batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  59%|▌| 24082/40960 [01:28<01:02, 269.98batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  59%|▌| 24138/40960 [01:29<01:01, 271.89batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  59%|▌| 24138/40960 [01:29<01:01, 271.89batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  59%|▌| 24199/40960 [01:29<00:59, 281.09batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  59%|▌| 24199/40960 [01:29<00:59, 281.09batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  59%|▌| 24258/40960 [01:29<00:58, 284.41batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  59%|▌| 24258/40960 [01:29<00:58, 284.41batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  59%|▌| 24312/40960 [01:29<00:59, 279.26batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  59%|▌| 24312/40960 [01:29<00:59, 279.26batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  59%|▌| 24369/40960 [01:29<00:59, 280.39batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  59%|▌| 24369/40960 [01:29<00:59, 280.39batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  60%|▌| 24428/40960 [01:30<00:58, 283.97batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  60%|▌| 24428/40960 [01:30<00:58, 283.97batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  60%|▌| 24483/40960 [01:30<00:58, 279.69batches/s, l2_loss: 0.2989 - round_los\u001b[A\n",
      "Training:  60%|▌| 24483/40960 [01:30<00:58, 279.69batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  60%|▌| 24536/40960 [01:30<00:59, 275.02batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  60%|▌| 24536/40960 [01:30<00:59, 275.02batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  60%|▌| 24591/40960 [01:30<00:59, 274.54batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  60%|▌| 24591/40960 [01:30<00:59, 274.54batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  60%|▌| 24649/40960 [01:30<00:58, 278.78batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  60%|▌| 24649/40960 [01:30<00:58, 278.78batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  60%|▌| 24708/40960 [01:31<00:57, 283.15batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  60%|▌| 24708/40960 [01:31<00:57, 283.15batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  60%|▌| 24766/40960 [01:31<00:56, 284.65batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  60%|▌| 24766/40960 [01:31<00:56, 284.65batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [01:31<00:55, 288.18batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [01:31<00:55, 288.18batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  61%|▌| 24885/40960 [01:31<00:55, 289.08batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  61%|▌| 24885/40960 [01:31<00:55, 289.08batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  61%|▌| 24944/40960 [01:31<00:55, 290.46batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  61%|▌| 24944/40960 [01:31<00:55, 290.46batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  61%|▌| 25002/40960 [01:32<00:55, 289.54batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  61%|▌| 25002/40960 [01:32<00:55, 289.54batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  61%|▌| 25056/40960 [01:32<00:56, 282.96batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  61%|▌| 25056/40960 [01:32<00:56, 282.96batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  61%|▌| 25116/40960 [01:32<00:55, 287.19batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  61%|▌| 25116/40960 [01:32<00:55, 287.19batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  61%|▌| 25174/40960 [01:32<00:55, 286.56batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  61%|▌| 25174/40960 [01:32<00:55, 286.56batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  62%|▌| 25232/40960 [01:32<00:54, 286.28batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  62%|▌| 25232/40960 [01:32<00:54, 286.28batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  62%|▌| 25286/40960 [01:33<00:55, 281.27batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  62%|▌| 25286/40960 [01:33<00:55, 281.27batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  62%|▌| 25346/40960 [01:33<00:54, 285.68batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  62%|▌| 25346/40960 [01:33<00:54, 285.68batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  62%|▌| 25403/40960 [01:33<00:54, 284.88batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  62%|▌| 25403/40960 [01:33<00:54, 284.88batches/s, l2_loss: 0.2985 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|▌| 25456/40960 [01:33<00:55, 278.78batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  62%|▌| 25456/40960 [01:33<00:55, 278.78batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  62%|▌| 25511/40960 [01:33<00:55, 277.02batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  62%|▌| 25511/40960 [01:33<00:55, 277.02batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  62%|▌| 25560/40960 [01:34<00:57, 267.25batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  62%|▌| 25560/40960 [01:34<00:57, 267.25batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  63%|▋| 25613/40960 [01:34<00:57, 266.31batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  63%|▋| 25613/40960 [01:34<00:57, 266.31batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  63%|▋| 25671/40960 [01:34<00:55, 273.15batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  63%|▋| 25671/40960 [01:34<00:55, 273.15batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  63%|▋| 25723/40960 [01:34<00:56, 268.82batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  63%|▋| 25723/40960 [01:34<00:56, 268.82batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  63%|▋| 25781/40960 [01:34<00:55, 274.71batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  63%|▋| 25781/40960 [01:34<00:55, 274.71batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  63%|▋| 25839/40960 [01:35<00:54, 278.50batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  63%|▋| 25839/40960 [01:35<00:54, 278.50batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  63%|▋| 25895/40960 [01:35<00:54, 278.45batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  63%|▋| 25895/40960 [01:35<00:54, 278.45batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  63%|▋| 25953/40960 [01:35<00:53, 281.40batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  63%|▋| 25953/40960 [01:35<00:53, 281.40batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  64%|▋| 26012/40960 [01:35<00:52, 284.80batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  64%|▋| 26012/40960 [01:35<00:52, 284.80batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  64%|▋| 26071/40960 [01:35<00:51, 286.59batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  64%|▋| 26071/40960 [01:35<00:51, 286.59batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  64%|▋| 26130/40960 [01:36<00:51, 288.74batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  64%|▋| 26130/40960 [01:36<00:51, 288.74batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  64%|▋| 26189/40960 [01:36<00:50, 290.19batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  64%|▋| 26189/40960 [01:36<00:50, 290.19batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  64%|▋| 26245/40960 [01:36<00:51, 287.10batches/s, l2_loss: 0.2988 - round_los\u001b[A\n",
      "Training:  64%|▋| 26245/40960 [01:36<00:51, 287.10batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  64%|▋| 26300/40960 [01:36<00:51, 283.04batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  64%|▋| 26300/40960 [01:36<00:51, 283.04batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  64%|▋| 26361/40960 [01:36<00:50, 288.28batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  64%|▋| 26361/40960 [01:36<00:50, 288.28batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  65%|▋| 26422/40960 [01:37<00:49, 292.48batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  65%|▋| 26422/40960 [01:37<00:49, 292.48batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26483/40960 [01:37<00:49, 295.42batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26483/40960 [01:37<00:49, 295.42batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  65%|▋| 26541/40960 [01:37<00:49, 293.15batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  65%|▋| 26541/40960 [01:37<00:49, 293.15batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26596/40960 [01:37<00:50, 287.23batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26596/40960 [01:37<00:50, 287.23batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26653/40960 [01:37<00:50, 285.22batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26653/40960 [01:37<00:50, 285.22batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  65%|▋| 26710/40960 [01:38<00:50, 284.60batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  65%|▋| 26710/40960 [01:38<00:50, 284.60batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26766/40960 [01:38<00:50, 283.09batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26766/40960 [01:38<00:50, 283.09batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26825/40960 [01:38<00:49, 285.34batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  65%|▋| 26825/40960 [01:38<00:49, 285.34batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  66%|▋| 26881/40960 [01:38<00:49, 283.40batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  66%|▋| 26881/40960 [01:38<00:49, 283.40batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  66%|▋| 26940/40960 [01:38<00:49, 285.65batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  66%|▋| 26940/40960 [01:38<00:49, 285.65batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  66%|▋| 26993/40960 [01:39<00:50, 278.86batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  66%|▋| 26993/40960 [01:39<00:50, 278.86batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  66%|▋| 27051/40960 [01:39<00:49, 282.13batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  66%|▋| 27051/40960 [01:39<00:49, 282.13batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  66%|▋| 27110/40960 [01:39<00:48, 284.99batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  66%|▋| 27110/40960 [01:39<00:48, 284.99batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  66%|▋| 27162/40960 [01:39<00:49, 276.02batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  66%|▋| 27162/40960 [01:39<00:49, 276.02batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  66%|▋| 27218/40960 [01:39<00:49, 276.25batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  66%|▋| 27218/40960 [01:39<00:49, 276.25batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  67%|▋| 27274/40960 [01:40<00:49, 275.90batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  67%|▋| 27274/40960 [01:40<00:49, 275.90batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  67%|▋| 27327/40960 [01:40<00:50, 272.07batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  67%|▋| 27327/40960 [01:40<00:50, 272.07batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  67%|▋| 27380/40960 [01:40<00:50, 268.99batches/s, l2_loss: 0.2987 - round_los\u001b[A\n",
      "Training:  67%|▋| 27380/40960 [01:40<00:50, 268.99batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  67%|▋| 27430/40960 [01:40<00:51, 263.00batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  67%|▋| 27430/40960 [01:40<00:51, 263.00batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  67%|▋| 27488/40960 [01:40<00:49, 270.28batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  67%|▋| 27488/40960 [01:40<00:49, 270.28batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  67%|▋| 27546/40960 [01:41<00:48, 275.04batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  67%|▋| 27546/40960 [01:41<00:48, 275.04batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  67%|▋| 27603/40960 [01:41<00:48, 277.11batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  67%|▋| 27603/40960 [01:41<00:48, 277.11batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  68%|▋| 27663/40960 [01:41<00:47, 282.59batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  68%|▋| 27663/40960 [01:41<00:47, 282.59batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  68%|▋| 27720/40960 [01:41<00:46, 283.24batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  68%|▋| 27720/40960 [01:41<00:46, 283.24batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  68%|▋| 27780/40960 [01:41<00:45, 287.74batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  68%|▋| 27780/40960 [01:41<00:45, 287.74batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  68%|▋| 27836/40960 [01:42<00:46, 284.33batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  68%|▋| 27836/40960 [01:42<00:46, 284.33batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  68%|▋| 27893/40960 [01:42<00:46, 283.79batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  68%|▋| 27893/40960 [01:42<00:46, 283.79batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  68%|▋| 27952/40960 [01:42<00:45, 285.78batches/s, l2_loss: 0.2985 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|▋| 27952/40960 [01:42<00:45, 285.78batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  68%|▋| 28011/40960 [01:42<00:44, 288.03batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  68%|▋| 28011/40960 [01:42<00:44, 288.03batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  69%|▋| 28069/40960 [01:42<00:44, 287.63batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  69%|▋| 28069/40960 [01:42<00:44, 287.63batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  69%|▋| 28127/40960 [01:43<00:44, 288.16batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  69%|▋| 28127/40960 [01:43<00:44, 288.16batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  69%|▋| 28185/40960 [01:43<00:44, 287.42batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  69%|▋| 28185/40960 [01:43<00:44, 287.42batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  69%|▋| 28240/40960 [01:43<00:45, 282.63batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  69%|▋| 28240/40960 [01:43<00:45, 282.63batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  69%|▋| 28293/40960 [01:43<00:45, 277.14batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  69%|▋| 28293/40960 [01:43<00:45, 277.14batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  69%|▋| 28352/40960 [01:43<00:44, 282.20batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  69%|▋| 28352/40960 [01:43<00:44, 282.20batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  69%|▋| 28405/40960 [01:44<00:45, 276.84batches/s, l2_loss: 0.2986 - round_los\u001b[A\n",
      "Training:  69%|▋| 28405/40960 [01:44<00:45, 276.84batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  69%|▋| 28461/40960 [01:44<00:45, 277.19batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  69%|▋| 28461/40960 [01:44<00:45, 277.19batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  70%|▋| 28520/40960 [01:44<00:44, 282.34batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  70%|▋| 28520/40960 [01:44<00:44, 282.34batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  70%|▋| 28577/40960 [01:44<00:43, 282.97batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  70%|▋| 28577/40960 [01:44<00:43, 282.97batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  70%|▋| 28637/40960 [01:44<00:42, 286.94batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  70%|▋| 28637/40960 [01:44<00:42, 286.94batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  70%|▋| 28695/40960 [01:45<00:42, 286.42batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  70%|▋| 28695/40960 [01:45<00:42, 286.42batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  70%|▋| 28754/40960 [01:45<00:42, 288.50batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  70%|▋| 28754/40960 [01:45<00:42, 288.50batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  70%|▋| 28808/40960 [01:45<00:43, 282.32batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  70%|▋| 28808/40960 [01:45<00:43, 282.32batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  70%|▋| 28868/40960 [01:45<00:42, 286.92batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  70%|▋| 28868/40960 [01:45<00:42, 286.92batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  71%|▋| 28928/40960 [01:45<00:41, 290.05batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  71%|▋| 28928/40960 [01:45<00:41, 290.05batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  71%|▋| 28978/40960 [01:46<00:43, 277.21batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  71%|▋| 28978/40960 [01:46<00:43, 277.21batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  71%|▋| 29036/40960 [01:46<00:42, 280.57batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  71%|▋| 29036/40960 [01:46<00:42, 280.57batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  71%|▋| 29088/40960 [01:46<00:43, 272.31batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  71%|▋| 29088/40960 [01:46<00:43, 272.31batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  71%|▋| 29144/40960 [01:46<00:43, 273.61batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  71%|▋| 29144/40960 [01:46<00:43, 273.61batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  71%|▋| 29201/40960 [01:46<00:42, 276.28batches/s, l2_loss: 0.2984 - round_los\u001b[A\n",
      "Training:  71%|▋| 29201/40960 [01:46<00:42, 276.28batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  71%|▋| 29256/40960 [01:47<00:42, 274.89batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  71%|▋| 29256/40960 [01:47<00:42, 274.89batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  72%|▋| 29313/40960 [01:47<00:42, 276.86batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  72%|▋| 29313/40960 [01:47<00:42, 276.86batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  72%|▋| 29369/40960 [01:47<00:41, 277.77batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  72%|▋| 29369/40960 [01:47<00:41, 277.77batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  72%|▋| 29428/40960 [01:47<00:40, 282.56batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  72%|▋| 29428/40960 [01:47<00:40, 282.56batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  72%|▋| 29488/40960 [01:47<00:40, 286.00batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  72%|▋| 29488/40960 [01:47<00:40, 286.00batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  72%|▋| 29537/40960 [01:48<00:41, 273.03batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  72%|▋| 29537/40960 [01:48<00:41, 273.03batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  72%|▋| 29595/40960 [01:48<00:40, 277.65batches/s, l2_loss: 0.2985 - round_los\u001b[A\n",
      "Training:  72%|▋| 29595/40960 [01:48<00:40, 277.65batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  72%|▋| 29653/40960 [01:48<00:40, 281.26batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  72%|▋| 29653/40960 [01:48<00:40, 281.26batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  73%|▋| 29710/40960 [01:48<00:39, 282.25batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  73%|▋| 29710/40960 [01:48<00:39, 282.25batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  73%|▋| 29765/40960 [01:49<00:40, 278.60batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  73%|▋| 29765/40960 [01:49<00:40, 278.60batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  73%|▋| 29820/40960 [01:49<00:40, 277.46batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  73%|▋| 29820/40960 [01:49<00:40, 277.46batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  73%|▋| 29879/40960 [01:49<00:39, 282.68batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  73%|▋| 29879/40960 [01:49<00:39, 282.68batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  73%|▋| 29938/40960 [01:49<00:38, 285.60batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  73%|▋| 29938/40960 [01:49<00:38, 285.60batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  73%|▋| 29996/40960 [01:49<00:38, 286.32batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  73%|▋| 29996/40960 [01:49<00:38, 286.32batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  73%|▋| 30054/40960 [01:50<00:38, 286.22batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  73%|▋| 30054/40960 [01:50<00:38, 286.22batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  74%|▋| 30111/40960 [01:50<00:38, 284.76batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  74%|▋| 30111/40960 [01:50<00:38, 284.76batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  74%|▋| 30169/40960 [01:50<00:37, 285.04batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  74%|▋| 30169/40960 [01:50<00:37, 285.04batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  74%|▋| 30221/40960 [01:50<00:38, 276.68batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  74%|▋| 30221/40960 [01:50<00:38, 276.68batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  74%|▋| 30265/40960 [01:50<00:41, 257.82batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  74%|▋| 30265/40960 [01:50<00:41, 257.82batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  74%|▋| 30320/40960 [01:51<00:40, 262.34batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  74%|▋| 30320/40960 [01:51<00:40, 262.34batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  74%|▋| 30370/40960 [01:51<00:41, 256.54batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  74%|▋| 30370/40960 [01:51<00:41, 256.54batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  74%|▋| 30429/40960 [01:51<00:39, 266.69batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  74%|▋| 30429/40960 [01:51<00:39, 266.69batches/s, l2_loss: 0.2982 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|▋| 30488/40960 [01:51<00:38, 274.19batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  74%|▋| 30488/40960 [01:51<00:38, 274.19batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  75%|▋| 30547/40960 [01:51<00:37, 279.16batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  75%|▋| 30547/40960 [01:51<00:37, 279.16batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  75%|▋| 30604/40960 [01:52<00:36, 280.33batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  75%|▋| 30604/40960 [01:52<00:36, 280.33batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  75%|▋| 30655/40960 [01:52<00:37, 271.63batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  75%|▋| 30655/40960 [01:52<00:37, 271.63batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  75%|▋| 30710/40960 [01:52<00:37, 272.53batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  75%|▋| 30710/40960 [01:52<00:37, 272.53batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  75%|▊| 30764/40960 [01:52<00:37, 270.97batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  75%|▊| 30764/40960 [01:52<00:37, 270.97batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  75%|▊| 30816/40960 [01:52<00:37, 267.02batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  75%|▊| 30816/40960 [01:52<00:37, 267.02batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  75%|▊| 30871/40960 [01:53<00:37, 267.85batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  75%|▊| 30871/40960 [01:53<00:37, 267.85batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  76%|▊| 30926/40960 [01:53<00:37, 269.46batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  76%|▊| 30926/40960 [01:53<00:37, 269.46batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  76%|▊| 30982/40960 [01:53<00:36, 272.54batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  76%|▊| 30982/40960 [01:53<00:36, 272.54batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  76%|▊| 31032/40960 [01:53<00:37, 265.22batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  76%|▊| 31032/40960 [01:53<00:37, 265.22batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  76%|▊| 31091/40960 [01:53<00:36, 272.58batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  76%|▊| 31091/40960 [01:53<00:36, 272.58batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  76%|▊| 31147/40960 [01:54<00:35, 273.71batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  76%|▊| 31147/40960 [01:54<00:35, 273.71batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  76%|▊| 31206/40960 [01:54<00:34, 279.45batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  76%|▊| 31206/40960 [01:54<00:34, 279.45batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  76%|▊| 31263/40960 [01:54<00:34, 280.62batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  76%|▊| 31263/40960 [01:54<00:34, 280.62batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  76%|▊| 31319/40960 [01:54<00:34, 279.64batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  76%|▊| 31319/40960 [01:54<00:34, 279.64batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  77%|▊| 31377/40960 [01:54<00:34, 281.20batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  77%|▊| 31377/40960 [01:54<00:34, 281.20batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  77%|▊| 31432/40960 [01:55<00:34, 278.91batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  77%|▊| 31432/40960 [01:55<00:34, 278.91batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  77%|▊| 31483/40960 [01:55<00:35, 270.54batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  77%|▊| 31483/40960 [01:55<00:35, 270.54batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  77%|▊| 31532/40960 [01:55<00:36, 261.68batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  77%|▊| 31532/40960 [01:55<00:36, 261.68batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  77%|▊| 31591/40960 [01:55<00:34, 271.32batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  77%|▊| 31591/40960 [01:55<00:34, 271.32batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  77%|▊| 31651/40960 [01:55<00:33, 278.94batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  77%|▊| 31651/40960 [01:55<00:33, 278.94batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  77%|▊| 31707/40960 [01:56<00:33, 278.32batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  77%|▊| 31707/40960 [01:56<00:33, 278.32batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  78%|▊| 31765/40960 [01:56<00:32, 281.08batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  78%|▊| 31765/40960 [01:56<00:32, 281.08batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  78%|▊| 31825/40960 [01:56<00:32, 285.41batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  78%|▊| 31825/40960 [01:56<00:32, 285.41batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  78%|▊| 31884/40960 [01:56<00:31, 287.87batches/s, l2_loss: 0.2983 - round_los\u001b[A\n",
      "Training:  78%|▊| 31884/40960 [01:56<00:31, 287.87batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  78%|▊| 31945/40960 [01:56<00:30, 292.44batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  78%|▊| 31945/40960 [01:56<00:30, 292.44batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  78%|▊| 31999/40960 [01:57<00:31, 285.73batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  78%|▊| 31999/40960 [01:57<00:31, 285.73batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  78%|▊| 32056/40960 [01:57<00:31, 284.78batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  78%|▊| 32056/40960 [01:57<00:31, 284.78batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  78%|▊| 32113/40960 [01:57<00:31, 283.95batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  78%|▊| 32113/40960 [01:57<00:31, 283.95batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  79%|▊| 32167/40960 [01:57<00:31, 278.24batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  79%|▊| 32167/40960 [01:57<00:31, 278.24batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32225/40960 [01:57<00:31, 280.67batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32225/40960 [01:57<00:31, 280.67batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32283/40960 [01:58<00:30, 281.98batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32283/40960 [01:58<00:30, 281.98batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32337/40960 [01:58<00:31, 277.51batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32337/40960 [01:58<00:31, 277.51batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32395/40960 [01:58<00:30, 280.55batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32395/40960 [01:58<00:30, 280.55batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  79%|▊| 32453/40960 [01:58<00:30, 282.35batches/s, l2_loss: 0.2982 - round_los\u001b[A\n",
      "Training:  79%|▊| 32453/40960 [01:58<00:30, 282.35batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  79%|▊| 32497/40960 [01:58<00:32, 263.71batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  79%|▊| 32497/40960 [01:58<00:32, 263.71batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32548/40960 [01:59<00:32, 259.78batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  79%|▊| 32548/40960 [01:59<00:32, 259.78batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  80%|▊| 32607/40960 [01:59<00:31, 268.72batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  80%|▊| 32607/40960 [01:59<00:31, 268.72batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  80%|▊| 32665/40960 [01:59<00:30, 274.13batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  80%|▊| 32665/40960 [01:59<00:30, 274.13batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  80%|▊| 32725/40960 [01:59<00:29, 280.67batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  80%|▊| 32725/40960 [01:59<00:29, 280.67batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  80%|▊| 32783/40960 [01:59<00:29, 281.93batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  80%|▊| 32783/40960 [01:59<00:29, 281.93batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  80%|▊| 32843/40960 [02:00<00:28, 286.72batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  80%|▊| 32843/40960 [02:00<00:28, 286.72batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  80%|▊| 32903/40960 [02:00<00:27, 290.39batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  80%|▊| 32903/40960 [02:00<00:27, 290.39batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  80%|▊| 32961/40960 [02:00<00:27, 289.74batches/s, l2_loss: 0.2980 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32961/40960 [02:00<00:27, 289.74batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  81%|▊| 33018/40960 [02:00<00:27, 287.89batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  81%|▊| 33018/40960 [02:00<00:27, 287.89batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  81%|▊| 33072/40960 [02:00<00:27, 282.40batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  81%|▊| 33072/40960 [02:00<00:27, 282.40batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  81%|▊| 33127/40960 [02:01<00:28, 279.13batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  81%|▊| 33127/40960 [02:01<00:28, 279.13batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  81%|▊| 33185/40960 [02:01<00:27, 281.31batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  81%|▊| 33185/40960 [02:01<00:27, 281.31batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  81%|▊| 33244/40960 [02:01<00:27, 284.79batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  81%|▊| 33244/40960 [02:01<00:27, 284.79batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  81%|▊| 33304/40960 [02:01<00:26, 288.27batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  81%|▊| 33304/40960 [02:01<00:26, 288.27batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  81%|▊| 33357/40960 [02:01<00:27, 280.52batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  81%|▊| 33357/40960 [02:01<00:27, 280.52batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  82%|▊| 33417/40960 [02:02<00:26, 285.52batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  82%|▊| 33417/40960 [02:02<00:26, 285.52batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  82%|▊| 33477/40960 [02:02<00:25, 289.35batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  82%|▊| 33477/40960 [02:02<00:25, 289.35batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  82%|▊| 33537/40960 [02:02<00:25, 292.03batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  82%|▊| 33537/40960 [02:02<00:25, 292.03batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  82%|▊| 33595/40960 [02:02<00:25, 290.83batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  82%|▊| 33595/40960 [02:02<00:25, 290.83batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  82%|▊| 33655/40960 [02:02<00:24, 292.60batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  82%|▊| 33655/40960 [02:02<00:24, 292.60batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  82%|▊| 33711/40960 [02:03<00:25, 286.80batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  82%|▊| 33711/40960 [02:03<00:25, 286.80batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  82%|▊| 33764/40960 [02:03<00:25, 278.79batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  82%|▊| 33764/40960 [02:03<00:25, 278.79batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  83%|▊| 33822/40960 [02:03<00:25, 281.89batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  83%|▊| 33822/40960 [02:03<00:25, 281.89batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  83%|▊| 33877/40960 [02:03<00:25, 278.92batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  83%|▊| 33877/40960 [02:03<00:25, 278.92batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  83%|▊| 33931/40960 [02:03<00:25, 274.69batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  83%|▊| 33931/40960 [02:03<00:25, 274.69batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  83%|▊| 33988/40960 [02:04<00:25, 276.96batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  83%|▊| 33988/40960 [02:04<00:25, 276.96batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  83%|▊| 34036/40960 [02:04<00:26, 265.42batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  83%|▊| 34036/40960 [02:04<00:26, 265.42batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  83%|▊| 34092/40960 [02:04<00:25, 268.43batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  83%|▊| 34092/40960 [02:04<00:25, 268.43batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  83%|▊| 34147/40960 [02:04<00:25, 269.17batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  83%|▊| 34147/40960 [02:04<00:25, 269.17batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  84%|▊| 34205/40960 [02:04<00:24, 274.29batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  84%|▊| 34205/40960 [02:04<00:24, 274.29batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  84%|▊| 34265/40960 [02:05<00:23, 280.68batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  84%|▊| 34265/40960 [02:05<00:23, 280.68batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  84%|▊| 34321/40960 [02:05<00:23, 278.07batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  84%|▊| 34321/40960 [02:05<00:23, 278.07batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  84%|▊| 34379/40960 [02:05<00:23, 280.34batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  84%|▊| 34379/40960 [02:05<00:23, 280.34batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  84%|▊| 34436/40960 [02:05<00:23, 280.54batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  84%|▊| 34436/40960 [02:05<00:23, 280.54batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  84%|▊| 34492/40960 [02:05<00:23, 279.22batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  84%|▊| 34492/40960 [02:05<00:23, 279.22batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  84%|▊| 34551/40960 [02:06<00:22, 282.86batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  84%|▊| 34551/40960 [02:06<00:22, 282.86batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  84%|▊| 34610/40960 [02:06<00:22, 286.17batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  84%|▊| 34610/40960 [02:06<00:22, 286.17batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  85%|▊| 34664/40960 [02:06<00:22, 279.74batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  85%|▊| 34664/40960 [02:06<00:22, 279.74batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  85%|▊| 34707/40960 [02:06<00:24, 258.00batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  85%|▊| 34707/40960 [02:06<00:24, 258.00batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  85%|▊| 34763/40960 [02:07<00:23, 263.70batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  85%|▊| 34763/40960 [02:07<00:23, 263.70batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  85%|▊| 34818/40960 [02:07<00:23, 266.42batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  85%|▊| 34818/40960 [02:07<00:23, 266.42batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  85%|▊| 34878/40960 [02:07<00:22, 275.24batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  85%|▊| 34878/40960 [02:07<00:22, 275.24batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  85%|▊| 34936/40960 [02:07<00:21, 278.11batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  85%|▊| 34936/40960 [02:07<00:21, 278.11batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  85%|▊| 34991/40960 [02:07<00:21, 276.93batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  85%|▊| 34991/40960 [02:07<00:21, 276.93batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  86%|▊| 35046/40960 [02:08<00:21, 276.21batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  86%|▊| 35046/40960 [02:08<00:21, 276.21batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  86%|▊| 35102/40960 [02:08<00:21, 277.15batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  86%|▊| 35102/40960 [02:08<00:21, 277.15batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  86%|▊| 35160/40960 [02:08<00:20, 280.41batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  86%|▊| 35160/40960 [02:08<00:20, 280.41batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  86%|▊| 35218/40960 [02:08<00:20, 281.56batches/s, l2_loss: 0.2981 - round_los\u001b[A\n",
      "Training:  86%|▊| 35218/40960 [02:08<00:20, 281.56batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  86%|▊| 35275/40960 [02:08<00:20, 281.55batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  86%|▊| 35275/40960 [02:08<00:20, 281.55batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  86%|▊| 35332/40960 [02:09<00:19, 282.56batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  86%|▊| 35332/40960 [02:09<00:19, 282.56batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  86%|▊| 35387/40960 [02:09<00:19, 280.09batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  86%|▊| 35387/40960 [02:09<00:19, 280.09batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  87%|▊| 35445/40960 [02:09<00:19, 282.80batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  87%|▊| 35445/40960 [02:09<00:19, 282.80batches/s, l2_loss: 0.2979 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|▊| 35502/40960 [02:09<00:19, 282.91batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  87%|▊| 35502/40960 [02:09<00:19, 282.91batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  87%|▊| 35559/40960 [02:09<00:19, 282.65batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  87%|▊| 35559/40960 [02:09<00:19, 282.65batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  87%|▊| 35619/40960 [02:10<00:18, 286.44batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  87%|▊| 35619/40960 [02:10<00:18, 286.44batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  87%|▊| 35678/40960 [02:10<00:18, 288.92batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  87%|▊| 35678/40960 [02:10<00:18, 288.92batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  87%|▊| 35739/40960 [02:10<00:17, 292.85batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  87%|▊| 35739/40960 [02:10<00:17, 292.85batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  87%|▊| 35797/40960 [02:10<00:17, 291.90batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  87%|▊| 35797/40960 [02:10<00:17, 291.90batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  88%|▉| 35856/40960 [02:10<00:17, 291.36batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  88%|▉| 35856/40960 [02:10<00:17, 291.36batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  88%|▉| 35913/40960 [02:11<00:17, 289.28batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  88%|▉| 35913/40960 [02:11<00:17, 289.28batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  88%|▉| 35973/40960 [02:11<00:17, 291.25batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  88%|▉| 35973/40960 [02:11<00:17, 291.25batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  88%|▉| 36022/40960 [02:11<00:17, 277.18batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  88%|▉| 36022/40960 [02:11<00:17, 277.18batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  88%|▉| 36073/40960 [02:11<00:18, 270.03batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  88%|▉| 36073/40960 [02:11<00:18, 270.03batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  88%|▉| 36131/40960 [02:11<00:17, 275.50batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  88%|▉| 36131/40960 [02:11<00:17, 275.50batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  88%|▉| 36188/40960 [02:12<00:17, 278.01batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  88%|▉| 36188/40960 [02:12<00:17, 278.01batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  88%|▉| 36245/40960 [02:12<00:16, 279.77batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  88%|▉| 36245/40960 [02:12<00:16, 279.77batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  89%|▉| 36297/40960 [02:12<00:17, 273.51batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  89%|▉| 36297/40960 [02:12<00:17, 273.51batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  89%|▉| 36350/40960 [02:12<00:17, 270.18batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  89%|▉| 36350/40960 [02:12<00:17, 270.18batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  89%|▉| 36407/40960 [02:12<00:16, 273.67batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  89%|▉| 36407/40960 [02:12<00:16, 273.67batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  89%|▉| 36459/40960 [02:13<00:16, 268.91batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  89%|▉| 36459/40960 [02:13<00:16, 268.91batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  89%|▉| 36515/40960 [02:13<00:16, 272.20batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  89%|▉| 36515/40960 [02:13<00:16, 272.20batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  89%|▉| 36570/40960 [02:13<00:16, 272.85batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  89%|▉| 36570/40960 [02:13<00:16, 272.85batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  89%|▉| 36627/40960 [02:13<00:15, 275.40batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  89%|▉| 36627/40960 [02:13<00:15, 275.40batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  90%|▉| 36681/40960 [02:13<00:15, 273.72batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  90%|▉| 36681/40960 [02:13<00:15, 273.72batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  90%|▉| 36736/40960 [02:14<00:15, 273.76batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  90%|▉| 36736/40960 [02:14<00:15, 273.76batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  90%|▉| 36790/40960 [02:14<00:15, 272.09batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  90%|▉| 36790/40960 [02:14<00:15, 272.09batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  90%|▉| 36847/40960 [02:14<00:14, 275.09batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  90%|▉| 36847/40960 [02:14<00:14, 275.09batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  90%|▉| 36905/40960 [02:14<00:14, 279.05batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  90%|▉| 36905/40960 [02:14<00:14, 279.05batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  90%|▉| 36958/40960 [02:14<00:14, 273.57batches/s, l2_loss: 0.2980 - round_los\u001b[A\n",
      "Training:  90%|▉| 36958/40960 [02:14<00:14, 273.57batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  90%|▉| 37016/40960 [02:15<00:14, 278.24batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  90%|▉| 37016/40960 [02:15<00:14, 278.24batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [02:15<00:14, 274.58batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [02:15<00:14, 274.58batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37120/40960 [02:15<00:14, 266.88batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37120/40960 [02:15<00:14, 266.88batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37177/40960 [02:15<00:13, 271.76batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37177/40960 [02:15<00:13, 271.76batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37236/40960 [02:15<00:13, 278.63batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37236/40960 [02:15<00:13, 278.63batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  91%|▉| 37289/40960 [02:16<00:13, 273.02batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  91%|▉| 37289/40960 [02:16<00:13, 273.02batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37346/40960 [02:16<00:13, 275.61batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37346/40960 [02:16<00:13, 275.61batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  91%|▉| 37406/40960 [02:16<00:12, 281.64batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  91%|▉| 37406/40960 [02:16<00:12, 281.64batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37462/40960 [02:16<00:12, 279.81batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  91%|▉| 37462/40960 [02:16<00:12, 279.81batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37509/40960 [02:16<00:13, 264.95batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37509/40960 [02:16<00:13, 264.95batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  92%|▉| 37556/40960 [02:17<00:13, 255.58batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  92%|▉| 37556/40960 [02:17<00:13, 255.58batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37602/40960 [02:17<00:13, 247.65batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37602/40960 [02:17<00:13, 247.65batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37658/40960 [02:17<00:12, 256.64batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37658/40960 [02:17<00:12, 256.64batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  92%|▉| 37708/40960 [02:17<00:12, 254.12batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  92%|▉| 37708/40960 [02:17<00:12, 254.12batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37762/40960 [02:17<00:12, 257.69batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37762/40960 [02:17<00:12, 257.69batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37818/40960 [02:18<00:11, 263.82batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  92%|▉| 37818/40960 [02:18<00:11, 263.82batches/s, l2_loss: 0.2976 - round_los\u001b[A\n",
      "Training:  92%|▉| 37869/40960 [02:18<00:11, 260.89batches/s, l2_loss: 0.2976 - round_los\u001b[A\n",
      "Training:  92%|▉| 37869/40960 [02:18<00:11, 260.89batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 37921/40960 [02:18<00:11, 260.11batches/s, l2_loss: 0.2978 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|▉| 37921/40960 [02:18<00:11, 260.11batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  93%|▉| 37969/40960 [02:18<00:11, 253.19batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  93%|▉| 37969/40960 [02:18<00:11, 253.19batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 38025/40960 [02:18<00:11, 260.62batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 38025/40960 [02:18<00:11, 260.62batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  93%|▉| 38079/40960 [02:19<00:10, 262.17batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  93%|▉| 38079/40960 [02:19<00:10, 262.17batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 38136/40960 [02:19<00:10, 268.28batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 38136/40960 [02:19<00:10, 268.28batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 38192/40960 [02:19<00:10, 270.99batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 38192/40960 [02:19<00:10, 270.99batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 38244/40960 [02:19<00:10, 267.53batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  93%|▉| 38244/40960 [02:19<00:10, 267.53batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  94%|▉| 38298/40960 [02:19<00:09, 267.69batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  94%|▉| 38298/40960 [02:19<00:09, 267.69batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38350/40960 [02:20<00:09, 264.28batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38350/40960 [02:20<00:09, 264.28batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  94%|▉| 38405/40960 [02:20<00:09, 266.15batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  94%|▉| 38405/40960 [02:20<00:09, 266.15batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38462/40960 [02:20<00:09, 271.24batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38462/40960 [02:20<00:09, 271.24batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  94%|▉| 38516/40960 [02:20<00:09, 269.46batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  94%|▉| 38516/40960 [02:20<00:09, 269.46batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38571/40960 [02:20<00:08, 270.26batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38571/40960 [02:20<00:08, 270.26batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38622/40960 [02:21<00:08, 265.03batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38622/40960 [02:21<00:08, 265.03batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38677/40960 [02:21<00:08, 267.25batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  94%|▉| 38677/40960 [02:21<00:08, 267.25batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  95%|▉| 38731/40960 [02:21<00:08, 267.70batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  95%|▉| 38731/40960 [02:21<00:08, 267.70batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  95%|▉| 38786/40960 [02:21<00:08, 269.20batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  95%|▉| 38786/40960 [02:21<00:08, 269.20batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  95%|▉| 38840/40960 [02:21<00:07, 269.16batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  95%|▉| 38840/40960 [02:21<00:07, 269.16batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  95%|▉| 38891/40960 [02:22<00:07, 264.33batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  95%|▉| 38891/40960 [02:22<00:07, 264.33batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  95%|▉| 38945/40960 [02:22<00:07, 265.46batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  95%|▉| 38945/40960 [02:22<00:07, 265.46batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  95%|▉| 39001/40960 [02:22<00:07, 268.89batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  95%|▉| 39001/40960 [02:22<00:07, 268.89batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  95%|▉| 39057/40960 [02:22<00:07, 271.67batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  95%|▉| 39057/40960 [02:22<00:07, 271.67batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  95%|▉| 39114/40960 [02:22<00:06, 275.15batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  95%|▉| 39114/40960 [02:22<00:06, 275.15batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  96%|▉| 39165/40960 [02:23<00:06, 267.76batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  96%|▉| 39165/40960 [02:23<00:06, 267.76batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  96%|▉| 39213/40960 [02:23<00:06, 258.22batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  96%|▉| 39213/40960 [02:23<00:06, 258.22batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  96%|▉| 39262/40960 [02:23<00:06, 253.75batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  96%|▉| 39262/40960 [02:23<00:06, 253.75batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  96%|▉| 39316/40960 [02:23<00:06, 258.07batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  96%|▉| 39316/40960 [02:23<00:06, 258.07batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  96%|▉| 39369/40960 [02:23<00:06, 259.78batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  96%|▉| 39369/40960 [02:23<00:06, 259.78batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  96%|▉| 39427/40960 [02:24<00:05, 268.18batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  96%|▉| 39427/40960 [02:24<00:05, 268.18batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  96%|▉| 39483/40960 [02:24<00:05, 271.46batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  96%|▉| 39483/40960 [02:24<00:05, 271.46batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39540/40960 [02:24<00:05, 273.65batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39540/40960 [02:24<00:05, 273.65batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39577/40960 [02:24<00:05, 246.56batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39577/40960 [02:24<00:05, 246.56batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  97%|▉| 39633/40960 [02:24<00:05, 256.22batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  97%|▉| 39633/40960 [02:24<00:05, 256.22batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  97%|▉| 39688/40960 [02:25<00:04, 261.33batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  97%|▉| 39688/40960 [02:25<00:04, 261.33batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39729/40960 [02:25<00:05, 243.87batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39729/40960 [02:25<00:05, 243.87batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39784/40960 [02:25<00:04, 253.12batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39784/40960 [02:25<00:04, 253.12batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39841/40960 [02:25<00:04, 261.64batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39841/40960 [02:25<00:04, 261.64batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  97%|▉| 39888/40960 [02:25<00:04, 253.11batches/s, l2_loss: 0.2979 - round_los\u001b[A\n",
      "Training:  97%|▉| 39888/40960 [02:25<00:04, 253.11batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  98%|▉| 39941/40960 [02:26<00:03, 256.29batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  98%|▉| 39941/40960 [02:26<00:03, 256.29batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 39997/40960 [02:26<00:03, 262.58batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 39997/40960 [02:26<00:03, 262.58batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40054/40960 [02:26<00:03, 268.83batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40054/40960 [02:26<00:03, 268.83batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40111/40960 [02:26<00:03, 272.90batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40111/40960 [02:26<00:03, 272.90batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40168/40960 [02:26<00:02, 276.39batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40168/40960 [02:26<00:02, 276.39batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40225/40960 [02:27<00:02, 277.82batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40225/40960 [02:27<00:02, 277.82batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40282/40960 [02:27<00:02, 279.94batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40282/40960 [02:27<00:02, 279.94batches/s, l2_loss: 0.2977 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40334/40960 [02:27<00:02, 272.50batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  98%|▉| 40334/40960 [02:27<00:02, 272.50batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40388/40960 [02:27<00:02, 270.45batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40388/40960 [02:27<00:02, 270.45batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  99%|▉| 40445/40960 [02:27<00:01, 274.64batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training:  99%|▉| 40445/40960 [02:27<00:01, 274.64batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40502/40960 [02:28<00:01, 277.01batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40502/40960 [02:28<00:01, 277.01batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40555/40960 [02:28<00:01, 273.20batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40555/40960 [02:28<00:01, 273.20batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40612/40960 [02:28<00:01, 276.31batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40612/40960 [02:28<00:01, 276.31batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40669/40960 [02:28<00:01, 278.65batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40669/40960 [02:28<00:01, 278.65batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40726/40960 [02:28<00:00, 280.42batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training:  99%|▉| 40726/40960 [02:28<00:00, 280.42batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training: 100%|▉| 40784/40960 [02:29<00:00, 281.91batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training: 100%|▉| 40784/40960 [02:29<00:00, 281.91batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training: 100%|▉| 40841/40960 [02:29<00:00, 282.60batches/s, l2_loss: 0.2978 - round_los\u001b[A\n",
      "Training: 100%|▉| 40841/40960 [02:29<00:00, 282.60batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training: 100%|▉| 40901/40960 [02:29<00:00, 286.73batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "Training: 100%|▉| 40901/40960 [02:29<00:00, 286.73batches/s, l2_loss: 0.2976 - round_los\u001b[A\n",
      "Training: 100%|█| 40960/40960 [02:29<00:00, 288.23batches/s, l2_loss: 0.2976 - round_los\u001b[A\n",
      "Training: 100%|█| 40960/40960 [02:29<00:00, 288.23batches/s, l2_loss: 0.2977 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:26:47.594412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  69%|▋| 18/26 [37:28<18:40, 140.02s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:26:50.948508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:26:58.018995: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<27:47:55,  2.44s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<27:47:55,  2.44s/batches, l2_loss: 0.0216 - round_loss:\u001b[A\n",
      "Training:   0%| | 48/40960 [00:02<27:18, 24.97batches/s, l2_loss: 0.0216 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 48/40960 [00:02<27:18, 24.97batches/s, l2_loss: 0.0398 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 102/40960 [00:02<11:59, 56.80batches/s, l2_loss: 0.0398 - round_loss: \u001b[A\n",
      "Training:   0%| | 102/40960 [00:02<11:59, 56.80batches/s, l2_loss: 0.0444 - round_loss: \u001b[A\n",
      "Training:   0%| | 164/40960 [00:03<07:02, 96.45batches/s, l2_loss: 0.0444 - round_loss: \u001b[A\n",
      "Training:   0%| | 164/40960 [00:03<07:02, 96.45batches/s, l2_loss: 0.0452 - round_loss: \u001b[A\n",
      "Training:   1%| | 225/40960 [00:03<05:02, 134.49batches/s, l2_loss: 0.0452 - round_loss:\u001b[A\n",
      "Training:   1%| | 225/40960 [00:03<05:02, 134.49batches/s, l2_loss: 0.0439 - round_loss:\u001b[A\n",
      "Training:   1%| | 287/40960 [00:03<03:58, 170.54batches/s, l2_loss: 0.0439 - round_loss:\u001b[A\n",
      "Training:   1%| | 287/40960 [00:03<03:58, 170.54batches/s, l2_loss: 0.0427 - round_loss:\u001b[A\n",
      "Training:   1%| | 346/40960 [00:03<03:25, 197.37batches/s, l2_loss: 0.0427 - round_loss:\u001b[A\n",
      "Training:   1%| | 346/40960 [00:03<03:25, 197.37batches/s, l2_loss: 0.0435 - round_loss:\u001b[A\n",
      "Training:   1%| | 400/40960 [00:03<03:09, 214.04batches/s, l2_loss: 0.0435 - round_loss:\u001b[A\n",
      "Training:   1%| | 400/40960 [00:03<03:09, 214.04batches/s, l2_loss: 0.0430 - round_loss:\u001b[A\n",
      "Training:   1%| | 457/40960 [00:04<02:54, 231.66batches/s, l2_loss: 0.0430 - round_loss:\u001b[A\n",
      "Training:   1%| | 457/40960 [00:04<02:54, 231.66batches/s, l2_loss: 0.0435 - round_loss:\u001b[A\n",
      "Training:   1%| | 518/40960 [00:04<02:41, 250.56batches/s, l2_loss: 0.0435 - round_loss:\u001b[A\n",
      "Training:   1%| | 518/40960 [00:04<02:41, 250.56batches/s, l2_loss: 0.0435 - round_loss:\u001b[A\n",
      "Training:   1%| | 562/40960 [00:04<02:47, 240.63batches/s, l2_loss: 0.0435 - round_loss:\u001b[A\n",
      "Training:   1%| | 562/40960 [00:04<02:47, 240.63batches/s, l2_loss: 0.0435 - round_loss:\u001b[A\n",
      "Training:   2%| | 615/40960 [00:04<02:43, 247.08batches/s, l2_loss: 0.0435 - round_loss:\u001b[A\n",
      "Training:   2%| | 615/40960 [00:04<02:43, 247.08batches/s, l2_loss: 0.0442 - round_loss:\u001b[A\n",
      "Training:   2%| | 679/40960 [00:04<02:30, 267.24batches/s, l2_loss: 0.0442 - round_loss:\u001b[A\n",
      "Training:   2%| | 679/40960 [00:04<02:30, 267.24batches/s, l2_loss: 0.0442 - round_loss:\u001b[A\n",
      "Training:   2%| | 742/40960 [00:05<02:23, 280.29batches/s, l2_loss: 0.0442 - round_loss:\u001b[A\n",
      "Training:   2%| | 742/40960 [00:05<02:23, 280.29batches/s, l2_loss: 0.0439 - round_loss:\u001b[A\n",
      "Training:   2%| | 806/40960 [00:05<02:18, 290.96batches/s, l2_loss: 0.0439 - round_loss:\u001b[A\n",
      "Training:   2%| | 806/40960 [00:05<02:18, 290.96batches/s, l2_loss: 0.0438 - round_loss:\u001b[A\n",
      "Training:   2%| | 863/40960 [00:05<02:19, 288.42batches/s, l2_loss: 0.0438 - round_loss:\u001b[A\n",
      "Training:   2%| | 863/40960 [00:05<02:19, 288.42batches/s, l2_loss: 0.0436 - round_loss:\u001b[A\n",
      "Training:   2%| | 917/40960 [00:05<02:21, 282.19batches/s, l2_loss: 0.0436 - round_loss:\u001b[A\n",
      "Training:   2%| | 917/40960 [00:05<02:21, 282.19batches/s, l2_loss: 0.0439 - round_loss:\u001b[A\n",
      "Training:   2%| | 980/40960 [00:05<02:17, 291.42batches/s, l2_loss: 0.0439 - round_loss:\u001b[A\n",
      "Training:   2%| | 980/40960 [00:05<02:17, 291.42batches/s, l2_loss: 0.0436 - round_loss:\u001b[A\n",
      "Training:   3%| | 1041/40960 [00:06<02:15, 294.32batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   3%| | 1041/40960 [00:06<02:15, 294.32batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   3%| | 1094/40960 [00:06<02:19, 285.52batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   3%| | 1094/40960 [00:06<02:19, 285.52batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   3%| | 1152/40960 [00:06<02:19, 285.76batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   3%| | 1152/40960 [00:06<02:19, 285.76batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   3%| | 1213/40960 [00:06<02:17, 289.91batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   3%| | 1213/40960 [00:06<02:17, 289.91batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   3%| | 1274/40960 [00:06<02:15, 293.36batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   3%| | 1274/40960 [00:06<02:15, 293.36batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   3%| | 1337/40960 [00:07<02:12, 299.68batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   3%| | 1337/40960 [00:07<02:12, 299.68batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   3%| | 1399/40960 [00:07<02:10, 302.45batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   3%| | 1399/40960 [00:07<02:10, 302.45batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   4%| | 1457/40960 [00:07<02:12, 298.40batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   4%| | 1457/40960 [00:07<02:12, 298.40batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%| | 1520/40960 [00:07<02:10, 302.28batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   4%| | 1520/40960 [00:07<02:10, 302.28batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   4%| | 1578/40960 [00:07<02:12, 298.19batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   4%| | 1578/40960 [00:07<02:12, 298.19batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   4%| | 1641/40960 [00:08<02:10, 302.03batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   4%| | 1641/40960 [00:08<02:10, 302.03batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   4%| | 1701/40960 [00:08<02:10, 300.29batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   4%| | 1701/40960 [00:08<02:10, 300.29batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   4%| | 1765/40960 [00:08<02:08, 304.91batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   4%| | 1765/40960 [00:08<02:08, 304.91batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   4%| | 1826/40960 [00:08<02:08, 303.73batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   4%| | 1826/40960 [00:08<02:08, 303.73batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   5%| | 1887/40960 [00:08<02:08, 304.01batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   5%| | 1887/40960 [00:08<02:08, 304.01batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   5%| | 1948/40960 [00:09<02:08, 303.63batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   5%| | 1948/40960 [00:09<02:08, 303.63batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   5%| | 2009/40960 [00:09<02:08, 303.96batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   5%| | 2009/40960 [00:09<02:08, 303.96batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   5%| | 2068/40960 [00:09<02:09, 300.66batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   5%| | 2068/40960 [00:09<02:09, 300.66batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   5%| | 2129/40960 [00:09<02:08, 301.61batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   5%| | 2129/40960 [00:09<02:08, 301.61batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   5%| | 2192/40960 [00:09<02:06, 305.48batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   5%| | 2192/40960 [00:09<02:06, 305.48batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   6%| | 2254/40960 [00:10<02:06, 306.38batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   6%| | 2254/40960 [00:10<02:06, 306.38batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   6%| | 2315/40960 [00:10<02:06, 304.99batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   6%| | 2315/40960 [00:10<02:06, 304.99batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   6%| | 2376/40960 [00:10<02:06, 304.08batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   6%| | 2376/40960 [00:10<02:06, 304.08batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   6%| | 2440/40960 [00:10<02:05, 307.60batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   6%| | 2440/40960 [00:10<02:05, 307.60batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   6%| | 2502/40960 [00:10<02:04, 308.06batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   6%| | 2502/40960 [00:10<02:04, 308.06batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   6%| | 2564/40960 [00:11<02:04, 308.23batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   6%| | 2564/40960 [00:11<02:04, 308.23batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   6%| | 2626/40960 [00:11<02:04, 307.94batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   6%| | 2626/40960 [00:11<02:04, 307.94batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   7%| | 2689/40960 [00:11<02:03, 309.51batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   7%| | 2689/40960 [00:11<02:03, 309.51batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   7%| | 2751/40960 [00:11<02:03, 308.96batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   7%| | 2751/40960 [00:11<02:03, 308.96batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   7%| | 2806/40960 [00:11<02:07, 298.54batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   7%| | 2806/40960 [00:11<02:07, 298.54batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   7%| | 2866/40960 [00:12<02:07, 298.37batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   7%| | 2866/40960 [00:12<02:07, 298.37batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   7%| | 2927/40960 [00:12<02:07, 298.61batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   7%| | 2927/40960 [00:12<02:07, 298.61batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   7%| | 2989/40960 [00:12<02:06, 301.08batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   7%| | 2989/40960 [00:12<02:06, 301.08batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   7%| | 3045/40960 [00:12<02:09, 293.48batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   7%| | 3045/40960 [00:12<02:09, 293.48batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   8%| | 3098/40960 [00:12<02:12, 284.82batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   8%| | 3098/40960 [00:12<02:12, 284.82batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   8%| | 3156/40960 [00:13<02:12, 285.24batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   8%| | 3156/40960 [00:13<02:12, 285.24batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   8%| | 3220/40960 [00:13<02:08, 294.63batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   8%| | 3220/40960 [00:13<02:08, 294.63batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   8%| | 3278/40960 [00:13<02:09, 291.15batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   8%| | 3278/40960 [00:13<02:09, 291.15batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   8%| | 3335/40960 [00:13<02:11, 286.16batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   8%| | 3335/40960 [00:13<02:11, 286.16batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   8%| | 3397/40960 [00:13<02:08, 292.37batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   8%| | 3397/40960 [00:13<02:08, 292.37batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   8%| | 3457/40960 [00:14<02:07, 294.20batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   8%| | 3457/40960 [00:14<02:07, 294.20batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3517/40960 [00:14<02:07, 293.98batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3517/40960 [00:14<02:07, 293.98batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3581/40960 [00:14<02:04, 300.85batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3581/40960 [00:14<02:04, 300.85batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3643/40960 [00:14<02:03, 303.18batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3643/40960 [00:14<02:03, 303.18batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   9%| | 3705/40960 [00:14<02:02, 305.11batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   9%| | 3705/40960 [00:14<02:02, 305.11batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3770/40960 [00:15<01:59, 310.16batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3770/40960 [00:15<01:59, 310.16batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:   9%| | 3832/40960 [00:15<02:00, 308.63batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:   9%| | 3832/40960 [00:15<02:00, 308.63batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  10%| | 3893/40960 [00:15<02:00, 307.18batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  10%| | 3893/40960 [00:15<02:00, 307.18batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  10%| | 3954/40960 [00:15<02:01, 305.38batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  10%| | 3954/40960 [00:15<02:01, 305.38batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  10%| | 4018/40960 [00:15<01:59, 308.66batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  10%| | 4018/40960 [00:15<01:59, 308.66batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  10%| | 4083/40960 [00:16<01:57, 313.40batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  10%| | 4083/40960 [00:16<01:57, 313.40batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4138/40960 [00:16<02:02, 301.54batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4138/40960 [00:16<02:02, 301.54batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4197/40960 [00:16<02:02, 299.33batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 4197/40960 [00:16<02:02, 299.33batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4252/40960 [00:16<02:06, 290.84batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4252/40960 [00:16<02:06, 290.84batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  11%| | 4310/40960 [00:16<02:06, 288.95batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  11%| | 4310/40960 [00:16<02:06, 288.95batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4371/40960 [00:17<02:05, 292.30batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4371/40960 [00:17<02:05, 292.30batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4426/40960 [00:17<02:07, 286.75batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4426/40960 [00:17<02:07, 286.75batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  11%| | 4489/40960 [00:17<02:03, 294.70batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  11%| | 4489/40960 [00:17<02:03, 294.70batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4553/40960 [00:17<02:00, 301.60batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4553/40960 [00:17<02:00, 301.60batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  11%| | 4615/40960 [00:17<01:59, 303.70batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  11%| | 4615/40960 [00:17<01:59, 303.70batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4674/40960 [00:18<02:00, 300.88batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4674/40960 [00:18<02:00, 300.88batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4737/40960 [00:18<01:59, 303.63batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4737/40960 [00:18<01:59, 303.63batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4799/40960 [00:18<01:58, 304.29batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4799/40960 [00:18<01:58, 304.29batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  12%| | 4862/40960 [00:18<01:58, 305.54batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  12%| | 4862/40960 [00:18<01:58, 305.54batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4918/40960 [00:19<02:01, 297.60batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4918/40960 [00:19<02:01, 297.60batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  12%| | 4979/40960 [00:19<02:00, 298.35batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  12%| | 4979/40960 [00:19<02:00, 298.35batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  12%| | 5037/40960 [00:19<02:01, 295.47batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  12%| | 5037/40960 [00:19<02:01, 295.47batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 5097/40960 [00:19<02:00, 296.40batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 5097/40960 [00:19<02:00, 296.40batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5157/40960 [00:19<02:00, 296.28batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5157/40960 [00:19<02:00, 296.28batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5220/40960 [00:20<01:58, 300.91batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5220/40960 [00:20<01:58, 300.91batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5274/40960 [00:20<02:02, 290.95batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5274/40960 [00:20<02:02, 290.95batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5333/40960 [00:20<02:02, 291.57batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5333/40960 [00:20<02:02, 291.57batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5394/40960 [00:20<02:00, 295.08batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5394/40960 [00:20<02:00, 295.08batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5453/40960 [00:20<02:00, 294.74batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5453/40960 [00:20<02:00, 294.74batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5516/40960 [00:21<01:57, 300.45batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5516/40960 [00:21<01:57, 300.45batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5579/40960 [00:21<01:56, 304.36batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5579/40960 [00:21<01:56, 304.36batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5639/40960 [00:21<01:56, 302.68batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5639/40960 [00:21<01:56, 302.68batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5700/40960 [00:21<01:56, 302.16batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5700/40960 [00:21<01:56, 302.16batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5762/40960 [00:21<01:56, 302.77batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5762/40960 [00:21<01:56, 302.77batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5812/40960 [00:22<02:03, 283.83batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5812/40960 [00:22<02:03, 283.83batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5868/40960 [00:22<02:04, 282.64batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5868/40960 [00:22<02:04, 282.64batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5922/40960 [00:22<02:05, 278.32batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5922/40960 [00:22<02:05, 278.32batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5985/40960 [00:22<02:01, 288.86batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5985/40960 [00:22<02:01, 288.86batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6046/40960 [00:22<01:58, 293.54batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6046/40960 [00:22<01:58, 293.54batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6109/40960 [00:23<01:56, 299.31batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6109/40960 [00:23<01:56, 299.31batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6173/40960 [00:23<01:54, 304.41batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6173/40960 [00:23<01:54, 304.41batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6233/40960 [00:23<01:54, 303.02batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6233/40960 [00:23<01:54, 303.02batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6296/40960 [00:23<01:53, 305.93batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6296/40960 [00:23<01:53, 305.93batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6353/40960 [00:23<01:55, 298.87batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6353/40960 [00:23<01:55, 298.87batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6415/40960 [00:24<01:54, 301.91batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6415/40960 [00:24<01:54, 301.91batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6478/40960 [00:24<01:52, 305.59batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6478/40960 [00:24<01:52, 305.59batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6541/40960 [00:24<01:52, 307.21batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6541/40960 [00:24<01:52, 307.21batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6603/40960 [00:24<01:51, 307.84batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6603/40960 [00:24<01:51, 307.84batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6664/40960 [00:24<01:51, 306.89batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6664/40960 [00:24<01:51, 306.89batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6723/40960 [00:25<01:52, 303.02batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6723/40960 [00:25<01:52, 303.02batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6779/40960 [00:25<01:55, 295.13batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6779/40960 [00:25<01:55, 295.13batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6830/40960 [00:25<02:00, 282.17batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6830/40960 [00:25<02:00, 282.17batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|▏| 6878/40960 [00:25<02:07, 268.32batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6878/40960 [00:25<02:07, 268.32batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6933/40960 [00:25<02:06, 269.11batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6933/40960 [00:25<02:06, 269.11batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6989/40960 [00:26<02:04, 271.80batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6989/40960 [00:26<02:04, 271.80batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7040/40960 [00:26<02:07, 265.60batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7040/40960 [00:26<02:07, 265.60batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7092/40960 [00:26<02:08, 262.72batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7092/40960 [00:26<02:08, 262.72batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7145/40960 [00:26<02:08, 262.61batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7145/40960 [00:26<02:08, 262.61batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7200/40960 [00:26<02:06, 265.89batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7200/40960 [00:26<02:06, 265.89batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7255/40960 [00:27<02:05, 267.96batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7255/40960 [00:27<02:05, 267.96batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7308/40960 [00:27<02:06, 265.75batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7308/40960 [00:27<02:06, 265.75batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7362/40960 [00:27<02:05, 266.84batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7362/40960 [00:27<02:05, 266.84batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7416/40960 [00:27<02:05, 266.53batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7416/40960 [00:27<02:05, 266.53batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7470/40960 [00:27<02:05, 267.43batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7470/40960 [00:27<02:05, 267.43batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7524/40960 [00:28<02:05, 267.07batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7524/40960 [00:28<02:05, 267.07batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7579/40960 [00:28<02:04, 269.10batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7579/40960 [00:28<02:04, 269.10batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7636/40960 [00:28<02:01, 273.69batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7636/40960 [00:28<02:01, 273.69batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7693/40960 [00:28<02:00, 276.88batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7693/40960 [00:28<02:00, 276.88batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7750/40960 [00:28<01:59, 278.88batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7750/40960 [00:28<01:59, 278.88batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7805/40960 [00:29<01:59, 277.24batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7805/40960 [00:29<01:59, 277.24batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7862/40960 [00:29<01:58, 278.59batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7862/40960 [00:29<01:58, 278.59batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7921/40960 [00:29<01:57, 282.31batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7921/40960 [00:29<01:57, 282.31batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7974/40960 [00:29<01:59, 276.14batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7974/40960 [00:29<01:59, 276.14batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8028/40960 [00:29<02:00, 273.16batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8028/40960 [00:29<02:00, 273.16batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8088/40960 [00:30<01:57, 280.22batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8088/40960 [00:30<01:57, 280.22batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8149/40960 [00:30<01:54, 287.11batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8149/40960 [00:30<01:54, 287.11batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8209/40960 [00:30<01:53, 289.35batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8209/40960 [00:30<01:53, 289.35batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8261/40960 [00:30<01:56, 280.19batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8261/40960 [00:30<01:56, 280.19batches/s, l2_loss: 0.0458 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8312/40960 [00:30<01:59, 272.40batches/s, l2_loss: 0.0458 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8312/40960 [00:30<01:59, 272.40batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8360/40960 [00:31<02:04, 262.59batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8360/40960 [00:31<02:04, 262.59batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8409/40960 [00:31<02:06, 256.82batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8409/40960 [00:31<02:06, 256.82batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8463/40960 [00:31<02:04, 260.34batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8463/40960 [00:31<02:04, 260.34batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8518/40960 [00:31<02:02, 263.99batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8518/40960 [00:31<02:02, 263.99batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8574/40960 [00:31<02:00, 268.35batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8574/40960 [00:31<02:00, 268.35batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8629/40960 [00:32<01:59, 270.14batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8629/40960 [00:32<01:59, 270.14batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8680/40960 [00:32<02:01, 265.23batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8680/40960 [00:32<02:01, 265.23batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8735/40960 [00:32<02:00, 267.95batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8735/40960 [00:32<02:00, 267.95batches/s, l2_loss: 0.0418 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8787/40960 [00:32<02:01, 265.42batches/s, l2_loss: 0.0418 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8787/40960 [00:32<02:01, 265.42batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8842/40960 [00:32<01:59, 267.87batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8842/40960 [00:32<01:59, 267.87batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8894/40960 [00:33<02:01, 263.82batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8894/40960 [00:33<02:01, 263.82batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8942/40960 [00:33<02:04, 256.62batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8942/40960 [00:33<02:04, 256.62batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8992/40960 [00:33<02:05, 254.55batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8992/40960 [00:33<02:05, 254.55batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9044/40960 [00:33<02:04, 255.78batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9044/40960 [00:33<02:04, 255.78batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9099/40960 [00:33<02:02, 260.63batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9099/40960 [00:33<02:02, 260.63batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9155/40960 [00:34<01:59, 265.48batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9155/40960 [00:34<01:59, 265.48batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9213/40960 [00:34<01:56, 272.41batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9213/40960 [00:34<01:56, 272.41batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9268/40960 [00:34<01:56, 272.00batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|▏| 9268/40960 [00:34<01:56, 272.00batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9325/40960 [00:34<01:55, 275.03batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9325/40960 [00:34<01:55, 275.03batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9381/40960 [00:34<01:54, 275.79batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9381/40960 [00:34<01:54, 275.79batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9432/40960 [00:35<01:57, 268.49batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9432/40960 [00:35<01:57, 268.49batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9485/40960 [00:35<01:57, 267.43batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9485/40960 [00:35<01:57, 267.43batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9545/40960 [00:35<01:53, 276.91batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9545/40960 [00:35<01:53, 276.91batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9604/40960 [00:35<01:51, 281.34batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9604/40960 [00:35<01:51, 281.34batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9660/40960 [00:35<01:51, 280.69batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9660/40960 [00:35<01:51, 280.69batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9712/40960 [00:36<01:54, 273.97batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9712/40960 [00:36<01:54, 273.97batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9761/40960 [00:36<01:57, 265.07batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9761/40960 [00:36<01:57, 265.07batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9815/40960 [00:36<01:57, 265.51batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9815/40960 [00:36<01:57, 265.51batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9867/40960 [00:36<01:57, 263.70batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9867/40960 [00:36<01:57, 263.70batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9919/40960 [00:36<01:58, 261.93batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9919/40960 [00:36<01:58, 261.93batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9970/40960 [00:37<01:59, 259.32batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9970/40960 [00:37<01:59, 259.32batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10019/40960 [00:37<02:01, 253.99batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  24%|▏| 10019/40960 [00:37<02:01, 253.99batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  25%|▏| 10074/40960 [00:37<01:59, 259.18batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  25%|▏| 10074/40960 [00:37<01:59, 259.18batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  25%|▏| 10129/40960 [00:37<01:57, 262.81batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  25%|▏| 10129/40960 [00:37<01:57, 262.81batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  25%|▏| 10186/40960 [00:37<01:54, 268.87batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  25%|▏| 10186/40960 [00:37<01:54, 268.87batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  25%|▎| 10243/40960 [00:38<01:52, 272.89batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  25%|▎| 10243/40960 [00:38<01:52, 272.89batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  25%|▎| 10300/40960 [00:38<01:51, 275.44batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  25%|▎| 10300/40960 [00:38<01:51, 275.44batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  25%|▎| 10359/40960 [00:38<01:49, 280.39batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  25%|▎| 10359/40960 [00:38<01:49, 280.39batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  25%|▎| 10417/40960 [00:38<01:47, 283.15batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  25%|▎| 10417/40960 [00:38<01:47, 283.15batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  26%|▎| 10469/40960 [00:38<01:50, 275.08batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  26%|▎| 10469/40960 [00:38<01:50, 275.08batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  26%|▎| 10523/40960 [00:39<01:51, 272.44batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  26%|▎| 10523/40960 [00:39<01:51, 272.44batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  26%|▎| 10572/40960 [00:39<01:55, 263.19batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  26%|▎| 10572/40960 [00:39<01:55, 263.19batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  26%|▎| 10628/40960 [00:39<01:53, 267.85batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  26%|▎| 10628/40960 [00:39<01:53, 267.85batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  26%|▎| 10685/40960 [00:39<01:51, 271.69batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  26%|▎| 10685/40960 [00:39<01:51, 271.69batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  26%|▎| 10740/40960 [00:39<01:51, 271.52batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  26%|▎| 10740/40960 [00:39<01:51, 271.52batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  26%|▎| 10792/40960 [00:40<01:52, 267.38batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  26%|▎| 10792/40960 [00:40<01:52, 267.38batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  26%|▎| 10845/40960 [00:40<01:53, 266.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  26%|▎| 10845/40960 [00:40<01:53, 266.32batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  27%|▎| 10903/40960 [00:40<01:50, 272.28batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  27%|▎| 10903/40960 [00:40<01:50, 272.28batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  27%|▎| 10962/40960 [00:40<01:47, 277.96batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  27%|▎| 10962/40960 [00:40<01:47, 277.96batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  27%|▎| 11017/40960 [00:40<01:48, 275.56batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  27%|▎| 11017/40960 [00:40<01:48, 275.56batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  27%|▎| 11068/40960 [00:41<01:51, 267.74batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  27%|▎| 11068/40960 [00:41<01:51, 267.74batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  27%|▎| 11116/40960 [00:41<01:55, 259.48batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  27%|▎| 11116/40960 [00:41<01:55, 259.48batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  27%|▎| 11168/40960 [00:41<01:54, 259.56batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  27%|▎| 11168/40960 [00:41<01:54, 259.56batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  27%|▎| 11224/40960 [00:41<01:52, 264.13batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  27%|▎| 11224/40960 [00:41<01:52, 264.13batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  28%|▎| 11280/40960 [00:42<01:50, 267.45batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  28%|▎| 11280/40960 [00:42<01:50, 267.45batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  28%|▎| 11339/40960 [00:42<01:47, 274.77batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  28%|▎| 11339/40960 [00:42<01:47, 274.77batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  28%|▎| 11391/40960 [00:42<01:49, 269.32batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  28%|▎| 11391/40960 [00:42<01:49, 269.32batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  28%|▎| 11442/40960 [00:42<01:51, 263.77batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  28%|▎| 11442/40960 [00:42<01:51, 263.77batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  28%|▎| 11497/40960 [00:42<01:50, 266.69batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  28%|▎| 11497/40960 [00:42<01:50, 266.69batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  28%|▎| 11550/40960 [00:43<01:50, 265.38batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  28%|▎| 11550/40960 [00:43<01:50, 265.38batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  28%|▎| 11609/40960 [00:43<01:47, 273.63batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  28%|▎| 11609/40960 [00:43<01:47, 273.63batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  28%|▎| 11668/40960 [00:43<01:45, 278.24batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  28%|▎| 11668/40960 [00:43<01:45, 278.24batches/s, l2_loss: 0.0425 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|▎| 11727/40960 [00:43<01:43, 282.44batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  29%|▎| 11727/40960 [00:43<01:43, 282.44batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  29%|▎| 11787/40960 [00:43<01:41, 286.84batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  29%|▎| 11787/40960 [00:43<01:41, 286.84batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  29%|▎| 11849/40960 [00:44<01:39, 292.53batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  29%|▎| 11849/40960 [00:44<01:39, 292.53batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  29%|▎| 11909/40960 [00:44<01:38, 294.49batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  29%|▎| 11909/40960 [00:44<01:38, 294.49batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  29%|▎| 11967/40960 [00:44<01:38, 292.91batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  29%|▎| 11967/40960 [00:44<01:38, 292.91batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  29%|▎| 12026/40960 [00:44<01:38, 293.35batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  29%|▎| 12026/40960 [00:44<01:38, 293.35batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  30%|▎| 12087/40960 [00:44<01:37, 296.09batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  30%|▎| 12087/40960 [00:44<01:37, 296.09batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  30%|▎| 12145/40960 [00:45<01:38, 293.63batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  30%|▎| 12145/40960 [00:45<01:38, 293.63batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  30%|▎| 12202/40960 [00:45<01:39, 289.59batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  30%|▎| 12202/40960 [00:45<01:39, 289.59batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  30%|▎| 12258/40960 [00:45<01:40, 286.20batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  30%|▎| 12258/40960 [00:45<01:40, 286.20batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  30%|▎| 12316/40960 [00:45<01:39, 286.72batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  30%|▎| 12316/40960 [00:45<01:39, 286.72batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  30%|▎| 12373/40960 [00:45<01:40, 285.67batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  30%|▎| 12373/40960 [00:45<01:40, 285.67batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  30%|▎| 12430/40960 [00:46<01:40, 284.46batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  30%|▎| 12430/40960 [00:46<01:40, 284.46batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  30%|▎| 12490/40960 [00:46<01:38, 288.70batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  30%|▎| 12490/40960 [00:46<01:38, 288.70batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  31%|▎| 12548/40960 [00:46<01:38, 288.20batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  31%|▎| 12548/40960 [00:46<01:38, 288.20batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  31%|▎| 12608/40960 [00:46<01:37, 291.52batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  31%|▎| 12608/40960 [00:46<01:37, 291.52batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  31%|▎| 12668/40960 [00:46<01:36, 293.20batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  31%|▎| 12668/40960 [00:46<01:36, 293.20batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  31%|▎| 12728/40960 [00:47<01:35, 295.16batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  31%|▎| 12728/40960 [00:47<01:35, 295.16batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  31%|▎| 12788/40960 [00:47<01:35, 296.24batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  31%|▎| 12788/40960 [00:47<01:35, 296.24batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  31%|▎| 12848/40960 [00:47<01:34, 296.19batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  31%|▎| 12848/40960 [00:47<01:34, 296.19batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 12908/40960 [00:47<01:34, 295.84batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 12908/40960 [00:47<01:34, 295.84batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 12964/40960 [00:47<01:36, 290.22batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 12964/40960 [00:47<01:36, 290.22batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13020/40960 [00:48<01:37, 286.50batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13020/40960 [00:48<01:37, 286.50batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13068/40960 [00:48<01:42, 271.81batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13068/40960 [00:48<01:42, 271.81batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13126/40960 [00:48<01:40, 275.94batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13126/40960 [00:48<01:40, 275.94batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13180/40960 [00:48<01:41, 273.06batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13180/40960 [00:48<01:41, 273.06batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13238/40960 [00:48<01:39, 277.54batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  32%|▎| 13238/40960 [00:48<01:39, 277.54batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  32%|▎| 13296/40960 [00:49<01:38, 281.12batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  32%|▎| 13296/40960 [00:49<01:38, 281.12batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13354/40960 [00:49<01:37, 283.04batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13354/40960 [00:49<01:37, 283.04batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  33%|▎| 13413/40960 [00:49<01:36, 285.14batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  33%|▎| 13413/40960 [00:49<01:36, 285.14batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13469/40960 [00:49<01:37, 282.53batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13469/40960 [00:49<01:37, 282.53batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13523/40960 [00:49<01:38, 278.41batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13523/40960 [00:49<01:38, 278.41batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13583/40960 [00:50<01:36, 283.32batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13583/40960 [00:50<01:36, 283.32batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13635/40960 [00:50<01:39, 275.22batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13635/40960 [00:50<01:39, 275.22batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13687/40960 [00:50<01:40, 270.56batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  33%|▎| 13687/40960 [00:50<01:40, 270.56batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 13739/40960 [00:50<01:41, 267.12batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 13739/40960 [00:50<01:41, 267.12batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 13798/40960 [00:50<01:38, 275.15batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 13798/40960 [00:50<01:38, 275.15batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  34%|▎| 13855/40960 [00:51<01:37, 277.51batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  34%|▎| 13855/40960 [00:51<01:37, 277.51batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 13911/40960 [00:51<01:37, 277.93batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 13911/40960 [00:51<01:37, 277.93batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 13969/40960 [00:51<01:36, 280.50batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 13969/40960 [00:51<01:36, 280.50batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 14025/40960 [00:51<01:36, 279.97batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 14025/40960 [00:51<01:36, 279.97batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 14082/40960 [00:51<01:35, 280.23batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 14082/40960 [00:51<01:35, 280.23batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 14131/40960 [00:52<01:39, 269.02batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  34%|▎| 14131/40960 [00:52<01:39, 269.02batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14184/40960 [00:52<01:40, 267.29batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14184/40960 [00:52<01:40, 267.29batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14235/40960 [00:52<01:41, 262.69batches/s, l2_loss: 0.0425 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14235/40960 [00:52<01:41, 262.69batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  35%|▎| 14290/40960 [00:52<01:40, 265.94batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  35%|▎| 14290/40960 [00:52<01:40, 265.94batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14347/40960 [00:52<01:38, 270.98batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14347/40960 [00:52<01:38, 270.98batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14406/40960 [00:53<01:35, 277.59batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14406/40960 [00:53<01:35, 277.59batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14464/40960 [00:53<01:34, 280.67batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14464/40960 [00:53<01:34, 280.67batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14519/40960 [00:53<01:35, 277.49batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  35%|▎| 14519/40960 [00:53<01:35, 277.49batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14576/40960 [00:53<01:34, 279.40batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14576/40960 [00:53<01:34, 279.40batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14632/40960 [00:53<01:34, 277.82batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14632/40960 [00:53<01:34, 277.82batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14688/40960 [00:54<01:34, 278.26batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14688/40960 [00:54<01:34, 278.26batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14744/40960 [00:54<01:34, 278.05batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14744/40960 [00:54<01:34, 278.05batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14801/40960 [00:54<01:33, 278.42batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14801/40960 [00:54<01:33, 278.42batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14861/40960 [00:54<01:31, 284.56batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14861/40960 [00:54<01:31, 284.56batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14920/40960 [00:54<01:30, 287.02batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  36%|▎| 14920/40960 [00:54<01:30, 287.02batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 14977/40960 [00:55<01:30, 285.62batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 14977/40960 [00:55<01:30, 285.62batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 15033/40960 [00:55<01:31, 283.78batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 15033/40960 [00:55<01:31, 283.78batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 15089/40960 [00:55<01:31, 281.66batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 15089/40960 [00:55<01:31, 281.66batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 15146/40960 [00:55<01:31, 281.94batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 15146/40960 [00:55<01:31, 281.94batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  37%|▎| 15197/40960 [00:55<01:34, 273.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  37%|▎| 15197/40960 [00:55<01:34, 273.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  37%|▎| 15250/40960 [00:56<01:35, 268.84batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  37%|▎| 15250/40960 [00:56<01:35, 268.84batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 15297/40960 [00:56<01:40, 256.19batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  37%|▎| 15297/40960 [00:56<01:40, 256.19batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  37%|▎| 15357/40960 [00:56<01:35, 268.82batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  37%|▎| 15357/40960 [00:56<01:35, 268.82batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15410/40960 [00:56<01:35, 267.23batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15410/40960 [00:56<01:35, 267.23batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15462/40960 [00:56<01:36, 264.56batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15462/40960 [00:56<01:36, 264.56batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15518/40960 [00:57<01:34, 268.80batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15518/40960 [00:57<01:34, 268.80batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15570/40960 [00:57<01:35, 265.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15570/40960 [00:57<01:35, 265.22batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  38%|▍| 15630/40960 [00:57<01:32, 274.42batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  38%|▍| 15630/40960 [00:57<01:32, 274.42batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15689/40960 [00:57<01:30, 280.41batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  38%|▍| 15689/40960 [00:57<01:30, 280.41batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  38%|▍| 15748/40960 [00:57<01:28, 283.54batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  38%|▍| 15748/40960 [00:57<01:28, 283.54batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 15808/40960 [00:58<01:27, 287.26batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 15808/40960 [00:58<01:27, 287.26batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 15865/40960 [00:58<01:27, 285.98batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 15865/40960 [00:58<01:27, 285.98batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 15925/40960 [00:58<01:26, 288.89batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 15925/40960 [00:58<01:26, 288.89batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 15983/40960 [00:58<01:26, 288.69batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 15983/40960 [00:58<01:26, 288.69batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 16040/40960 [00:58<01:26, 286.88batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  39%|▍| 16040/40960 [00:58<01:26, 286.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  39%|▍| 16100/40960 [00:59<01:25, 290.42batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  39%|▍| 16100/40960 [00:59<01:25, 290.42batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  39%|▍| 16160/40960 [00:59<01:24, 293.05batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  39%|▍| 16160/40960 [00:59<01:24, 293.05batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16216/40960 [00:59<01:25, 288.83batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16216/40960 [00:59<01:25, 288.83batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16275/40960 [00:59<01:25, 289.70batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16275/40960 [00:59<01:25, 289.70batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  40%|▍| 16333/40960 [00:59<01:25, 288.86batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  40%|▍| 16333/40960 [00:59<01:25, 288.86batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16388/40960 [01:00<01:26, 283.86batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16388/40960 [01:00<01:26, 283.86batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16446/40960 [01:00<01:26, 284.51batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16446/40960 [01:00<01:26, 284.51batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  40%|▍| 16507/40960 [01:00<01:24, 289.81batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  40%|▍| 16507/40960 [01:00<01:24, 289.81batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16567/40960 [01:00<01:23, 291.98batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  40%|▍| 16567/40960 [01:00<01:23, 291.98batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  41%|▍| 16625/40960 [01:00<01:23, 291.31batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  41%|▍| 16625/40960 [01:00<01:23, 291.31batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  41%|▍| 16684/40960 [01:01<01:23, 291.46batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  41%|▍| 16684/40960 [01:01<01:23, 291.46batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  41%|▍| 16743/40960 [01:01<01:22, 291.98batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  41%|▍| 16743/40960 [01:01<01:22, 291.98batches/s, l2_loss: 0.0425 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|▍| 16801/40960 [01:01<01:23, 290.61batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  41%|▍| 16801/40960 [01:01<01:23, 290.61batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  41%|▍| 16859/40960 [01:01<01:23, 289.07batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  41%|▍| 16859/40960 [01:01<01:23, 289.07batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  41%|▍| 16919/40960 [01:01<01:22, 291.51batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  41%|▍| 16919/40960 [01:01<01:22, 291.51batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  41%|▍| 16978/40960 [01:02<01:22, 291.11batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  41%|▍| 16978/40960 [01:02<01:22, 291.11batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  42%|▍| 17030/40960 [01:02<01:25, 280.64batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  42%|▍| 17030/40960 [01:02<01:25, 280.64batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  42%|▍| 17087/40960 [01:02<01:24, 281.82batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  42%|▍| 17087/40960 [01:02<01:24, 281.82batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  42%|▍| 17146/40960 [01:02<01:23, 284.72batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  42%|▍| 17146/40960 [01:02<01:23, 284.72batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  42%|▍| 17206/40960 [01:02<01:22, 288.34batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  42%|▍| 17206/40960 [01:03<01:22, 288.34batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  42%|▍| 17263/40960 [01:03<01:22, 287.29batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  42%|▍| 17263/40960 [01:03<01:22, 287.29batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  42%|▍| 17323/40960 [01:03<01:21, 290.21batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  42%|▍| 17323/40960 [01:03<01:21, 290.21batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  42%|▍| 17383/40960 [01:03<01:20, 292.83batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  42%|▍| 17383/40960 [01:03<01:20, 292.83batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  43%|▍| 17441/40960 [01:03<01:20, 291.49batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  43%|▍| 17441/40960 [01:03<01:20, 291.49batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  43%|▍| 17501/40960 [01:04<01:19, 293.47batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  43%|▍| 17501/40960 [01:04<01:19, 293.47batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  43%|▍| 17562/40960 [01:04<01:19, 295.64batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  43%|▍| 17562/40960 [01:04<01:19, 295.64batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  43%|▍| 17620/40960 [01:04<01:19, 292.66batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  43%|▍| 17620/40960 [01:04<01:19, 292.66batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  43%|▍| 17681/40960 [01:04<01:18, 294.98batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  43%|▍| 17681/40960 [01:04<01:18, 294.98batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  43%|▍| 17737/40960 [01:04<01:20, 289.78batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  43%|▍| 17737/40960 [01:04<01:20, 289.78batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  43%|▍| 17798/40960 [01:05<01:19, 292.90batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  43%|▍| 17798/40960 [01:05<01:19, 292.90batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  44%|▍| 17856/40960 [01:05<01:19, 291.17batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  44%|▍| 17856/40960 [01:05<01:19, 291.17batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  44%|▍| 17916/40960 [01:05<01:18, 292.68batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  44%|▍| 17916/40960 [01:05<01:18, 292.68batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  44%|▍| 17975/40960 [01:05<01:18, 293.33batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  44%|▍| 17975/40960 [01:05<01:18, 293.33batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  44%|▍| 18031/40960 [01:05<01:19, 288.61batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  44%|▍| 18031/40960 [01:05<01:19, 288.61batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  44%|▍| 18088/40960 [01:06<01:19, 286.61batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  44%|▍| 18088/40960 [01:06<01:19, 286.61batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  44%|▍| 18147/40960 [01:06<01:19, 287.79batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  44%|▍| 18147/40960 [01:06<01:19, 287.79batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  44%|▍| 18208/40960 [01:06<01:17, 292.26batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  44%|▍| 18208/40960 [01:06<01:17, 292.26batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18269/40960 [01:06<01:16, 295.08batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18269/40960 [01:06<01:16, 295.08batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18326/40960 [01:06<01:17, 291.84batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18326/40960 [01:06<01:17, 291.84batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18387/40960 [01:07<01:16, 295.31batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18387/40960 [01:07<01:16, 295.31batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18446/40960 [01:07<01:16, 294.66batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18446/40960 [01:07<01:16, 294.66batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  45%|▍| 18505/40960 [01:07<01:16, 293.58batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  45%|▍| 18505/40960 [01:07<01:16, 293.58batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  45%|▍| 18562/40960 [01:07<01:17, 290.22batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  45%|▍| 18562/40960 [01:07<01:17, 290.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18621/40960 [01:07<01:16, 290.69batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  45%|▍| 18621/40960 [01:07<01:16, 290.69batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  46%|▍| 18680/40960 [01:08<01:16, 291.68batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  46%|▍| 18680/40960 [01:08<01:16, 291.68batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18735/40960 [01:08<01:18, 284.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18735/40960 [01:08<01:18, 284.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18785/40960 [01:08<01:21, 273.49batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18785/40960 [01:08<01:21, 273.49batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18837/40960 [01:08<01:22, 268.42batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18837/40960 [01:08<01:22, 268.42batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18885/40960 [01:08<01:25, 258.89batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18885/40960 [01:08<01:25, 258.89batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18934/40960 [01:09<01:26, 254.37batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18934/40960 [01:09<01:26, 254.37batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18992/40960 [01:09<01:23, 264.03batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 18992/40960 [01:09<01:23, 264.03batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 19044/40960 [01:09<01:23, 262.14batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  46%|▍| 19044/40960 [01:09<01:23, 262.14batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19095/40960 [01:09<01:24, 258.63batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19095/40960 [01:09<01:24, 258.63batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  47%|▍| 19150/40960 [01:09<01:22, 262.81batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  47%|▍| 19150/40960 [01:09<01:22, 262.81batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  47%|▍| 19211/40960 [01:10<01:19, 274.55batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  47%|▍| 19211/40960 [01:10<01:19, 274.55batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19257/40960 [01:10<01:23, 259.78batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19257/40960 [01:10<01:23, 259.78batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19309/40960 [01:10<01:23, 258.66batches/s, l2_loss: 0.0424 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|▍| 19309/40960 [01:10<01:23, 258.66batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19361/40960 [01:10<01:23, 258.11batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19361/40960 [01:10<01:23, 258.11batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19419/40960 [01:10<01:20, 266.53batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  47%|▍| 19419/40960 [01:10<01:20, 266.53batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19478/40960 [01:11<01:18, 273.94batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19478/40960 [01:11<01:18, 273.94batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19535/40960 [01:11<01:17, 275.61batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19535/40960 [01:11<01:17, 275.61batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  48%|▍| 19590/40960 [01:11<01:17, 275.21batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  48%|▍| 19590/40960 [01:11<01:17, 275.21batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19643/40960 [01:11<01:18, 271.61batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19643/40960 [01:11<01:18, 271.61batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19695/40960 [01:11<01:19, 267.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19695/40960 [01:11<01:19, 267.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19749/40960 [01:12<01:19, 267.29batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19749/40960 [01:12<01:19, 267.29batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19802/40960 [01:12<01:19, 264.93batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19802/40960 [01:12<01:19, 264.93batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19855/40960 [01:12<01:19, 264.73batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  48%|▍| 19855/40960 [01:12<01:19, 264.73batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 19909/40960 [01:12<01:19, 265.97batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 19909/40960 [01:12<01:19, 265.97batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 19967/40960 [01:12<01:17, 272.51batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 19967/40960 [01:12<01:17, 272.51batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20018/40960 [01:13<01:18, 267.00batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20018/40960 [01:13<01:18, 267.00batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20076/40960 [01:13<01:16, 273.51batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20076/40960 [01:13<01:16, 273.51batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20131/40960 [01:13<01:16, 272.94batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20131/40960 [01:13<01:16, 272.94batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20182/40960 [01:13<01:17, 266.95batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20182/40960 [01:13<01:17, 266.95batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20206/40960 [01:13<01:17, 266.95batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20258/40960 [01:14<01:29, 230.78batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  49%|▍| 20258/40960 [01:14<01:29, 230.78batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▍| 20316/40960 [01:14<01:24, 244.55batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▍| 20316/40960 [01:14<01:24, 244.55batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▍| 20343/40960 [01:14<01:35, 215.91batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▍| 20343/40960 [01:14<01:35, 215.91batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▍| 20401/40960 [01:14<01:27, 235.93batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▍| 20401/40960 [01:14<01:27, 235.93batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▍| 20460/40960 [01:14<01:21, 252.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▍| 20460/40960 [01:14<01:21, 252.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20500/40960 [01:15<01:27, 233.90batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20500/40960 [01:15<01:27, 233.90batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20539/40960 [01:15<01:31, 222.06batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20539/40960 [01:15<01:31, 222.06batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20590/40960 [01:15<01:27, 231.57batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20590/40960 [01:15<01:27, 231.57batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20617/40960 [01:15<01:41, 199.52batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20617/40960 [01:15<01:41, 199.52batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20674/40960 [01:15<01:30, 224.19batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  50%|▌| 20674/40960 [01:15<01:30, 224.19batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  51%|▌| 20729/40960 [01:16<01:24, 238.77batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  51%|▌| 20729/40960 [01:16<01:24, 238.77batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 20781/40960 [01:16<01:22, 244.47batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 20781/40960 [01:16<01:22, 244.47batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 20835/40960 [01:16<01:20, 251.18batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 20835/40960 [01:16<01:20, 251.18batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 20895/40960 [01:16<01:15, 264.69batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 20895/40960 [01:16<01:15, 264.69batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 20953/40960 [01:16<01:13, 271.07batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 20953/40960 [01:16<01:13, 271.07batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 21002/40960 [01:17<01:16, 261.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 21002/40960 [01:17<01:16, 261.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 21039/40960 [01:17<01:23, 238.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 21039/40960 [01:17<01:23, 238.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 21092/40960 [01:17<01:21, 244.76batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  51%|▌| 21092/40960 [01:17<01:21, 244.76batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21143/40960 [01:17<01:20, 247.40batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21143/40960 [01:17<01:20, 247.40batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21193/40960 [01:17<01:20, 245.15batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21193/40960 [01:17<01:20, 245.15batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21248/40960 [01:18<01:17, 253.13batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21248/40960 [01:18<01:17, 253.13batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21303/40960 [01:18<01:15, 259.05batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21303/40960 [01:18<01:15, 259.05batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21358/40960 [01:18<01:14, 263.03batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21358/40960 [01:18<01:14, 263.03batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21397/40960 [01:18<01:20, 242.44batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21397/40960 [01:18<01:20, 242.44batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21444/40960 [01:18<01:21, 239.60batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21444/40960 [01:18<01:21, 239.60batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21496/40960 [01:19<01:19, 245.28batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  52%|▌| 21496/40960 [01:19<01:19, 245.28batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21545/40960 [01:19<01:20, 240.10batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21545/40960 [01:19<01:20, 240.10batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21600/40960 [01:19<01:17, 249.53batches/s, l2_loss: 0.0424 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|▌| 21600/40960 [01:19<01:17, 249.53batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21658/40960 [01:19<01:13, 260.99batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21658/40960 [01:19<01:13, 260.99batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21714/40960 [01:20<01:12, 265.54batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21714/40960 [01:20<01:12, 265.54batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21766/40960 [01:20<01:13, 261.85batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21766/40960 [01:20<01:13, 261.85batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21820/40960 [01:20<01:12, 263.35batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21820/40960 [01:20<01:12, 263.35batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21871/40960 [01:20<01:13, 259.91batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  53%|▌| 21871/40960 [01:20<01:13, 259.91batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 21930/40960 [01:20<01:10, 269.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 21930/40960 [01:20<01:10, 269.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 21987/40960 [01:21<01:09, 273.23batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 21987/40960 [01:21<01:09, 273.23batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22045/40960 [01:21<01:08, 277.29batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22045/40960 [01:21<01:08, 277.29batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22103/40960 [01:21<01:07, 280.71batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22103/40960 [01:21<01:07, 280.71batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22140/40960 [01:21<01:14, 251.34batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22140/40960 [01:21<01:14, 251.34batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22189/40960 [01:21<01:15, 249.27batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22189/40960 [01:21<01:15, 249.27batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22249/40960 [01:22<01:10, 263.60batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22249/40960 [01:22<01:10, 263.60batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22287/40960 [01:22<01:17, 241.56batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  54%|▌| 22287/40960 [01:22<01:17, 241.56batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22324/40960 [01:22<01:22, 224.65batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22324/40960 [01:22<01:22, 224.65batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22383/40960 [01:22<01:15, 245.02batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22383/40960 [01:22<01:15, 245.02batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22443/40960 [01:22<01:10, 260.85batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22443/40960 [01:22<01:10, 260.85batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22499/40960 [01:23<01:09, 265.25batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22499/40960 [01:23<01:09, 265.25batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22557/40960 [01:23<01:07, 271.91batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22557/40960 [01:23<01:07, 271.91batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22617/40960 [01:23<01:05, 279.05batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22617/40960 [01:23<01:05, 279.05batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22676/40960 [01:23<01:04, 282.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  55%|▌| 22676/40960 [01:23<01:04, 282.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22734/40960 [01:23<01:04, 284.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22734/40960 [01:23<01:04, 284.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22791/40960 [01:24<01:04, 282.79batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22791/40960 [01:24<01:04, 282.79batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22847/40960 [01:24<01:04, 280.63batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22847/40960 [01:24<01:04, 280.63batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22904/40960 [01:24<01:04, 281.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22904/40960 [01:24<01:04, 281.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22961/40960 [01:24<01:04, 281.23batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 22961/40960 [01:24<01:04, 281.23batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 23020/40960 [01:24<01:03, 284.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 23020/40960 [01:24<01:03, 284.04batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 23080/40960 [01:25<01:01, 288.60batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 23080/40960 [01:25<01:01, 288.60batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 23138/40960 [01:25<01:01, 288.17batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  56%|▌| 23138/40960 [01:25<01:01, 288.17batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23188/40960 [01:25<01:04, 276.65batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23188/40960 [01:25<01:04, 276.65batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23243/40960 [01:25<01:04, 274.89batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23243/40960 [01:25<01:04, 274.89batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  57%|▌| 23299/40960 [01:25<01:04, 275.75batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  57%|▌| 23299/40960 [01:25<01:04, 275.75batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23357/40960 [01:26<01:02, 279.81batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23357/40960 [01:26<01:02, 279.81batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23412/40960 [01:26<01:03, 278.34batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23412/40960 [01:26<01:03, 278.34batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23466/40960 [01:26<01:03, 274.36batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23466/40960 [01:26<01:03, 274.36batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23523/40960 [01:26<01:02, 277.00batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  57%|▌| 23523/40960 [01:26<01:02, 277.00batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23585/40960 [01:26<01:00, 285.47batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23585/40960 [01:26<01:00, 285.47batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23642/40960 [01:27<01:00, 285.31batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23642/40960 [01:27<01:00, 285.31batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23700/40960 [01:27<01:00, 286.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23700/40960 [01:27<01:00, 286.22batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23753/40960 [01:27<01:01, 279.64batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23753/40960 [01:27<01:01, 279.64batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23809/40960 [01:27<01:01, 278.57batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23809/40960 [01:27<01:01, 278.57batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23869/40960 [01:27<01:00, 283.89batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23869/40960 [01:27<01:00, 283.89batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23927/40960 [01:28<00:59, 284.13batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  58%|▌| 23927/40960 [01:28<00:59, 284.13batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 23983/40960 [01:28<01:00, 281.82batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 23983/40960 [01:28<01:00, 281.82batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 24038/40960 [01:28<01:00, 279.71batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 24038/40960 [01:28<01:00, 279.71batches/s, l2_loss: 0.0424 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|▌| 24098/40960 [01:28<00:59, 285.70batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 24098/40960 [01:28<00:59, 285.70batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 24155/40960 [01:28<00:59, 284.32batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 24155/40960 [01:28<00:59, 284.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  59%|▌| 24209/40960 [01:29<01:00, 278.36batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  59%|▌| 24209/40960 [01:29<01:00, 278.36batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 24262/40960 [01:29<01:00, 273.98batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  59%|▌| 24262/40960 [01:29<01:00, 273.98batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  59%|▌| 24316/40960 [01:29<01:01, 272.08batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  59%|▌| 24316/40960 [01:29<01:01, 272.08batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24372/40960 [01:29<01:00, 273.39batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24372/40960 [01:29<01:00, 273.39batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24429/40960 [01:29<00:59, 275.61batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24429/40960 [01:29<00:59, 275.61batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24481/40960 [01:30<01:01, 269.20batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24481/40960 [01:30<01:01, 269.20batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24531/40960 [01:30<01:02, 263.35batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24531/40960 [01:30<01:02, 263.35batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24571/40960 [01:30<01:07, 244.24batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24571/40960 [01:30<01:07, 244.24batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24630/40960 [01:30<01:02, 259.38batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24630/40960 [01:30<01:02, 259.38batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24688/40960 [01:30<01:01, 266.56batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24688/40960 [01:30<01:01, 266.56batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24748/40960 [01:31<00:58, 276.11batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  60%|▌| 24748/40960 [01:31<00:58, 276.11batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  61%|▌| 24802/40960 [01:31<00:59, 273.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  61%|▌| 24802/40960 [01:31<00:59, 273.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  61%|▌| 24854/40960 [01:31<00:59, 268.88batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  61%|▌| 24854/40960 [01:31<00:59, 268.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  61%|▌| 24914/40960 [01:31<00:57, 278.14batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  61%|▌| 24914/40960 [01:31<00:57, 278.14batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  61%|▌| 24974/40960 [01:31<00:56, 284.32batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  61%|▌| 24974/40960 [01:31<00:56, 284.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  61%|▌| 25032/40960 [01:32<00:55, 284.63batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  61%|▌| 25032/40960 [01:32<00:55, 284.63batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  61%|▌| 25077/40960 [01:32<00:59, 266.69batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  61%|▌| 25077/40960 [01:32<00:59, 266.69batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  61%|▌| 25135/40960 [01:32<00:58, 272.30batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  61%|▌| 25135/40960 [01:32<00:58, 272.30batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  61%|▌| 25190/40960 [01:32<00:57, 272.91batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  61%|▌| 25190/40960 [01:32<00:57, 272.91batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  62%|▌| 25244/40960 [01:32<00:57, 271.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  62%|▌| 25244/40960 [01:32<00:57, 271.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  62%|▌| 25301/40960 [01:33<00:57, 274.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  62%|▌| 25301/40960 [01:33<00:57, 274.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  62%|▌| 25359/40960 [01:33<00:56, 278.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  62%|▌| 25359/40960 [01:33<00:56, 278.17batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  62%|▌| 25416/40960 [01:33<00:55, 278.93batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  62%|▌| 25416/40960 [01:33<00:55, 278.93batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  62%|▌| 25472/40960 [01:33<00:55, 278.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  62%|▌| 25472/40960 [01:33<00:55, 278.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  62%|▌| 25525/40960 [01:33<00:56, 273.37batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  62%|▌| 25525/40960 [01:33<00:56, 273.37batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  62%|▌| 25582/40960 [01:34<00:55, 276.05batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  62%|▌| 25582/40960 [01:34<00:55, 276.05batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25643/40960 [01:34<00:54, 283.36batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25643/40960 [01:34<00:54, 283.36batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25699/40960 [01:34<00:54, 281.66batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25699/40960 [01:34<00:54, 281.66batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25750/40960 [01:34<00:56, 271.43batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25750/40960 [01:34<00:56, 271.43batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25804/40960 [01:34<00:56, 268.42batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25804/40960 [01:34<00:56, 268.42batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25845/40960 [01:35<01:01, 247.41batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25845/40960 [01:35<01:01, 247.41batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25880/40960 [01:35<01:07, 224.25batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25880/40960 [01:35<01:07, 224.25batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25937/40960 [01:35<01:02, 241.98batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25937/40960 [01:35<01:02, 241.98batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25996/40960 [01:35<00:58, 256.31batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  63%|▋| 25996/40960 [01:35<00:58, 256.31batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26053/40960 [01:35<00:56, 263.91batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26053/40960 [01:35<00:56, 263.91batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26107/40960 [01:36<00:55, 265.24batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26107/40960 [01:36<00:55, 265.24batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  64%|▋| 26162/40960 [01:36<00:55, 266.83batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  64%|▋| 26162/40960 [01:36<00:55, 266.83batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26219/40960 [01:36<00:54, 271.25batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26219/40960 [01:36<00:54, 271.25batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26277/40960 [01:36<00:53, 275.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26277/40960 [01:36<00:53, 275.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26333/40960 [01:36<00:52, 276.45batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  64%|▋| 26333/40960 [01:36<00:52, 276.45batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  64%|▋| 26393/40960 [01:37<00:51, 283.30batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  64%|▋| 26393/40960 [01:37<00:51, 283.30batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  65%|▋| 26453/40960 [01:37<00:50, 287.10batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  65%|▋| 26453/40960 [01:37<00:50, 287.10batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  65%|▋| 26511/40960 [01:37<00:50, 287.86batches/s, l2_loss: 0.0424 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 26511/40960 [01:37<00:50, 287.86batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  65%|▋| 26564/40960 [01:37<00:51, 279.86batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  65%|▋| 26564/40960 [01:37<00:51, 279.86batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  65%|▋| 26620/40960 [01:37<00:51, 279.40batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  65%|▋| 26620/40960 [01:37<00:51, 279.40batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  65%|▋| 26679/40960 [01:38<00:50, 283.50batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  65%|▋| 26679/40960 [01:38<00:50, 283.50batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  65%|▋| 26726/40960 [01:38<00:53, 267.89batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  65%|▋| 26726/40960 [01:38<00:53, 267.89batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  65%|▋| 26780/40960 [01:38<00:53, 267.07batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  65%|▋| 26780/40960 [01:38<00:53, 267.07batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 26834/40960 [01:38<00:52, 267.26batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 26834/40960 [01:38<00:52, 267.26batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 26893/40960 [01:39<00:51, 273.65batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 26893/40960 [01:39<00:51, 273.65batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 26949/40960 [01:39<00:50, 275.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 26949/40960 [01:39<00:50, 275.39batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  66%|▋| 27008/40960 [01:39<00:49, 280.52batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  66%|▋| 27008/40960 [01:39<00:49, 280.52batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 27067/40960 [01:39<00:48, 284.41batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 27067/40960 [01:39<00:48, 284.41batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  66%|▋| 27124/40960 [01:39<00:48, 284.55batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  66%|▋| 27124/40960 [01:39<00:48, 284.55batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 27182/40960 [01:40<00:48, 284.90batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  66%|▋| 27182/40960 [01:40<00:48, 284.90batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  67%|▋| 27241/40960 [01:40<00:47, 287.33batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  67%|▋| 27241/40960 [01:40<00:47, 287.33batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  67%|▋| 27298/40960 [01:40<00:47, 286.19batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  67%|▋| 27298/40960 [01:40<00:47, 286.19batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  67%|▋| 27356/40960 [01:40<00:47, 286.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  67%|▋| 27356/40960 [01:40<00:47, 286.88batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  67%|▋| 27413/40960 [01:40<00:47, 285.99batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  67%|▋| 27413/40960 [01:40<00:47, 285.99batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  67%|▋| 27468/40960 [01:41<00:47, 281.66batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  67%|▋| 27468/40960 [01:41<00:47, 281.66batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  67%|▋| 27520/40960 [01:41<00:49, 273.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  67%|▋| 27520/40960 [01:41<00:49, 273.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  67%|▋| 27568/40960 [01:41<00:50, 262.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  67%|▋| 27568/40960 [01:41<00:50, 262.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  67%|▋| 27617/40960 [01:41<00:52, 256.00batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  67%|▋| 27617/40960 [01:41<00:52, 256.00batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27667/40960 [01:41<00:52, 253.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27667/40960 [01:41<00:52, 253.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27720/40960 [01:42<00:51, 255.97batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27720/40960 [01:42<00:51, 255.97batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  68%|▋| 27775/40960 [01:42<00:50, 261.18batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  68%|▋| 27775/40960 [01:42<00:50, 261.18batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27813/40960 [01:42<00:55, 237.76batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27813/40960 [01:42<00:55, 237.76batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27869/40960 [01:42<00:52, 249.21batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27869/40960 [01:42<00:52, 249.21batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27924/40960 [01:42<00:51, 255.48batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27924/40960 [01:42<00:51, 255.48batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27972/40960 [01:43<00:51, 250.24batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  68%|▋| 27972/40960 [01:43<00:51, 250.24batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  68%|▋| 28023/40960 [01:43<00:51, 251.09batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  68%|▋| 28023/40960 [01:43<00:51, 251.09batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28075/40960 [01:43<00:50, 252.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28075/40960 [01:43<00:50, 252.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28133/40960 [01:43<00:48, 262.99batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28133/40960 [01:43<00:48, 262.99batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28189/40960 [01:43<00:47, 267.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28189/40960 [01:43<00:47, 267.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28247/40960 [01:44<00:46, 273.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28247/40960 [01:44<00:46, 273.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28301/40960 [01:44<00:46, 271.83batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28301/40960 [01:44<00:46, 271.83batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28356/40960 [01:44<00:46, 271.77batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28356/40960 [01:44<00:46, 271.77batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28410/40960 [01:44<00:46, 269.97batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28410/40960 [01:44<00:46, 269.97batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28467/40960 [01:44<00:45, 273.48batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  69%|▋| 28467/40960 [01:44<00:45, 273.48batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28524/40960 [01:45<00:45, 276.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28524/40960 [01:45<00:45, 276.32batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  70%|▋| 28580/40960 [01:45<00:44, 276.32batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  70%|▋| 28580/40960 [01:45<00:44, 276.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28634/40960 [01:45<00:44, 274.06batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28634/40960 [01:45<00:44, 274.06batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28690/40960 [01:45<00:44, 274.49batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28690/40960 [01:45<00:44, 274.49batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28750/40960 [01:45<00:43, 281.22batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28750/40960 [01:45<00:43, 281.22batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28801/40960 [01:46<00:44, 273.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28801/40960 [01:46<00:44, 273.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28855/40960 [01:46<00:44, 271.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  70%|▋| 28855/40960 [01:46<00:44, 271.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 28911/40960 [01:46<00:44, 273.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 28911/40960 [01:46<00:44, 273.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|▋| 28969/40960 [01:46<00:43, 277.50batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 28969/40960 [01:46<00:43, 277.50batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29021/40960 [01:46<00:44, 271.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29021/40960 [01:46<00:44, 271.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29078/40960 [01:47<00:43, 274.62batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29078/40960 [01:47<00:43, 274.62batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29133/40960 [01:47<00:43, 273.94batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29133/40960 [01:47<00:43, 273.94batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29187/40960 [01:47<00:43, 272.62batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29187/40960 [01:47<00:43, 272.62batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29245/40960 [01:47<00:42, 276.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  71%|▋| 29245/40960 [01:47<00:42, 276.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29300/40960 [01:47<00:42, 275.42batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29300/40960 [01:47<00:42, 275.42batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29355/40960 [01:48<00:42, 274.06batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29355/40960 [01:48<00:42, 274.06batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29413/40960 [01:48<00:41, 277.90batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29413/40960 [01:48<00:41, 277.90batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29469/40960 [01:48<00:41, 278.35batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29469/40960 [01:48<00:41, 278.35batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29519/40960 [01:48<00:42, 269.00batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29519/40960 [01:48<00:42, 269.00batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29574/40960 [01:48<00:42, 270.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29574/40960 [01:48<00:42, 270.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29634/40960 [01:49<00:40, 278.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  72%|▋| 29634/40960 [01:49<00:40, 278.29batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  72%|▋| 29690/40960 [01:49<00:40, 278.27batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  72%|▋| 29690/40960 [01:49<00:40, 278.27batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29750/40960 [01:49<00:39, 284.19batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29750/40960 [01:49<00:39, 284.19batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29808/40960 [01:49<00:39, 284.71batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29808/40960 [01:49<00:39, 284.71batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29864/40960 [01:49<00:39, 281.55batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29864/40960 [01:49<00:39, 281.55batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29922/40960 [01:50<00:39, 282.93batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29922/40960 [01:50<00:39, 282.93batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29980/40960 [01:50<00:38, 283.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 29980/40960 [01:50<00:38, 283.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 30037/40960 [01:50<00:38, 282.67batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 30037/40960 [01:50<00:38, 282.67batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 30092/40960 [01:50<00:38, 279.47batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  73%|▋| 30092/40960 [01:50<00:38, 279.47batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30145/40960 [01:50<00:39, 274.63batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30145/40960 [01:50<00:39, 274.63batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30201/40960 [01:51<00:39, 275.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30201/40960 [01:51<00:39, 275.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30258/40960 [01:51<00:38, 278.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30258/40960 [01:51<00:38, 278.17batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  74%|▋| 30312/40960 [01:51<00:38, 275.16batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  74%|▋| 30312/40960 [01:51<00:38, 275.16batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30368/40960 [01:51<00:38, 276.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30368/40960 [01:51<00:38, 276.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30427/40960 [01:51<00:37, 281.11batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30427/40960 [01:51<00:37, 281.11batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30484/40960 [01:52<00:37, 280.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  74%|▋| 30484/40960 [01:52<00:37, 280.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▋| 30540/40960 [01:52<00:37, 280.36batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▋| 30540/40960 [01:52<00:37, 280.36batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▋| 30597/40960 [01:52<00:36, 281.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▋| 30597/40960 [01:52<00:36, 281.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▋| 30656/40960 [01:52<00:36, 284.44batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▋| 30656/40960 [01:52<00:36, 284.44batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▋| 30711/40960 [01:52<00:36, 280.81batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▋| 30711/40960 [01:52<00:36, 280.81batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▊| 30771/40960 [01:53<00:35, 285.47batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▊| 30771/40960 [01:53<00:35, 285.47batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▊| 30829/40960 [01:53<00:35, 286.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▊| 30829/40960 [01:53<00:35, 286.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▊| 30887/40960 [01:53<00:35, 285.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▊| 30887/40960 [01:53<00:35, 285.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 30946/40960 [01:53<00:34, 287.10batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 30946/40960 [01:53<00:34, 287.10batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31002/40960 [01:53<00:34, 284.77batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31002/40960 [01:53<00:34, 284.77batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31061/40960 [01:54<00:34, 286.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31061/40960 [01:54<00:34, 286.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31122/40960 [01:54<00:33, 291.11batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31122/40960 [01:54<00:33, 291.11batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31180/40960 [01:54<00:33, 289.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31180/40960 [01:54<00:33, 289.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31238/40960 [01:54<00:33, 288.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31238/40960 [01:54<00:33, 288.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31297/40960 [01:54<00:33, 289.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31297/40960 [01:54<00:33, 289.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31354/40960 [01:55<00:33, 287.36batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31354/40960 [01:55<00:33, 287.36batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31411/40960 [01:55<00:33, 286.46batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31411/40960 [01:55<00:33, 286.46batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31466/40960 [01:55<00:33, 282.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|▊| 31466/40960 [01:55<00:33, 282.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31523/40960 [01:55<00:33, 283.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31523/40960 [01:55<00:33, 283.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31579/40960 [01:55<00:33, 281.52batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31579/40960 [01:55<00:33, 281.52batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31641/40960 [01:56<00:32, 288.90batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31641/40960 [01:56<00:32, 288.90batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31697/40960 [01:56<00:32, 285.33batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31697/40960 [01:56<00:32, 285.33batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31751/40960 [01:56<00:32, 279.57batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31751/40960 [01:56<00:32, 279.57batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31811/40960 [01:56<00:32, 284.48batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31811/40960 [01:56<00:32, 284.48batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31872/40960 [01:56<00:31, 289.44batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31872/40960 [01:56<00:31, 289.44batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31930/40960 [01:57<00:31, 288.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31930/40960 [01:57<00:31, 288.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31987/40960 [01:57<00:31, 286.34batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 31987/40960 [01:57<00:31, 286.34batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 32043/40960 [01:57<00:31, 284.12batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 32043/40960 [01:57<00:31, 284.12batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 32095/40960 [01:57<00:32, 276.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 32095/40960 [01:57<00:32, 276.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 32149/40960 [01:57<00:32, 273.98batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  78%|▊| 32149/40960 [01:58<00:32, 273.98batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32201/40960 [01:58<00:32, 268.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32201/40960 [01:58<00:32, 268.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32249/40960 [01:58<00:33, 259.72batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32249/40960 [01:58<00:33, 259.72batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32301/40960 [01:58<00:33, 258.99batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32301/40960 [01:58<00:33, 258.99batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32351/40960 [01:58<00:33, 255.80batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32351/40960 [01:58<00:33, 255.80batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32403/40960 [01:59<00:33, 255.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32403/40960 [01:59<00:33, 255.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32460/40960 [01:59<00:32, 263.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32460/40960 [01:59<00:32, 263.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32516/40960 [01:59<00:31, 266.89batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  79%|▊| 32516/40960 [01:59<00:31, 266.89batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32571/40960 [01:59<00:31, 268.06batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32571/40960 [01:59<00:31, 268.06batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32622/40960 [01:59<00:31, 264.08batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32622/40960 [01:59<00:31, 264.08batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32675/40960 [02:00<00:31, 264.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32675/40960 [02:00<00:31, 264.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32724/40960 [02:00<00:32, 256.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32724/40960 [02:00<00:32, 256.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32777/40960 [02:00<00:31, 258.50batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32777/40960 [02:00<00:31, 258.50batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32834/40960 [02:00<00:30, 265.04batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32834/40960 [02:00<00:30, 265.04batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32891/40960 [02:00<00:29, 270.66batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32891/40960 [02:00<00:29, 270.66batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32950/40960 [02:01<00:28, 277.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  80%|▊| 32950/40960 [02:01<00:28, 277.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33008/40960 [02:01<00:28, 280.81batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33008/40960 [02:01<00:28, 280.81batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33065/40960 [02:01<00:28, 280.92batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33065/40960 [02:01<00:28, 280.92batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33121/40960 [02:01<00:27, 280.20batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33121/40960 [02:01<00:27, 280.20batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33182/40960 [02:01<00:27, 286.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33182/40960 [02:01<00:27, 286.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33238/40960 [02:02<00:27, 284.45batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33238/40960 [02:02<00:27, 284.45batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33296/40960 [02:02<00:26, 285.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33296/40960 [02:02<00:26, 285.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33353/40960 [02:02<00:26, 284.73batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  81%|▊| 33353/40960 [02:02<00:26, 284.73batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33407/40960 [02:02<00:27, 278.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33407/40960 [02:02<00:27, 278.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33459/40960 [02:02<00:27, 272.04batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33459/40960 [02:02<00:27, 272.04batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33516/40960 [02:03<00:26, 275.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33516/40960 [02:03<00:26, 275.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33576/40960 [02:03<00:26, 282.88batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33576/40960 [02:03<00:26, 282.88batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33634/40960 [02:03<00:25, 283.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33634/40960 [02:03<00:25, 283.85batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33692/40960 [02:03<00:25, 285.26batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33692/40960 [02:03<00:25, 285.26batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33749/40960 [02:03<00:25, 285.19batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  82%|▊| 33749/40960 [02:03<00:25, 285.19batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 33806/40960 [02:04<00:25, 283.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 33806/40960 [02:04<00:25, 283.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 33847/40960 [02:04<00:27, 259.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 33847/40960 [02:04<00:27, 259.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 33899/40960 [02:04<00:27, 258.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 33899/40960 [02:04<00:27, 258.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 33951/40960 [02:04<00:27, 258.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 33951/40960 [02:04<00:27, 258.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 34010/40960 [02:04<00:25, 268.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 34010/40960 [02:04<00:25, 268.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 34066/40960 [02:05<00:25, 272.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 34066/40960 [02:05<00:25, 272.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 34129/40960 [02:05<00:24, 283.83batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 34129/40960 [02:05<00:24, 283.83batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 34187/40960 [02:05<00:23, 284.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  83%|▊| 34187/40960 [02:05<00:23, 284.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34244/40960 [02:05<00:23, 283.54batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34244/40960 [02:05<00:23, 283.54batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34305/40960 [02:05<00:23, 289.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34305/40960 [02:05<00:23, 289.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34358/40960 [02:06<00:23, 280.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34358/40960 [02:06<00:23, 280.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34403/40960 [02:06<00:24, 262.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34403/40960 [02:06<00:24, 262.74batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34439/40960 [02:06<00:27, 237.64batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34439/40960 [02:06<00:27, 237.64batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34491/40960 [02:06<00:26, 243.38batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34491/40960 [02:06<00:26, 243.38batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34545/40960 [02:06<00:25, 250.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34545/40960 [02:06<00:25, 250.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34603/40960 [02:07<00:24, 261.41batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  84%|▊| 34603/40960 [02:07<00:24, 261.41batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34659/40960 [02:07<00:23, 266.25batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34659/40960 [02:07<00:23, 266.25batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34698/40960 [02:07<00:25, 244.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34698/40960 [02:07<00:25, 244.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34738/40960 [02:07<00:27, 230.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34738/40960 [02:07<00:27, 230.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34789/40960 [02:07<00:25, 237.41batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34789/40960 [02:07<00:25, 237.41batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34840/40960 [02:08<00:25, 240.98batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34840/40960 [02:08<00:25, 240.98batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34896/40960 [02:08<00:24, 251.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34896/40960 [02:08<00:24, 251.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34955/40960 [02:08<00:22, 264.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34955/40960 [02:08<00:22, 264.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34995/40960 [02:08<00:24, 244.07batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  85%|▊| 34995/40960 [02:08<00:24, 244.07batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35055/40960 [02:08<00:22, 260.36batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35055/40960 [02:08<00:22, 260.36batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35111/40960 [02:09<00:22, 265.43batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35111/40960 [02:09<00:22, 265.43batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35172/40960 [02:09<00:20, 277.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35172/40960 [02:09<00:20, 277.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35229/40960 [02:09<00:20, 278.57batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35229/40960 [02:09<00:20, 278.57batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35281/40960 [02:09<00:20, 272.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35281/40960 [02:09<00:20, 272.01batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35338/40960 [02:09<00:20, 275.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35338/40960 [02:09<00:20, 275.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35386/40960 [02:10<00:21, 261.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  86%|▊| 35386/40960 [02:10<00:21, 261.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35435/40960 [02:10<00:21, 255.93batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35435/40960 [02:10<00:21, 255.93batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35494/40960 [02:10<00:20, 266.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35494/40960 [02:10<00:20, 266.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35544/40960 [02:10<00:20, 261.18batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35544/40960 [02:10<00:20, 261.18batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35601/40960 [02:10<00:19, 268.09batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35601/40960 [02:10<00:19, 268.09batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35658/40960 [02:11<00:19, 272.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35658/40960 [02:11<00:19, 272.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35714/40960 [02:11<00:19, 274.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35714/40960 [02:11<00:19, 274.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35773/40960 [02:11<00:18, 279.84batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35773/40960 [02:11<00:18, 279.84batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35830/40960 [02:11<00:18, 280.97batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  87%|▊| 35830/40960 [02:11<00:18, 280.97batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 35890/40960 [02:11<00:17, 285.44batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 35890/40960 [02:11<00:17, 285.44batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 35942/40960 [02:12<00:18, 277.05batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 35942/40960 [02:12<00:18, 277.05batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36002/40960 [02:12<00:17, 283.27batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36002/40960 [02:12<00:17, 283.27batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36058/40960 [02:12<00:17, 281.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36058/40960 [02:12<00:17, 281.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36116/40960 [02:12<00:17, 283.49batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36116/40960 [02:12<00:17, 283.49batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36173/40960 [02:12<00:16, 282.92batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36173/40960 [02:12<00:16, 282.92batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36230/40960 [02:13<00:16, 282.64batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  88%|▉| 36230/40960 [02:13<00:16, 282.64batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36291/40960 [02:13<00:16, 288.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36291/40960 [02:13<00:16, 288.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36340/40960 [02:13<00:16, 274.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36340/40960 [02:13<00:16, 274.82batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36396/40960 [02:13<00:16, 275.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36396/40960 [02:13<00:16, 275.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36451/40960 [02:13<00:16, 274.63batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36451/40960 [02:13<00:16, 274.63batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36511/40960 [02:14<00:15, 281.50batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36511/40960 [02:14<00:15, 281.50batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36568/40960 [02:14<00:15, 282.12batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36568/40960 [02:14<00:15, 282.12batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36621/40960 [02:14<00:15, 276.72batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36621/40960 [02:14<00:15, 276.72batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36679/40960 [02:14<00:15, 280.00batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36679/40960 [02:14<00:15, 280.00batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36735/40960 [02:14<00:15, 278.49batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36735/40960 [02:14<00:15, 278.49batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36784/40960 [02:15<00:15, 266.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36784/40960 [02:15<00:15, 266.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36832/40960 [02:15<00:15, 258.68batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36832/40960 [02:15<00:15, 258.68batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36880/40960 [02:15<00:16, 252.54batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36880/40960 [02:15<00:16, 252.54batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36936/40960 [02:15<00:15, 259.72batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36936/40960 [02:15<00:15, 259.72batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36989/40960 [02:15<00:15, 260.12batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36989/40960 [02:15<00:15, 260.12batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 37035/40960 [02:16<00:15, 250.69batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  90%|▉| 37035/40960 [02:16<00:15, 250.69batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37090/40960 [02:16<00:15, 257.73batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37090/40960 [02:16<00:15, 257.73batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37146/40960 [02:16<00:14, 262.96batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37146/40960 [02:16<00:14, 262.96batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37194/40960 [02:16<00:14, 255.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37194/40960 [02:16<00:14, 255.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37248/40960 [02:16<00:14, 258.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37248/40960 [02:16<00:14, 258.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37305/40960 [02:17<00:13, 266.43batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37305/40960 [02:17<00:13, 266.43batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37363/40960 [02:17<00:13, 272.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37363/40960 [02:17<00:13, 272.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37420/40960 [02:17<00:12, 275.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  91%|▉| 37420/40960 [02:17<00:12, 275.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37479/40960 [02:17<00:12, 280.31batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37479/40960 [02:17<00:12, 280.31batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37536/40960 [02:17<00:12, 281.07batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37536/40960 [02:17<00:12, 281.07batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37593/40960 [02:18<00:11, 281.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37593/40960 [02:18<00:11, 281.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37646/40960 [02:18<00:11, 276.53batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37646/40960 [02:18<00:11, 276.53batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37700/40960 [02:18<00:11, 274.05batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37700/40960 [02:18<00:11, 274.05batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37748/40960 [02:18<00:12, 263.35batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37748/40960 [02:18<00:12, 263.35batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37803/40960 [02:18<00:11, 265.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37803/40960 [02:19<00:11, 265.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37860/40960 [02:19<00:11, 270.63batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  92%|▉| 37860/40960 [02:19<00:11, 270.63batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 37916/40960 [02:19<00:11, 272.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 37916/40960 [02:19<00:11, 272.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 37973/40960 [02:19<00:10, 275.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 37973/40960 [02:19<00:10, 275.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38034/40960 [02:19<00:10, 283.73batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38034/40960 [02:19<00:10, 283.73batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38082/40960 [02:20<00:10, 269.81batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38082/40960 [02:20<00:10, 269.81batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38142/40960 [02:20<00:10, 278.26batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38142/40960 [02:20<00:10, 278.26batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38201/40960 [02:20<00:09, 281.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38201/40960 [02:20<00:09, 281.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38260/40960 [02:20<00:09, 285.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  93%|▉| 38260/40960 [02:20<00:09, 285.39batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38313/40960 [02:20<00:09, 279.18batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38313/40960 [02:20<00:09, 279.18batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38363/40960 [02:21<00:09, 270.42batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38363/40960 [02:21<00:09, 270.42batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [02:21<00:09, 279.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [02:21<00:09, 279.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38478/40960 [02:21<00:08, 275.78batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38478/40960 [02:21<00:08, 275.78batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38538/40960 [02:21<00:08, 281.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38538/40960 [02:21<00:08, 281.51batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38596/40960 [02:21<00:08, 283.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38596/40960 [02:21<00:08, 283.13batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38657/40960 [02:22<00:07, 289.28batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38657/40960 [02:22<00:07, 289.28batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38700/40960 [02:22<00:08, 266.47batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  94%|▉| 38700/40960 [02:22<00:08, 266.47batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38754/40960 [02:22<00:08, 266.84batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38754/40960 [02:22<00:08, 266.84batches/s, l2_loss: 0.0423 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 38811/40960 [02:22<00:07, 271.31batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38811/40960 [02:22<00:07, 271.31batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38870/40960 [02:22<00:07, 278.05batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38870/40960 [02:22<00:07, 278.05batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38929/40960 [02:23<00:07, 281.68batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38929/40960 [02:23<00:07, 281.68batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38986/40960 [02:23<00:06, 282.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 38986/40960 [02:23<00:06, 282.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 39038/40960 [02:23<00:06, 274.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 39038/40960 [02:23<00:06, 274.59batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 39095/40960 [02:23<00:06, 277.26batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  95%|▉| 39095/40960 [02:23<00:06, 277.26batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39151/40960 [02:23<00:06, 277.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39151/40960 [02:23<00:06, 277.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39211/40960 [02:24<00:06, 284.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39211/40960 [02:24<00:06, 284.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39268/40960 [02:24<00:05, 284.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39268/40960 [02:24<00:05, 284.17batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39314/40960 [02:24<00:06, 266.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39314/40960 [02:24<00:06, 266.87batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39348/40960 [02:24<00:06, 236.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39348/40960 [02:24<00:06, 236.29batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39394/40960 [02:24<00:06, 233.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39394/40960 [02:24<00:06, 233.95batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39449/40960 [02:25<00:06, 244.47batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39449/40960 [02:25<00:06, 244.47batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39498/40960 [02:25<00:05, 244.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  96%|▉| 39498/40960 [02:25<00:05, 244.58batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39556/40960 [02:25<00:05, 258.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39556/40960 [02:25<00:05, 258.03batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39609/40960 [02:25<00:05, 259.86batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39609/40960 [02:25<00:05, 259.86batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39664/40960 [02:25<00:04, 263.81batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39664/40960 [02:25<00:04, 263.81batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39721/40960 [02:26<00:04, 269.40batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39721/40960 [02:26<00:04, 269.40batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39780/40960 [02:26<00:04, 275.92batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39780/40960 [02:26<00:04, 275.92batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39839/40960 [02:26<00:03, 281.40batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39839/40960 [02:26<00:03, 281.40batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39896/40960 [02:26<00:03, 281.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  97%|▉| 39896/40960 [02:26<00:03, 281.79batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 39957/40960 [02:26<00:03, 288.60batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 39957/40960 [02:26<00:03, 288.60batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40009/40960 [02:27<00:03, 278.11batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40009/40960 [02:27<00:03, 278.11batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40052/40960 [02:27<00:03, 258.12batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40052/40960 [02:27<00:03, 258.12batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40100/40960 [02:27<00:03, 251.34batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40100/40960 [02:27<00:03, 251.34batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40146/40960 [02:27<00:03, 244.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40146/40960 [02:27<00:03, 244.32batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40190/40960 [02:27<00:03, 234.92batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40190/40960 [02:27<00:03, 234.92batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40235/40960 [02:28<00:03, 230.99batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40235/40960 [02:28<00:03, 230.99batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40284/40960 [02:28<00:02, 235.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40284/40960 [02:28<00:02, 235.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40341/40960 [02:28<00:02, 249.27batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  98%|▉| 40341/40960 [02:28<00:02, 249.27batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40400/40960 [02:28<00:02, 261.99batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40400/40960 [02:28<00:02, 261.99batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40450/40960 [02:28<00:01, 256.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40450/40960 [02:28<00:01, 256.14batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40496/40960 [02:29<00:01, 247.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40496/40960 [02:29<00:01, 247.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40547/40960 [02:29<00:01, 248.71batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40547/40960 [02:29<00:01, 248.71batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40604/40960 [02:29<00:01, 258.94batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40604/40960 [02:29<00:01, 258.94batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40662/40960 [02:29<00:01, 268.04batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40662/40960 [02:29<00:01, 268.04batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40720/40960 [02:29<00:00, 273.43batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  99%|▉| 40720/40960 [02:29<00:00, 273.43batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training: 100%|▉| 40779/40960 [02:30<00:00, 278.80batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training: 100%|▉| 40779/40960 [02:30<00:00, 278.80batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training: 100%|▉| 40841/40960 [02:30<00:00, 286.91batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training: 100%|▉| 40841/40960 [02:30<00:00, 286.91batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training: 100%|▉| 40890/40960 [02:30<00:00, 273.33batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training: 100%|▉| 40890/40960 [02:30<00:00, 273.33batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training: 100%|▉| 40941/40960 [02:30<00:00, 266.41batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training: 100%|▉| 40941/40960 [02:30<00:00, 266.41batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-08 19:29:26.835828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  73%|▋| 19/26 [40:07<17:00, 145.79s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-08 19:29:30.171195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-08 19:29:32.992215: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<11:48:54,  1.04s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<11:48:54,  1.04s/batches, l2_loss: 0.0196 - round_loss:\u001b[A\n",
      "Training:   0%| | 87/40960 [00:01<07:17, 93.52batches/s, l2_loss: 0.0196 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 87/40960 [00:01<07:17, 93.52batches/s, l2_loss: 0.0457 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 173/40960 [00:01<03:56, 172.59batches/s, l2_loss: 0.0457 - round_loss:\u001b[A\n",
      "Training:   0%| | 173/40960 [00:01<03:56, 172.59batches/s, l2_loss: 0.0442 - round_loss:\u001b[A\n",
      "Training:   1%| | 266/40960 [00:01<02:45, 245.54batches/s, l2_loss: 0.0442 - round_loss:\u001b[A\n",
      "Training:   1%| | 266/40960 [00:01<02:45, 245.54batches/s, l2_loss: 0.0440 - round_loss:\u001b[A\n",
      "Training:   1%| | 360/40960 [00:01<02:13, 304.52batches/s, l2_loss: 0.0440 - round_loss:\u001b[A\n",
      "Training:   1%| | 360/40960 [00:01<02:13, 304.52batches/s, l2_loss: 0.0459 - round_loss:\u001b[A\n",
      "Training:   1%| | 449/40960 [00:02<01:58, 342.36batches/s, l2_loss: 0.0459 - round_loss:\u001b[A\n",
      "Training:   1%| | 449/40960 [00:02<01:58, 342.36batches/s, l2_loss: 0.0449 - round_loss:\u001b[A\n",
      "Training:   1%| | 533/40960 [00:02<01:51, 364.00batches/s, l2_loss: 0.0449 - round_loss:\u001b[A\n",
      "Training:   1%| | 533/40960 [00:02<01:51, 364.00batches/s, l2_loss: 0.0438 - round_loss:\u001b[A\n",
      "Training:   2%| | 623/40960 [00:02<01:43, 388.20batches/s, l2_loss: 0.0438 - round_loss:\u001b[A\n",
      "Training:   2%| | 623/40960 [00:02<01:43, 388.20batches/s, l2_loss: 0.0448 - round_loss:\u001b[A\n",
      "Training:   2%| | 710/40960 [00:02<01:40, 400.91batches/s, l2_loss: 0.0448 - round_loss:\u001b[A\n",
      "Training:   2%| | 710/40960 [00:02<01:40, 400.91batches/s, l2_loss: 0.0441 - round_loss:\u001b[A\n",
      "Training:   2%| | 800/40960 [00:02<01:36, 414.24batches/s, l2_loss: 0.0441 - round_loss:\u001b[A\n",
      "Training:   2%| | 800/40960 [00:02<01:36, 414.24batches/s, l2_loss: 0.0445 - round_loss:\u001b[A\n",
      "Training:   2%| | 888/40960 [00:03<01:35, 420.74batches/s, l2_loss: 0.0445 - round_loss:\u001b[A\n",
      "Training:   2%| | 888/40960 [00:03<01:35, 420.74batches/s, l2_loss: 0.0439 - round_loss:\u001b[A\n",
      "Training:   2%| | 961/40960 [00:03<01:39, 403.58batches/s, l2_loss: 0.0439 - round_loss:\u001b[A\n",
      "Training:   2%| | 961/40960 [00:03<01:39, 403.58batches/s, l2_loss: 0.0451 - round_loss:\u001b[A\n",
      "Training:   3%| | 1052/40960 [00:03<01:35, 418.61batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:   3%| | 1052/40960 [00:03<01:35, 418.61batches/s, l2_loss: 0.0443 - round_loss\u001b[A\n",
      "Training:   3%| | 1118/40960 [00:03<01:42, 390.08batches/s, l2_loss: 0.0443 - round_loss\u001b[A\n",
      "Training:   3%| | 1118/40960 [00:03<01:42, 390.08batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   3%| | 1199/40960 [00:03<01:40, 393.89batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   3%| | 1199/40960 [00:03<01:40, 393.89batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   3%| | 1287/40960 [00:04<01:37, 406.70batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   3%| | 1287/40960 [00:04<01:37, 406.70batches/s, l2_loss: 0.0440 - round_loss\u001b[A\n",
      "Training:   3%| | 1374/40960 [00:04<01:35, 413.99batches/s, l2_loss: 0.0440 - round_loss\u001b[A\n",
      "Training:   3%| | 1374/40960 [00:04<01:35, 413.99batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:   4%| | 1458/40960 [00:04<01:35, 414.51batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:   4%| | 1458/40960 [00:04<01:35, 414.51batches/s, l2_loss: 0.0440 - round_loss\u001b[A\n",
      "Training:   4%| | 1547/40960 [00:04<01:33, 422.83batches/s, l2_loss: 0.0440 - round_loss\u001b[A\n",
      "Training:   4%| | 1547/40960 [00:04<01:33, 422.83batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   4%| | 1637/40960 [00:04<01:31, 430.73batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   4%| | 1637/40960 [00:04<01:31, 430.73batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   4%| | 1721/40960 [00:05<01:32, 425.88batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   4%| | 1721/40960 [00:05<01:32, 425.88batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:   4%| | 1805/40960 [00:05<01:32, 423.53batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:   4%| | 1805/40960 [00:05<01:32, 423.53batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   5%| | 1890/40960 [00:05<01:32, 422.81batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   5%| | 1890/40960 [00:05<01:32, 422.81batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   5%| | 1978/40960 [00:05<01:31, 427.05batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   5%| | 1978/40960 [00:05<01:31, 427.05batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   5%| | 2058/40960 [00:05<01:33, 417.51batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   5%| | 2058/40960 [00:05<01:33, 417.51batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   5%| | 2116/40960 [00:06<01:42, 378.69batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   5%| | 2116/40960 [00:06<01:42, 378.69batches/s, l2_loss: 0.0440 - round_loss\u001b[A\n",
      "Training:   5%| | 2187/40960 [00:06<01:44, 371.39batches/s, l2_loss: 0.0440 - round_loss\u001b[A\n",
      "Training:   5%| | 2187/40960 [00:06<01:44, 371.39batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   6%| | 2272/40960 [00:06<01:39, 386.91batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   6%| | 2272/40960 [00:06<01:39, 386.91batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   6%| | 2357/40960 [00:06<01:36, 398.00batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   6%| | 2357/40960 [00:06<01:36, 398.00batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   6%| | 2438/40960 [00:06<01:36, 399.27batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   6%| | 2438/40960 [00:06<01:36, 399.27batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   6%| | 2529/40960 [00:07<01:32, 414.90batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   6%| | 2529/40960 [00:07<01:32, 414.90batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   6%| | 2607/40960 [00:07<01:34, 406.58batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   6%| | 2607/40960 [00:07<01:34, 406.58batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   7%| | 2695/40960 [00:07<01:32, 414.86batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   7%| | 2695/40960 [00:07<01:32, 414.86batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   7%| | 2779/40960 [00:07<01:31, 415.27batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   7%| | 2779/40960 [00:07<01:31, 415.27batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   7%| | 2859/40960 [00:07<01:32, 410.49batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   7%| | 2859/40960 [00:07<01:32, 410.49batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   7%| | 2944/40960 [00:08<01:31, 413.64batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   7%| | 2944/40960 [00:08<01:31, 413.64batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   7%| | 3028/40960 [00:08<01:31, 415.13batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   7%| | 3028/40960 [00:08<01:31, 415.13batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   8%| | 3119/40960 [00:08<01:28, 426.49batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   8%| | 3119/40960 [00:08<01:28, 426.49batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   8%| | 3210/40960 [00:08<01:26, 434.34batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   8%| | 3210/40960 [00:08<01:26, 434.34batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   8%| | 3300/40960 [00:08<01:25, 439.01batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   8%| | 3300/40960 [00:08<01:25, 439.01batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   8%| | 3395/40960 [00:09<01:23, 449.06batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   8%| | 3395/40960 [00:09<01:23, 449.06batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   9%| | 3488/40960 [00:09<01:22, 453.72batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   9%| | 3488/40960 [00:09<01:22, 453.72batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3551/40960 [00:09<01:30, 411.59batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%| | 3551/40960 [00:09<01:30, 411.59batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   9%| | 3634/40960 [00:09<01:30, 411.86batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:   9%| | 3634/40960 [00:09<01:30, 411.86batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   9%| | 3722/40960 [00:09<01:28, 419.42batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   9%| | 3722/40960 [00:09<01:28, 419.42batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3811/40960 [00:10<01:27, 426.33batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3811/40960 [00:10<01:27, 426.33batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  10%| | 3902/40960 [00:10<01:25, 433.94batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:  10%| | 3902/40960 [00:10<01:25, 433.94batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 3988/40960 [00:10<01:25, 432.71batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 3988/40960 [00:10<01:25, 432.71batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4059/40960 [00:10<01:30, 408.44batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4059/40960 [00:10<01:30, 408.44batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4130/40960 [00:10<01:33, 392.00batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 4130/40960 [00:10<01:33, 392.00batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 4222/40960 [00:11<01:29, 411.85batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 4222/40960 [00:11<01:29, 411.85batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4303/40960 [00:11<01:29, 408.68batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4303/40960 [00:11<01:29, 408.68batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:  11%| | 4391/40960 [00:11<01:27, 417.52batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:  11%| | 4391/40960 [00:11<01:27, 417.52batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4478/40960 [00:11<01:26, 422.42batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4478/40960 [00:11<01:26, 422.42batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4570/40960 [00:11<01:23, 433.37batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  11%| | 4570/40960 [00:11<01:23, 433.37batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  11%| | 4657/40960 [00:12<01:23, 432.53batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  11%| | 4657/40960 [00:12<01:23, 432.53batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4745/40960 [00:12<01:23, 433.74batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4745/40960 [00:12<01:23, 433.74batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4830/40960 [00:12<01:24, 429.78batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4830/40960 [00:12<01:24, 429.78batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4922/40960 [00:12<01:22, 438.48batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 4922/40960 [00:12<01:22, 438.48batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 5015/40960 [00:12<01:20, 446.02batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  12%| | 5015/40960 [00:12<01:20, 446.02batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  12%| | 5109/40960 [00:13<01:19, 453.14batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  12%| | 5109/40960 [00:13<01:19, 453.14batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5203/40960 [00:13<01:18, 457.88batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5203/40960 [00:13<01:18, 457.88batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5296/40960 [00:13<01:17, 459.86batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5296/40960 [00:13<01:17, 459.86batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5389/40960 [00:13<01:17, 460.20batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5389/40960 [00:13<01:17, 460.20batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5479/40960 [00:13<01:17, 456.23batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5479/40960 [00:13<01:17, 456.23batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5571/40960 [00:14<01:17, 456.45batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5571/40960 [00:14<01:17, 456.45batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5662/40960 [00:14<01:17, 455.77batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5662/40960 [00:14<01:17, 455.77batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5755/40960 [00:14<01:16, 457.59batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5755/40960 [00:14<01:16, 457.59batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5850/40960 [00:14<01:16, 461.81batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5850/40960 [00:14<01:16, 461.81batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5943/40960 [00:14<01:15, 462.60batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5943/40960 [00:14<01:15, 462.60batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6034/40960 [00:15<01:16, 459.31batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6034/40960 [00:15<01:16, 459.31batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6124/40960 [00:15<01:16, 456.46batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6124/40960 [00:15<01:16, 456.46batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6203/40960 [00:15<01:19, 437.25batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6203/40960 [00:15<01:19, 437.25batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6291/40960 [00:15<01:19, 436.89batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6291/40960 [00:15<01:19, 436.89batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6374/40960 [00:15<01:20, 430.07batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6374/40960 [00:15<01:20, 430.07batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6460/40960 [00:16<01:20, 429.24batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6460/40960 [00:16<01:20, 429.24batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6546/40960 [00:16<01:20, 428.90batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6546/40960 [00:16<01:20, 428.90batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6633/40960 [00:16<01:19, 429.70batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6633/40960 [00:16<01:19, 429.70batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6725/40960 [00:16<01:18, 438.21batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6725/40960 [00:16<01:18, 438.21batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6816/40960 [00:16<01:17, 442.67batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6816/40960 [00:16<01:17, 442.67batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6908/40960 [00:17<01:16, 446.63batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6908/40960 [00:17<01:16, 446.63batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7000/40960 [00:17<01:15, 449.28batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7000/40960 [00:17<01:15, 449.28batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7089/40960 [00:17<01:15, 447.02batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7089/40960 [00:17<01:15, 447.02batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7176/40960 [00:17<01:16, 442.68batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7176/40960 [00:17<01:16, 442.68batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7268/40960 [00:17<01:15, 447.46batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7268/40960 [00:17<01:15, 447.46batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7360/40960 [00:18<01:14, 451.08batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7360/40960 [00:18<01:14, 451.08batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7445/40960 [00:18<01:15, 442.80batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7445/40960 [00:18<01:15, 442.80batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|▏| 7514/40960 [00:18<01:20, 413.09batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7514/40960 [00:18<01:20, 413.09batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7603/40960 [00:18<01:19, 421.80batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7603/40960 [00:18<01:19, 421.80batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7686/40960 [00:18<01:19, 417.57batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7686/40960 [00:18<01:19, 417.57batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7772/40960 [00:19<01:18, 420.79batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7772/40960 [00:19<01:18, 420.79batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7860/40960 [00:19<01:17, 426.20batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7860/40960 [00:19<01:17, 426.20batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7947/40960 [00:19<01:17, 427.34batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7947/40960 [00:19<01:17, 427.34batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8033/40960 [00:19<01:16, 427.78batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8033/40960 [00:19<01:16, 427.78batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8123/40960 [00:19<01:15, 433.52batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8123/40960 [00:19<01:15, 433.52batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8211/40960 [00:20<01:15, 434.96batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8211/40960 [00:20<01:15, 434.96batches/s, l2_loss: 0.0256 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8294/40960 [00:20<01:16, 428.17batches/s, l2_loss: 0.0256 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8294/40960 [00:20<01:16, 428.17batches/s, l2_loss: 0.0400 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8375/40960 [00:20<01:17, 419.93batches/s, l2_loss: 0.0400 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8375/40960 [00:20<01:17, 419.93batches/s, l2_loss: 0.0466 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8459/40960 [00:20<01:17, 419.23batches/s, l2_loss: 0.0466 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8459/40960 [00:20<01:17, 419.23batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8544/40960 [00:20<01:17, 420.53batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8544/40960 [00:20<01:17, 420.53batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8628/40960 [00:21<01:17, 419.75batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8628/40960 [00:21<01:17, 419.75batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8711/40960 [00:21<01:17, 417.70batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8711/40960 [00:21<01:17, 417.70batches/s, l2_loss: 0.0408 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8794/40960 [00:21<01:17, 415.47batches/s, l2_loss: 0.0408 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8794/40960 [00:21<01:17, 415.47batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8877/40960 [00:21<01:17, 415.31batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8877/40960 [00:21<01:17, 415.31batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8960/40960 [00:21<01:17, 414.57batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8960/40960 [00:21<01:17, 414.57batches/s, l2_loss: 0.0410 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9042/40960 [00:22<01:17, 411.91batches/s, l2_loss: 0.0410 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9042/40960 [00:22<01:17, 411.91batches/s, l2_loss: 0.0406 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9128/40960 [00:22<01:16, 415.98batches/s, l2_loss: 0.0406 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9128/40960 [00:22<01:16, 415.98batches/s, l2_loss: 0.0416 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9210/40960 [00:22<01:16, 412.75batches/s, l2_loss: 0.0416 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9210/40960 [00:22<01:16, 412.75batches/s, l2_loss: 0.0410 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9295/40960 [00:22<01:16, 415.57batches/s, l2_loss: 0.0410 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9295/40960 [00:22<01:16, 415.57batches/s, l2_loss: 0.0416 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9380/40960 [00:22<01:15, 417.97batches/s, l2_loss: 0.0416 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9380/40960 [00:22<01:15, 417.97batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9463/40960 [00:23<01:15, 416.26batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9463/40960 [00:23<01:15, 416.26batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9545/40960 [00:23<01:15, 413.71batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9545/40960 [00:23<01:15, 413.71batches/s, l2_loss: 0.0415 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9626/40960 [00:23<01:16, 410.77batches/s, l2_loss: 0.0415 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9626/40960 [00:23<01:16, 410.77batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9708/40960 [00:23<01:16, 409.15batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9708/40960 [00:23<01:16, 409.15batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9791/40960 [00:23<01:16, 409.58batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9791/40960 [00:23<01:16, 409.58batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9873/40960 [00:24<01:16, 408.14batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9873/40960 [00:24<01:16, 408.14batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9955/40960 [00:24<01:15, 408.45batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9955/40960 [00:24<01:15, 408.45batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10038/40960 [00:24<01:15, 409.09batches/s, l2_loss: 0.0411 - round_los\u001b[A\n",
      "Training:  25%|▏| 10038/40960 [00:24<01:15, 409.09batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  25%|▏| 10121/40960 [00:24<01:15, 410.62batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  25%|▏| 10121/40960 [00:24<01:15, 410.62batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  25%|▏| 10201/40960 [00:24<01:15, 406.23batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  25%|▏| 10201/40960 [00:24<01:15, 406.23batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  25%|▎| 10283/40960 [00:25<01:15, 407.30batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  25%|▎| 10283/40960 [00:25<01:15, 407.30batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  25%|▎| 10365/40960 [00:25<01:15, 407.30batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  25%|▎| 10365/40960 [00:25<01:15, 407.30batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  25%|▎| 10438/40960 [00:25<01:17, 394.51batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  25%|▎| 10438/40960 [00:25<01:17, 394.51batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  26%|▎| 10513/40960 [00:25<01:18, 387.33batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  26%|▎| 10513/40960 [00:25<01:18, 387.33batches/s, l2_loss: 0.0410 - round_los\u001b[A\n",
      "Training:  26%|▎| 10582/40960 [00:25<01:21, 373.82batches/s, l2_loss: 0.0410 - round_los\u001b[A\n",
      "Training:  26%|▎| 10582/40960 [00:25<01:21, 373.82batches/s, l2_loss: 0.0410 - round_los\u001b[A\n",
      "Training:  26%|▎| 10652/40960 [00:26<01:22, 366.09batches/s, l2_loss: 0.0410 - round_los\u001b[A\n",
      "Training:  26%|▎| 10652/40960 [00:26<01:22, 366.09batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  26%|▎| 10727/40960 [00:26<01:22, 368.14batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  26%|▎| 10727/40960 [00:26<01:22, 368.14batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  26%|▎| 10806/40960 [00:26<01:20, 375.20batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  26%|▎| 10806/40960 [00:26<01:20, 375.20batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  27%|▎| 10890/40960 [00:26<01:17, 387.92batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  27%|▎| 10890/40960 [00:26<01:17, 387.92batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  27%|▎| 10973/40960 [00:26<01:15, 395.00batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  27%|▎| 10973/40960 [00:27<01:15, 395.00batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  27%|▎| 11056/40960 [00:27<01:14, 400.08batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  27%|▎| 11056/40960 [00:27<01:14, 400.08batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  27%|▎| 11134/40960 [00:27<01:15, 396.77batches/s, l2_loss: 0.0405 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|▎| 11134/40960 [00:27<01:15, 396.77batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  27%|▎| 11216/40960 [00:27<01:14, 400.07batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  27%|▎| 11216/40960 [00:27<01:14, 400.07batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  28%|▎| 11291/40960 [00:27<01:15, 392.44batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  28%|▎| 11291/40960 [00:27<01:15, 392.44batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  28%|▎| 11367/40960 [00:28<01:16, 387.29batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  28%|▎| 11367/40960 [00:28<01:16, 387.29batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  28%|▎| 11443/40960 [00:28<01:16, 385.10batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  28%|▎| 11443/40960 [00:28<01:16, 385.10batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  28%|▎| 11519/40960 [00:28<01:16, 382.69batches/s, l2_loss: 0.0409 - round_los\u001b[A\n",
      "Training:  28%|▎| 11519/40960 [00:28<01:16, 382.69batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  28%|▎| 11594/40960 [00:28<01:17, 380.38batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  28%|▎| 11594/40960 [00:28<01:17, 380.38batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  28%|▎| 11666/40960 [00:28<01:18, 373.12batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  28%|▎| 11666/40960 [00:28<01:18, 373.12batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  29%|▎| 11741/40960 [00:29<01:18, 373.57batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  29%|▎| 11741/40960 [00:29<01:18, 373.57batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  29%|▎| 11815/40960 [00:29<01:18, 371.71batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  29%|▎| 11815/40960 [00:29<01:18, 371.71batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  29%|▎| 11891/40960 [00:29<01:17, 373.12batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  29%|▎| 11891/40960 [00:29<01:17, 373.12batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  29%|▎| 11974/40960 [00:29<01:15, 384.57batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  29%|▎| 11974/40960 [00:29<01:15, 384.57batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  29%|▎| 12050/40960 [00:29<01:15, 382.02batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  29%|▎| 12050/40960 [00:29<01:15, 382.02batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  30%|▎| 12122/40960 [00:30<01:17, 374.21batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  30%|▎| 12122/40960 [00:30<01:17, 374.21batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  30%|▎| 12196/40960 [00:30<01:17, 371.98batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  30%|▎| 12196/40960 [00:30<01:17, 371.98batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  30%|▎| 12274/40960 [00:30<01:16, 377.00batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  30%|▎| 12274/40960 [00:30<01:16, 377.00batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  30%|▎| 12355/40960 [00:30<01:14, 385.18batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  30%|▎| 12355/40960 [00:30<01:14, 385.18batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  30%|▎| 12437/40960 [00:30<01:12, 391.39batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  30%|▎| 12437/40960 [00:30<01:12, 391.39batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  31%|▎| 12520/40960 [00:31<01:11, 397.35batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  31%|▎| 12520/40960 [00:31<01:11, 397.35batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  31%|▎| 12602/40960 [00:31<01:10, 399.75batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  31%|▎| 12602/40960 [00:31<01:10, 399.75batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  31%|▎| 12684/40960 [00:31<01:10, 402.47batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  31%|▎| 12684/40960 [00:31<01:10, 402.47batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  31%|▎| 12763/40960 [00:31<01:10, 398.90batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  31%|▎| 12763/40960 [00:31<01:10, 398.90batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  31%|▎| 12841/40960 [00:31<01:11, 394.80batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  31%|▎| 12841/40960 [00:31<01:11, 394.80batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  32%|▎| 12917/40960 [00:32<01:11, 390.00batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  32%|▎| 12917/40960 [00:32<01:11, 390.00batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  32%|▎| 12993/40960 [00:32<01:12, 385.79batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  32%|▎| 12993/40960 [00:32<01:12, 385.79batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  32%|▎| 13070/40960 [00:32<01:12, 384.80batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  32%|▎| 13070/40960 [00:32<01:12, 384.80batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  32%|▎| 13144/40960 [00:32<01:13, 379.30batches/s, l2_loss: 0.0408 - round_los\u001b[A\n",
      "Training:  32%|▎| 13144/40960 [00:32<01:13, 379.30batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  32%|▎| 13221/40960 [00:32<01:12, 380.63batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  32%|▎| 13221/40960 [00:32<01:12, 380.63batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  32%|▎| 13299/40960 [00:33<01:12, 382.84batches/s, l2_loss: 0.0407 - round_los\u001b[A\n",
      "Training:  32%|▎| 13299/40960 [00:33<01:12, 382.84batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  33%|▎| 13375/40960 [00:33<01:12, 381.63batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  33%|▎| 13375/40960 [00:33<01:12, 381.63batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  33%|▎| 13455/40960 [00:33<01:11, 386.81batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  33%|▎| 13455/40960 [00:33<01:11, 386.81batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  33%|▎| 13539/40960 [00:33<01:09, 395.48batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  33%|▎| 13539/40960 [00:33<01:09, 395.48batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  33%|▎| 13620/40960 [00:33<01:08, 398.11batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  33%|▎| 13620/40960 [00:33<01:08, 398.11batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  33%|▎| 13700/40960 [00:34<01:08, 397.39batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  33%|▎| 13700/40960 [00:34<01:08, 397.39batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  34%|▎| 13779/40960 [00:34<01:08, 395.48batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  34%|▎| 13779/40960 [00:34<01:08, 395.48batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  34%|▎| 13859/40960 [00:34<01:08, 396.74batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  34%|▎| 13859/40960 [00:34<01:08, 396.74batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  34%|▎| 13940/40960 [00:34<01:07, 398.38batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  34%|▎| 13940/40960 [00:34<01:07, 398.38batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  34%|▎| 14023/40960 [00:34<01:06, 402.85batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  34%|▎| 14023/40960 [00:34<01:06, 402.85batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  34%|▎| 14106/40960 [00:35<01:06, 404.88batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  34%|▎| 14106/40960 [00:35<01:06, 404.88batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  35%|▎| 14186/40960 [00:35<01:06, 402.30batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  35%|▎| 14186/40960 [00:35<01:06, 402.30batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  35%|▎| 14271/40960 [00:35<01:05, 407.72batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  35%|▎| 14271/40960 [00:35<01:05, 407.72batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  35%|▎| 14350/40960 [00:35<01:05, 403.39batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  35%|▎| 14350/40960 [00:35<01:05, 403.39batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  35%|▎| 14426/40960 [00:35<01:07, 395.14batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  35%|▎| 14426/40960 [00:35<01:07, 395.14batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  35%|▎| 14504/40960 [00:36<01:07, 392.54batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  35%|▎| 14504/40960 [00:36<01:07, 392.54batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  36%|▎| 14583/40960 [00:36<01:07, 392.00batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  36%|▎| 14583/40960 [00:36<01:07, 392.00batches/s, l2_loss: 0.0404 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|▎| 14657/40960 [00:36<01:08, 385.01batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  36%|▎| 14657/40960 [00:36<01:08, 385.01batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  36%|▎| 14733/40960 [00:36<01:08, 382.02batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  36%|▎| 14733/40960 [00:36<01:08, 382.02batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  36%|▎| 14814/40960 [00:36<01:07, 388.29batches/s, l2_loss: 0.0406 - round_los\u001b[A\n",
      "Training:  36%|▎| 14814/40960 [00:36<01:07, 388.29batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  36%|▎| 14896/40960 [00:37<01:06, 393.67batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  36%|▎| 14896/40960 [00:37<01:06, 393.67batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 14977/40960 [00:37<01:05, 396.90batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 14977/40960 [00:37<01:05, 396.90batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 15059/40960 [00:37<01:04, 399.58batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 15059/40960 [00:37<01:04, 399.58batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 15141/40960 [00:37<01:04, 401.40batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 15141/40960 [00:37<01:04, 401.40batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 15223/40960 [00:37<01:03, 403.06batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 15223/40960 [00:37<01:03, 403.06batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 15308/40960 [00:38<01:02, 408.59batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  37%|▎| 15308/40960 [00:38<01:02, 408.59batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  38%|▍| 15390/40960 [00:38<01:02, 408.31batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  38%|▍| 15390/40960 [00:38<01:02, 408.31batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  38%|▍| 15471/40960 [00:38<01:02, 406.37batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  38%|▍| 15471/40960 [00:38<01:02, 406.37batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  38%|▍| 15553/40960 [00:38<01:02, 405.77batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  38%|▍| 15553/40960 [00:38<01:02, 405.77batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  38%|▍| 15624/40960 [00:38<01:05, 389.43batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  38%|▍| 15624/40960 [00:38<01:05, 389.43batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  38%|▍| 15697/40960 [00:39<01:06, 381.04batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  38%|▍| 15697/40960 [00:39<01:06, 381.04batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  39%|▍| 15779/40960 [00:39<01:04, 388.90batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  39%|▍| 15779/40960 [00:39<01:04, 388.90batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 15863/40960 [00:39<01:03, 397.55batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 15863/40960 [00:39<01:03, 397.55batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 15943/40960 [00:39<01:02, 397.94batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 15943/40960 [00:39<01:02, 397.94batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 16017/40960 [00:39<01:04, 388.33batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 16017/40960 [00:39<01:04, 388.33batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 16091/40960 [00:40<01:05, 381.60batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 16091/40960 [00:40<01:05, 381.60batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 16162/40960 [00:40<01:06, 372.50batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  39%|▍| 16162/40960 [00:40<01:06, 372.50batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  40%|▍| 16243/40960 [00:40<01:04, 381.09batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  40%|▍| 16243/40960 [00:40<01:04, 381.09batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  40%|▍| 16327/40960 [00:40<01:02, 391.56batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  40%|▍| 16327/40960 [00:40<01:02, 391.56batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  40%|▍| 16410/40960 [00:40<01:01, 397.92batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  40%|▍| 16410/40960 [00:40<01:01, 397.92batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  40%|▍| 16493/40960 [00:41<01:00, 402.68batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  40%|▍| 16493/40960 [00:41<01:00, 402.68batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  40%|▍| 16572/40960 [00:41<01:01, 399.78batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  40%|▍| 16572/40960 [00:41<01:01, 399.78batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  41%|▍| 16654/40960 [00:41<01:00, 402.22batches/s, l2_loss: 0.0405 - round_los\u001b[A\n",
      "Training:  41%|▍| 16654/40960 [00:41<01:00, 402.22batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  41%|▍| 16736/40960 [00:41<00:59, 403.82batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  41%|▍| 16736/40960 [00:41<00:59, 403.82batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  41%|▍| 16809/40960 [00:41<01:01, 391.30batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  41%|▍| 16809/40960 [00:41<01:01, 391.30batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  41%|▍| 16890/40960 [00:42<01:00, 394.64batches/s, l2_loss: 0.0404 - round_los\u001b[A\n",
      "Training:  41%|▍| 16890/40960 [00:42<01:00, 394.64batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  41%|▍| 16973/40960 [00:42<00:59, 400.48batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  41%|▍| 16973/40960 [00:42<00:59, 400.48batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17054/40960 [00:42<00:59, 401.22batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17054/40960 [00:42<00:59, 401.22batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17135/40960 [00:42<00:59, 402.12batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17135/40960 [00:42<00:59, 402.12batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17219/40960 [00:42<00:58, 407.21batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17219/40960 [00:42<00:58, 407.21batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17303/40960 [00:43<00:57, 410.55batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17303/40960 [00:43<00:57, 410.55batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17386/40960 [00:43<00:57, 411.11batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  42%|▍| 17386/40960 [00:43<00:57, 411.11batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  43%|▍| 17461/40960 [00:43<00:58, 400.31batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  43%|▍| 17461/40960 [00:43<00:58, 400.31batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  43%|▍| 17537/40960 [00:43<00:59, 394.03batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  43%|▍| 17537/40960 [00:43<00:59, 394.03batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  43%|▍| 17618/40960 [00:43<00:58, 395.83batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  43%|▍| 17618/40960 [00:43<00:58, 395.83batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  43%|▍| 17699/40960 [00:44<00:58, 398.11batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  43%|▍| 17699/40960 [00:44<00:58, 398.11batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  43%|▍| 17783/40960 [00:44<00:57, 404.22batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  43%|▍| 17783/40960 [00:44<00:57, 404.22batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  44%|▍| 17866/40960 [00:44<00:56, 406.56batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  44%|▍| 17866/40960 [00:44<00:56, 406.56batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  44%|▍| 17950/40960 [00:44<00:56, 409.62batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  44%|▍| 17950/40960 [00:44<00:56, 409.62batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  44%|▍| 18033/40960 [00:44<00:55, 410.47batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  44%|▍| 18033/40960 [00:44<00:55, 410.47batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  44%|▍| 18112/40960 [00:45<00:56, 404.92batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  44%|▍| 18112/40960 [00:45<00:56, 404.92batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  44%|▍| 18187/40960 [00:45<00:57, 395.07batches/s, l2_loss: 0.0403 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 18187/40960 [00:45<00:57, 395.07batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  45%|▍| 18269/40960 [00:45<00:56, 399.31batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  45%|▍| 18269/40960 [00:45<00:56, 399.31batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  45%|▍| 18337/40960 [00:45<00:59, 380.84batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  45%|▍| 18337/40960 [00:45<00:59, 380.84batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  45%|▍| 18409/40960 [00:45<01:00, 373.83batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  45%|▍| 18409/40960 [00:45<01:00, 373.83batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  45%|▍| 18491/40960 [00:46<00:58, 383.52batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  45%|▍| 18491/40960 [00:46<00:58, 383.52batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  45%|▍| 18575/40960 [00:46<00:56, 394.09batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  45%|▍| 18575/40960 [00:46<00:56, 394.09batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 18660/40960 [00:46<00:55, 402.45batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 18660/40960 [00:46<00:55, 402.45batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 18741/40960 [00:46<00:55, 403.06batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 18741/40960 [00:46<00:55, 403.06batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  46%|▍| 18821/40960 [00:46<00:55, 401.27batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  46%|▍| 18821/40960 [00:46<00:55, 401.27batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 18895/40960 [00:47<00:56, 390.78batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 18895/40960 [00:47<00:56, 390.78batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 18951/40960 [00:47<01:01, 357.11batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 18951/40960 [00:47<01:01, 357.11batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 19019/40960 [00:47<01:02, 351.70batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  46%|▍| 19019/40960 [00:47<01:02, 351.70batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  47%|▍| 19099/40960 [00:47<00:59, 366.07batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  47%|▍| 19099/40960 [00:47<00:59, 366.07batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  47%|▍| 19182/40960 [00:47<00:57, 379.55batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  47%|▍| 19182/40960 [00:47<00:57, 379.55batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  47%|▍| 19268/40960 [00:48<00:55, 393.72batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  47%|▍| 19268/40960 [00:48<00:55, 393.72batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  47%|▍| 19350/40960 [00:48<00:54, 398.15batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  47%|▍| 19350/40960 [00:48<00:54, 398.15batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  47%|▍| 19435/40960 [00:48<00:53, 404.92batches/s, l2_loss: 0.0403 - round_los\u001b[A\n",
      "Training:  47%|▍| 19435/40960 [00:48<00:53, 404.92batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  48%|▍| 19519/40960 [00:48<00:52, 408.87batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  48%|▍| 19519/40960 [00:48<00:52, 408.87batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  48%|▍| 19593/40960 [00:48<00:53, 396.11batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  48%|▍| 19593/40960 [00:48<00:53, 396.11batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  48%|▍| 19673/40960 [00:49<00:53, 396.63batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  48%|▍| 19673/40960 [00:49<00:53, 396.63batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  48%|▍| 19757/40960 [00:49<00:52, 402.46batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  48%|▍| 19757/40960 [00:49<00:52, 402.46batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  48%|▍| 19825/40960 [00:49<00:55, 383.77batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  48%|▍| 19825/40960 [00:49<00:55, 383.77batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  49%|▍| 19895/40960 [00:49<00:56, 372.77batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  49%|▍| 19895/40960 [00:49<00:56, 372.77batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  49%|▍| 19973/40960 [00:49<00:55, 376.82batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  49%|▍| 19973/40960 [00:49<00:55, 376.82batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  49%|▍| 20054/40960 [00:50<00:54, 384.76batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  49%|▍| 20054/40960 [00:50<00:54, 384.76batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  49%|▍| 20121/40960 [00:50<00:56, 369.26batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  49%|▍| 20121/40960 [00:50<00:56, 369.26batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  49%|▍| 20187/40960 [00:50<00:58, 356.16batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  49%|▍| 20187/40960 [00:50<00:58, 356.16batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  49%|▍| 20264/40960 [00:50<00:56, 363.63batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  49%|▍| 20264/40960 [00:50<00:56, 363.63batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  50%|▍| 20349/40960 [00:50<00:53, 381.92batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  50%|▍| 20349/40960 [00:50<00:53, 381.92batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  50%|▍| 20421/40960 [00:51<00:54, 375.35batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  50%|▍| 20421/40960 [00:51<00:54, 375.35batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  50%|▌| 20495/40960 [00:51<00:54, 372.22batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  50%|▌| 20495/40960 [00:51<00:54, 372.22batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  50%|▌| 20581/40960 [00:51<00:52, 388.95batches/s, l2_loss: 0.0402 - round_los\u001b[A\n",
      "Training:  50%|▌| 20581/40960 [00:51<00:52, 388.95batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  50%|▌| 20656/40960 [00:51<00:52, 383.15batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  50%|▌| 20656/40960 [00:51<00:52, 383.15batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 20732/40960 [00:51<00:53, 380.70batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 20732/40960 [00:51<00:53, 380.70batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 20793/40960 [00:52<00:56, 358.03batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 20793/40960 [00:52<00:56, 358.03batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  51%|▌| 20854/40960 [00:52<00:58, 342.19batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  51%|▌| 20854/40960 [00:52<00:58, 342.19batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 20912/40960 [00:52<01:01, 325.99batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 20912/40960 [00:52<01:01, 325.99batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 20994/40960 [00:52<00:56, 350.66batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 20994/40960 [00:52<00:56, 350.66batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 21074/40960 [00:52<00:54, 364.11batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  51%|▌| 21074/40960 [00:52<00:54, 364.11batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21147/40960 [00:53<00:54, 362.82batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21147/40960 [00:53<00:54, 362.82batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21216/40960 [00:53<00:55, 357.26batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21216/40960 [00:53<00:55, 357.26batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21292/40960 [00:53<00:54, 363.22batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21292/40960 [00:53<00:54, 363.22batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21368/40960 [00:53<00:53, 367.33batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21368/40960 [00:53<00:53, 367.33batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21445/40960 [00:53<00:52, 372.52batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  52%|▌| 21445/40960 [00:53<00:52, 372.52batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  53%|▌| 21527/40960 [00:54<00:50, 382.90batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  53%|▌| 21527/40960 [00:54<00:50, 382.90batches/s, l2_loss: 0.0401 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|▌| 21611/40960 [00:54<00:49, 393.05batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  53%|▌| 21611/40960 [00:54<00:49, 393.05batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  53%|▌| 21694/40960 [00:54<00:48, 398.60batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  53%|▌| 21694/40960 [00:54<00:48, 398.60batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  53%|▌| 21771/40960 [00:54<00:48, 393.09batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  53%|▌| 21771/40960 [00:54<00:48, 393.09batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  53%|▌| 21847/40960 [00:54<00:49, 388.24batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  53%|▌| 21847/40960 [00:54<00:49, 388.24batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  54%|▌| 21925/40960 [00:55<00:48, 388.48batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  54%|▌| 21925/40960 [00:55<00:48, 388.48batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  54%|▌| 22006/40960 [00:55<00:48, 392.60batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  54%|▌| 22006/40960 [00:55<00:48, 392.60batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  54%|▌| 22088/40960 [00:55<00:47, 397.49batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  54%|▌| 22088/40960 [00:55<00:47, 397.49batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  54%|▌| 22170/40960 [00:55<00:46, 400.76batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  54%|▌| 22170/40960 [00:55<00:46, 400.76batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  54%|▌| 22245/40960 [00:55<00:47, 392.01batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  54%|▌| 22245/40960 [00:55<00:47, 392.01batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22327/40960 [00:56<00:46, 396.96batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22327/40960 [00:56<00:46, 396.96batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22407/40960 [00:56<00:46, 396.56batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22407/40960 [00:56<00:46, 396.56batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22486/40960 [00:56<00:46, 395.16batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22486/40960 [00:56<00:46, 395.16batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22568/40960 [00:56<00:46, 399.21batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22568/40960 [00:56<00:46, 399.21batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22651/40960 [00:56<00:45, 402.59batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22651/40960 [00:57<00:45, 402.59batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22729/40960 [00:57<00:45, 397.68batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  55%|▌| 22729/40960 [00:57<00:45, 397.68batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  56%|▌| 22812/40960 [00:57<00:45, 402.73batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  56%|▌| 22812/40960 [00:57<00:45, 402.73batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  56%|▌| 22890/40960 [00:57<00:45, 398.90batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  56%|▌| 22890/40960 [00:57<00:45, 398.90batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  56%|▌| 22972/40960 [00:57<00:44, 401.00batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  56%|▌| 22972/40960 [00:57<00:44, 401.00batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  56%|▌| 23048/40960 [00:58<00:45, 393.97batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  56%|▌| 23048/40960 [00:58<00:45, 393.97batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  56%|▌| 23128/40960 [00:58<00:45, 394.88batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  56%|▌| 23128/40960 [00:58<00:45, 394.88batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  57%|▌| 23206/40960 [00:58<00:45, 392.51batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  57%|▌| 23206/40960 [00:58<00:45, 392.51batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  57%|▌| 23286/40960 [00:58<00:44, 393.69batches/s, l2_loss: 0.0401 - round_los\u001b[A\n",
      "Training:  57%|▌| 23286/40960 [00:58<00:44, 393.69batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  57%|▌| 23366/40960 [00:58<00:44, 394.18batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  57%|▌| 23366/40960 [00:58<00:44, 394.18batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  57%|▌| 23448/40960 [00:59<00:43, 398.74batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  57%|▌| 23448/40960 [00:59<00:43, 398.74batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  57%|▌| 23528/40960 [00:59<00:43, 398.21batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  57%|▌| 23528/40960 [00:59<00:43, 398.21batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23610/40960 [00:59<00:43, 400.43batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23610/40960 [00:59<00:43, 400.43batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23691/40960 [00:59<00:43, 400.58batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23691/40960 [00:59<00:43, 400.58batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23771/40960 [00:59<00:42, 400.35batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23771/40960 [00:59<00:42, 400.35batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23851/40960 [01:00<00:42, 399.32batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23851/40960 [01:00<00:42, 399.32batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23935/40960 [01:00<00:42, 405.09batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  58%|▌| 23935/40960 [01:00<00:42, 405.09batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  59%|▌| 24017/40960 [01:00<00:41, 406.02batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  59%|▌| 24017/40960 [01:00<00:41, 406.02batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "Training:  59%|▌| 24100/40960 [01:00<00:41, 407.58batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "Training:  59%|▌| 24100/40960 [01:00<00:41, 407.58batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "Training:  59%|▌| 24184/40960 [01:00<00:40, 410.80batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "Training:  59%|▌| 24184/40960 [01:00<00:40, 410.80batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "Training:  59%|▌| 24267/40960 [01:01<00:40, 411.69batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "Training:  59%|▌| 24267/40960 [01:01<00:40, 411.69batches/s, l2_loss: 0.0400 - round_los\u001b[A\n",
      "Training:  59%|▌| 24350/40960 [01:01<00:40, 411.68batches/s, l2_loss: 0.0400 - round_los\u001b[A"
     ]
    }
   ],
   "source": [
    "# Cuantizar el modelo con el dataset de calibración\n",
    "\n",
    "# For calling Optimize, use the short version: runner.optimize(calib_dataset)\n",
    "# A more general approach is being used here that works also with multiple input nodes.\n",
    "# The calibration dataset could also be a dictionary with the format:\n",
    "# {input_layer_name_1_from_hn: layer_1_calib_dataset, input_layer_name_2_from_hn: layer_2_calib_dataset}\n",
    "hn_layers = runner.get_hn_dict()[\"layers\"]\n",
    "print(\"Input layers are: \")\n",
    "print([layer for layer in hn_layers if hn_layers[layer][\"type\"] == \"input_layer\"])  # See available input layer names\n",
    "calib_dataset_dict = {\"model_ResBaGAN_discriminator/input_layer1\": calib_dataset}  # In our case there is only one input layer\n",
    "\n",
    "optimization_level = 4\n",
    "compression_level = 0\n",
    "# Mapeamos las proporciones de pesos de 4 bits según el nivel de compresión\n",
    "compression_ratios = {\n",
    "    0: 0.0,\n",
    "    1: 0.2,\n",
    "    2: 0.4,\n",
    "    3: 0.6,\n",
    "    4: 0.8,\n",
    "    5: 1.0\n",
    "}\n",
    "auto_4bit_ratio = compression_ratios.get(compression_level, 0.0)\n",
    "\n",
    "alls_lines = [\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # Batch size is 8 by default; 2 was used for stability on PCs with low amount of RAM / VRAM\n",
    "    f\"model_optimization_flavor(optimization_level={optimization_level}, compression_level={compression_level}, batch_size=8)\\n\",\n",
    "    # The following line is needed because this is a really small model, and the compression_level is always reverted back to 0.'\n",
    "    # To force using compression_level with small models, the following line should be used (compression level=4 equals to 80% 4-bit):\n",
    "    f\"model_optimization_config(compression_params, auto_4bit_weights_ratio={auto_4bit_ratio})\\n\",\n",
    "    # The application of the compression could be seen by the [info] messages: \"Assigning 4bit weight to layer ..\"\n",
    "]\n",
    "\n",
    "runner.load_model_script(\"\".join(alls_lines))\n",
    "\n",
    "runner.optimize(calib_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb54f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:36:57.287589: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:36:58.477768: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:12,  8.33entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.2700 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:11.067731: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:11.190760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 430.80entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.3000 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:11.567841: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:11.692391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 451.37entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.4500 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:12.062407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:12.188070: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 513.97entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.4300 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:12.522297: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:12.647244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 468.27entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.5900 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:13.005980: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:13.137327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 556.02entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.2600 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:13.454331: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:13.580769: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 545.04entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.4300 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:13.915756: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:14.046041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 568.86entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.4300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:14.353656: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:14.478927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 605.57entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.3100 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:14.782774: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:14.910727: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 601.30entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.2700 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:15.224154: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:15.348399: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 564.35entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.4400 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:15.686066: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:15.813175: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 482.26entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.4500 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:16.168148: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:16.294465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 524.63entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.3500 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:16.626252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:16.749685: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 583.00entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.2900 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:17.090792: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:17.213773: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 521.61entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.4800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:17.555508: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:17.683589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 563.43entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.4900 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:18.011088: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:18.134358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 595.18entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.3000 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:18.451115: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:18.576270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 519.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.5800 ; Coincidencias: 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:18.901160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:19.030555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 542.26entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:19.368802: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:19.497396: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 560.52entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.2400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:19.820173: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:19.945084: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 582.67entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.3500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:20.260004: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:20.383000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 509.57entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.3200 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:20.733091: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:20.857684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 447.78entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.3700 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:21.231186: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:21.358766: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 497.69entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.3100 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:21.698321: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:21.820842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 560.94entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.4400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:22.139682: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:22.265781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 583.41entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.2200 ; Coincidencias: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:22.611525: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:22.734001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 460.18entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.5400 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:23.105201: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:23.231909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 284.03entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.5300 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:23.736815: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:23.858419: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 495.52entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.2400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:24.209304: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:24.337571: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 484.35entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.1300 ; Coincidencias: 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:24.700861: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:24.825583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 499.12entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.4100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:25.168258: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:25.291817: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 425.70entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.3000 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:25.666003: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:25.786930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 515.29entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.3400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:26.128430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:26.250932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 577.10entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.4900 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:26.566238: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:26.688518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 490.50entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.4500 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:27.030832: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:27.153324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 423.74entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.3200 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:27.526830: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:27.650541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 449.54entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.5000 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:28.018752: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:28.141353: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 465.28entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.3600 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:28.495935: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:28.618476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 474.76entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.3700 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:28.968614: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:29.092164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 499.79entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.4200 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:29.424581: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:29.549003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 446.70entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.3900 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:29.909131: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:30.033331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 404.63entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.2800 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:30.431067: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:30.554655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 548.85entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.4200 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:30.891722: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:31.014469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 544.79entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.3500 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:31.340329: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:31.465452: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 487.43entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.3400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:31.808642: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:31.931345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 453.13entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.3800 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:32.304008: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:32.428156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 383.33entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.4400 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:32.835724: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:32.958362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 631.87entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.2000 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:33.252990: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:33.376292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 423.02entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.3300 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:33.752636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:33.875787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 405.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.3400 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:34.279131: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:34.401393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 400.28entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.3200 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:34.810415: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:34.932854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 464.76entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.3600 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:35.298693: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:35.421451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 575.39entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.2200 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:35.729680: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:35.852241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 440.49entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.2700 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:36.235610: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:36.359339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 388.28entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:36.768894: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:36.892947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 376.55entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:37.319734: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:37.447675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 581.91entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.1700 ; Coincidencias: 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:37.763602: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:37.892066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 504.85entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.4100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:38.277885: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:38.407151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 470.40entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:38.770626: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:38.904604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 576.72entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.3700 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:39.232787: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:39.359309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 504.97entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.4100 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:39.707559: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:39.839813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 525.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.3300 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:40.183140: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:40.309527: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 553.30entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.5800 ; Coincidencias: 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:40.641066: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:40.764776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 588.25entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.3300 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:41.082505: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:41.214798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 534.18entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:41.533483: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:41.661393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 567.40entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.3400 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:41.989978: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:42.130421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 567.96entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.2700 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:42.459010: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:42.583835: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 544.77entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.4100 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:42.917171: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:43.042300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 611.26entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.1900 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:43.351478: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:43.475877: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 482.41entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.4100 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:43.843626: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:43.970135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 569.98entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.3100 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:44.291520: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:44.413431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 499.59entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.4600 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:44.760996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:44.886867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 489.53entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.3900 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:45.248721: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:45.376751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 586.12entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.4300 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:45.689209: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:45.813593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 371.75entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.3100 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:46.225461: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:46.351890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 527.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.4100 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:46.710388: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:46.836973: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 474.40entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.3800 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:47.184753: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:47.312269: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 528.86entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.3100 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:47.636993: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:47.759812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 565.82entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.2300 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:48.079016: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:48.203706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 490.52entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:48.556341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:48.687292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 570.07entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.3600 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:49.019707: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:49.155465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 572.67entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.4500 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:49.464263: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:49.587215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 438.11entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:49.948556: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:50.069956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 626.55entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.5200 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:50.381430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:50.506439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 420.77entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.3900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:50.882667: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:51.007432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 603.77entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.2700 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:51.332425: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:51.458629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 439.94entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.3500 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:51.840795: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:51.965123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 609.02entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.4900 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:52.270615: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:52.394191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 611.84entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.4000 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:52.689146: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:52.812201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 614.38entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.4600 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:53.126557: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:53.255685: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 609.58entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.5200 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:53.565720: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:53.690138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 589.71entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.4600 ; Coincidencias: 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:54.011183: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:54.134597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 556.44entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.2600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:54.449118: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:54.574474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 548.14entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.3800 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:54.888454: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:55.010981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 581.13entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.3600 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:55.323588: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:55.445185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 476.79entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.4200 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:55.795856: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:55.921608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 546.97entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.2500 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:56.250981: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:56.375741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 395.25entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.3000 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:37:56.767505: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:56.889959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 410.91entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.3600 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:37:57.289458: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:37:57.417114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 597.27entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.2800 ; Coincidencias: 83/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.364300\n",
      "Precisión global: 81.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR cuantizado\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_QUANTIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61eebb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Saved HAR to: /home/pablo/Documentos/Enxeñaría Informática/Cuarto/2º Cuatrimestre/Traballo Fin de Grao/hyper-rpi/results/models/model_ResBaGAN_discriminator_quantized_model_o2_c0.har\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo cuantizado\n",
    "# Let's save the runner's state to a Quantized HAR\n",
    "quantized_model_har_path = f\"{model_name}_quantized_model_o{optimization_level}_c{compression_level}.har\"\n",
    "runner.save_har(quantized_model_har_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24260b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b9b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dcee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hailo_gpu_env] *",
   "language": "python",
   "name": "conda-env-hailo_gpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
