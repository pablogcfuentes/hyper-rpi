{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b76dd13",
   "metadata": {},
   "source": [
    "# Fase 1.3: Optimización del modelo en HAR (Hailo Archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f181ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 14:46:20.444950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-09 14:46:21.270977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/pablo/anaconda3/envs/hailo_gpu_env/lib/python3.8/site-packages/nvidia/dali/backend.py:77: Warning: DALI 1.49 is the last release to support Python 3.8 Please update your environment to use Python 3.9, or newer.\n",
      "  deprecation_warning(\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from matplotlib import patches\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.python.eager.context import eager_mode\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from itertools import islice\n",
    "\n",
    "# Funciones y parámetros de la CNN base\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import resbagan_networks\n",
    "import resbagan_datasets\n",
    "\n",
    "# import the hailo sdk client relevant classes\n",
    "from hailo_sdk_client import ClientRunner, InferenceContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d16a4d",
   "metadata": {},
   "source": [
    "## 1. Optimización detallada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f860d1c",
   "metadata": {},
   "source": [
    "### 1.1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f18540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrada\n",
    "\n",
    "batch_size = 100\n",
    "B = 5\n",
    "sizex = 32\n",
    "sizey = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0231fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading dataset oitaven_river from disk\n",
      "\toitaven_river dataset is in RAW format\n",
      "[*] Recording available classes\n",
      "[*] Starting preprocessing\n",
      "[*] Scaling dataset to [-1, 1]\n",
      "[*] Splitting dataset into train, validation, and test sets: ratios (0.02, 0.01)\n",
      "[*] Total samples: 6067179\n",
      "\t[*] Recording samples for class Water (309248 items)\n",
      "\t[*] Recording samples for class Bare soil (113324 items)\n",
      "\t[*] Recording samples for class Rock (79152 items)\n",
      "\t[*] Recording samples for class Asphalt (43861 items)\n",
      "\t[*] Recording samples for class Concrete (128022 items)\n",
      "\t[*] Recording samples for class Tiles (78785 items)\n",
      "\t[*] Recording samples for class Meadows (2428482 items)\n",
      "\t[*] Recording samples for class Native trees (1829360 items)\n",
      "\t[*] Recording samples for class Pines (193884 items)\n",
      "\t[*] Recording samples for class Eucalyptus (863061 items)\n",
      "\n",
      "[*] HyperDataset summary:\n",
      "\tName: oitaven_river\n",
      "\tShape: (height) 6689, (width) 6722, (bands) 5\n",
      "\tClasses: ['Water', 'Bare soil', 'Rock', 'Asphalt', 'Concrete', 'Tiles', 'Meadows', 'Native trees', 'Pines', 'Eucalyptus']\n",
      "\tClasses count: 10\n",
      "\tSegmented: False\n",
      "\tSuperpixels count: 0\n",
      "\tPatch size: 32\n",
      "\tRatios: (train) 0.02, (val) 0.01\n",
      "\tSamples count: (train) 121339, (val) 60670, (test) 5885170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir parámetros y cargar datos\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "MODEL=\"../results/models/model_ResBaGAN.pt\"\n",
    "\n",
    "# Proporción de entrenamiento, validación y test\n",
    "SAMPLES=[0.02,0.01]\n",
    "\n",
    "# Carga de datos para la inferencia en el discriminador\n",
    "dataset = resbagan_datasets.HyperDataset(\n",
    "    \"oitaven_river\", segmented=False, patch_size=32, ratios=(SAMPLES[0], SAMPLES[1]))\n",
    "\n",
    "# Almacenamos las dimensiones en variables\n",
    "H = dataset.height\n",
    "V = dataset.width\n",
    "\n",
    "# En este caso seleccionamos samples aleatorios\n",
    "samples = dataset.test_set['samples']\n",
    "\n",
    "# Obtenemos el array de gt\n",
    "truth = dataset.gt.flatten()\n",
    "# Obtenemos un array de indices para test\n",
    "test = dataset.test_index_list\n",
    "\n",
    "# Obtenemos el numero de clases y el numero de clases no vacias para test\n",
    "nclases = dataset.classes_count\n",
    "nclases_no_vacias = 0\n",
    "for i in range(nclases):\n",
    "    clase_actual = i + 1\n",
    "    if any(truth[idx] == clase_actual for idx in test):\n",
    "        nclases_no_vacias += 1\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# The custom HyperDataset object contains all the train, validation and test data\n",
    "#   --> But it will wrapped into a PyTorch data feeder for convenience\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf81525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo convertido a ONNX\n",
    "\n",
    "ort_session = ort.InferenceSession(\"../results/models/model_ResBaGAN_discriminator.onnx\")\n",
    "\n",
    "# Cargar el modelo en HAR\n",
    "\n",
    "model_name = \"../results/models/model_ResBaGAN_discriminator\"\n",
    "hailo_model_har_name = f\"{model_name}_hailo_model.har\"\n",
    "assert os.path.isfile(hailo_model_har_name), \"Please provide valid path for HAR file\"\n",
    "runner = ClientRunner(har=hailo_model_har_name, hw_arch=\"hailo8l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0ecb0",
   "metadata": {},
   "source": [
    "### 1.2 Evaluar el modelo en har sin optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a259b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.4338574   1.9349066  -1.1357371 -12.580229   -3.8186932   1.6274607\n",
      "   -6.9782634  -1.3601333   5.832494   -5.047649    8.855347 ]]\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 20:57:12.424312: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 20:57:12.524259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 8entries [00:00, 247.31entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ -2.5148022   1.4130999  -0.5689734 -10.232361   -1.7181966\n",
      "      0.7633981  -2.620554   -2.6805184   2.9597077  -3.3096926\n",
      "      5.988242 ]]]]\n",
      "Error medio entre ONNX y HAR: 1.952363133430481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Comprobacion rapida de la diferencia de precisión\n",
    "\n",
    "# Crear tensor de entrada de prueba\n",
    "input_tensor = (torch.rand(1, B, sizex, sizey) * 2 - 1).to(\"cpu\")\n",
    "input_np = input_tensor.cpu().numpy()\n",
    "\n",
    "# Realizar la inferencia en ONNX\n",
    "output_onnx = ort_session.run(None, {'input': input_np})[0]\n",
    "\n",
    "print(output_onnx)\n",
    "\n",
    "# Realizar la inferencia en HAR\n",
    "with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "    input_har = np.transpose(input_np, (0, 2, 3, 1))\n",
    "\n",
    "    # Realizar la inferencia en el modelo .har\n",
    "    output_har = runner.infer(ctx, input_har)[0]\n",
    "\n",
    "    print(output_har) \n",
    "\n",
    "# Comparar las diferencias\n",
    "error = np.abs(output_onnx - output_har).mean()\n",
    "print(f'Error medio entre ONNX y HAR: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16be5c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:04.413847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.419331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.419525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.422797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.423007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:04.423214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:06.504143: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:06.504376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:06.504563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-07 23:34:06.504701: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-07 23:34:06.504723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-07 23:34:06.658158: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:07.443633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-07 23:34:14.600249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2025-06-07 23:34:15.915506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Inference: 104entries [00:08, 11.81entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.5300 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:34:16.336811: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:16.441401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1341.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:16.650773: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:16.754623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1450.86entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.3200 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:16.947318: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:17.053381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1470.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.4000 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:17.254454: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:17.363471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1527.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.1900 ; Coincidencias: 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:17.561969: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:17.668376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1472.30entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:17.872931: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:17.971694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1449.86entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.3700 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:18.171859: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:18.270555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1499.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.1600 ; Coincidencias: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:18.466656: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:18.567202: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1452.23entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.4600 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:18.760160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:18.861526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1557.96entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.5900 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:19.062206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:19.159028: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1634.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.2800 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:19.334027: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:19.433828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1545.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.3400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:19.635662: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:19.736819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1645.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.3700 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:19.908076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:20.007599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1545.18entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.2000 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:20.201079: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:20.304468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1349.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.4900 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:20.510608: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:20.614806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1313.12entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.3500 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:20.840357: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:20.938342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1524.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.3200 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:21.126102: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:21.225441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1508.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.4400 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:21.406574: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:21.505760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1578.15entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:21.685393: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:21.785320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1532.34entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.3800 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:21.971498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:22.069723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1596.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.2700 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:22.244747: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:22.343876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1633.53entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.4300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:22.528339: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:22.630837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1423.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.2700 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:22.875973: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:22.974045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1571.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.5500 ; Coincidencias: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:23.173105: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:23.273424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1483.73entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.2800 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:23.466854: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:23.567350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1661.05entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.2700 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:23.747132: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:23.846073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1669.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.4300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:24.020512: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:24.119094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1471.33entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.2600 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:24.300104: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:24.399585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1549.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:24.581281: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:24.681169: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1559.30entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.3900 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:24.865457: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:24.964043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1598.31entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.4700 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:25.135530: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:25.233164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1545.27entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.3800 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:25.408357: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:25.504934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1654.29entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.3500 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:25.703706: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:25.804422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1665.64entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.2800 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:25.988273: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:26.086341: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1661.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.3300 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:26.266350: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:26.366856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1697.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.2800 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:26.539675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:26.637750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1622.81entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.2900 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:26.822507: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:26.923240: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1591.81entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.3800 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:27.104311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:27.202029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1583.45entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.2600 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:27.383299: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:27.482623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.3700 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:27.657949: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:27.756564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1575.37entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.2300 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:27.928806: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:28.028290: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1504.93entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.3100 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:28.238518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:28.336128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1557.95entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.2400 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:28.514813: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:28.611720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1653.84entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.3700 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:28.784599: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:28.882080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1676.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.2300 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:29.064821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:29.164921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1566.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.3000 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:29.355355: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:29.453554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1672.75entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.3600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:29.638585: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:29.738628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1660.25entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.4200 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:29.921699: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:30.021168: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1556.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.2500 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:30.212133: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:30.311205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1627.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:30.500558: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:30.602040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1469.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.3400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:30.798684: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:30.936539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1468.12entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.3900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:34:31.133775: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:31.239530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1427.54entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:31.428341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:31.530919: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1532.79entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:31.714850: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:31.813857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1620.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.4600 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:31.996176: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:32.094696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:32.269482: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:32.367906: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1539.03entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.4400 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:32.544051: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:32.641318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1629.59entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.3500 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:32.819472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:32.920435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1486.23entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.2800 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:33.121154: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:33.219017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1645.12entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.4200 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:33.390085: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:33.487564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1549.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.4700 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:33.662725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:33.764683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1458.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.4500 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:33.969175: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:34.068467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1595.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.5000 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:34.260531: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:34.361102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1586.74entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.3400 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:34.534826: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:34.632846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1599.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.4600 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:34.813160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:34.912840: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1543.78entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.3300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:35.104087: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:35.203281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1625.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.4200 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:35.386482: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:35.485178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1646.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.2500 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:35.660854: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:35.758731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1635.31entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:35.931586: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:36.029982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1663.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:36.206848: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:36.304523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1652.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:36.494031: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:36.593461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1640.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.3800 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:36.774162: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:36.873610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1667.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.3200 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:37.052097: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:37.151523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1526.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.2400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:37.350411: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:37.450671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1651.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.4000 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:37.636959: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:37.737092: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1544.00entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.2400 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:37.927089: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:38.030507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1491.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.3500 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:38.223149: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:38.322768: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:38.497999: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:38.596402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1480.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.4200 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:38.789679: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:38.890432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1517.03entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.2500 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:39.075666: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:39.175711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1605.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.3500 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:39.349461: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:39.450130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1510.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.3500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:39.665302: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:39.765641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1510.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:39.966426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:40.064596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1661.42entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.2900 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:40.243700: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:40.341428: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1607.21entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.3200 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:40.517695: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:40.619999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1466.83entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.3400 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:40.803063: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:40.904069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1525.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:41.093111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:41.191363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1581.83entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:41.369341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:41.467264: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1603.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:41.641954: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:41.740337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1580.63entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.3600 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:41.935870: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:42.036194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1384.16entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.4000 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:42.234043: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:42.344520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1483.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.2800 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:42.533002: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:42.631912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.42entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.3600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:42.802249: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:42.899921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1601.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.4200 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:43.076516: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:43.175553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1600.42entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.2100 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:43.369673: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:43.470982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1324.93entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.3000 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:43.702081: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:43.802838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1496.21entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.4700 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:43.982785: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:44.082144: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1557.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.4900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:44.271766: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:44.374167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1515.55entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.4000 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:34:44.569055: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:34:44.669716: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1505.83entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.3400 ; Coincidencias: 84/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.354600\n",
      "Precisión global: 82.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR sin optimizacion\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e9139",
   "metadata": {},
   "source": [
    "### 1.3 Aplicar modificaciones de optimización al modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac30ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warning] Model script is empty\n",
      "[info] Loading model script commands to model_ResBaGAN_discriminator from string\n",
      "[warning] Model script is empty\n",
      "[warning] DEPRECATION WARNING: Optimizing in full precision will require calibration data in the near future, to allow more accurate optimization algorithms which require inference on actual data.\n"
     ]
    }
   ],
   "source": [
    "# Crear un model script para el proceso de optimización\n",
    "\n",
    "model_script_lines = [\n",
    "    # Add normalization layer with mean [123.675, 116.28, 103.53] and std [58.395, 57.12, 57.375])\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # For multiple input nodes:\n",
    "    # {normalization_layer_name_1} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_1_from_hn})\\n',\n",
    "    # {normalization_layer_name_2} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_2_from_hn})\\n',\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Load the model script to ClientRunner so it will be considered on optimization\n",
    "runner.load_model_script(\"\".join(model_script_lines))\n",
    "runner.optimize_full_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d521d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:07.796378: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:08.558899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:04, 25.80entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.3900 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-07 23:35:12.695495: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:12.800920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1602.44entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.3500 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:12.987117: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:13.093916: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1597.56entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.4800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:13.274844: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:13.379376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1628.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.2600 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:13.563201: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:13.666750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1655.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:13.855468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:13.959353: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1627.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.2100 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:14.139219: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:14.244643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1639.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:14.422088: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:14.523884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1642.74entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.3400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:14.718330: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:14.819922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1668.52entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.3200 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:15.055009: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:15.164555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1336.18entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:15.358369: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:15.462884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1493.55entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.3400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:15.651544: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:15.756334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1541.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.3400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:15.937065: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:16.044294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1520.15entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.3500 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:16.242235: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:16.346185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1662.04entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.3900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:16.522809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:16.623804: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1609.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.4500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:16.815246: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:16.920566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1718.65entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.3700 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:17.100420: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:17.202553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1638.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.3100 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:17.377375: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:17.480373: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1635.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.4500 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:17.654455: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:17.755830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1636.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.2200 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:17.933288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:18.034868: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1599.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.3400 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:18.228513: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:18.341691: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1503.01entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.3700 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:18.541240: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:18.644940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1612.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.2900 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:18.822397: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:18.928234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1575.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.3600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:19.123144: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:19.226669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1524.07entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.3600 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:19.408771: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:19.511637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1626.79entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.4900 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:19.692160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:19.792999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1704.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.2900 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:19.967550: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:20.072116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1504.15entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.3300 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:20.272627: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:20.375815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1714.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.4000 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:20.567977: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:20.672901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1639.00entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.3900 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:20.847155: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:20.951061: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1531.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.2100 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:21.137706: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:21.240267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1620.76entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.4000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:21.418685: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:21.525149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1533.57entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:21.708001: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:21.809293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1577.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.4700 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:21.987203: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:22.088683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1621.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:22.281945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:22.387712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1510.78entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.4400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:22.589717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:22.694708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1691.16entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.4800 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:22.874198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:22.977385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1689.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.5000 ; Coincidencias: 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:23.161164: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:23.268578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1464.21entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.3000 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:23.459708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:23.564975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1426.23entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.2800 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:23.760617: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:23.865138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1653.22entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.3500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:24.047658: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:24.154836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1427.28entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.3200 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:24.349928: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:24.454482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1639.80entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.1600 ; Coincidencias: 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:24.635087: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:24.739933: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1417.57entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.5100 ; Coincidencias: 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:24.952367: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:25.060538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1677.19entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.3100 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:25.236034: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:25.338013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1645.16entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:25.536746: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:25.642535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1633.45entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.3600 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:25.820852: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:25.924902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1677.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.4300 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:26.107036: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:26.209377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1564.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.3500 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:26.392229: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:26.495311: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1619.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.3500 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:26.673461: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:26.775646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1513.41entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.5100 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:26.993868: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:27.099546: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1565.93entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.3800 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:27.330517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:27.432412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1661.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.3300 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:27.616785: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:27.720957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1483.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.2800 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:27.907575: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:28.010494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1596.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.4400 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:28.186809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:28.290234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1651.84entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.5400 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:28.465045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:28.569646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1625.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.3200 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:28.745518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:28.846847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1558.37entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.1900 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:29.032225: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:29.136197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1669.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.3800 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:29.316178: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:29.418501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1669.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.2300 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:29.607586: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:29.710537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1664.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.2000 ; Coincidencias: 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:29.885946: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:29.988656: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1538.41entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.4000 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:30.170797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:30.273921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1693.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.2700 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:30.466348: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:30.569291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1666.38entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.2300 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:30.743047: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:30.845760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1662.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:31.037514: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:31.142079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1496.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.5100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:31.334949: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:31.440261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1580.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.5400 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:31.634971: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:31.737255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1627.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.2600 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:31.922210: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:32.024838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1623.45entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:32.218880: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:32.320741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1635.30entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.5000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:32.499824: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:32.601815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1636.05entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.4500 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:32.784146: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:32.888293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1542.13entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.5900 ; Coincidencias: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:33.077617: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:33.179707: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1512.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.2900 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:33.368869: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:33.473956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1406.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.4900 ; Coincidencias: 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:33.677136: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:33.783950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1481.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.4100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:33.971186: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:34.073852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1652.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.3300 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:34.261340: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:34.366348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1486.49entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.5000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:34.579083: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:34.684794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1490.77entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.5100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:34.881561: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:34.986508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1422.67entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.3900 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:35.180137: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:35.283757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1554.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.4700 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:35.486339: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:35.590724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1597.73entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.2600 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:35.782435: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:35.886398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1547.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.2700 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:36.064846: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:36.179443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1525.22entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.2600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:36.372095: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:36.478306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1604.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.3200 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:36.655668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:36.759929: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1504.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.3200 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:36.950231: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:37.052227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1662.91entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.4100 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:37.230991: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:37.333758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1643.18entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.3000 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:37.515156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:37.620283: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1453.17entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.2600 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:37.808121: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:37.913175: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1645.65entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.4700 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:38.102572: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:38.207377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1559.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.2100 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:38.391187: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:38.500051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1466.02entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.3300 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:38.688337: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:38.791709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1462.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.4700 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:38.981979: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:39.087228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1536.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.3400 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:39.286252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:39.390561: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1585.09entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.4100 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:39.570191: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:39.675532: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1581.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.4200 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:39.868267: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:39.974315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1626.75entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.1400 ; Coincidencias: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:40.160341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:40.266267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1496.84entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:40.465552: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:40.569989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1619.12entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.3600 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:40.750174: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:40.857530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1440.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.4200 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:41.053111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:41.156590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1618.50entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.3600 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 23:35:41.344027: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-07 23:35:41.450568: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1530.31entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.3200 ; Coincidencias: 84/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.355800\n",
      "Precisión global: 82.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR con optimizacion\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_FP_OPTIMIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce0f2c",
   "metadata": {},
   "source": [
    "### 1.4 Cuantizar el modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8005d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataset de calibración\n",
    "# The original images are being used, just as the input to the SDK_FP_OPTIMIZED emulator\n",
    "total_images = 1050\n",
    "\n",
    "dataset.to_train()\n",
    "calib_dataset = np.zeros((total_images, sizex, sizey, B), dtype = np.float32)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Seleccionamos batches del dataloader para guardarlos en el dataset\n",
    "for (inputs, labels, targets_pixel_level) in data_loader:\n",
    "    for img in inputs:\n",
    "        if count >= total_images:\n",
    "            break\n",
    "            \n",
    "        # Los inputs son de la forma (batch_size, B, sizex, sizey)\n",
    "        img_np = img.numpy()\n",
    "        # Trasponemos los inputs a formato (batch_size, sizex, sizey, B)\n",
    "        img_har = np.transpose(img_np, (1, 2, 0))\n",
    "\n",
    "        calib_dataset[count] = img_har\n",
    "        count += 1\n",
    "        \n",
    "    if count >= total_images:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4166000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layers are: \n",
      "['model_ResBaGAN_discriminator/input_layer1']\n",
      "[info] Loading model script commands to model_ResBaGAN_discriminator from string\n",
      "[info] Starting Model Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 14:47:03.119293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:03.123455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:03.123798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:03.125355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:03.125651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:03.125893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:04.793297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:04.793627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:04.793835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:04.793986: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-09 14:47:04.794028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-09 14:47:05.072014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:05.074317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:05.074597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:05.075962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:05.076175: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:05.076371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:06.634958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:06.635208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:06.635403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:06.635568: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-09 14:47:06.635619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warning] Reducing compression ratio to 0 because the number of parameters in the network is not large enough (0M and need at least 20M). Can be enforced using model_optimization_config(compression_params, auto_4bit_weights_ratio=0.600)\n",
      "[info] Model received quantization params from the hn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 14:47:07.108286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:07.111086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:07.111356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:07.112569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:07.112786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:07.112985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.586698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.586983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.587193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.587364: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-09 14:47:08.587413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-09 14:47:08.833188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.835208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.835438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.836684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.836902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:08.837097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:10.277052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:10.277314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:10.277536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:10.277691: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-09 14:47:10.277719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] MatmulDecompose skipped\n",
      "[info] Starting Mixed Precision\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv21 with 147.46k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv23 with 147.46k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv18 with 36.86k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv11 with 9.22k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv13 with 9.22k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv14 with 9.22k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv15 with 9.22k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv16 with 9.22k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv10 with 4.61k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv9 with 4.61k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv2 with 2.30k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv3 with 2.30k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv4 with 2.30k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv5 with 2.30k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv6 with 2.30k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv7 with 2.30k parameters\n",
      "[info] Assigning 4bit weights to layer model_ResBaGAN_discriminator/conv8 with 2.30k parameters\n",
      "[info] Ratio of weights in 4bit is 0.43\n",
      "[info] Model Optimization Algorithm Mixed Precision is done (completion time is 00:00:00.21)\n",
      "[info] LayerNorm Decomposition skipped\n",
      "[info] Starting Statistics Collector\n",
      "[info] Using dataset with 64 entries for calibration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration:   0%|                                          | 0/64 [00:00<?, ?entries/s]2025-06-09 14:47:14.495950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:14.515693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:22.359159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "Calibration: 100%|█████████████████████████████████| 64/64 [00:10<00:00,  6.11entries/s]\n",
      "2025-06-09 14:47:23.460418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-06-09 14:47:23.465851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:23.481889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:23.496927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:23.511597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:23.526372: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:23.540930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:23.555558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Statistics Collector is done (completion time is 00:00:11.30)\n",
      "[info] Starting Fix zp_comp Encoding\n",
      "[info] Model Optimization Algorithm Fix zp_comp Encoding is done (completion time is 00:00:00.00)\n",
      "[info] Matmul Equalization skipped\n",
      "[info] Starting MatmulDecomposeFix\n",
      "[info] Model Optimization Algorithm MatmulDecomposeFix is done (completion time is 00:00:00.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 14:47:32.935346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:32.941748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:32.942000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:32.943389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:32.943615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:32.943817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:34.617697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:34.617946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:34.618139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:34.618285: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-09 14:47:34.618313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-09 14:47:35.389369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:35.391051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:35.391279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:35.392865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:35.393091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:35.393282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:36.774994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:36.775274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:36.775488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 14:47:36.775639: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-09 14:47:36.775677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Finetune encoding skipped\n",
      "[info] Bias Correction skipped\n",
      "[warning] Dataset is larger than dataset_size in Adaround. Increasing the algorithm dataset size might improve the results\n",
      "[info] Starting Adaround\n",
      "[info] The algorithm Adaround will use up to 0.23 GB of storage space\n",
      "[info] Using dataset with 1024 entries for Adaround\n",
      "[info] Using dataset with 64 entries for bias correction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 14:47:39.971924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:39.972103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:40.574425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:40.574615: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:   0%| | 0/26 [00:00<?, ?blocks/s, Layers=['model_ResBaGAN_discriminator/conv1_2025-06-09 14:47:41.247876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 14:47:42.985528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 14:47:47.082078: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-06-09 14:47:47.150348: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x56358fd3efb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-09 14:47:47.150370: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-06-09 14:47:47.179651: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-09 14:47:47.360787: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<27:42:08,  2.43s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<27:42:08,  2.43s/batches, l2_loss: 0.0004 - round_loss:\u001b[A\n",
      "Training:   0%| | 93/40960 [00:02<13:59, 48.65batches/s, l2_loss: 0.0004 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 93/40960 [00:02<13:59, 48.65batches/s, l2_loss: 0.0008 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 186/40960 [00:02<06:36, 102.81batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   0%| | 186/40960 [00:02<06:36, 102.81batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 280/40960 [00:03<04:13, 160.22batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 280/40960 [00:03<04:13, 160.22batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 376/40960 [00:03<03:05, 218.36batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 376/40960 [00:03<03:05, 218.36batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   1%| | 472/40960 [00:03<02:28, 272.40batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   1%| | 472/40960 [00:03<02:28, 272.40batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 566/40960 [00:03<02:07, 317.20batches/s, l2_loss: 0.0008 - round_loss:\u001b[A\n",
      "Training:   1%| | 566/40960 [00:03<02:07, 317.20batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   2%| | 660/40960 [00:03<01:53, 353.94batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   2%| | 660/40960 [00:03<01:53, 353.94batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   2%| | 753/40960 [00:04<01:45, 382.29batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   2%| | 753/40960 [00:04<01:45, 382.29batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   2%| | 845/40960 [00:04<01:39, 402.44batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   2%| | 845/40960 [00:04<01:39, 402.44batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   2%| | 940/40960 [00:04<01:34, 422.07batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   2%| | 940/40960 [00:04<01:34, 422.07batches/s, l2_loss: 0.0007 - round_loss:\u001b[A\n",
      "Training:   3%| | 1032/40960 [00:04<01:32, 432.10batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   3%| | 1032/40960 [00:04<01:32, 432.10batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1126/40960 [00:04<01:30, 441.92batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:   3%| | 1126/40960 [00:04<01:30, 441.92batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   3%| | 1221/40960 [00:05<01:28, 450.58batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   3%| | 1221/40960 [00:05<01:28, 450.58batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   3%| | 1314/40960 [00:05<01:27, 454.13batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   3%| | 1314/40960 [00:05<01:27, 454.13batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   3%| | 1407/40960 [00:05<01:26, 457.23batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   3%| | 1407/40960 [00:05<01:26, 457.23batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   4%| | 1500/40960 [00:05<01:25, 459.00batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   4%| | 1500/40960 [00:05<01:25, 459.00batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   4%| | 1593/40960 [00:05<01:25, 460.76batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   4%| | 1593/40960 [00:05<01:25, 460.76batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   4%| | 1686/40960 [00:06<01:25, 461.53batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   4%| | 1686/40960 [00:06<01:25, 461.53batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   4%| | 1781/40960 [00:06<01:24, 464.25batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   4%| | 1781/40960 [00:06<01:24, 464.25batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 1872/40960 [00:06<01:24, 460.81batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 1872/40960 [00:06<01:24, 460.81batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 1967/40960 [00:06<01:23, 464.59batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 1967/40960 [00:06<01:23, 464.59batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 2058/40960 [00:06<01:24, 461.63batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 2058/40960 [00:06<01:24, 461.63batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 2153/40960 [00:07<01:23, 465.54batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 2153/40960 [00:07<01:23, 465.54batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 2248/40960 [00:07<01:22, 467.94batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   5%| | 2248/40960 [00:07<01:22, 467.94batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   6%| | 2341/40960 [00:07<01:22, 466.61batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   6%| | 2341/40960 [00:07<01:22, 466.61batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   6%| | 2436/40960 [00:07<01:22, 467.81batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   6%| | 2436/40960 [00:07<01:22, 467.81batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   6%| | 2531/40960 [00:07<01:21, 468.87batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   6%| | 2531/40960 [00:07<01:21, 468.87batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   6%| | 2624/40960 [00:08<01:22, 467.39batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%| | 2624/40960 [00:08<01:22, 467.39batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   7%| | 2719/40960 [00:08<01:21, 468.32batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   7%| | 2719/40960 [00:08<01:21, 468.32batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   7%| | 2812/40960 [00:08<01:21, 466.28batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   7%| | 2812/40960 [00:08<01:21, 466.28batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   7%| | 2906/40960 [00:08<01:21, 467.20batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   7%| | 2906/40960 [00:08<01:21, 467.20batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   7%| | 3002/40960 [00:08<01:20, 470.08batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   7%| | 3002/40960 [00:08<01:20, 470.08batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3097/40960 [00:09<01:20, 470.32batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3097/40960 [00:09<01:20, 470.32batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3192/40960 [00:09<01:20, 471.47batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3192/40960 [00:09<01:20, 471.47batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3285/40960 [00:09<01:20, 468.37batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3285/40960 [00:09<01:20, 468.37batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3380/40960 [00:09<01:20, 469.65batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3380/40960 [00:09<01:20, 469.65batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3473/40960 [00:09<01:20, 467.74batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   8%| | 3473/40960 [00:09<01:20, 467.74batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   9%| | 3566/40960 [00:10<01:20, 466.41batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   9%| | 3566/40960 [00:10<01:20, 466.41batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   9%| | 3659/40960 [00:10<01:20, 465.63batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   9%| | 3659/40960 [00:10<01:20, 465.63batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   9%| | 3752/40960 [00:10<01:20, 464.14batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   9%| | 3752/40960 [00:10<01:20, 464.14batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   9%| | 3847/40960 [00:10<01:19, 467.34batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:   9%| | 3847/40960 [00:10<01:19, 467.34batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  10%| | 3940/40960 [00:10<01:19, 466.18batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  10%| | 3940/40960 [00:10<01:19, 466.18batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  10%| | 4035/40960 [00:11<01:18, 467.78batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  10%| | 4035/40960 [00:11<01:18, 467.78batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  10%| | 4130/40960 [00:11<01:18, 469.14batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  10%| | 4130/40960 [00:11<01:18, 469.14batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  10%| | 4226/40960 [00:11<01:17, 471.90batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  10%| | 4226/40960 [00:11<01:17, 471.90batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4320/40960 [00:11<01:17, 470.57batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4320/40960 [00:11<01:17, 470.57batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4414/40960 [00:11<01:17, 469.29batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4414/40960 [00:11<01:17, 469.29batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4507/40960 [00:12<01:17, 467.79batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4507/40960 [00:12<01:17, 467.79batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4603/40960 [00:12<01:17, 470.13batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4603/40960 [00:12<01:17, 470.13batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4697/40960 [00:12<01:17, 468.87batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  11%| | 4697/40960 [00:12<01:17, 468.87batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  12%| | 4791/40960 [00:12<01:17, 468.31batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  12%| | 4791/40960 [00:12<01:17, 468.31batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  12%| | 4884/40960 [00:12<01:17, 465.91batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  12%| | 4884/40960 [00:12<01:17, 465.91batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  12%| | 4976/40960 [00:13<01:17, 462.89batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  12%| | 4976/40960 [00:13<01:17, 462.89batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  12%| | 5070/40960 [00:13<01:17, 464.13batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  12%| | 5070/40960 [00:13<01:17, 464.13batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5164/40960 [00:13<01:16, 465.24batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5164/40960 [00:13<01:16, 465.24batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5258/40960 [00:13<01:16, 465.64batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5258/40960 [00:13<01:16, 465.64batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5352/40960 [00:13<01:16, 466.18batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5352/40960 [00:13<01:16, 466.18batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5447/40960 [00:14<01:15, 468.61batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5447/40960 [00:14<01:15, 468.61batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5541/40960 [00:14<01:15, 468.85batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5541/40960 [00:14<01:15, 468.85batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5637/40960 [00:14<01:14, 471.72batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5637/40960 [00:14<01:14, 471.72batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5730/40960 [00:14<01:15, 468.34batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5730/40960 [00:14<01:15, 468.34batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5822/40960 [00:14<01:15, 464.84batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5822/40960 [00:14<01:15, 464.84batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5916/40960 [00:15<01:15, 465.32batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5916/40960 [00:15<01:15, 465.32batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6010/40960 [00:15<01:15, 465.68batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6010/40960 [00:15<01:15, 465.68batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6103/40960 [00:15<01:14, 465.22batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6103/40960 [00:15<01:14, 465.22batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6196/40960 [00:15<01:14, 463.90batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6196/40960 [00:15<01:14, 463.90batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6290/40960 [00:15<01:14, 465.46batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6290/40960 [00:15<01:14, 465.46batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6385/40960 [00:16<01:14, 467.18batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6385/40960 [00:16<01:14, 467.18batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6479/40960 [00:16<01:13, 466.68batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6479/40960 [00:16<01:13, 466.68batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6573/40960 [00:16<01:13, 467.62batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6573/40960 [00:16<01:13, 467.62batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6666/40960 [00:16<01:13, 466.11batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6666/40960 [00:16<01:13, 466.11batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6761/40960 [00:16<01:13, 468.14batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6761/40960 [00:16<01:13, 468.14batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|▏| 6854/40960 [00:17<01:13, 466.41batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6854/40960 [00:17<01:13, 466.41batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6947/40960 [00:17<01:13, 465.91batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6947/40960 [00:17<01:13, 465.91batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7041/40960 [00:17<01:12, 466.77batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7041/40960 [00:17<01:12, 466.77batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7136/40960 [00:17<01:12, 468.81batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7136/40960 [00:17<01:12, 468.81batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7231/40960 [00:17<01:11, 470.40batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7231/40960 [00:17<01:11, 470.40batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7325/40960 [00:18<01:11, 469.88batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7325/40960 [00:18<01:11, 469.88batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7419/40960 [00:18<01:11, 468.90batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7419/40960 [00:18<01:11, 468.90batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7512/40960 [00:18<01:11, 466.74batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7512/40960 [00:18<01:11, 466.74batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7606/40960 [00:18<01:11, 467.47batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7606/40960 [00:18<01:11, 467.47batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7700/40960 [00:18<01:11, 468.22batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7700/40960 [00:18<01:11, 468.22batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7794/40960 [00:19<01:10, 467.79batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7794/40960 [00:19<01:10, 467.79batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7889/40960 [00:19<01:10, 468.59batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7889/40960 [00:19<01:10, 468.59batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7985/40960 [00:19<01:10, 470.74batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7985/40960 [00:19<01:10, 470.74batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8079/40960 [00:19<01:09, 470.02batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8079/40960 [00:19<01:09, 470.02batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8174/40960 [00:19<01:09, 470.27batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8174/40960 [00:19<01:09, 470.27batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8254/40960 [00:20<01:12, 449.11batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8254/40960 [00:20<01:12, 449.11batches/s, l2_loss: 0.0012 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8339/40960 [00:20<01:13, 441.11batches/s, l2_loss: 0.0012 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8339/40960 [00:20<01:13, 441.11batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8424/40960 [00:20<01:14, 436.17batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8424/40960 [00:20<01:14, 436.17batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8510/40960 [00:20<01:14, 433.09batches/s, l2_loss: 0.0008 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8510/40960 [00:20<01:14, 433.09batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8594/40960 [00:20<01:15, 429.09batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8594/40960 [00:20<01:15, 429.09batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8675/40960 [00:21<01:16, 421.74batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8675/40960 [00:21<01:16, 421.74batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8760/40960 [00:21<01:16, 421.78batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8760/40960 [00:21<01:16, 421.78batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8847/40960 [00:21<01:15, 425.23batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8847/40960 [00:21<01:15, 425.23batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8930/40960 [00:21<01:15, 421.96batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8930/40960 [00:21<01:15, 421.96batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9014/40960 [00:21<01:16, 420.26batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9014/40960 [00:21<01:16, 420.26batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9099/40960 [00:22<01:15, 421.14batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9099/40960 [00:22<01:15, 421.14batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9185/40960 [00:22<01:15, 423.58batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9185/40960 [00:22<01:15, 423.58batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9272/40960 [00:22<01:14, 425.50batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9272/40960 [00:22<01:14, 425.50batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9355/40960 [00:22<01:14, 422.36batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9355/40960 [00:22<01:14, 422.36batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9442/40960 [00:22<01:14, 425.45batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9442/40960 [00:22<01:14, 425.45batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9524/40960 [00:23<01:14, 419.95batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9524/40960 [00:23<01:14, 419.95batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9606/40960 [00:23<01:15, 416.52batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9606/40960 [00:23<01:15, 416.52batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9692/40960 [00:23<01:14, 419.94batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9692/40960 [00:23<01:14, 419.94batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9776/40960 [00:23<01:14, 419.90batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9776/40960 [00:23<01:14, 419.90batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9860/40960 [00:23<01:14, 419.39batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9860/40960 [00:23<01:14, 419.39batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9945/40960 [00:24<01:13, 420.28batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9945/40960 [00:24<01:13, 420.28batches/s, l2_loss: 0.0007 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10028/40960 [00:24<01:14, 417.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  24%|▏| 10028/40960 [00:24<01:14, 417.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▏| 10114/40960 [00:24<01:13, 420.51batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▏| 10114/40960 [00:24<01:13, 420.51batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▏| 10187/40960 [00:24<01:16, 403.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▏| 10187/40960 [00:24<01:16, 403.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▎| 10254/40960 [00:24<01:20, 382.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▎| 10254/40960 [00:24<01:20, 382.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▎| 10319/40960 [00:25<01:23, 364.91batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▎| 10319/40960 [00:25<01:23, 364.91batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▎| 10400/40960 [00:25<01:21, 376.83batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  25%|▎| 10400/40960 [00:25<01:21, 376.83batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10482/40960 [00:25<01:18, 386.10batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10482/40960 [00:25<01:18, 386.10batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10563/40960 [00:25<01:17, 391.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10563/40960 [00:25<01:17, 391.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10639/40960 [00:25<01:18, 387.52batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10639/40960 [00:25<01:18, 387.52batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10716/40960 [00:26<01:18, 385.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10716/40960 [00:26<01:18, 385.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10798/40960 [00:26<01:16, 391.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  26%|▎| 10798/40960 [00:26<01:16, 391.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 10882/40960 [00:26<01:15, 400.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 10882/40960 [00:26<01:15, 400.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 10955/40960 [00:26<01:17, 389.30batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 10955/40960 [00:26<01:17, 389.30batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11019/40960 [00:26<01:21, 367.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11019/40960 [00:26<01:21, 367.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11085/40960 [00:27<01:23, 356.33batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11085/40960 [00:27<01:23, 356.33batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11167/40960 [00:27<01:20, 371.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11167/40960 [00:27<01:20, 371.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11240/40960 [00:27<01:20, 368.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  27%|▎| 11240/40960 [00:27<01:20, 368.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11320/40960 [00:27<01:18, 377.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11320/40960 [00:27<01:18, 377.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11404/40960 [00:27<01:15, 389.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11404/40960 [00:27<01:15, 389.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11482/40960 [00:28<01:15, 388.42batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11482/40960 [00:28<01:15, 388.42batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11563/40960 [00:28<01:14, 393.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11563/40960 [00:28<01:14, 393.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11641/40960 [00:28<01:14, 391.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  28%|▎| 11641/40960 [00:28<01:14, 391.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11723/40960 [00:28<01:13, 395.78batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11723/40960 [00:28<01:13, 395.78batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11802/40960 [00:28<01:13, 394.69batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11802/40960 [00:28<01:13, 394.69batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11884/40960 [00:29<01:13, 398.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11884/40960 [00:29<01:13, 398.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11968/40960 [00:29<01:11, 404.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 11968/40960 [00:29<01:11, 404.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 12051/40960 [00:29<01:10, 407.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  29%|▎| 12051/40960 [00:29<01:10, 407.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12135/40960 [00:29<01:10, 410.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12135/40960 [00:29<01:10, 410.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12212/40960 [00:29<01:11, 402.97batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12212/40960 [00:29<01:11, 402.97batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12292/40960 [00:30<01:11, 400.78batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12292/40960 [00:30<01:11, 400.78batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12373/40960 [00:30<01:11, 400.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12373/40960 [00:30<01:11, 400.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12458/40960 [00:30<01:09, 407.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  30%|▎| 12458/40960 [00:30<01:09, 407.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12542/40960 [00:30<01:09, 411.25batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12542/40960 [00:30<01:09, 411.25batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12627/40960 [00:30<01:08, 414.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12627/40960 [00:30<01:08, 414.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12712/40960 [00:31<01:07, 416.32batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12712/40960 [00:31<01:07, 416.32batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12791/40960 [00:31<01:08, 409.86batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12791/40960 [00:31<01:08, 409.86batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12875/40960 [00:31<01:08, 411.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  31%|▎| 12875/40960 [00:31<01:08, 411.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 12956/40960 [00:31<01:08, 409.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 12956/40960 [00:31<01:08, 409.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 13040/40960 [00:31<01:07, 411.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 13040/40960 [00:31<01:07, 411.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 13122/40960 [00:32<01:07, 410.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 13122/40960 [00:32<01:07, 410.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 13207/40960 [00:32<01:06, 415.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 13207/40960 [00:32<01:06, 415.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 13292/40960 [00:32<01:06, 417.61batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  32%|▎| 13292/40960 [00:32<01:06, 417.61batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13377/40960 [00:32<01:05, 418.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13377/40960 [00:32<01:05, 418.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13461/40960 [00:32<01:05, 418.27batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13461/40960 [00:32<01:05, 418.27batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13544/40960 [00:33<01:05, 416.82batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13544/40960 [00:33<01:05, 416.82batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13628/40960 [00:33<01:05, 417.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13628/40960 [00:33<01:05, 417.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13711/40960 [00:33<01:05, 415.54batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  33%|▎| 13711/40960 [00:33<01:05, 415.54batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 13794/40960 [00:33<01:05, 414.16batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 13794/40960 [00:33<01:05, 414.16batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 13877/40960 [00:34<01:05, 413.85batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 13877/40960 [00:34<01:05, 413.85batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 13960/40960 [00:34<01:05, 413.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 13960/40960 [00:34<01:05, 413.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 14041/40960 [00:34<01:05, 409.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 14041/40960 [00:34<01:05, 409.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 14122/40960 [00:34<01:05, 407.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  34%|▎| 14122/40960 [00:34<01:05, 407.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  35%|▎| 14207/40960 [00:34<01:04, 412.19batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  35%|▎| 14207/40960 [00:34<01:04, 412.19batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14289/40960 [00:35<01:05, 409.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  35%|▎| 14289/40960 [00:35<01:05, 409.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  35%|▎| 14374/40960 [00:35<01:04, 413.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  35%|▎| 14374/40960 [00:35<01:04, 413.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  35%|▎| 14460/40960 [00:35<01:03, 417.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  35%|▎| 14460/40960 [00:35<01:03, 417.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14545/40960 [00:35<01:02, 419.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14545/40960 [00:35<01:02, 419.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14628/40960 [00:35<01:03, 417.37batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14628/40960 [00:35<01:03, 417.37batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14705/40960 [00:36<01:04, 406.76batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14705/40960 [00:36<01:04, 406.76batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14772/40960 [00:36<01:08, 384.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14772/40960 [00:36<01:08, 384.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14843/40960 [00:36<01:09, 374.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14843/40960 [00:36<01:09, 374.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14913/40960 [00:36<01:11, 365.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  36%|▎| 14913/40960 [00:36<01:11, 365.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 14991/40960 [00:36<01:09, 372.36batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 14991/40960 [00:36<01:09, 372.36batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 15076/40960 [00:37<01:06, 387.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 15076/40960 [00:37<01:06, 387.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 15161/40960 [00:37<01:04, 398.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 15161/40960 [00:37<01:04, 398.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 15242/40960 [00:37<01:04, 399.19batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 15242/40960 [00:37<01:04, 399.19batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 15320/40960 [00:37<01:04, 395.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  37%|▎| 15320/40960 [00:37<01:04, 395.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15398/40960 [00:37<01:05, 392.76batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15398/40960 [00:37<01:05, 392.76batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15474/40960 [00:38<01:05, 388.73batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15474/40960 [00:38<01:05, 388.73batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15550/40960 [00:38<01:05, 385.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15550/40960 [00:38<01:05, 385.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15624/40960 [00:38<01:06, 380.45batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15624/40960 [00:38<01:06, 380.45batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15700/40960 [00:38<01:06, 379.80batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  38%|▍| 15700/40960 [00:38<01:06, 379.80batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 15775/40960 [00:38<01:06, 377.36batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 15775/40960 [00:38<01:06, 377.36batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 15849/40960 [00:39<01:06, 375.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 15849/40960 [00:39<01:06, 375.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 15927/40960 [00:39<01:05, 379.40batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 15927/40960 [00:39<01:05, 379.40batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 16004/40960 [00:39<01:05, 380.45batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 16004/40960 [00:39<01:05, 380.45batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 16084/40960 [00:39<01:04, 385.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 16084/40960 [00:39<01:04, 385.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 16168/40960 [00:39<01:02, 394.77batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  39%|▍| 16168/40960 [00:39<01:02, 394.77batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  40%|▍| 16254/40960 [00:40<01:01, 404.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  40%|▍| 16254/40960 [00:40<01:01, 404.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  40%|▍| 16339/40960 [00:40<01:00, 410.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  40%|▍| 16339/40960 [00:40<01:00, 410.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  40%|▍| 16425/40960 [00:40<00:59, 415.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  40%|▍| 16425/40960 [00:40<00:59, 415.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  40%|▍| 16507/40960 [00:40<00:59, 413.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  40%|▍| 16507/40960 [00:40<00:59, 413.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16592/40960 [00:40<00:58, 416.82batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16592/40960 [00:40<00:58, 416.82batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16677/40960 [00:41<00:57, 419.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16677/40960 [00:41<00:57, 419.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16761/40960 [00:41<00:57, 419.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16761/40960 [00:41<00:57, 419.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16845/40960 [00:41<00:57, 419.10batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16845/40960 [00:41<00:57, 419.10batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16927/40960 [00:41<00:57, 416.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  41%|▍| 16927/40960 [00:41<00:57, 416.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17011/40960 [00:41<00:57, 415.93batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17011/40960 [00:41<00:57, 415.93batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17096/40960 [00:42<00:57, 418.26batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17096/40960 [00:42<00:57, 418.26batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17181/40960 [00:42<00:56, 419.82batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17181/40960 [00:42<00:56, 419.82batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17264/40960 [00:42<00:56, 417.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17264/40960 [00:42<00:56, 417.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17350/40960 [00:42<00:56, 420.06batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  42%|▍| 17350/40960 [00:42<00:56, 420.06batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17431/40960 [00:42<00:56, 414.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17431/40960 [00:42<00:56, 414.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17516/40960 [00:43<00:56, 417.02batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17516/40960 [00:43<00:56, 417.02batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17600/40960 [00:43<00:56, 416.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17600/40960 [00:43<00:56, 416.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17674/40960 [00:43<00:57, 401.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17674/40960 [00:43<00:57, 401.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17749/40960 [00:43<00:58, 393.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  43%|▍| 17749/40960 [00:43<00:58, 393.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 17834/40960 [00:43<00:57, 402.13batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 17834/40960 [00:43<00:57, 402.13batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 17917/40960 [00:44<00:56, 405.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 17917/40960 [00:44<00:56, 405.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 17992/40960 [00:44<00:58, 395.85batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 17992/40960 [00:44<00:58, 395.85batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 18067/40960 [00:44<00:58, 388.64batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 18067/40960 [00:44<00:58, 388.64batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 18147/40960 [00:44<00:58, 391.50batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  44%|▍| 18147/40960 [00:44<00:58, 391.50batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18231/40960 [00:44<00:57, 398.55batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18231/40960 [00:44<00:57, 398.55batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18312/40960 [00:45<00:56, 399.83batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18312/40960 [00:45<00:56, 399.83batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18382/40960 [00:45<00:58, 383.45batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18382/40960 [00:45<00:58, 383.45batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18455/40960 [00:45<00:59, 377.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18455/40960 [00:45<00:59, 377.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18536/40960 [00:45<00:58, 384.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18536/40960 [00:45<00:58, 384.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18619/40960 [00:45<00:56, 393.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  45%|▍| 18619/40960 [00:45<00:56, 393.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 18700/40960 [00:46<00:56, 396.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 18700/40960 [00:46<00:56, 396.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 18783/40960 [00:46<00:55, 401.59batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 18783/40960 [00:46<00:55, 401.59batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 18846/40960 [00:46<00:59, 374.41batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 18846/40960 [00:46<00:59, 374.41batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 18916/40960 [00:46<01:00, 367.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 18916/40960 [00:46<01:00, 367.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 19000/40960 [00:46<00:57, 381.77batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  46%|▍| 19000/40960 [00:46<00:57, 381.77batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19082/40960 [00:47<00:56, 389.92batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19082/40960 [00:47<00:56, 389.92batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19166/40960 [00:47<00:54, 398.48batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19166/40960 [00:47<00:54, 398.48batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19250/40960 [00:47<00:53, 404.08batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19250/40960 [00:47<00:53, 404.08batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19333/40960 [00:47<00:53, 406.54batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19333/40960 [00:47<00:53, 406.54batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19415/40960 [00:47<00:52, 406.84batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  47%|▍| 19415/40960 [00:47<00:52, 406.84batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19496/40960 [00:48<00:52, 405.80batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19496/40960 [00:48<00:52, 405.80batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19580/40960 [00:48<00:52, 409.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19580/40960 [00:48<00:52, 409.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19663/40960 [00:48<00:51, 410.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19663/40960 [00:48<00:51, 410.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19745/40960 [00:48<00:51, 409.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19745/40960 [00:48<00:51, 409.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19829/40960 [00:48<00:51, 411.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  48%|▍| 19829/40960 [00:48<00:51, 411.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 19909/40960 [00:49<00:51, 408.03batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 19909/40960 [00:49<00:51, 408.03batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 19990/40960 [00:49<00:51, 405.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 19990/40960 [00:49<00:51, 405.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 20072/40960 [00:49<00:51, 406.85batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 20072/40960 [00:49<00:51, 406.85batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 20159/40960 [00:49<00:50, 413.91batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 20159/40960 [00:49<00:50, 413.91batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 20241/40960 [00:49<00:50, 412.13batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  49%|▍| 20241/40960 [00:49<00:50, 412.13batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▍| 20326/40960 [00:50<00:49, 415.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▍| 20326/40960 [00:50<00:49, 415.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▍| 20410/40960 [00:50<00:49, 416.42batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▍| 20410/40960 [00:50<00:49, 416.42batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▌| 20492/40960 [00:50<00:49, 414.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▌| 20492/40960 [00:50<00:49, 414.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▌| 20576/40960 [00:50<00:49, 414.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▌| 20576/40960 [00:50<00:49, 414.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▌| 20659/40960 [00:50<00:48, 414.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  50%|▌| 20659/40960 [00:50<00:48, 414.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 20743/40960 [00:51<00:48, 415.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 20743/40960 [00:51<00:48, 415.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 20827/40960 [00:51<00:48, 415.91batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 20827/40960 [00:51<00:48, 415.91batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 20911/40960 [00:51<00:48, 415.58batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 20911/40960 [00:51<00:48, 415.58batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 20995/40960 [00:51<00:47, 415.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 20995/40960 [00:51<00:47, 415.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 21076/40960 [00:51<00:48, 412.25batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  51%|▌| 21076/40960 [00:51<00:48, 412.25batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21159/40960 [00:52<00:47, 413.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21159/40960 [00:52<00:47, 413.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21241/40960 [00:52<00:47, 411.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21241/40960 [00:52<00:47, 411.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21322/40960 [00:52<00:48, 409.00batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21322/40960 [00:52<00:48, 409.00batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21407/40960 [00:52<00:47, 412.78batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21407/40960 [00:52<00:47, 412.78batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21489/40960 [00:52<00:47, 411.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  52%|▌| 21489/40960 [00:52<00:47, 411.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21568/40960 [00:53<00:47, 406.24batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21568/40960 [00:53<00:47, 406.24batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21650/40960 [00:53<00:47, 407.26batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21650/40960 [00:53<00:47, 407.26batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21735/40960 [00:53<00:46, 411.81batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21735/40960 [00:53<00:46, 411.81batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21819/40960 [00:53<00:46, 413.73batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21819/40960 [00:53<00:46, 413.73batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21903/40960 [00:53<00:45, 414.75batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  53%|▌| 21903/40960 [00:53<00:45, 414.75batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 21987/40960 [00:54<00:45, 416.27batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 21987/40960 [00:54<00:45, 416.27batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 22071/40960 [00:54<00:45, 416.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 22071/40960 [00:54<00:45, 416.99batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 22143/40960 [00:54<00:47, 399.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 22143/40960 [00:54<00:47, 399.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 22216/40960 [00:54<00:48, 389.09batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 22216/40960 [00:54<00:48, 389.09batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 22295/40960 [00:54<00:47, 390.29batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  54%|▌| 22295/40960 [00:54<00:47, 390.29batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22379/40960 [00:55<00:46, 398.57batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22379/40960 [00:55<00:46, 398.57batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22460/40960 [00:55<00:46, 400.13batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22460/40960 [00:55<00:46, 400.13batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22537/40960 [00:55<00:46, 394.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22537/40960 [00:55<00:46, 394.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22609/40960 [00:55<00:47, 382.92batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22609/40960 [00:55<00:47, 382.92batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [00:55<00:47, 387.59batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [00:55<00:47, 387.59batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 22761/40960 [00:56<00:48, 378.49batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 22761/40960 [00:56<00:48, 378.49batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 22844/40960 [00:56<00:46, 388.94batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 22844/40960 [00:56<00:46, 388.94batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 22922/40960 [00:56<00:46, 388.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 22922/40960 [00:56<00:46, 388.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 23002/40960 [00:56<00:45, 391.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 23002/40960 [00:56<00:45, 391.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 23087/40960 [00:56<00:44, 400.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  56%|▌| 23087/40960 [00:56<00:44, 400.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23173/40960 [00:57<00:43, 407.86batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23173/40960 [00:57<00:43, 407.86batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23259/40960 [00:57<00:42, 413.60batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23259/40960 [00:57<00:42, 413.60batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23340/40960 [00:57<00:42, 410.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23340/40960 [00:57<00:42, 410.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23421/40960 [00:57<00:42, 408.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23421/40960 [00:57<00:42, 408.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23495/40960 [00:57<00:44, 396.48batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  57%|▌| 23495/40960 [00:57<00:44, 396.48batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23579/40960 [00:58<00:43, 402.30batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23579/40960 [00:58<00:43, 402.30batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23660/40960 [00:58<00:42, 402.97batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23660/40960 [00:58<00:42, 402.97batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23739/40960 [00:58<00:43, 399.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23739/40960 [00:58<00:43, 399.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23818/40960 [00:58<00:43, 397.33batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23818/40960 [00:58<00:43, 397.33batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23895/40960 [00:58<00:43, 393.59batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  58%|▌| 23895/40960 [00:58<00:43, 393.59batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 23965/40960 [00:59<00:44, 380.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 23965/40960 [00:59<00:44, 380.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 24048/40960 [00:59<00:43, 389.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 24048/40960 [00:59<00:43, 389.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 24134/40960 [00:59<00:42, 400.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 24134/40960 [00:59<00:42, 400.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 24220/40960 [00:59<00:40, 408.53batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 24220/40960 [00:59<00:40, 408.53batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 24306/40960 [00:59<00:40, 414.85batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  59%|▌| 24306/40960 [00:59<00:40, 414.85batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24377/40960 [01:00<00:41, 395.61batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24377/40960 [01:00<00:41, 395.61batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24459/40960 [01:00<00:41, 399.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24459/40960 [01:00<00:41, 399.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24537/40960 [01:00<00:41, 395.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24537/40960 [01:00<00:41, 395.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24617/40960 [01:00<00:41, 396.24batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24617/40960 [01:00<00:41, 396.24batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24698/40960 [01:00<00:40, 398.38batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24698/40960 [01:00<00:40, 398.38batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24780/40960 [01:01<00:40, 401.17batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  60%|▌| 24780/40960 [01:01<00:40, 401.17batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 24863/40960 [01:01<00:39, 405.17batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 24863/40960 [01:01<00:39, 405.17batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 24946/40960 [01:01<00:39, 406.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 24946/40960 [01:01<00:39, 406.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 25026/40960 [01:01<00:39, 403.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 25026/40960 [01:01<00:39, 403.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 25102/40960 [01:01<00:40, 396.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 25102/40960 [01:01<00:40, 396.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 25184/40960 [01:02<00:39, 400.09batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  61%|▌| 25184/40960 [01:02<00:39, 400.09batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25260/40960 [01:02<00:39, 392.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25260/40960 [01:02<00:39, 392.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25337/40960 [01:02<00:40, 390.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25337/40960 [01:02<00:40, 390.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25414/40960 [01:02<00:40, 388.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25414/40960 [01:02<00:40, 388.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25491/40960 [01:02<00:39, 386.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25491/40960 [01:02<00:39, 386.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25567/40960 [01:03<00:40, 384.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  62%|▌| 25567/40960 [01:03<00:40, 384.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25649/40960 [01:03<00:39, 390.40batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25649/40960 [01:03<00:39, 390.40batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25724/40960 [01:03<00:39, 385.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25724/40960 [01:03<00:39, 385.04batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25810/40960 [01:03<00:38, 397.98batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25810/40960 [01:03<00:38, 397.98batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25887/40960 [01:03<00:38, 393.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25887/40960 [01:03<00:38, 393.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25962/40960 [01:04<00:38, 387.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  63%|▋| 25962/40960 [01:04<00:38, 387.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26043/40960 [01:04<00:38, 391.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26043/40960 [01:04<00:38, 391.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26127/40960 [01:04<00:37, 399.17batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26127/40960 [01:04<00:37, 399.17batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26210/40960 [01:04<00:36, 402.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26210/40960 [01:04<00:36, 402.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26288/40960 [01:04<00:36, 398.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26288/40960 [01:04<00:36, 398.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26366/40960 [01:05<00:36, 395.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  64%|▋| 26366/40960 [01:05<00:36, 395.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26450/40960 [01:05<00:36, 401.20batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26450/40960 [01:05<00:36, 401.20batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26530/40960 [01:05<00:36, 400.06batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26530/40960 [01:05<00:36, 400.06batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26603/40960 [01:05<00:36, 388.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26603/40960 [01:05<00:36, 388.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26686/40960 [01:05<00:36, 396.08batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26686/40960 [01:05<00:36, 396.08batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26768/40960 [01:06<00:35, 399.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  65%|▋| 26768/40960 [01:06<00:35, 399.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 26851/40960 [01:06<00:34, 404.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 26851/40960 [01:06<00:34, 404.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 26933/40960 [01:06<00:34, 404.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 26933/40960 [01:06<00:34, 404.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 27016/40960 [01:06<00:34, 407.40batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 27016/40960 [01:06<00:34, 407.40batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 27097/40960 [01:06<00:34, 405.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 27097/40960 [01:06<00:34, 405.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 27182/40960 [01:07<00:33, 410.38batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  66%|▋| 27182/40960 [01:07<00:33, 410.38batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27268/40960 [01:07<00:32, 415.64batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27268/40960 [01:07<00:32, 415.64batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27353/40960 [01:07<00:32, 417.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27353/40960 [01:07<00:32, 417.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27438/40960 [01:07<00:32, 418.81batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27438/40960 [01:07<00:32, 418.81batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27522/40960 [01:07<00:32, 417.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27522/40960 [01:08<00:32, 417.70batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27607/40960 [01:08<00:31, 419.42batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  67%|▋| 27607/40960 [01:08<00:31, 419.42batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 27690/40960 [01:08<00:31, 417.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 27690/40960 [01:08<00:31, 417.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 27775/40960 [01:08<00:31, 419.16batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 27775/40960 [01:08<00:31, 419.16batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 27858/40960 [01:08<00:31, 416.80batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 27858/40960 [01:08<00:31, 416.80batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 27942/40960 [01:09<00:31, 417.32batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 27942/40960 [01:09<00:31, 417.32batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 28024/40960 [01:09<00:31, 415.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  68%|▋| 28024/40960 [01:09<00:31, 415.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28109/40960 [01:09<00:30, 417.27batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28109/40960 [01:09<00:30, 417.27batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28194/40960 [01:09<00:30, 419.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28194/40960 [01:09<00:30, 419.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28278/40960 [01:09<00:30, 418.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28278/40960 [01:09<00:30, 418.95batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28362/40960 [01:10<00:30, 418.93batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28362/40960 [01:10<00:30, 418.93batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28445/40960 [01:10<00:30, 416.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  69%|▋| 28445/40960 [01:10<00:30, 416.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28524/40960 [01:10<00:30, 409.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28524/40960 [01:10<00:30, 409.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28598/40960 [01:10<00:31, 397.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28598/40960 [01:10<00:31, 397.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28672/40960 [01:10<00:31, 388.93batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28672/40960 [01:10<00:31, 388.93batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28747/40960 [01:11<00:31, 384.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28747/40960 [01:11<00:31, 384.63batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28822/40960 [01:11<00:31, 381.50batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  70%|▋| 28822/40960 [01:11<00:31, 381.50batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 28905/40960 [01:11<00:30, 390.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 28905/40960 [01:11<00:30, 390.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 28990/40960 [01:11<00:29, 400.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 28990/40960 [01:11<00:29, 400.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 29072/40960 [01:11<00:29, 402.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 29072/40960 [01:11<00:29, 402.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 29145/40960 [01:12<00:30, 391.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 29145/40960 [01:12<00:30, 391.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 29221/40960 [01:12<00:30, 387.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  71%|▋| 29221/40960 [01:12<00:30, 387.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29296/40960 [01:12<00:30, 383.17batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29296/40960 [01:12<00:30, 383.17batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29378/40960 [01:12<00:29, 391.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29378/40960 [01:12<00:29, 391.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29464/40960 [01:12<00:28, 401.86batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29464/40960 [01:12<00:28, 401.86batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29546/40960 [01:13<00:28, 403.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29546/40960 [01:13<00:28, 403.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29621/40960 [01:13<00:28, 394.60batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  72%|▋| 29621/40960 [01:13<00:28, 394.60batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 29701/40960 [01:13<00:28, 395.32batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 29701/40960 [01:13<00:28, 395.32batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 29785/40960 [01:13<00:27, 402.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 29785/40960 [01:13<00:27, 402.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 29862/40960 [01:13<00:28, 396.21batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 29862/40960 [01:13<00:28, 396.21batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 29940/40960 [01:14<00:27, 393.81batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 29940/40960 [01:14<00:27, 393.81batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 30014/40960 [01:14<00:28, 385.77batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 30014/40960 [01:14<00:28, 385.77batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 30089/40960 [01:14<00:28, 381.64batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  73%|▋| 30089/40960 [01:14<00:28, 381.64batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30172/40960 [01:14<00:27, 391.36batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30172/40960 [01:14<00:27, 391.36batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30256/40960 [01:14<00:26, 399.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30256/40960 [01:14<00:26, 399.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30341/40960 [01:15<00:26, 406.76batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30341/40960 [01:15<00:26, 406.76batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30424/40960 [01:15<00:25, 407.69batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30424/40960 [01:15<00:25, 407.69batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30501/40960 [01:15<00:26, 399.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  74%|▋| 30501/40960 [01:15<00:26, 399.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  75%|▋| 30586/40960 [01:15<00:25, 406.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  75%|▋| 30586/40960 [01:15<00:25, 406.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  75%|▋| 30671/40960 [01:15<00:24, 411.60batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  75%|▋| 30671/40960 [01:15<00:24, 411.60batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  75%|▊| 30758/40960 [01:16<00:24, 417.19batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  75%|▊| 30758/40960 [01:16<00:24, 417.19batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  75%|▊| 30843/40960 [01:16<00:24, 419.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  75%|▊| 30843/40960 [01:16<00:24, 419.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 30927/40960 [01:16<00:23, 418.80batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 30927/40960 [01:16<00:23, 418.80batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 31010/40960 [01:16<00:23, 417.16batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 31010/40960 [01:16<00:23, 417.16batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 31093/40960 [01:16<00:23, 415.83batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 31093/40960 [01:16<00:23, 415.83batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 31174/40960 [01:17<00:23, 412.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 31174/40960 [01:17<00:23, 412.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 31257/40960 [01:17<00:23, 412.06batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  76%|▊| 31257/40960 [01:17<00:23, 412.06batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31340/40960 [01:17<00:23, 411.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31340/40960 [01:17<00:23, 411.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31424/40960 [01:17<00:23, 414.02batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31424/40960 [01:17<00:23, 414.02batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31508/40960 [01:17<00:22, 415.72batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31508/40960 [01:17<00:22, 415.72batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31594/40960 [01:18<00:22, 418.76batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31594/40960 [01:18<00:22, 418.76batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31678/40960 [01:18<00:22, 418.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  77%|▊| 31678/40960 [01:18<00:22, 418.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 31761/40960 [01:18<00:22, 417.16batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 31761/40960 [01:18<00:22, 417.16batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 31846/40960 [01:18<00:21, 418.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 31846/40960 [01:18<00:21, 418.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 31931/40960 [01:18<00:21, 420.21batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 31931/40960 [01:18<00:21, 420.21batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 32016/40960 [01:19<00:21, 421.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 32016/40960 [01:19<00:21, 421.35batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 32100/40960 [01:19<00:21, 420.41batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  78%|▊| 32100/40960 [01:19<00:21, 420.41batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32184/40960 [01:19<00:20, 419.82batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32184/40960 [01:19<00:20, 419.82batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32269/40960 [01:19<00:20, 421.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|▊| 32269/40960 [01:19<00:20, 421.23batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32350/40960 [01:19<00:20, 415.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32350/40960 [01:19<00:20, 415.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32433/40960 [01:20<00:20, 414.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32433/40960 [01:20<00:20, 414.79batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32516/40960 [01:20<00:20, 414.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  79%|▊| 32516/40960 [01:20<00:20, 414.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32600/40960 [01:20<00:20, 414.54batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32600/40960 [01:20<00:20, 414.54batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32683/40960 [01:20<00:20, 413.64batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32683/40960 [01:20<00:20, 413.64batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32767/40960 [01:20<00:19, 414.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32767/40960 [01:20<00:19, 414.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32849/40960 [01:21<00:19, 412.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32849/40960 [01:21<00:19, 412.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32932/40960 [01:21<00:19, 412.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  80%|▊| 32932/40960 [01:21<00:19, 412.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33015/40960 [01:21<00:19, 412.61batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33015/40960 [01:21<00:19, 412.61batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33098/40960 [01:21<00:19, 412.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33098/40960 [01:21<00:19, 412.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33184/40960 [01:21<00:18, 417.00batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33184/40960 [01:21<00:18, 417.00batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33272/40960 [01:22<00:18, 422.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33272/40960 [01:22<00:18, 422.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33356/40960 [01:22<00:18, 421.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  81%|▊| 33356/40960 [01:22<00:18, 421.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33438/40960 [01:22<00:18, 417.03batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33438/40960 [01:22<00:18, 417.03batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33523/40960 [01:22<00:17, 418.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33523/40960 [01:22<00:17, 418.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33605/40960 [01:22<00:17, 415.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33605/40960 [01:22<00:17, 415.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33691/40960 [01:23<00:17, 418.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33691/40960 [01:23<00:17, 418.71batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33776/40960 [01:23<00:17, 420.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  82%|▊| 33776/40960 [01:23<00:17, 420.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 33855/40960 [01:23<00:17, 411.40batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 33855/40960 [01:23<00:17, 411.40batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 33939/40960 [01:23<00:16, 413.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 33939/40960 [01:23<00:16, 413.56batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 34025/40960 [01:23<00:16, 418.46batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 34025/40960 [01:23<00:16, 418.46batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 34110/40960 [01:24<00:16, 420.38batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 34110/40960 [01:24<00:16, 420.38batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 34195/40960 [01:24<00:16, 421.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  83%|▊| 34195/40960 [01:24<00:16, 421.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  84%|▊| 34280/40960 [01:24<00:15, 422.13batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  84%|▊| 34280/40960 [01:24<00:15, 422.13batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  84%|▊| 34366/40960 [01:24<00:15, 423.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  84%|▊| 34366/40960 [01:24<00:15, 423.67batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  84%|▊| 34450/40960 [01:24<00:15, 421.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  84%|▊| 34450/40960 [01:24<00:15, 421.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  84%|▊| 34535/40960 [01:25<00:15, 421.38batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  84%|▊| 34535/40960 [01:25<00:15, 421.38batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34621/40960 [01:25<00:14, 423.72batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34621/40960 [01:25<00:14, 423.72batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34705/40960 [01:25<00:14, 421.69batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34705/40960 [01:25<00:14, 421.69batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34792/40960 [01:25<00:14, 424.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34792/40960 [01:25<00:14, 424.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34875/40960 [01:25<00:14, 421.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34875/40960 [01:25<00:14, 421.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34958/40960 [01:26<00:14, 418.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  85%|▊| 34958/40960 [01:26<00:14, 418.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35043/40960 [01:26<00:14, 420.07batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35043/40960 [01:26<00:14, 420.07batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35129/40960 [01:26<00:13, 422.20batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35129/40960 [01:26<00:13, 422.20batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35215/40960 [01:26<00:13, 423.53batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35215/40960 [01:26<00:13, 423.53batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35296/40960 [01:26<00:13, 416.98batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35296/40960 [01:26<00:13, 416.98batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35380/40960 [01:27<00:13, 417.59batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  86%|▊| 35380/40960 [01:27<00:13, 417.59batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35463/40960 [01:27<00:13, 416.65batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35463/40960 [01:27<00:13, 416.65batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35547/40960 [01:27<00:12, 417.00batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35547/40960 [01:27<00:12, 417.00batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35629/40960 [01:27<00:12, 414.41batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35629/40960 [01:27<00:12, 414.41batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35712/40960 [01:27<00:12, 414.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35712/40960 [01:27<00:12, 414.18batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35797/40960 [01:28<00:12, 416.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  87%|▊| 35797/40960 [01:28<00:12, 416.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 35882/40960 [01:28<00:12, 417.36batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 35882/40960 [01:28<00:12, 417.36batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 35966/40960 [01:28<00:11, 416.73batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 35966/40960 [01:28<00:11, 416.73batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|▉| 36046/40960 [01:28<00:11, 410.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 36046/40960 [01:28<00:11, 410.28batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 36127/40960 [01:28<00:11, 408.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 36127/40960 [01:28<00:11, 408.11batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 36211/40960 [01:29<00:11, 411.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  88%|▉| 36211/40960 [01:29<00:11, 411.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36295/40960 [01:29<00:11, 412.83batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36295/40960 [01:29<00:11, 412.83batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36380/40960 [01:29<00:11, 415.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36380/40960 [01:29<00:11, 415.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36463/40960 [01:29<00:10, 414.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36463/40960 [01:29<00:10, 414.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36548/40960 [01:29<00:10, 417.03batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36548/40960 [01:29<00:10, 417.03batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36632/40960 [01:30<00:10, 416.65batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  89%|▉| 36632/40960 [01:30<00:10, 416.65batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 36716/40960 [01:30<00:10, 416.24batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 36716/40960 [01:30<00:10, 416.24batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 36801/40960 [01:30<00:09, 418.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 36801/40960 [01:30<00:09, 418.47batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 36885/40960 [01:30<00:09, 418.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 36885/40960 [01:30<00:09, 418.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 36970/40960 [01:30<00:09, 419.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 36970/40960 [01:30<00:09, 419.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 37055/40960 [01:31<00:09, 420.91batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  90%|▉| 37055/40960 [01:31<00:09, 420.91batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37140/40960 [01:31<00:09, 420.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37140/40960 [01:31<00:09, 420.90batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37223/40960 [01:31<00:08, 418.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37223/40960 [01:31<00:08, 418.14batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37308/40960 [01:31<00:08, 418.93batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37308/40960 [01:31<00:08, 418.93batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37392/40960 [01:31<00:08, 417.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37392/40960 [01:31<00:08, 417.88batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37477/40960 [01:32<00:08, 419.55batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  91%|▉| 37477/40960 [01:32<00:08, 419.55batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  92%|▉| 37562/40960 [01:32<00:08, 420.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  92%|▉| 37562/40960 [01:32<00:08, 420.34batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  92%|▉| 37645/40960 [01:32<00:07, 418.09batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  92%|▉| 37645/40960 [01:32<00:07, 418.09batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  92%|▉| 37729/40960 [01:32<00:07, 417.98batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  92%|▉| 37729/40960 [01:32<00:07, 417.98batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  92%|▉| 37814/40960 [01:32<00:07, 419.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  92%|▉| 37814/40960 [01:32<00:07, 419.22batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 37899/40960 [01:33<00:07, 420.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 37899/40960 [01:33<00:07, 420.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 37983/40960 [01:33<00:07, 419.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 37983/40960 [01:33<00:07, 419.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 38068/40960 [01:33<00:06, 420.33batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 38068/40960 [01:33<00:06, 420.33batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 38153/40960 [01:33<00:06, 421.52batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 38153/40960 [01:33<00:06, 421.52batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 38238/40960 [01:33<00:06, 422.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  93%|▉| 38238/40960 [01:33<00:06, 422.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38320/40960 [01:34<00:06, 418.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38320/40960 [01:34<00:06, 418.05batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38404/40960 [01:34<00:06, 418.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38404/40960 [01:34<00:06, 418.31batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38491/40960 [01:34<00:05, 422.37batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38491/40960 [01:34<00:05, 422.37batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38574/40960 [01:34<00:05, 420.15batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38574/40960 [01:34<00:05, 420.15batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38659/40960 [01:34<00:05, 421.20batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  94%|▉| 38659/40960 [01:34<00:05, 421.20batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 38743/40960 [01:35<00:05, 419.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 38743/40960 [01:35<00:05, 419.89batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 38830/40960 [01:35<00:05, 423.61batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 38830/40960 [01:35<00:05, 423.61batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 38916/40960 [01:35<00:04, 425.37batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 38916/40960 [01:35<00:04, 425.37batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 39002/40960 [01:35<00:04, 425.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 39002/40960 [01:35<00:04, 425.44batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 39087/40960 [01:35<00:04, 424.54batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  95%|▉| 39087/40960 [01:35<00:04, 424.54batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39171/40960 [01:36<00:04, 422.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39171/40960 [01:36<00:04, 422.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39253/40960 [01:36<00:04, 418.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39253/40960 [01:36<00:04, 418.68batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39338/40960 [01:36<00:03, 419.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39338/40960 [01:36<00:03, 419.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39426/40960 [01:36<00:03, 425.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39426/40960 [01:36<00:03, 425.01batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39506/40960 [01:36<00:03, 417.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  96%|▉| 39506/40960 [01:36<00:03, 417.39batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39590/40960 [01:37<00:03, 417.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39590/40960 [01:37<00:03, 417.43batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39675/40960 [01:37<00:03, 419.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39675/40960 [01:37<00:03, 419.66batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39759/40960 [01:37<00:02, 419.07batches/s, l2_loss: 0.0007 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39759/40960 [01:37<00:02, 419.07batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39845/40960 [01:37<00:02, 420.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39845/40960 [01:37<00:02, 420.96batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39931/40960 [01:37<00:02, 422.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  97%|▉| 39931/40960 [01:37<00:02, 422.74batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  98%|▉| 40016/40960 [01:38<00:02, 422.72batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  98%|▉| 40016/40960 [01:38<00:02, 422.72batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  98%|▉| 40103/40960 [01:38<00:02, 425.78batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  98%|▉| 40103/40960 [01:38<00:02, 425.78batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  98%|▉| 40187/40960 [01:38<00:01, 423.08batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  98%|▉| 40187/40960 [01:38<00:01, 423.08batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  98%|▉| 40272/40960 [01:38<00:01, 423.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  98%|▉| 40272/40960 [01:38<00:01, 423.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40356/40960 [01:38<00:01, 421.37batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40356/40960 [01:38<00:01, 421.37batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40441/40960 [01:39<00:01, 421.84batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40441/40960 [01:39<00:01, 421.84batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40526/40960 [01:39<00:01, 422.60batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40526/40960 [01:39<00:01, 422.60batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40612/40960 [01:39<00:00, 423.75batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40612/40960 [01:39<00:00, 423.75batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40695/40960 [01:39<00:00, 419.81batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training:  99%|▉| 40695/40960 [01:39<00:00, 419.81batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training: 100%|▉| 40779/40960 [01:39<00:00, 418.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training: 100%|▉| 40779/40960 [01:39<00:00, 418.62batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training: 100%|▉| 40859/40960 [01:40<00:00, 411.77batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training: 100%|▉| 40859/40960 [01:40<00:00, 411.77batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training: 100%|▉| 40941/40960 [01:40<00:00, 410.52batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "Training: 100%|▉| 40941/40960 [01:40<00:00, 410.52batches/s, l2_loss: 0.0007 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 14:49:26.012394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:   4%| | 1/26 [01:46<44:22, 106.52s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 14:49:27.771704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 14:49:30.662273: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<11:00:45,  1.03batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<11:00:45,  1.03batches/s, l2_loss: 0.0011 - round_loss:\u001b[A\n",
      "Training:   0%| | 92/40960 [00:01<06:31, 104.40batches/s, l2_loss: 0.0011 - round_loss: \u001b[A\n",
      "Training:   0%| | 92/40960 [00:01<06:31, 104.40batches/s, l2_loss: 0.0018 - round_loss: \u001b[A\n",
      "Training:   0%| | 186/40960 [00:01<03:30, 193.79batches/s, l2_loss: 0.0018 - round_loss:\u001b[A\n",
      "Training:   0%| | 186/40960 [00:01<03:30, 193.79batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   1%| | 278/40960 [00:01<02:35, 262.16batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   1%| | 278/40960 [00:01<02:35, 262.16batches/s, l2_loss: 0.0018 - round_loss:\u001b[A\n",
      "Training:   1%| | 370/40960 [00:01<02:08, 314.92batches/s, l2_loss: 0.0018 - round_loss:\u001b[A\n",
      "Training:   1%| | 370/40960 [00:01<02:08, 314.92batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   1%| | 461/40960 [00:01<01:54, 352.97batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   1%| | 461/40960 [00:01<01:54, 352.97batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   1%| | 552/40960 [00:02<01:46, 381.12batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   1%| | 552/40960 [00:02<01:46, 381.12batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   2%| | 644/40960 [00:02<01:40, 402.79batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   2%| | 644/40960 [00:02<01:40, 402.79batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   2%| | 737/40960 [00:02<01:35, 420.68batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   2%| | 737/40960 [00:02<01:35, 420.68batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   2%| | 828/40960 [00:02<01:33, 429.94batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   2%| | 828/40960 [00:02<01:33, 429.94batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   2%| | 911/40960 [00:02<01:34, 424.21batches/s, l2_loss: 0.0017 - round_loss:\u001b[A\n",
      "Training:   2%| | 911/40960 [00:02<01:34, 424.21batches/s, l2_loss: 0.0016 - round_loss:\u001b[A\n",
      "Training:   2%| | 996/40960 [00:03<01:34, 423.05batches/s, l2_loss: 0.0016 - round_loss:\u001b[A\n",
      "Training:   2%| | 996/40960 [00:03<01:34, 423.05batches/s, l2_loss: 0.0016 - round_loss:\u001b[A\n",
      "Training:   3%| | 1080/40960 [00:03<01:34, 421.96batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1080/40960 [00:03<01:34, 421.96batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1162/40960 [00:03<01:35, 418.37batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1162/40960 [00:03<01:35, 418.37batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1253/40960 [00:03<01:32, 428.26batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1253/40960 [00:03<01:32, 428.26batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1338/40960 [00:03<01:33, 425.90batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1338/40960 [00:03<01:33, 425.90batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1419/40960 [00:04<01:34, 419.49batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   3%| | 1419/40960 [00:04<01:34, 419.49batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   4%| | 1491/40960 [00:04<01:38, 401.62batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:   4%| | 1491/40960 [00:04<01:38, 401.62batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   4%| | 1577/40960 [00:04<01:36, 409.34batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   4%| | 1577/40960 [00:04<01:36, 409.34batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   4%| | 1653/40960 [00:04<01:38, 400.44batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   4%| | 1653/40960 [00:04<01:38, 400.44batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   4%| | 1720/40960 [00:04<01:43, 380.10batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   4%| | 1720/40960 [00:04<01:43, 380.10batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   4%| | 1788/40960 [00:05<01:46, 367.41batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   4%| | 1788/40960 [00:05<01:46, 367.41batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 1850/40960 [00:05<01:51, 349.41batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 1850/40960 [00:05<01:51, 349.41batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 1932/40960 [00:05<01:46, 367.06batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 1932/40960 [00:05<01:46, 367.06batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 2024/40960 [00:05<01:38, 393.96batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 2024/40960 [00:05<01:38, 393.96batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 2116/40960 [00:05<01:34, 412.85batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 2116/40960 [00:06<01:34, 412.85batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 2202/40960 [00:06<01:33, 416.60batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   5%| | 2202/40960 [00:06<01:33, 416.60batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2272/40960 [00:06<01:37, 396.42batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2272/40960 [00:06<01:37, 396.42batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2354/40960 [00:06<01:36, 400.20batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2354/40960 [00:06<01:36, 400.20batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2441/40960 [00:06<01:33, 409.81batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2441/40960 [00:06<01:33, 409.81batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2532/40960 [00:07<01:30, 422.49batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2532/40960 [00:07<01:30, 422.49batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2623/40960 [00:07<01:28, 431.62batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   6%| | 2623/40960 [00:07<01:28, 431.62batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   7%| | 2716/40960 [00:07<01:26, 441.22batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   7%| | 2716/40960 [00:07<01:26, 441.22batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   7%| | 2808/40960 [00:07<01:25, 446.00batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   7%| | 2808/40960 [00:07<01:25, 446.00batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   7%| | 2898/40960 [00:07<01:25, 446.26batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   7%| | 2898/40960 [00:07<01:25, 446.26batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   7%| | 2991/40960 [00:08<01:24, 451.56batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   7%| | 2991/40960 [00:08<01:24, 451.56batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   8%| | 3083/40960 [00:08<01:23, 453.57batches/s, l2_loss: 0.0015 - round_loss\u001b[A\n",
      "Training:   8%| | 3083/40960 [00:08<01:23, 453.57batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   8%| | 3176/40960 [00:08<01:22, 456.35batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   8%| | 3176/40960 [00:08<01:22, 456.35batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   8%| | 3267/40960 [00:08<01:22, 454.16batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   8%| | 3267/40960 [00:08<01:22, 454.16batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   8%| | 3356/40960 [00:08<01:23, 450.68batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   8%| | 3356/40960 [00:08<01:23, 450.68batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   8%| | 3448/40960 [00:09<01:22, 452.89batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   8%| | 3448/40960 [00:09<01:22, 452.89batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3540/40960 [00:09<01:22, 453.93batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3540/40960 [00:09<01:22, 453.93batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3630/40960 [00:09<01:22, 452.60batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3630/40960 [00:09<01:22, 452.60batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3720/40960 [00:09<01:22, 451.00batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3720/40960 [00:09<01:22, 451.00batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3807/40960 [00:09<01:23, 446.11batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3807/40960 [00:09<01:23, 446.11batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3891/40960 [00:10<01:24, 438.03batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:   9%| | 3891/40960 [00:10<01:24, 438.03batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  10%| | 3983/40960 [00:10<01:23, 443.42batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  10%| | 3983/40960 [00:10<01:23, 443.42batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  10%| | 4070/40960 [00:10<01:23, 439.96batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  10%| | 4070/40960 [00:10<01:23, 439.96batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  10%| | 4161/40960 [00:10<01:22, 443.92batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  10%| | 4161/40960 [00:10<01:22, 443.92batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  10%| | 4255/40960 [00:10<01:21, 450.35batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  10%| | 4255/40960 [00:10<01:21, 450.35batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4346/40960 [00:11<01:21, 451.14batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4346/40960 [00:11<01:21, 451.14batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4436/40960 [00:11<01:21, 449.89batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4436/40960 [00:11<01:21, 449.89batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4526/40960 [00:11<01:21, 449.63batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4526/40960 [00:11<01:21, 449.63batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4616/40960 [00:11<01:20, 448.98batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4616/40960 [00:11<01:20, 448.98batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4707/40960 [00:11<01:20, 449.74batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  11%| | 4707/40960 [00:11<01:20, 449.74batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  12%| | 4798/40960 [00:12<01:20, 451.03batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  12%| | 4798/40960 [00:12<01:20, 451.03batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  12%| | 4890/40960 [00:12<01:19, 452.04batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  12%| | 4890/40960 [00:12<01:19, 452.04batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  12%| | 4980/40960 [00:12<01:19, 451.27batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  12%| | 4980/40960 [00:12<01:19, 451.27batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  12%| | 5072/40960 [00:12<01:19, 453.42batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  12%| | 5072/40960 [00:12<01:19, 453.42batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5164/40960 [00:12<01:18, 454.33batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5164/40960 [00:12<01:18, 454.33batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5255/40960 [00:13<01:18, 454.21batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5255/40960 [00:13<01:18, 454.21batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5346/40960 [00:13<01:18, 453.96batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5346/40960 [00:13<01:18, 453.96batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5438/40960 [00:13<01:18, 454.83batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5438/40960 [00:13<01:18, 454.83batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5532/40960 [00:13<01:17, 458.75batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5532/40960 [00:13<01:17, 458.75batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5624/40960 [00:13<01:17, 458.47batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5624/40960 [00:13<01:17, 458.47batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5716/40960 [00:14<01:16, 457.85batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5716/40960 [00:14<01:16, 457.85batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5809/40960 [00:14<01:16, 458.97batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5809/40960 [00:14<01:16, 458.97batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5902/40960 [00:14<01:16, 459.77batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5902/40960 [00:14<01:16, 459.77batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 5996/40960 [00:14<01:15, 461.52batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5996/40960 [00:14<01:15, 461.52batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6087/40960 [00:14<01:16, 458.50batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6087/40960 [00:14<01:16, 458.50batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6176/40960 [00:15<01:16, 453.67batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6176/40960 [00:15<01:16, 453.67batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6266/40960 [00:15<01:16, 452.38batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6266/40960 [00:15<01:16, 452.38batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6353/40960 [00:15<01:17, 446.48batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6353/40960 [00:15<01:17, 446.48batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6446/40960 [00:15<01:16, 450.84batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6446/40960 [00:15<01:16, 450.84batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6539/40960 [00:15<01:15, 453.76batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6539/40960 [00:15<01:15, 453.76batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6630/40960 [00:16<01:15, 454.08batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6630/40960 [00:16<01:15, 454.08batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6720/40960 [00:16<01:15, 451.91batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6720/40960 [00:16<01:15, 451.91batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6810/40960 [00:16<01:15, 450.98batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6810/40960 [00:16<01:15, 450.98batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6903/40960 [00:16<01:14, 454.66batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6903/40960 [00:16<01:14, 454.66batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6996/40960 [00:16<01:14, 456.81batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6996/40960 [00:16<01:14, 456.81batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7086/40960 [00:17<01:14, 454.74batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7086/40960 [00:17<01:14, 454.74batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7147/40960 [00:17<01:22, 408.50batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7147/40960 [00:17<01:22, 408.50batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7228/40960 [00:17<01:23, 406.41batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7228/40960 [00:17<01:23, 406.41batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7288/40960 [00:17<01:29, 374.47batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7288/40960 [00:17<01:29, 374.47batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7345/40960 [00:17<01:36, 346.75batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7345/40960 [00:17<01:36, 346.75batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7406/40960 [00:18<01:40, 334.18batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7406/40960 [00:18<01:40, 334.18batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7497/40960 [00:18<01:30, 369.69batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7497/40960 [00:18<01:30, 369.69batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7568/40960 [00:18<01:31, 364.73batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7568/40960 [00:18<01:31, 364.73batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7644/40960 [00:18<01:30, 368.37batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7644/40960 [00:18<01:30, 368.37batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7735/40960 [00:18<01:24, 393.76batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7735/40960 [00:18<01:24, 393.76batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7823/40960 [00:19<01:21, 406.49batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7823/40960 [00:19<01:21, 406.49batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7909/40960 [00:19<01:20, 412.86batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7909/40960 [00:19<01:20, 412.86batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8001/40960 [00:19<01:17, 426.10batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8001/40960 [00:19<01:17, 426.10batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8093/40960 [00:19<01:15, 435.47batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8093/40960 [00:19<01:15, 435.47batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8180/40960 [00:19<01:15, 435.31batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8180/40960 [00:19<01:15, 435.31batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8257/40960 [00:20<01:17, 419.84batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8257/40960 [00:20<01:17, 419.84batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8339/40960 [00:20<01:18, 416.88batches/s, l2_loss: 0.0016 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8339/40960 [00:20<01:18, 416.88batches/s, l2_loss: 0.0012 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8420/40960 [00:20<01:18, 413.09batches/s, l2_loss: 0.0012 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8420/40960 [00:20<01:18, 413.09batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8503/40960 [00:20<01:18, 413.32batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8503/40960 [00:20<01:18, 413.32batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8583/40960 [00:20<01:19, 408.32batches/s, l2_loss: 0.0014 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8583/40960 [00:20<01:19, 408.32batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8665/40960 [00:21<01:19, 408.73batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8665/40960 [00:21<01:19, 408.73batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8726/40960 [00:21<01:25, 376.47batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8726/40960 [00:21<01:25, 376.47batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8777/40960 [00:21<01:34, 340.12batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8777/40960 [00:21<01:34, 340.12batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8849/40960 [00:21<01:33, 345.06batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8849/40960 [00:21<01:33, 345.06batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8921/40960 [00:21<01:31, 349.02batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8921/40960 [00:21<01:31, 349.02batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8977/40960 [00:22<01:37, 327.93batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8977/40960 [00:22<01:37, 327.93batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9037/40960 [00:22<01:40, 318.62batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9037/40960 [00:22<01:40, 318.62batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9099/40960 [00:22<01:41, 315.20batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9099/40960 [00:22<01:41, 315.20batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9177/40960 [00:22<01:34, 337.25batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9177/40960 [00:22<01:34, 337.25batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9255/40960 [00:22<01:29, 352.98batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9255/40960 [00:22<01:29, 352.98batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9332/40960 [00:23<01:27, 361.00batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9332/40960 [00:23<01:27, 361.00batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9409/40960 [00:23<01:25, 367.28batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9409/40960 [00:23<01:25, 367.28batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9482/40960 [00:23<01:26, 365.50batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|▏| 9482/40960 [00:23<01:26, 365.50batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9553/40960 [00:23<01:26, 361.62batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9553/40960 [00:23<01:26, 361.62batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9637/40960 [00:23<01:22, 377.94batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9637/40960 [00:23<01:22, 377.94batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9716/40960 [00:24<01:21, 381.62batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9716/40960 [00:24<01:21, 381.62batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9796/40960 [00:24<01:20, 386.38batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9796/40960 [00:24<01:20, 386.38batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9872/40960 [00:24<01:20, 384.21batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9872/40960 [00:24<01:20, 384.21batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9948/40960 [00:24<01:21, 382.84batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9948/40960 [00:24<01:21, 382.84batches/s, l2_loss: 0.0013 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10028/40960 [00:24<01:19, 387.59batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  24%|▏| 10028/40960 [00:24<01:19, 387.59batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▏| 10111/40960 [00:25<01:17, 395.73batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▏| 10111/40960 [00:25<01:17, 395.73batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▏| 10188/40960 [00:25<01:18, 391.61batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▏| 10188/40960 [00:25<01:18, 391.61batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▎| 10270/40960 [00:25<01:17, 396.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▎| 10270/40960 [00:25<01:17, 396.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▎| 10346/40960 [00:25<01:18, 391.28batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▎| 10346/40960 [00:25<01:18, 391.28batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▎| 10421/40960 [00:25<01:19, 385.92batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  25%|▎| 10421/40960 [00:25<01:19, 385.92batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10501/40960 [00:26<01:18, 390.09batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10501/40960 [00:26<01:18, 390.09batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10583/40960 [00:26<01:16, 394.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10583/40960 [00:26<01:16, 394.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10656/40960 [00:26<01:18, 385.22batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10656/40960 [00:26<01:18, 385.22batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10737/40960 [00:26<01:17, 390.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10737/40960 [00:26<01:17, 390.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10815/40960 [00:26<01:17, 389.35batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  26%|▎| 10815/40960 [00:26<01:17, 389.35batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 10893/40960 [00:27<01:17, 388.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 10893/40960 [00:27<01:17, 388.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 10966/40960 [00:27<01:18, 381.23batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 10966/40960 [00:27<01:18, 381.23batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 11039/40960 [00:27<01:19, 375.85batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 11039/40960 [00:27<01:19, 375.85batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 11113/40960 [00:27<01:19, 374.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 11113/40960 [00:27<01:19, 374.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 11180/40960 [00:27<01:22, 361.71batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 11180/40960 [00:27<01:22, 361.71batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 11250/40960 [00:28<01:23, 357.36batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  27%|▎| 11250/40960 [00:28<01:23, 357.36batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11325/40960 [00:28<01:21, 362.64batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11325/40960 [00:28<01:21, 362.64batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11407/40960 [00:28<01:18, 375.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11407/40960 [00:28<01:18, 375.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11487/40960 [00:28<01:17, 382.27batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11487/40960 [00:28<01:17, 382.27batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11553/40960 [00:28<01:20, 366.07batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11553/40960 [00:28<01:20, 366.07batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11605/40960 [00:29<01:27, 334.24batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11605/40960 [00:29<01:27, 334.24batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11658/40960 [00:29<01:33, 313.52batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  28%|▎| 11658/40960 [00:29<01:33, 313.52batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 11717/40960 [00:29<01:35, 307.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 11717/40960 [00:29<01:35, 307.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 11798/40960 [00:29<01:26, 336.11batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 11798/40960 [00:29<01:26, 336.11batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 11883/40960 [00:29<01:20, 361.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 11883/40960 [00:29<01:20, 361.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 11967/40960 [00:30<01:16, 377.96batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 11967/40960 [00:30<01:16, 377.96batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 12044/40960 [00:30<01:16, 379.37batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  29%|▎| 12044/40960 [00:30<01:16, 379.37batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12126/40960 [00:30<01:14, 387.65batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12126/40960 [00:30<01:14, 387.65batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12206/40960 [00:30<01:13, 390.78batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12206/40960 [00:30<01:13, 390.78batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12281/40960 [00:30<01:14, 384.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12281/40960 [00:30<01:14, 384.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12363/40960 [00:31<01:13, 391.10batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12363/40960 [00:31<01:13, 391.10batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12442/40960 [00:31<01:12, 391.45batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  30%|▎| 12442/40960 [00:31<01:12, 391.45batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12521/40960 [00:31<01:12, 392.27batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12521/40960 [00:31<01:12, 392.27batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12602/40960 [00:31<01:11, 395.00batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12602/40960 [00:31<01:11, 395.00batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12680/40960 [00:31<01:11, 392.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12680/40960 [00:31<01:11, 392.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12762/40960 [00:32<01:10, 397.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12762/40960 [00:32<01:10, 397.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12845/40960 [00:32<01:09, 402.62batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  31%|▎| 12845/40960 [00:32<01:09, 402.62batches/s, l2_loss: 0.0013 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 12927/40960 [00:32<01:09, 404.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 12927/40960 [00:32<01:09, 404.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 13005/40960 [00:32<01:10, 399.29batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 13005/40960 [00:32<01:10, 399.29batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 13089/40960 [00:32<01:08, 404.18batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 13089/40960 [00:32<01:08, 404.18batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 13169/40960 [00:33<01:08, 402.85batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 13169/40960 [00:33<01:08, 402.85batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 13251/40960 [00:33<01:08, 403.91batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  32%|▎| 13251/40960 [00:33<01:08, 403.91batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13335/40960 [00:33<01:07, 408.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13335/40960 [00:33<01:07, 408.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13418/40960 [00:33<01:07, 410.14batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13418/40960 [00:33<01:07, 410.14batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13493/40960 [00:33<01:08, 398.90batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13493/40960 [00:33<01:08, 398.90batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13575/40960 [00:34<01:08, 400.89batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13575/40960 [00:34<01:08, 400.89batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13651/40960 [00:34<01:09, 394.15batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  33%|▎| 13651/40960 [00:34<01:09, 394.15batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13728/40960 [00:34<01:09, 390.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13728/40960 [00:34<01:09, 390.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13792/40960 [00:34<01:13, 367.90batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13792/40960 [00:34<01:13, 367.90batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13855/40960 [00:34<01:16, 352.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13855/40960 [00:34<01:16, 352.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13930/40960 [00:35<01:15, 358.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13930/40960 [00:35<01:15, 358.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13993/40960 [00:35<01:18, 344.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 13993/40960 [00:35<01:18, 344.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 14047/40960 [00:35<01:23, 321.70batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 14047/40960 [00:35<01:23, 321.70batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 14108/40960 [00:35<01:25, 315.67batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  34%|▎| 14108/40960 [00:35<01:25, 315.67batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14173/40960 [00:35<01:24, 318.24batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14173/40960 [00:35<01:24, 318.24batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14240/40960 [00:36<01:22, 322.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14240/40960 [00:36<01:22, 322.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14317/40960 [00:36<01:18, 339.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14317/40960 [00:36<01:18, 339.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14394/40960 [00:36<01:15, 352.56batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14394/40960 [00:36<01:15, 352.56batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14471/40960 [00:36<01:13, 361.66batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  35%|▎| 14471/40960 [00:36<01:13, 361.66batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14546/40960 [00:36<01:12, 365.35batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14546/40960 [00:36<01:12, 365.35batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14621/40960 [00:37<01:11, 367.32batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14621/40960 [00:37<01:11, 367.32batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14699/40960 [00:37<01:10, 372.90batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14699/40960 [00:37<01:10, 372.90batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14777/40960 [00:37<01:09, 376.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14777/40960 [00:37<01:09, 376.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14858/40960 [00:37<01:07, 384.97batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14858/40960 [00:37<01:07, 384.97batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14941/40960 [00:37<01:06, 393.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  36%|▎| 14941/40960 [00:37<01:06, 393.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15009/40960 [00:38<01:08, 376.69batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15009/40960 [00:38<01:08, 376.69batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15059/40960 [00:38<01:16, 338.00batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15059/40960 [00:38<01:16, 338.00batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15110/40960 [00:38<01:22, 312.20batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15110/40960 [00:38<01:22, 312.20batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15183/40960 [00:38<01:18, 326.95batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15183/40960 [00:38<01:18, 326.95batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15258/40960 [00:38<01:15, 340.15batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15258/40960 [00:38<01:15, 340.15batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15328/40960 [00:39<01:15, 341.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  37%|▎| 15328/40960 [00:39<01:15, 341.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15384/40960 [00:39<01:19, 322.96batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15384/40960 [00:39<01:19, 322.96batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15454/40960 [00:39<01:17, 329.83batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15454/40960 [00:39<01:17, 329.83batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15524/40960 [00:39<01:15, 335.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15524/40960 [00:39<01:15, 335.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15582/40960 [00:39<01:18, 321.63batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15582/40960 [00:40<01:18, 321.63batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15654/40960 [00:40<01:16, 332.79batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15654/40960 [00:40<01:16, 332.79batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15731/40960 [00:40<01:12, 347.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  38%|▍| 15731/40960 [00:40<01:12, 347.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 15798/40960 [00:40<01:13, 342.85batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 15798/40960 [00:40<01:13, 342.85batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 15858/40960 [00:40<01:16, 329.21batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 15858/40960 [00:40<01:16, 329.21batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 15929/40960 [00:41<01:14, 335.32batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 15929/40960 [00:41<01:14, 335.32batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 15985/40960 [00:41<01:18, 317.70batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 15985/40960 [00:41<01:18, 317.70batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 16063/40960 [00:41<01:13, 338.67batches/s, l2_loss: 0.0013 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|▍| 16063/40960 [00:41<01:13, 338.67batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 16132/40960 [00:41<01:13, 340.04batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  39%|▍| 16132/40960 [00:41<01:13, 340.04batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16198/40960 [00:41<01:13, 336.45batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16198/40960 [00:41<01:13, 336.45batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16282/40960 [00:42<01:08, 360.23batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16282/40960 [00:42<01:08, 360.23batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16364/40960 [00:42<01:05, 373.94batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16364/40960 [00:42<01:05, 373.94batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16447/40960 [00:42<01:03, 384.94batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16447/40960 [00:42<01:03, 384.94batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16530/40960 [00:42<01:02, 393.25batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  40%|▍| 16530/40960 [00:42<01:02, 393.25batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16612/40960 [00:42<01:01, 396.89batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16612/40960 [00:42<01:01, 396.89batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16693/40960 [00:43<01:00, 399.20batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16693/40960 [00:43<01:00, 399.20batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16777/40960 [00:43<00:59, 404.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16777/40960 [00:43<00:59, 404.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16861/40960 [00:43<00:59, 408.02batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16861/40960 [00:43<00:59, 408.02batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16943/40960 [00:43<00:58, 407.40batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  41%|▍| 16943/40960 [00:43<00:58, 407.40batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17022/40960 [00:43<00:59, 402.65batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17022/40960 [00:43<00:59, 402.65batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17103/40960 [00:44<00:59, 402.79batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17103/40960 [00:44<00:59, 402.79batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17185/40960 [00:44<00:58, 403.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17185/40960 [00:44<00:58, 403.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17264/40960 [00:44<00:59, 400.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17264/40960 [00:44<00:59, 400.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17345/40960 [00:44<00:58, 401.88batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  42%|▍| 17345/40960 [00:44<00:58, 401.88batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17428/40960 [00:44<00:58, 404.93batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17428/40960 [00:44<00:58, 404.93batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17511/40960 [00:45<00:57, 407.49batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17511/40960 [00:45<00:57, 407.49batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17595/40960 [00:45<00:56, 410.03batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17595/40960 [00:45<00:56, 410.03batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17679/40960 [00:45<00:56, 411.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17679/40960 [00:45<00:56, 411.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17762/40960 [00:45<00:56, 412.42batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  43%|▍| 17762/40960 [00:45<00:56, 412.42batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 17846/40960 [00:45<00:55, 413.46batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 17846/40960 [00:45<00:55, 413.46batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 17927/40960 [00:46<00:56, 410.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 17927/40960 [00:46<00:56, 410.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 18008/40960 [00:46<00:56, 408.68batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 18008/40960 [00:46<00:56, 408.68batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 18091/40960 [00:46<00:55, 409.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 18091/40960 [00:46<00:55, 409.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 18173/40960 [00:46<00:55, 409.61batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  44%|▍| 18173/40960 [00:46<00:55, 409.61batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18255/40960 [00:46<00:55, 408.57batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18255/40960 [00:46<00:55, 408.57batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18338/40960 [00:47<00:55, 409.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18338/40960 [00:47<00:55, 409.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18418/40960 [00:47<00:55, 405.89batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18418/40960 [00:47<00:55, 405.89batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18502/40960 [00:47<00:54, 408.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18502/40960 [00:47<00:54, 408.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18583/40960 [00:47<00:54, 406.92batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  45%|▍| 18583/40960 [00:47<00:54, 406.92batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18664/40960 [00:47<00:54, 406.19batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18664/40960 [00:47<00:54, 406.19batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18748/40960 [00:48<00:54, 408.92batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18748/40960 [00:48<00:54, 408.92batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18830/40960 [00:48<00:54, 407.98batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18830/40960 [00:48<00:54, 407.98batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18909/40960 [00:48<00:54, 402.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18909/40960 [00:48<00:54, 402.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18992/40960 [00:48<00:54, 405.72batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  46%|▍| 18992/40960 [00:48<00:54, 405.72batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19072/40960 [00:48<00:54, 402.60batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19072/40960 [00:48<00:54, 402.60batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19148/40960 [00:49<00:55, 394.97batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19148/40960 [00:49<00:55, 394.97batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19226/40960 [00:49<00:55, 392.89batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19226/40960 [00:49<00:55, 392.89batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19307/40960 [00:49<00:54, 395.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19307/40960 [00:49<00:54, 395.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19386/40960 [00:49<00:54, 394.11batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  47%|▍| 19386/40960 [00:49<00:54, 394.11batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19470/40960 [00:49<00:53, 401.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19470/40960 [00:49<00:53, 401.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19555/40960 [00:50<00:52, 407.62batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19555/40960 [00:50<00:52, 407.62batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19634/40960 [00:50<00:52, 403.57batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19634/40960 [00:50<00:52, 403.57batches/s, l2_loss: 0.0013 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|▍| 19712/40960 [00:50<00:53, 399.34batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19712/40960 [00:50<00:53, 399.34batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19794/40960 [00:50<00:52, 401.75batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  48%|▍| 19794/40960 [00:50<00:52, 401.75batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 19873/40960 [00:50<00:52, 399.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 19873/40960 [00:50<00:52, 399.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 19953/40960 [00:51<00:52, 398.83batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 19953/40960 [00:51<00:52, 398.83batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 20032/40960 [00:51<00:52, 397.46batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 20032/40960 [00:51<00:52, 397.46batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 20114/40960 [00:51<00:52, 400.34batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 20114/40960 [00:51<00:52, 400.34batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 20194/40960 [00:51<00:51, 399.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  49%|▍| 20194/40960 [00:51<00:51, 399.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▍| 20277/40960 [00:51<00:51, 403.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▍| 20277/40960 [00:51<00:51, 403.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▍| 20357/40960 [00:52<00:51, 402.27batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▍| 20357/40960 [00:52<00:51, 402.27batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▍| 20438/40960 [00:52<00:51, 402.28batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▍| 20438/40960 [00:52<00:51, 402.28batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▌| 20517/40960 [00:52<00:51, 400.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▌| 20517/40960 [00:52<00:51, 400.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▌| 20601/40960 [00:52<00:50, 405.76batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▌| 20601/40960 [00:52<00:50, 405.76batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▌| 20684/40960 [00:52<00:49, 407.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  50%|▌| 20684/40960 [00:52<00:49, 407.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 20767/40960 [00:53<00:49, 408.67batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 20767/40960 [00:53<00:49, 408.67batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 20847/40960 [00:53<00:49, 405.03batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 20847/40960 [00:53<00:49, 405.03batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 20929/40960 [00:53<00:49, 406.03batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 20929/40960 [00:53<00:49, 406.03batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 21011/40960 [00:53<00:49, 406.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 21011/40960 [00:53<00:49, 406.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 21093/40960 [00:53<00:48, 407.04batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  51%|▌| 21093/40960 [00:53<00:48, 407.04batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  52%|▌| 21175/40960 [00:54<00:48, 406.83batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  52%|▌| 21175/40960 [00:54<00:48, 406.83batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  52%|▌| 21260/40960 [00:54<00:47, 411.47batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  52%|▌| 21260/40960 [00:54<00:47, 411.47batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  52%|▌| 21341/40960 [00:54<00:48, 408.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  52%|▌| 21341/40960 [00:54<00:48, 408.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  52%|▌| 21426/40960 [00:54<00:47, 412.54batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  52%|▌| 21426/40960 [00:54<00:47, 412.54batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21510/40960 [00:54<00:47, 413.57batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21510/40960 [00:54<00:47, 413.57batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21593/40960 [00:55<00:46, 413.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21593/40960 [00:55<00:46, 413.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21677/40960 [00:55<00:46, 414.19batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21677/40960 [00:55<00:46, 414.19batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21758/40960 [00:55<00:46, 410.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21758/40960 [00:55<00:46, 410.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21841/40960 [00:55<00:46, 410.13batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  53%|▌| 21841/40960 [00:55<00:46, 410.13batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 21925/40960 [00:55<00:46, 412.35batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 21925/40960 [00:55<00:46, 412.35batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 22009/40960 [00:56<00:45, 413.47batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 22009/40960 [00:56<00:45, 413.47batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 22092/40960 [00:56<00:45, 413.49batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 22092/40960 [00:56<00:45, 413.49batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 22175/40960 [00:56<00:45, 413.40batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 22175/40960 [00:56<00:45, 413.40batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 22258/40960 [00:56<00:45, 413.66batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  54%|▌| 22258/40960 [00:56<00:45, 413.66batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22342/40960 [00:56<00:44, 414.94batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22342/40960 [00:56<00:44, 414.94batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22426/40960 [00:57<00:44, 415.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22426/40960 [00:57<00:44, 415.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22510/40960 [00:57<00:44, 416.28batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22510/40960 [00:57<00:44, 416.28batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22593/40960 [00:57<00:44, 415.24batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22593/40960 [00:57<00:44, 415.24batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22675/40960 [00:57<00:44, 413.13batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  55%|▌| 22675/40960 [00:57<00:44, 413.13batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 22759/40960 [00:57<00:43, 415.02batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 22759/40960 [00:57<00:43, 415.02batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 22840/40960 [00:58<00:44, 410.60batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 22840/40960 [00:58<00:44, 410.60batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 22923/40960 [00:58<00:43, 411.49batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 22923/40960 [00:58<00:43, 411.49batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 23003/40960 [00:58<00:44, 406.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 23003/40960 [00:58<00:44, 406.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 23083/40960 [00:58<00:44, 403.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  56%|▌| 23083/40960 [00:58<00:44, 403.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23164/40960 [00:58<00:44, 403.36batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23164/40960 [00:58<00:44, 403.36batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23247/40960 [00:59<00:43, 405.69batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23247/40960 [00:59<00:43, 405.69batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23326/40960 [00:59<00:43, 401.30batches/s, l2_loss: 0.0013 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|▌| 23326/40960 [00:59<00:43, 401.30batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23409/40960 [00:59<00:43, 404.73batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23409/40960 [00:59<00:43, 404.73batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23491/40960 [00:59<00:43, 405.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  57%|▌| 23491/40960 [00:59<00:43, 405.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23573/40960 [00:59<00:42, 405.42batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23573/40960 [00:59<00:42, 405.42batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23653/40960 [01:00<00:42, 402.80batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23653/40960 [01:00<00:42, 402.80batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23736/40960 [01:00<00:42, 405.44batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23736/40960 [01:00<00:42, 405.44batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23818/40960 [01:00<00:42, 405.46batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23818/40960 [01:00<00:42, 405.46batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23897/40960 [01:00<00:42, 401.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  58%|▌| 23897/40960 [01:00<00:42, 401.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 23979/40960 [01:00<00:42, 402.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 23979/40960 [01:00<00:42, 402.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 24062/40960 [01:01<00:41, 406.29batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 24062/40960 [01:01<00:41, 406.29batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 24144/40960 [01:01<00:41, 406.20batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 24144/40960 [01:01<00:41, 406.20batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 24223/40960 [01:01<00:41, 402.15batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 24223/40960 [01:01<00:41, 402.15batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 24306/40960 [01:01<00:41, 405.44batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  59%|▌| 24306/40960 [01:01<00:41, 405.44batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24389/40960 [01:01<00:40, 406.97batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24389/40960 [01:01<00:40, 406.97batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24473/40960 [01:02<00:40, 410.16batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24473/40960 [01:02<00:40, 410.16batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24554/40960 [01:02<00:40, 408.38batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24554/40960 [01:02<00:40, 408.38batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24634/40960 [01:02<00:40, 405.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24634/40960 [01:02<00:40, 405.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24718/40960 [01:02<00:39, 408.65batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  60%|▌| 24718/40960 [01:02<00:39, 408.65batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 24802/40960 [01:02<00:39, 411.36batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 24802/40960 [01:02<00:39, 411.36batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 24886/40960 [01:03<00:38, 412.52batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 24886/40960 [01:03<00:38, 412.52batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 24970/40960 [01:03<00:38, 414.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 24970/40960 [01:03<00:38, 414.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 25053/40960 [01:03<00:38, 413.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 25053/40960 [01:03<00:38, 413.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 25131/40960 [01:03<00:38, 406.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  61%|▌| 25131/40960 [01:03<00:38, 406.55batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25211/40960 [01:03<00:38, 404.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25211/40960 [01:03<00:38, 404.53batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25291/40960 [01:04<00:38, 402.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25291/40960 [01:04<00:38, 402.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25374/40960 [01:04<00:38, 405.36batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25374/40960 [01:04<00:38, 405.36batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25455/40960 [01:04<00:38, 403.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25455/40960 [01:04<00:38, 403.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25537/40960 [01:04<00:38, 404.33batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  62%|▌| 25537/40960 [01:04<00:38, 404.33batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25621/40960 [01:04<00:37, 407.80batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25621/40960 [01:04<00:37, 407.80batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25705/40960 [01:05<00:37, 410.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25705/40960 [01:05<00:37, 410.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25790/40960 [01:05<00:36, 413.83batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25790/40960 [01:05<00:36, 413.83batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25870/40960 [01:05<00:36, 409.54batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25870/40960 [01:05<00:36, 409.54batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25953/40960 [01:05<00:36, 410.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  63%|▋| 25953/40960 [01:05<00:36, 410.81batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26037/40960 [01:05<00:36, 412.47batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26037/40960 [01:05<00:36, 412.47batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26120/40960 [01:06<00:36, 411.93batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26120/40960 [01:06<00:36, 411.93batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26202/40960 [01:06<00:35, 410.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26202/40960 [01:06<00:35, 410.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26283/40960 [01:06<00:35, 409.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26283/40960 [01:06<00:35, 409.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26364/40960 [01:06<00:35, 407.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  64%|▋| 26364/40960 [01:06<00:35, 407.82batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26446/40960 [01:06<00:35, 408.24batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26446/40960 [01:06<00:35, 408.24batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26528/40960 [01:07<00:35, 407.43batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26528/40960 [01:07<00:35, 407.43batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26610/40960 [01:07<00:35, 407.95batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26610/40960 [01:07<00:35, 407.95batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26693/40960 [01:07<00:34, 409.49batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26693/40960 [01:07<00:34, 409.49batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26776/40960 [01:07<00:34, 410.37batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  65%|▋| 26776/40960 [01:07<00:34, 410.37batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 26857/40960 [01:07<00:34, 408.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 26857/40960 [01:07<00:34, 408.48batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 26938/40960 [01:08<00:34, 406.64batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 26938/40960 [01:08<00:34, 406.64batches/s, l2_loss: 0.0013 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|▋| 27019/40960 [01:08<00:34, 405.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 27019/40960 [01:08<00:34, 405.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 27095/40960 [01:08<00:34, 397.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 27095/40960 [01:08<00:34, 397.31batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 27179/40960 [01:08<00:34, 403.39batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  66%|▋| 27179/40960 [01:08<00:34, 403.39batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27262/40960 [01:08<00:33, 406.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27262/40960 [01:08<00:33, 406.01batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27346/40960 [01:09<00:33, 410.03batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27346/40960 [01:09<00:33, 410.03batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27429/40960 [01:09<00:32, 411.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27429/40960 [01:09<00:32, 411.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27512/40960 [01:09<00:32, 411.26batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27512/40960 [01:09<00:32, 411.26batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27597/40960 [01:09<00:32, 414.17batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  67%|▋| 27597/40960 [01:09<00:32, 414.17batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 27682/40960 [01:09<00:31, 417.23batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 27682/40960 [01:09<00:31, 417.23batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 27763/40960 [01:10<00:31, 413.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 27763/40960 [01:10<00:31, 413.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 27845/40960 [01:10<00:31, 412.34batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 27845/40960 [01:10<00:31, 412.34batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 27927/40960 [01:10<00:31, 410.71batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 27927/40960 [01:10<00:31, 410.71batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 28010/40960 [01:10<00:31, 411.16batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  68%|▋| 28010/40960 [01:10<00:31, 411.16batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28094/40960 [01:10<00:31, 412.58batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28094/40960 [01:11<00:31, 412.58batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28179/40960 [01:11<00:30, 415.22batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28179/40960 [01:11<00:30, 415.22batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28261/40960 [01:11<00:30, 412.54batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28261/40960 [01:11<00:30, 412.54batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28345/40960 [01:11<00:30, 414.12batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28345/40960 [01:11<00:30, 414.12batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28427/40960 [01:11<00:30, 412.71batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  69%|▋| 28427/40960 [01:11<00:30, 412.71batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28504/40960 [01:12<00:30, 403.60batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28504/40960 [01:12<00:30, 403.60batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28584/40960 [01:12<00:30, 401.60batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28584/40960 [01:12<00:30, 401.60batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28665/40960 [01:12<00:30, 402.29batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28665/40960 [01:12<00:30, 402.29batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28746/40960 [01:12<00:30, 402.93batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28746/40960 [01:12<00:30, 402.93batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28827/40960 [01:12<00:30, 402.67batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  70%|▋| 28827/40960 [01:12<00:30, 402.67batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 28911/40960 [01:13<00:29, 407.37batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 28911/40960 [01:13<00:29, 407.37batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 28993/40960 [01:13<00:29, 407.25batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 28993/40960 [01:13<00:29, 407.25batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 29076/40960 [01:13<00:29, 409.22batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 29076/40960 [01:13<00:29, 409.22batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 29158/40960 [01:13<00:28, 408.93batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 29158/40960 [01:13<00:28, 408.93batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 29240/40960 [01:13<00:28, 409.15batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  71%|▋| 29240/40960 [01:13<00:28, 409.15batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29320/40960 [01:14<00:28, 406.11batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29320/40960 [01:14<00:28, 406.11batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29398/40960 [01:14<00:28, 399.95batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29398/40960 [01:14<00:28, 399.95batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29480/40960 [01:14<00:28, 401.78batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29480/40960 [01:14<00:28, 401.78batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29560/40960 [01:14<00:28, 401.20batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29560/40960 [01:14<00:28, 401.20batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29640/40960 [01:14<00:28, 399.95batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  72%|▋| 29640/40960 [01:14<00:28, 399.95batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 29718/40960 [01:15<00:28, 396.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 29718/40960 [01:15<00:28, 396.87batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 29800/40960 [01:15<00:27, 400.40batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 29800/40960 [01:15<00:27, 400.40batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 29884/40960 [01:15<00:27, 406.23batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 29884/40960 [01:15<00:27, 406.23batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 29965/40960 [01:15<00:27, 405.69batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 29965/40960 [01:15<00:27, 405.69batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 30049/40960 [01:15<00:26, 409.11batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  73%|▋| 30049/40960 [01:15<00:26, 409.11batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30132/40960 [01:16<00:26, 409.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30132/40960 [01:16<00:26, 409.77batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30214/40960 [01:16<00:26, 408.66batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30214/40960 [01:16<00:26, 408.66batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30297/40960 [01:16<00:26, 409.71batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30297/40960 [01:16<00:26, 409.71batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30380/40960 [01:16<00:25, 410.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30380/40960 [01:16<00:25, 410.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30464/40960 [01:16<00:25, 412.64batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  74%|▋| 30464/40960 [01:16<00:25, 412.64batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▋| 30547/40960 [01:17<00:25, 412.37batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▋| 30547/40960 [01:17<00:25, 412.37batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▋| 30628/40960 [01:17<00:25, 409.92batches/s, l2_loss: 0.0013 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▋| 30628/40960 [01:17<00:25, 409.92batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▋| 30710/40960 [01:17<00:25, 409.17batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▋| 30710/40960 [01:17<00:25, 409.17batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▊| 30793/40960 [01:17<00:24, 410.51batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▊| 30793/40960 [01:17<00:24, 410.51batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▊| 30875/40960 [01:17<00:24, 410.22batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  75%|▊| 30875/40960 [01:17<00:24, 410.22batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 30956/40960 [01:18<00:24, 408.57batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 30956/40960 [01:18<00:24, 408.57batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 31038/40960 [01:18<00:24, 408.88batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 31038/40960 [01:18<00:24, 408.88batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 31121/40960 [01:18<00:23, 410.30batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 31121/40960 [01:18<00:23, 410.30batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 31201/40960 [01:18<00:23, 407.14batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 31201/40960 [01:18<00:23, 407.14batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 31281/40960 [01:18<00:23, 403.75batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  76%|▊| 31281/40960 [01:18<00:23, 403.75batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31362/40960 [01:19<00:23, 403.04batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31362/40960 [01:19<00:23, 403.04batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31441/40960 [01:19<00:23, 399.46batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31441/40960 [01:19<00:23, 399.46batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31524/40960 [01:19<00:23, 404.07batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31524/40960 [01:19<00:23, 404.07batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31608/40960 [01:19<00:22, 408.75batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31608/40960 [01:19<00:22, 408.75batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31688/40960 [01:19<00:22, 405.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  77%|▊| 31688/40960 [01:19<00:22, 405.41batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 31771/40960 [01:20<00:22, 407.86batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 31771/40960 [01:20<00:22, 407.86batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 31851/40960 [01:20<00:22, 404.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 31851/40960 [01:20<00:22, 404.50batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 31934/40960 [01:20<00:22, 406.75batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 31934/40960 [01:20<00:22, 406.75batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 32015/40960 [01:20<00:22, 406.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 32015/40960 [01:20<00:22, 406.06batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 32099/40960 [01:20<00:21, 409.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  78%|▊| 32099/40960 [01:20<00:21, 409.84batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  79%|▊| 32180/40960 [01:21<00:21, 408.32batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  79%|▊| 32180/40960 [01:21<00:21, 408.32batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  79%|▊| 32264/40960 [01:21<00:21, 410.39batches/s, l2_loss: 0.0013 - round_los\u001b[A\n",
      "Training:  79%|▊| 32264/40960 [01:21<00:21, 410.39batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  79%|▊| 32345/40960 [01:21<00:21, 408.48batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  79%|▊| 32345/40960 [01:21<00:21, 408.48batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  79%|▊| 32427/40960 [01:21<00:20, 407.96batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  79%|▊| 32427/40960 [01:21<00:20, 407.96batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  79%|▊| 32504/40960 [01:21<00:21, 399.81batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  79%|▊| 32504/40960 [01:21<00:21, 399.81batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32584/40960 [01:22<00:20, 399.25batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32584/40960 [01:22<00:20, 399.25batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32657/40960 [01:22<00:21, 388.52batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32657/40960 [01:22<00:21, 388.52batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32707/40960 [01:22<00:23, 346.76batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32707/40960 [01:22<00:23, 346.76batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32773/40960 [01:22<00:24, 341.01batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32773/40960 [01:22<00:24, 341.01batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32840/40960 [01:22<00:24, 337.25batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32840/40960 [01:22<00:24, 337.25batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32899/40960 [01:23<00:24, 324.52batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  80%|▊| 32899/40960 [01:23<00:24, 324.52batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 32978/40960 [01:23<00:23, 345.39batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 32978/40960 [01:23<00:23, 345.39batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33031/40960 [01:23<00:24, 320.30batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33031/40960 [01:23<00:24, 320.30batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33110/40960 [01:23<00:22, 342.52batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33110/40960 [01:23<00:22, 342.52batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33173/40960 [01:23<00:23, 333.96batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33173/40960 [01:23<00:23, 333.96batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33225/40960 [01:24<00:24, 311.63batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33225/40960 [01:24<00:24, 311.63batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33307/40960 [01:24<00:22, 340.04batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  81%|▊| 33307/40960 [01:24<00:22, 340.04batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33391/40960 [01:24<00:20, 362.92batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33391/40960 [01:24<00:20, 362.92batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33474/40960 [01:24<00:19, 377.27batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33474/40960 [01:24<00:19, 377.27batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33553/40960 [01:24<00:19, 382.13batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33553/40960 [01:24<00:19, 382.13batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33633/40960 [01:25<00:18, 387.26batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33633/40960 [01:25<00:18, 387.26batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33713/40960 [01:25<00:18, 390.85batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33713/40960 [01:25<00:18, 390.85batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33789/40960 [01:25<00:18, 386.49batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  82%|▊| 33789/40960 [01:25<00:18, 386.49batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 33865/40960 [01:25<00:18, 384.40batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 33865/40960 [01:25<00:18, 384.40batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 33945/40960 [01:25<00:18, 388.58batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 33945/40960 [01:25<00:18, 388.58batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 34021/40960 [01:26<00:18, 384.76batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 34021/40960 [01:26<00:18, 384.76batches/s, l2_loss: 0.0014 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 34097/40960 [01:26<00:17, 382.94batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 34097/40960 [01:26<00:17, 382.94batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 34173/40960 [01:26<00:17, 381.81batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  83%|▊| 34173/40960 [01:26<00:17, 381.81batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34227/40960 [01:26<00:19, 347.36batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34227/40960 [01:26<00:19, 347.36batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34299/40960 [01:26<00:18, 351.04batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34299/40960 [01:26<00:18, 351.04batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34362/40960 [01:27<00:19, 339.45batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34362/40960 [01:27<00:19, 339.45batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34422/40960 [01:27<00:19, 327.57batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34422/40960 [01:27<00:19, 327.57batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34496/40960 [01:27<00:19, 340.19batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34496/40960 [01:27<00:19, 340.19batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34555/40960 [01:27<00:19, 325.77batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  84%|▊| 34555/40960 [01:27<00:19, 325.77batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34626/40960 [01:27<00:19, 333.29batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34626/40960 [01:27<00:19, 333.29batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34692/40960 [01:28<00:18, 331.96batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34692/40960 [01:28<00:18, 331.96batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34771/40960 [01:28<00:17, 350.31batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34771/40960 [01:28<00:17, 350.31batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34836/40960 [01:28<00:17, 341.80batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34836/40960 [01:28<00:17, 341.80batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34918/40960 [01:28<00:16, 361.88batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34918/40960 [01:28<00:16, 361.88batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34997/40960 [01:28<00:16, 370.58batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  85%|▊| 34997/40960 [01:28<00:16, 370.58batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35073/40960 [01:29<00:15, 373.34batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35073/40960 [01:29<00:15, 373.34batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35152/40960 [01:29<00:15, 379.50batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35152/40960 [01:29<00:15, 379.50batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35234/40960 [01:29<00:14, 387.56batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35234/40960 [01:29<00:14, 387.56batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35309/40960 [01:29<00:14, 382.81batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35309/40960 [01:29<00:14, 382.81batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35384/40960 [01:29<00:14, 380.02batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  86%|▊| 35384/40960 [01:29<00:14, 380.02batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35463/40960 [01:30<00:14, 384.11batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35463/40960 [01:30<00:14, 384.11batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35540/40960 [01:30<00:14, 383.32batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35540/40960 [01:30<00:14, 383.32batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35618/40960 [01:30<00:13, 385.03batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35618/40960 [01:30<00:13, 385.03batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35702/40960 [01:30<00:13, 394.63batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35702/40960 [01:30<00:13, 394.63batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35784/40960 [01:30<00:13, 397.95batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  87%|▊| 35784/40960 [01:30<00:13, 397.95batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 35867/40960 [01:31<00:12, 402.05batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 35867/40960 [01:31<00:12, 402.05batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 35950/40960 [01:31<00:12, 404.77batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 35950/40960 [01:31<00:12, 404.77batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 36034/40960 [01:31<00:12, 408.56batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 36034/40960 [01:31<00:12, 408.56batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 36085/40960 [01:31<00:13, 361.50batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 36085/40960 [01:31<00:13, 361.50batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 36160/40960 [01:31<00:13, 364.92batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 36160/40960 [01:31<00:13, 364.92batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 36241/40960 [01:32<00:12, 375.82batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  88%|▉| 36241/40960 [01:32<00:12, 375.82batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36318/40960 [01:32<00:12, 377.51batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36318/40960 [01:32<00:12, 377.51batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36375/40960 [01:32<00:13, 348.56batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36375/40960 [01:32<00:13, 348.56batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36446/40960 [01:32<00:12, 350.34batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36446/40960 [01:32<00:12, 350.34batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36504/40960 [01:32<00:13, 331.25batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36504/40960 [01:32<00:13, 331.25batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36578/40960 [01:33<00:12, 342.00batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36578/40960 [01:33<00:12, 342.00batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36631/40960 [01:33<00:13, 318.87batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  89%|▉| 36631/40960 [01:33<00:13, 318.87batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36705/40960 [01:33<00:12, 332.72batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36705/40960 [01:33<00:12, 332.72batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36760/40960 [01:33<00:13, 315.01batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36760/40960 [01:33<00:13, 315.01batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36841/40960 [01:33<00:12, 341.45batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36841/40960 [01:33<00:12, 341.45batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36897/40960 [01:34<00:12, 322.88batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36897/40960 [01:34<00:12, 322.88batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36963/40960 [01:34<00:12, 323.85batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 36963/40960 [01:34<00:12, 323.85batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 37034/40960 [01:34<00:11, 332.93batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  90%|▉| 37034/40960 [01:34<00:11, 332.93batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37110/40960 [01:34<00:11, 346.99batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37110/40960 [01:34<00:11, 346.99batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37187/40960 [01:34<00:10, 358.19batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37187/40960 [01:34<00:10, 358.19batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37266/40960 [01:35<00:10, 368.73batches/s, l2_loss: 0.0014 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|▉| 37266/40960 [01:35<00:10, 368.73batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37347/40960 [01:35<00:09, 379.56batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37347/40960 [01:35<00:09, 379.56batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37426/40960 [01:35<00:09, 383.99batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  91%|▉| 37426/40960 [01:35<00:09, 383.99batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37508/40960 [01:35<00:08, 391.25batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37508/40960 [01:35<00:08, 391.25batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37583/40960 [01:35<00:08, 386.05batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37583/40960 [01:35<00:08, 386.05batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37658/40960 [01:36<00:08, 381.92batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37658/40960 [01:36<00:08, 381.92batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37733/40960 [01:36<00:08, 379.12batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37733/40960 [01:36<00:08, 379.12batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37814/40960 [01:36<00:08, 385.53batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  92%|▉| 37814/40960 [01:36<00:08, 385.53batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 37891/40960 [01:36<00:07, 384.22batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 37891/40960 [01:36<00:07, 384.22batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 37970/40960 [01:36<00:07, 386.64batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 37970/40960 [01:36<00:07, 386.64batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38049/40960 [01:37<00:07, 389.05batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38049/40960 [01:37<00:07, 389.05batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38112/40960 [01:37<00:07, 366.00batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38112/40960 [01:37<00:07, 366.00batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38165/40960 [01:37<00:08, 335.06batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38165/40960 [01:37<00:08, 335.06batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38220/40960 [01:37<00:08, 315.50batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38220/40960 [01:37<00:08, 315.50batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38275/40960 [01:37<00:08, 303.09batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  93%|▉| 38275/40960 [01:37<00:08, 303.09batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38339/40960 [01:38<00:08, 307.99batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38339/40960 [01:38<00:08, 307.99batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [01:38<00:07, 342.12batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [01:38<00:07, 342.12batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38501/40960 [01:38<00:06, 354.85batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38501/40960 [01:38<00:06, 354.85batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38578/40960 [01:38<00:06, 362.83batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38578/40960 [01:38<00:06, 362.83batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38662/40960 [01:38<00:06, 378.83batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  94%|▉| 38662/40960 [01:38<00:06, 378.83batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  95%|▉| 38743/40960 [01:39<00:05, 384.98batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  95%|▉| 38743/40960 [01:39<00:05, 384.98batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  95%|▉| 38814/40960 [01:39<00:05, 374.81batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  95%|▉| 38814/40960 [01:39<00:05, 374.81batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  95%|▉| 38885/40960 [01:39<00:05, 368.23batches/s, l2_loss: 0.0014 - round_los\u001b[A\n",
      "Training:  95%|▉| 38885/40960 [01:39<00:05, 368.23batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  95%|▉| 38948/40960 [01:39<00:05, 350.82batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  95%|▉| 38948/40960 [01:39<00:05, 350.82batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  95%|▉| 39007/40960 [01:39<00:05, 333.78batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  95%|▉| 39007/40960 [01:39<00:05, 333.78batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  95%|▉| 39070/40960 [01:40<00:05, 327.00batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  95%|▉| 39070/40960 [01:40<00:05, 327.00batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39139/40960 [01:40<00:05, 331.71batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39139/40960 [01:40<00:05, 331.71batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39200/40960 [01:40<00:05, 322.87batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39200/40960 [01:40<00:05, 322.87batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39258/40960 [01:40<00:05, 312.30batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39258/40960 [01:40<00:05, 312.30batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39316/40960 [01:40<00:05, 305.01batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39316/40960 [01:40<00:05, 305.01batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39388/40960 [01:41<00:04, 320.22batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39388/40960 [01:41<00:04, 320.22batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39463/40960 [01:41<00:04, 335.49batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  96%|▉| 39463/40960 [01:41<00:04, 335.49batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39538/40960 [01:41<00:04, 346.80batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39538/40960 [01:41<00:04, 346.80batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39619/40960 [01:41<00:03, 363.94batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39619/40960 [01:41<00:03, 363.94batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39699/40960 [01:41<00:03, 374.70batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39699/40960 [01:41<00:03, 374.70batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39781/40960 [01:42<00:03, 384.23batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39781/40960 [01:42<00:03, 384.23batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39859/40960 [01:42<00:02, 384.37batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  97%|▉| 39859/40960 [01:42<00:02, 384.37batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 39939/40960 [01:42<00:02, 387.79batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 39939/40960 [01:42<00:02, 387.79batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40020/40960 [01:42<00:02, 391.60batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40020/40960 [01:42<00:02, 391.60batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40100/40960 [01:42<00:02, 393.37batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40100/40960 [01:42<00:02, 393.37batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40178/40960 [01:43<00:01, 391.98batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40178/40960 [01:43<00:01, 391.98batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40259/40960 [01:43<00:01, 395.65batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40259/40960 [01:43<00:01, 395.65batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40338/40960 [01:43<00:01, 395.01batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  98%|▉| 40338/40960 [01:43<00:01, 395.01batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40421/40960 [01:43<00:01, 400.96batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40421/40960 [01:43<00:01, 400.96batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40506/40960 [01:43<00:01, 406.90batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40506/40960 [01:44<00:01, 406.90batches/s, l2_loss: 0.0015 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|▉| 40585/40960 [01:44<00:00, 402.15batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40585/40960 [01:44<00:00, 402.15batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40665/40960 [01:44<00:00, 400.29batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40665/40960 [01:44<00:00, 400.29batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40743/40960 [01:44<00:00, 395.75batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training:  99%|▉| 40743/40960 [01:44<00:00, 395.75batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training: 100%|▉| 40821/40960 [01:44<00:00, 393.81batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training: 100%|▉| 40821/40960 [01:44<00:00, 393.81batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training: 100%|▉| 40904/40960 [01:45<00:00, 399.55batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "Training: 100%|▉| 40904/40960 [01:45<00:00, 399.55batches/s, l2_loss: 0.0015 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 14:51:15.214161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:   8%| | 2/26 [03:35<43:08, 107.86s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 14:51:16.559535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A\n",
      "Training:   0%|                               | 1/40960 [00:00<10:18:15,  1.10batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:18:15,  1.10batches/s, l2_loss: 0.0183 - round_loss:\u001b[A2025-06-09 14:51:19.391642: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%| | 92/40960 [00:01<06:12, 109.83batches/s, l2_loss: 0.0183 - round_loss: \u001b[A\n",
      "Training:   0%| | 92/40960 [00:01<06:12, 109.83batches/s, l2_loss: 0.0257 - round_loss: \u001b[A\n",
      "Training:   0%| | 184/40960 [00:01<03:24, 198.93batches/s, l2_loss: 0.0257 - round_loss:\u001b[A\n",
      "Training:   0%| | 184/40960 [00:01<03:24, 198.93batches/s, l2_loss: 0.0208 - round_loss:\u001b[A\n",
      "Training:   1%| | 274/40960 [00:01<02:33, 265.40batches/s, l2_loss: 0.0208 - round_loss:\u001b[A\n",
      "Training:   1%| | 274/40960 [00:01<02:33, 265.40batches/s, l2_loss: 0.0206 - round_loss:\u001b[A\n",
      "Training:   1%| | 364/40960 [00:01<02:08, 316.13batches/s, l2_loss: 0.0206 - round_loss:\u001b[A\n",
      "Training:   1%| | 364/40960 [00:01<02:08, 316.13batches/s, l2_loss: 0.0217 - round_loss:\u001b[A\n",
      "Training:   1%| | 458/40960 [00:01<01:52, 358.91batches/s, l2_loss: 0.0217 - round_loss:\u001b[A\n",
      "Training:   1%| | 458/40960 [00:01<01:52, 358.91batches/s, l2_loss: 0.0193 - round_loss:\u001b[A\n",
      "Training:   1%| | 552/40960 [00:02<01:43, 389.97batches/s, l2_loss: 0.0193 - round_loss:\u001b[A\n",
      "Training:   1%| | 552/40960 [00:02<01:43, 389.97batches/s, l2_loss: 0.0201 - round_loss:\u001b[A\n",
      "Training:   2%| | 646/40960 [00:02<01:37, 412.81batches/s, l2_loss: 0.0201 - round_loss:\u001b[A\n",
      "Training:   2%| | 646/40960 [00:02<01:37, 412.81batches/s, l2_loss: 0.0205 - round_loss:\u001b[A\n",
      "Training:   2%| | 737/40960 [00:02<01:34, 424.65batches/s, l2_loss: 0.0205 - round_loss:\u001b[A\n",
      "Training:   2%| | 737/40960 [00:02<01:34, 424.65batches/s, l2_loss: 0.0203 - round_loss:\u001b[A\n",
      "Training:   2%| | 828/40960 [00:02<01:32, 432.90batches/s, l2_loss: 0.0203 - round_loss:\u001b[A\n",
      "Training:   2%| | 828/40960 [00:02<01:32, 432.90batches/s, l2_loss: 0.0201 - round_loss:\u001b[A\n",
      "Training:   2%| | 922/40960 [00:02<01:30, 443.42batches/s, l2_loss: 0.0201 - round_loss:\u001b[A\n",
      "Training:   2%| | 922/40960 [00:02<01:30, 443.42batches/s, l2_loss: 0.0204 - round_loss:\u001b[A\n",
      "Training:   2%| | 1014/40960 [00:03<01:29, 447.44batches/s, l2_loss: 0.0204 - round_loss\u001b[A\n",
      "Training:   2%| | 1014/40960 [00:03<01:29, 447.44batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   3%| | 1108/40960 [00:03<01:27, 453.26batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   3%| | 1108/40960 [00:03<01:27, 453.26batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:   3%| | 1202/40960 [00:03<01:26, 457.21batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:   3%| | 1202/40960 [00:03<01:26, 457.21batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   3%| | 1297/40960 [00:03<01:25, 461.23batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   3%| | 1297/40960 [00:03<01:25, 461.23batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   3%| | 1386/40960 [00:03<01:26, 455.90batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   3%| | 1386/40960 [00:03<01:26, 455.90batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   4%| | 1478/40960 [00:04<01:26, 456.81batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   4%| | 1478/40960 [00:04<01:26, 456.81batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   4%| | 1569/40960 [00:04<01:26, 455.46batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   4%| | 1569/40960 [00:04<01:26, 455.46batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:   4%| | 1660/40960 [00:04<01:26, 454.63batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:   4%| | 1660/40960 [00:04<01:26, 454.63batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:   4%| | 1750/40960 [00:04<01:26, 452.98batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:   4%| | 1750/40960 [00:04<01:26, 452.98batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:   4%| | 1840/40960 [00:04<01:26, 451.20batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:   4%| | 1840/40960 [00:04<01:26, 451.20batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   5%| | 1933/40960 [00:05<01:25, 454.78batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   5%| | 1933/40960 [00:05<01:25, 454.78batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:   5%| | 2025/40960 [00:05<01:25, 455.77batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:   5%| | 2025/40960 [00:05<01:25, 455.77batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:   5%| | 2121/40960 [00:05<01:24, 461.87batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:   5%| | 2121/40960 [00:05<01:24, 461.87batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:   5%| | 2214/40960 [00:05<01:23, 461.46batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:   5%| | 2214/40960 [00:05<01:23, 461.46batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:   6%| | 2306/40960 [00:05<01:24, 459.92batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:   6%| | 2306/40960 [00:05<01:24, 459.92batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:   6%| | 2399/40960 [00:06<01:23, 461.34batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:   6%| | 2399/40960 [00:06<01:23, 461.34batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:   6%| | 2492/40960 [00:06<01:23, 461.43batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:   6%| | 2492/40960 [00:06<01:23, 461.43batches/s, l2_loss: 0.0193 - round_loss\u001b[A\n",
      "Training:   6%| | 2581/40960 [00:06<01:24, 455.17batches/s, l2_loss: 0.0193 - round_loss\u001b[A\n",
      "Training:   6%| | 2581/40960 [00:06<01:24, 455.17batches/s, l2_loss: 0.0193 - round_loss\u001b[A\n",
      "Training:   7%| | 2673/40960 [00:06<01:23, 456.16batches/s, l2_loss: 0.0193 - round_loss\u001b[A\n",
      "Training:   7%| | 2673/40960 [00:06<01:23, 456.16batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:   7%| | 2764/40960 [00:06<01:24, 454.69batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:   7%| | 2764/40960 [00:06<01:24, 454.69batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:   7%| | 2857/40960 [00:07<01:23, 456.35batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:   7%| | 2857/40960 [00:07<01:23, 456.35batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   7%| | 2949/40960 [00:07<01:23, 456.88batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   7%| | 2949/40960 [00:07<01:23, 456.88batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 3041/40960 [00:07<01:22, 457.74batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n",
      "Training:   7%| | 3041/40960 [00:07<01:22, 457.74batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n",
      "Training:   8%| | 3132/40960 [00:07<01:22, 456.68batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n",
      "Training:   8%| | 3132/40960 [00:07<01:22, 456.68batches/s, l2_loss: 0.0193 - round_loss\u001b[A\n",
      "Training:   8%| | 3225/40960 [00:07<01:22, 458.14batches/s, l2_loss: 0.0193 - round_loss\u001b[A\n",
      "Training:   8%| | 3225/40960 [00:07<01:22, 458.14batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n",
      "Training:   8%| | 3314/40960 [00:08<01:23, 452.97batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n",
      "Training:   8%| | 3314/40960 [00:08<01:23, 452.97batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   8%| | 3405/40960 [00:08<01:22, 453.28batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   8%| | 3405/40960 [00:08<01:22, 453.28batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:   9%| | 3496/40960 [00:08<01:22, 452.54batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:   9%| | 3496/40960 [00:08<01:22, 452.54batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   9%| | 3588/40960 [00:08<01:22, 453.75batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   9%| | 3588/40960 [00:08<01:22, 453.75batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   9%| | 3681/40960 [00:08<01:21, 456.59batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   9%| | 3681/40960 [00:08<01:21, 456.59batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   9%| | 3771/40960 [00:09<01:21, 454.39batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   9%| | 3771/40960 [00:09<01:21, 454.39batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   9%| | 3863/40960 [00:09<01:21, 455.98batches/s, l2_loss: 0.0191 - round_loss\u001b[A\n",
      "Training:   9%| | 3863/40960 [00:09<01:21, 455.98batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  10%| | 3956/40960 [00:09<01:20, 458.29batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  10%| | 3956/40960 [00:09<01:20, 458.29batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  10%| | 4050/40960 [00:09<01:20, 460.93batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  10%| | 4050/40960 [00:09<01:20, 460.93batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  10%| | 4143/40960 [00:09<01:19, 461.12batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  10%| | 4143/40960 [00:09<01:19, 461.12batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  10%| | 4235/40960 [00:10<01:19, 460.64batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  10%| | 4235/40960 [00:10<01:19, 460.64batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  11%| | 4326/40960 [00:10<01:19, 458.30batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  11%| | 4326/40960 [00:10<01:19, 458.30batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  11%| | 4421/40960 [00:10<01:18, 462.74batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  11%| | 4421/40960 [00:10<01:18, 462.74batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  11%| | 4515/40960 [00:10<01:18, 464.36batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  11%| | 4515/40960 [00:10<01:18, 464.36batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  11%| | 4608/40960 [00:10<01:18, 464.16batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  11%| | 4608/40960 [00:10<01:18, 464.16batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  11%| | 4698/40960 [00:11<01:18, 459.04batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  11%| | 4698/40960 [00:11<01:18, 459.04batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  12%| | 4789/40960 [00:11<01:19, 456.73batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  12%| | 4789/40960 [00:11<01:19, 456.73batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  12%| | 4877/40960 [00:11<01:19, 451.51batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  12%| | 4877/40960 [00:11<01:19, 451.51batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  12%| | 4968/40960 [00:11<01:19, 451.49batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  12%| | 4968/40960 [00:11<01:19, 451.49batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  12%| | 5059/40960 [00:11<01:19, 451.33batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  12%| | 5059/40960 [00:11<01:19, 451.33batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5149/40960 [00:12<01:19, 450.31batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5149/40960 [00:12<01:19, 450.31batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5243/40960 [00:12<01:18, 454.81batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5243/40960 [00:12<01:18, 454.81batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5336/40960 [00:12<01:17, 456.95batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5336/40960 [00:12<01:17, 456.95batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5429/40960 [00:12<01:17, 457.99batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5429/40960 [00:12<01:17, 457.99batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5519/40960 [00:12<01:17, 454.72batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5519/40960 [00:12<01:17, 454.72batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5610/40960 [00:13<01:17, 453.50batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5610/40960 [00:13<01:17, 453.50batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5702/40960 [00:13<01:17, 454.93batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5702/40960 [00:13<01:17, 454.93batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5793/40960 [00:13<01:17, 453.63batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5793/40960 [00:13<01:17, 453.63batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5884/40960 [00:13<01:17, 453.33batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5884/40960 [00:13<01:17, 453.33batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5975/40960 [00:13<01:17, 453.09batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5975/40960 [00:13<01:17, 453.09batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6067/40960 [00:14<01:16, 453.75batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6067/40960 [00:14<01:16, 453.75batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6158/40960 [00:14<01:16, 453.58batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6158/40960 [00:14<01:16, 453.58batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6250/40960 [00:14<01:16, 454.52batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6250/40960 [00:14<01:16, 454.52batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6342/40960 [00:14<01:16, 455.47batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6342/40960 [00:14<01:16, 455.47batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6434/40960 [00:14<01:15, 455.65batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6434/40960 [00:14<01:15, 455.65batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6526/40960 [00:15<01:15, 455.96batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6526/40960 [00:15<01:15, 455.96batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6616/40960 [00:15<01:15, 453.27batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6616/40960 [00:15<01:15, 453.27batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6709/40960 [00:15<01:15, 455.39batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6709/40960 [00:15<01:15, 455.39batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6799/40960 [00:15<01:15, 453.40batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6799/40960 [00:15<01:15, 453.40batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6891/40960 [00:15<01:14, 454.79batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6891/40960 [00:15<01:14, 454.79batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6982/40960 [00:16<01:14, 453.75batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6982/40960 [00:16<01:14, 453.75batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7076/40960 [00:16<01:14, 457.47batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|▏| 7076/40960 [00:16<01:14, 457.47batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7167/40960 [00:16<01:14, 455.69batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7167/40960 [00:16<01:14, 455.69batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7257/40960 [00:16<01:14, 452.69batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7257/40960 [00:16<01:14, 452.69batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7349/40960 [00:16<01:13, 454.69batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7349/40960 [00:17<01:13, 454.69batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7440/40960 [00:17<01:13, 453.80batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7440/40960 [00:17<01:13, 453.80batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7533/40960 [00:17<01:13, 456.26batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7533/40960 [00:17<01:13, 456.26batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7624/40960 [00:17<01:13, 454.66batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7624/40960 [00:17<01:13, 454.66batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7715/40960 [00:17<01:13, 453.50batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7715/40960 [00:17<01:13, 453.50batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7806/40960 [00:18<01:13, 453.89batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7806/40960 [00:18<01:13, 453.89batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7898/40960 [00:18<01:12, 455.53batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7898/40960 [00:18<01:12, 455.53batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7989/40960 [00:18<01:12, 454.93batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7989/40960 [00:18<01:12, 454.93batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8081/40960 [00:18<01:12, 456.39batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8081/40960 [00:18<01:12, 456.39batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8170/40960 [00:18<01:12, 452.50batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8170/40960 [00:18<01:12, 452.50batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8249/40960 [00:19<01:15, 434.76batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8249/40960 [00:19<01:15, 434.76batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8331/40960 [00:19<01:16, 427.03batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8331/40960 [00:19<01:16, 427.03batches/s, l2_loss: 0.0173 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8413/40960 [00:19<01:17, 420.62batches/s, l2_loss: 0.0173 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8413/40960 [00:19<01:17, 420.62batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8495/40960 [00:19<01:18, 416.09batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8495/40960 [00:19<01:18, 416.09batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8576/40960 [00:19<01:18, 411.75batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8576/40960 [00:19<01:18, 411.75batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8661/40960 [00:20<01:17, 414.61batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8661/40960 [00:20<01:17, 414.61batches/s, l2_loss: 0.0176 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8744/40960 [00:20<01:17, 413.86batches/s, l2_loss: 0.0176 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8744/40960 [00:20<01:17, 413.86batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8826/40960 [00:20<01:17, 412.20batches/s, l2_loss: 0.0190 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8826/40960 [00:20<01:17, 412.20batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8907/40960 [00:20<01:18, 408.76batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8907/40960 [00:20<01:18, 408.76batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8989/40960 [00:20<01:18, 408.51batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8989/40960 [00:20<01:18, 408.51batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9070/40960 [00:21<01:18, 406.43batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9070/40960 [00:21<01:18, 406.43batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9150/40960 [00:21<01:18, 404.43batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9150/40960 [00:21<01:18, 404.43batches/s, l2_loss: 0.0182 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9233/40960 [00:21<01:18, 406.31batches/s, l2_loss: 0.0182 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9233/40960 [00:21<01:18, 406.31batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9314/40960 [00:21<01:17, 405.77batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9314/40960 [00:21<01:17, 405.77batches/s, l2_loss: 0.0184 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9396/40960 [00:21<01:17, 405.78batches/s, l2_loss: 0.0184 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9396/40960 [00:21<01:17, 405.78batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9473/40960 [00:22<01:18, 399.55batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9473/40960 [00:22<01:18, 399.55batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9553/40960 [00:22<01:18, 398.40batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9553/40960 [00:22<01:18, 398.40batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9637/40960 [00:22<01:17, 404.85batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9637/40960 [00:22<01:17, 404.85batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9719/40960 [00:22<01:16, 405.96batches/s, l2_loss: 0.0189 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9719/40960 [00:22<01:16, 405.96batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9801/40960 [00:22<01:16, 406.37batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9801/40960 [00:22<01:16, 406.37batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9880/40960 [00:23<01:17, 402.96batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9880/40960 [00:23<01:17, 402.96batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9959/40960 [00:23<01:17, 399.64batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9959/40960 [00:23<01:17, 399.64batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10040/40960 [00:23<01:17, 400.62batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  25%|▏| 10040/40960 [00:23<01:17, 400.62batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  25%|▏| 10122/40960 [00:23<01:16, 402.86batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  25%|▏| 10122/40960 [00:23<01:16, 402.86batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  25%|▏| 10204/40960 [00:23<01:16, 403.84batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  25%|▏| 10204/40960 [00:23<01:16, 403.84batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  25%|▎| 10283/40960 [00:24<01:16, 400.31batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  25%|▎| 10283/40960 [00:24<01:16, 400.31batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▎| 10366/40960 [00:24<01:15, 403.52batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▎| 10366/40960 [00:24<01:15, 403.52batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  26%|▎| 10449/40960 [00:24<01:15, 406.09batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  26%|▎| 10449/40960 [00:24<01:15, 406.09batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  26%|▎| 10530/40960 [00:24<01:15, 404.38batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  26%|▎| 10530/40960 [00:24<01:15, 404.38batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  26%|▎| 10612/40960 [00:24<01:14, 405.16batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  26%|▎| 10612/40960 [00:24<01:14, 405.16batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  26%|▎| 10691/40960 [00:25<01:15, 401.61batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  26%|▎| 10691/40960 [00:25<01:15, 401.61batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  26%|▎| 10774/40960 [00:25<01:14, 405.11batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  26%|▎| 10774/40960 [00:25<01:14, 405.11batches/s, l2_loss: 0.0186 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|▎| 10857/40960 [00:25<01:14, 406.78batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 10857/40960 [00:25<01:14, 406.78batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 10938/40960 [00:25<01:14, 405.67batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 10938/40960 [00:25<01:14, 405.67batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  27%|▎| 11021/40960 [00:25<01:13, 408.42batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  27%|▎| 11021/40960 [00:25<01:13, 408.42batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11101/40960 [00:26<01:13, 404.82batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11101/40960 [00:26<01:13, 404.82batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11182/40960 [00:26<01:13, 403.88batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11182/40960 [00:26<01:13, 403.88batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11266/40960 [00:26<01:12, 407.24batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11266/40960 [00:26<01:12, 407.24batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  28%|▎| 11350/40960 [00:26<01:12, 410.24batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  28%|▎| 11350/40960 [00:26<01:12, 410.24batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11434/40960 [00:26<01:11, 412.88batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11434/40960 [00:26<01:11, 412.88batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  28%|▎| 11509/40960 [00:27<01:13, 400.95batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  28%|▎| 11509/40960 [00:27<01:13, 400.95batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  28%|▎| 11569/40960 [00:27<01:19, 370.65batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  28%|▎| 11569/40960 [00:27<01:19, 370.65batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  28%|▎| 11637/40960 [00:27<01:21, 361.01batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  28%|▎| 11637/40960 [00:27<01:21, 361.01batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  29%|▎| 11703/40960 [00:27<01:23, 351.32batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  29%|▎| 11703/40960 [00:27<01:23, 351.32batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  29%|▎| 11777/40960 [00:27<01:22, 355.85batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  29%|▎| 11777/40960 [00:27<01:22, 355.85batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  29%|▎| 11834/40960 [00:28<01:27, 334.25batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  29%|▎| 11834/40960 [00:28<01:27, 334.25batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  29%|▎| 11897/40960 [00:28<01:28, 328.04batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  29%|▎| 11897/40960 [00:28<01:28, 328.04batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  29%|▎| 11975/40960 [00:28<01:23, 345.77batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  29%|▎| 11975/40960 [00:28<01:23, 345.77batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 12053/40960 [00:28<01:20, 358.51batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 12053/40960 [00:28<01:20, 358.51batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  30%|▎| 12118/40960 [00:28<01:23, 346.97batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  30%|▎| 12118/40960 [00:28<01:23, 346.97batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  30%|▎| 12191/40960 [00:29<01:21, 351.48batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  30%|▎| 12191/40960 [00:29<01:21, 351.48batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  30%|▎| 12269/40960 [00:29<01:19, 362.59batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  30%|▎| 12269/40960 [00:29<01:19, 362.59batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  30%|▎| 12343/40960 [00:29<01:18, 363.61batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  30%|▎| 12343/40960 [00:29<01:18, 363.61batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  30%|▎| 12421/40960 [00:29<01:16, 371.28batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  30%|▎| 12421/40960 [00:29<01:16, 371.28batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  31%|▎| 12499/40960 [00:29<01:15, 375.99batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  31%|▎| 12499/40960 [00:29<01:15, 375.99batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12577/40960 [00:30<01:14, 379.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12577/40960 [00:30<01:14, 379.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12658/40960 [00:30<01:13, 386.36batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12658/40960 [00:30<01:13, 386.36batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12733/40960 [00:30<01:13, 382.41batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12733/40960 [00:30<01:13, 382.41batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  31%|▎| 12810/40960 [00:30<01:13, 381.97batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  31%|▎| 12810/40960 [00:30<01:13, 381.97batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  31%|▎| 12887/40960 [00:30<01:13, 381.53batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  31%|▎| 12887/40960 [00:30<01:13, 381.53batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  32%|▎| 12949/40960 [00:31<01:17, 359.22batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  32%|▎| 12949/40960 [00:31<01:17, 359.22batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13023/40960 [00:31<01:17, 361.90batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13023/40960 [00:31<01:17, 361.90batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13102/40960 [00:31<01:14, 371.46batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13102/40960 [00:31<01:14, 371.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  32%|▎| 13180/40960 [00:31<01:13, 375.79batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  32%|▎| 13180/40960 [00:31<01:13, 375.79batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  32%|▎| 13257/40960 [00:31<01:13, 378.45batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  32%|▎| 13257/40960 [00:31<01:13, 378.45batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13333/40960 [00:32<01:13, 378.08batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13333/40960 [00:32<01:13, 378.08batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  33%|▎| 13413/40960 [00:32<01:11, 384.15batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  33%|▎| 13413/40960 [00:32<01:11, 384.15batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  33%|▎| 13494/40960 [00:32<01:10, 388.85batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  33%|▎| 13494/40960 [00:32<01:10, 388.85batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  33%|▎| 13571/40960 [00:32<01:10, 386.48batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  33%|▎| 13571/40960 [00:32<01:10, 386.48batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  33%|▎| 13648/40960 [00:32<01:10, 385.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  33%|▎| 13648/40960 [00:32<01:10, 385.44batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 13724/40960 [00:33<01:11, 383.57batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 13724/40960 [00:33<01:11, 383.57batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  34%|▎| 13805/40960 [00:33<01:09, 389.54batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  34%|▎| 13805/40960 [00:33<01:09, 389.54batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  34%|▎| 13878/40960 [00:33<01:11, 381.11batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  34%|▎| 13878/40960 [00:33<01:11, 381.11batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  34%|▎| 13950/40960 [00:33<01:12, 374.72batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  34%|▎| 13950/40960 [00:33<01:12, 374.72batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  34%|▎| 14028/40960 [00:33<01:11, 378.88batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  34%|▎| 14028/40960 [00:33<01:11, 378.88batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  34%|▎| 14107/40960 [00:34<01:10, 383.30batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  34%|▎| 14107/40960 [00:34<01:10, 383.30batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  35%|▎| 14185/40960 [00:34<01:09, 384.85batches/s, l2_loss: 0.0184 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14185/40960 [00:34<01:09, 384.85batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14260/40960 [00:34<01:09, 381.70batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14260/40960 [00:34<01:09, 381.70batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  35%|▎| 14341/40960 [00:34<01:08, 388.36batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  35%|▎| 14341/40960 [00:34<01:08, 388.36batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14418/40960 [00:34<01:08, 387.20batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14418/40960 [00:34<01:08, 387.20batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  35%|▎| 14497/40960 [00:35<01:08, 388.92batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  35%|▎| 14497/40960 [00:35<01:08, 388.92batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  36%|▎| 14578/40960 [00:35<01:07, 393.26batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  36%|▎| 14578/40960 [00:35<01:07, 393.26batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14657/40960 [00:35<01:07, 392.26batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14657/40960 [00:35<01:07, 392.26batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14736/40960 [00:35<01:06, 393.03batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14736/40960 [00:35<01:06, 393.03batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  36%|▎| 14813/40960 [00:35<01:07, 389.57batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  36%|▎| 14813/40960 [00:35<01:07, 389.57batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14892/40960 [00:36<01:06, 390.32batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14892/40960 [00:36<01:06, 390.32batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  37%|▎| 14970/40960 [00:36<01:06, 389.60batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  37%|▎| 14970/40960 [00:36<01:06, 389.60batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  37%|▎| 15046/40960 [00:36<01:07, 386.11batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  37%|▎| 15046/40960 [00:36<01:07, 386.11batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15122/40960 [00:36<01:07, 383.26batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15122/40960 [00:36<01:07, 383.26batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  37%|▎| 15199/40960 [00:36<01:07, 382.98batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  37%|▎| 15199/40960 [00:36<01:07, 382.98batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  37%|▎| 15274/40960 [00:37<01:07, 380.41batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  37%|▎| 15274/40960 [00:37<01:07, 380.41batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  37%|▎| 15354/40960 [00:37<01:06, 385.15batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  37%|▎| 15354/40960 [00:37<01:06, 385.15batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  38%|▍| 15432/40960 [00:37<01:06, 386.31batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  38%|▍| 15432/40960 [00:37<01:06, 386.31batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15512/40960 [00:37<01:05, 389.80batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15512/40960 [00:37<01:05, 389.80batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  38%|▍| 15590/40960 [00:37<01:05, 389.85batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  38%|▍| 15590/40960 [00:37<01:05, 389.85batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15670/40960 [00:38<01:04, 392.07batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15670/40960 [00:38<01:04, 392.07batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15743/40960 [00:38<01:05, 383.76batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15743/40960 [00:38<01:05, 383.76batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 15806/40960 [00:38<01:09, 362.27batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 15806/40960 [00:38<01:09, 362.27batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  39%|▍| 15875/40960 [00:38<01:10, 356.50batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  39%|▍| 15875/40960 [00:38<01:10, 356.50batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 15955/40960 [00:38<01:07, 368.60batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 15955/40960 [00:38<01:07, 368.60batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  39%|▍| 16031/40960 [00:39<01:07, 370.97batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  39%|▍| 16031/40960 [00:39<01:07, 370.97batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 16110/40960 [00:39<01:05, 378.14batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 16110/40960 [00:39<01:05, 378.14batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  40%|▍| 16186/40960 [00:39<01:05, 377.75batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  40%|▍| 16186/40960 [00:39<01:05, 377.75batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  40%|▍| 16265/40960 [00:39<01:04, 382.54batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  40%|▍| 16265/40960 [00:39<01:04, 382.54batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16341/40960 [00:39<01:04, 381.78batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16341/40960 [00:39<01:04, 381.78batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16415/40960 [00:40<01:05, 377.18batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16415/40960 [00:40<01:05, 377.18batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  40%|▍| 16492/40960 [00:40<01:04, 378.29batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  40%|▍| 16492/40960 [00:40<01:04, 378.29batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16571/40960 [00:40<01:03, 382.89batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16571/40960 [00:40<01:03, 382.89batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16650/40960 [00:40<01:02, 386.14batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16650/40960 [00:40<01:02, 386.14batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  41%|▍| 16728/40960 [00:40<01:02, 384.75batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  41%|▍| 16728/40960 [00:40<01:02, 384.75batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16805/40960 [00:41<01:02, 384.79batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16805/40960 [00:41<01:02, 384.79batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16883/40960 [00:41<01:02, 385.61batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16883/40960 [00:41<01:02, 385.61batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  41%|▍| 16958/40960 [00:41<01:02, 382.39batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  41%|▍| 16958/40960 [00:41<01:02, 382.39batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  42%|▍| 17037/40960 [00:41<01:02, 385.14batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  42%|▍| 17037/40960 [00:41<01:02, 385.14batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  42%|▍| 17112/40960 [00:41<01:02, 382.01batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  42%|▍| 17112/40960 [00:41<01:02, 382.01batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  42%|▍| 17191/40960 [00:42<01:01, 385.62batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  42%|▍| 17191/40960 [00:42<01:01, 385.62batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17269/40960 [00:42<01:01, 386.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17269/40960 [00:42<01:01, 386.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17348/40960 [00:42<01:00, 388.73batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17348/40960 [00:42<01:00, 388.73batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17427/40960 [00:42<01:00, 389.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17427/40960 [00:42<01:00, 389.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17502/40960 [00:42<01:00, 384.64batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17502/40960 [00:42<01:00, 384.64batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  43%|▍| 17581/40960 [00:43<01:00, 387.25batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  43%|▍| 17581/40960 [00:43<01:00, 387.25batches/s, l2_loss: 0.0184 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17658/40960 [00:43<01:00, 386.55batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17658/40960 [00:43<01:00, 386.55batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17736/40960 [00:43<01:00, 386.87batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17736/40960 [00:43<01:00, 386.87batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  43%|▍| 17815/40960 [00:43<00:59, 388.33batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  43%|▍| 17815/40960 [00:43<00:59, 388.33batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17892/40960 [00:43<00:59, 387.01batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17892/40960 [00:43<00:59, 387.01batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17972/40960 [00:44<00:59, 389.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17972/40960 [00:44<00:59, 389.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18047/40960 [00:44<00:59, 383.95batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18047/40960 [00:44<00:59, 383.95batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18122/40960 [00:44<00:59, 381.25batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18122/40960 [00:44<00:59, 381.25batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18199/40960 [00:44<00:59, 381.69batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18199/40960 [00:44<00:59, 381.69batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18278/40960 [00:44<00:59, 384.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18278/40960 [00:44<00:59, 384.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18354/40960 [00:45<00:59, 382.26batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18354/40960 [00:45<00:59, 382.26batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18434/40960 [00:45<00:58, 386.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18434/40960 [00:45<00:58, 386.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18511/40960 [00:45<00:58, 385.50batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18511/40960 [00:45<00:58, 385.50batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18590/40960 [00:45<00:57, 387.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18590/40960 [00:45<00:57, 387.46batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  46%|▍| 18671/40960 [00:45<00:56, 391.99batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  46%|▍| 18671/40960 [00:45<00:56, 391.99batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18744/40960 [00:46<00:57, 383.45batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18744/40960 [00:46<00:57, 383.45batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  46%|▍| 18822/40960 [00:46<00:57, 384.98batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  46%|▍| 18822/40960 [00:46<00:57, 384.98batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18897/40960 [00:46<00:57, 381.32batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18897/40960 [00:46<00:57, 381.32batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18976/40960 [00:46<00:57, 384.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18976/40960 [00:46<00:57, 384.46batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19058/40960 [00:46<00:55, 391.38batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19058/40960 [00:46<00:55, 391.38batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19133/40960 [00:47<00:56, 385.27batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19133/40960 [00:47<00:56, 385.27batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19212/40960 [00:47<00:56, 387.76batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19212/40960 [00:47<00:56, 387.76batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19288/40960 [00:47<00:56, 384.54batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19288/40960 [00:47<00:56, 384.54batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19365/40960 [00:47<00:56, 384.02batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19365/40960 [00:47<00:56, 384.02batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19441/40960 [00:47<00:56, 382.13batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  47%|▍| 19441/40960 [00:47<00:56, 382.13batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19520/40960 [00:48<00:55, 384.94batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19520/40960 [00:48<00:55, 384.94batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19598/40960 [00:48<00:55, 384.52batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19598/40960 [00:48<00:55, 384.52batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19677/40960 [00:48<00:55, 386.74batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19677/40960 [00:48<00:55, 386.74batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19754/40960 [00:48<00:55, 384.49batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19754/40960 [00:48<00:55, 384.49batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19833/40960 [00:48<00:54, 387.41batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  48%|▍| 19833/40960 [00:48<00:54, 387.41batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  49%|▍| 19912/40960 [00:49<00:54, 388.90batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  49%|▍| 19912/40960 [00:49<00:54, 388.90batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 19989/40960 [00:49<00:54, 386.49batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 19989/40960 [00:49<00:54, 386.49batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20057/40960 [00:49<00:56, 371.40batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20057/40960 [00:49<00:56, 371.40batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20119/40960 [00:49<00:59, 351.93batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20119/40960 [00:49<00:59, 351.93batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20184/40960 [00:50<01:00, 342.95batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20184/40960 [00:50<01:00, 342.95batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  49%|▍| 20248/40960 [00:50<01:01, 335.29batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  49%|▍| 20248/40960 [00:50<01:01, 335.29batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▍| 20313/40960 [00:50<01:02, 331.90batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▍| 20313/40960 [00:50<01:02, 331.90batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  50%|▍| 20380/40960 [00:50<01:01, 332.48batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  50%|▍| 20380/40960 [00:50<01:01, 332.48batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  50%|▍| 20445/40960 [00:50<01:02, 329.72batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  50%|▍| 20445/40960 [00:50<01:02, 329.72batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▌| 20521/40960 [00:51<00:59, 344.28batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▌| 20521/40960 [00:51<00:59, 344.28batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▌| 20600/40960 [00:51<00:56, 358.59batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▌| 20600/40960 [00:51<00:56, 358.59batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  50%|▌| 20681/40960 [00:51<00:54, 371.32batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  50%|▌| 20681/40960 [00:51<00:54, 371.32batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  51%|▌| 20759/40960 [00:51<00:53, 376.78batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  51%|▌| 20759/40960 [00:51<00:53, 376.78batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  51%|▌| 20838/40960 [00:51<00:52, 381.12batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  51%|▌| 20838/40960 [00:51<00:52, 381.12batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  51%|▌| 20917/40960 [00:52<00:52, 384.87batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  51%|▌| 20917/40960 [00:52<00:52, 384.87batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  51%|▌| 20996/40960 [00:52<00:51, 387.57batches/s, l2_loss: 0.0184 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|▌| 20996/40960 [00:52<00:51, 387.57batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  51%|▌| 21076/40960 [00:52<00:50, 389.94batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  51%|▌| 21076/40960 [00:52<00:50, 389.94batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  52%|▌| 21159/40960 [00:52<00:49, 396.54batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  52%|▌| 21159/40960 [00:52<00:49, 396.54batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  52%|▌| 21240/40960 [00:52<00:49, 397.97batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  52%|▌| 21240/40960 [00:52<00:49, 397.97batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  52%|▌| 21320/40960 [00:53<00:49, 397.91batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  52%|▌| 21320/40960 [00:53<00:49, 397.91batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  52%|▌| 21403/40960 [00:53<00:48, 401.89batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  52%|▌| 21403/40960 [00:53<00:48, 401.89batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  52%|▌| 21486/40960 [00:53<00:48, 405.51batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  52%|▌| 21486/40960 [00:53<00:48, 405.51batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21569/40960 [00:53<00:47, 407.08batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21569/40960 [00:53<00:47, 407.08batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21652/40960 [00:53<00:47, 408.78batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21652/40960 [00:53<00:47, 408.78batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21737/40960 [00:54<00:46, 412.81batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21737/40960 [00:54<00:46, 412.81batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21819/40960 [00:54<00:46, 411.40batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21819/40960 [00:54<00:46, 411.40batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21904/40960 [00:54<00:46, 414.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  53%|▌| 21904/40960 [00:54<00:46, 414.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 21987/40960 [00:54<00:45, 413.36batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 21987/40960 [00:54<00:45, 413.36batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 22071/40960 [00:54<00:45, 414.33batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 22071/40960 [00:54<00:45, 414.33batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 22153/40960 [00:55<00:45, 412.12batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 22153/40960 [00:55<00:45, 412.12batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 22238/40960 [00:55<00:45, 414.80batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 22238/40960 [00:55<00:45, 414.80batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 22315/40960 [00:55<00:45, 405.87batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  54%|▌| 22315/40960 [00:55<00:45, 405.87batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  55%|▌| 22396/40960 [00:55<00:45, 404.65batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  55%|▌| 22396/40960 [00:55<00:45, 404.65batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  55%|▌| 22479/40960 [00:55<00:45, 406.86batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  55%|▌| 22479/40960 [00:55<00:45, 406.86batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  55%|▌| 22563/40960 [00:56<00:44, 409.84batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  55%|▌| 22563/40960 [00:56<00:44, 409.84batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  55%|▌| 22643/40960 [00:56<00:45, 405.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  55%|▌| 22643/40960 [00:56<00:45, 405.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  55%|▌| 22728/40960 [00:56<00:44, 410.46batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  55%|▌| 22728/40960 [00:56<00:44, 410.46batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 22811/40960 [00:56<00:44, 411.64batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 22811/40960 [00:56<00:44, 411.64batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 22892/40960 [00:56<00:44, 408.57batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 22892/40960 [00:56<00:44, 408.57batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 22965/40960 [00:57<00:45, 394.92batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 22965/40960 [00:57<00:45, 394.92batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 23033/40960 [00:57<00:47, 377.73batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 23033/40960 [00:57<00:47, 377.73batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 23100/40960 [00:57<00:49, 364.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  56%|▌| 23100/40960 [00:57<00:49, 364.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23169/40960 [00:57<00:49, 357.68batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23169/40960 [00:57<00:49, 357.68batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23241/40960 [00:57<00:49, 356.85batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23241/40960 [00:57<00:49, 356.85batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23307/40960 [00:58<00:50, 348.13batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23307/40960 [00:58<00:50, 348.13batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23375/40960 [00:58<00:51, 344.54batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23375/40960 [00:58<00:51, 344.54batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23444/40960 [00:58<00:50, 343.75batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23444/40960 [00:58<00:50, 343.75batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23517/40960 [00:58<00:49, 349.27batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  57%|▌| 23517/40960 [00:58<00:49, 349.27batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23590/40960 [00:58<00:49, 353.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23590/40960 [00:58<00:49, 353.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23661/40960 [00:59<00:48, 353.24batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23661/40960 [00:59<00:48, 353.24batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23737/40960 [00:59<00:47, 360.87batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23737/40960 [00:59<00:47, 360.87batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23809/40960 [00:59<00:47, 360.52batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23809/40960 [00:59<00:47, 360.52batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23891/40960 [00:59<00:45, 375.14batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  58%|▌| 23891/40960 [00:59<00:45, 375.14batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 23972/40960 [00:59<00:44, 382.90batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 23972/40960 [00:59<00:44, 382.90batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 24054/40960 [01:00<00:43, 390.32batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 24054/40960 [01:00<00:43, 390.32batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 24135/40960 [01:00<00:42, 393.50batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 24135/40960 [01:00<00:42, 393.50batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 24218/40960 [01:00<00:41, 399.04batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 24218/40960 [01:00<00:41, 399.04batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 24300/40960 [01:00<00:41, 401.29batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  59%|▌| 24300/40960 [01:00<00:41, 401.29batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24385/40960 [01:00<00:40, 407.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24385/40960 [01:00<00:40, 407.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24469/40960 [01:01<00:40, 410.90batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24469/40960 [01:01<00:40, 410.90batches/s, l2_loss: 0.0186 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 24554/40960 [01:01<00:39, 414.20batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  60%|▌| 24554/40960 [01:01<00:39, 414.20batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24628/40960 [01:01<00:40, 400.61batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24628/40960 [01:01<00:40, 400.61batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24695/40960 [01:01<00:42, 380.36batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24695/40960 [01:01<00:42, 380.36batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24767/40960 [01:01<00:43, 373.12batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  60%|▌| 24767/40960 [01:01<00:43, 373.12batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 24838/40960 [01:02<00:43, 367.06batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 24838/40960 [01:02<00:43, 367.06batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 24910/40960 [01:02<00:44, 363.60batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 24910/40960 [01:02<00:44, 363.60batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 24982/40960 [01:02<00:44, 362.43batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 24982/40960 [01:02<00:44, 362.43batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 25060/40960 [01:02<00:43, 369.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 25060/40960 [01:02<00:43, 369.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 25143/40960 [01:02<00:41, 382.01batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  61%|▌| 25143/40960 [01:02<00:41, 382.01batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25224/40960 [01:03<00:40, 388.39batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25224/40960 [01:03<00:40, 388.39batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25305/40960 [01:03<00:39, 392.12batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25305/40960 [01:03<00:39, 392.12batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25390/40960 [01:03<00:38, 400.58batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25390/40960 [01:03<00:38, 400.58batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25472/40960 [01:03<00:38, 403.23batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25472/40960 [01:03<00:38, 403.23batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25553/40960 [01:03<00:38, 403.13batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  62%|▌| 25553/40960 [01:03<00:38, 403.13batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  63%|▋| 25634/40960 [01:04<00:38, 402.24batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  63%|▋| 25634/40960 [01:04<00:38, 402.24batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  63%|▋| 25712/40960 [01:04<00:38, 398.48batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  63%|▋| 25712/40960 [01:04<00:38, 398.48batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  63%|▋| 25794/40960 [01:04<00:37, 401.14batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  63%|▋| 25794/40960 [01:04<00:37, 401.14batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  63%|▋| 25874/40960 [01:04<00:37, 400.06batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  63%|▋| 25874/40960 [01:04<00:37, 400.06batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  63%|▋| 25953/40960 [01:04<00:37, 398.32batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  63%|▋| 25953/40960 [01:04<00:37, 398.32batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  64%|▋| 26035/40960 [01:05<00:37, 400.79batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  64%|▋| 26035/40960 [01:05<00:37, 400.79batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  64%|▋| 26119/40960 [01:05<00:36, 405.59batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  64%|▋| 26119/40960 [01:05<00:36, 405.59batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  64%|▋| 26193/40960 [01:05<00:37, 394.84batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  64%|▋| 26193/40960 [01:05<00:37, 394.84batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  64%|▋| 26269/40960 [01:05<00:37, 390.29batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  64%|▋| 26269/40960 [01:05<00:37, 390.29batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  64%|▋| 26350/40960 [01:05<00:37, 394.54batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  64%|▋| 26350/40960 [01:05<00:37, 394.54batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  65%|▋| 26422/40960 [01:06<00:37, 382.86batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  65%|▋| 26422/40960 [01:06<00:37, 382.86batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  65%|▋| 26505/40960 [01:06<00:36, 391.27batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  65%|▋| 26505/40960 [01:06<00:36, 391.27batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  65%|▋| 26588/40960 [01:06<00:36, 396.90batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  65%|▋| 26588/40960 [01:06<00:36, 396.90batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  65%|▋| 26670/40960 [01:06<00:35, 399.65batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  65%|▋| 26670/40960 [01:06<00:35, 399.65batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  65%|▋| 26752/40960 [01:06<00:35, 401.51batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  65%|▋| 26752/40960 [01:06<00:35, 401.51batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  66%|▋| 26832/40960 [01:07<00:35, 399.69batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  66%|▋| 26832/40960 [01:07<00:35, 399.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  66%|▋| 26917/40960 [01:07<00:34, 405.83batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  66%|▋| 26917/40960 [01:07<00:34, 405.83batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  66%|▋| 27001/40960 [01:07<00:34, 409.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  66%|▋| 27001/40960 [01:07<00:34, 409.15batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  66%|▋| 27084/40960 [01:07<00:33, 410.14batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  66%|▋| 27084/40960 [01:07<00:33, 410.14batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  66%|▋| 27165/40960 [01:07<00:33, 408.53batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  66%|▋| 27165/40960 [01:07<00:33, 408.53batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27246/40960 [01:08<00:33, 406.28batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27246/40960 [01:08<00:33, 406.28batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27330/40960 [01:08<00:33, 409.92batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27330/40960 [01:08<00:33, 409.92batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27410/40960 [01:08<00:33, 406.17batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27410/40960 [01:08<00:33, 406.17batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27491/40960 [01:08<00:33, 404.75batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27491/40960 [01:08<00:33, 404.75batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27572/40960 [01:08<00:33, 403.53batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  67%|▋| 27572/40960 [01:08<00:33, 403.53batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27655/40960 [01:09<00:32, 406.25batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27655/40960 [01:09<00:32, 406.25batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27739/40960 [01:09<00:32, 410.24batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27739/40960 [01:09<00:32, 410.24batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27821/40960 [01:09<00:32, 409.79batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27821/40960 [01:09<00:32, 409.79batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27902/40960 [01:09<00:31, 408.13batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27902/40960 [01:09<00:31, 408.13batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27984/40960 [01:09<00:31, 408.43batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  68%|▋| 27984/40960 [01:09<00:31, 408.43batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28069/40960 [01:10<00:31, 412.22batches/s, l2_loss: 0.0186 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|▋| 28069/40960 [01:10<00:31, 412.22batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28148/40960 [01:10<00:31, 407.00batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28148/40960 [01:10<00:31, 407.00batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28233/40960 [01:10<00:30, 411.13batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28233/40960 [01:10<00:30, 411.13batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28318/40960 [01:10<00:30, 414.19batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28318/40960 [01:10<00:30, 414.19batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28400/40960 [01:10<00:30, 412.87batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  69%|▋| 28400/40960 [01:10<00:30, 412.87batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28485/40960 [01:11<00:30, 415.39batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28485/40960 [01:11<00:30, 415.39batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28569/40960 [01:11<00:29, 416.34batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28569/40960 [01:11<00:29, 416.34batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28653/40960 [01:11<00:29, 417.26batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28653/40960 [01:11<00:29, 417.26batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28733/40960 [01:11<00:29, 410.64batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28733/40960 [01:11<00:29, 410.64batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28819/40960 [01:11<00:29, 415.84batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  70%|▋| 28819/40960 [01:11<00:29, 415.84batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  71%|▋| 28905/40960 [01:12<00:28, 418.70batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  71%|▋| 28905/40960 [01:12<00:28, 418.70batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  71%|▋| 28988/40960 [01:12<00:28, 416.62batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  71%|▋| 28988/40960 [01:12<00:28, 416.62batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  71%|▋| 29073/40960 [01:12<00:28, 418.47batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  71%|▋| 29073/40960 [01:12<00:28, 418.47batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  71%|▋| 29157/40960 [01:12<00:28, 418.17batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  71%|▋| 29157/40960 [01:12<00:28, 418.17batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  71%|▋| 29240/40960 [01:12<00:28, 416.06batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  71%|▋| 29240/40960 [01:12<00:28, 416.06batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  72%|▋| 29324/40960 [01:13<00:27, 416.29batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  72%|▋| 29324/40960 [01:13<00:27, 416.29batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  72%|▋| 29405/40960 [01:13<00:28, 412.22batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  72%|▋| 29405/40960 [01:13<00:28, 412.22batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  72%|▋| 29487/40960 [01:13<00:27, 411.28batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  72%|▋| 29487/40960 [01:13<00:27, 411.28batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  72%|▋| 29569/40960 [01:13<00:27, 410.57batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  72%|▋| 29569/40960 [01:13<00:27, 410.57batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  72%|▋| 29652/40960 [01:13<00:27, 411.09batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  72%|▋| 29652/40960 [01:13<00:27, 411.09batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  73%|▋| 29738/40960 [01:14<00:27, 415.51batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  73%|▋| 29738/40960 [01:14<00:27, 415.51batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  73%|▋| 29822/40960 [01:14<00:26, 416.38batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  73%|▋| 29822/40960 [01:14<00:26, 416.38batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  73%|▋| 29906/40960 [01:14<00:26, 415.98batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  73%|▋| 29906/40960 [01:14<00:26, 415.98batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  73%|▋| 29989/40960 [01:14<00:26, 415.48batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  73%|▋| 29989/40960 [01:14<00:26, 415.48batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  73%|▋| 30072/40960 [01:14<00:26, 414.46batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  73%|▋| 30072/40960 [01:14<00:26, 414.46batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30156/40960 [01:15<00:26, 414.87batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30156/40960 [01:15<00:26, 414.87batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30238/40960 [01:15<00:26, 412.01batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30238/40960 [01:15<00:26, 412.01batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30318/40960 [01:15<00:26, 407.80batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30318/40960 [01:15<00:26, 407.80batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30397/40960 [01:15<00:26, 403.89batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30397/40960 [01:15<00:26, 403.89batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30480/40960 [01:15<00:25, 406.37batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  74%|▋| 30480/40960 [01:15<00:25, 406.37batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▋| 30565/40960 [01:16<00:25, 411.29batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▋| 30565/40960 [01:16<00:25, 411.29batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▋| 30649/40960 [01:16<00:24, 413.82batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▋| 30649/40960 [01:16<00:24, 413.82batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▊| 30734/40960 [01:16<00:24, 416.26batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▊| 30734/40960 [01:16<00:24, 416.26batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▊| 30818/40960 [01:16<00:24, 417.07batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▊| 30818/40960 [01:16<00:24, 417.07batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▊| 30899/40960 [01:16<00:24, 412.67batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  75%|▊| 30899/40960 [01:16<00:24, 412.67batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 30983/40960 [01:17<00:24, 414.40batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 30983/40960 [01:17<00:24, 414.40batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 31068/40960 [01:17<00:23, 416.42batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 31068/40960 [01:17<00:23, 416.42batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 31151/40960 [01:17<00:23, 414.66batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 31151/40960 [01:17<00:23, 414.66batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 31235/40960 [01:17<00:23, 414.90batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 31235/40960 [01:17<00:23, 414.90batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 31320/40960 [01:17<00:23, 417.49batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  76%|▊| 31320/40960 [01:17<00:23, 417.49batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  77%|▊| 31404/40960 [01:18<00:22, 417.65batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  77%|▊| 31404/40960 [01:18<00:22, 417.65batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  77%|▊| 31488/40960 [01:18<00:22, 417.60batches/s, l2_loss: 0.0187 - round_los\u001b[A\n",
      "Training:  77%|▊| 31488/40960 [01:18<00:22, 417.60batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  77%|▊| 31569/40960 [01:18<00:22, 412.80batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  77%|▊| 31569/40960 [01:18<00:22, 412.80batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  77%|▊| 31652/40960 [01:18<00:22, 412.36batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  77%|▊| 31652/40960 [01:18<00:22, 412.36batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  77%|▊| 31737/40960 [01:18<00:22, 414.86batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  77%|▊| 31737/40960 [01:18<00:22, 414.86batches/s, l2_loss: 0.0188 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|▊| 31821/40960 [01:19<00:22, 415.32batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 31821/40960 [01:19<00:22, 415.32batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 31904/40960 [01:19<00:21, 414.28batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 31904/40960 [01:19<00:21, 414.28batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 31988/40960 [01:19<00:21, 415.38batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 31988/40960 [01:19<00:21, 415.38batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 32071/40960 [01:19<00:21, 414.07batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 32071/40960 [01:19<00:21, 414.07batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 32153/40960 [01:20<00:21, 412.43batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  78%|▊| 32153/40960 [01:20<00:21, 412.43batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32233/40960 [01:20<00:21, 408.33batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32233/40960 [01:20<00:21, 408.33batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32317/40960 [01:20<00:21, 410.87batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32317/40960 [01:20<00:21, 410.87batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32399/40960 [01:20<00:20, 410.24batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32399/40960 [01:20<00:20, 410.24batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32473/40960 [01:20<00:21, 397.69batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32473/40960 [01:20<00:21, 397.69batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32552/40960 [01:21<00:21, 396.42batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  79%|▊| 32552/40960 [01:21<00:21, 396.42batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  80%|▊| 32633/40960 [01:21<00:20, 398.69batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  80%|▊| 32633/40960 [01:21<00:20, 398.69batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  80%|▊| 32718/40960 [01:21<00:20, 406.43batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  80%|▊| 32718/40960 [01:21<00:20, 406.43batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  80%|▊| 32795/40960 [01:21<00:20, 399.47batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  80%|▊| 32795/40960 [01:21<00:20, 399.47batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  80%|▊| 32873/40960 [01:21<00:20, 396.01batches/s, l2_loss: 0.0188 - round_los\u001b[A\n",
      "Training:  80%|▊| 32873/40960 [01:21<00:20, 396.01batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  80%|▊| 32956/40960 [01:22<00:19, 400.72batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  80%|▊| 32956/40960 [01:22<00:19, 400.72batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33038/40960 [01:22<00:19, 403.16batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33038/40960 [01:22<00:19, 403.16batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33114/40960 [01:22<00:19, 394.70batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33114/40960 [01:22<00:19, 394.70batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33181/40960 [01:22<00:20, 376.12batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33181/40960 [01:22<00:20, 376.12batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33257/40960 [01:22<00:20, 376.47batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33257/40960 [01:22<00:20, 376.47batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33339/40960 [01:23<00:19, 386.42batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  81%|▊| 33339/40960 [01:23<00:19, 386.42batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33416/40960 [01:23<00:19, 385.99batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33416/40960 [01:23<00:19, 385.99batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33486/40960 [01:23<00:19, 374.16batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33486/40960 [01:23<00:19, 374.16batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33567/40960 [01:23<00:19, 383.07batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33567/40960 [01:23<00:19, 383.07batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33633/40960 [01:23<00:19, 366.99batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33633/40960 [01:23<00:19, 366.99batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33714/40960 [01:24<00:19, 378.29batches/s, l2_loss: 0.0189 - round_los\u001b[A\n",
      "Training:  82%|▊| 33714/40960 [01:24<00:19, 378.29batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  82%|▊| 33791/40960 [01:24<00:18, 379.79batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  82%|▊| 33791/40960 [01:24<00:18, 379.79batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 33866/40960 [01:24<00:18, 377.37batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 33866/40960 [01:24<00:18, 377.37batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 33946/40960 [01:24<00:18, 384.08batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 33946/40960 [01:24<00:18, 384.08batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 34018/40960 [01:24<00:18, 376.03batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 34018/40960 [01:24<00:18, 376.03batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 34096/40960 [01:25<00:18, 378.66batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 34096/40960 [01:25<00:18, 378.66batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 34178/40960 [01:25<00:17, 387.22batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  83%|▊| 34178/40960 [01:25<00:17, 387.22batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34249/40960 [01:25<00:17, 376.86batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34249/40960 [01:25<00:17, 376.86batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34321/40960 [01:25<00:17, 371.18batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34321/40960 [01:25<00:17, 371.18batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34400/40960 [01:25<00:17, 377.32batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34400/40960 [01:25<00:17, 377.32batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34470/40960 [01:26<00:17, 368.48batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34470/40960 [01:26<00:17, 368.48batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34542/40960 [01:26<00:17, 365.23batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  84%|▊| 34542/40960 [01:26<00:17, 365.23batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  85%|▊| 34613/40960 [01:26<00:17, 361.20batches/s, l2_loss: 0.0190 - round_los\u001b[A\n",
      "Training:  85%|▊| 34613/40960 [01:26<00:17, 361.20batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 34689/40960 [01:26<00:17, 365.63batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 34689/40960 [01:26<00:17, 365.63batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 34763/40960 [01:26<00:16, 366.62batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 34763/40960 [01:26<00:16, 366.62batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 34844/40960 [01:27<00:16, 376.96batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 34844/40960 [01:27<00:16, 376.96batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 34926/40960 [01:27<00:15, 386.06batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 34926/40960 [01:27<00:15, 386.06batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 35004/40960 [01:27<00:15, 386.11batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  85%|▊| 35004/40960 [01:27<00:15, 386.11batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  86%|▊| 35077/40960 [01:27<00:15, 379.14batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  86%|▊| 35077/40960 [01:27<00:15, 379.14batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  86%|▊| 35151/40960 [01:27<00:15, 374.81batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  86%|▊| 35151/40960 [01:27<00:15, 374.81batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  86%|▊| 35223/40960 [01:28<00:15, 369.98batches/s, l2_loss: 0.0191 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|▊| 35223/40960 [01:28<00:15, 369.98batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  86%|▊| 35298/40960 [01:28<00:15, 370.60batches/s, l2_loss: 0.0191 - round_los\u001b[A\n",
      "Training:  86%|▊| 35298/40960 [01:28<00:15, 370.60batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  86%|▊| 35373/40960 [01:28<00:15, 370.99batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  86%|▊| 35373/40960 [01:28<00:15, 370.99batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35448/40960 [01:28<00:14, 371.14batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35448/40960 [01:28<00:14, 371.14batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35524/40960 [01:28<00:14, 373.06batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35524/40960 [01:28<00:14, 373.06batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35600/40960 [01:29<00:14, 373.84batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35600/40960 [01:29<00:14, 373.84batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35673/40960 [01:29<00:14, 370.56batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35673/40960 [01:29<00:14, 370.56batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35746/40960 [01:29<00:14, 367.89batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35746/40960 [01:29<00:14, 367.89batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35818/40960 [01:29<00:14, 364.68batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  87%|▊| 35818/40960 [01:29<00:14, 364.68batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  88%|▉| 35891/40960 [01:29<00:13, 363.96batches/s, l2_loss: 0.0192 - round_los\u001b[A\n",
      "Training:  88%|▉| 35891/40960 [01:29<00:13, 363.96batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  88%|▉| 35971/40960 [01:30<00:13, 373.69batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  88%|▉| 35971/40960 [01:30<00:13, 373.69batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  88%|▉| 36053/40960 [01:30<00:12, 383.29batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  88%|▉| 36053/40960 [01:30<00:12, 383.29batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  88%|▉| 36134/40960 [01:30<00:12, 388.83batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  88%|▉| 36134/40960 [01:30<00:12, 388.83batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  88%|▉| 36209/40960 [01:30<00:12, 383.65batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  88%|▉| 36209/40960 [01:30<00:12, 383.65batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  89%|▉| 36293/40960 [01:30<00:11, 393.56batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  89%|▉| 36293/40960 [01:30<00:11, 393.56batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  89%|▉| 36371/40960 [01:31<00:11, 392.01batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  89%|▉| 36371/40960 [01:31<00:11, 392.01batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  89%|▉| 36455/40960 [01:31<00:11, 399.39batches/s, l2_loss: 0.0193 - round_los\u001b[A\n",
      "Training:  89%|▉| 36455/40960 [01:31<00:11, 399.39batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  89%|▉| 36534/40960 [01:31<00:11, 397.61batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  89%|▉| 36534/40960 [01:31<00:11, 397.61batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  89%|▉| 36614/40960 [01:31<00:10, 397.82batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  89%|▉| 36614/40960 [01:31<00:10, 397.82batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 36689/40960 [01:31<00:10, 390.45batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 36689/40960 [01:31<00:10, 390.45batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 36768/40960 [01:32<00:10, 391.47batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 36768/40960 [01:32<00:10, 391.47batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 36851/40960 [01:32<00:10, 398.12batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 36851/40960 [01:32<00:10, 398.12batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 36932/40960 [01:32<00:10, 399.01batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 36932/40960 [01:32<00:10, 399.01batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 37014/40960 [01:32<00:09, 400.93batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  90%|▉| 37014/40960 [01:32<00:09, 400.93batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  91%|▉| 37093/40960 [01:32<00:09, 399.05batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  91%|▉| 37093/40960 [01:32<00:09, 399.05batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  91%|▉| 37175/40960 [01:33<00:09, 401.14batches/s, l2_loss: 0.0194 - round_los\u001b[A\n",
      "Training:  91%|▉| 37175/40960 [01:33<00:09, 401.14batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  91%|▉| 37257/40960 [01:33<00:09, 403.75batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  91%|▉| 37257/40960 [01:33<00:09, 403.75batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  91%|▉| 37338/40960 [01:33<00:08, 403.01batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  91%|▉| 37338/40960 [01:33<00:08, 403.01batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  91%|▉| 37410/40960 [01:33<00:09, 389.75batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  91%|▉| 37410/40960 [01:33<00:09, 389.75batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  92%|▉| 37494/40960 [01:33<00:08, 398.04batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  92%|▉| 37494/40960 [01:33<00:08, 398.04batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  92%|▉| 37576/40960 [01:34<00:08, 400.46batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  92%|▉| 37576/40960 [01:34<00:08, 400.46batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  92%|▉| 37649/40960 [01:34<00:08, 389.59batches/s, l2_loss: 0.0195 - round_los\u001b[A\n",
      "Training:  92%|▉| 37649/40960 [01:34<00:08, 389.59batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  92%|▉| 37727/40960 [01:34<00:08, 389.20batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  92%|▉| 37727/40960 [01:34<00:08, 389.20batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  92%|▉| 37806/40960 [01:34<00:08, 390.04batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  92%|▉| 37806/40960 [01:34<00:08, 390.04batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  92%|▉| 37884/40960 [01:34<00:07, 389.14batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  92%|▉| 37884/40960 [01:34<00:07, 389.14batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  93%|▉| 37959/40960 [01:35<00:07, 384.57batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  93%|▉| 37959/40960 [01:35<00:07, 384.57batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  93%|▉| 38043/40960 [01:35<00:07, 394.55batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  93%|▉| 38043/40960 [01:35<00:07, 394.55batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  93%|▉| 38125/40960 [01:35<00:07, 399.08batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  93%|▉| 38125/40960 [01:35<00:07, 399.08batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  93%|▉| 38203/40960 [01:35<00:06, 396.02batches/s, l2_loss: 0.0196 - round_los\u001b[A\n",
      "Training:  93%|▉| 38203/40960 [01:35<00:06, 396.02batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  93%|▉| 38277/40960 [01:35<00:06, 387.76batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  93%|▉| 38277/40960 [01:35<00:06, 387.76batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  94%|▉| 38354/40960 [01:36<00:06, 385.52batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  94%|▉| 38354/40960 [01:36<00:06, 385.52batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  94%|▉| 38425/40960 [01:36<00:06, 374.99batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  94%|▉| 38425/40960 [01:36<00:06, 374.99batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  94%|▉| 38657/40960 [01:36<00:03, 609.01batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  94%|▉| 38657/40960 [01:36<00:03, 609.01batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  95%|▉| 38729/40960 [01:36<00:04, 533.14batches/s, l2_loss: 0.0197 - round_los\u001b[A\n",
      "Training:  95%|▉| 38729/40960 [01:36<00:04, 533.14batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 38805/40960 [01:36<00:04, 486.96batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 38805/40960 [01:36<00:04, 486.96batches/s, l2_loss: 0.0198 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 38885/40960 [01:37<00:04, 460.12batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 38885/40960 [01:37<00:04, 460.12batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 38954/40960 [01:37<00:04, 424.53batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 38954/40960 [01:37<00:04, 424.53batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 39010/40960 [01:37<00:05, 380.90batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 39010/40960 [01:37<00:05, 380.90batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 39074/40960 [01:37<00:05, 362.04batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  95%|▉| 39074/40960 [01:37<00:05, 362.04batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  96%|▉| 39153/40960 [01:37<00:04, 370.72batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  96%|▉| 39153/40960 [01:37<00:04, 370.72batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  96%|▉| 39235/40960 [01:38<00:04, 381.69batches/s, l2_loss: 0.0198 - round_los\u001b[A\n",
      "Training:  96%|▉| 39235/40960 [01:38<00:04, 381.69batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  96%|▉| 39317/40960 [01:38<00:04, 390.12batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  96%|▉| 39317/40960 [01:38<00:04, 390.12batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  96%|▉| 39396/40960 [01:38<00:03, 391.15batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  96%|▉| 39396/40960 [01:38<00:03, 391.15batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  96%|▉| 39474/40960 [01:38<00:03, 390.36batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  96%|▉| 39474/40960 [01:38<00:03, 390.36batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  97%|▉| 39555/40960 [01:38<00:03, 394.02batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  97%|▉| 39555/40960 [01:38<00:03, 394.02batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  97%|▉| 39630/40960 [01:39<00:03, 388.26batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  97%|▉| 39630/40960 [01:39<00:03, 388.26batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  97%|▉| 39708/40960 [01:39<00:03, 387.32batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  97%|▉| 39708/40960 [01:39<00:03, 387.32batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  97%|▉| 39787/40960 [01:39<00:03, 388.51batches/s, l2_loss: 0.0199 - round_los\u001b[A\n",
      "Training:  97%|▉| 39787/40960 [01:39<00:03, 388.51batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  97%|▉| 39870/40960 [01:39<00:02, 395.68batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  97%|▉| 39870/40960 [01:39<00:02, 395.68batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 39951/40960 [01:39<00:02, 397.58batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 39951/40960 [01:39<00:02, 397.58batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 40035/40960 [01:40<00:02, 403.69batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 40035/40960 [01:40<00:02, 403.69batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 40118/40960 [01:40<00:02, 406.43batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 40118/40960 [01:40<00:02, 406.43batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 40198/40960 [01:40<00:01, 403.88batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 40198/40960 [01:40<00:01, 403.88batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 40277/40960 [01:40<00:01, 400.77batches/s, l2_loss: 0.0200 - round_los\u001b[A\n",
      "Training:  98%|▉| 40277/40960 [01:40<00:01, 400.77batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40354/40960 [01:40<00:01, 394.67batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40354/40960 [01:40<00:01, 394.67batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40434/40960 [01:41<00:01, 395.47batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40434/40960 [01:41<00:01, 395.47batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40514/40960 [01:41<00:01, 395.63batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40514/40960 [01:41<00:01, 395.63batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40593/40960 [01:41<00:00, 395.32batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40593/40960 [01:41<00:00, 395.32batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40672/40960 [01:41<00:00, 393.47batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40672/40960 [01:41<00:00, 393.47batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40752/40960 [01:41<00:00, 394.82batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training:  99%|▉| 40752/40960 [01:41<00:00, 394.82batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training: 100%|▉| 40829/40960 [01:42<00:00, 391.82batches/s, l2_loss: 0.0201 - round_los\u001b[A\n",
      "Training: 100%|▉| 40829/40960 [01:42<00:00, 391.82batches/s, l2_loss: 0.0202 - round_los\u001b[A\n",
      "Training: 100%|▉| 40908/40960 [01:42<00:00, 392.02batches/s, l2_loss: 0.0202 - round_los\u001b[A\n",
      "Training: 100%|▉| 40908/40960 [01:42<00:00, 392.02batches/s, l2_loss: 0.0202 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 14:53:01.256765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  12%| | 3/26 [05:21<41:01, 107.02s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 14:53:02.580176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 14:53:05.337128: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<10:59:16,  1.04batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:59:16,  1.04batches/s, l2_loss: 0.0183 - round_loss:\u001b[A\n",
      "Training:   0%| | 91/40960 [00:01<06:35, 103.36batches/s, l2_loss: 0.0183 - round_loss: \u001b[A\n",
      "Training:   0%| | 91/40960 [00:01<06:35, 103.36batches/s, l2_loss: 0.0135 - round_loss: \u001b[A\n",
      "Training:   0%| | 180/40960 [00:01<03:38, 186.91batches/s, l2_loss: 0.0135 - round_loss:\u001b[A\n",
      "Training:   0%| | 180/40960 [00:01<03:38, 186.91batches/s, l2_loss: 0.0115 - round_loss:\u001b[A\n",
      "Training:   1%| | 267/40960 [00:01<02:42, 250.81batches/s, l2_loss: 0.0115 - round_loss:\u001b[A\n",
      "Training:   1%| | 267/40960 [00:01<02:42, 250.81batches/s, l2_loss: 0.0114 - round_loss:\u001b[A\n",
      "Training:   1%| | 355/40960 [00:01<02:14, 301.13batches/s, l2_loss: 0.0114 - round_loss:\u001b[A\n",
      "Training:   1%| | 355/40960 [00:01<02:14, 301.13batches/s, l2_loss: 0.0109 - round_loss:\u001b[A\n",
      "Training:   1%| | 442/40960 [00:01<01:59, 337.89batches/s, l2_loss: 0.0109 - round_loss:\u001b[A\n",
      "Training:   1%| | 442/40960 [00:01<01:59, 337.89batches/s, l2_loss: 0.0102 - round_loss:\u001b[A\n",
      "Training:   1%| | 522/40960 [00:02<01:53, 355.41batches/s, l2_loss: 0.0102 - round_loss:\u001b[A\n",
      "Training:   1%| | 522/40960 [00:02<01:53, 355.41batches/s, l2_loss: 0.0101 - round_loss:\u001b[A\n",
      "Training:   1%| | 606/40960 [00:02<01:47, 373.99batches/s, l2_loss: 0.0101 - round_loss:\u001b[A\n",
      "Training:   1%| | 606/40960 [00:02<01:47, 373.99batches/s, l2_loss: 0.0099 - round_loss:\u001b[A\n",
      "Training:   2%| | 690/40960 [00:02<01:43, 387.33batches/s, l2_loss: 0.0099 - round_loss:\u001b[A\n",
      "Training:   2%| | 690/40960 [00:02<01:43, 387.33batches/s, l2_loss: 0.0096 - round_loss:\u001b[A\n",
      "Training:   2%| | 763/40960 [00:02<01:46, 379.01batches/s, l2_loss: 0.0096 - round_loss:\u001b[A\n",
      "Training:   2%| | 763/40960 [00:02<01:46, 379.01batches/s, l2_loss: 0.0094 - round_loss:\u001b[A\n",
      "Training:   2%| | 820/40960 [00:02<01:54, 350.12batches/s, l2_loss: 0.0094 - round_loss:\u001b[A\n",
      "Training:   2%| | 820/40960 [00:02<01:54, 350.12batches/s, l2_loss: 0.0094 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%| | 889/40960 [00:03<01:55, 348.31batches/s, l2_loss: 0.0094 - round_loss:\u001b[A\n",
      "Training:   2%| | 889/40960 [00:03<01:55, 348.31batches/s, l2_loss: 0.0092 - round_loss:\u001b[A\n",
      "Training:   2%| | 979/40960 [00:03<01:45, 378.32batches/s, l2_loss: 0.0092 - round_loss:\u001b[A\n",
      "Training:   2%| | 979/40960 [00:03<01:45, 378.32batches/s, l2_loss: 0.0090 - round_loss:\u001b[A\n",
      "Training:   3%| | 1072/40960 [00:03<01:38, 403.82batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:   3%| | 1072/40960 [00:03<01:38, 403.82batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:   3%| | 1166/40960 [00:03<01:33, 423.50batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:   3%| | 1166/40960 [00:03<01:33, 423.50batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:   3%| | 1260/40960 [00:03<01:30, 436.84batches/s, l2_loss: 0.0086 - round_loss\u001b[A\n",
      "Training:   3%| | 1260/40960 [00:03<01:30, 436.84batches/s, l2_loss: 0.0085 - round_loss\u001b[A\n",
      "Training:   3%| | 1350/40960 [00:04<01:30, 439.97batches/s, l2_loss: 0.0085 - round_loss\u001b[A\n",
      "Training:   3%| | 1350/40960 [00:04<01:30, 439.97batches/s, l2_loss: 0.0085 - round_loss\u001b[A\n",
      "Training:   4%| | 1438/40960 [00:04<01:29, 439.93batches/s, l2_loss: 0.0085 - round_loss\u001b[A\n",
      "Training:   4%| | 1438/40960 [00:04<01:29, 439.93batches/s, l2_loss: 0.0083 - round_loss\u001b[A\n",
      "Training:   4%| | 1526/40960 [00:04<01:29, 438.50batches/s, l2_loss: 0.0083 - round_loss\u001b[A\n",
      "Training:   4%| | 1526/40960 [00:04<01:29, 438.50batches/s, l2_loss: 0.0082 - round_loss\u001b[A\n",
      "Training:   4%| | 1615/40960 [00:04<01:29, 440.14batches/s, l2_loss: 0.0082 - round_loss\u001b[A\n",
      "Training:   4%| | 1615/40960 [00:04<01:29, 440.14batches/s, l2_loss: 0.0081 - round_loss\u001b[A\n",
      "Training:   4%| | 1705/40960 [00:04<01:28, 442.23batches/s, l2_loss: 0.0081 - round_loss\u001b[A\n",
      "Training:   4%| | 1705/40960 [00:04<01:28, 442.23batches/s, l2_loss: 0.0080 - round_loss\u001b[A\n",
      "Training:   4%| | 1797/40960 [00:05<01:27, 446.42batches/s, l2_loss: 0.0080 - round_loss\u001b[A\n",
      "Training:   4%| | 1797/40960 [00:05<01:27, 446.42batches/s, l2_loss: 0.0080 - round_loss\u001b[A\n",
      "Training:   5%| | 1888/40960 [00:05<01:27, 448.65batches/s, l2_loss: 0.0080 - round_loss\u001b[A\n",
      "Training:   5%| | 1888/40960 [00:05<01:27, 448.65batches/s, l2_loss: 0.0079 - round_loss\u001b[A\n",
      "Training:   5%| | 1974/40960 [00:05<01:28, 442.11batches/s, l2_loss: 0.0079 - round_loss\u001b[A\n",
      "Training:   5%| | 1974/40960 [00:05<01:28, 442.11batches/s, l2_loss: 0.0079 - round_loss\u001b[A\n",
      "Training:   5%| | 2063/40960 [00:05<01:27, 442.70batches/s, l2_loss: 0.0079 - round_loss\u001b[A\n",
      "Training:   5%| | 2063/40960 [00:05<01:27, 442.70batches/s, l2_loss: 0.0078 - round_loss\u001b[A\n",
      "Training:   5%| | 2156/40960 [00:05<01:26, 448.49batches/s, l2_loss: 0.0078 - round_loss\u001b[A\n",
      "Training:   5%| | 2156/40960 [00:05<01:26, 448.49batches/s, l2_loss: 0.0077 - round_loss\u001b[A\n",
      "Training:   5%| | 2247/40960 [00:06<01:26, 449.00batches/s, l2_loss: 0.0077 - round_loss\u001b[A\n",
      "Training:   5%| | 2247/40960 [00:06<01:26, 449.00batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   6%| | 2328/40960 [00:06<01:28, 434.47batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   6%| | 2328/40960 [00:06<01:28, 434.47batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   6%| | 2408/40960 [00:06<01:31, 423.60batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   6%| | 2408/40960 [00:06<01:31, 423.60batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   6%| | 2494/40960 [00:06<01:30, 424.68batches/s, l2_loss: 0.0076 - round_loss\u001b[A\n",
      "Training:   6%| | 2494/40960 [00:06<01:30, 424.68batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2584/40960 [00:06<01:28, 432.05batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   6%| | 2584/40960 [00:07<01:28, 432.05batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 2676/40960 [00:07<01:27, 439.26batches/s, l2_loss: 0.0075 - round_loss\u001b[A\n",
      "Training:   7%| | 2676/40960 [00:07<01:27, 439.26batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:   7%| | 2763/40960 [00:07<01:27, 437.54batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:   7%| | 2763/40960 [00:07<01:27, 437.54batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:   7%| | 2853/40960 [00:07<01:26, 440.46batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:   7%| | 2853/40960 [00:07<01:26, 440.46batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:   7%| | 2942/40960 [00:07<01:26, 441.11batches/s, l2_loss: 0.0074 - round_loss\u001b[A\n",
      "Training:   7%| | 2942/40960 [00:07<01:26, 441.11batches/s, l2_loss: 0.0073 - round_loss\u001b[A\n",
      "Training:   7%| | 3023/40960 [00:08<01:28, 429.00batches/s, l2_loss: 0.0073 - round_loss\u001b[A\n",
      "Training:   7%| | 3023/40960 [00:08<01:28, 429.00batches/s, l2_loss: 0.0073 - round_loss\u001b[A\n",
      "Training:   8%| | 3112/40960 [00:08<01:27, 433.16batches/s, l2_loss: 0.0073 - round_loss\u001b[A\n",
      "Training:   8%| | 3112/40960 [00:08<01:27, 433.16batches/s, l2_loss: 0.0073 - round_loss\u001b[A\n",
      "Training:   8%| | 3196/40960 [00:08<01:28, 429.11batches/s, l2_loss: 0.0073 - round_loss\u001b[A\n",
      "Training:   8%| | 3196/40960 [00:08<01:28, 429.11batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:   8%| | 3279/40960 [00:08<01:28, 424.86batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:   8%| | 3279/40960 [00:08<01:28, 424.86batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:   8%| | 3354/40960 [00:08<01:32, 408.51batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:   8%| | 3354/40960 [00:08<01:32, 408.51batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:   8%| | 3425/40960 [00:09<01:35, 392.40batches/s, l2_loss: 0.0072 - round_loss\u001b[A\n",
      "Training:   8%| | 3425/40960 [00:09<01:35, 392.40batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:   9%| | 3500/40960 [00:09<01:36, 387.16batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:   9%| | 3500/40960 [00:09<01:36, 387.16batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:   9%| | 3586/40960 [00:09<01:33, 399.63batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:   9%| | 3586/40960 [00:09<01:33, 399.63batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:   9%| | 3672/40960 [00:09<01:31, 408.20batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:   9%| | 3672/40960 [00:09<01:31, 408.20batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:   9%| | 3764/40960 [00:09<01:27, 423.28batches/s, l2_loss: 0.0071 - round_loss\u001b[A\n",
      "Training:   9%| | 3764/40960 [00:09<01:27, 423.28batches/s, l2_loss: 0.0070 - round_loss\u001b[A\n",
      "Training:   9%| | 3854/40960 [00:10<01:26, 430.99batches/s, l2_loss: 0.0070 - round_loss\u001b[A\n",
      "Training:   9%| | 3854/40960 [00:10<01:26, 430.99batches/s, l2_loss: 0.0070 - round_loss\u001b[A\n",
      "Training:  10%| | 3931/40960 [00:10<01:28, 416.97batches/s, l2_loss: 0.0070 - round_loss\u001b[A\n",
      "Training:  10%| | 3931/40960 [00:10<01:28, 416.97batches/s, l2_loss: 0.0070 - round_loss\u001b[A\n",
      "Training:  10%| | 4013/40960 [00:10<01:29, 413.79batches/s, l2_loss: 0.0070 - round_loss\u001b[A\n",
      "Training:  10%| | 4013/40960 [00:10<01:29, 413.79batches/s, l2_loss: 0.0070 - round_loss\u001b[A\n",
      "Training:  10%| | 4097/40960 [00:10<01:29, 412.64batches/s, l2_loss: 0.0070 - round_loss\u001b[A\n",
      "Training:  10%| | 4097/40960 [00:10<01:29, 412.64batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  10%| | 4181/40960 [00:10<01:28, 414.38batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  10%| | 4181/40960 [00:10<01:28, 414.38batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  10%| | 4265/40960 [00:11<01:28, 415.23batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  10%| | 4265/40960 [00:11<01:28, 415.23batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  11%| | 4345/40960 [00:11<01:29, 410.68batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  11%| | 4345/40960 [00:11<01:29, 410.68batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  11%| | 4437/40960 [00:11<01:26, 424.10batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  11%| | 4437/40960 [00:11<01:26, 424.10batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  11%| | 4530/40960 [00:11<01:23, 435.12batches/s, l2_loss: 0.0069 - round_loss\u001b[A\n",
      "Training:  11%| | 4530/40960 [00:11<01:23, 435.12batches/s, l2_loss: 0.0068 - round_loss\u001b[A\n",
      "Training:  11%| | 4622/40960 [00:11<01:22, 442.11batches/s, l2_loss: 0.0068 - round_loss\u001b[A\n",
      "Training:  11%| | 4622/40960 [00:11<01:22, 442.11batches/s, l2_loss: 0.0068 - round_loss\u001b[A\n",
      "Training:  11%| | 4709/40960 [00:12<01:22, 439.96batches/s, l2_loss: 0.0068 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%| | 4709/40960 [00:12<01:22, 439.96batches/s, l2_loss: 0.0068 - round_loss\u001b[A\n",
      "Training:  12%| | 4802/40960 [00:12<01:20, 446.72batches/s, l2_loss: 0.0068 - round_loss\u001b[A\n",
      "Training:  12%| | 4802/40960 [00:12<01:20, 446.72batches/s, l2_loss: 0.0068 - round_loss\u001b[A\n",
      "Training:  12%| | 4896/40960 [00:12<01:19, 453.12batches/s, l2_loss: 0.0068 - round_loss\u001b[A\n",
      "Training:  12%| | 4896/40960 [00:12<01:19, 453.12batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  12%| | 4983/40960 [00:12<01:20, 446.66batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  12%| | 4983/40960 [00:12<01:20, 446.66batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  12%| | 5076/40960 [00:12<01:19, 450.97batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  12%| | 5076/40960 [00:12<01:19, 450.97batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5170/40960 [00:13<01:18, 456.50batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5170/40960 [00:13<01:18, 456.50batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5263/40960 [00:13<01:17, 457.85batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5263/40960 [00:13<01:17, 457.85batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5357/40960 [00:13<01:17, 461.28batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5357/40960 [00:13<01:17, 461.28batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5450/40960 [00:13<01:16, 462.31batches/s, l2_loss: 0.0067 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5450/40960 [00:13<01:16, 462.31batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5542/40960 [00:13<01:16, 460.61batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5542/40960 [00:13<01:16, 460.61batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5634/40960 [00:14<01:16, 459.29batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5634/40960 [00:14<01:16, 459.29batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5728/40960 [00:14<01:16, 462.38batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5728/40960 [00:14<01:16, 462.38batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5818/40960 [00:14<01:16, 458.03batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5818/40960 [00:14<01:16, 458.03batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5911/40960 [00:14<01:16, 459.58batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5911/40960 [00:14<01:16, 459.58batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5998/40960 [00:14<01:17, 451.77batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5998/40960 [00:14<01:17, 451.77batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6071/40960 [00:15<01:21, 425.76batches/s, l2_loss: 0.0066 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6071/40960 [00:15<01:21, 425.76batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6150/40960 [00:15<01:23, 415.63batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6150/40960 [00:15<01:23, 415.63batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6234/40960 [00:15<01:23, 416.40batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6234/40960 [00:15<01:23, 416.40batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6320/40960 [00:15<01:22, 419.86batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6320/40960 [00:15<01:22, 419.86batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6395/40960 [00:15<01:25, 405.53batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6395/40960 [00:15<01:25, 405.53batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6475/40960 [00:16<01:25, 402.35batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6475/40960 [00:16<01:25, 402.35batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6552/40960 [00:16<01:26, 396.31batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6552/40960 [00:16<01:26, 396.31batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6639/40960 [00:16<01:24, 407.85batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6639/40960 [00:16<01:24, 407.85batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6731/40960 [00:16<01:20, 423.22batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6731/40960 [00:16<01:20, 423.22batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6810/40960 [00:16<01:22, 413.84batches/s, l2_loss: 0.0065 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6810/40960 [00:16<01:22, 413.84batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6893/40960 [00:17<01:22, 413.88batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6893/40960 [00:17<01:22, 413.88batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6985/40960 [00:17<01:19, 427.53batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6985/40960 [00:17<01:19, 427.53batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7076/40960 [00:17<01:17, 435.24batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7076/40960 [00:17<01:17, 435.24batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7169/40960 [00:17<01:16, 442.77batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7169/40960 [00:17<01:16, 442.77batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7262/40960 [00:17<01:15, 449.28batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7262/40960 [00:17<01:15, 449.28batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7355/40960 [00:18<01:14, 452.82batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7355/40960 [00:18<01:14, 452.82batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7446/40960 [00:18<01:14, 452.59batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7446/40960 [00:18<01:14, 452.59batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7534/40960 [00:18<01:14, 448.25batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7534/40960 [00:18<01:14, 448.25batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7626/40960 [00:18<01:13, 450.55batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7626/40960 [00:18<01:13, 450.55batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7717/40960 [00:18<01:13, 451.88batches/s, l2_loss: 0.0064 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7717/40960 [00:18<01:13, 451.88batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7792/40960 [00:19<01:17, 427.63batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7792/40960 [00:19<01:17, 427.63batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7877/40960 [00:19<01:17, 426.37batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7877/40960 [00:19<01:17, 426.37batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7953/40960 [00:19<01:20, 411.72batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7953/40960 [00:19<01:20, 411.72batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8037/40960 [00:19<01:19, 413.95batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8037/40960 [00:19<01:19, 413.95batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8132/40960 [00:19<01:15, 431.95batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8132/40960 [00:19<01:15, 431.95batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8210/40960 [00:20<01:18, 417.84batches/s, l2_loss: 0.0063 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8210/40960 [00:20<01:18, 417.84batches/s, l2_loss: 0.0052 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8287/40960 [00:20<01:20, 406.75batches/s, l2_loss: 0.0052 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8287/40960 [00:20<01:20, 406.75batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8370/40960 [00:20<01:19, 408.28batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8370/40960 [00:20<01:19, 408.28batches/s, l2_loss: 0.0057 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8450/40960 [00:20<01:20, 405.38batches/s, l2_loss: 0.0057 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8450/40960 [00:20<01:20, 405.38batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8534/40960 [00:20<01:19, 408.76batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8534/40960 [00:20<01:19, 408.76batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|▏| 8614/40960 [00:21<01:19, 405.94batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8614/40960 [00:21<01:19, 405.94batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8693/40960 [00:21<01:20, 401.98batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8693/40960 [00:21<01:20, 401.98batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8776/40960 [00:21<01:19, 404.49batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8776/40960 [00:21<01:19, 404.49batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8861/40960 [00:21<01:18, 409.39batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8861/40960 [00:21<01:18, 409.39batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8939/40960 [00:21<01:19, 403.48batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8939/40960 [00:21<01:19, 403.48batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9016/40960 [00:22<01:20, 397.22batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9016/40960 [00:22<01:20, 397.22batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9095/40960 [00:22<01:20, 395.30batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9095/40960 [00:22<01:20, 395.30batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9173/40960 [00:22<01:20, 392.81batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9173/40960 [00:22<01:20, 392.81batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9249/40960 [00:22<01:21, 387.65batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9249/40960 [00:22<01:21, 387.65batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9333/40960 [00:22<01:19, 396.22batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9333/40960 [00:22<01:19, 396.22batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9416/40960 [00:23<01:18, 401.50batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9416/40960 [00:23<01:18, 401.50batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9498/40960 [00:23<01:18, 403.35batches/s, l2_loss: 0.0058 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9498/40960 [00:23<01:18, 403.35batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9578/40960 [00:23<01:18, 402.18batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9578/40960 [00:23<01:18, 402.18batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9655/40960 [00:23<01:19, 396.06batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9655/40960 [00:23<01:19, 396.06batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9734/40960 [00:23<01:19, 395.03batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9734/40960 [00:23<01:19, 395.03batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9817/40960 [00:24<01:17, 399.95batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9817/40960 [00:24<01:17, 399.95batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9896/40960 [00:24<01:18, 397.84batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9896/40960 [00:24<01:18, 397.84batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9978/40960 [00:24<01:17, 400.94batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9978/40960 [00:24<01:17, 400.94batches/s, l2_loss: 0.0059 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10055/40960 [00:24<01:18, 395.78batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▏| 10055/40960 [00:24<01:18, 395.78batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▏| 10135/40960 [00:24<01:17, 395.83batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▏| 10135/40960 [00:24<01:17, 395.83batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▏| 10214/40960 [00:25<01:17, 394.45batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▏| 10214/40960 [00:25<01:17, 394.45batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▎| 10293/40960 [00:25<01:17, 393.79batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▎| 10293/40960 [00:25<01:17, 393.79batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▎| 10375/40960 [00:25<01:16, 397.50batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  25%|▎| 10375/40960 [00:25<01:16, 397.50batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  26%|▎| 10454/40960 [00:25<01:17, 395.93batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  26%|▎| 10454/40960 [00:25<01:17, 395.93batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  26%|▎| 10534/40960 [00:25<01:16, 396.98batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  26%|▎| 10534/40960 [00:25<01:16, 396.98batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  26%|▎| 10616/40960 [00:26<01:15, 400.18batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  26%|▎| 10616/40960 [00:26<01:15, 400.18batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  26%|▎| 10695/40960 [00:26<01:15, 398.36batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  26%|▎| 10695/40960 [00:26<01:15, 398.36batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  26%|▎| 10777/40960 [00:26<01:15, 400.79batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  26%|▎| 10777/40960 [00:26<01:15, 400.79batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  27%|▎| 10856/40960 [00:26<01:15, 399.00batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  27%|▎| 10856/40960 [00:26<01:15, 399.00batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  27%|▎| 10941/40960 [00:26<01:14, 405.48batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  27%|▎| 10941/40960 [00:26<01:14, 405.48batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  27%|▎| 11022/40960 [00:27<01:13, 404.66batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  27%|▎| 11022/40960 [00:27<01:13, 404.66batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  27%|▎| 11104/40960 [00:27<01:13, 405.76batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  27%|▎| 11104/40960 [00:27<01:13, 405.76batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  27%|▎| 11184/40960 [00:27<01:13, 403.75batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  27%|▎| 11184/40960 [00:27<01:13, 403.75batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  28%|▎| 11266/40960 [00:27<01:13, 404.82batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  28%|▎| 11266/40960 [00:27<01:13, 404.82batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  28%|▎| 11350/40960 [00:27<01:12, 408.50batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  28%|▎| 11350/40960 [00:27<01:12, 408.50batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  28%|▎| 11431/40960 [00:28<01:12, 406.69batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  28%|▎| 11431/40960 [00:28<01:12, 406.69batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  28%|▎| 11512/40960 [00:28<01:12, 405.80batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  28%|▎| 11512/40960 [00:28<01:12, 405.80batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  28%|▎| 11597/40960 [00:28<01:11, 410.82batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  28%|▎| 11597/40960 [00:28<01:11, 410.82batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  29%|▎| 11676/40960 [00:28<01:12, 405.41batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  29%|▎| 11676/40960 [00:28<01:12, 405.41batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  29%|▎| 11759/40960 [00:28<01:11, 407.90batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  29%|▎| 11759/40960 [00:28<01:11, 407.90batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  29%|▎| 11840/40960 [00:29<01:11, 406.52batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  29%|▎| 11840/40960 [00:29<01:11, 406.52batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  29%|▎| 11922/40960 [00:29<01:11, 407.11batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  29%|▎| 11922/40960 [00:29<01:11, 407.11batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  29%|▎| 12001/40960 [00:29<01:11, 403.44batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  29%|▎| 12001/40960 [00:29<01:11, 403.44batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  29%|▎| 12082/40960 [00:29<01:11, 402.64batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  29%|▎| 12082/40960 [00:29<01:11, 402.64batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12165/40960 [00:29<01:10, 405.58batches/s, l2_loss: 0.0058 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 12165/40960 [00:29<01:10, 405.58batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12248/40960 [00:30<01:10, 407.77batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12248/40960 [00:30<01:10, 407.77batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12327/40960 [00:30<01:11, 403.15batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12327/40960 [00:30<01:11, 403.15batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12408/40960 [00:30<01:10, 403.15batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12408/40960 [00:30<01:10, 403.15batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12490/40960 [00:30<01:10, 403.91batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  30%|▎| 12490/40960 [00:30<01:10, 403.91batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12565/40960 [00:30<01:11, 395.13batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12565/40960 [00:30<01:11, 395.13batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12639/40960 [00:31<01:13, 386.56batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12639/40960 [00:31<01:13, 386.56batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12718/40960 [00:31<01:12, 388.60batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12718/40960 [00:31<01:12, 388.60batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12781/40960 [00:31<01:17, 365.77batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12781/40960 [00:31<01:17, 365.77batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12840/40960 [00:31<01:21, 343.51batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  31%|▎| 12840/40960 [00:31<01:21, 343.51batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 12913/40960 [00:31<01:20, 348.86batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 12913/40960 [00:31<01:20, 348.86batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 12995/40960 [00:32<01:16, 366.74batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 12995/40960 [00:32<01:16, 366.74batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 13077/40960 [00:32<01:13, 379.57batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 13077/40960 [00:32<01:13, 379.57batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 13157/40960 [00:32<01:12, 384.89batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 13157/40960 [00:32<01:12, 384.89batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 13239/40960 [00:32<01:10, 392.31batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  32%|▎| 13239/40960 [00:32<01:10, 392.31batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13323/40960 [00:32<01:09, 399.40batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13323/40960 [00:32<01:09, 399.40batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13408/40960 [00:33<01:07, 406.01batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13408/40960 [00:33<01:07, 406.01batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13491/40960 [00:33<01:07, 407.89batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13491/40960 [00:33<01:07, 407.89batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13572/40960 [00:33<01:07, 406.83batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13572/40960 [00:33<01:07, 406.83batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13653/40960 [00:33<01:07, 406.01batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13653/40960 [00:33<01:07, 406.01batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13718/40960 [00:33<01:11, 380.89batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  33%|▎| 13718/40960 [00:33<01:11, 380.89batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 13795/40960 [00:34<01:11, 381.56batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 13795/40960 [00:34<01:11, 381.56batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 13876/40960 [00:34<01:09, 387.94batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 13876/40960 [00:34<01:09, 387.94batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 13952/40960 [00:34<01:10, 385.51batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 13952/40960 [00:34<01:10, 385.51batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 14031/40960 [00:34<01:09, 387.28batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 14031/40960 [00:34<01:09, 387.28batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 14104/40960 [00:34<01:10, 380.10batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  34%|▎| 14104/40960 [00:34<01:10, 380.10batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14178/40960 [00:35<01:11, 375.48batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14178/40960 [00:35<01:11, 375.48batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14248/40960 [00:35<01:12, 367.16batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14248/40960 [00:35<01:12, 367.16batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14322/40960 [00:35<01:12, 367.20batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14322/40960 [00:35<01:12, 367.20batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14398/40960 [00:35<01:11, 370.05batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14398/40960 [00:35<01:11, 370.05batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14475/40960 [00:35<01:10, 373.84batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  35%|▎| 14475/40960 [00:35<01:10, 373.84batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14541/40960 [00:36<01:13, 360.76batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14541/40960 [00:36<01:13, 360.76batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14615/40960 [00:36<01:12, 363.47batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14615/40960 [00:36<01:12, 363.47batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14685/40960 [00:36<01:13, 359.25batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14685/40960 [00:36<01:13, 359.25batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14755/40960 [00:36<01:13, 355.01batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14755/40960 [00:36<01:13, 355.01batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14833/40960 [00:36<01:11, 365.25batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14833/40960 [00:36<01:11, 365.25batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14900/40960 [00:37<01:13, 355.57batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  36%|▎| 14900/40960 [00:37<01:13, 355.57batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 14982/40960 [00:37<01:10, 370.97batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 14982/40960 [00:37<01:10, 370.97batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 15060/40960 [00:37<01:08, 376.35batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 15060/40960 [00:37<01:08, 376.35batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 15138/40960 [00:37<01:08, 379.63batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 15138/40960 [00:37<01:08, 379.63batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 15216/40960 [00:37<01:07, 382.69batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 15216/40960 [00:37<01:07, 382.69batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 15295/40960 [00:38<01:06, 386.06batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  37%|▎| 15295/40960 [00:38<01:06, 386.06batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15375/40960 [00:38<01:05, 389.80batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15375/40960 [00:38<01:05, 389.80batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15450/40960 [00:38<01:06, 384.90batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15450/40960 [00:38<01:06, 384.90batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15523/40960 [00:38<01:07, 378.90batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15523/40960 [00:38<01:07, 378.90batches/s, l2_loss: 0.0058 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|▍| 15602/40960 [00:38<01:06, 382.64batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15602/40960 [00:38<01:06, 382.64batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15677/40960 [00:39<01:06, 380.06batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15677/40960 [00:39<01:06, 380.06batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15747/40960 [00:39<01:08, 370.30batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  38%|▍| 15747/40960 [00:39<01:08, 370.30batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 15828/40960 [00:39<01:06, 380.08batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 15828/40960 [00:39<01:06, 380.08batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 15907/40960 [00:39<01:05, 384.17batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 15907/40960 [00:39<01:05, 384.17batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 15983/40960 [00:39<01:05, 382.88batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 15983/40960 [00:39<01:05, 382.88batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 16061/40960 [00:40<01:04, 384.14batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 16061/40960 [00:40<01:04, 384.14batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 16126/40960 [00:40<01:08, 364.42batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  39%|▍| 16126/40960 [00:40<01:08, 364.42batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16185/40960 [00:40<01:12, 343.35batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16185/40960 [00:40<01:12, 343.35batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16257/40960 [00:40<01:11, 347.07batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16257/40960 [00:40<01:11, 347.07batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16323/40960 [00:40<01:12, 341.31batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16323/40960 [00:40<01:12, 341.31batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16401/40960 [00:41<01:09, 354.42batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16401/40960 [00:41<01:09, 354.42batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16483/40960 [00:41<01:06, 370.19batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16483/40960 [00:41<01:06, 370.19batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16567/40960 [00:41<01:03, 384.97batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16567/40960 [00:41<01:03, 384.97batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16651/40960 [00:41<01:01, 394.66batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16651/40960 [00:41<01:01, 394.66batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16730/40960 [00:41<01:01, 393.55batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16730/40960 [00:42<01:01, 393.55batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16816/40960 [00:42<00:59, 403.62batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16816/40960 [00:42<00:59, 403.62batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16901/40960 [00:42<00:58, 408.79batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16901/40960 [00:42<00:58, 408.79batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16986/40960 [00:42<00:58, 412.71batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  41%|▍| 16986/40960 [00:42<00:58, 412.71batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17070/40960 [00:42<00:57, 414.72batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17070/40960 [00:42<00:57, 414.72batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17155/40960 [00:43<00:57, 416.69batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17155/40960 [00:43<00:57, 416.69batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17238/40960 [00:43<00:57, 414.92batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17238/40960 [00:43<00:57, 414.92batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17316/40960 [00:43<00:58, 406.15batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17316/40960 [00:43<00:58, 406.15batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17395/40960 [00:43<00:58, 401.58batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  42%|▍| 17395/40960 [00:43<00:58, 401.58batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17478/40960 [00:43<00:58, 404.35batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17478/40960 [00:43<00:58, 404.35batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17554/40960 [00:44<00:58, 396.98batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17554/40960 [00:44<00:58, 396.98batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17632/40960 [00:44<00:59, 394.62batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17632/40960 [00:44<00:59, 394.62batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17710/40960 [00:44<00:59, 391.96batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17710/40960 [00:44<00:59, 391.96batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17793/40960 [00:44<00:58, 398.21batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  43%|▍| 17793/40960 [00:44<00:58, 398.21batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 17869/40960 [00:44<00:58, 392.51batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 17869/40960 [00:44<00:58, 392.51batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 17940/40960 [00:45<01:00, 380.73batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 17940/40960 [00:45<01:00, 380.73batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 18022/40960 [00:45<00:59, 388.24batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 18022/40960 [00:45<00:59, 388.24batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 18103/40960 [00:45<00:58, 392.59batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 18103/40960 [00:45<00:58, 392.59batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 18175/40960 [00:45<00:59, 382.33batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  44%|▍| 18175/40960 [00:45<00:59, 382.33batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18246/40960 [00:45<01:00, 373.65batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18246/40960 [00:45<01:00, 373.65batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18328/40960 [00:46<00:58, 383.80batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18328/40960 [00:46<00:58, 383.80batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18398/40960 [00:46<01:00, 372.53batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18398/40960 [00:46<01:00, 372.53batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18474/40960 [00:46<01:00, 373.75batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18474/40960 [00:46<01:00, 373.75batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18556/40960 [00:46<00:58, 384.42batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  45%|▍| 18556/40960 [00:46<00:58, 384.42batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18637/40960 [00:46<00:57, 389.63batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18637/40960 [00:46<00:57, 389.63batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18722/40960 [00:47<00:55, 400.04batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18722/40960 [00:47<00:55, 400.04batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18804/40960 [00:47<00:54, 403.01batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18804/40960 [00:47<00:54, 403.01batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18884/40960 [00:47<00:54, 401.87batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18884/40960 [00:47<00:54, 401.87batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18964/40960 [00:47<00:54, 401.21batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 18964/40960 [00:47<00:54, 401.21batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  46%|▍| 19045/40960 [00:47<00:54, 401.56batches/s, l2_loss: 0.0058 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|▍| 19045/40960 [00:47<00:54, 401.56batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  47%|▍| 19130/40960 [00:48<00:53, 407.52batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  47%|▍| 19130/40960 [00:48<00:53, 407.52batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  47%|▍| 19213/40960 [00:48<00:53, 409.50batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  47%|▍| 19213/40960 [00:48<00:53, 409.50batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  47%|▍| 19297/40960 [00:48<00:52, 412.12batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  47%|▍| 19297/40960 [00:48<00:52, 412.12batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  47%|▍| 19383/40960 [00:48<00:51, 416.23batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  47%|▍| 19383/40960 [00:48<00:51, 416.23batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19466/40960 [00:48<00:51, 415.26batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19466/40960 [00:48<00:51, 415.26batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19545/40960 [00:49<00:52, 408.67batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19545/40960 [00:49<00:52, 408.67batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19622/40960 [00:49<00:53, 400.23batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19622/40960 [00:49<00:53, 400.23batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19704/40960 [00:49<00:52, 402.83batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19704/40960 [00:49<00:52, 402.83batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19788/40960 [00:49<00:51, 407.27batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  48%|▍| 19788/40960 [00:49<00:51, 407.27batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 19866/40960 [00:49<00:52, 401.72batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 19866/40960 [00:49<00:52, 401.72batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 19940/40960 [00:50<00:53, 391.77batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 19940/40960 [00:50<00:53, 391.77batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 20017/40960 [00:50<00:53, 389.06batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 20017/40960 [00:50<00:53, 389.06batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 20092/40960 [00:50<00:54, 384.22batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 20092/40960 [00:50<00:54, 384.22batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 20165/40960 [00:50<00:55, 377.84batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 20165/40960 [00:50<00:55, 377.84batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 20238/40960 [00:50<00:55, 372.69batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  49%|▍| 20238/40960 [00:50<00:55, 372.69batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  50%|▍| 20312/40960 [00:51<00:55, 371.39batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  50%|▍| 20312/40960 [00:51<00:55, 371.39batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  50%|▍| 20387/40960 [00:51<00:55, 371.07batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  50%|▍| 20387/40960 [00:51<00:55, 371.07batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  50%|▍| 20464/40960 [00:51<00:54, 374.41batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  50%|▍| 20464/40960 [00:51<00:54, 374.41batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  50%|▌| 20540/40960 [00:51<00:54, 375.00batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  50%|▌| 20540/40960 [00:51<00:54, 375.00batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  50%|▌| 20621/40960 [00:51<00:53, 383.06batches/s, l2_loss: 0.0058 - round_los\u001b[A\n",
      "Training:  50%|▌| 20621/40960 [00:51<00:53, 383.06batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20701/40960 [00:52<00:52, 387.15batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20701/40960 [00:52<00:52, 387.15batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20781/40960 [00:52<00:51, 390.59batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20781/40960 [00:52<00:51, 390.59batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20859/40960 [00:52<00:51, 389.15batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20859/40960 [00:52<00:51, 389.15batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20917/40960 [00:52<00:55, 359.47batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20917/40960 [00:52<00:55, 359.47batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20968/40960 [00:52<01:01, 327.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 20968/40960 [00:52<01:01, 327.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 21025/40960 [00:53<01:03, 313.88batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  51%|▌| 21025/40960 [00:53<01:03, 313.88batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21098/40960 [00:53<01:00, 328.65batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21098/40960 [00:53<01:00, 328.65batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21173/40960 [00:53<00:57, 341.53batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21173/40960 [00:53<00:57, 341.53batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21246/40960 [00:53<00:56, 347.90batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21246/40960 [00:53<00:56, 347.90batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21323/40960 [00:53<00:54, 357.86batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21323/40960 [00:53<00:54, 357.86batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21401/40960 [00:54<00:53, 366.67batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21401/40960 [00:54<00:53, 366.67batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21481/40960 [00:54<00:51, 375.92batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  52%|▌| 21481/40960 [00:54<00:51, 375.92batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21552/40960 [00:54<00:52, 368.94batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21552/40960 [00:54<00:52, 368.94batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21630/40960 [00:54<00:51, 374.68batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21630/40960 [00:54<00:51, 374.68batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21711/40960 [00:54<00:50, 382.53batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21711/40960 [00:54<00:50, 382.53batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21793/40960 [00:55<00:49, 389.75batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21793/40960 [00:55<00:49, 389.75batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21875/40960 [00:55<00:48, 395.38batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  53%|▌| 21875/40960 [00:55<00:48, 395.38batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 21956/40960 [00:55<00:47, 397.73batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 21956/40960 [00:55<00:47, 397.73batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 22035/40960 [00:55<00:47, 396.52batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 22035/40960 [00:55<00:47, 396.52batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 22117/40960 [00:55<00:47, 399.07batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 22117/40960 [00:55<00:47, 399.07batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 22198/40960 [00:56<00:46, 400.31batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 22198/40960 [00:56<00:46, 400.31batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 22283/40960 [00:56<00:45, 406.65batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  54%|▌| 22283/40960 [00:56<00:45, 406.65batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22365/40960 [00:56<00:45, 407.00batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22365/40960 [00:56<00:45, 407.00batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22446/40960 [00:56<00:45, 406.15batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22446/40960 [00:56<00:45, 406.15batches/s, l2_loss: 0.0059 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22527/40960 [00:56<00:45, 405.79batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22527/40960 [00:56<00:45, 405.79batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22609/40960 [00:57<00:45, 406.62batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22609/40960 [00:57<00:45, 406.62batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [00:57<00:45, 403.80batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [00:57<00:45, 403.80batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 22764/40960 [00:57<00:46, 394.81batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 22764/40960 [00:57<00:46, 394.81batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 22841/40960 [00:57<00:46, 390.82batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 22841/40960 [00:57<00:46, 390.82batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 22926/40960 [00:57<00:45, 400.60batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 22926/40960 [00:57<00:45, 400.60batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 23009/40960 [00:58<00:44, 404.31batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 23009/40960 [00:58<00:44, 404.31batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 23093/40960 [00:58<00:43, 408.97batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  56%|▌| 23093/40960 [00:58<00:43, 408.97batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23163/40960 [00:58<00:45, 390.70batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23163/40960 [00:58<00:45, 390.70batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23246/40960 [00:58<00:44, 396.94batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23246/40960 [00:58<00:44, 396.94batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23330/40960 [00:58<00:43, 403.02batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23330/40960 [00:58<00:43, 403.02batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23413/40960 [00:59<00:43, 405.33batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23413/40960 [00:59<00:43, 405.33batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23496/40960 [00:59<00:42, 408.11batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  57%|▌| 23496/40960 [00:59<00:42, 408.11batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23573/40960 [00:59<00:43, 401.08batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23573/40960 [00:59<00:43, 401.08batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23655/40960 [00:59<00:42, 403.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23655/40960 [00:59<00:42, 403.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23739/40960 [00:59<00:42, 408.02batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23739/40960 [00:59<00:42, 408.02batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23820/40960 [01:00<00:42, 406.37batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23820/40960 [01:00<00:42, 406.37batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23904/40960 [01:00<00:41, 409.50batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  58%|▌| 23904/40960 [01:00<00:41, 409.50batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 23983/40960 [01:00<00:41, 404.94batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 23983/40960 [01:00<00:41, 404.94batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 24066/40960 [01:00<00:41, 406.81batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 24066/40960 [01:00<00:41, 406.81batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 24146/40960 [01:00<00:41, 402.92batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 24146/40960 [01:00<00:41, 402.92batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 24225/40960 [01:01<00:41, 400.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 24225/40960 [01:01<00:41, 400.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 24302/40960 [01:01<00:42, 394.63batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  59%|▌| 24302/40960 [01:01<00:42, 394.63batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24382/40960 [01:01<00:41, 395.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24382/40960 [01:01<00:41, 395.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24458/40960 [01:01<00:42, 390.34batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24458/40960 [01:01<00:42, 390.34batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24523/40960 [01:01<00:44, 369.55batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24523/40960 [01:01<00:44, 369.55batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24581/40960 [01:02<00:47, 345.08batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24581/40960 [01:02<00:47, 345.08batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24654/40960 [01:02<00:46, 350.49batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24654/40960 [01:02<00:46, 350.49batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24728/40960 [01:02<00:45, 355.37batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  60%|▌| 24728/40960 [01:02<00:45, 355.37batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 24810/40960 [01:02<00:43, 371.61batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 24810/40960 [01:02<00:43, 371.61batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 24894/40960 [01:02<00:41, 385.88batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 24894/40960 [01:02<00:41, 385.88batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 24968/40960 [01:03<00:42, 380.43batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 24968/40960 [01:03<00:42, 380.43batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 25043/40960 [01:03<00:42, 377.86batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 25043/40960 [01:03<00:42, 377.86batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 25114/40960 [01:03<00:42, 368.85batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 25114/40960 [01:03<00:42, 368.85batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 25169/40960 [01:03<00:46, 340.40batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  61%|▌| 25169/40960 [01:03<00:46, 340.40batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25232/40960 [01:03<00:47, 332.12batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25232/40960 [01:03<00:47, 332.12batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25309/40960 [01:04<00:45, 347.34batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25309/40960 [01:04<00:45, 347.34batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25390/40960 [01:04<00:42, 363.39batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25390/40960 [01:04<00:42, 363.39batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25466/40960 [01:04<00:42, 368.07batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25466/40960 [01:04<00:42, 368.07batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25544/40960 [01:04<00:41, 373.72batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  62%|▌| 25544/40960 [01:04<00:41, 373.72batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25624/40960 [01:04<00:40, 380.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25624/40960 [01:04<00:40, 380.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25699/40960 [01:05<00:40, 377.47batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25699/40960 [01:05<00:40, 377.47batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25782/40960 [01:05<00:39, 388.29batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25782/40960 [01:05<00:39, 388.29batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25858/40960 [01:05<00:39, 385.63batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25858/40960 [01:05<00:39, 385.63batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  63%|▋| 25942/40960 [01:05<00:37, 395.56batches/s, l2_loss: 0.0059 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|▋| 25942/40960 [01:05<00:37, 395.56batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26025/40960 [01:05<00:37, 400.61batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26025/40960 [01:05<00:37, 400.61batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26108/40960 [01:06<00:36, 404.11batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26108/40960 [01:06<00:36, 404.11batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26187/40960 [01:06<00:36, 399.85batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26187/40960 [01:06<00:36, 399.85batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26262/40960 [01:06<00:37, 392.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26262/40960 [01:06<00:37, 392.32batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26337/40960 [01:06<00:37, 386.52batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26337/40960 [01:06<00:37, 386.52batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26409/40960 [01:06<00:38, 377.58batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  64%|▋| 26409/40960 [01:06<00:38, 377.58batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26485/40960 [01:07<00:38, 377.10batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26485/40960 [01:07<00:38, 377.10batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26557/40960 [01:07<00:38, 371.51batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26557/40960 [01:07<00:38, 371.51batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26637/40960 [01:07<00:37, 379.98batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26637/40960 [01:07<00:37, 379.98batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26721/40960 [01:07<00:36, 390.90batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26721/40960 [01:07<00:36, 390.90batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26802/40960 [01:07<00:35, 394.50batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  65%|▋| 26802/40960 [01:07<00:35, 394.50batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  66%|▋| 26883/40960 [01:08<00:35, 397.34batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  66%|▋| 26883/40960 [01:08<00:35, 397.34batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  66%|▋| 26962/40960 [01:08<00:35, 396.02batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  66%|▋| 26962/40960 [01:08<00:35, 396.02batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  66%|▋| 27044/40960 [01:08<00:34, 399.99batches/s, l2_loss: 0.0059 - round_los\u001b[A\n",
      "Training:  66%|▋| 27044/40960 [01:08<00:34, 399.99batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  66%|▋| 27122/40960 [01:08<00:34, 396.53batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  66%|▋| 27122/40960 [01:08<00:34, 396.53batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:08<00:34, 393.14batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:08<00:34, 393.14batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27283/40960 [01:09<00:34, 398.72batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27283/40960 [01:09<00:34, 398.72batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27364/40960 [01:09<00:33, 400.48batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27364/40960 [01:09<00:33, 400.48batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27447/40960 [01:09<00:33, 404.73batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27447/40960 [01:09<00:33, 404.73batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27529/40960 [01:09<00:33, 404.97batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27529/40960 [01:09<00:33, 404.97batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27613/40960 [01:09<00:32, 408.55batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  67%|▋| 27613/40960 [01:09<00:32, 408.55batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 27698/40960 [01:10<00:32, 412.68batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 27698/40960 [01:10<00:32, 412.68batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 27780/40960 [01:10<00:32, 410.59batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 27780/40960 [01:10<00:32, 410.59batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 27862/40960 [01:10<00:31, 409.95batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 27862/40960 [01:10<00:31, 409.95batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 27947/40960 [01:10<00:31, 413.48batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 27947/40960 [01:10<00:31, 413.48batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 28032/40960 [01:10<00:31, 415.45batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  68%|▋| 28032/40960 [01:10<00:31, 415.45batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28116/40960 [01:11<00:30, 416.76batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28116/40960 [01:11<00:30, 416.76batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28200/40960 [01:11<00:30, 416.69batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28200/40960 [01:11<00:30, 416.69batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28281/40960 [01:11<00:30, 412.70batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28281/40960 [01:11<00:30, 412.70batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28365/40960 [01:11<00:30, 413.46batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28365/40960 [01:11<00:30, 413.46batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28449/40960 [01:11<00:30, 414.01batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  69%|▋| 28449/40960 [01:11<00:30, 414.01batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28532/40960 [01:12<00:30, 413.49batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28532/40960 [01:12<00:30, 413.49batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28609/40960 [01:12<00:30, 404.76batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28609/40960 [01:12<00:30, 404.76batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28684/40960 [01:12<00:31, 395.03batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28684/40960 [01:12<00:31, 395.03batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28763/40960 [01:12<00:30, 394.88batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28763/40960 [01:12<00:30, 394.88batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28840/40960 [01:12<00:30, 391.92batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  70%|▋| 28840/40960 [01:12<00:30, 391.92batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 28921/40960 [01:13<00:30, 394.68batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 28921/40960 [01:13<00:30, 394.68batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 29004/40960 [01:13<00:29, 400.70batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 29004/40960 [01:13<00:29, 400.70batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 29086/40960 [01:13<00:29, 402.98batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 29086/40960 [01:13<00:29, 402.98batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 29163/40960 [01:13<00:29, 397.33batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 29163/40960 [01:13<00:29, 397.33batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 29233/40960 [01:13<00:30, 381.87batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  71%|▋| 29233/40960 [01:13<00:30, 381.87batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29301/40960 [01:14<00:31, 368.84batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29301/40960 [01:14<00:31, 368.84batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29376/40960 [01:14<00:31, 370.06batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29376/40960 [01:14<00:31, 370.06batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29456/40960 [01:14<00:30, 378.85batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29456/40960 [01:14<00:30, 378.85batches/s, l2_loss: 0.0060 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|▋| 29537/40960 [01:14<00:29, 385.46batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29537/40960 [01:14<00:29, 385.46batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29618/40960 [01:15<00:29, 390.50batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  72%|▋| 29618/40960 [01:15<00:29, 390.50batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  73%|▋| 29697/40960 [01:15<00:28, 391.16batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  73%|▋| 29697/40960 [01:15<00:28, 391.16batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  73%|▋| 29779/40960 [01:15<00:28, 396.71batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  73%|▋| 29779/40960 [01:15<00:28, 396.71batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  73%|▋| 29858/40960 [01:15<00:28, 394.85batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  73%|▋| 29858/40960 [01:15<00:28, 394.85batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  73%|▋| 29933/40960 [01:15<00:28, 388.01batches/s, l2_loss: 0.0060 - round_los\u001b[A\n",
      "Training:  73%|▋| 29933/40960 [01:15<00:28, 388.01batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  73%|▋| 30007/40960 [01:16<00:28, 381.08batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  73%|▋| 30007/40960 [01:16<00:28, 381.08batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  73%|▋| 30086/40960 [01:16<00:28, 384.32batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  73%|▋| 30086/40960 [01:16<00:28, 384.32batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30163/40960 [01:16<00:28, 383.12batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30163/40960 [01:16<00:28, 383.12batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30240/40960 [01:16<00:27, 383.03batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30240/40960 [01:16<00:27, 383.03batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30316/40960 [01:16<00:27, 381.12batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30316/40960 [01:16<00:27, 381.12batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30395/40960 [01:17<00:27, 383.99batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30395/40960 [01:17<00:27, 383.99batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30477/40960 [01:17<00:26, 391.02batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30477/40960 [01:17<00:26, 391.02batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30556/40960 [01:17<00:26, 391.56batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30556/40960 [01:17<00:26, 391.56batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30639/40960 [01:17<00:25, 398.20batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30639/40960 [01:17<00:25, 398.20batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30721/40960 [01:17<00:25, 400.33batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30721/40960 [01:17<00:25, 400.33batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30804/40960 [01:18<00:25, 404.69batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30804/40960 [01:18<00:25, 404.69batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30887/40960 [01:18<00:24, 407.26batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30887/40960 [01:18<00:24, 407.26batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 30966/40960 [01:18<00:24, 403.03batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 30966/40960 [01:18<00:24, 403.03batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 31049/40960 [01:18<00:24, 405.83batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 31049/40960 [01:18<00:24, 405.83batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 31131/40960 [01:18<00:24, 404.63batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 31131/40960 [01:18<00:24, 404.63batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 31210/40960 [01:19<00:24, 401.03batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 31210/40960 [01:19<00:24, 401.03batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 31292/40960 [01:19<00:23, 403.48batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  76%|▊| 31292/40960 [01:19<00:23, 403.48batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31375/40960 [01:19<00:23, 406.45batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31375/40960 [01:19<00:23, 406.45batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31458/40960 [01:19<00:23, 408.00batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31458/40960 [01:19<00:23, 408.00batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31541/40960 [01:19<00:22, 409.75batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31541/40960 [01:19<00:22, 409.75batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31621/40960 [01:20<00:22, 406.65batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31621/40960 [01:20<00:22, 406.65batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31705/40960 [01:20<00:22, 410.13batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  77%|▊| 31705/40960 [01:20<00:22, 410.13batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  78%|▊| 31789/40960 [01:20<00:22, 411.86batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  78%|▊| 31789/40960 [01:20<00:22, 411.86batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  78%|▊| 31873/40960 [01:20<00:21, 413.51batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  78%|▊| 31873/40960 [01:20<00:21, 413.51batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  78%|▊| 31956/40960 [01:20<00:21, 412.98batches/s, l2_loss: 0.0061 - round_los\u001b[A\n",
      "Training:  78%|▊| 31956/40960 [01:20<00:21, 412.98batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  78%|▊| 32039/40960 [01:21<00:21, 412.48batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  78%|▊| 32039/40960 [01:21<00:21, 412.48batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  78%|▊| 32120/40960 [01:21<00:21, 409.41batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  78%|▊| 32120/40960 [01:21<00:21, 409.41batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32197/40960 [01:21<00:21, 400.60batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32197/40960 [01:21<00:21, 400.60batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32272/40960 [01:21<00:22, 392.86batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32272/40960 [01:21<00:22, 392.86batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32347/40960 [01:21<00:22, 386.06batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32347/40960 [01:21<00:22, 386.06batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32427/40960 [01:22<00:21, 389.55batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32427/40960 [01:22<00:21, 389.55batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32508/40960 [01:22<00:21, 393.63batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  79%|▊| 32508/40960 [01:22<00:21, 393.63batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32580/40960 [01:22<00:21, 383.51batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32580/40960 [01:22<00:21, 383.51batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32661/40960 [01:22<00:21, 389.03batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32661/40960 [01:22<00:21, 389.03batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32742/40960 [01:22<00:20, 393.27batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32742/40960 [01:22<00:20, 393.27batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32826/40960 [01:23<00:20, 400.97batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32826/40960 [01:23<00:20, 400.97batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32904/40960 [01:23<00:20, 397.54batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  80%|▊| 32904/40960 [01:23<00:20, 397.54batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 32987/40960 [01:23<00:19, 402.76batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 32987/40960 [01:23<00:19, 402.76batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 33070/40960 [01:23<00:19, 405.54batches/s, l2_loss: 0.0062 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|▊| 33070/40960 [01:23<00:19, 405.54batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 33153/40960 [01:23<00:19, 407.72batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 33153/40960 [01:23<00:19, 407.72batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 33237/40960 [01:24<00:18, 410.42batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 33237/40960 [01:24<00:18, 410.42batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 33320/40960 [01:24<00:18, 411.55batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  81%|▊| 33320/40960 [01:24<00:18, 411.55batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  82%|▊| 33399/40960 [01:24<00:18, 405.51batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  82%|▊| 33399/40960 [01:24<00:18, 405.51batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  82%|▊| 33481/40960 [01:24<00:18, 406.65batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  82%|▊| 33481/40960 [01:24<00:18, 406.65batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  82%|▊| 33565/40960 [01:24<00:18, 410.03batches/s, l2_loss: 0.0062 - round_los\u001b[A\n",
      "Training:  82%|▊| 33565/40960 [01:24<00:18, 410.03batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  82%|▊| 33649/40960 [01:25<00:17, 412.07batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  82%|▊| 33649/40960 [01:25<00:17, 412.07batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  82%|▊| 33732/40960 [01:25<00:17, 412.94batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  82%|▊| 33732/40960 [01:25<00:17, 412.94batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 33814/40960 [01:25<00:17, 410.93batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 33814/40960 [01:25<00:17, 410.93batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 33893/40960 [01:25<00:17, 404.81batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 33893/40960 [01:25<00:17, 404.81batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 33974/40960 [01:25<00:17, 404.37batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 33974/40960 [01:25<00:17, 404.37batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 34056/40960 [01:26<00:17, 405.44batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 34056/40960 [01:26<00:17, 405.44batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 34127/40960 [01:26<00:17, 389.75batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 34127/40960 [01:26<00:17, 389.75batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 34200/40960 [01:26<00:17, 382.09batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  83%|▊| 34200/40960 [01:26<00:17, 382.09batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34279/40960 [01:26<00:17, 385.35batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34279/40960 [01:26<00:17, 385.35batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34360/40960 [01:26<00:16, 390.52batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34360/40960 [01:26<00:16, 390.52batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34441/40960 [01:27<00:16, 394.66batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34441/40960 [01:27<00:16, 394.66batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34524/40960 [01:27<00:16, 400.45batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34524/40960 [01:27<00:16, 400.45batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34606/40960 [01:27<00:15, 402.02batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  84%|▊| 34606/40960 [01:27<00:15, 402.02batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  85%|▊| 34686/40960 [01:27<00:15, 401.20batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  85%|▊| 34686/40960 [01:27<00:15, 401.20batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  85%|▊| 34758/40960 [01:27<00:15, 388.07batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  85%|▊| 34758/40960 [01:27<00:15, 388.07batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  85%|▊| 34839/40960 [01:28<00:15, 391.50batches/s, l2_loss: 0.0063 - round_los\u001b[A\n",
      "Training:  85%|▊| 34839/40960 [01:28<00:15, 391.50batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  85%|▊| 34912/40960 [01:28<00:15, 382.39batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  85%|▊| 34912/40960 [01:28<00:15, 382.39batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  85%|▊| 34994/40960 [01:28<00:15, 390.23batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  85%|▊| 34994/40960 [01:28<00:15, 390.23batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35077/40960 [01:28<00:14, 396.68batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35077/40960 [01:28<00:14, 396.68batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35160/40960 [01:28<00:14, 401.65batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35160/40960 [01:28<00:14, 401.65batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35239/40960 [01:29<00:14, 399.50batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35239/40960 [01:29<00:14, 399.50batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35320/40960 [01:29<00:14, 400.68batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35320/40960 [01:29<00:14, 400.68batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35400/40960 [01:29<00:13, 399.75batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  86%|▊| 35400/40960 [01:29<00:13, 399.75batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35480/40960 [01:29<00:13, 399.69batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35480/40960 [01:29<00:13, 399.69batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35560/40960 [01:29<00:13, 398.83batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35560/40960 [01:29<00:13, 398.83batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35638/40960 [01:30<00:13, 396.04batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35638/40960 [01:30<00:13, 396.04batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35716/40960 [01:30<00:13, 393.78batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35716/40960 [01:30<00:13, 393.78batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35795/40960 [01:30<00:13, 393.16batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  87%|▊| 35795/40960 [01:30<00:13, 393.16batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  88%|▉| 35873/40960 [01:30<00:12, 391.91batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  88%|▉| 35873/40960 [01:30<00:12, 391.91batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  88%|▉| 35946/40960 [01:30<00:13, 382.59batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  88%|▉| 35946/40960 [01:30<00:13, 382.59batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  88%|▉| 36023/40960 [01:31<00:12, 382.16batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  88%|▉| 36023/40960 [01:31<00:12, 382.16batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  88%|▉| 36104/40960 [01:31<00:12, 387.69batches/s, l2_loss: 0.0064 - round_los\u001b[A\n",
      "Training:  88%|▉| 36104/40960 [01:31<00:12, 387.69batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  88%|▉| 36188/40960 [01:31<00:12, 396.87batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  88%|▉| 36188/40960 [01:31<00:12, 396.87batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36270/40960 [01:31<00:11, 399.48batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36270/40960 [01:31<00:11, 399.48batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36354/40960 [01:31<00:11, 404.45batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36354/40960 [01:31<00:11, 404.45batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36434/40960 [01:32<00:11, 402.84batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36434/40960 [01:32<00:11, 402.84batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36516/40960 [01:32<00:10, 404.66batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36516/40960 [01:32<00:10, 404.66batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36598/40960 [01:32<00:10, 405.26batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  89%|▉| 36598/40960 [01:32<00:10, 405.26batches/s, l2_loss: 0.0065 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 36679/40960 [01:32<00:10, 403.61batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 36679/40960 [01:32<00:10, 403.61batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 36761/40960 [01:32<00:10, 405.28batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 36761/40960 [01:32<00:10, 405.28batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 36844/40960 [01:33<00:10, 408.16batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 36844/40960 [01:33<00:10, 408.16batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 36926/40960 [01:33<00:09, 407.57batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 36926/40960 [01:33<00:09, 407.57batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 37009/40960 [01:33<00:09, 408.72batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  90%|▉| 37009/40960 [01:33<00:09, 408.72batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  91%|▉| 37091/40960 [01:33<00:09, 408.92batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  91%|▉| 37091/40960 [01:33<00:09, 408.92batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  91%|▉| 37172/40960 [01:33<00:09, 406.18batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  91%|▉| 37172/40960 [01:33<00:09, 406.18batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  91%|▉| 37250/40960 [01:34<00:09, 400.15batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  91%|▉| 37250/40960 [01:34<00:09, 400.15batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  91%|▉| 37329/40960 [01:34<00:09, 398.11batches/s, l2_loss: 0.0065 - round_los\u001b[A\n",
      "Training:  91%|▉| 37329/40960 [01:34<00:09, 398.11batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  91%|▉| 37411/40960 [01:34<00:08, 401.00batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  91%|▉| 37411/40960 [01:34<00:08, 401.00batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37492/40960 [01:34<00:08, 401.27batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37492/40960 [01:34<00:08, 401.27batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37567/40960 [01:34<00:08, 393.05batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37567/40960 [01:34<00:08, 393.05batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37641/40960 [01:35<00:08, 385.06batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37641/40960 [01:35<00:08, 385.06batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37720/40960 [01:35<00:08, 387.98batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37720/40960 [01:35<00:08, 387.98batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37796/40960 [01:35<00:08, 385.31batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37796/40960 [01:35<00:08, 385.31batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37877/40960 [01:35<00:07, 390.44batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  92%|▉| 37877/40960 [01:35<00:07, 390.44batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  93%|▉| 37958/40960 [01:35<00:07, 394.57batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  93%|▉| 37958/40960 [01:35<00:07, 394.57batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  93%|▉| 38038/40960 [01:36<00:07, 395.31batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  93%|▉| 38038/40960 [01:36<00:07, 395.31batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  93%|▉| 38121/40960 [01:36<00:07, 401.03batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  93%|▉| 38121/40960 [01:36<00:07, 401.03batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  93%|▉| 38202/40960 [01:36<00:06, 401.64batches/s, l2_loss: 0.0066 - round_los\u001b[A\n",
      "Training:  93%|▉| 38202/40960 [01:36<00:06, 401.64batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  93%|▉| 38279/40960 [01:36<00:06, 395.54batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  93%|▉| 38279/40960 [01:36<00:06, 395.54batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38352/40960 [01:36<00:06, 385.62batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38352/40960 [01:36<00:06, 385.62batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38427/40960 [01:37<00:06, 381.16batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38427/40960 [01:37<00:06, 381.16batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38503/40960 [01:37<00:06, 378.26batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38503/40960 [01:37<00:06, 378.26batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38585/40960 [01:37<00:06, 386.70batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38585/40960 [01:37<00:06, 386.70batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38662/40960 [01:37<00:05, 385.60batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  94%|▉| 38662/40960 [01:37<00:05, 385.60batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  95%|▉| 38737/40960 [01:37<00:05, 381.90batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  95%|▉| 38737/40960 [01:37<00:05, 381.90batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  95%|▉| 38815/40960 [01:38<00:05, 383.69batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  95%|▉| 38815/40960 [01:38<00:05, 383.69batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  95%|▉| 38892/40960 [01:38<00:05, 383.23batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  95%|▉| 38892/40960 [01:38<00:05, 383.23batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  95%|▉| 38969/40960 [01:38<00:05, 383.12batches/s, l2_loss: 0.0067 - round_los\u001b[A\n",
      "Training:  95%|▉| 38969/40960 [01:38<00:05, 383.12batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  95%|▉| 39048/40960 [01:38<00:04, 386.25batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  95%|▉| 39048/40960 [01:38<00:04, 386.25batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39125/40960 [01:38<00:04, 384.90batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39125/40960 [01:38<00:04, 384.90batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39203/40960 [01:39<00:04, 386.10batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39203/40960 [01:39<00:04, 386.10batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39277/40960 [01:39<00:04, 380.93batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39277/40960 [01:39<00:04, 380.93batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39354/40960 [01:39<00:04, 382.08batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39354/40960 [01:39<00:04, 382.08batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39438/40960 [01:39<00:03, 390.96batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39438/40960 [01:39<00:03, 390.96batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39508/40960 [01:39<00:03, 377.79batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  96%|▉| 39508/40960 [01:39<00:03, 377.79batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  97%|▉| 39587/40960 [01:40<00:03, 382.49batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  97%|▉| 39587/40960 [01:40<00:03, 382.49batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  97%|▉| 39667/40960 [01:40<00:03, 386.60batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  97%|▉| 39667/40960 [01:40<00:03, 386.60batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  97%|▉| 39747/40960 [01:40<00:03, 389.62batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  97%|▉| 39747/40960 [01:40<00:03, 389.62batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  97%|▉| 39826/40960 [01:40<00:02, 390.77batches/s, l2_loss: 0.0068 - round_los\u001b[A\n",
      "Training:  97%|▉| 39826/40960 [01:40<00:02, 390.77batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  97%|▉| 39904/40960 [01:40<00:02, 388.90batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  97%|▉| 39904/40960 [01:40<00:02, 388.90batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 39979/40960 [01:41<00:02, 383.68batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 39979/40960 [01:41<00:02, 383.68batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 40061/40960 [01:41<00:02, 390.00batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 40061/40960 [01:41<00:02, 390.00batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 40141/40960 [01:41<00:02, 392.71batches/s, l2_loss: 0.0069 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40141/40960 [01:41<00:02, 392.71batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 40224/40960 [01:41<00:01, 399.30batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 40224/40960 [01:41<00:01, 399.30batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 40304/40960 [01:41<00:01, 398.07batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  98%|▉| 40304/40960 [01:41<00:01, 398.07batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40387/40960 [01:42<00:01, 402.02batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40387/40960 [01:42<00:01, 402.02batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40471/40960 [01:42<00:01, 406.71batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40471/40960 [01:42<00:01, 406.71batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40554/40960 [01:42<00:00, 408.30batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40554/40960 [01:42<00:00, 408.30batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40638/40960 [01:42<00:00, 411.17batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40638/40960 [01:42<00:00, 411.17batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40722/40960 [01:42<00:00, 412.34batches/s, l2_loss: 0.0069 - round_los\u001b[A\n",
      "Training:  99%|▉| 40722/40960 [01:42<00:00, 412.34batches/s, l2_loss: 0.0070 - round_los\u001b[A\n",
      "Training: 100%|▉| 40804/40960 [01:43<00:00, 410.84batches/s, l2_loss: 0.0070 - round_los\u001b[A\n",
      "Training: 100%|▉| 40804/40960 [01:43<00:00, 410.84batches/s, l2_loss: 0.0070 - round_los\u001b[A\n",
      "Training: 100%|▉| 40888/40960 [01:43<00:00, 412.62batches/s, l2_loss: 0.0070 - round_los\u001b[A\n",
      "Training: 100%|▉| 40888/40960 [01:43<00:00, 412.62batches/s, l2_loss: 0.0070 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 14:54:48.306139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  15%|▏| 4/26 [07:08<39:14, 107.02s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 14:54:49.599031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 14:54:54.102716: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<23:57:57,  2.11s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<23:57:57,  2.11s/batches, l2_loss: 0.1359 - round_loss:\u001b[A\n",
      "Training:   0%| | 77/40960 [00:02<14:52, 45.79batches/s, l2_loss: 0.1359 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 77/40960 [00:02<14:52, 45.79batches/s, l2_loss: 0.0265 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 152/40960 [00:02<07:15, 93.73batches/s, l2_loss: 0.0265 - round_loss: \u001b[A\n",
      "Training:   0%| | 152/40960 [00:02<07:15, 93.73batches/s, l2_loss: 0.0239 - round_loss: \u001b[A\n",
      "Training:   1%| | 230/40960 [00:02<04:41, 144.47batches/s, l2_loss: 0.0239 - round_loss:\u001b[A\n",
      "Training:   1%| | 230/40960 [00:02<04:41, 144.47batches/s, l2_loss: 0.0230 - round_loss:\u001b[A\n",
      "Training:   1%| | 307/40960 [00:02<03:32, 191.76batches/s, l2_loss: 0.0230 - round_loss:\u001b[A\n",
      "Training:   1%| | 307/40960 [00:02<03:32, 191.76batches/s, l2_loss: 0.0222 - round_loss:\u001b[A\n",
      "Training:   1%| | 386/40960 [00:03<02:51, 236.37batches/s, l2_loss: 0.0222 - round_loss:\u001b[A\n",
      "Training:   1%| | 386/40960 [00:03<02:51, 236.37batches/s, l2_loss: 0.0215 - round_loss:\u001b[A\n",
      "Training:   1%| | 457/40960 [00:03<02:33, 264.36batches/s, l2_loss: 0.0215 - round_loss:\u001b[A\n",
      "Training:   1%| | 457/40960 [00:03<02:33, 264.36batches/s, l2_loss: 0.0211 - round_loss:\u001b[A\n",
      "Training:   1%| | 538/40960 [00:03<02:15, 299.32batches/s, l2_loss: 0.0211 - round_loss:\u001b[A\n",
      "Training:   1%| | 538/40960 [00:03<02:15, 299.32batches/s, l2_loss: 0.0205 - round_loss:\u001b[A\n",
      "Training:   1%| | 613/40960 [00:03<02:06, 318.43batches/s, l2_loss: 0.0205 - round_loss:\u001b[A\n",
      "Training:   1%| | 613/40960 [00:03<02:06, 318.43batches/s, l2_loss: 0.0200 - round_loss:\u001b[A\n",
      "Training:   2%| | 689/40960 [00:03<02:00, 335.02batches/s, l2_loss: 0.0200 - round_loss:\u001b[A\n",
      "Training:   2%| | 689/40960 [00:03<02:00, 335.02batches/s, l2_loss: 0.0196 - round_loss:\u001b[A\n",
      "Training:   2%| | 766/40960 [00:04<01:55, 348.14batches/s, l2_loss: 0.0196 - round_loss:\u001b[A\n",
      "Training:   2%| | 766/40960 [00:04<01:55, 348.14batches/s, l2_loss: 0.0194 - round_loss:\u001b[A\n",
      "Training:   2%| | 837/40960 [00:04<01:54, 349.10batches/s, l2_loss: 0.0194 - round_loss:\u001b[A\n",
      "Training:   2%| | 837/40960 [00:04<01:54, 349.10batches/s, l2_loss: 0.0192 - round_loss:\u001b[A\n",
      "Training:   2%| | 891/40960 [00:04<02:03, 325.43batches/s, l2_loss: 0.0192 - round_loss:\u001b[A\n",
      "Training:   2%| | 891/40960 [00:04<02:03, 325.43batches/s, l2_loss: 0.0190 - round_loss:\u001b[A\n",
      "Training:   2%| | 953/40960 [00:04<02:04, 320.22batches/s, l2_loss: 0.0190 - round_loss:\u001b[A\n",
      "Training:   2%| | 953/40960 [00:04<02:04, 320.22batches/s, l2_loss: 0.0187 - round_loss:\u001b[A\n",
      "Training:   3%| | 1025/40960 [00:04<02:00, 330.77batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:   3%| | 1025/40960 [00:04<02:00, 330.77batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:   3%| | 1089/40960 [00:05<02:02, 326.60batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:   3%| | 1089/40960 [00:05<02:02, 326.60batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:   3%| | 1163/40960 [00:05<01:57, 338.63batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:   3%| | 1163/40960 [00:05<01:57, 338.63batches/s, l2_loss: 0.0183 - round_loss\u001b[A\n",
      "Training:   3%| | 1227/40960 [00:05<01:59, 331.82batches/s, l2_loss: 0.0183 - round_loss\u001b[A\n",
      "Training:   3%| | 1227/40960 [00:05<01:59, 331.82batches/s, l2_loss: 0.0182 - round_loss\u001b[A\n",
      "Training:   3%| | 1283/40960 [00:05<02:05, 316.11batches/s, l2_loss: 0.0182 - round_loss\u001b[A\n",
      "Training:   3%| | 1283/40960 [00:05<02:05, 316.11batches/s, l2_loss: 0.0180 - round_loss\u001b[A\n",
      "Training:   3%| | 1358/40960 [00:05<01:59, 332.75batches/s, l2_loss: 0.0180 - round_loss\u001b[A\n",
      "Training:   3%| | 1358/40960 [00:05<01:59, 332.75batches/s, l2_loss: 0.0178 - round_loss\u001b[A\n",
      "Training:   4%| | 1434/40960 [00:06<01:53, 346.79batches/s, l2_loss: 0.0178 - round_loss\u001b[A\n",
      "Training:   4%| | 1434/40960 [00:06<01:53, 346.79batches/s, l2_loss: 0.0177 - round_loss\u001b[A\n",
      "Training:   4%| | 1510/40960 [00:06<01:50, 356.23batches/s, l2_loss: 0.0177 - round_loss\u001b[A\n",
      "Training:   4%| | 1510/40960 [00:06<01:50, 356.23batches/s, l2_loss: 0.0176 - round_loss\u001b[A\n",
      "Training:   4%| | 1590/40960 [00:06<01:46, 368.78batches/s, l2_loss: 0.0176 - round_loss\u001b[A\n",
      "Training:   4%| | 1590/40960 [00:06<01:46, 368.78batches/s, l2_loss: 0.0175 - round_loss\u001b[A\n",
      "Training:   4%| | 1668/40960 [00:06<01:44, 374.24batches/s, l2_loss: 0.0175 - round_loss\u001b[A\n",
      "Training:   4%| | 1668/40960 [00:06<01:44, 374.24batches/s, l2_loss: 0.0174 - round_loss\u001b[A\n",
      "Training:   4%| | 1743/40960 [00:06<01:44, 373.87batches/s, l2_loss: 0.0174 - round_loss\u001b[A\n",
      "Training:   4%| | 1743/40960 [00:06<01:44, 373.87batches/s, l2_loss: 0.0173 - round_loss\u001b[A\n",
      "Training:   4%| | 1823/40960 [00:07<01:42, 380.66batches/s, l2_loss: 0.0173 - round_loss\u001b[A\n",
      "Training:   4%| | 1823/40960 [00:07<01:42, 380.66batches/s, l2_loss: 0.0171 - round_loss\u001b[A\n",
      "Training:   5%| | 1900/40960 [00:07<01:42, 381.37batches/s, l2_loss: 0.0171 - round_loss\u001b[A\n",
      "Training:   5%| | 1900/40960 [00:07<01:42, 381.37batches/s, l2_loss: 0.0170 - round_loss\u001b[A\n",
      "Training:   5%| | 1977/40960 [00:07<01:42, 381.16batches/s, l2_loss: 0.0170 - round_loss\u001b[A\n",
      "Training:   5%| | 1977/40960 [00:07<01:42, 381.16batches/s, l2_loss: 0.0170 - round_loss\u001b[A\n",
      "Training:   5%| | 2057/40960 [00:07<01:40, 385.82batches/s, l2_loss: 0.0170 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 2057/40960 [00:07<01:40, 385.82batches/s, l2_loss: 0.0169 - round_loss\u001b[A\n",
      "Training:   5%| | 2134/40960 [00:07<01:41, 384.32batches/s, l2_loss: 0.0169 - round_loss\u001b[A\n",
      "Training:   5%| | 2134/40960 [00:07<01:41, 384.32batches/s, l2_loss: 0.0168 - round_loss\u001b[A\n",
      "Training:   5%| | 2210/40960 [00:08<01:41, 382.68batches/s, l2_loss: 0.0168 - round_loss\u001b[A\n",
      "Training:   5%| | 2210/40960 [00:08<01:41, 382.68batches/s, l2_loss: 0.0167 - round_loss\u001b[A\n",
      "Training:   6%| | 2288/40960 [00:08<01:40, 384.03batches/s, l2_loss: 0.0167 - round_loss\u001b[A\n",
      "Training:   6%| | 2288/40960 [00:08<01:40, 384.03batches/s, l2_loss: 0.0166 - round_loss\u001b[A\n",
      "Training:   6%| | 2369/40960 [00:08<01:39, 389.62batches/s, l2_loss: 0.0166 - round_loss\u001b[A\n",
      "Training:   6%| | 2369/40960 [00:08<01:39, 389.62batches/s, l2_loss: 0.0165 - round_loss\u001b[A\n",
      "Training:   6%| | 2450/40960 [00:08<01:38, 392.94batches/s, l2_loss: 0.0165 - round_loss\u001b[A\n",
      "Training:   6%| | 2450/40960 [00:08<01:38, 392.94batches/s, l2_loss: 0.0165 - round_loss\u001b[A\n",
      "Training:   6%| | 2527/40960 [00:08<01:38, 389.75batches/s, l2_loss: 0.0165 - round_loss\u001b[A\n",
      "Training:   6%| | 2527/40960 [00:08<01:38, 389.75batches/s, l2_loss: 0.0164 - round_loss\u001b[A\n",
      "Training:   6%| | 2604/40960 [00:09<01:38, 387.97batches/s, l2_loss: 0.0164 - round_loss\u001b[A\n",
      "Training:   6%| | 2604/40960 [00:09<01:38, 387.97batches/s, l2_loss: 0.0163 - round_loss\u001b[A\n",
      "Training:   7%| | 2683/40960 [00:09<01:38, 389.60batches/s, l2_loss: 0.0163 - round_loss\u001b[A\n",
      "Training:   7%| | 2683/40960 [00:09<01:38, 389.60batches/s, l2_loss: 0.0163 - round_loss\u001b[A\n",
      "Training:   7%| | 2760/40960 [00:09<01:38, 388.12batches/s, l2_loss: 0.0163 - round_loss\u001b[A\n",
      "Training:   7%| | 2760/40960 [00:09<01:38, 388.12batches/s, l2_loss: 0.0162 - round_loss\u001b[A\n",
      "Training:   7%| | 2839/40960 [00:09<01:37, 389.93batches/s, l2_loss: 0.0162 - round_loss\u001b[A\n",
      "Training:   7%| | 2839/40960 [00:09<01:37, 389.93batches/s, l2_loss: 0.0162 - round_loss\u001b[A\n",
      "Training:   7%| | 2908/40960 [00:09<01:41, 375.62batches/s, l2_loss: 0.0162 - round_loss\u001b[A\n",
      "Training:   7%| | 2908/40960 [00:09<01:41, 375.62batches/s, l2_loss: 0.0161 - round_loss\u001b[A\n",
      "Training:   7%| | 2976/40960 [00:10<01:44, 364.75batches/s, l2_loss: 0.0161 - round_loss\u001b[A\n",
      "Training:   7%| | 2976/40960 [00:10<01:44, 364.75batches/s, l2_loss: 0.0161 - round_loss\u001b[A\n",
      "Training:   7%| | 3055/40960 [00:10<01:41, 373.13batches/s, l2_loss: 0.0161 - round_loss\u001b[A\n",
      "Training:   7%| | 3055/40960 [00:10<01:41, 373.13batches/s, l2_loss: 0.0160 - round_loss\u001b[A\n",
      "Training:   8%| | 3134/40960 [00:10<01:39, 379.59batches/s, l2_loss: 0.0160 - round_loss\u001b[A\n",
      "Training:   8%| | 3134/40960 [00:10<01:39, 379.59batches/s, l2_loss: 0.0160 - round_loss\u001b[A\n",
      "Training:   8%| | 3210/40960 [00:10<01:39, 379.05batches/s, l2_loss: 0.0160 - round_loss\u001b[A\n",
      "Training:   8%| | 3210/40960 [00:10<01:39, 379.05batches/s, l2_loss: 0.0159 - round_loss\u001b[A\n",
      "Training:   8%| | 3275/40960 [00:10<01:44, 362.11batches/s, l2_loss: 0.0159 - round_loss\u001b[A\n",
      "Training:   8%| | 3275/40960 [00:10<01:44, 362.11batches/s, l2_loss: 0.0158 - round_loss\u001b[A\n",
      "Training:   8%| | 3348/40960 [00:11<01:43, 361.72batches/s, l2_loss: 0.0158 - round_loss\u001b[A\n",
      "Training:   8%| | 3348/40960 [00:11<01:43, 361.72batches/s, l2_loss: 0.0158 - round_loss\u001b[A\n",
      "Training:   8%| | 3412/40960 [00:11<01:47, 348.04batches/s, l2_loss: 0.0158 - round_loss\u001b[A\n",
      "Training:   8%| | 3412/40960 [00:11<01:47, 348.04batches/s, l2_loss: 0.0158 - round_loss\u001b[A\n",
      "Training:   8%| | 3478/40960 [00:11<01:49, 342.07batches/s, l2_loss: 0.0158 - round_loss\u001b[A\n",
      "Training:   8%| | 3478/40960 [00:11<01:49, 342.07batches/s, l2_loss: 0.0157 - round_loss\u001b[A\n",
      "Training:   9%| | 3534/40960 [00:11<01:56, 322.12batches/s, l2_loss: 0.0157 - round_loss\u001b[A\n",
      "Training:   9%| | 3534/40960 [00:11<01:56, 322.12batches/s, l2_loss: 0.0157 - round_loss\u001b[A\n",
      "Training:   9%| | 3601/40960 [00:11<01:55, 324.83batches/s, l2_loss: 0.0157 - round_loss\u001b[A\n",
      "Training:   9%| | 3601/40960 [00:11<01:55, 324.83batches/s, l2_loss: 0.0157 - round_loss\u001b[A\n",
      "Training:   9%| | 3675/40960 [00:12<01:50, 337.84batches/s, l2_loss: 0.0157 - round_loss\u001b[A\n",
      "Training:   9%| | 3675/40960 [00:12<01:50, 337.84batches/s, l2_loss: 0.0156 - round_loss\u001b[A\n",
      "Training:   9%| | 3745/40960 [00:12<01:49, 340.59batches/s, l2_loss: 0.0156 - round_loss\u001b[A\n",
      "Training:   9%| | 3745/40960 [00:12<01:49, 340.59batches/s, l2_loss: 0.0156 - round_loss\u001b[A\n",
      "Training:   9%| | 3822/40960 [00:12<01:45, 352.92batches/s, l2_loss: 0.0156 - round_loss\u001b[A\n",
      "Training:   9%| | 3822/40960 [00:12<01:45, 352.92batches/s, l2_loss: 0.0156 - round_loss\u001b[A\n",
      "Training:  10%| | 3895/40960 [00:12<01:43, 356.52batches/s, l2_loss: 0.0156 - round_loss\u001b[A\n",
      "Training:  10%| | 3895/40960 [00:12<01:43, 356.52batches/s, l2_loss: 0.0155 - round_loss\u001b[A\n",
      "Training:  10%| | 3969/40960 [00:12<01:42, 360.48batches/s, l2_loss: 0.0155 - round_loss\u001b[A\n",
      "Training:  10%| | 3969/40960 [00:12<01:42, 360.48batches/s, l2_loss: 0.0155 - round_loss\u001b[A\n",
      "Training:  10%| | 4047/40960 [00:13<01:40, 368.68batches/s, l2_loss: 0.0155 - round_loss\u001b[A\n",
      "Training:  10%| | 4047/40960 [00:13<01:40, 368.68batches/s, l2_loss: 0.0155 - round_loss\u001b[A\n",
      "Training:  10%| | 4124/40960 [00:13<01:38, 372.86batches/s, l2_loss: 0.0155 - round_loss\u001b[A\n",
      "Training:  10%| | 4124/40960 [00:13<01:38, 372.86batches/s, l2_loss: 0.0154 - round_loss\u001b[A\n",
      "Training:  10%| | 4202/40960 [00:13<01:37, 377.72batches/s, l2_loss: 0.0154 - round_loss\u001b[A\n",
      "Training:  10%| | 4202/40960 [00:13<01:37, 377.72batches/s, l2_loss: 0.0154 - round_loss\u001b[A\n",
      "Training:  10%| | 4282/40960 [00:13<01:35, 383.51batches/s, l2_loss: 0.0154 - round_loss\u001b[A\n",
      "Training:  10%| | 4282/40960 [00:13<01:35, 383.51batches/s, l2_loss: 0.0153 - round_loss\u001b[A\n",
      "Training:  11%| | 4363/40960 [00:13<01:33, 389.58batches/s, l2_loss: 0.0153 - round_loss\u001b[A\n",
      "Training:  11%| | 4363/40960 [00:13<01:33, 389.58batches/s, l2_loss: 0.0153 - round_loss\u001b[A\n",
      "Training:  11%| | 4440/40960 [00:14<01:34, 387.52batches/s, l2_loss: 0.0153 - round_loss\u001b[A\n",
      "Training:  11%| | 4440/40960 [00:14<01:34, 387.52batches/s, l2_loss: 0.0153 - round_loss\u001b[A\n",
      "Training:  11%| | 4517/40960 [00:14<01:34, 385.63batches/s, l2_loss: 0.0153 - round_loss\u001b[A\n",
      "Training:  11%| | 4517/40960 [00:14<01:34, 385.63batches/s, l2_loss: 0.0153 - round_loss\u001b[A\n",
      "Training:  11%| | 4592/40960 [00:14<01:35, 381.79batches/s, l2_loss: 0.0153 - round_loss\u001b[A\n",
      "Training:  11%| | 4592/40960 [00:14<01:35, 381.79batches/s, l2_loss: 0.0152 - round_loss\u001b[A\n",
      "Training:  11%| | 4667/40960 [00:14<01:35, 379.72batches/s, l2_loss: 0.0152 - round_loss\u001b[A\n",
      "Training:  11%| | 4667/40960 [00:14<01:35, 379.72batches/s, l2_loss: 0.0152 - round_loss\u001b[A\n",
      "Training:  12%| | 4744/40960 [00:14<01:35, 380.41batches/s, l2_loss: 0.0152 - round_loss\u001b[A\n",
      "Training:  12%| | 4744/40960 [00:14<01:35, 380.41batches/s, l2_loss: 0.0152 - round_loss\u001b[A\n",
      "Training:  12%| | 4819/40960 [00:15<01:35, 377.33batches/s, l2_loss: 0.0152 - round_loss\u001b[A\n",
      "Training:  12%| | 4819/40960 [00:15<01:35, 377.33batches/s, l2_loss: 0.0151 - round_loss\u001b[A\n",
      "Training:  12%| | 4895/40960 [00:15<01:35, 378.10batches/s, l2_loss: 0.0151 - round_loss\u001b[A\n",
      "Training:  12%| | 4895/40960 [00:15<01:35, 378.10batches/s, l2_loss: 0.0151 - round_loss\u001b[A\n",
      "Training:  12%| | 4973/40960 [00:15<01:34, 381.36batches/s, l2_loss: 0.0151 - round_loss\u001b[A\n",
      "Training:  12%| | 4973/40960 [00:15<01:34, 381.36batches/s, l2_loss: 0.0151 - round_loss\u001b[A\n",
      "Training:  12%| | 5052/40960 [00:15<01:33, 384.11batches/s, l2_loss: 0.0151 - round_loss\u001b[A\n",
      "Training:  12%| | 5052/40960 [00:15<01:33, 384.11batches/s, l2_loss: 0.0151 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5131/40960 [00:15<01:32, 385.79batches/s, l2_loss: 0.0151 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5131/40960 [00:16<01:32, 385.79batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5210/40960 [00:16<01:32, 387.24batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5210/40960 [00:16<01:32, 387.24batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5290/40960 [00:16<01:31, 390.10batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5290/40960 [00:16<01:31, 390.10batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5363/40960 [00:16<01:33, 382.49batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5363/40960 [00:16<01:33, 382.49batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|▏| 5438/40960 [00:16<01:33, 378.94batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5438/40960 [00:16<01:33, 378.94batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5515/40960 [00:17<01:33, 379.92batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5515/40960 [00:17<01:33, 379.92batches/s, l2_loss: 0.0149 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5595/40960 [00:17<01:31, 384.87batches/s, l2_loss: 0.0149 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5595/40960 [00:17<01:31, 384.87batches/s, l2_loss: 0.0149 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5675/40960 [00:17<01:30, 388.52batches/s, l2_loss: 0.0149 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5675/40960 [00:17<01:30, 388.52batches/s, l2_loss: 0.0149 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5748/40960 [00:17<01:32, 380.32batches/s, l2_loss: 0.0149 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5748/40960 [00:17<01:32, 380.32batches/s, l2_loss: 0.0149 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5822/40960 [00:17<01:33, 376.02batches/s, l2_loss: 0.0149 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5822/40960 [00:17<01:33, 376.02batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5894/40960 [00:18<01:34, 370.13batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5894/40960 [00:18<01:34, 370.13batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5963/40960 [00:18<01:36, 362.18batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5963/40960 [00:18<01:36, 362.18batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6031/40960 [00:18<01:38, 354.64batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6031/40960 [00:18<01:38, 354.64batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6102/40960 [00:18<01:38, 353.59batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6102/40960 [00:18<01:38, 353.59batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6176/40960 [00:18<01:37, 357.31batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6176/40960 [00:18<01:37, 357.31batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6243/40960 [00:19<01:39, 350.32batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6243/40960 [00:19<01:39, 350.32batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6312/40960 [00:19<01:39, 347.66batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6312/40960 [00:19<01:39, 347.66batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6380/40960 [00:19<01:40, 344.31batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6380/40960 [00:19<01:40, 344.31batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6446/40960 [00:19<01:41, 339.19batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6446/40960 [00:19<01:41, 339.19batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6513/40960 [00:19<01:42, 336.52batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6513/40960 [00:19<01:42, 336.52batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6578/40960 [00:20<01:43, 332.18batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6578/40960 [00:20<01:43, 332.18batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6630/40960 [00:20<01:50, 309.55batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6630/40960 [00:20<01:50, 309.55batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6688/40960 [00:20<01:53, 302.36batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6688/40960 [00:20<01:53, 302.36batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6759/40960 [00:20<01:47, 317.46batches/s, l2_loss: 0.0147 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6759/40960 [00:20<01:47, 317.46batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6827/40960 [00:20<01:45, 323.57batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6827/40960 [00:20<01:45, 323.57batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6907/40960 [00:21<01:38, 346.21batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6907/40960 [00:21<01:38, 346.21batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6990/40960 [00:21<01:32, 366.16batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6990/40960 [00:21<01:32, 366.16batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7071/40960 [00:21<01:29, 377.19batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7071/40960 [00:21<01:29, 377.19batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7147/40960 [00:21<01:29, 376.73batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7147/40960 [00:21<01:29, 376.73batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7220/40960 [00:21<01:30, 371.80batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7220/40960 [00:21<01:30, 371.80batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7294/40960 [00:22<01:30, 370.22batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7294/40960 [00:22<01:30, 370.22batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7367/40960 [00:22<01:31, 368.58batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7367/40960 [00:22<01:31, 368.58batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7443/40960 [00:22<01:30, 371.14batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7443/40960 [00:22<01:30, 371.14batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7515/40960 [00:22<01:31, 367.17batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7515/40960 [00:22<01:31, 367.17batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7594/40960 [00:22<01:29, 374.86batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7594/40960 [00:22<01:29, 374.86batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7673/40960 [00:23<01:27, 380.26batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7673/40960 [00:23<01:27, 380.26batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7750/40960 [00:23<01:27, 380.28batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7750/40960 [00:23<01:27, 380.28batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7828/40960 [00:23<01:26, 383.14batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7828/40960 [00:23<01:26, 383.14batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7908/40960 [00:23<01:25, 387.10batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7908/40960 [00:23<01:25, 387.10batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7990/40960 [00:23<01:23, 392.82batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7990/40960 [00:23<01:23, 392.82batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8069/40960 [00:24<01:23, 391.78batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8069/40960 [00:24<01:23, 391.78batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8147/40960 [00:24<01:24, 390.04batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8147/40960 [00:24<01:24, 390.04batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8222/40960 [00:24<01:25, 384.32batches/s, l2_loss: 0.0144 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8222/40960 [00:24<01:25, 384.32batches/s, l2_loss: 0.0141 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8294/40960 [00:24<01:26, 376.16batches/s, l2_loss: 0.0141 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8294/40960 [00:24<01:26, 376.16batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8368/40960 [00:24<01:27, 373.22batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8368/40960 [00:24<01:27, 373.22batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8437/40960 [00:25<01:29, 363.37batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8437/40960 [00:25<01:29, 363.37batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8502/40960 [00:25<01:32, 350.90batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8502/40960 [00:25<01:32, 350.90batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8568/40960 [00:25<01:34, 343.90batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8568/40960 [00:25<01:34, 343.90batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8633/40960 [00:25<01:36, 336.47batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|▏| 8633/40960 [00:25<01:36, 336.47batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8706/40960 [00:25<01:33, 344.39batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8706/40960 [00:25<01:33, 344.39batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8779/40960 [00:26<01:32, 349.48batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8779/40960 [00:26<01:32, 349.48batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8849/40960 [00:26<01:32, 347.86batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8849/40960 [00:26<01:32, 347.86batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8920/40960 [00:26<01:31, 349.96batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8920/40960 [00:26<01:31, 349.96batches/s, l2_loss: 0.0138 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8992/40960 [00:26<01:30, 352.47batches/s, l2_loss: 0.0138 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8992/40960 [00:26<01:30, 352.47batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9063/40960 [00:26<01:30, 352.27batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9063/40960 [00:26<01:30, 352.27batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9131/40960 [00:27<01:31, 348.30batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9131/40960 [00:27<01:31, 348.30batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9200/40960 [00:27<01:31, 347.23batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9200/40960 [00:27<01:31, 347.23batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9273/40960 [00:27<01:30, 351.26batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9273/40960 [00:27<01:30, 351.26batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9347/40960 [00:27<01:28, 355.74batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9347/40960 [00:27<01:28, 355.74batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9419/40960 [00:27<01:28, 355.73batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9419/40960 [00:27<01:28, 355.73batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9490/40960 [00:28<01:28, 355.17batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9490/40960 [00:28<01:28, 355.17batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9563/40960 [00:28<01:27, 357.90batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9563/40960 [00:28<01:27, 357.90batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9623/40960 [00:28<01:32, 338.77batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9623/40960 [00:28<01:32, 338.77batches/s, l2_loss: 0.0137 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9685/40960 [00:28<01:35, 328.97batches/s, l2_loss: 0.0137 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9685/40960 [00:28<01:35, 328.97batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9756/40960 [00:28<01:32, 336.07batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9756/40960 [00:28<01:32, 336.07batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9823/40960 [00:29<01:33, 334.34batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9823/40960 [00:29<01:33, 334.34batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9891/40960 [00:29<01:32, 334.91batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9891/40960 [00:29<01:32, 334.91batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9965/40960 [00:29<01:29, 344.68batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9965/40960 [00:29<01:29, 344.68batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10034/40960 [00:29<01:29, 344.38batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  24%|▏| 10034/40960 [00:29<01:29, 344.38batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  25%|▏| 10107/40960 [00:29<01:28, 349.78batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  25%|▏| 10107/40960 [00:29<01:28, 349.78batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  25%|▏| 10177/40960 [00:30<01:28, 349.80batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  25%|▏| 10177/40960 [00:30<01:28, 349.80batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  25%|▎| 10241/40960 [00:30<01:30, 340.88batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  25%|▎| 10241/40960 [00:30<01:30, 340.88batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  25%|▎| 10311/40960 [00:30<01:29, 343.32batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  25%|▎| 10311/40960 [00:30<01:29, 343.32batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  25%|▎| 10378/40960 [00:30<01:29, 340.20batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  25%|▎| 10378/40960 [00:30<01:29, 340.20batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10445/40960 [00:30<01:30, 338.56batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10445/40960 [00:30<01:30, 338.56batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10518/40960 [00:31<01:27, 346.15batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10518/40960 [00:31<01:27, 346.15batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10590/40960 [00:31<01:27, 349.07batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10590/40960 [00:31<01:27, 349.07batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10661/40960 [00:31<01:26, 349.78batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10661/40960 [00:31<01:26, 349.78batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10733/40960 [00:31<01:25, 352.83batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10733/40960 [00:31<01:25, 352.83batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10806/40960 [00:31<01:24, 355.85batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  26%|▎| 10806/40960 [00:31<01:24, 355.85batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 10881/40960 [00:32<01:23, 359.91batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 10881/40960 [00:32<01:23, 359.91batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 10951/40960 [00:32<01:24, 356.95batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 10951/40960 [00:32<01:24, 356.95batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 11025/40960 [00:32<01:23, 360.42batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 11025/40960 [00:32<01:23, 360.42batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 11098/40960 [00:32<01:22, 361.67batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 11098/40960 [00:32<01:22, 361.67batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 11172/40960 [00:32<01:21, 363.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  27%|▎| 11172/40960 [00:32<01:21, 363.45batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  27%|▎| 11243/40960 [00:33<01:22, 360.38batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  27%|▎| 11243/40960 [00:33<01:22, 360.38batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11317/40960 [00:33<01:21, 362.01batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11317/40960 [00:33<01:21, 362.01batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11389/40960 [00:33<01:21, 361.13batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11389/40960 [00:33<01:21, 361.13batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11462/40960 [00:33<01:21, 362.17batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11462/40960 [00:33<01:21, 362.17batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11533/40960 [00:33<01:21, 359.54batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11533/40960 [00:33<01:21, 359.54batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11605/40960 [00:34<01:21, 358.37batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  28%|▎| 11605/40960 [00:34<01:21, 358.37batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  29%|▎| 11676/40960 [00:34<01:22, 356.62batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  29%|▎| 11676/40960 [00:34<01:22, 356.62batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  29%|▎| 11749/40960 [00:34<01:21, 357.88batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  29%|▎| 11749/40960 [00:34<01:21, 357.88batches/s, l2_loss: 0.0135 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|▎| 11819/40960 [00:34<01:22, 354.79batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  29%|▎| 11819/40960 [00:34<01:22, 354.79batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  29%|▎| 11892/40960 [00:34<01:21, 357.81batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  29%|▎| 11892/40960 [00:34<01:21, 357.81batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  29%|▎| 11966/40960 [00:35<01:20, 360.18batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  29%|▎| 11966/40960 [00:35<01:20, 360.18batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  29%|▎| 12039/40960 [00:35<01:20, 361.37batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  29%|▎| 12039/40960 [00:35<01:20, 361.37batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  30%|▎| 12111/40960 [00:35<01:20, 360.47batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  30%|▎| 12111/40960 [00:35<01:20, 360.47batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  30%|▎| 12185/40960 [00:35<01:19, 363.27batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  30%|▎| 12185/40960 [00:35<01:19, 363.27batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  30%|▎| 12260/40960 [00:35<01:18, 365.98batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  30%|▎| 12260/40960 [00:35<01:18, 365.98batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  30%|▎| 12333/40960 [00:36<01:18, 364.89batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  30%|▎| 12333/40960 [00:36<01:18, 364.89batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  30%|▎| 12409/40960 [00:36<01:17, 368.87batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  30%|▎| 12409/40960 [00:36<01:17, 368.87batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  30%|▎| 12484/40960 [00:36<01:17, 369.51batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  30%|▎| 12484/40960 [00:36<01:17, 369.51batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  31%|▎| 12559/40960 [00:36<01:16, 370.93batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  31%|▎| 12559/40960 [00:36<01:16, 370.93batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  31%|▎| 12635/40960 [00:36<01:16, 372.40batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  31%|▎| 12635/40960 [00:36<01:16, 372.40batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  31%|▎| 12707/40960 [00:37<01:16, 367.11batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  31%|▎| 12707/40960 [00:37<01:16, 367.11batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  31%|▎| 12776/40960 [00:37<01:18, 359.85batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  31%|▎| 12776/40960 [00:37<01:18, 359.85batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  31%|▎| 12845/40960 [00:37<01:19, 354.86batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  31%|▎| 12845/40960 [00:37<01:19, 354.86batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 12918/40960 [00:37<01:18, 356.62batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 12918/40960 [00:37<01:18, 356.62batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 12984/40960 [00:37<01:20, 348.42batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 12984/40960 [00:37<01:20, 348.42batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 13054/40960 [00:38<01:20, 348.70batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 13054/40960 [00:38<01:20, 348.70batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 13122/40960 [00:38<01:20, 344.83batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 13122/40960 [00:38<01:20, 344.83batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  32%|▎| 13193/40960 [00:38<01:19, 347.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  32%|▎| 13193/40960 [00:38<01:19, 347.45batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 13259/40960 [00:38<01:21, 340.77batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  32%|▎| 13259/40960 [00:38<01:21, 340.77batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  33%|▎| 13332/40960 [00:38<01:19, 347.30batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  33%|▎| 13332/40960 [00:38<01:19, 347.30batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13405/40960 [00:39<01:18, 352.25batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13405/40960 [00:39<01:18, 352.25batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13477/40960 [00:39<01:17, 353.80batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13477/40960 [00:39<01:17, 353.80batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13544/40960 [00:39<01:18, 348.09batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13544/40960 [00:39<01:18, 348.09batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13613/40960 [00:39<01:18, 346.94batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13613/40960 [00:39<01:18, 346.94batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13685/40960 [00:39<01:17, 350.67batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  33%|▎| 13685/40960 [00:39<01:17, 350.67batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 13756/40960 [00:40<01:17, 351.95batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 13756/40960 [00:40<01:17, 351.95batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 13825/40960 [00:40<01:17, 349.51batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 13825/40960 [00:40<01:17, 349.51batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 13896/40960 [00:40<01:17, 349.74batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 13896/40960 [00:40<01:17, 349.74batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 13967/40960 [00:40<01:17, 349.88batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 13967/40960 [00:40<01:17, 349.88batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 14037/40960 [00:40<01:17, 349.24batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 14037/40960 [00:40<01:17, 349.24batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 14108/40960 [00:41<01:16, 350.35batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  34%|▎| 14108/40960 [00:41<01:16, 350.35batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  35%|▎| 14180/40960 [00:41<01:15, 352.78batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  35%|▎| 14180/40960 [00:41<01:15, 352.78batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14255/40960 [00:41<01:14, 358.10batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14255/40960 [00:41<01:14, 358.10batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14327/40960 [00:41<01:14, 356.99batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14327/40960 [00:41<01:14, 356.99batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14401/40960 [00:41<01:13, 360.80batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14401/40960 [00:41<01:13, 360.80batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14458/40960 [00:42<01:19, 335.42batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14458/40960 [00:42<01:19, 335.42batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14531/40960 [00:42<01:17, 342.75batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  35%|▎| 14531/40960 [00:42<01:17, 342.75batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14604/40960 [00:42<01:15, 348.14batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14604/40960 [00:42<01:15, 348.14batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14678/40960 [00:42<01:14, 353.75batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14678/40960 [00:42<01:14, 353.75batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14750/40960 [00:43<01:13, 355.40batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14750/40960 [00:43<01:13, 355.40batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14826/40960 [00:43<01:12, 361.63batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14826/40960 [00:43<01:12, 361.63batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14897/40960 [00:43<01:12, 359.31batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  36%|▎| 14897/40960 [00:43<01:12, 359.31batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 14967/40960 [00:43<01:13, 355.45batches/s, l2_loss: 0.0135 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 14967/40960 [00:43<01:13, 355.45batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15038/40960 [00:43<01:13, 354.66batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15038/40960 [00:43<01:13, 354.66batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15111/40960 [00:44<01:12, 357.08batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15111/40960 [00:44<01:12, 357.08batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15183/40960 [00:44<01:12, 357.59batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15183/40960 [00:44<01:12, 357.59batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15258/40960 [00:44<01:11, 361.43batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15258/40960 [00:44<01:11, 361.43batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15331/40960 [00:44<01:10, 362.13batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  37%|▎| 15331/40960 [00:44<01:10, 362.13batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15403/40960 [00:44<01:10, 360.33batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15403/40960 [00:44<01:10, 360.33batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15475/40960 [00:45<01:10, 359.44batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15475/40960 [00:45<01:10, 359.44batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15540/40960 [00:45<01:12, 348.80batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15540/40960 [00:45<01:12, 348.80batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15610/40960 [00:45<01:12, 348.17batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15610/40960 [00:45<01:12, 348.17batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15683/40960 [00:45<01:11, 352.10batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15683/40960 [00:45<01:11, 352.10batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15751/40960 [00:45<01:12, 348.09batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  38%|▍| 15751/40960 [00:45<01:12, 348.09batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 15824/40960 [00:46<01:11, 353.07batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 15824/40960 [00:46<01:11, 353.07batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 15897/40960 [00:46<01:10, 355.79batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 15897/40960 [00:46<01:10, 355.79batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 15970/40960 [00:46<01:09, 358.14batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 15970/40960 [00:46<01:09, 358.14batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 16043/40960 [00:46<01:09, 359.12batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 16043/40960 [00:46<01:09, 359.12batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 16116/40960 [00:46<01:08, 360.58batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  39%|▍| 16116/40960 [00:46<01:08, 360.58batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16188/40960 [00:47<01:08, 360.39batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16188/40960 [00:47<01:08, 360.39batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16262/40960 [00:47<01:08, 362.28batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16262/40960 [00:47<01:08, 362.28batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16336/40960 [00:47<01:07, 364.21batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16336/40960 [00:47<01:07, 364.21batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16404/40960 [00:47<01:08, 356.69batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16404/40960 [00:47<01:08, 356.69batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16468/40960 [00:47<01:10, 345.13batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16468/40960 [00:47<01:10, 345.13batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16539/40960 [00:48<01:10, 347.49batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  40%|▍| 16539/40960 [00:48<01:10, 347.49batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16612/40960 [00:48<01:09, 352.03batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16612/40960 [00:48<01:09, 352.03batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16682/40960 [00:48<01:09, 351.10batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16682/40960 [00:48<01:09, 351.10batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16755/40960 [00:48<01:08, 353.98batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16755/40960 [00:48<01:08, 353.98batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16826/40960 [00:48<01:08, 354.27batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16826/40960 [00:48<01:08, 354.27batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16898/40960 [00:49<01:07, 355.21batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16898/40960 [00:49<01:07, 355.21batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16968/40960 [00:49<01:07, 353.45batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  41%|▍| 16968/40960 [00:49<01:07, 353.45batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17042/40960 [00:49<01:06, 357.34batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17042/40960 [00:49<01:06, 357.34batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17114/40960 [00:49<01:06, 356.85batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17114/40960 [00:49<01:06, 356.85batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17186/40960 [00:49<01:06, 356.87batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17186/40960 [00:49<01:06, 356.87batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17259/40960 [00:50<01:06, 358.63batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17259/40960 [00:50<01:06, 358.63batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17333/40960 [00:50<01:05, 360.72batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17333/40960 [00:50<01:05, 360.72batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17408/40960 [00:50<01:04, 364.81batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  42%|▍| 17408/40960 [00:50<01:04, 364.81batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17482/40960 [00:50<01:04, 365.05batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17482/40960 [00:50<01:04, 365.05batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17556/40960 [00:50<01:03, 366.44batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17556/40960 [00:50<01:03, 366.44batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17628/40960 [00:51<01:04, 364.38batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17628/40960 [00:51<01:04, 364.38batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17703/40960 [00:51<01:03, 366.26batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17703/40960 [00:51<01:03, 366.26batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17776/40960 [00:51<01:03, 364.69batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  43%|▍| 17776/40960 [00:51<01:03, 364.69batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 17851/40960 [00:51<01:02, 366.84batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 17851/40960 [00:51<01:02, 366.84batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 17924/40960 [00:51<01:02, 365.98batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 17924/40960 [00:51<01:02, 365.98batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 17999/40960 [00:52<01:02, 367.25batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 17999/40960 [00:52<01:02, 367.25batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 18071/40960 [00:52<01:02, 364.73batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 18071/40960 [00:52<01:02, 364.73batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 18145/40960 [00:52<01:02, 365.44batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 18145/40960 [00:52<01:02, 365.44batches/s, l2_loss: 0.0135 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 18217/40960 [00:52<01:02, 362.61batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  44%|▍| 18217/40960 [00:52<01:02, 362.61batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18287/40960 [00:52<01:03, 358.73batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18287/40960 [00:52<01:03, 358.73batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18360/40960 [00:53<01:02, 360.13batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18360/40960 [00:53<01:02, 360.13batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18434/40960 [00:53<01:02, 362.20batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18434/40960 [00:53<01:02, 362.20batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18510/40960 [00:53<01:01, 366.28batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18510/40960 [00:53<01:01, 366.28batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18584/40960 [00:53<01:01, 366.15batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  45%|▍| 18584/40960 [00:53<01:01, 366.15batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18655/40960 [00:53<01:01, 361.92batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18655/40960 [00:53<01:01, 361.92batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18728/40960 [00:54<01:01, 362.01batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18728/40960 [00:54<01:01, 362.01batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18801/40960 [00:54<01:01, 361.68batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18801/40960 [00:54<01:01, 361.68batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18871/40960 [00:54<01:01, 357.95batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18871/40960 [00:54<01:01, 357.95batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18945/40960 [00:54<01:01, 360.37batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 18945/40960 [00:54<01:01, 360.37batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 19019/40960 [00:54<01:00, 362.67batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  46%|▍| 19019/40960 [00:54<01:00, 362.67batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19093/40960 [00:55<01:00, 364.35batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19093/40960 [00:55<01:00, 364.35batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19167/40960 [00:55<00:59, 364.83batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19167/40960 [00:55<00:59, 364.83batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19241/40960 [00:55<00:59, 365.51batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19241/40960 [00:55<00:59, 365.51batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19314/40960 [00:55<00:59, 364.17batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19314/40960 [00:55<00:59, 364.17batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19385/40960 [00:55<00:59, 359.82batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19385/40960 [00:55<00:59, 359.82batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19455/40960 [00:56<01:00, 356.46batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  47%|▍| 19455/40960 [00:56<01:00, 356.46batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  48%|▍| 19530/40960 [00:56<00:59, 361.17batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  48%|▍| 19530/40960 [00:56<00:59, 361.17batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  48%|▍| 19601/40960 [00:56<00:59, 358.06batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  48%|▍| 19601/40960 [00:56<00:59, 358.06batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  48%|▍| 19673/40960 [00:56<00:59, 358.20batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  48%|▍| 19673/40960 [00:56<00:59, 358.20batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  48%|▍| 19747/40960 [00:56<00:58, 360.78batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  48%|▍| 19747/40960 [00:56<00:58, 360.78batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  48%|▍| 19822/40960 [00:57<00:58, 363.62batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  48%|▍| 19822/40960 [00:57<00:58, 363.62batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 19897/40960 [00:57<00:57, 367.00batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 19897/40960 [00:57<00:57, 367.00batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 19965/40960 [00:57<00:58, 358.32batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 19965/40960 [00:57<00:58, 358.32batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 20034/40960 [00:57<00:59, 353.74batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 20034/40960 [00:57<00:59, 353.74batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  49%|▍| 20105/40960 [00:57<00:59, 353.44batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  49%|▍| 20105/40960 [00:57<00:59, 353.44batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 20176/40960 [00:58<00:58, 353.10batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 20176/40960 [00:58<00:58, 353.10batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 20249/40960 [00:58<00:58, 355.99batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  49%|▍| 20249/40960 [00:58<00:58, 355.99batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▍| 20324/40960 [00:58<00:57, 360.40batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▍| 20324/40960 [00:58<00:57, 360.40batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▍| 20398/40960 [00:58<00:56, 362.05batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▍| 20398/40960 [00:58<00:56, 362.05batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▍| 20470/40960 [00:58<00:56, 360.10batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▍| 20470/40960 [00:58<00:56, 360.10batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▌| 20540/40960 [00:59<00:57, 356.05batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▌| 20540/40960 [00:59<00:57, 356.05batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▌| 20613/40960 [00:59<00:56, 358.00batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▌| 20613/40960 [00:59<00:56, 358.00batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▌| 20680/40960 [00:59<00:57, 350.89batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  50%|▌| 20680/40960 [00:59<00:57, 350.89batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20746/40960 [00:59<00:58, 343.00batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20746/40960 [00:59<00:58, 343.00batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20792/40960 [00:59<01:05, 306.99batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20792/40960 [00:59<01:05, 306.99batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20852/40960 [01:00<01:06, 304.04batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20852/40960 [01:00<01:06, 304.04batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20923/40960 [01:00<01:02, 318.40batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20923/40960 [01:00<01:02, 318.40batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20989/40960 [01:00<01:02, 321.20batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 20989/40960 [01:00<01:02, 321.20batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 21050/40960 [01:00<01:03, 315.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  51%|▌| 21050/40960 [01:00<01:03, 315.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21118/40960 [01:00<01:01, 322.53batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21118/40960 [01:00<01:01, 322.53batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21193/40960 [01:01<00:58, 337.24batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21193/40960 [01:01<00:58, 337.24batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21267/40960 [01:01<00:56, 345.97batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21267/40960 [01:01<00:56, 345.97batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21330/40960 [01:01<00:58, 334.75batches/s, l2_loss: 0.0136 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21330/40960 [01:01<00:58, 334.75batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21402/40960 [01:01<00:57, 340.97batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21402/40960 [01:01<00:57, 340.97batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21477/40960 [01:01<00:55, 349.80batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  52%|▌| 21477/40960 [01:01<00:55, 349.80batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21551/40960 [01:02<00:54, 355.29batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21551/40960 [01:02<00:54, 355.29batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21625/40960 [01:02<00:53, 358.94batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21625/40960 [01:02<00:53, 358.94batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21699/40960 [01:02<00:53, 361.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21699/40960 [01:02<00:53, 361.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21769/40960 [01:02<00:53, 356.29batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21769/40960 [01:02<00:53, 356.29batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21843/40960 [01:02<00:53, 359.24batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  53%|▌| 21843/40960 [01:02<00:53, 359.24batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 21918/40960 [01:03<00:52, 363.80batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 21918/40960 [01:03<00:52, 363.80batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 21991/40960 [01:03<00:52, 362.86batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 21991/40960 [01:03<00:52, 362.86batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 22063/40960 [01:03<00:52, 361.14batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 22063/40960 [01:03<00:52, 361.14batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 22134/40960 [01:03<00:52, 358.70batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 22134/40960 [01:03<00:52, 358.70batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 22205/40960 [01:03<00:52, 357.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 22205/40960 [01:03<00:52, 357.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 22279/40960 [01:04<00:51, 359.93batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  54%|▌| 22279/40960 [01:04<00:51, 359.93batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22347/40960 [01:04<00:52, 353.72batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22347/40960 [01:04<00:52, 353.72batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22419/40960 [01:04<00:52, 355.04batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22419/40960 [01:04<00:52, 355.04batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22493/40960 [01:04<00:51, 358.13batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22493/40960 [01:04<00:51, 358.13batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22567/40960 [01:04<00:51, 360.50batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22567/40960 [01:04<00:51, 360.50batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22641/40960 [01:05<00:50, 362.96batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22641/40960 [01:05<00:50, 362.96batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22715/40960 [01:05<00:50, 364.36batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  55%|▌| 22715/40960 [01:05<00:50, 364.36batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 22789/40960 [01:05<00:49, 364.83batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 22789/40960 [01:05<00:49, 364.83batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 22862/40960 [01:05<00:49, 363.98batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 22862/40960 [01:05<00:49, 363.98batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 22937/40960 [01:05<00:49, 366.94batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 22937/40960 [01:05<00:49, 366.94batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 22989/40960 [01:06<00:54, 331.96batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 22989/40960 [01:06<00:54, 331.96batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 23062/40960 [01:06<00:52, 341.76batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 23062/40960 [01:06<00:52, 341.76batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 23129/40960 [01:06<00:52, 338.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  56%|▌| 23129/40960 [01:06<00:52, 338.45batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23205/40960 [01:06<00:50, 349.71batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23205/40960 [01:06<00:50, 349.71batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23277/40960 [01:06<00:50, 351.60batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23277/40960 [01:06<00:50, 351.60batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23349/40960 [01:07<00:49, 352.27batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23349/40960 [01:07<00:49, 352.27batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23424/40960 [01:07<00:48, 358.08batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23424/40960 [01:07<00:48, 358.08batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23498/40960 [01:07<00:48, 360.52batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  57%|▌| 23498/40960 [01:07<00:48, 360.52batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23575/40960 [01:07<00:47, 366.73batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23575/40960 [01:07<00:47, 366.73batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23650/40960 [01:08<00:46, 368.55batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23650/40960 [01:08<00:46, 368.55batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23725/40960 [01:08<00:46, 369.65batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23725/40960 [01:08<00:46, 369.65batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23799/40960 [01:08<00:46, 369.62batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23799/40960 [01:08<00:46, 369.62batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23871/40960 [01:08<00:46, 366.57batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23871/40960 [01:08<00:46, 366.57batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23943/40960 [01:08<00:46, 363.32batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  58%|▌| 23943/40960 [01:08<00:46, 363.32batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 23994/40960 [01:09<00:51, 330.82batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 23994/40960 [01:09<00:51, 330.82batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24057/40960 [01:09<00:51, 325.42batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24057/40960 [01:09<00:51, 325.42batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24131/40960 [01:09<00:49, 338.44batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24131/40960 [01:09<00:49, 338.44batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24202/40960 [01:09<00:48, 342.60batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24202/40960 [01:09<00:48, 342.60batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24276/40960 [01:09<00:47, 350.16batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24276/40960 [01:09<00:47, 350.16batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24350/40960 [01:10<00:46, 355.10batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  59%|▌| 24350/40960 [01:10<00:46, 355.10batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24419/40960 [01:10<00:47, 350.72batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24419/40960 [01:10<00:47, 350.72batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24488/40960 [01:10<00:47, 348.08batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24488/40960 [01:10<00:47, 348.08batches/s, l2_loss: 0.0137 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 24559/40960 [01:10<00:46, 349.90batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24559/40960 [01:10<00:46, 349.90batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24628/40960 [01:10<00:47, 347.22batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24628/40960 [01:10<00:47, 347.22batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24698/40960 [01:11<00:46, 347.97batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24698/40960 [01:11<00:46, 347.97batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24771/40960 [01:11<00:45, 352.08batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  60%|▌| 24771/40960 [01:11<00:45, 352.08batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 24844/40960 [01:11<00:45, 354.96batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 24844/40960 [01:11<00:45, 354.96batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 24911/40960 [01:11<00:46, 348.44batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 24911/40960 [01:11<00:46, 348.44batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 24976/40960 [01:11<00:46, 341.30batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 24976/40960 [01:11<00:46, 341.30batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 25036/40960 [01:12<00:48, 327.65batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 25036/40960 [01:12<00:48, 327.65batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 25103/40960 [01:12<00:48, 329.04batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 25103/40960 [01:12<00:48, 329.04batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 25170/40960 [01:12<00:47, 329.53batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  61%|▌| 25170/40960 [01:12<00:47, 329.53batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25239/40960 [01:12<00:47, 333.72batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25239/40960 [01:12<00:47, 333.72batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25310/40960 [01:12<00:46, 338.93batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25310/40960 [01:12<00:46, 338.93batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25380/40960 [01:13<00:45, 342.09batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25380/40960 [01:13<00:45, 342.09batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25441/40960 [01:13<00:46, 330.49batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25441/40960 [01:13<00:46, 330.49batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25501/40960 [01:13<00:48, 321.14batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25501/40960 [01:13<00:48, 321.14batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25570/40960 [01:13<00:46, 327.90batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  62%|▌| 25570/40960 [01:13<00:46, 327.90batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25633/40960 [01:13<00:47, 323.10batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25633/40960 [01:13<00:47, 323.10batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25700/40960 [01:14<00:46, 326.24batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25700/40960 [01:14<00:46, 326.24batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25768/40960 [01:14<00:46, 329.69batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25768/40960 [01:14<00:46, 329.69batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25836/40960 [01:14<00:45, 332.75batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25836/40960 [01:14<00:45, 332.75batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25907/40960 [01:14<00:44, 338.76batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25907/40960 [01:14<00:44, 338.76batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25971/40960 [01:14<00:45, 331.97batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  63%|▋| 25971/40960 [01:14<00:45, 331.97batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  64%|▋| 26044/40960 [01:15<00:43, 341.07batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  64%|▋| 26044/40960 [01:15<00:43, 341.07batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26112/40960 [01:15<00:43, 340.39batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26112/40960 [01:15<00:43, 340.39batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26179/40960 [01:15<00:43, 338.73batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26179/40960 [01:15<00:43, 338.73batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26253/40960 [01:15<00:42, 347.33batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26253/40960 [01:15<00:42, 347.33batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26317/40960 [01:15<00:43, 338.34batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26317/40960 [01:15<00:43, 338.34batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26390/40960 [01:16<00:42, 345.07batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  64%|▋| 26390/40960 [01:16<00:42, 345.07batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26457/40960 [01:16<00:42, 341.98batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26457/40960 [01:16<00:42, 341.98batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26526/40960 [01:16<00:42, 341.53batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26526/40960 [01:16<00:42, 341.53batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26601/40960 [01:16<00:41, 349.35batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26601/40960 [01:16<00:41, 349.35batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26666/40960 [01:16<00:41, 341.14batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26666/40960 [01:16<00:41, 341.14batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26740/40960 [01:17<00:40, 349.16batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26740/40960 [01:17<00:40, 349.16batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26807/40960 [01:17<00:41, 343.51batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  65%|▋| 26807/40960 [01:17<00:41, 343.51batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 26873/40960 [01:17<00:41, 339.12batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 26873/40960 [01:17<00:41, 339.12batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 26944/40960 [01:17<00:40, 342.21batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 26944/40960 [01:17<00:40, 342.21batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 27015/40960 [01:17<00:40, 345.60batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 27015/40960 [01:17<00:40, 345.60batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 27083/40960 [01:18<00:40, 342.90batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 27083/40960 [01:18<00:40, 342.90batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 27141/40960 [01:18<00:42, 327.06batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 27141/40960 [01:18<00:42, 327.06batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 27189/40960 [01:18<00:45, 300.33batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  66%|▋| 27189/40960 [01:18<00:45, 300.33batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27243/40960 [01:18<00:47, 290.55batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27243/40960 [01:18<00:47, 290.55batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27299/40960 [01:18<00:47, 286.88batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27299/40960 [01:18<00:47, 286.88batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27366/40960 [01:19<00:45, 300.50batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27366/40960 [01:19<00:45, 300.50batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27438/40960 [01:19<00:42, 317.01batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27438/40960 [01:19<00:42, 317.01batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27507/40960 [01:19<00:41, 325.33batches/s, l2_loss: 0.0138 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|▋| 27507/40960 [01:19<00:41, 325.33batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27582/40960 [01:19<00:39, 338.95batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  67%|▋| 27582/40960 [01:19<00:39, 338.95batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  68%|▋| 27655/40960 [01:19<00:38, 345.70batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  68%|▋| 27655/40960 [01:19<00:38, 345.70batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  68%|▋| 27729/40960 [01:20<00:37, 352.17batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  68%|▋| 27729/40960 [01:20<00:37, 352.17batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  68%|▋| 27804/40960 [01:20<00:36, 358.76batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  68%|▋| 27804/40960 [01:20<00:36, 358.76batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  68%|▋| 27877/40960 [01:20<00:36, 360.62batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  68%|▋| 27877/40960 [01:20<00:36, 360.62batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  68%|▋| 27947/40960 [01:20<00:36, 356.35batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  68%|▋| 27947/40960 [01:20<00:36, 356.35batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  68%|▋| 28021/40960 [01:20<00:35, 360.24batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  68%|▋| 28021/40960 [01:20<00:35, 360.24batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28095/40960 [01:21<00:35, 362.53batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28095/40960 [01:21<00:35, 362.53batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28169/40960 [01:21<00:35, 363.45batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28169/40960 [01:21<00:35, 363.45batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28240/40960 [01:21<00:35, 359.77batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28240/40960 [01:21<00:35, 359.77batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28312/40960 [01:21<00:35, 358.62batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28312/40960 [01:21<00:35, 358.62batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28382/40960 [01:21<00:35, 355.84batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28382/40960 [01:21<00:35, 355.84batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28451/40960 [01:22<00:35, 351.50batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  69%|▋| 28451/40960 [01:22<00:35, 351.50batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28520/40960 [01:22<00:35, 348.80batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28520/40960 [01:22<00:35, 348.80batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28590/40960 [01:22<00:35, 347.79batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28590/40960 [01:22<00:35, 347.79batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28662/40960 [01:22<00:35, 350.38batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28662/40960 [01:22<00:35, 350.38batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28733/40960 [01:22<00:34, 351.66batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28733/40960 [01:22<00:34, 351.66batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28806/40960 [01:23<00:34, 354.55batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  70%|▋| 28806/40960 [01:23<00:34, 354.55batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  71%|▋| 28880/40960 [01:23<00:33, 358.25batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  71%|▋| 28880/40960 [01:23<00:33, 358.25batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  71%|▋| 28953/40960 [01:23<00:33, 359.78batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  71%|▋| 28953/40960 [01:23<00:33, 359.78batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  71%|▋| 29027/40960 [01:23<00:33, 361.40batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  71%|▋| 29027/40960 [01:23<00:33, 361.40batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  71%|▋| 29100/40960 [01:23<00:32, 362.06batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  71%|▋| 29100/40960 [01:23<00:32, 362.06batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  71%|▋| 29173/40960 [01:24<00:32, 362.67batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  71%|▋| 29173/40960 [01:24<00:32, 362.67batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  71%|▋| 29235/40960 [01:24<00:33, 346.67batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  71%|▋| 29235/40960 [01:24<00:33, 346.67batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  71%|▋| 29283/40960 [01:24<00:37, 313.65batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  71%|▋| 29283/40960 [01:24<00:37, 313.65batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29351/40960 [01:24<00:36, 320.48batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29351/40960 [01:24<00:36, 320.48batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29395/40960 [01:24<00:39, 289.95batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29395/40960 [01:24<00:39, 289.95batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29459/40960 [01:25<00:38, 298.61batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29459/40960 [01:25<00:38, 298.61batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29504/40960 [01:25<00:41, 275.62batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29504/40960 [01:25<00:41, 275.62batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29567/40960 [01:25<00:39, 286.92batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29567/40960 [01:25<00:39, 286.92batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29614/40960 [01:25<00:41, 270.69batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29614/40960 [01:25<00:41, 270.69batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29688/40960 [01:25<00:37, 299.68batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  72%|▋| 29688/40960 [01:25<00:37, 299.68batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 29762/40960 [01:26<00:35, 319.90batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 29762/40960 [01:26<00:35, 319.90batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 29837/40960 [01:26<00:33, 335.09batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 29837/40960 [01:26<00:33, 335.09batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 29912/40960 [01:26<00:31, 346.02batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 29912/40960 [01:26<00:31, 346.02batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 29976/40960 [01:26<00:32, 336.56batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 29976/40960 [01:26<00:32, 336.56batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 30025/40960 [01:26<00:35, 308.63batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 30025/40960 [01:26<00:35, 308.63batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 30087/40960 [01:27<00:35, 308.80batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  73%|▋| 30087/40960 [01:27<00:35, 308.80batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  74%|▋| 30133/40960 [01:27<00:37, 285.18batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  74%|▋| 30133/40960 [01:27<00:37, 285.18batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30188/40960 [01:27<00:38, 281.26batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30188/40960 [01:27<00:38, 281.26batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30247/40960 [01:27<00:37, 284.53batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30247/40960 [01:27<00:37, 284.53batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30299/40960 [01:27<00:38, 275.84batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30299/40960 [01:27<00:38, 275.84batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30361/40960 [01:28<00:37, 285.41batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30361/40960 [01:28<00:37, 285.41batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30417/40960 [01:28<00:37, 283.56batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30417/40960 [01:28<00:37, 283.56batches/s, l2_loss: 0.0141 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|▋| 30481/40960 [01:28<00:35, 293.72batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  74%|▋| 30481/40960 [01:28<00:35, 293.72batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▋| 30554/40960 [01:28<00:33, 314.08batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▋| 30554/40960 [01:28<00:33, 314.08batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▋| 30624/40960 [01:28<00:31, 323.93batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▋| 30624/40960 [01:28<00:31, 323.93batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▋| 30697/40960 [01:29<00:30, 335.80batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▋| 30697/40960 [01:29<00:30, 335.80batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▊| 30769/40960 [01:29<00:29, 342.78batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▊| 30769/40960 [01:29<00:29, 342.78batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▊| 30841/40960 [01:29<00:29, 346.98batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▊| 30841/40960 [01:29<00:29, 346.98batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▊| 30914/40960 [01:29<00:28, 351.71batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  75%|▊| 30914/40960 [01:29<00:28, 351.71batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 30983/40960 [01:29<00:28, 348.47batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 30983/40960 [01:29<00:28, 348.47batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 31053/40960 [01:30<00:28, 348.25batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 31053/40960 [01:30<00:28, 348.25batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 31125/40960 [01:30<00:28, 350.67batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 31125/40960 [01:30<00:28, 350.67batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 31197/40960 [01:30<00:27, 352.76batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 31197/40960 [01:30<00:27, 352.76batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 31247/40960 [01:30<00:30, 320.90batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  76%|▊| 31247/40960 [01:30<00:30, 320.90batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  76%|▊| 31319/40960 [01:30<00:29, 332.09batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  76%|▊| 31319/40960 [01:30<00:29, 332.09batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31388/40960 [01:31<00:28, 334.61batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31388/40960 [01:31<00:28, 334.61batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31460/40960 [01:31<00:27, 341.22batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31460/40960 [01:31<00:27, 341.22batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31530/40960 [01:31<00:27, 343.27batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31530/40960 [01:31<00:27, 343.27batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31602/40960 [01:31<00:26, 347.63batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31602/40960 [01:31<00:26, 347.63batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31678/40960 [01:31<00:26, 356.60batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  77%|▊| 31678/40960 [01:31<00:26, 356.60batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 31748/40960 [01:32<00:26, 352.62batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 31748/40960 [01:32<00:26, 352.62batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 31819/40960 [01:32<00:25, 352.34batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 31819/40960 [01:32<00:25, 352.34batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 31889/40960 [01:32<00:25, 351.53batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 31889/40960 [01:32<00:25, 351.53batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 31961/40960 [01:32<00:25, 353.93batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 31961/40960 [01:32<00:25, 353.93batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 32034/40960 [01:32<00:25, 356.12batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 32034/40960 [01:32<00:25, 356.12batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 32104/40960 [01:33<00:25, 354.15batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  78%|▊| 32104/40960 [01:33<00:25, 354.15batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  79%|▊| 32178/40960 [01:33<00:24, 358.61batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  79%|▊| 32178/40960 [01:33<00:24, 358.61batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32241/40960 [01:33<00:25, 343.83batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32241/40960 [01:33<00:25, 343.83batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32309/40960 [01:33<00:25, 341.36batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32309/40960 [01:33<00:25, 341.36batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32378/40960 [01:33<00:25, 342.38batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32378/40960 [01:34<00:25, 342.38batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32447/40960 [01:34<00:24, 342.93batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32447/40960 [01:34<00:24, 342.93batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32519/40960 [01:34<00:24, 347.45batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  79%|▊| 32519/40960 [01:34<00:24, 347.45batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32592/40960 [01:34<00:23, 351.48batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32592/40960 [01:34<00:23, 351.48batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32663/40960 [01:34<00:23, 350.98batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32663/40960 [01:34<00:23, 350.98batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32738/40960 [01:35<00:23, 357.29batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32738/40960 [01:35<00:23, 357.29batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32813/40960 [01:35<00:22, 362.32batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32813/40960 [01:35<00:22, 362.32batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32887/40960 [01:35<00:22, 364.18batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32887/40960 [01:35<00:22, 364.18batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32960/40960 [01:35<00:21, 363.68batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  80%|▊| 32960/40960 [01:35<00:21, 363.68batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  81%|▊| 33032/40960 [01:35<00:21, 362.36batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  81%|▊| 33032/40960 [01:35<00:21, 362.36batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  81%|▊| 33104/40960 [01:36<00:21, 361.07batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  81%|▊| 33104/40960 [01:36<00:21, 361.07batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  81%|▊| 33176/40960 [01:36<00:21, 359.75batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  81%|▊| 33176/40960 [01:36<00:21, 359.75batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  81%|▊| 33251/40960 [01:36<00:21, 363.01batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  81%|▊| 33251/40960 [01:36<00:21, 363.01batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  81%|▊| 33325/40960 [01:36<00:21, 363.34batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  81%|▊| 33325/40960 [01:36<00:21, 363.34batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33396/40960 [01:36<00:21, 360.09batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33396/40960 [01:36<00:21, 360.09batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33468/40960 [01:37<00:20, 359.23batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33468/40960 [01:37<00:20, 359.23batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33544/40960 [01:37<00:20, 364.85batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33544/40960 [01:37<00:20, 364.85batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33618/40960 [01:37<00:20, 365.25batches/s, l2_loss: 0.0144 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|▊| 33618/40960 [01:37<00:20, 365.25batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33694/40960 [01:37<00:19, 369.07batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33694/40960 [01:37<00:19, 369.07batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33768/40960 [01:37<00:19, 368.49batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  82%|▊| 33768/40960 [01:37<00:19, 368.49batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 33843/40960 [01:38<00:19, 369.54batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 33843/40960 [01:38<00:19, 369.54batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 33918/40960 [01:38<00:19, 370.31batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 33918/40960 [01:38<00:19, 370.31batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 33992/40960 [01:38<00:18, 369.89batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 33992/40960 [01:38<00:18, 369.89batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 34063/40960 [01:38<00:18, 364.35batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 34063/40960 [01:38<00:18, 364.35batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 34128/40960 [01:38<00:19, 352.02batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 34128/40960 [01:38<00:19, 352.02batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 34190/40960 [01:39<00:19, 339.10batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  83%|▊| 34190/40960 [01:39<00:19, 339.10batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34254/40960 [01:39<00:20, 331.79batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34254/40960 [01:39<00:20, 331.79batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34320/40960 [01:39<00:20, 331.03batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34320/40960 [01:39<00:20, 331.03batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34389/40960 [01:39<00:19, 333.80batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34389/40960 [01:39<00:19, 333.80batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34447/40960 [01:39<00:20, 319.94batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34447/40960 [01:39<00:20, 319.94batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34519/40960 [01:40<00:19, 330.93batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  84%|▊| 34519/40960 [01:40<00:19, 330.93batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  84%|▊| 34583/40960 [01:40<00:19, 327.60batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  84%|▊| 34583/40960 [01:40<00:19, 327.60batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34655/40960 [01:40<00:18, 336.11batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34655/40960 [01:40<00:18, 336.11batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34726/40960 [01:40<00:18, 340.66batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34726/40960 [01:40<00:18, 340.66batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34799/40960 [01:40<00:17, 347.51batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34799/40960 [01:40<00:17, 347.51batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34873/40960 [01:41<00:17, 353.15batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34873/40960 [01:41<00:17, 353.15batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34947/40960 [01:41<00:16, 357.40batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 34947/40960 [01:41<00:16, 357.40batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 35014/40960 [01:41<00:16, 350.30batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  85%|▊| 35014/40960 [01:41<00:16, 350.30batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  86%|▊| 35088/40960 [01:41<00:16, 355.45batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  86%|▊| 35088/40960 [01:41<00:16, 355.45batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  86%|▊| 35159/40960 [01:41<00:16, 353.80batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  86%|▊| 35159/40960 [01:41<00:16, 353.80batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  86%|▊| 35228/40960 [01:42<00:16, 350.44batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  86%|▊| 35228/40960 [01:42<00:16, 350.44batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  86%|▊| 35295/40960 [01:42<00:16, 345.43batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  86%|▊| 35295/40960 [01:42<00:16, 345.43batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  86%|▊| 35364/40960 [01:42<00:16, 344.70batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  86%|▊| 35364/40960 [01:42<00:16, 344.70batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35437/40960 [01:42<00:15, 349.55batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35437/40960 [01:42<00:15, 349.55batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35507/40960 [01:42<00:15, 348.14batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35507/40960 [01:42<00:15, 348.14batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35573/40960 [01:43<00:15, 341.70batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35573/40960 [01:43<00:15, 341.70batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35643/40960 [01:43<00:15, 342.40batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35643/40960 [01:43<00:15, 342.40batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35716/40960 [01:43<00:15, 348.56batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35716/40960 [01:43<00:15, 348.56batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35776/40960 [01:43<00:15, 333.10batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  87%|▊| 35776/40960 [01:43<00:15, 333.10batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 35846/40960 [01:43<00:15, 337.33batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 35846/40960 [01:43<00:15, 337.33batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 35917/40960 [01:44<00:14, 342.14batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 35917/40960 [01:44<00:14, 342.14batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 35984/40960 [01:44<00:14, 339.72batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 35984/40960 [01:44<00:14, 339.72batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 36051/40960 [01:44<00:14, 337.20batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 36051/40960 [01:44<00:14, 337.20batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 36118/40960 [01:44<00:14, 334.56batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 36118/40960 [01:44<00:14, 334.56batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 36182/40960 [01:44<00:14, 329.17batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  88%|▉| 36182/40960 [01:44<00:14, 329.17batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36256/40960 [01:45<00:13, 340.86batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36256/40960 [01:45<00:13, 340.86batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36330/40960 [01:45<00:13, 348.36batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36330/40960 [01:45<00:13, 348.36batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36405/40960 [01:45<00:12, 355.88batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36405/40960 [01:45<00:12, 355.88batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36477/40960 [01:45<00:12, 356.41batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36477/40960 [01:45<00:12, 356.41batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36550/40960 [01:45<00:12, 358.97batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36550/40960 [01:45<00:12, 358.97batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36625/40960 [01:46<00:11, 363.35batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36625/40960 [01:46<00:11, 363.35batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36696/40960 [01:46<00:11, 359.84batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36696/40960 [01:46<00:11, 359.84batches/s, l2_loss: 0.0149 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 36768/40960 [01:46<00:11, 359.66batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36768/40960 [01:46<00:11, 359.66batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36841/40960 [01:46<00:11, 360.68batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36841/40960 [01:46<00:11, 360.68batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36914/40960 [01:46<00:11, 360.97batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36914/40960 [01:46<00:11, 360.97batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 36986/40960 [01:47<00:11, 359.96batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 36986/40960 [01:47<00:11, 359.96batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 37058/40960 [01:47<00:10, 359.06batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 37058/40960 [01:47<00:10, 359.06batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37131/40960 [01:47<00:10, 360.10batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37131/40960 [01:47<00:10, 360.10batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37198/40960 [01:47<00:10, 352.49batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37198/40960 [01:47<00:10, 352.49batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37265/40960 [01:47<00:10, 346.31batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37265/40960 [01:47<00:10, 346.31batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37334/40960 [01:48<00:10, 345.69batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37334/40960 [01:48<00:10, 345.69batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37403/40960 [01:48<00:10, 344.65batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  91%|▉| 37403/40960 [01:48<00:10, 344.65batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  91%|▉| 37477/40960 [01:48<00:09, 351.99batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  91%|▉| 37477/40960 [01:48<00:09, 351.99batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37548/40960 [01:48<00:09, 352.67batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37548/40960 [01:48<00:09, 352.67batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37618/40960 [01:48<00:09, 351.08batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37618/40960 [01:48<00:09, 351.08batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37693/40960 [01:49<00:09, 357.51batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37693/40960 [01:49<00:09, 357.51batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37767/40960 [01:49<00:08, 360.81batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37767/40960 [01:49<00:08, 360.81batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37837/40960 [01:49<00:08, 356.60batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  92%|▉| 37837/40960 [01:49<00:08, 356.60batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 37910/40960 [01:49<00:08, 358.33batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 37910/40960 [01:49<00:08, 358.33batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 37985/40960 [01:49<00:08, 361.90batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 37985/40960 [01:49<00:08, 361.90batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 38060/40960 [01:50<00:07, 364.83batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 38060/40960 [01:50<00:07, 364.83batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 38133/40960 [01:50<00:07, 364.26batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 38133/40960 [01:50<00:07, 364.26batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 38206/40960 [01:50<00:07, 363.93batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 38206/40960 [01:50<00:07, 363.93batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 38280/40960 [01:50<00:07, 364.47batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  93%|▉| 38280/40960 [01:50<00:07, 364.47batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38350/40960 [01:50<00:07, 359.87batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38350/40960 [01:50<00:07, 359.87batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38421/40960 [01:51<00:07, 357.82batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38421/40960 [01:51<00:07, 357.82batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38495/40960 [01:51<00:06, 360.46batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38495/40960 [01:51<00:06, 360.46batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38564/40960 [01:51<00:06, 355.46batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38564/40960 [01:51<00:06, 355.46batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38632/40960 [01:51<00:06, 350.43batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38632/40960 [01:51<00:06, 350.43batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38702/40960 [01:51<00:06, 349.21batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  94%|▉| 38702/40960 [01:51<00:06, 349.21batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 38769/40960 [01:52<00:06, 344.94batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 38769/40960 [01:52<00:06, 344.94batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 38824/40960 [01:52<00:06, 323.83batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 38824/40960 [01:52<00:06, 323.83batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 38894/40960 [01:52<00:06, 330.82batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 38894/40960 [01:52<00:06, 330.82batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 38957/40960 [01:52<00:06, 322.91batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 38957/40960 [01:52<00:06, 322.91batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 39007/40960 [01:52<00:06, 300.59batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 39007/40960 [01:52<00:06, 300.59batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 39061/40960 [01:53<00:06, 289.58batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  95%|▉| 39061/40960 [01:53<00:06, 289.58batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  96%|▉| 39129/40960 [01:53<00:06, 304.04batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  96%|▉| 39129/40960 [01:53<00:06, 304.04batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39204/40960 [01:53<00:05, 324.20batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39204/40960 [01:53<00:05, 324.20batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39278/40960 [01:53<00:04, 336.59batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39278/40960 [01:53<00:04, 336.59batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39349/40960 [01:53<00:04, 340.76batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39349/40960 [01:53<00:04, 340.76batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39420/40960 [01:54<00:04, 344.32batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39420/40960 [01:54<00:04, 344.32batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39495/40960 [01:54<00:04, 352.55batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  96%|▉| 39495/40960 [01:54<00:04, 352.55batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  97%|▉| 39567/40960 [01:54<00:03, 354.52batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  97%|▉| 39567/40960 [01:54<00:03, 354.52batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39632/40960 [01:54<00:03, 344.65batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39632/40960 [01:54<00:03, 344.65batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39704/40960 [01:54<00:03, 348.93batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39704/40960 [01:54<00:03, 348.93batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39779/40960 [01:55<00:03, 355.83batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39779/40960 [01:55<00:03, 355.83batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39852/40960 [01:55<00:03, 358.18batches/s, l2_loss: 0.0156 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39852/40960 [01:55<00:03, 358.18batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39925/40960 [01:55<00:02, 360.08batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  97%|▉| 39925/40960 [01:55<00:02, 360.08batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  98%|▉| 39999/40960 [01:55<00:02, 361.83batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  98%|▉| 39999/40960 [01:55<00:02, 361.83batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  98%|▉| 40073/40960 [01:55<00:02, 362.89batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  98%|▉| 40073/40960 [01:55<00:02, 362.89batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  98%|▉| 40144/40960 [01:56<00:02, 359.21batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  98%|▉| 40144/40960 [01:56<00:02, 359.21batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  98%|▉| 40215/40960 [01:56<00:02, 356.78batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  98%|▉| 40215/40960 [01:56<00:02, 356.78batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  98%|▉| 40283/40960 [01:56<00:01, 350.77batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  98%|▉| 40283/40960 [01:56<00:01, 350.77batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  99%|▉| 40358/40960 [01:56<00:01, 357.07batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  99%|▉| 40358/40960 [01:56<00:01, 357.07batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  99%|▉| 40426/40960 [01:56<00:01, 351.08batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  99%|▉| 40426/40960 [01:56<00:01, 351.08batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  99%|▉| 40499/40960 [01:57<00:01, 354.07batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  99%|▉| 40499/40960 [01:57<00:01, 354.07batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  99%|▉| 40572/40960 [01:57<00:01, 357.12batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  99%|▉| 40572/40960 [01:57<00:01, 357.12batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  99%|▉| 40645/40960 [01:57<00:00, 358.85batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  99%|▉| 40645/40960 [01:57<00:00, 358.85batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  99%|▉| 40718/40960 [01:57<00:00, 360.19batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  99%|▉| 40718/40960 [01:57<00:00, 360.19batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training: 100%|▉| 40790/40960 [01:57<00:00, 359.58batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training: 100%|▉| 40790/40960 [01:57<00:00, 359.58batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training: 100%|▉| 40865/40960 [01:58<00:00, 362.90batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training: 100%|▉| 40865/40960 [01:58<00:00, 362.90batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "Training: 100%|▉| 40938/40960 [01:58<00:00, 363.00batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "Training: 100%|▉| 40938/40960 [01:58<00:00, 363.00batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 14:56:51.383915: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  19%|▏| 5/26 [09:12<39:34, 113.07s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 14:56:53.452651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A\n",
      "Training:   0%|                                | 1/40960 [00:00<9:45:58,  1.16batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<9:45:58,  1.16batches/s, l2_loss: 0.0088 - round_loss: \u001b[A2025-06-09 14:56:56.176777: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%| | 94/40960 [00:01<05:49, 116.80batches/s, l2_loss: 0.0088 - round_loss: \u001b[A\n",
      "Training:   0%| | 94/40960 [00:01<05:49, 116.80batches/s, l2_loss: 0.0162 - round_loss: \u001b[A\n",
      "Training:   0%| | 183/40960 [00:01<03:21, 202.78batches/s, l2_loss: 0.0162 - round_loss:\u001b[A\n",
      "Training:   0%| | 183/40960 [00:01<03:21, 202.78batches/s, l2_loss: 0.0146 - round_loss:\u001b[A\n",
      "Training:   1%| | 276/40960 [00:01<02:28, 274.03batches/s, l2_loss: 0.0146 - round_loss:\u001b[A\n",
      "Training:   1%| | 276/40960 [00:01<02:28, 274.03batches/s, l2_loss: 0.0145 - round_loss:\u001b[A\n",
      "Training:   1%| | 371/40960 [00:01<02:03, 329.51batches/s, l2_loss: 0.0145 - round_loss:\u001b[A\n",
      "Training:   1%| | 371/40960 [00:01<02:03, 329.51batches/s, l2_loss: 0.0142 - round_loss:\u001b[A\n",
      "Training:   1%| | 462/40960 [00:01<01:51, 364.38batches/s, l2_loss: 0.0142 - round_loss:\u001b[A\n",
      "Training:   1%| | 462/40960 [00:01<01:51, 364.38batches/s, l2_loss: 0.0141 - round_loss:\u001b[A\n",
      "Training:   1%| | 554/40960 [00:02<01:43, 391.60batches/s, l2_loss: 0.0141 - round_loss:\u001b[A\n",
      "Training:   1%| | 554/40960 [00:02<01:43, 391.60batches/s, l2_loss: 0.0138 - round_loss:\u001b[A\n",
      "Training:   2%| | 645/40960 [00:02<01:38, 409.46batches/s, l2_loss: 0.0138 - round_loss:\u001b[A\n",
      "Training:   2%| | 645/40960 [00:02<01:38, 409.46batches/s, l2_loss: 0.0137 - round_loss:\u001b[A\n",
      "Training:   2%| | 739/40960 [00:02<01:34, 426.40batches/s, l2_loss: 0.0137 - round_loss:\u001b[A\n",
      "Training:   2%| | 739/40960 [00:02<01:34, 426.40batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   2%| | 830/40960 [00:02<01:32, 434.10batches/s, l2_loss: 0.0136 - round_loss:\u001b[A\n",
      "Training:   2%| | 830/40960 [00:02<01:32, 434.10batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 922/40960 [00:02<01:30, 441.33batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 922/40960 [00:02<01:30, 441.33batches/s, l2_loss: 0.0134 - round_loss:\u001b[A\n",
      "Training:   2%| | 1014/40960 [00:03<01:29, 446.16batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   2%| | 1014/40960 [00:03<01:29, 446.16batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   3%| | 1107/40960 [00:03<01:28, 450.69batches/s, l2_loss: 0.0133 - round_loss\u001b[A\n",
      "Training:   3%| | 1107/40960 [00:03<01:28, 450.69batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:   3%| | 1199/40960 [00:03<01:27, 452.51batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:   3%| | 1199/40960 [00:03<01:27, 452.51batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:   3%| | 1292/40960 [00:03<01:27, 455.39batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:   3%| | 1292/40960 [00:03<01:27, 455.39batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:   3%| | 1384/40960 [00:03<01:26, 456.40batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:   3%| | 1384/40960 [00:03<01:26, 456.40batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:   4%| | 1477/40960 [00:04<01:26, 458.03batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:   4%| | 1477/40960 [00:04<01:26, 458.03batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:   4%| | 1568/40960 [00:04<01:26, 456.16batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:   4%| | 1568/40960 [00:04<01:26, 456.16batches/s, l2_loss: 0.0127 - round_loss\u001b[A\n",
      "Training:   4%| | 1660/40960 [00:04<01:25, 457.20batches/s, l2_loss: 0.0127 - round_loss\u001b[A\n",
      "Training:   4%| | 1660/40960 [00:04<01:25, 457.20batches/s, l2_loss: 0.0127 - round_loss\u001b[A\n",
      "Training:   4%| | 1753/40960 [00:04<01:25, 458.60batches/s, l2_loss: 0.0127 - round_loss\u001b[A\n",
      "Training:   4%| | 1753/40960 [00:04<01:25, 458.60batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:   5%| | 1846/40960 [00:04<01:25, 459.14batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:   5%| | 1846/40960 [00:04<01:25, 459.14batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:   5%| | 1938/40960 [00:05<01:25, 458.18batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:   5%| | 1938/40960 [00:05<01:25, 458.18batches/s, l2_loss: 0.0125 - round_loss\u001b[A\n",
      "Training:   5%| | 2029/40960 [00:05<01:25, 457.20batches/s, l2_loss: 0.0125 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 2029/40960 [00:05<01:25, 457.20batches/s, l2_loss: 0.0125 - round_loss\u001b[A\n",
      "Training:   5%| | 2120/40960 [00:05<01:25, 455.73batches/s, l2_loss: 0.0125 - round_loss\u001b[A\n",
      "Training:   5%| | 2120/40960 [00:05<01:25, 455.73batches/s, l2_loss: 0.0125 - round_loss\u001b[A\n",
      "Training:   5%| | 2212/40960 [00:05<01:25, 455.85batches/s, l2_loss: 0.0125 - round_loss\u001b[A\n",
      "Training:   5%| | 2212/40960 [00:05<01:25, 455.85batches/s, l2_loss: 0.0124 - round_loss\u001b[A\n",
      "Training:   6%| | 2305/40960 [00:05<01:24, 457.14batches/s, l2_loss: 0.0124 - round_loss\u001b[A\n",
      "Training:   6%| | 2305/40960 [00:05<01:24, 457.14batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:   6%| | 2399/40960 [00:06<01:23, 459.72batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:   6%| | 2399/40960 [00:06<01:23, 459.72batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:   6%| | 2490/40960 [00:06<01:24, 457.29batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:   6%| | 2490/40960 [00:06<01:24, 457.29batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:   6%| | 2584/40960 [00:06<01:23, 460.81batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:   6%| | 2584/40960 [00:06<01:23, 460.81batches/s, l2_loss: 0.0122 - round_loss\u001b[A\n",
      "Training:   7%| | 2675/40960 [00:06<01:23, 458.95batches/s, l2_loss: 0.0122 - round_loss\u001b[A\n",
      "Training:   7%| | 2675/40960 [00:06<01:23, 458.95batches/s, l2_loss: 0.0122 - round_loss\u001b[A\n",
      "Training:   7%| | 2767/40960 [00:06<01:23, 458.85batches/s, l2_loss: 0.0122 - round_loss\u001b[A\n",
      "Training:   7%| | 2767/40960 [00:06<01:23, 458.85batches/s, l2_loss: 0.0122 - round_loss\u001b[A\n",
      "Training:   7%| | 2859/40960 [00:07<01:23, 458.55batches/s, l2_loss: 0.0122 - round_loss\u001b[A\n",
      "Training:   7%| | 2859/40960 [00:07<01:23, 458.55batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:   7%| | 2953/40960 [00:07<01:22, 460.95batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:   7%| | 2953/40960 [00:07<01:22, 460.95batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:   7%| | 3046/40960 [00:07<01:22, 461.51batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:   7%| | 3046/40960 [00:07<01:22, 461.51batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:   8%| | 3139/40960 [00:07<01:21, 462.43batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:   8%| | 3139/40960 [00:07<01:21, 462.43batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:   8%| | 3232/40960 [00:07<01:21, 462.08batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:   8%| | 3232/40960 [00:07<01:21, 462.08batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:   8%| | 3323/40960 [00:08<01:21, 459.89batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:   8%| | 3323/40960 [00:08<01:21, 459.89batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:   8%| | 3417/40960 [00:08<01:21, 461.70batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:   8%| | 3417/40960 [00:08<01:21, 461.70batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:   9%| | 3508/40960 [00:08<01:21, 459.59batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:   9%| | 3508/40960 [00:08<01:21, 459.59batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:   9%| | 3598/40960 [00:08<01:21, 455.91batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:   9%| | 3598/40960 [00:08<01:21, 455.91batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:   9%| | 3690/40960 [00:08<01:21, 456.70batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:   9%| | 3690/40960 [00:08<01:21, 456.70batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:   9%| | 3781/40960 [00:09<01:21, 455.12batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:   9%| | 3781/40960 [00:09<01:21, 455.12batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:   9%| | 3874/40960 [00:09<01:21, 456.86batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:   9%| | 3874/40960 [00:09<01:21, 456.86batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  10%| | 3968/40960 [00:09<01:20, 459.38batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  10%| | 3968/40960 [00:09<01:20, 459.38batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  10%| | 4061/40960 [00:09<01:20, 460.55batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  10%| | 4061/40960 [00:09<01:20, 460.55batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  10%| | 4153/40960 [00:09<01:20, 459.31batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  10%| | 4153/40960 [00:09<01:20, 459.31batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  10%| | 4246/40960 [00:10<01:19, 460.36batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  10%| | 4246/40960 [00:10<01:19, 460.36batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  11%| | 4341/40960 [00:10<01:18, 463.57batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  11%| | 4341/40960 [00:10<01:18, 463.57batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  11%| | 4432/40960 [00:10<01:19, 460.00batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  11%| | 4432/40960 [00:10<01:19, 460.00batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  11%| | 4524/40960 [00:10<01:19, 459.58batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  11%| | 4524/40960 [00:10<01:19, 459.58batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  11%| | 4617/40960 [00:10<01:19, 459.90batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  11%| | 4617/40960 [00:10<01:19, 459.90batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  12%| | 4711/40960 [00:11<01:18, 462.14batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  12%| | 4711/40960 [00:11<01:18, 462.14batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  12%| | 4804/40960 [00:11<01:18, 461.83batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  12%| | 4804/40960 [00:11<01:18, 461.83batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  12%| | 4897/40960 [00:11<01:18, 461.57batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  12%| | 4897/40960 [00:11<01:18, 461.57batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  12%| | 4991/40960 [00:11<01:17, 462.93batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  12%| | 4991/40960 [00:11<01:17, 462.93batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  12%| | 5082/40960 [00:11<01:18, 459.20batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  12%| | 5082/40960 [00:11<01:18, 459.20batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5176/40960 [00:12<01:17, 461.07batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5176/40960 [00:12<01:17, 461.07batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5268/40960 [00:12<01:17, 459.98batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5268/40960 [00:12<01:17, 459.98batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5359/40960 [00:12<01:17, 458.10batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5359/40960 [00:12<01:17, 458.10batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5451/40960 [00:12<01:17, 458.26batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5451/40960 [00:12<01:17, 458.26batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5544/40960 [00:12<01:17, 459.73batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5544/40960 [00:12<01:17, 459.73batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5636/40960 [00:13<01:16, 459.53batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5636/40960 [00:13<01:16, 459.53batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5728/40960 [00:13<01:16, 459.20batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5728/40960 [00:13<01:16, 459.20batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5820/40960 [00:13<01:16, 458.48batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5820/40960 [00:13<01:16, 458.48batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5914/40960 [00:13<01:16, 460.58batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5914/40960 [00:13<01:16, 460.58batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6008/40960 [00:13<01:15, 462.72batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6008/40960 [00:13<01:15, 462.72batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6100/40960 [00:14<01:15, 461.63batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6100/40960 [00:14<01:15, 461.63batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 6196/40960 [00:14<01:14, 466.06batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6196/40960 [00:14<01:14, 466.06batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6289/40960 [00:14<01:14, 464.71batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6289/40960 [00:14<01:14, 464.71batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6382/40960 [00:14<01:14, 464.24batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6382/40960 [00:14<01:14, 464.24batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6476/40960 [00:14<01:14, 464.83batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6476/40960 [00:14<01:14, 464.83batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6567/40960 [00:15<01:14, 461.50batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6567/40960 [00:15<01:14, 461.50batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6662/40960 [00:15<01:13, 465.06batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6662/40960 [00:15<01:13, 465.06batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6754/40960 [00:15<01:13, 463.46batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6754/40960 [00:15<01:13, 463.46batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6846/40960 [00:15<01:13, 461.58batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6846/40960 [00:15<01:13, 461.58batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6939/40960 [00:15<01:13, 462.23batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6939/40960 [00:15<01:13, 462.23batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7033/40960 [00:16<01:13, 463.61batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7033/40960 [00:16<01:13, 463.61batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7127/40960 [00:16<01:12, 464.55batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7127/40960 [00:16<01:12, 464.55batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7220/40960 [00:16<01:12, 464.31batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7220/40960 [00:16<01:12, 464.31batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7311/40960 [00:16<01:12, 461.43batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7311/40960 [00:16<01:12, 461.43batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7402/40960 [00:16<01:13, 459.38batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7402/40960 [00:16<01:13, 459.38batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7494/40960 [00:17<01:12, 459.31batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7494/40960 [00:17<01:12, 459.31batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7588/40960 [00:17<01:12, 461.53batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7588/40960 [00:17<01:12, 461.53batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7684/40960 [00:17<01:11, 465.68batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7684/40960 [00:17<01:11, 465.68batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7778/40960 [00:17<01:11, 466.89batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7778/40960 [00:17<01:11, 466.89batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7873/40960 [00:17<01:10, 468.02batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7873/40960 [00:17<01:10, 468.02batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7965/40960 [00:18<01:11, 464.36batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7965/40960 [00:18<01:11, 464.36batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8059/40960 [00:18<01:10, 465.26batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8059/40960 [00:18<01:10, 465.26batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8154/40960 [00:18<01:10, 467.97batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8154/40960 [00:18<01:10, 467.97batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8239/40960 [00:18<01:12, 454.16batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8239/40960 [00:18<01:12, 454.16batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8321/40960 [00:18<01:14, 439.51batches/s, l2_loss: 0.0090 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8321/40960 [00:18<01:14, 439.51batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8405/40960 [00:19<01:15, 433.46batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8405/40960 [00:19<01:15, 433.46batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8489/40960 [00:19<01:15, 427.90batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8489/40960 [00:19<01:15, 427.90batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8574/40960 [00:19<01:15, 426.95batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8574/40960 [00:19<01:15, 426.95batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8657/40960 [00:19<01:16, 422.18batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8657/40960 [00:19<01:16, 422.18batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8738/40960 [00:19<01:17, 416.96batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8738/40960 [00:19<01:17, 416.96batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8822/40960 [00:20<01:17, 416.32batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8822/40960 [00:20<01:17, 416.32batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8905/40960 [00:20<01:17, 415.46batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8905/40960 [00:20<01:17, 415.46batches/s, l2_loss: 0.0112 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8987/40960 [00:20<01:17, 413.69batches/s, l2_loss: 0.0112 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8987/40960 [00:20<01:17, 413.69batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9068/40960 [00:20<01:17, 410.26batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9068/40960 [00:20<01:17, 410.26batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9152/40960 [00:20<01:17, 412.92batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9152/40960 [00:20<01:17, 412.92batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9237/40960 [00:21<01:16, 415.28batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9237/40960 [00:21<01:16, 415.28batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9322/40960 [00:21<01:15, 416.85batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9322/40960 [00:21<01:15, 416.85batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9404/40960 [00:21<01:16, 413.42batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9404/40960 [00:21<01:16, 413.42batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9482/40960 [00:21<01:17, 405.20batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9482/40960 [00:21<01:17, 405.20batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9538/40960 [00:21<01:25, 367.09batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9538/40960 [00:21<01:25, 367.09batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9622/40960 [00:22<01:22, 381.70batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9622/40960 [00:22<01:22, 381.70batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9706/40960 [00:22<01:19, 391.83batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9706/40960 [00:22<01:19, 391.83batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9767/40960 [00:22<01:25, 364.04batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9767/40960 [00:22<01:25, 364.04batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9827/40960 [00:22<01:30, 343.68batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9827/40960 [00:22<01:30, 343.68batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9902/40960 [00:22<01:28, 352.36batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9902/40960 [00:23<01:28, 352.36batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9955/40960 [00:23<01:35, 324.83batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|▏| 9955/40960 [00:23<01:35, 324.83batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10031/40960 [00:23<01:31, 339.52batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  24%|▏| 10031/40960 [00:23<01:31, 339.52batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  25%|▏| 10082/40960 [00:23<01:38, 313.87batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  25%|▏| 10082/40960 [00:23<01:38, 313.87batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  25%|▏| 10155/40960 [00:23<01:33, 327.96batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  25%|▏| 10155/40960 [00:23<01:33, 327.96batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  25%|▏| 10207/40960 [00:24<01:40, 307.29batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  25%|▏| 10207/40960 [00:24<01:40, 307.29batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  25%|▎| 10293/40960 [00:24<01:29, 342.75batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  25%|▎| 10293/40960 [00:24<01:29, 342.75batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  25%|▎| 10378/40960 [00:24<01:23, 367.16batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  25%|▎| 10378/40960 [00:24<01:23, 367.16batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10448/40960 [00:24<01:24, 361.23batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10448/40960 [00:24<01:24, 361.23batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10510/40960 [00:24<01:28, 344.84batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10510/40960 [00:24<01:28, 344.84batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10594/40960 [00:25<01:22, 367.13batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10594/40960 [00:25<01:22, 367.13batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10679/40960 [00:25<01:19, 383.16batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10679/40960 [00:25<01:19, 383.16batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  26%|▎| 10743/40960 [00:25<01:23, 362.78batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  26%|▎| 10743/40960 [00:25<01:23, 362.78batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10801/40960 [00:25<01:28, 340.88batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  26%|▎| 10801/40960 [00:25<01:28, 340.88batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 10868/40960 [00:25<01:28, 338.29batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 10868/40960 [00:25<01:28, 338.29batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  27%|▎| 10925/40960 [00:26<01:33, 321.92batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  27%|▎| 10925/40960 [00:26<01:33, 321.92batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 11009/40960 [00:26<01:25, 350.90batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 11009/40960 [00:26<01:25, 350.90batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 11062/40960 [00:26<01:31, 325.12batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 11062/40960 [00:26<01:31, 325.12batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  27%|▎| 11138/40960 [00:26<01:27, 339.62batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  27%|▎| 11138/40960 [00:26<01:27, 339.62batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 11189/40960 [00:26<01:34, 314.00batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 11189/40960 [00:26<01:34, 314.00batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 11263/40960 [00:27<01:29, 330.52batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  27%|▎| 11263/40960 [00:27<01:29, 330.52batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11342/40960 [00:27<01:24, 349.20batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11342/40960 [00:27<01:24, 349.20batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11391/40960 [00:27<01:32, 317.96batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11391/40960 [00:27<01:32, 317.96batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11472/40960 [00:27<01:26, 342.80batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11472/40960 [00:27<01:26, 342.80batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  28%|▎| 11523/40960 [00:27<01:33, 315.42batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  28%|▎| 11523/40960 [00:27<01:33, 315.42batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11594/40960 [00:28<01:30, 325.59batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11594/40960 [00:28<01:30, 325.59batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11647/40960 [00:28<01:35, 307.45batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  28%|▎| 11647/40960 [00:28<01:35, 307.45batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11719/40960 [00:28<01:30, 323.03batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11719/40960 [00:28<01:30, 323.03batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11771/40960 [00:28<01:36, 303.70batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11771/40960 [00:28<01:36, 303.70batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11853/40960 [00:28<01:26, 334.88batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11853/40960 [00:28<01:26, 334.88batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11934/40960 [00:29<01:21, 355.77batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11934/40960 [00:29<01:21, 355.77batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11983/40960 [00:29<01:29, 322.54batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 11983/40960 [00:29<01:29, 322.54batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 12044/40960 [00:29<01:31, 316.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  29%|▎| 12044/40960 [00:29<01:31, 316.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  30%|▎| 12127/40960 [00:29<01:23, 345.82batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  30%|▎| 12127/40960 [00:29<01:23, 345.82batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  30%|▎| 12211/40960 [00:29<01:18, 367.47batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  30%|▎| 12211/40960 [00:29<01:18, 367.47batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  30%|▎| 12291/40960 [00:30<01:16, 375.98batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  30%|▎| 12291/40960 [00:30<01:16, 375.98batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  30%|▎| 12374/40960 [00:30<01:13, 386.42batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  30%|▎| 12374/40960 [00:30<01:13, 386.42batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  30%|▎| 12457/40960 [00:30<01:12, 394.86batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  30%|▎| 12457/40960 [00:30<01:12, 394.86batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12538/40960 [00:30<01:11, 396.98batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12538/40960 [00:30<01:11, 396.98batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12623/40960 [00:30<01:10, 404.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12623/40960 [00:30<01:10, 404.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12705/40960 [00:31<01:09, 405.34batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12705/40960 [00:31<01:09, 405.34batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12785/40960 [00:31<01:09, 403.67batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12785/40960 [00:31<01:09, 403.67batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12853/40960 [00:31<01:13, 384.44batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  31%|▎| 12853/40960 [00:31<01:13, 384.44batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 12918/40960 [00:31<01:16, 366.57batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 12918/40960 [00:31<01:16, 366.57batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13001/40960 [00:31<01:13, 379.96batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13001/40960 [00:31<01:13, 379.96batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13052/40960 [00:32<01:21, 341.64batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13052/40960 [00:32<01:21, 341.64batches/s, l2_loss: 0.0110 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 13108/40960 [00:32<01:26, 321.83batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13108/40960 [00:32<01:26, 321.83batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13164/40960 [00:32<01:29, 309.29batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13164/40960 [00:32<01:29, 309.29batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13232/40960 [00:32<01:27, 317.94batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  32%|▎| 13232/40960 [00:32<01:27, 317.94batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  32%|▎| 13304/40960 [00:32<01:23, 330.00batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  32%|▎| 13304/40960 [00:32<01:23, 330.00batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13359/40960 [00:33<01:28, 313.07batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13359/40960 [00:33<01:28, 313.07batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13438/40960 [00:33<01:21, 336.18batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13438/40960 [00:33<01:21, 336.18batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13492/40960 [00:33<01:27, 315.09batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13492/40960 [00:33<01:27, 315.09batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13575/40960 [00:33<01:19, 344.27batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13575/40960 [00:33<01:19, 344.27batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13630/40960 [00:33<01:24, 322.45batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13630/40960 [00:33<01:24, 322.45batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13706/40960 [00:34<01:20, 339.54batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  33%|▎| 13706/40960 [00:34<01:20, 339.54batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 13765/40960 [00:34<01:23, 325.59batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 13765/40960 [00:34<01:23, 325.59batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 13834/40960 [00:34<01:21, 331.28batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 13834/40960 [00:34<01:21, 331.28batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 13897/40960 [00:34<01:23, 325.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 13897/40960 [00:34<01:23, 325.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 13969/40960 [00:34<01:20, 335.11batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 13969/40960 [00:34<01:20, 335.11batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 14032/40960 [00:35<01:22, 327.34batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  34%|▎| 14032/40960 [00:35<01:22, 327.34batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  34%|▎| 14096/40960 [00:35<01:22, 324.93batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  34%|▎| 14096/40960 [00:35<01:22, 324.93batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14160/40960 [00:35<01:23, 322.80batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14160/40960 [00:35<01:23, 322.80batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14228/40960 [00:35<01:21, 327.46batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14228/40960 [00:35<01:21, 327.46batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14312/40960 [00:35<01:15, 353.88batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14312/40960 [00:35<01:15, 353.88batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14394/40960 [00:36<01:11, 369.51batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14394/40960 [00:36<01:11, 369.51batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14448/40960 [00:36<01:18, 338.33batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14448/40960 [00:36<01:18, 338.33batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14512/40960 [00:36<01:19, 331.88batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  35%|▎| 14512/40960 [00:36<01:19, 331.88batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14593/40960 [00:36<01:14, 353.17batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14593/40960 [00:36<01:14, 353.17batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14645/40960 [00:36<01:21, 324.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14645/40960 [00:36<01:21, 324.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14727/40960 [00:37<01:15, 349.03batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14727/40960 [00:37<01:15, 349.03batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14785/40960 [00:37<01:19, 330.15batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14785/40960 [00:37<01:19, 330.15batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14849/40960 [00:37<01:19, 326.80batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14849/40960 [00:37<01:19, 326.80batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14909/40960 [00:37<01:21, 318.34batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  36%|▎| 14909/40960 [00:37<01:21, 318.34batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 14981/40960 [00:37<01:18, 330.68batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 14981/40960 [00:37<01:18, 330.68batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 15044/40960 [00:38<01:19, 324.32batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 15044/40960 [00:38<01:19, 324.32batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 15115/40960 [00:38<01:17, 332.70batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 15115/40960 [00:38<01:17, 332.70batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 15177/40960 [00:38<01:19, 324.38batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 15177/40960 [00:38<01:19, 324.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  37%|▎| 15237/40960 [00:38<01:21, 316.51batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  37%|▎| 15237/40960 [00:38<01:21, 316.51batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 15304/40960 [00:38<01:20, 320.62batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  37%|▎| 15304/40960 [00:38<01:20, 320.62batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  38%|▍| 15365/40960 [00:39<01:21, 315.15batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  38%|▍| 15365/40960 [00:39<01:21, 315.15batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  38%|▍| 15446/40960 [00:39<01:14, 341.69batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  38%|▍| 15446/40960 [00:39<01:14, 341.69batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  38%|▍| 15524/40960 [00:39<01:11, 355.14batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  38%|▍| 15524/40960 [00:39<01:11, 355.14batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  38%|▍| 15572/40960 [00:39<01:19, 319.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  38%|▍| 15572/40960 [00:39<01:19, 319.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  38%|▍| 15645/40960 [00:39<01:16, 332.72batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  38%|▍| 15645/40960 [00:39<01:16, 332.72batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  38%|▍| 15727/40960 [00:40<01:10, 355.60batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  38%|▍| 15727/40960 [00:40<01:10, 355.60batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 15809/40960 [00:40<01:07, 371.10batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 15809/40960 [00:40<01:07, 371.10batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 15894/40960 [00:40<01:04, 386.02batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 15894/40960 [00:40<01:04, 386.02batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 15976/40960 [00:40<01:03, 392.13batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 15976/40960 [00:40<01:03, 392.13batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 16058/40960 [00:40<01:02, 396.46batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 16058/40960 [00:40<01:02, 396.46batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  39%|▍| 16143/40960 [00:41<01:01, 404.12batches/s, l2_loss: 0.0111 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|▍| 16143/40960 [00:41<01:01, 404.12batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16226/40960 [00:41<01:00, 406.44batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16226/40960 [00:41<01:00, 406.44batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16288/40960 [00:41<01:05, 377.25batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16288/40960 [00:41<01:05, 377.25batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16337/40960 [00:41<01:13, 335.88batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16337/40960 [00:41<01:13, 335.88batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16417/40960 [00:41<01:09, 353.98batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16417/40960 [00:41<01:09, 353.98batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16478/40960 [00:42<01:12, 337.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16478/40960 [00:42<01:12, 337.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16529/40960 [00:42<01:18, 311.42batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  40%|▍| 16529/40960 [00:42<01:18, 311.42batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16591/40960 [00:42<01:18, 310.90batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16591/40960 [00:42<01:18, 310.90batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16675/40960 [00:42<01:10, 342.48batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16675/40960 [00:42<01:10, 342.48batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16752/40960 [00:42<01:08, 354.49batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16752/40960 [00:42<01:08, 354.49batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16834/40960 [00:43<01:05, 369.92batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16834/40960 [00:43<01:05, 369.92batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16918/40960 [00:43<01:02, 384.31batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  41%|▍| 16918/40960 [00:43<01:02, 384.31batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 16999/40960 [00:43<01:01, 389.97batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 16999/40960 [00:43<01:01, 389.97batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17071/40960 [00:43<01:02, 379.81batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17071/40960 [00:43<01:02, 379.81batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17125/40960 [00:43<01:08, 346.24batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17125/40960 [00:43<01:08, 346.24batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17184/40960 [00:44<01:12, 330.21batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17184/40960 [00:44<01:12, 330.21batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17234/40960 [00:44<01:17, 306.19batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17234/40960 [00:44<01:17, 306.19batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17285/40960 [00:44<01:21, 289.45batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17285/40960 [00:44<01:21, 289.45batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17338/40960 [00:44<01:23, 282.02batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17338/40960 [00:44<01:23, 282.02batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17398/40960 [00:44<01:22, 286.05batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  42%|▍| 17398/40960 [00:44<01:22, 286.05batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17447/40960 [00:45<01:26, 272.59batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17447/40960 [00:45<01:26, 272.59batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17501/40960 [00:45<01:26, 271.67batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17501/40960 [00:45<01:26, 271.67batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17553/40960 [00:45<01:27, 267.86batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17553/40960 [00:45<01:27, 267.86batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17606/40960 [00:45<01:27, 265.91batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17606/40960 [00:45<01:27, 265.91batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17682/40960 [00:45<01:17, 299.04batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17682/40960 [00:45<01:17, 299.04batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17736/40960 [00:46<01:20, 289.21batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17736/40960 [00:46<01:20, 289.21batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17802/40960 [00:46<01:17, 300.54batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  43%|▍| 17802/40960 [00:46<01:17, 300.54batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 17853/40960 [00:46<01:20, 286.64batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 17853/40960 [00:46<01:20, 286.64batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 17907/40960 [00:46<01:21, 281.66batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 17907/40960 [00:46<01:21, 281.66batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 17956/40960 [00:46<01:25, 269.28batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 17956/40960 [00:46<01:25, 269.28batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 18016/40960 [00:47<01:22, 277.51batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 18016/40960 [00:47<01:22, 277.51batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 18072/40960 [00:47<01:22, 277.64batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 18072/40960 [00:47<01:22, 277.64batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 18131/40960 [00:47<01:20, 282.48batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 18131/40960 [00:47<01:20, 282.48batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 18210/40960 [00:47<01:11, 315.98batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  44%|▍| 18210/40960 [00:47<01:11, 315.98batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18263/40960 [00:47<01:15, 300.21batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18263/40960 [00:47<01:15, 300.21batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18335/40960 [00:48<01:11, 317.97batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18335/40960 [00:48<01:11, 317.97batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18418/40960 [00:48<01:05, 346.50batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18418/40960 [00:48<01:05, 346.50batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18467/40960 [00:48<01:11, 315.03batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18467/40960 [00:48<01:11, 315.03batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18518/40960 [00:48<01:15, 296.55batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18518/40960 [00:48<01:15, 296.55batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18574/40960 [00:48<01:16, 291.41batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18574/40960 [00:48<01:16, 291.41batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18636/40960 [00:49<01:15, 296.13batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  45%|▍| 18636/40960 [00:49<01:15, 296.13batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18689/40960 [00:49<01:17, 286.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18689/40960 [00:49<01:17, 286.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18744/40960 [00:49<01:18, 282.74batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18744/40960 [00:49<01:18, 282.74batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18815/40960 [00:49<01:12, 303.71batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18815/40960 [00:49<01:12, 303.71batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18896/40960 [00:49<01:06, 333.02batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18896/40960 [00:50<01:06, 333.02batches/s, l2_loss: 0.0111 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|▍| 18956/40960 [00:50<01:08, 322.93batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 18956/40960 [00:50<01:08, 322.93batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 19011/40960 [00:50<01:11, 308.34batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  46%|▍| 19011/40960 [00:50<01:11, 308.34batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19065/40960 [00:50<01:13, 296.81batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19065/40960 [00:50<01:13, 296.81batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19117/40960 [00:50<01:16, 284.53batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19117/40960 [00:50<01:16, 284.53batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19170/40960 [00:51<01:18, 278.12batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19170/40960 [00:51<01:18, 278.12batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19230/40960 [00:51<01:16, 283.68batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19230/40960 [00:51<01:16, 283.68batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19288/40960 [00:51<01:15, 285.37batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19288/40960 [00:51<01:15, 285.37batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19348/40960 [00:51<01:14, 288.83batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19348/40960 [00:51<01:14, 288.83batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19430/40960 [00:51<01:06, 324.97batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  47%|▍| 19430/40960 [00:51<01:06, 324.97batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19512/40960 [00:52<01:01, 349.64batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19512/40960 [00:52<01:01, 349.64batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19595/40960 [00:52<00:58, 368.33batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19595/40960 [00:52<00:58, 368.33batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19676/40960 [00:52<00:56, 377.86batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19676/40960 [00:52<00:56, 377.86batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19761/40960 [00:52<00:54, 390.60batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19761/40960 [00:52<00:54, 390.60batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19846/40960 [00:52<00:52, 400.21batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  48%|▍| 19846/40960 [00:52<00:52, 400.21batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 19927/40960 [00:53<00:52, 401.54batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 19927/40960 [00:53<00:52, 401.54batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 20012/40960 [00:53<00:51, 407.34batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 20012/40960 [00:53<00:51, 407.34batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 20096/40960 [00:53<00:50, 410.19batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 20096/40960 [00:53<00:50, 410.19batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 20175/40960 [00:53<00:51, 405.07batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 20175/40960 [00:53<00:51, 405.07batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 20256/40960 [00:53<00:51, 404.50batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  49%|▍| 20256/40960 [00:53<00:51, 404.50batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▍| 20339/40960 [00:54<00:50, 407.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▍| 20339/40960 [00:54<00:50, 407.38batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▍| 20422/40960 [00:54<00:50, 409.18batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▍| 20422/40960 [00:54<00:50, 409.18batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▌| 20507/40960 [00:54<00:49, 413.45batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▌| 20507/40960 [00:54<00:49, 413.45batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▌| 20587/40960 [00:54<00:49, 408.99batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▌| 20587/40960 [00:54<00:49, 408.99batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▌| 20670/40960 [00:54<00:49, 410.08batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  50%|▌| 20670/40960 [00:54<00:49, 410.08batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 20752/40960 [00:55<00:49, 409.90batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 20752/40960 [00:55<00:49, 409.90batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 20837/40960 [00:55<00:48, 413.56batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 20837/40960 [00:55<00:48, 413.56batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 20920/40960 [00:55<00:48, 413.13batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 20920/40960 [00:55<00:48, 413.13batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 21004/40960 [00:55<00:48, 413.91batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 21004/40960 [00:55<00:48, 413.91batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 21087/40960 [00:55<00:48, 412.85batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  51%|▌| 21087/40960 [00:55<00:48, 412.85batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21168/40960 [00:56<00:48, 409.18batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21168/40960 [00:56<00:48, 409.18batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21251/40960 [00:56<00:48, 410.20batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21251/40960 [00:56<00:48, 410.20batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21335/40960 [00:56<00:47, 412.25batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21335/40960 [00:56<00:47, 412.25batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21394/40960 [00:56<00:52, 375.35batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21394/40960 [00:56<00:52, 375.35batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21445/40960 [00:56<00:57, 337.57batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  52%|▌| 21445/40960 [00:56<00:57, 337.57batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21508/40960 [00:57<00:58, 329.83batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21508/40960 [00:57<00:58, 329.83batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21591/40960 [00:57<00:54, 354.22batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21591/40960 [00:57<00:54, 354.22batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21652/40960 [00:57<00:57, 338.71batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21652/40960 [00:57<00:57, 338.71batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21705/40960 [00:57<01:01, 315.55batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21705/40960 [00:57<01:01, 315.55batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21753/40960 [00:57<01:05, 292.69batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21753/40960 [00:57<01:05, 292.69batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21803/40960 [00:58<01:08, 279.70batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21803/40960 [00:58<01:08, 279.70batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21855/40960 [00:58<01:09, 273.33batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21855/40960 [00:58<01:09, 273.33batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21908/40960 [00:58<01:10, 270.19batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  53%|▌| 21908/40960 [00:58<01:10, 270.19batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 21981/40960 [00:58<01:03, 297.55batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 21981/40960 [00:58<01:03, 297.55batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 22066/40960 [00:58<00:56, 335.36batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 22066/40960 [00:58<00:56, 335.36batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 22146/40960 [00:59<00:53, 353.27batches/s, l2_loss: 0.0111 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|▌| 22146/40960 [00:59<00:53, 353.27batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 22220/40960 [00:59<00:52, 358.01batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 22220/40960 [00:59<00:52, 358.01batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [00:59<00:51, 363.48batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [00:59<00:51, 363.48batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  55%|▌| 22365/40960 [00:59<00:52, 356.85batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  55%|▌| 22365/40960 [00:59<00:52, 356.85batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  55%|▌| 22446/40960 [00:59<00:50, 370.26batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  55%|▌| 22446/40960 [00:59<00:50, 370.26batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  55%|▌| 22501/40960 [01:00<00:54, 340.72batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  55%|▌| 22501/40960 [01:00<00:54, 340.72batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  55%|▌| 22550/40960 [01:00<00:59, 311.65batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  55%|▌| 22550/40960 [01:00<00:59, 311.65batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  55%|▌| 22610/40960 [01:00<00:59, 308.10batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  55%|▌| 22610/40960 [01:00<00:59, 308.10batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  55%|▌| 22667/40960 [01:00<01:01, 299.74batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  55%|▌| 22667/40960 [01:00<01:01, 299.74batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  55%|▌| 22719/40960 [01:00<01:03, 286.70batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  55%|▌| 22719/40960 [01:00<01:03, 286.70batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 22775/40960 [01:01<01:03, 284.47batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 22775/40960 [01:01<01:03, 284.47batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 22857/40960 [01:01<00:56, 321.44batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 22857/40960 [01:01<00:56, 321.44batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 22938/40960 [01:01<00:52, 346.15batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 22938/40960 [01:01<00:52, 346.15batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 23021/40960 [01:01<00:49, 365.85batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 23021/40960 [01:01<00:49, 365.85batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 23078/40960 [01:01<00:52, 340.85batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  56%|▌| 23078/40960 [01:01<00:52, 340.85batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23154/40960 [01:02<00:50, 352.27batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23154/40960 [01:02<00:50, 352.27batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23237/40960 [01:02<00:47, 370.06batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23237/40960 [01:02<00:47, 370.06batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23302/40960 [01:02<00:49, 355.24batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23302/40960 [01:02<00:49, 355.24batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23354/40960 [01:02<00:54, 325.59batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23354/40960 [01:02<00:54, 325.59batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23408/40960 [01:02<00:57, 307.82batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23408/40960 [01:02<00:57, 307.82batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23477/40960 [01:03<00:55, 317.82batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  57%|▌| 23477/40960 [01:03<00:55, 317.82batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23557/40960 [01:03<00:50, 341.79batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23557/40960 [01:03<00:50, 341.79batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23636/40960 [01:03<00:48, 357.29batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23636/40960 [01:03<00:48, 357.29batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23718/40960 [01:03<00:46, 372.79batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23718/40960 [01:03<00:46, 372.79batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23802/40960 [01:03<00:44, 386.15batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23802/40960 [01:03<00:44, 386.15batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23882/40960 [01:04<00:43, 389.31batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23882/40960 [01:04<00:43, 389.31batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23960/40960 [01:04<00:43, 389.08batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  58%|▌| 23960/40960 [01:04<00:43, 389.08batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24043/40960 [01:04<00:42, 396.71batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24043/40960 [01:04<00:42, 396.71batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24127/40960 [01:04<00:41, 403.35batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24127/40960 [01:04<00:41, 403.35batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24210/40960 [01:04<00:41, 406.74batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24210/40960 [01:04<00:41, 406.74batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24288/40960 [01:05<00:41, 400.38batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24288/40960 [01:05<00:41, 400.38batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24360/40960 [01:05<00:42, 387.31batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  59%|▌| 24360/40960 [01:05<00:42, 387.31batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24438/40960 [01:05<00:42, 387.85batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24438/40960 [01:05<00:42, 387.85batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24522/40960 [01:05<00:41, 396.24batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24522/40960 [01:05<00:41, 396.24batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24606/40960 [01:05<00:40, 402.63batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24606/40960 [01:05<00:40, 402.63batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24681/40960 [01:06<00:41, 393.92batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24681/40960 [01:06<00:41, 393.92batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24764/40960 [01:06<00:40, 399.24batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  60%|▌| 24764/40960 [01:06<00:40, 399.24batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 24845/40960 [01:06<00:40, 400.82batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 24845/40960 [01:06<00:40, 400.82batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 24920/40960 [01:06<00:40, 391.80batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 24920/40960 [01:06<00:40, 391.80batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 24994/40960 [01:06<00:41, 384.52batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 24994/40960 [01:06<00:41, 384.52batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 25066/40960 [01:07<00:42, 376.90batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 25066/40960 [01:07<00:42, 376.90batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 25136/40960 [01:07<00:42, 368.65batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  61%|▌| 25136/40960 [01:07<00:42, 368.65batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25209/40960 [01:07<00:42, 366.71batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25209/40960 [01:07<00:42, 366.71batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25285/40960 [01:07<00:42, 369.56batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25285/40960 [01:07<00:42, 369.56batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25362/40960 [01:07<00:41, 373.67batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25362/40960 [01:07<00:41, 373.67batches/s, l2_loss: 0.0112 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|▌| 25441/40960 [01:08<00:40, 378.91batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25441/40960 [01:08<00:40, 378.91batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25523/40960 [01:08<00:39, 387.39batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  62%|▌| 25523/40960 [01:08<00:39, 387.39batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25605/40960 [01:08<00:39, 393.31batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25605/40960 [01:08<00:39, 393.31batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25684/40960 [01:08<00:38, 393.62batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25684/40960 [01:08<00:38, 393.62batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25758/40960 [01:08<00:39, 385.51batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25758/40960 [01:08<00:39, 385.51batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25839/40960 [01:09<00:38, 390.30batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25839/40960 [01:09<00:38, 390.30batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25914/40960 [01:09<00:39, 385.02batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25914/40960 [01:09<00:39, 385.02batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25987/40960 [01:09<00:39, 378.25batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  63%|▋| 25987/40960 [01:09<00:39, 378.25batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  64%|▋| 26053/40960 [01:09<00:40, 363.82batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  64%|▋| 26053/40960 [01:09<00:40, 363.82batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  64%|▋| 26117/40960 [01:09<00:42, 349.80batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  64%|▋| 26117/40960 [01:09<00:42, 349.80batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  64%|▋| 26196/40960 [01:10<00:40, 363.24batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  64%|▋| 26196/40960 [01:10<00:40, 363.24batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  64%|▋| 26272/40960 [01:10<00:39, 367.97batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  64%|▋| 26272/40960 [01:10<00:39, 367.97batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  64%|▋| 26355/40960 [01:10<00:38, 381.65batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  64%|▋| 26355/40960 [01:10<00:38, 381.65batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26433/40960 [01:10<00:37, 383.21batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26433/40960 [01:10<00:37, 383.21batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26508/40960 [01:10<00:37, 380.50batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26508/40960 [01:10<00:37, 380.50batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26587/40960 [01:11<00:37, 384.59batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26587/40960 [01:11<00:37, 384.59batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26672/40960 [01:11<00:36, 395.63batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26672/40960 [01:11<00:36, 395.63batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26743/40960 [01:11<00:37, 382.96batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26743/40960 [01:11<00:37, 382.96batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26810/40960 [01:11<00:38, 368.06batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  65%|▋| 26810/40960 [01:11<00:38, 368.06batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 26873/40960 [01:11<00:40, 351.28batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 26873/40960 [01:11<00:40, 351.28batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 26945/40960 [01:12<00:39, 352.79batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 26945/40960 [01:12<00:39, 352.79batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 27025/40960 [01:12<00:37, 366.81batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 27025/40960 [01:12<00:37, 366.81batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 27104/40960 [01:12<00:36, 375.23batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 27104/40960 [01:12<00:36, 375.23batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 27189/40960 [01:12<00:35, 389.48batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  66%|▋| 27189/40960 [01:12<00:35, 389.48batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27270/40960 [01:12<00:34, 393.33batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27270/40960 [01:12<00:34, 393.33batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27353/40960 [01:13<00:34, 398.75batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27353/40960 [01:13<00:34, 398.75batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27434/40960 [01:13<00:33, 399.41batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27434/40960 [01:13<00:33, 399.41batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27510/40960 [01:13<00:34, 393.27batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27510/40960 [01:13<00:34, 393.27batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27584/40960 [01:13<00:34, 385.29batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27584/40960 [01:13<00:34, 385.29batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27664/40960 [01:13<00:34, 389.18batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27664/40960 [01:13<00:34, 389.18batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27743/40960 [01:14<00:33, 390.22batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27743/40960 [01:14<00:33, 390.22batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27818/40960 [01:14<00:34, 385.14batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27818/40960 [01:14<00:34, 385.14batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27895/40960 [01:14<00:33, 384.55batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27895/40960 [01:14<00:33, 384.55batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27980/40960 [01:14<00:32, 395.39batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27980/40960 [01:14<00:32, 395.39batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28061/40960 [01:14<00:32, 397.21batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28061/40960 [01:14<00:32, 397.21batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28139/40960 [01:15<00:32, 394.94batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28139/40960 [01:15<00:32, 394.94batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28222/40960 [01:15<00:31, 399.78batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28222/40960 [01:15<00:31, 399.78batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28303/40960 [01:15<00:31, 400.78batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28303/40960 [01:15<00:31, 400.78batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28386/40960 [01:15<00:31, 404.66batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  69%|▋| 28386/40960 [01:15<00:31, 404.66batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28469/40960 [01:15<00:30, 406.61batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28469/40960 [01:15<00:30, 406.61batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28554/40960 [01:16<00:30, 411.23batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28554/40960 [01:16<00:30, 411.23batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28638/40960 [01:16<00:29, 413.58batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28638/40960 [01:16<00:29, 413.58batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  70%|▋| 28720/40960 [01:16<00:29, 411.43batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  70%|▋| 28720/40960 [01:16<00:29, 411.43batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  70%|▋| 28800/40960 [01:16<00:29, 406.85batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  70%|▋| 28800/40960 [01:16<00:29, 406.85batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 28885/40960 [01:16<00:29, 411.16batches/s, l2_loss: 0.0114 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|▋| 28885/40960 [01:16<00:29, 411.16batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 28968/40960 [01:17<00:29, 411.54batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 28968/40960 [01:17<00:29, 411.54batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29048/40960 [01:17<00:29, 407.94batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29048/40960 [01:17<00:29, 407.94batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29129/40960 [01:17<00:29, 406.55batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29129/40960 [01:17<00:29, 406.55batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29208/40960 [01:17<00:29, 402.67batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29208/40960 [01:17<00:29, 402.67batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29292/40960 [01:17<00:28, 406.63batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29292/40960 [01:17<00:28, 406.63batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29376/40960 [01:18<00:28, 409.84batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29376/40960 [01:18<00:28, 409.84batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29461/40960 [01:18<00:27, 413.83batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29461/40960 [01:18<00:27, 413.83batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29544/40960 [01:18<00:27, 413.70batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29544/40960 [01:18<00:27, 413.70batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29625/40960 [01:18<00:27, 410.05batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  72%|▋| 29625/40960 [01:18<00:27, 410.05batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 29705/40960 [01:18<00:27, 406.17batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 29705/40960 [01:18<00:27, 406.17batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 29786/40960 [01:19<00:27, 404.39batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 29786/40960 [01:19<00:27, 404.39batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 29870/40960 [01:19<00:27, 408.51batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 29870/40960 [01:19<00:27, 408.51batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 29953/40960 [01:19<00:26, 410.22batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 29953/40960 [01:19<00:26, 410.22batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 30033/40960 [01:19<00:26, 406.98batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  73%|▋| 30033/40960 [01:19<00:26, 406.98batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30114/40960 [01:19<00:26, 405.46batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30114/40960 [01:19<00:26, 405.46batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30194/40960 [01:20<00:26, 403.06batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30194/40960 [01:20<00:26, 403.06batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30278/40960 [01:20<00:26, 407.36batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30278/40960 [01:20<00:26, 407.36batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30359/40960 [01:20<00:26, 405.28batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30359/40960 [01:20<00:26, 405.28batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30443/40960 [01:20<00:25, 408.76batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  74%|▋| 30443/40960 [01:20<00:25, 408.76batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  75%|▋| 30526/40960 [01:21<00:25, 410.05batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  75%|▋| 30526/40960 [01:21<00:25, 410.05batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  75%|▋| 30611/40960 [01:21<00:24, 414.05batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  75%|▋| 30611/40960 [01:21<00:24, 414.05batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  75%|▋| 30695/40960 [01:21<00:24, 415.46batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  75%|▋| 30695/40960 [01:21<00:24, 415.46batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  75%|▊| 30777/40960 [01:21<00:24, 413.18batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  75%|▊| 30777/40960 [01:21<00:24, 413.18batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  75%|▊| 30857/40960 [01:21<00:24, 408.66batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  75%|▊| 30857/40960 [01:21<00:24, 408.66batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 30939/40960 [01:22<00:24, 408.95batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 30939/40960 [01:22<00:24, 408.95batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 31021/40960 [01:22<00:24, 408.33batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 31021/40960 [01:22<00:24, 408.33batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 31107/40960 [01:22<00:23, 414.74batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 31107/40960 [01:22<00:23, 414.74batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 31190/40960 [01:22<00:23, 413.45batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 31190/40960 [01:22<00:23, 413.45batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 31272/40960 [01:22<00:23, 411.04batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  76%|▊| 31272/40960 [01:22<00:23, 411.04batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31357/40960 [01:23<00:23, 413.88batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31357/40960 [01:23<00:23, 413.88batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31441/40960 [01:23<00:22, 414.73batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31441/40960 [01:23<00:22, 414.73batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31525/40960 [01:23<00:22, 415.38batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31525/40960 [01:23<00:22, 415.38batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31607/40960 [01:23<00:22, 413.62batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31607/40960 [01:23<00:22, 413.62batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31686/40960 [01:23<00:22, 407.97batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  77%|▊| 31686/40960 [01:23<00:22, 407.97batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 31770/40960 [01:24<00:22, 411.35batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 31770/40960 [01:24<00:22, 411.35batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 31854/40960 [01:24<00:22, 413.28batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 31854/40960 [01:24<00:22, 413.28batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 31925/40960 [01:24<00:22, 394.76batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 31925/40960 [01:24<00:22, 394.76batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 32003/40960 [01:24<00:22, 393.22batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 32003/40960 [01:24<00:22, 393.22batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 32085/40960 [01:24<00:22, 398.23batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  78%|▊| 32085/40960 [01:24<00:22, 398.23batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  79%|▊| 32169/40960 [01:25<00:21, 403.74batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  79%|▊| 32169/40960 [01:25<00:21, 403.74batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  79%|▊| 32250/40960 [01:25<00:21, 404.04batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  79%|▊| 32250/40960 [01:25<00:21, 404.04batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  79%|▊| 32333/40960 [01:25<00:21, 406.47batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  79%|▊| 32333/40960 [01:25<00:21, 406.47batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  79%|▊| 32418/40960 [01:25<00:20, 410.81batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  79%|▊| 32418/40960 [01:25<00:20, 410.81batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  79%|▊| 32489/40960 [01:25<00:21, 393.76batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  79%|▊| 32489/40960 [01:25<00:21, 393.76batches/s, l2_loss: 0.0116 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32564/40960 [01:26<00:21, 387.16batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32564/40960 [01:26<00:21, 387.16batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32647/40960 [01:26<00:21, 394.48batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32647/40960 [01:26<00:21, 394.48batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32732/40960 [01:26<00:20, 402.70batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32732/40960 [01:26<00:20, 402.70batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32816/40960 [01:26<00:20, 407.03batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32816/40960 [01:26<00:20, 407.03batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32896/40960 [01:26<00:19, 403.86batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32896/40960 [01:26<00:19, 403.86batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 32974/40960 [01:27<00:19, 399.61batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 32974/40960 [01:27<00:19, 399.61batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 33055/40960 [01:27<00:19, 400.95batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 33055/40960 [01:27<00:19, 400.95batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 33139/40960 [01:27<00:19, 405.87batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 33139/40960 [01:27<00:19, 405.87batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 33225/40960 [01:27<00:18, 411.73batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 33225/40960 [01:27<00:18, 411.73batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 33308/40960 [01:27<00:18, 412.60batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  81%|▊| 33308/40960 [01:27<00:18, 412.60batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  82%|▊| 33391/40960 [01:28<00:18, 413.32batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  82%|▊| 33391/40960 [01:28<00:18, 413.32batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  82%|▊| 33467/40960 [01:28<00:18, 403.06batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  82%|▊| 33467/40960 [01:28<00:18, 403.06batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  82%|▊| 33550/40960 [01:28<00:18, 406.56batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  82%|▊| 33550/40960 [01:28<00:18, 406.56batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  82%|▊| 33627/40960 [01:28<00:18, 398.73batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  82%|▊| 33627/40960 [01:28<00:18, 398.73batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  82%|▊| 33705/40960 [01:28<00:18, 395.48batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  82%|▊| 33705/40960 [01:28<00:18, 395.48batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  82%|▊| 33783/40960 [01:29<00:18, 392.76batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  82%|▊| 33783/40960 [01:29<00:18, 392.76batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 33860/40960 [01:29<00:18, 389.95batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 33860/40960 [01:29<00:18, 389.95batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 33935/40960 [01:29<00:18, 384.65batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 33935/40960 [01:29<00:18, 384.65batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 34012/40960 [01:29<00:18, 384.30batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 34012/40960 [01:29<00:18, 384.30batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 34094/40960 [01:29<00:17, 390.70batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 34094/40960 [01:29<00:17, 390.70batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 34177/40960 [01:30<00:17, 397.94batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  83%|▊| 34177/40960 [01:30<00:17, 397.94batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34261/40960 [01:30<00:16, 403.38batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34261/40960 [01:30<00:16, 403.38batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34343/40960 [01:30<00:16, 405.25batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34343/40960 [01:30<00:16, 405.25batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34420/40960 [01:30<00:16, 398.97batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34420/40960 [01:30<00:16, 398.97batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34495/40960 [01:30<00:16, 390.80batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34495/40960 [01:30<00:16, 390.80batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34573/40960 [01:31<00:16, 389.73batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  84%|▊| 34573/40960 [01:31<00:16, 389.73batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34651/40960 [01:31<00:16, 388.57batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34651/40960 [01:31<00:16, 388.57batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34728/40960 [01:31<00:16, 386.41batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34728/40960 [01:31<00:16, 386.41batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34804/40960 [01:31<00:16, 384.18batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34804/40960 [01:31<00:16, 384.18batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34882/40960 [01:31<00:15, 384.72batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34882/40960 [01:31<00:15, 384.72batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34959/40960 [01:32<00:15, 384.73batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  85%|▊| 34959/40960 [01:32<00:15, 384.73batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35040/40960 [01:32<00:15, 390.62batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35040/40960 [01:32<00:15, 390.62batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35122/40960 [01:32<00:14, 395.33batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35122/40960 [01:32<00:14, 395.33batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35201/40960 [01:32<00:14, 395.14batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35201/40960 [01:32<00:14, 395.14batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35279/40960 [01:32<00:14, 393.04batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35279/40960 [01:32<00:14, 393.04batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35363/40960 [01:33<00:13, 400.56batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  86%|▊| 35363/40960 [01:33<00:13, 400.56batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  87%|▊| 35446/40960 [01:33<00:13, 404.11batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  87%|▊| 35446/40960 [01:33<00:13, 404.11batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  87%|▊| 35528/40960 [01:33<00:13, 405.83batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  87%|▊| 35528/40960 [01:33<00:13, 405.83batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  87%|▊| 35609/40960 [01:33<00:13, 404.35batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  87%|▊| 35609/40960 [01:33<00:13, 404.35batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  87%|▊| 35691/40960 [01:33<00:12, 405.47batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  87%|▊| 35691/40960 [01:33<00:12, 405.47batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  87%|▊| 35772/40960 [01:34<00:12, 404.70batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  87%|▊| 35772/40960 [01:34<00:12, 404.70batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 35845/40960 [01:34<00:13, 391.99batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 35845/40960 [01:34<00:13, 391.99batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 35925/40960 [01:34<00:12, 393.94batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 35925/40960 [01:34<00:12, 393.94batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 36003/40960 [01:34<00:12, 391.31batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 36003/40960 [01:34<00:12, 391.31batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 36078/40960 [01:34<00:12, 384.94batches/s, l2_loss: 0.0119 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|▉| 36078/40960 [01:34<00:12, 384.94batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 36154/40960 [01:35<00:12, 383.12batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  88%|▉| 36154/40960 [01:35<00:12, 383.12batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  88%|▉| 36235/40960 [01:35<00:12, 389.10batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  88%|▉| 36235/40960 [01:35<00:12, 389.10batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36315/40960 [01:35<00:11, 391.93batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36315/40960 [01:35<00:11, 391.93batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36392/40960 [01:35<00:11, 389.82batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36392/40960 [01:35<00:11, 389.82batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36470/40960 [01:35<00:11, 389.41batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36470/40960 [01:35<00:11, 389.41batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36552/40960 [01:36<00:11, 394.54batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36552/40960 [01:36<00:11, 394.54batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36629/40960 [01:36<00:11, 390.77batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  89%|▉| 36629/40960 [01:36<00:11, 390.77batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  90%|▉| 36707/40960 [01:36<00:10, 389.56batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  90%|▉| 36707/40960 [01:36<00:10, 389.56batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  90%|▉| 36790/40960 [01:36<00:10, 396.90batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  90%|▉| 36790/40960 [01:36<00:10, 396.90batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  90%|▉| 36871/40960 [01:36<00:10, 399.03batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  90%|▉| 36871/40960 [01:36<00:10, 399.03batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  90%|▉| 36954/40960 [01:37<00:09, 403.40batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  90%|▉| 36954/40960 [01:37<00:09, 403.40batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  90%|▉| 37037/40960 [01:37<00:09, 406.67batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  90%|▉| 37037/40960 [01:37<00:09, 406.67batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37120/40960 [01:37<00:09, 408.95batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37120/40960 [01:37<00:09, 408.95batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37205/40960 [01:37<00:09, 413.64batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37205/40960 [01:37<00:09, 413.64batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37290/40960 [01:37<00:08, 415.88batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37290/40960 [01:37<00:08, 415.88batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37374/40960 [01:38<00:08, 416.62batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37374/40960 [01:38<00:08, 416.62batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37460/40960 [01:38<00:08, 419.19batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  91%|▉| 37460/40960 [01:38<00:08, 419.19batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  92%|▉| 37543/40960 [01:38<00:08, 416.87batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  92%|▉| 37543/40960 [01:38<00:08, 416.87batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  92%|▉| 37621/40960 [01:38<00:08, 408.10batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  92%|▉| 37621/40960 [01:38<00:08, 408.10batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  92%|▉| 37695/40960 [01:38<00:08, 395.44batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  92%|▉| 37695/40960 [01:38<00:08, 395.44batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  92%|▉| 37770/40960 [01:39<00:08, 389.15batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  92%|▉| 37770/40960 [01:39<00:08, 389.15batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  92%|▉| 37849/40960 [01:39<00:07, 389.77batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  92%|▉| 37849/40960 [01:39<00:07, 389.77batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 37933/40960 [01:39<00:07, 397.88batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 37933/40960 [01:39<00:07, 397.88batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 38011/40960 [01:39<00:07, 395.36batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 38011/40960 [01:39<00:07, 395.36batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 38092/40960 [01:39<00:07, 397.09batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 38092/40960 [01:39<00:07, 397.09batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 38176/40960 [01:40<00:06, 402.50batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 38176/40960 [01:40<00:06, 402.50batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 38253/40960 [01:40<00:06, 397.13batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  93%|▉| 38253/40960 [01:40<00:06, 397.13batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  94%|▉| 38334/40960 [01:40<00:06, 399.46batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  94%|▉| 38334/40960 [01:40<00:06, 399.46batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  94%|▉| 38414/40960 [01:40<00:06, 398.34batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  94%|▉| 38414/40960 [01:40<00:06, 398.34batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  94%|▉| 38496/40960 [01:40<00:06, 400.83batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  94%|▉| 38496/40960 [01:40<00:06, 400.83batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  94%|▉| 38576/40960 [01:41<00:05, 399.98batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  94%|▉| 38576/40960 [01:41<00:05, 399.98batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  94%|▉| 38659/40960 [01:41<00:05, 403.99batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  94%|▉| 38659/40960 [01:41<00:05, 403.99batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 38744/40960 [01:41<00:05, 408.91batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 38744/40960 [01:41<00:05, 408.91batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 38829/40960 [01:41<00:05, 412.84batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 38829/40960 [01:41<00:05, 412.84batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 38914/40960 [01:41<00:04, 415.02batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 38914/40960 [01:41<00:04, 415.02batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 38998/40960 [01:42<00:04, 415.64batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 38998/40960 [01:42<00:04, 415.64batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 39082/40960 [01:42<00:04, 416.60batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  95%|▉| 39082/40960 [01:42<00:04, 416.60batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  96%|▉| 39165/40960 [01:42<00:04, 414.75batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  96%|▉| 39165/40960 [01:42<00:04, 414.75batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  96%|▉| 39248/40960 [01:42<00:04, 414.54batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  96%|▉| 39248/40960 [01:42<00:04, 414.54batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  96%|▉| 39330/40960 [01:42<00:03, 412.22batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  96%|▉| 39330/40960 [01:42<00:03, 412.22batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  96%|▉| 39404/40960 [01:43<00:03, 398.18batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  96%|▉| 39404/40960 [01:43<00:03, 398.18batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  96%|▉| 39481/40960 [01:43<00:03, 393.40batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  96%|▉| 39481/40960 [01:43<00:03, 393.40batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39555/40960 [01:43<00:03, 385.47batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39555/40960 [01:43<00:03, 385.47batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39632/40960 [01:43<00:03, 384.28batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39632/40960 [01:43<00:03, 384.28batches/s, l2_loss: 0.0124 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39715/40960 [01:43<00:03, 392.07batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39715/40960 [01:43<00:03, 392.07batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39797/40960 [01:44<00:02, 397.00batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39797/40960 [01:44<00:02, 397.00batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39882/40960 [01:44<00:02, 404.15batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  97%|▉| 39882/40960 [01:44<00:02, 404.15batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  98%|▉| 39965/40960 [01:44<00:02, 407.06batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  98%|▉| 39965/40960 [01:44<00:02, 407.06batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  98%|▉| 40049/40960 [01:44<00:02, 409.96batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  98%|▉| 40049/40960 [01:44<00:02, 409.96batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  98%|▉| 40131/40960 [01:44<00:02, 409.01batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  98%|▉| 40131/40960 [01:44<00:02, 409.01batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  98%|▉| 40216/40960 [01:45<00:01, 412.50batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  98%|▉| 40216/40960 [01:45<00:01, 412.50batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  98%|▉| 40300/40960 [01:45<00:01, 413.56batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  98%|▉| 40300/40960 [01:45<00:01, 413.56batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40376/40960 [01:45<00:01, 402.97batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40376/40960 [01:45<00:01, 402.97batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40456/40960 [01:45<00:01, 401.99batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40456/40960 [01:45<00:01, 401.99batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40534/40960 [01:45<00:01, 398.18batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40534/40960 [01:45<00:01, 398.18batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40608/40960 [01:46<00:00, 388.89batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40608/40960 [01:46<00:00, 388.89batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40683/40960 [01:46<00:00, 383.60batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  99%|▉| 40683/40960 [01:46<00:00, 383.60batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40756/40960 [01:46<00:00, 376.91batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40756/40960 [01:46<00:00, 376.91batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40835/40960 [01:46<00:00, 380.97batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40835/40960 [01:46<00:00, 380.97batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40910/40960 [01:46<00:00, 378.17batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40910/40960 [01:46<00:00, 378.17batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 14:58:42.709073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  23%|▏| 6/26 [11:02<37:25, 112.27s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 14:58:44.121883: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 14:58:51.203395: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<22:08:43,  1.95s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<22:08:43,  1.95s/batches, l2_loss: 0.0643 - round_loss:\u001b[A\n",
      "Training:   0%| | 57/40960 [00:02<18:48, 36.24batches/s, l2_loss: 0.0643 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 57/40960 [00:02<18:48, 36.24batches/s, l2_loss: 0.0682 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 117/40960 [00:02<08:50, 76.97batches/s, l2_loss: 0.0682 - round_loss: \u001b[A\n",
      "Training:   0%| | 117/40960 [00:02<08:50, 76.97batches/s, l2_loss: 0.0647 - round_loss: \u001b[A\n",
      "Training:   0%| | 186/40960 [00:02<05:25, 125.12batches/s, l2_loss: 0.0647 - round_loss:\u001b[A\n",
      "Training:   0%| | 186/40960 [00:02<05:25, 125.12batches/s, l2_loss: 0.0629 - round_loss:\u001b[A\n",
      "Training:   1%| | 257/40960 [00:02<03:56, 171.86batches/s, l2_loss: 0.0629 - round_loss:\u001b[A\n",
      "Training:   1%| | 257/40960 [00:02<03:56, 171.86batches/s, l2_loss: 0.0601 - round_loss:\u001b[A\n",
      "Training:   1%| | 326/40960 [00:02<03:12, 210.66batches/s, l2_loss: 0.0601 - round_loss:\u001b[A\n",
      "Training:   1%| | 326/40960 [00:02<03:12, 210.66batches/s, l2_loss: 0.0590 - round_loss:\u001b[A\n",
      "Training:   1%| | 393/40960 [00:03<02:48, 240.56batches/s, l2_loss: 0.0590 - round_loss:\u001b[A\n",
      "Training:   1%| | 393/40960 [00:03<02:48, 240.56batches/s, l2_loss: 0.0575 - round_loss:\u001b[A\n",
      "Training:   1%| | 462/40960 [00:03<02:31, 266.92batches/s, l2_loss: 0.0575 - round_loss:\u001b[A\n",
      "Training:   1%| | 462/40960 [00:03<02:31, 266.92batches/s, l2_loss: 0.0563 - round_loss:\u001b[A\n",
      "Training:   1%| | 526/40960 [00:03<02:24, 280.11batches/s, l2_loss: 0.0563 - round_loss:\u001b[A\n",
      "Training:   1%| | 526/40960 [00:03<02:24, 280.11batches/s, l2_loss: 0.0555 - round_loss:\u001b[A\n",
      "Training:   1%| | 589/40960 [00:03<02:19, 289.42batches/s, l2_loss: 0.0555 - round_loss:\u001b[A\n",
      "Training:   1%| | 589/40960 [00:03<02:19, 289.42batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   2%| | 658/40960 [00:03<02:12, 304.95batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   2%| | 658/40960 [00:03<02:12, 304.95batches/s, l2_loss: 0.0541 - round_loss:\u001b[A\n",
      "Training:   2%| | 727/40960 [00:04<02:07, 315.80batches/s, l2_loss: 0.0541 - round_loss:\u001b[A\n",
      "Training:   2%| | 727/40960 [00:04<02:07, 315.80batches/s, l2_loss: 0.0533 - round_loss:\u001b[A\n",
      "Training:   2%| | 797/40960 [00:04<02:03, 325.48batches/s, l2_loss: 0.0533 - round_loss:\u001b[A\n",
      "Training:   2%| | 797/40960 [00:04<02:03, 325.48batches/s, l2_loss: 0.0525 - round_loss:\u001b[A\n",
      "Training:   2%| | 864/40960 [00:04<02:02, 327.05batches/s, l2_loss: 0.0525 - round_loss:\u001b[A\n",
      "Training:   2%| | 864/40960 [00:04<02:02, 327.05batches/s, l2_loss: 0.0518 - round_loss:\u001b[A\n",
      "Training:   2%| | 930/40960 [00:04<02:02, 326.71batches/s, l2_loss: 0.0518 - round_loss:\u001b[A\n",
      "Training:   2%| | 930/40960 [00:04<02:02, 326.71batches/s, l2_loss: 0.0515 - round_loss:\u001b[A\n",
      "Training:   2%| | 996/40960 [00:04<02:02, 327.07batches/s, l2_loss: 0.0515 - round_loss:\u001b[A\n",
      "Training:   2%| | 996/40960 [00:04<02:02, 327.07batches/s, l2_loss: 0.0507 - round_loss:\u001b[A\n",
      "Training:   3%| | 1060/40960 [00:05<02:03, 323.95batches/s, l2_loss: 0.0507 - round_loss\u001b[A\n",
      "Training:   3%| | 1060/40960 [00:05<02:03, 323.95batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:   3%| | 1124/40960 [00:05<02:03, 322.46batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:   3%| | 1124/40960 [00:05<02:03, 322.46batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:   3%| | 1192/40960 [00:05<02:01, 327.37batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:   3%| | 1192/40960 [00:05<02:01, 327.37batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:   3%| | 1257/40960 [00:05<02:01, 326.50batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:   3%| | 1257/40960 [00:05<02:01, 326.50batches/s, l2_loss: 0.0487 - round_loss\u001b[A\n",
      "Training:   3%| | 1320/40960 [00:05<02:02, 322.86batches/s, l2_loss: 0.0487 - round_loss\u001b[A\n",
      "Training:   3%| | 1320/40960 [00:05<02:02, 322.86batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:   3%| | 1385/40960 [00:06<02:02, 322.15batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:   3%| | 1385/40960 [00:06<02:02, 322.15batches/s, l2_loss: 0.0481 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%| | 1452/40960 [00:06<02:01, 325.04batches/s, l2_loss: 0.0481 - round_loss\u001b[A\n",
      "Training:   4%| | 1452/40960 [00:06<02:01, 325.04batches/s, l2_loss: 0.0476 - round_loss\u001b[A\n",
      "Training:   4%| | 1515/40960 [00:06<02:02, 321.15batches/s, l2_loss: 0.0476 - round_loss\u001b[A\n",
      "Training:   4%| | 1515/40960 [00:06<02:02, 321.15batches/s, l2_loss: 0.0474 - round_loss\u001b[A\n",
      "Training:   4%| | 1579/40960 [00:06<02:03, 319.63batches/s, l2_loss: 0.0474 - round_loss\u001b[A\n",
      "Training:   4%| | 1579/40960 [00:06<02:03, 319.63batches/s, l2_loss: 0.0471 - round_loss\u001b[A\n",
      "Training:   4%| | 1646/40960 [00:06<02:01, 323.76batches/s, l2_loss: 0.0471 - round_loss\u001b[A\n",
      "Training:   4%| | 1646/40960 [00:06<02:01, 323.76batches/s, l2_loss: 0.0467 - round_loss\u001b[A\n",
      "Training:   4%| | 1711/40960 [00:07<02:01, 323.67batches/s, l2_loss: 0.0467 - round_loss\u001b[A\n",
      "Training:   4%| | 1711/40960 [00:07<02:01, 323.67batches/s, l2_loss: 0.0464 - round_loss\u001b[A\n",
      "Training:   4%| | 1774/40960 [00:07<02:02, 319.97batches/s, l2_loss: 0.0464 - round_loss\u001b[A\n",
      "Training:   4%| | 1774/40960 [00:07<02:02, 319.97batches/s, l2_loss: 0.0461 - round_loss\u001b[A\n",
      "Training:   4%| | 1837/40960 [00:07<02:03, 317.98batches/s, l2_loss: 0.0461 - round_loss\u001b[A\n",
      "Training:   4%| | 1837/40960 [00:07<02:03, 317.98batches/s, l2_loss: 0.0459 - round_loss\u001b[A\n",
      "Training:   5%| | 1906/40960 [00:07<02:00, 325.18batches/s, l2_loss: 0.0459 - round_loss\u001b[A\n",
      "Training:   5%| | 1906/40960 [00:07<02:00, 325.18batches/s, l2_loss: 0.0456 - round_loss\u001b[A\n",
      "Training:   5%| | 1971/40960 [00:07<02:00, 324.22batches/s, l2_loss: 0.0456 - round_loss\u001b[A\n",
      "Training:   5%| | 1971/40960 [00:07<02:00, 324.22batches/s, l2_loss: 0.0454 - round_loss\u001b[A\n",
      "Training:   5%| | 2037/40960 [00:08<01:59, 325.63batches/s, l2_loss: 0.0454 - round_loss\u001b[A\n",
      "Training:   5%| | 2037/40960 [00:08<01:59, 325.63batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:   5%| | 2100/40960 [00:08<02:00, 322.20batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:   5%| | 2100/40960 [00:08<02:00, 322.20batches/s, l2_loss: 0.0450 - round_loss\u001b[A\n",
      "Training:   5%| | 2164/40960 [00:08<02:00, 321.01batches/s, l2_loss: 0.0450 - round_loss\u001b[A\n",
      "Training:   5%| | 2164/40960 [00:08<02:00, 321.01batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:   5%| | 2229/40960 [00:08<02:00, 321.17batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:   5%| | 2229/40960 [00:08<02:00, 321.17batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:   6%| | 2296/40960 [00:08<01:59, 324.32batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:   6%| | 2296/40960 [00:09<01:59, 324.32batches/s, l2_loss: 0.0443 - round_loss\u001b[A\n",
      "Training:   6%| | 2365/40960 [00:09<01:57, 329.29batches/s, l2_loss: 0.0443 - round_loss\u001b[A\n",
      "Training:   6%| | 2365/40960 [00:09<01:57, 329.29batches/s, l2_loss: 0.0440 - round_loss\u001b[A\n",
      "Training:   6%| | 2436/40960 [00:09<01:54, 335.70batches/s, l2_loss: 0.0440 - round_loss\u001b[A\n",
      "Training:   6%| | 2436/40960 [00:09<01:54, 335.70batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   6%| | 2500/40960 [00:09<01:56, 330.17batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:   6%| | 2500/40960 [00:09<01:56, 330.17batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   6%| | 2568/40960 [00:09<01:55, 333.06batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   6%| | 2568/40960 [00:09<01:55, 333.06batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   6%| | 2635/40960 [00:10<01:55, 332.66batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   6%| | 2635/40960 [00:10<01:55, 332.66batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   7%| | 2703/40960 [00:10<01:54, 332.92batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:   7%| | 2703/40960 [00:10<01:54, 332.92batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:   7%| | 2762/40960 [00:10<01:59, 319.55batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:   7%| | 2762/40960 [00:10<01:59, 319.55batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:   7%| | 2826/40960 [00:10<01:59, 319.34batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:   7%| | 2826/40960 [00:10<01:59, 319.34batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:   7%| | 2893/40960 [00:10<01:57, 323.47batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:   7%| | 2893/40960 [00:10<01:57, 323.47batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:   7%| | 2955/40960 [00:11<01:59, 319.19batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:   7%| | 2955/40960 [00:11<01:59, 319.19batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:   7%| | 3012/40960 [00:11<02:02, 308.69batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:   7%| | 3012/40960 [00:11<02:02, 308.69batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:   8%| | 3080/40960 [00:11<01:59, 318.01batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:   8%| | 3080/40960 [00:11<01:59, 318.01batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:   8%| | 3141/40960 [00:11<02:00, 313.68batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:   8%| | 3141/40960 [00:11<02:00, 313.68batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:   8%| | 3209/40960 [00:11<01:57, 321.33batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:   8%| | 3209/40960 [00:11<01:57, 321.33batches/s, l2_loss: 0.0419 - round_loss\u001b[A\n",
      "Training:   8%| | 3271/40960 [00:12<01:58, 317.94batches/s, l2_loss: 0.0419 - round_loss\u001b[A\n",
      "Training:   8%| | 3271/40960 [00:12<01:58, 317.94batches/s, l2_loss: 0.0418 - round_loss\u001b[A\n",
      "Training:   8%| | 3335/40960 [00:12<01:58, 318.08batches/s, l2_loss: 0.0418 - round_loss\u001b[A\n",
      "Training:   8%| | 3335/40960 [00:12<01:58, 318.08batches/s, l2_loss: 0.0417 - round_loss\u001b[A\n",
      "Training:   8%| | 3404/40960 [00:12<01:55, 324.90batches/s, l2_loss: 0.0417 - round_loss\u001b[A\n",
      "Training:   8%| | 3404/40960 [00:12<01:55, 324.90batches/s, l2_loss: 0.0416 - round_loss\u001b[A\n",
      "Training:   8%| | 3469/40960 [00:12<01:55, 324.39batches/s, l2_loss: 0.0416 - round_loss\u001b[A\n",
      "Training:   8%| | 3469/40960 [00:12<01:55, 324.39batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:   9%| | 3540/40960 [00:12<01:52, 332.95batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:   9%| | 3540/40960 [00:12<01:52, 332.95batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:   9%| | 3604/40960 [00:13<01:53, 328.45batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:   9%| | 3604/40960 [00:13<01:53, 328.45batches/s, l2_loss: 0.0412 - round_loss\u001b[A\n",
      "Training:   9%| | 3672/40960 [00:13<01:52, 330.84batches/s, l2_loss: 0.0412 - round_loss\u001b[A\n",
      "Training:   9%| | 3672/40960 [00:13<01:52, 330.84batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:   9%| | 3740/40960 [00:13<01:52, 332.17batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:   9%| | 3740/40960 [00:13<01:52, 332.17batches/s, l2_loss: 0.0410 - round_loss\u001b[A\n",
      "Training:   9%| | 3802/40960 [00:13<01:54, 324.80batches/s, l2_loss: 0.0410 - round_loss\u001b[A\n",
      "Training:   9%| | 3802/40960 [00:13<01:54, 324.80batches/s, l2_loss: 0.0409 - round_loss\u001b[A\n",
      "Training:   9%| | 3873/40960 [00:13<01:51, 332.99batches/s, l2_loss: 0.0409 - round_loss\u001b[A\n",
      "Training:   9%| | 3873/40960 [00:13<01:51, 332.99batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  10%| | 3936/40960 [00:14<01:53, 326.39batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  10%| | 3936/40960 [00:14<01:53, 326.39batches/s, l2_loss: 0.0406 - round_loss\u001b[A\n",
      "Training:  10%| | 4004/40960 [00:14<01:51, 330.31batches/s, l2_loss: 0.0406 - round_loss\u001b[A\n",
      "Training:  10%| | 4004/40960 [00:14<01:51, 330.31batches/s, l2_loss: 0.0405 - round_loss\u001b[A\n",
      "Training:  10%| | 4067/40960 [00:14<01:53, 324.59batches/s, l2_loss: 0.0405 - round_loss\u001b[A\n",
      "Training:  10%| | 4067/40960 [00:14<01:53, 324.59batches/s, l2_loss: 0.0404 - round_loss\u001b[A\n",
      "Training:  10%| | 4129/40960 [00:14<01:55, 319.35batches/s, l2_loss: 0.0404 - round_loss\u001b[A\n",
      "Training:  10%| | 4129/40960 [00:14<01:55, 319.35batches/s, l2_loss: 0.0403 - round_loss\u001b[A\n",
      "Training:  10%| | 4200/40960 [00:14<01:51, 329.90batches/s, l2_loss: 0.0403 - round_loss\u001b[A\n",
      "Training:  10%| | 4200/40960 [00:14<01:51, 329.90batches/s, l2_loss: 0.0403 - round_loss\u001b[A\n",
      "Training:  10%| | 4263/40960 [00:15<01:53, 324.75batches/s, l2_loss: 0.0403 - round_loss\u001b[A\n",
      "Training:  10%| | 4263/40960 [00:15<01:53, 324.75batches/s, l2_loss: 0.0401 - round_loss\u001b[A\n",
      "Training:  11%| | 4330/40960 [00:15<01:51, 327.41batches/s, l2_loss: 0.0401 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%| | 4330/40960 [00:15<01:51, 327.41batches/s, l2_loss: 0.0401 - round_loss\u001b[A\n",
      "Training:  11%| | 4397/40960 [00:15<01:51, 328.93batches/s, l2_loss: 0.0401 - round_loss\u001b[A\n",
      "Training:  11%| | 4397/40960 [00:15<01:51, 328.93batches/s, l2_loss: 0.0399 - round_loss\u001b[A\n",
      "Training:  11%| | 4460/40960 [00:15<01:52, 324.26batches/s, l2_loss: 0.0399 - round_loss\u001b[A\n",
      "Training:  11%| | 4460/40960 [00:15<01:52, 324.26batches/s, l2_loss: 0.0399 - round_loss\u001b[A\n",
      "Training:  11%| | 4527/40960 [00:15<01:51, 326.26batches/s, l2_loss: 0.0399 - round_loss\u001b[A\n",
      "Training:  11%| | 4527/40960 [00:15<01:51, 326.26batches/s, l2_loss: 0.0398 - round_loss\u001b[A\n",
      "Training:  11%| | 4589/40960 [00:16<01:53, 320.72batches/s, l2_loss: 0.0398 - round_loss\u001b[A\n",
      "Training:  11%| | 4589/40960 [00:16<01:53, 320.72batches/s, l2_loss: 0.0397 - round_loss\u001b[A\n",
      "Training:  11%| | 4656/40960 [00:16<01:51, 324.87batches/s, l2_loss: 0.0397 - round_loss\u001b[A\n",
      "Training:  11%| | 4656/40960 [00:16<01:51, 324.87batches/s, l2_loss: 0.0396 - round_loss\u001b[A\n",
      "Training:  12%| | 4724/40960 [00:16<01:50, 329.00batches/s, l2_loss: 0.0396 - round_loss\u001b[A\n",
      "Training:  12%| | 4724/40960 [00:16<01:50, 329.00batches/s, l2_loss: 0.0395 - round_loss\u001b[A\n",
      "Training:  12%| | 4794/40960 [00:16<01:47, 335.23batches/s, l2_loss: 0.0395 - round_loss\u001b[A\n",
      "Training:  12%| | 4794/40960 [00:16<01:47, 335.23batches/s, l2_loss: 0.0394 - round_loss\u001b[A\n",
      "Training:  12%| | 4850/40960 [00:16<01:53, 317.22batches/s, l2_loss: 0.0394 - round_loss\u001b[A\n",
      "Training:  12%| | 4850/40960 [00:16<01:53, 317.22batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:  12%| | 4899/40960 [00:17<02:02, 294.62batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:  12%| | 4899/40960 [00:17<02:02, 294.62batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:  12%| | 4945/40960 [00:17<02:11, 274.47batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:  12%| | 4945/40960 [00:17<02:11, 274.47batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:  12%| | 4992/40960 [00:17<02:17, 261.21batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:  12%| | 4992/40960 [00:17<02:17, 261.21batches/s, l2_loss: 0.0392 - round_loss\u001b[A\n",
      "Training:  12%| | 5048/40960 [00:17<02:14, 266.35batches/s, l2_loss: 0.0392 - round_loss\u001b[A\n",
      "Training:  12%| | 5048/40960 [00:17<02:14, 266.35batches/s, l2_loss: 0.0391 - round_loss\u001b[A\n",
      "Training:  12%| | 5116/40960 [00:17<02:04, 287.82batches/s, l2_loss: 0.0391 - round_loss\u001b[A\n",
      "Training:  12%| | 5116/40960 [00:17<02:04, 287.82batches/s, l2_loss: 0.0391 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5180/40960 [00:18<02:00, 296.99batches/s, l2_loss: 0.0391 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5180/40960 [00:18<02:00, 296.99batches/s, l2_loss: 0.0390 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5243/40960 [00:18<01:58, 302.24batches/s, l2_loss: 0.0390 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5243/40960 [00:18<01:58, 302.24batches/s, l2_loss: 0.0389 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5306/40960 [00:18<01:56, 305.16batches/s, l2_loss: 0.0389 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5306/40960 [00:18<01:56, 305.16batches/s, l2_loss: 0.0389 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5369/40960 [00:18<01:55, 307.85batches/s, l2_loss: 0.0389 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5369/40960 [00:18<01:55, 307.85batches/s, l2_loss: 0.0388 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5434/40960 [00:18<01:53, 312.09batches/s, l2_loss: 0.0388 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5434/40960 [00:18<01:53, 312.09batches/s, l2_loss: 0.0387 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5494/40960 [00:19<01:55, 307.96batches/s, l2_loss: 0.0387 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5494/40960 [00:19<01:55, 307.96batches/s, l2_loss: 0.0387 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5559/40960 [00:19<01:53, 313.02batches/s, l2_loss: 0.0387 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5559/40960 [00:19<01:53, 313.02batches/s, l2_loss: 0.0386 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5626/40960 [00:19<01:50, 318.47batches/s, l2_loss: 0.0386 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5626/40960 [00:19<01:50, 318.47batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5696/40960 [00:19<01:47, 327.10batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5696/40960 [00:19<01:47, 327.10batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5766/40960 [00:19<01:45, 332.88batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5766/40960 [00:19<01:45, 332.88batches/s, l2_loss: 0.0384 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5831/40960 [00:20<01:46, 330.16batches/s, l2_loss: 0.0384 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5831/40960 [00:20<01:46, 330.16batches/s, l2_loss: 0.0384 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5899/40960 [00:20<01:45, 333.05batches/s, l2_loss: 0.0384 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5899/40960 [00:20<01:45, 333.05batches/s, l2_loss: 0.0383 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5964/40960 [00:20<01:46, 329.13batches/s, l2_loss: 0.0383 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5964/40960 [00:20<01:46, 329.13batches/s, l2_loss: 0.0382 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6026/40960 [00:20<01:48, 321.85batches/s, l2_loss: 0.0382 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6026/40960 [00:20<01:48, 321.85batches/s, l2_loss: 0.0382 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6095/40960 [00:20<01:46, 327.34batches/s, l2_loss: 0.0382 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6095/40960 [00:20<01:46, 327.34batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6162/40960 [00:21<01:45, 329.50batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6162/40960 [00:21<01:45, 329.50batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6222/40960 [00:21<01:48, 320.16batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6222/40960 [00:21<01:48, 320.16batches/s, l2_loss: 0.0380 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6283/40960 [00:21<01:49, 315.41batches/s, l2_loss: 0.0380 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6283/40960 [00:21<01:49, 315.41batches/s, l2_loss: 0.0380 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6353/40960 [00:21<01:46, 324.48batches/s, l2_loss: 0.0380 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6353/40960 [00:21<01:46, 324.48batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:21<01:43, 333.82batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:21<01:43, 333.82batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6491/40960 [00:22<01:43, 331.61batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6491/40960 [00:22<01:43, 331.61batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6559/40960 [00:22<01:43, 332.98batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6559/40960 [00:22<01:43, 332.98batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6628/40960 [00:22<01:42, 335.44batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6628/40960 [00:22<01:42, 335.44batches/s, l2_loss: 0.0377 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6694/40960 [00:22<01:43, 332.41batches/s, l2_loss: 0.0377 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6694/40960 [00:22<01:43, 332.41batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6760/40960 [00:22<01:43, 330.79batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6760/40960 [00:22<01:43, 330.79batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6829/40960 [00:23<01:41, 334.73batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6829/40960 [00:23<01:41, 334.73batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6893/40960 [00:23<01:43, 330.18batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6893/40960 [00:23<01:43, 330.18batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6959/40960 [00:23<01:43, 329.32batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6959/40960 [00:23<01:43, 329.32batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7024/40960 [00:23<01:43, 326.91batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7024/40960 [00:23<01:43, 326.91batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7091/40960 [00:23<01:43, 328.02batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7091/40960 [00:23<01:43, 328.02batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7161/40960 [00:24<01:41, 333.83batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7161/40960 [00:24<01:41, 333.83batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|▏| 7228/40960 [00:24<01:41, 333.38batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7228/40960 [00:24<01:41, 333.38batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7292/40960 [00:24<01:43, 326.04batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7292/40960 [00:24<01:43, 326.04batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7355/40960 [00:24<01:44, 321.08batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7355/40960 [00:24<01:44, 321.08batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7417/40960 [00:24<01:45, 317.62batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7417/40960 [00:24<01:45, 317.62batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7483/40960 [00:25<01:44, 320.05batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7483/40960 [00:25<01:44, 320.05batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7550/40960 [00:25<01:43, 323.21batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7550/40960 [00:25<01:43, 323.21batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7621/40960 [00:25<01:40, 331.54batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7621/40960 [00:25<01:40, 331.54batches/s, l2_loss: 0.0370 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7691/40960 [00:25<01:39, 335.40batches/s, l2_loss: 0.0370 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7691/40960 [00:25<01:39, 335.40batches/s, l2_loss: 0.0370 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7762/40960 [00:25<01:37, 340.32batches/s, l2_loss: 0.0370 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7762/40960 [00:25<01:37, 340.32batches/s, l2_loss: 0.0369 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7834/40960 [00:26<01:35, 345.74batches/s, l2_loss: 0.0369 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7834/40960 [00:26<01:35, 345.74batches/s, l2_loss: 0.0369 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7906/40960 [00:26<01:34, 349.29batches/s, l2_loss: 0.0369 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7906/40960 [00:26<01:34, 349.29batches/s, l2_loss: 0.0368 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7973/40960 [00:26<01:35, 344.78batches/s, l2_loss: 0.0368 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7973/40960 [00:26<01:35, 344.78batches/s, l2_loss: 0.0368 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8043/40960 [00:26<01:35, 345.35batches/s, l2_loss: 0.0368 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8043/40960 [00:26<01:35, 345.35batches/s, l2_loss: 0.0368 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8115/40960 [00:26<01:34, 349.38batches/s, l2_loss: 0.0368 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8115/40960 [00:26<01:34, 349.38batches/s, l2_loss: 0.0367 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8181/40960 [00:27<01:35, 342.53batches/s, l2_loss: 0.0367 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8181/40960 [00:27<01:35, 342.53batches/s, l2_loss: 0.0367 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8240/40960 [00:27<01:39, 328.11batches/s, l2_loss: 0.0367 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8240/40960 [00:27<01:39, 328.11batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8298/40960 [00:27<01:43, 315.68batches/s, l2_loss: 0.0324 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8298/40960 [00:27<01:43, 315.68batches/s, l2_loss: 0.0328 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8361/40960 [00:27<01:43, 314.70batches/s, l2_loss: 0.0328 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8361/40960 [00:27<01:43, 314.70batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8420/40960 [00:27<01:45, 307.74batches/s, l2_loss: 0.0326 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8420/40960 [00:27<01:45, 307.74batches/s, l2_loss: 0.0327 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8486/40960 [00:28<01:43, 313.32batches/s, l2_loss: 0.0327 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8486/40960 [00:28<01:43, 313.32batches/s, l2_loss: 0.0334 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8550/40960 [00:28<01:43, 314.12batches/s, l2_loss: 0.0334 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8550/40960 [00:28<01:43, 314.12batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8609/40960 [00:28<01:45, 307.85batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8609/40960 [00:28<01:45, 307.85batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8673/40960 [00:28<01:44, 310.34batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8673/40960 [00:28<01:44, 310.34batches/s, l2_loss: 0.0329 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8735/40960 [00:28<01:44, 309.55batches/s, l2_loss: 0.0329 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8735/40960 [00:28<01:44, 309.55batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8797/40960 [00:29<01:43, 309.66batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8797/40960 [00:29<01:43, 309.66batches/s, l2_loss: 0.0335 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8862/40960 [00:29<01:42, 313.66batches/s, l2_loss: 0.0335 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8862/40960 [00:29<01:42, 313.66batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8919/40960 [00:29<01:45, 304.00batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8919/40960 [00:29<01:45, 304.00batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8976/40960 [00:29<01:47, 296.15batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8976/40960 [00:29<01:47, 296.15batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9035/40960 [00:29<01:48, 295.10batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9035/40960 [00:29<01:48, 295.10batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9096/40960 [00:30<01:47, 297.58batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9096/40960 [00:30<01:47, 297.58batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9160/40960 [00:30<01:44, 303.09batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9160/40960 [00:30<01:44, 303.09batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9225/40960 [00:30<01:42, 308.56batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9225/40960 [00:30<01:42, 308.56batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9289/40960 [00:30<01:41, 311.28batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9289/40960 [00:30<01:41, 311.28batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9353/40960 [00:30<01:40, 313.28batches/s, l2_loss: 0.0332 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9353/40960 [00:30<01:40, 313.28batches/s, l2_loss: 0.0335 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9418/40960 [00:31<01:39, 315.90batches/s, l2_loss: 0.0335 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9418/40960 [00:31<01:39, 315.90batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9482/40960 [00:31<01:39, 317.04batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9482/40960 [00:31<01:39, 317.04batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9543/40960 [00:31<01:40, 311.74batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9543/40960 [00:31<01:40, 311.74batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9591/40960 [00:31<01:48, 289.89batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9591/40960 [00:31<01:48, 289.89batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9649/40960 [00:31<01:48, 289.07batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9649/40960 [00:31<01:48, 289.07batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9705/40960 [00:32<01:49, 285.17batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9705/40960 [00:32<01:49, 285.17batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9769/40960 [00:32<01:45, 295.11batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9769/40960 [00:32<01:45, 295.11batches/s, l2_loss: 0.0334 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9833/40960 [00:32<01:42, 302.41batches/s, l2_loss: 0.0334 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9833/40960 [00:32<01:42, 302.41batches/s, l2_loss: 0.0334 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9898/40960 [00:32<01:40, 308.31batches/s, l2_loss: 0.0334 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9898/40960 [00:32<01:40, 308.31batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9961/40960 [00:33<01:40, 309.16batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9961/40960 [00:33<01:40, 309.16batches/s, l2_loss: 0.0333 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10024/40960 [00:33<01:39, 310.79batches/s, l2_loss: 0.0333 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|▏| 10024/40960 [00:33<01:39, 310.79batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  25%|▏| 10087/40960 [00:33<01:38, 311.94batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  25%|▏| 10087/40960 [00:33<01:38, 311.94batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  25%|▏| 10152/40960 [00:33<01:37, 315.42batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  25%|▏| 10152/40960 [00:33<01:37, 315.42batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  25%|▏| 10217/40960 [00:33<01:36, 317.97batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  25%|▏| 10217/40960 [00:33<01:36, 317.97batches/s, l2_loss: 0.0332 - round_los\u001b[A\n",
      "Training:  25%|▎| 10279/40960 [00:34<01:37, 315.35batches/s, l2_loss: 0.0332 - round_los\u001b[A\n",
      "Training:  25%|▎| 10279/40960 [00:34<01:37, 315.35batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  25%|▎| 10341/40960 [00:34<01:37, 312.60batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  25%|▎| 10341/40960 [00:34<01:37, 312.60batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  25%|▎| 10404/40960 [00:34<01:37, 312.49batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  25%|▎| 10404/40960 [00:34<01:37, 312.49batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10466/40960 [00:34<01:38, 310.93batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10466/40960 [00:34<01:38, 310.93batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10529/40960 [00:34<01:37, 310.97batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10529/40960 [00:34<01:37, 310.97batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10591/40960 [00:35<01:38, 309.71batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10591/40960 [00:35<01:38, 309.71batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10654/40960 [00:35<01:37, 311.13batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10654/40960 [00:35<01:37, 311.13batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10718/40960 [00:35<01:36, 312.33batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10718/40960 [00:35<01:36, 312.33batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  26%|▎| 10779/40960 [00:35<01:37, 309.18batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  26%|▎| 10779/40960 [00:35<01:37, 309.18batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10839/40960 [00:35<01:38, 305.66batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  26%|▎| 10839/40960 [00:35<01:38, 305.66batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 10897/40960 [00:36<01:40, 300.13batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 10897/40960 [00:36<01:40, 300.13batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 10948/40960 [00:36<01:45, 285.16batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 10948/40960 [00:36<01:45, 285.16batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 11003/40960 [00:36<01:46, 280.73batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 11003/40960 [00:36<01:46, 280.73batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 11059/40960 [00:36<01:46, 280.41batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 11059/40960 [00:36<01:46, 280.41batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  27%|▎| 11114/40960 [00:36<01:47, 277.61batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  27%|▎| 11114/40960 [00:36<01:47, 277.61batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 11174/40960 [00:37<01:44, 284.22batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  27%|▎| 11174/40960 [00:37<01:44, 284.22batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  27%|▎| 11235/40960 [00:37<01:42, 289.32batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  27%|▎| 11235/40960 [00:37<01:42, 289.32batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11295/40960 [00:37<01:41, 291.95batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11295/40960 [00:37<01:41, 291.95batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11360/40960 [00:37<01:38, 301.78batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11360/40960 [00:37<01:38, 301.78batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11424/40960 [00:37<01:36, 306.19batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11424/40960 [00:37<01:36, 306.19batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11490/40960 [00:38<01:34, 313.12batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11490/40960 [00:38<01:34, 313.12batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11548/40960 [00:38<01:36, 306.12batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11548/40960 [00:38<01:36, 306.12batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11612/40960 [00:38<01:34, 309.55batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  28%|▎| 11612/40960 [00:38<01:34, 309.55batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  29%|▎| 11679/40960 [00:38<01:32, 316.84batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  29%|▎| 11679/40960 [00:38<01:32, 316.84batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  29%|▎| 11745/40960 [00:38<01:31, 320.33batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  29%|▎| 11745/40960 [00:38<01:31, 320.33batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  29%|▎| 11811/40960 [00:39<01:30, 322.45batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  29%|▎| 11811/40960 [00:39<01:30, 322.45batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  29%|▎| 11879/40960 [00:39<01:28, 327.00batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  29%|▎| 11879/40960 [00:39<01:28, 327.00batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  29%|▎| 11942/40960 [00:39<01:30, 322.33batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  29%|▎| 11942/40960 [00:39<01:30, 322.33batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  29%|▎| 12003/40960 [00:39<01:31, 316.04batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  29%|▎| 12003/40960 [00:39<01:31, 316.04batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  29%|▎| 12064/40960 [00:39<01:32, 312.48batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  29%|▎| 12064/40960 [00:39<01:32, 312.48batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  30%|▎| 12128/40960 [00:40<01:31, 314.36batches/s, l2_loss: 0.0333 - round_los\u001b[A\n",
      "Training:  30%|▎| 12128/40960 [00:40<01:31, 314.36batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12193/40960 [00:40<01:30, 316.74batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12193/40960 [00:40<01:30, 316.74batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12256/40960 [00:40<01:30, 315.94batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12256/40960 [00:40<01:30, 315.94batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12319/40960 [00:40<01:31, 314.05batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12319/40960 [00:40<01:31, 314.05batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12380/40960 [00:40<01:31, 311.25batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12380/40960 [00:40<01:31, 311.25batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12441/40960 [00:41<01:32, 308.57batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  30%|▎| 12441/40960 [00:41<01:32, 308.57batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12505/40960 [00:41<01:31, 311.30batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12505/40960 [00:41<01:31, 311.30batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12565/40960 [00:41<01:32, 307.81batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12565/40960 [00:41<01:32, 307.81batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12621/40960 [00:41<01:34, 299.17batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12621/40960 [00:41<01:34, 299.17batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12688/40960 [00:41<01:31, 309.87batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12688/40960 [00:41<01:31, 309.87batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12751/40960 [00:42<01:30, 310.98batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12751/40960 [00:42<01:30, 310.98batches/s, l2_loss: 0.0334 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|▎| 12818/40960 [00:42<01:28, 317.62batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12818/40960 [00:42<01:28, 317.62batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12882/40960 [00:42<01:28, 317.67batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  31%|▎| 12882/40960 [00:42<01:28, 317.67batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 12947/40960 [00:42<01:27, 319.02batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 12947/40960 [00:42<01:27, 319.02batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13011/40960 [00:42<01:27, 318.94batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13011/40960 [00:42<01:27, 318.94batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13076/40960 [00:43<01:27, 319.45batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13076/40960 [00:43<01:27, 319.45batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13135/40960 [00:43<01:29, 310.88batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13135/40960 [00:43<01:29, 310.88batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13176/40960 [00:43<01:39, 278.02batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13176/40960 [00:43<01:39, 278.02batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13218/40960 [00:43<01:47, 257.57batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13218/40960 [00:43<01:47, 257.57batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13260/40960 [00:43<01:54, 242.43batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13260/40960 [00:43<01:54, 242.43batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13302/40960 [00:44<01:58, 232.42batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  32%|▎| 13302/40960 [00:44<01:58, 232.42batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13345/40960 [00:44<02:01, 226.44batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13345/40960 [00:44<02:01, 226.44batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13385/40960 [00:44<02:06, 218.01batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13385/40960 [00:44<02:06, 218.01batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13425/40960 [00:44<02:10, 211.78batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13425/40960 [00:44<02:10, 211.78batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13467/40960 [00:44<02:10, 211.05batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13467/40960 [00:44<02:10, 211.05batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13523/40960 [00:45<01:58, 231.55batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13523/40960 [00:45<01:58, 231.55batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13575/40960 [00:45<01:54, 239.12batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13575/40960 [00:45<01:54, 239.12batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13639/40960 [00:45<01:44, 262.56batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13639/40960 [00:45<01:44, 262.56batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13704/40960 [00:45<01:37, 280.55batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  33%|▎| 13704/40960 [00:45<01:37, 280.55batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13770/40960 [00:45<01:32, 294.81batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13770/40960 [00:45<01:32, 294.81batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13823/40960 [00:46<01:35, 283.92batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13823/40960 [00:46<01:35, 283.92batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13880/40960 [00:46<01:35, 282.85batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13880/40960 [00:46<01:35, 282.85batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13941/40960 [00:46<01:33, 288.09batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13941/40960 [00:46<01:33, 288.09batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13984/40960 [00:46<01:41, 266.11batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 13984/40960 [00:46<01:41, 266.11batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 14026/40960 [00:46<01:48, 248.76batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 14026/40960 [00:46<01:48, 248.76batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 14070/40960 [00:47<01:52, 239.19batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 14070/40960 [00:47<01:52, 239.19batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 14123/40960 [00:47<01:48, 246.58batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  34%|▎| 14123/40960 [00:47<01:48, 246.58batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14189/40960 [00:47<01:38, 270.90batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14189/40960 [00:47<01:38, 270.90batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14239/40960 [00:47<01:41, 264.13batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14239/40960 [00:47<01:41, 264.13batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14279/40960 [00:47<01:49, 243.59batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14279/40960 [00:47<01:49, 243.59batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14344/40960 [00:48<01:39, 267.80batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14344/40960 [00:48<01:39, 267.80batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14409/40960 [00:48<01:33, 283.88batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14409/40960 [00:48<01:33, 283.88batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14476/40960 [00:48<01:28, 298.42batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  35%|▎| 14476/40960 [00:48<01:28, 298.42batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14541/40960 [00:48<01:26, 305.83batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14541/40960 [00:48<01:26, 305.83batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14603/40960 [00:48<01:25, 306.62batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14603/40960 [00:48<01:25, 306.62batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14662/40960 [00:49<01:27, 302.23batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14662/40960 [00:49<01:27, 302.23batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14726/40960 [00:49<01:25, 306.85batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14726/40960 [00:49<01:25, 306.85batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14789/40960 [00:49<01:24, 307.98batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14789/40960 [00:49<01:24, 307.98batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14854/40960 [00:49<01:23, 311.87batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14854/40960 [00:49<01:23, 311.87batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14919/40960 [00:49<01:22, 315.69batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  36%|▎| 14919/40960 [00:49<01:22, 315.69batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 14981/40960 [00:50<01:22, 313.41batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 14981/40960 [00:50<01:22, 313.41batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15043/40960 [00:50<01:23, 311.74batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15043/40960 [00:50<01:23, 311.74batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15106/40960 [00:50<01:22, 311.56batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15106/40960 [00:50<01:22, 311.56batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15166/40960 [00:50<01:23, 307.54batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15166/40960 [00:50<01:23, 307.54batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15231/40960 [00:50<01:22, 312.68batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15231/40960 [00:50<01:22, 312.68batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15288/40960 [00:51<01:24, 304.12batches/s, l2_loss: 0.0334 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15288/40960 [00:51<01:24, 304.12batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15352/40960 [00:51<01:23, 308.44batches/s, l2_loss: 0.0334 - round_los\u001b[A\n",
      "Training:  37%|▎| 15352/40960 [00:51<01:23, 308.44batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15418/40960 [00:51<01:21, 313.95batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15418/40960 [00:51<01:21, 313.95batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15483/40960 [00:51<01:20, 316.24batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15483/40960 [00:51<01:20, 316.24batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15548/40960 [00:51<01:19, 317.68batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15548/40960 [00:51<01:19, 317.68batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15610/40960 [00:52<01:20, 315.31batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15610/40960 [00:52<01:20, 315.31batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15672/40960 [00:52<01:20, 312.51batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15672/40960 [00:52<01:20, 312.51batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15736/40960 [00:52<01:20, 313.66batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  38%|▍| 15736/40960 [00:52<01:20, 313.66batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 15800/40960 [00:52<01:20, 314.33batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 15800/40960 [00:52<01:20, 314.33batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 15866/40960 [00:52<01:18, 317.86batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 15866/40960 [00:52<01:18, 317.86batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 15932/40960 [00:53<01:17, 321.09batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 15932/40960 [00:53<01:17, 321.09batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 15998/40960 [00:53<01:17, 323.37batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 15998/40960 [00:53<01:17, 323.37batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 16059/40960 [00:53<01:18, 316.95batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 16059/40960 [00:53<01:18, 316.95batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 16122/40960 [00:53<01:18, 315.58batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  39%|▍| 16122/40960 [00:53<01:18, 315.58batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16184/40960 [00:53<01:19, 312.77batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16184/40960 [00:53<01:19, 312.77batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16245/40960 [00:54<01:19, 309.78batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16245/40960 [00:54<01:19, 309.78batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16310/40960 [00:54<01:18, 314.26batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16310/40960 [00:54<01:18, 314.26batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16375/40960 [00:54<01:17, 316.90batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16375/40960 [00:54<01:17, 316.90batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16436/40960 [00:54<01:18, 312.52batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16436/40960 [00:54<01:18, 312.52batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16494/40960 [00:54<01:20, 304.68batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16494/40960 [00:54<01:20, 304.68batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16534/40960 [00:55<01:29, 272.69batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16534/40960 [00:55<01:29, 272.69batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16578/40960 [00:55<01:35, 256.31batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  40%|▍| 16578/40960 [00:55<01:35, 256.31batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16619/40960 [00:55<01:41, 240.25batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16619/40960 [00:55<01:41, 240.25batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16661/40960 [00:55<01:45, 230.39batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16661/40960 [00:55<01:45, 230.39batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16715/40960 [00:55<01:40, 241.72batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16715/40960 [00:55<01:40, 241.72batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16780/40960 [00:56<01:30, 266.27batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16780/40960 [00:56<01:30, 266.27batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16846/40960 [00:56<01:24, 284.56batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16846/40960 [00:56<01:24, 284.56batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16904/40960 [00:56<01:24, 285.75batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16904/40960 [00:56<01:24, 285.75batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16948/40960 [00:56<01:30, 264.41batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  41%|▍| 16948/40960 [00:56<01:30, 264.41batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  41%|▍| 16992/40960 [00:56<01:35, 250.97batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  41%|▍| 16992/40960 [00:57<01:35, 250.97batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17048/40960 [00:57<01:32, 258.61batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17048/40960 [00:57<01:32, 258.61batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17093/40960 [00:57<01:36, 247.43batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17093/40960 [00:57<01:36, 247.43batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  42%|▍| 17139/40960 [00:57<01:38, 241.73batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  42%|▍| 17139/40960 [00:57<01:38, 241.73batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  42%|▍| 17204/40960 [00:57<01:29, 264.46batches/s, l2_loss: 0.0335 - round_los\u001b[A\n",
      "Training:  42%|▍| 17204/40960 [00:57<01:29, 264.46batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17268/40960 [00:58<01:24, 280.65batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17268/40960 [00:58<01:24, 280.65batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17330/40960 [00:58<01:21, 288.83batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17330/40960 [00:58<01:21, 288.83batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17387/40960 [00:58<01:22, 287.05batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  42%|▍| 17387/40960 [00:58<01:22, 287.05batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17434/40960 [00:58<01:27, 269.59batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17434/40960 [00:58<01:27, 269.59batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17494/40960 [00:58<01:24, 278.31batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17494/40960 [00:58<01:24, 278.31batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17561/40960 [00:59<01:19, 294.53batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17561/40960 [00:59<01:19, 294.53batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17624/40960 [00:59<01:17, 300.46batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17624/40960 [00:59<01:17, 300.46batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17689/40960 [00:59<01:15, 307.40batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17689/40960 [00:59<01:15, 307.40batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17749/40960 [00:59<01:16, 303.61batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17749/40960 [00:59<01:16, 303.61batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17808/40960 [00:59<01:17, 300.00batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  43%|▍| 17808/40960 [00:59<01:17, 300.00batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 17855/40960 [01:00<01:22, 280.62batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 17855/40960 [01:00<01:22, 280.62batches/s, l2_loss: 0.0336 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 17912/40960 [01:00<01:22, 280.33batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 17912/40960 [01:00<01:22, 280.33batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 17962/40960 [01:00<01:25, 269.63batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 17962/40960 [01:00<01:25, 269.63batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 18023/40960 [01:00<01:22, 277.44batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 18023/40960 [01:00<01:22, 277.44batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 18089/40960 [01:00<01:18, 292.12batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 18089/40960 [01:00<01:18, 292.12batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 18154/40960 [01:01<01:15, 301.47batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 18154/40960 [01:01<01:15, 301.47batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 18216/40960 [01:01<01:15, 303.22batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  44%|▍| 18216/40960 [01:01<01:15, 303.22batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18273/40960 [01:01<01:16, 296.79batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18273/40960 [01:01<01:16, 296.79batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18337/40960 [01:01<01:14, 302.49batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18337/40960 [01:01<01:14, 302.49batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18400/40960 [01:01<01:13, 305.72batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18400/40960 [01:01<01:13, 305.72batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18466/40960 [01:02<01:12, 312.02batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18466/40960 [01:02<01:12, 312.02batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18528/40960 [01:02<01:12, 310.92batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18528/40960 [01:02<01:12, 310.92batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18587/40960 [01:02<01:13, 304.86batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  45%|▍| 18587/40960 [01:02<01:13, 304.86batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  46%|▍| 18646/40960 [01:02<01:14, 301.54batches/s, l2_loss: 0.0336 - round_los\u001b[A\n",
      "Training:  46%|▍| 18646/40960 [01:02<01:14, 301.54batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18707/40960 [01:02<01:13, 301.43batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18707/40960 [01:02<01:13, 301.43batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18767/40960 [01:03<01:14, 299.86batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18767/40960 [01:03<01:14, 299.86batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18817/40960 [01:03<01:18, 282.89batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18817/40960 [01:03<01:18, 282.89batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18862/40960 [01:03<01:23, 265.55batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18862/40960 [01:03<01:23, 265.55batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18918/40960 [01:03<01:21, 269.62batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18918/40960 [01:03<01:21, 269.62batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18963/40960 [01:03<01:26, 254.34batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 18963/40960 [01:03<01:26, 254.34batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 19004/40960 [01:04<01:32, 237.49batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  46%|▍| 19004/40960 [01:04<01:32, 237.49batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19055/40960 [01:04<01:30, 241.30batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19055/40960 [01:04<01:30, 241.30batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19116/40960 [01:04<01:24, 259.92batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19116/40960 [01:04<01:24, 259.92batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19179/40960 [01:04<01:18, 275.92batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19179/40960 [01:04<01:18, 275.92batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19235/40960 [01:04<01:18, 276.36batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19235/40960 [01:04<01:18, 276.36batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19294/40960 [01:05<01:16, 281.76batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19294/40960 [01:05<01:16, 281.76batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19359/40960 [01:05<01:13, 293.51batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19359/40960 [01:05<01:13, 293.51batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19426/40960 [01:05<01:10, 304.78batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  47%|▍| 19426/40960 [01:05<01:10, 304.78batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19491/40960 [01:05<01:09, 309.60batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19491/40960 [01:05<01:09, 309.60batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19556/40960 [01:05<01:08, 313.72batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19556/40960 [01:05<01:08, 313.72batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19619/40960 [01:06<01:08, 313.79batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19619/40960 [01:06<01:08, 313.79batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19683/40960 [01:06<01:07, 315.22batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19683/40960 [01:06<01:07, 315.22batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19746/40960 [01:06<01:07, 314.75batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19746/40960 [01:06<01:07, 314.75batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19811/40960 [01:06<01:06, 317.16batches/s, l2_loss: 0.0337 - round_los\u001b[A\n",
      "Training:  48%|▍| 19811/40960 [01:06<01:06, 317.16batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 19867/40960 [01:06<01:09, 303.07batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 19867/40960 [01:06<01:09, 303.07batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 19929/40960 [01:07<01:08, 304.93batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 19929/40960 [01:07<01:08, 304.93batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 19992/40960 [01:07<01:08, 307.82batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 19992/40960 [01:07<01:08, 307.82batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 20052/40960 [01:07<01:08, 305.44batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 20052/40960 [01:07<01:08, 305.44batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 20116/40960 [01:07<01:07, 309.62batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 20116/40960 [01:07<01:07, 309.62batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 20177/40960 [01:07<01:07, 306.97batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 20177/40960 [01:07<01:07, 306.97batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 20235/40960 [01:08<01:09, 299.94batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  49%|▍| 20235/40960 [01:08<01:09, 299.94batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▍| 20290/40960 [01:08<01:11, 290.80batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▍| 20290/40960 [01:08<01:11, 290.80batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▍| 20350/40960 [01:08<01:10, 292.32batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▍| 20350/40960 [01:08<01:10, 292.32batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▍| 20410/40960 [01:08<01:09, 293.68batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▍| 20410/40960 [01:08<01:09, 293.68batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▍| 20475/40960 [01:08<01:07, 302.34batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▍| 20475/40960 [01:08<01:07, 302.34batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▌| 20538/40960 [01:09<01:06, 305.54batches/s, l2_loss: 0.0338 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 20538/40960 [01:09<01:06, 305.54batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▌| 20601/40960 [01:09<01:06, 307.21batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▌| 20601/40960 [01:09<01:06, 307.21batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▌| 20665/40960 [01:09<01:05, 309.09batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  50%|▌| 20665/40960 [01:09<01:05, 309.09batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 20721/40960 [01:09<01:07, 299.52batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 20721/40960 [01:09<01:07, 299.52batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 20778/40960 [01:09<01:08, 294.88batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 20778/40960 [01:09<01:08, 294.88batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 20842/40960 [01:10<01:06, 301.28batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 20842/40960 [01:10<01:06, 301.28batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 20909/40960 [01:10<01:04, 310.58batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 20909/40960 [01:10<01:04, 310.58batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  51%|▌| 20968/40960 [01:10<01:05, 304.65batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  51%|▌| 20968/40960 [01:10<01:05, 304.65batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 21033/40960 [01:10<01:04, 310.10batches/s, l2_loss: 0.0338 - round_los\u001b[A\n",
      "Training:  51%|▌| 21033/40960 [01:10<01:04, 310.10batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21101/40960 [01:10<01:02, 317.66batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21101/40960 [01:10<01:02, 317.66batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21167/40960 [01:11<01:01, 320.07batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21167/40960 [01:11<01:01, 320.07batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21228/40960 [01:11<01:02, 314.85batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21228/40960 [01:11<01:02, 314.85batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21295/40960 [01:11<01:01, 320.08batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21295/40960 [01:11<01:01, 320.08batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21356/40960 [01:11<01:02, 315.40batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21356/40960 [01:11<01:02, 315.40batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21408/40960 [01:11<01:05, 297.40batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21408/40960 [01:11<01:05, 297.40batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21465/40960 [01:12<01:07, 290.44batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  52%|▌| 21465/40960 [01:12<01:07, 290.44batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21523/40960 [01:12<01:07, 289.08batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21523/40960 [01:12<01:07, 289.08batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21586/40960 [01:12<01:05, 295.84batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21586/40960 [01:12<01:05, 295.84batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21651/40960 [01:12<01:03, 303.63batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21651/40960 [01:12<01:03, 303.63batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21715/40960 [01:12<01:02, 307.32batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21715/40960 [01:12<01:02, 307.32batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21779/40960 [01:13<01:01, 310.44batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21779/40960 [01:13<01:01, 310.44batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21846/40960 [01:13<01:00, 316.57batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21846/40960 [01:13<01:00, 316.57batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21909/40960 [01:13<01:00, 315.75batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  53%|▌| 21909/40960 [01:13<01:00, 315.75batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  54%|▌| 21974/40960 [01:13<00:59, 318.31batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  54%|▌| 21974/40960 [01:13<00:59, 318.31batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  54%|▌| 22039/40960 [01:13<00:59, 319.60batches/s, l2_loss: 0.0339 - round_los\u001b[A\n",
      "Training:  54%|▌| 22039/40960 [01:13<00:59, 319.60batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  54%|▌| 22103/40960 [01:14<00:59, 319.41batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  54%|▌| 22103/40960 [01:14<00:59, 319.41batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  54%|▌| 22166/40960 [01:14<00:59, 317.33batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  54%|▌| 22166/40960 [01:14<00:59, 317.33batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  54%|▌| 22228/40960 [01:14<00:59, 314.72batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  54%|▌| 22228/40960 [01:14<00:59, 314.72batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  54%|▌| 22294/40960 [01:14<00:58, 318.08batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  54%|▌| 22294/40960 [01:14<00:58, 318.08batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22360/40960 [01:14<00:57, 321.51batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22360/40960 [01:14<00:57, 321.51batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22420/40960 [01:15<00:58, 314.31batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22420/40960 [01:15<00:58, 314.31batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22481/40960 [01:15<00:59, 310.81batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22481/40960 [01:15<00:59, 310.81batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22543/40960 [01:15<00:59, 309.49batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22543/40960 [01:15<00:59, 309.49batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22605/40960 [01:15<00:59, 309.00batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22605/40960 [01:15<00:59, 309.00batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22669/40960 [01:15<00:58, 311.82batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22669/40960 [01:15<00:58, 311.82batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22730/40960 [01:16<00:59, 307.98batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  55%|▌| 22730/40960 [01:16<00:59, 307.98batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  56%|▌| 22789/40960 [01:16<00:59, 303.93batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  56%|▌| 22789/40960 [01:16<00:59, 303.93batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  56%|▌| 22844/40960 [01:16<01:01, 293.37batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  56%|▌| 22844/40960 [01:16<01:01, 293.37batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  56%|▌| 22906/40960 [01:16<01:00, 298.30batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  56%|▌| 22906/40960 [01:16<01:00, 298.30batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  56%|▌| 22968/40960 [01:17<00:59, 300.47batches/s, l2_loss: 0.0340 - round_los\u001b[A\n",
      "Training:  56%|▌| 22968/40960 [01:17<00:59, 300.47batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  56%|▌| 23035/40960 [01:17<00:57, 310.28batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  56%|▌| 23035/40960 [01:17<00:57, 310.28batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  56%|▌| 23101/40960 [01:17<00:56, 315.00batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  56%|▌| 23101/40960 [01:17<00:56, 315.00batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23158/40960 [01:17<00:58, 304.52batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23158/40960 [01:17<00:58, 304.52batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23217/40960 [01:17<00:59, 300.18batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23217/40960 [01:17<00:59, 300.18batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23273/40960 [01:18<01:00, 292.12batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23273/40960 [01:18<01:00, 292.12batches/s, l2_loss: 0.0341 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|▌| 23330/40960 [01:18<01:00, 289.32batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23330/40960 [01:18<01:00, 289.32batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23395/40960 [01:18<00:58, 299.17batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23395/40960 [01:18<00:58, 299.17batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23459/40960 [01:18<00:57, 305.08batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23459/40960 [01:18<00:57, 305.08batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23523/40960 [01:18<00:56, 308.31batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  57%|▌| 23523/40960 [01:18<00:56, 308.31batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23588/40960 [01:19<00:55, 311.93batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23588/40960 [01:19<00:55, 311.93batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23652/40960 [01:19<00:55, 314.26batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23652/40960 [01:19<00:55, 314.26batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23714/40960 [01:19<00:55, 312.34batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23714/40960 [01:19<00:55, 312.34batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23776/40960 [01:19<00:55, 310.42batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23776/40960 [01:19<00:55, 310.42batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23841/40960 [01:19<00:54, 314.34batches/s, l2_loss: 0.0341 - round_los\u001b[A\n",
      "Training:  58%|▌| 23841/40960 [01:19<00:54, 314.34batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  58%|▌| 23904/40960 [01:20<00:54, 314.24batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  58%|▌| 23904/40960 [01:20<00:54, 314.24batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 23969/40960 [01:20<00:53, 317.44batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 23969/40960 [01:20<00:53, 317.44batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24032/40960 [01:20<00:53, 316.05batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24032/40960 [01:20<00:53, 316.05batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24093/40960 [01:20<00:54, 312.11batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24093/40960 [01:20<00:54, 312.11batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24158/40960 [01:20<00:53, 314.80batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24158/40960 [01:20<00:53, 314.80batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24223/40960 [01:21<00:52, 317.37batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24223/40960 [01:21<00:52, 317.37batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24288/40960 [01:21<00:52, 318.71batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24288/40960 [01:21<00:52, 318.71batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24352/40960 [01:21<00:52, 318.77batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  59%|▌| 24352/40960 [01:21<00:52, 318.77batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24417/40960 [01:21<00:51, 320.03batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24417/40960 [01:21<00:51, 320.03batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24482/40960 [01:21<00:51, 320.64batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24482/40960 [01:21<00:51, 320.64batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24544/40960 [01:22<00:51, 315.88batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24544/40960 [01:22<00:51, 315.88batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24605/40960 [01:22<00:52, 312.04batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24605/40960 [01:22<00:52, 312.04batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24670/40960 [01:22<00:51, 315.33batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24670/40960 [01:22<00:51, 315.33batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24734/40960 [01:22<00:51, 316.25batches/s, l2_loss: 0.0342 - round_los\u001b[A\n",
      "Training:  60%|▌| 24734/40960 [01:22<00:51, 316.25batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 24796/40960 [01:22<00:51, 313.93batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 24796/40960 [01:22<00:51, 313.93batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 24861/40960 [01:23<00:50, 316.29batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 24861/40960 [01:23<00:50, 316.29batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 24923/40960 [01:23<00:51, 313.32batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 24923/40960 [01:23<00:51, 313.32batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 24987/40960 [01:23<00:50, 314.51batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 24987/40960 [01:23<00:50, 314.51batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 25050/40960 [01:23<00:50, 313.90batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 25050/40960 [01:23<00:50, 313.90batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 25115/40960 [01:23<00:50, 316.70batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 25115/40960 [01:23<00:50, 316.70batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 25178/40960 [01:24<00:50, 315.39batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  61%|▌| 25178/40960 [01:24<00:50, 315.39batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25239/40960 [01:24<00:50, 312.14batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25239/40960 [01:24<00:50, 312.14batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25302/40960 [01:24<00:50, 311.98batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25302/40960 [01:24<00:50, 311.98batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25363/40960 [01:24<00:50, 308.81batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25363/40960 [01:24<00:50, 308.81batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25426/40960 [01:24<00:50, 310.65batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25426/40960 [01:24<00:50, 310.65batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25490/40960 [01:25<00:49, 312.43batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25490/40960 [01:25<00:49, 312.43batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25551/40960 [01:25<00:49, 309.68batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▌| 25551/40960 [01:25<00:49, 309.68batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▋| 25600/40960 [01:25<00:52, 290.21batches/s, l2_loss: 0.0343 - round_los\u001b[A\n",
      "Training:  62%|▋| 25600/40960 [01:25<00:52, 290.21batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25640/40960 [01:25<00:58, 262.31batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25640/40960 [01:25<00:58, 262.31batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25678/40960 [01:25<01:03, 239.77batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25678/40960 [01:25<01:03, 239.77batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25719/40960 [01:26<01:06, 229.17batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25719/40960 [01:26<01:06, 229.17batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25776/40960 [01:26<01:01, 245.25batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25776/40960 [01:26<01:01, 245.25batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25822/40960 [01:26<01:03, 239.77batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25822/40960 [01:26<01:03, 239.77batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25886/40960 [01:26<00:57, 262.93batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25886/40960 [01:26<00:57, 262.93batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25949/40960 [01:26<00:53, 278.11batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  63%|▋| 25949/40960 [01:26<00:53, 278.11batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26011/40960 [01:27<00:52, 285.89batches/s, l2_loss: 0.0344 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|▋| 26011/40960 [01:27<00:52, 285.89batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26067/40960 [01:27<00:52, 283.31batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26067/40960 [01:27<00:52, 283.31batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26130/40960 [01:27<00:50, 292.58batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26130/40960 [01:27<00:50, 292.58batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26195/40960 [01:27<00:48, 301.59batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26195/40960 [01:27<00:48, 301.59batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26259/40960 [01:27<00:48, 306.15batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26259/40960 [01:27<00:48, 306.15batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26321/40960 [01:28<00:47, 306.14batches/s, l2_loss: 0.0344 - round_los\u001b[A\n",
      "Training:  64%|▋| 26321/40960 [01:28<00:47, 306.14batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  64%|▋| 26379/40960 [01:28<00:48, 300.27batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  64%|▋| 26379/40960 [01:28<00:48, 300.27batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26442/40960 [01:28<00:47, 304.12batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26442/40960 [01:28<00:47, 304.12batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26504/40960 [01:28<00:47, 305.41batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26504/40960 [01:28<00:47, 305.41batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26569/40960 [01:28<00:46, 309.91batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26569/40960 [01:28<00:46, 309.91batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26632/40960 [01:29<00:46, 310.45batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26632/40960 [01:29<00:46, 310.45batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26695/40960 [01:29<00:45, 311.03batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26695/40960 [01:29<00:45, 311.03batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26760/40960 [01:29<00:45, 314.80batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26760/40960 [01:29<00:45, 314.80batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26824/40960 [01:29<00:44, 316.28batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  65%|▋| 26824/40960 [01:29<00:44, 316.28batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  66%|▋| 26875/40960 [01:29<00:47, 297.37batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  66%|▋| 26875/40960 [01:29<00:47, 297.37batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  66%|▋| 26939/40960 [01:30<00:46, 303.73batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  66%|▋| 26939/40960 [01:30<00:46, 303.73batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  66%|▋| 26983/40960 [01:30<00:50, 277.29batches/s, l2_loss: 0.0345 - round_los\u001b[A\n",
      "Training:  66%|▋| 26983/40960 [01:30<00:50, 277.29batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27032/40960 [01:30<00:52, 266.67batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27032/40960 [01:30<00:52, 266.67batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27073/40960 [01:30<00:56, 246.99batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27073/40960 [01:30<00:56, 246.99batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27114/40960 [01:30<00:59, 234.10batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27114/40960 [01:30<00:59, 234.10batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27155/40960 [01:31<01:01, 224.51batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27155/40960 [01:31<01:01, 224.51batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27210/40960 [01:31<00:57, 238.93batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  66%|▋| 27210/40960 [01:31<00:57, 238.93batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27271/40960 [01:31<00:53, 257.53batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27271/40960 [01:31<00:53, 257.53batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27308/40960 [01:31<00:58, 235.34batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27308/40960 [01:31<00:58, 235.34batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27350/40960 [01:31<01:00, 226.41batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27350/40960 [01:31<01:00, 226.41batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27390/40960 [01:32<01:02, 217.91batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27390/40960 [01:32<01:02, 217.91batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27432/40960 [01:32<01:02, 215.07batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27432/40960 [01:32<01:02, 215.07batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27467/40960 [01:32<01:06, 203.08batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27467/40960 [01:32<01:06, 203.08batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27510/40960 [01:32<01:05, 205.90batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27510/40960 [01:32<01:05, 205.90batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27575/40960 [01:32<00:55, 240.32batches/s, l2_loss: 0.0346 - round_los\u001b[A\n",
      "Training:  67%|▋| 27575/40960 [01:32<00:55, 240.32batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  67%|▋| 27631/40960 [01:33<00:53, 250.75batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  67%|▋| 27631/40960 [01:33<00:53, 250.75batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27673/40960 [01:33<00:55, 238.28batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27673/40960 [01:33<00:55, 238.28batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27713/40960 [01:33<00:58, 226.03batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27713/40960 [01:33<00:58, 226.03batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27755/40960 [01:33<00:59, 220.40batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27755/40960 [01:33<00:59, 220.40batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27800/40960 [01:33<00:59, 221.31batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27800/40960 [01:33<00:59, 221.31batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27864/40960 [01:34<00:52, 250.29batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27864/40960 [01:34<00:52, 250.29batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27931/40960 [01:34<00:47, 275.11batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27931/40960 [01:34<00:47, 275.11batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27995/40960 [01:34<00:44, 288.50batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  68%|▋| 27995/40960 [01:34<00:44, 288.50batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  69%|▋| 28058/40960 [01:34<00:43, 295.79batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  69%|▋| 28058/40960 [01:34<00:43, 295.79batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  69%|▋| 28124/40960 [01:34<00:42, 304.67batches/s, l2_loss: 0.0347 - round_los\u001b[A\n",
      "Training:  69%|▋| 28124/40960 [01:34<00:42, 304.67batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28183/40960 [01:35<00:42, 299.14batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28183/40960 [01:35<00:42, 299.14batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28243/40960 [01:35<00:42, 299.05batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28243/40960 [01:35<00:42, 299.05batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28306/40960 [01:35<00:41, 303.42batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28306/40960 [01:35<00:41, 303.42batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28373/40960 [01:35<00:40, 311.56batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28373/40960 [01:35<00:40, 311.56batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28437/40960 [01:35<00:39, 313.39batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  69%|▋| 28437/40960 [01:35<00:39, 313.39batches/s, l2_loss: 0.0348 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28501/40960 [01:36<00:39, 314.03batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28501/40960 [01:36<00:39, 314.03batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28567/40960 [01:36<00:39, 317.68batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28567/40960 [01:36<00:39, 317.68batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28616/40960 [01:36<00:41, 295.30batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28616/40960 [01:36<00:41, 295.30batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28656/40960 [01:36<00:46, 265.44batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28656/40960 [01:36<00:46, 265.44batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28692/40960 [01:36<00:51, 238.80batches/s, l2_loss: 0.0348 - round_los\u001b[A\n",
      "Training:  70%|▋| 28692/40960 [01:37<00:51, 238.80batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  70%|▋| 28732/40960 [01:37<00:54, 225.80batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  70%|▋| 28732/40960 [01:37<00:54, 225.80batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  70%|▋| 28772/40960 [01:37<00:55, 217.69batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  70%|▋| 28772/40960 [01:37<00:55, 217.69batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  70%|▋| 28813/40960 [01:37<00:57, 212.76batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  70%|▋| 28813/40960 [01:37<00:57, 212.76batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  70%|▋| 28851/40960 [01:37<00:58, 205.77batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  70%|▋| 28851/40960 [01:37<00:58, 205.77batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 28914/40960 [01:38<00:50, 238.06batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 28914/40960 [01:38<00:50, 238.06batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 28980/40960 [01:38<00:45, 265.31batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 28980/40960 [01:38<00:45, 265.31batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 29040/40960 [01:38<00:43, 274.54batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 29040/40960 [01:38<00:43, 274.54batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 29102/40960 [01:38<00:41, 284.96batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 29102/40960 [01:38<00:41, 284.96batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 29167/40960 [01:38<00:39, 296.77batches/s, l2_loss: 0.0349 - round_los\u001b[A\n",
      "Training:  71%|▋| 29167/40960 [01:38<00:39, 296.77batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  71%|▋| 29224/40960 [01:39<00:40, 291.39batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  71%|▋| 29224/40960 [01:39<00:40, 291.39batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  71%|▋| 29266/40960 [01:39<00:43, 265.90batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  71%|▋| 29266/40960 [01:39<00:43, 265.90batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29322/40960 [01:39<00:43, 269.84batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29322/40960 [01:39<00:43, 269.84batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29386/40960 [01:39<00:40, 284.67batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29386/40960 [01:39<00:40, 284.67batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29448/40960 [01:39<00:39, 291.93batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29448/40960 [01:39<00:39, 291.93batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29506/40960 [01:40<00:39, 290.33batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29506/40960 [01:40<00:39, 290.33batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29571/40960 [01:40<00:38, 299.63batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29571/40960 [01:40<00:38, 299.63batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29636/40960 [01:40<00:36, 306.74batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  72%|▋| 29636/40960 [01:40<00:36, 306.74batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  73%|▋| 29701/40960 [01:40<00:36, 311.72batches/s, l2_loss: 0.0350 - round_los\u001b[A\n",
      "Training:  73%|▋| 29701/40960 [01:40<00:36, 311.72batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 29765/40960 [01:40<00:35, 313.20batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 29765/40960 [01:40<00:35, 313.20batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 29830/40960 [01:41<00:35, 315.18batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 29830/40960 [01:41<00:35, 315.18batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 29895/40960 [01:41<00:34, 317.03batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 29895/40960 [01:41<00:34, 317.03batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 29961/40960 [01:41<00:34, 319.89batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 29961/40960 [01:41<00:34, 319.89batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 30026/40960 [01:41<00:34, 320.72batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 30026/40960 [01:41<00:34, 320.72batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 30089/40960 [01:41<00:34, 318.90batches/s, l2_loss: 0.0351 - round_los\u001b[A\n",
      "Training:  73%|▋| 30089/40960 [01:41<00:34, 318.90batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30150/40960 [01:42<00:34, 312.97batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30150/40960 [01:42<00:34, 312.97batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30215/40960 [01:42<00:34, 315.83batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30215/40960 [01:42<00:34, 315.83batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30275/40960 [01:42<00:34, 309.46batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30275/40960 [01:42<00:34, 309.46batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30340/40960 [01:42<00:33, 312.91batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30340/40960 [01:42<00:33, 312.91batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30405/40960 [01:42<00:33, 315.55batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30405/40960 [01:42<00:33, 315.55batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30470/40960 [01:43<00:32, 318.16batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  74%|▋| 30470/40960 [01:43<00:32, 318.16batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  75%|▋| 30531/40960 [01:43<00:33, 313.99batches/s, l2_loss: 0.0352 - round_los\u001b[A\n",
      "Training:  75%|▋| 30531/40960 [01:43<00:33, 313.99batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▋| 30575/40960 [01:43<00:36, 284.25batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▋| 30575/40960 [01:43<00:36, 284.25batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▋| 30629/40960 [01:43<00:36, 279.93batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▋| 30629/40960 [01:43<00:36, 279.93batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▋| 30687/40960 [01:43<00:36, 281.45batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▋| 30687/40960 [01:43<00:36, 281.45batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▊| 30745/40960 [01:44<00:36, 282.30batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▊| 30745/40960 [01:44<00:36, 282.30batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▊| 30805/40960 [01:44<00:35, 287.42batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▊| 30805/40960 [01:44<00:35, 287.42batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▊| 30863/40960 [01:44<00:35, 287.53batches/s, l2_loss: 0.0353 - round_los\u001b[A\n",
      "Training:  75%|▊| 30863/40960 [01:44<00:35, 287.53batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  75%|▊| 30924/40960 [01:44<00:34, 292.72batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  75%|▊| 30924/40960 [01:44<00:34, 292.72batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 30988/40960 [01:44<00:33, 300.03batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 30988/40960 [01:44<00:33, 300.03batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 31050/40960 [01:45<00:32, 302.80batches/s, l2_loss: 0.0354 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31050/40960 [01:45<00:32, 302.80batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 31115/40960 [01:45<00:31, 308.71batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 31115/40960 [01:45<00:31, 308.71batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 31178/40960 [01:45<00:31, 309.25batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 31178/40960 [01:45<00:31, 309.25batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 31241/40960 [01:45<00:31, 309.99batches/s, l2_loss: 0.0354 - round_los\u001b[A\n",
      "Training:  76%|▊| 31241/40960 [01:45<00:31, 309.99batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  76%|▊| 31306/40960 [01:45<00:30, 313.57batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  76%|▊| 31306/40960 [01:45<00:30, 313.57batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31370/40960 [01:46<00:30, 315.02batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31370/40960 [01:46<00:30, 315.02batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31436/40960 [01:46<00:29, 318.73batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31436/40960 [01:46<00:29, 318.73batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31499/40960 [01:46<00:29, 315.98batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31499/40960 [01:46<00:29, 315.98batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31548/40960 [01:46<00:32, 291.88batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31548/40960 [01:46<00:32, 291.88batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31613/40960 [01:46<00:31, 300.61batches/s, l2_loss: 0.0355 - round_los\u001b[A\n",
      "Training:  77%|▊| 31613/40960 [01:46<00:31, 300.61batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  77%|▊| 31680/40960 [01:47<00:29, 309.80batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  77%|▊| 31680/40960 [01:47<00:29, 309.80batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  77%|▊| 31743/40960 [01:47<00:29, 310.96batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  77%|▊| 31743/40960 [01:47<00:29, 310.96batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  78%|▊| 31805/40960 [01:47<00:29, 308.96batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  78%|▊| 31805/40960 [01:47<00:29, 308.96batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  78%|▊| 31869/40960 [01:47<00:29, 311.89batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  78%|▊| 31869/40960 [01:47<00:29, 311.89batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  78%|▊| 31935/40960 [01:47<00:28, 316.57batches/s, l2_loss: 0.0356 - round_los\u001b[A\n",
      "Training:  78%|▊| 31935/40960 [01:47<00:28, 316.57batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  78%|▊| 31997/40960 [01:48<00:28, 314.36batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  78%|▊| 31997/40960 [01:48<00:28, 314.36batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  78%|▊| 32057/40960 [01:48<00:28, 309.61batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  78%|▊| 32057/40960 [01:48<00:28, 309.61batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  78%|▊| 32121/40960 [01:48<00:28, 311.53batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  78%|▊| 32121/40960 [01:48<00:28, 311.53batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  79%|▊| 32182/40960 [01:48<00:28, 308.35batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  79%|▊| 32182/40960 [01:48<00:28, 308.35batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  79%|▊| 32231/40960 [01:48<00:30, 288.82batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  79%|▊| 32231/40960 [01:48<00:30, 288.82batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  79%|▊| 32277/40960 [01:49<00:32, 269.81batches/s, l2_loss: 0.0357 - round_los\u001b[A\n",
      "Training:  79%|▊| 32277/40960 [01:49<00:32, 269.81batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32317/40960 [01:49<00:34, 248.26batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32317/40960 [01:49<00:34, 248.26batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32358/40960 [01:49<00:36, 234.84batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32358/40960 [01:49<00:36, 234.84batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32398/40960 [01:49<00:38, 223.86batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32398/40960 [01:49<00:38, 223.86batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32437/40960 [01:49<00:39, 213.81batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32437/40960 [01:49<00:39, 213.81batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32474/40960 [01:50<00:41, 204.48batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32474/40960 [01:50<00:41, 204.48batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32515/40960 [01:50<00:41, 204.09batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32515/40960 [01:50<00:41, 204.09batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32555/40960 [01:50<00:41, 202.81batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  79%|▊| 32555/40960 [01:50<00:41, 202.81batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  80%|▊| 32609/40960 [01:50<00:37, 221.89batches/s, l2_loss: 0.0358 - round_los\u001b[A\n",
      "Training:  80%|▊| 32609/40960 [01:50<00:37, 221.89batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32650/40960 [01:50<00:38, 215.84batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32650/40960 [01:50<00:38, 215.84batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32691/40960 [01:51<00:38, 212.13batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32691/40960 [01:51<00:38, 212.13batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32738/40960 [01:51<00:37, 218.29batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32738/40960 [01:51<00:37, 218.29batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32797/40960 [01:51<00:33, 241.01batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32797/40960 [01:51<00:33, 241.01batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32862/40960 [01:51<00:30, 265.49batches/s, l2_loss: 0.0359 - round_los\u001b[A\n",
      "Training:  80%|▊| 32862/40960 [01:51<00:30, 265.49batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  80%|▊| 32925/40960 [01:51<00:28, 279.97batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  80%|▊| 32925/40960 [01:51<00:28, 279.97batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  81%|▊| 32986/40960 [01:52<00:27, 287.17batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  81%|▊| 32986/40960 [01:52<00:27, 287.17batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  81%|▊| 33046/40960 [01:52<00:27, 290.96batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  81%|▊| 33046/40960 [01:52<00:27, 290.96batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  81%|▊| 33087/40960 [01:52<00:29, 264.72batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  81%|▊| 33087/40960 [01:52<00:29, 264.72batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  81%|▊| 33136/40960 [01:52<00:30, 257.95batches/s, l2_loss: 0.0360 - round_los\u001b[A\n",
      "Training:  81%|▊| 33136/40960 [01:52<00:30, 257.95batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  81%|▊| 33189/40960 [01:52<00:30, 258.20batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  81%|▊| 33189/40960 [01:52<00:30, 258.20batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  81%|▊| 33234/40960 [01:53<00:31, 247.71batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  81%|▊| 33234/40960 [01:53<00:31, 247.71batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  81%|▊| 33300/40960 [01:53<00:28, 271.85batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  81%|▊| 33300/40960 [01:53<00:28, 271.85batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  81%|▊| 33364/40960 [01:53<00:26, 285.08batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  81%|▊| 33364/40960 [01:53<00:26, 285.08batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  82%|▊| 33413/40960 [01:53<00:27, 272.15batches/s, l2_loss: 0.0361 - round_los\u001b[A\n",
      "Training:  82%|▊| 33413/40960 [01:53<00:27, 272.15batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33447/40960 [01:53<00:31, 241.58batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33447/40960 [01:53<00:31, 241.58batches/s, l2_loss: 0.0362 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|▊| 33484/40960 [01:54<00:33, 224.50batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33484/40960 [01:54<00:33, 224.50batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33527/40960 [01:54<00:33, 220.55batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33527/40960 [01:54<00:33, 220.55batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33568/40960 [01:54<00:34, 215.61batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33568/40960 [01:54<00:34, 215.61batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33631/40960 [01:54<00:29, 244.89batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33631/40960 [01:54<00:29, 244.89batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33691/40960 [01:54<00:28, 258.78batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  82%|▊| 33691/40960 [01:54<00:28, 258.78batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  82%|▊| 33753/40960 [01:55<00:26, 273.44batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  82%|▊| 33753/40960 [01:55<00:26, 273.44batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  83%|▊| 33805/40960 [01:55<00:26, 268.48batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  83%|▊| 33805/40960 [01:55<00:26, 268.48batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  83%|▊| 33847/40960 [01:55<00:28, 249.18batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  83%|▊| 33847/40960 [01:55<00:28, 249.18batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  83%|▊| 33891/40960 [01:55<00:29, 239.93batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  83%|▊| 33891/40960 [01:55<00:29, 239.93batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  83%|▊| 33955/40960 [01:55<00:26, 262.74batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  83%|▊| 33955/40960 [01:55<00:26, 262.74batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  83%|▊| 34008/40960 [01:56<00:26, 262.97batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  83%|▊| 34008/40960 [01:56<00:26, 262.97batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  83%|▊| 34051/40960 [01:56<00:27, 247.08batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  83%|▊| 34051/40960 [01:56<00:27, 247.08batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  83%|▊| 34093/40960 [01:56<00:29, 235.79batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  83%|▊| 34093/40960 [01:56<00:29, 235.79batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  83%|▊| 34156/40960 [01:56<00:26, 258.71batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  83%|▊| 34156/40960 [01:56<00:26, 258.71batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  84%|▊| 34215/40960 [01:56<00:25, 267.90batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  84%|▊| 34215/40960 [01:56<00:25, 267.90batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  84%|▊| 34281/40960 [01:57<00:23, 285.88batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  84%|▊| 34281/40960 [01:57<00:23, 285.88batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  84%|▊| 34345/40960 [01:57<00:22, 295.56batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  84%|▊| 34345/40960 [01:57<00:22, 295.56batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  84%|▊| 34411/40960 [01:57<00:21, 304.86batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  84%|▊| 34411/40960 [01:57<00:21, 304.86batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  84%|▊| 34476/40960 [01:57<00:20, 310.49batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  84%|▊| 34476/40960 [01:57<00:20, 310.49batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  84%|▊| 34540/40960 [01:57<00:20, 311.86batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  84%|▊| 34540/40960 [01:58<00:20, 311.86batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  84%|▊| 34597/40960 [01:58<00:20, 303.31batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  84%|▊| 34597/40960 [01:58<00:20, 303.31batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  85%|▊| 34655/40960 [01:58<00:21, 297.77batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  85%|▊| 34655/40960 [01:58<00:21, 297.77batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  85%|▊| 34720/40960 [01:58<00:20, 304.72batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  85%|▊| 34720/40960 [01:58<00:20, 304.72batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  85%|▊| 34786/40960 [01:58<00:19, 311.31batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  85%|▊| 34786/40960 [01:58<00:19, 311.31batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  85%|▊| 34849/40960 [01:59<00:19, 311.98batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  85%|▊| 34849/40960 [01:59<00:19, 311.98batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  85%|▊| 34913/40960 [01:59<00:19, 313.12batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  85%|▊| 34913/40960 [01:59<00:19, 313.12batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  85%|▊| 34978/40960 [01:59<00:18, 315.31batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  85%|▊| 34978/40960 [01:59<00:18, 315.31batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  86%|▊| 35036/40960 [01:59<00:19, 307.52batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  86%|▊| 35036/40960 [01:59<00:19, 307.52batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  86%|▊| 35102/40960 [01:59<00:18, 313.68batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  86%|▊| 35102/40960 [01:59<00:18, 313.68batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  86%|▊| 35166/40960 [02:00<00:18, 314.68batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  86%|▊| 35166/40960 [02:00<00:18, 314.68batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  86%|▊| 35222/40960 [02:00<00:18, 304.11batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  86%|▊| 35222/40960 [02:00<00:18, 304.11batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  86%|▊| 35274/40960 [02:00<00:19, 290.18batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  86%|▊| 35274/40960 [02:00<00:19, 290.18batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  86%|▊| 35319/40960 [02:00<00:21, 268.62batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  86%|▊| 35319/40960 [02:00<00:21, 268.62batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  86%|▊| 35378/40960 [02:00<00:20, 275.81batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  86%|▊| 35378/40960 [02:00<00:20, 275.81batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  87%|▊| 35443/40960 [02:01<00:19, 290.32batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  87%|▊| 35443/40960 [02:01<00:19, 290.32batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  87%|▊| 35506/40960 [02:01<00:18, 297.15batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  87%|▊| 35506/40960 [02:01<00:18, 297.15batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  87%|▊| 35569/40960 [02:01<00:17, 302.43batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  87%|▊| 35569/40960 [02:01<00:17, 302.43batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  87%|▊| 35630/40960 [02:01<00:17, 303.05batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  87%|▊| 35630/40960 [02:01<00:17, 303.05batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  87%|▊| 35695/40960 [02:01<00:17, 308.75batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  87%|▊| 35695/40960 [02:01<00:17, 308.75batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  87%|▊| 35757/40960 [02:02<00:16, 307.86batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  87%|▊| 35757/40960 [02:02<00:16, 307.86batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  87%|▊| 35815/40960 [02:02<00:17, 302.44batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  87%|▊| 35815/40960 [02:02<00:17, 302.44batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  88%|▉| 35877/40960 [02:02<00:16, 304.09batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  88%|▉| 35877/40960 [02:02<00:16, 304.09batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  88%|▉| 35936/40960 [02:02<00:16, 301.32batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  88%|▉| 35936/40960 [02:02<00:16, 301.32batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  88%|▉| 36002/40960 [02:02<00:16, 309.67batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  88%|▉| 36002/40960 [02:02<00:16, 309.67batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  88%|▉| 36065/40960 [02:03<00:15, 310.43batches/s, l2_loss: 0.0372 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|▉| 36065/40960 [02:03<00:15, 310.43batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  88%|▉| 36128/40960 [02:03<00:15, 311.39batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  88%|▉| 36128/40960 [02:03<00:15, 311.39batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  88%|▉| 36186/40960 [02:03<00:15, 303.56batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  88%|▉| 36186/40960 [02:03<00:15, 303.56batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  88%|▉| 36249/40960 [02:03<00:15, 306.65batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  88%|▉| 36249/40960 [02:03<00:15, 306.65batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  89%|▉| 36314/40960 [02:03<00:14, 311.37batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  89%|▉| 36314/40960 [02:03<00:14, 311.37batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  89%|▉| 36378/40960 [02:04<00:14, 313.80batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  89%|▉| 36378/40960 [02:04<00:14, 313.80batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  89%|▉| 36443/40960 [02:04<00:14, 317.00batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  89%|▉| 36443/40960 [02:04<00:14, 317.00batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  89%|▉| 36507/40960 [02:04<00:14, 317.53batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  89%|▉| 36507/40960 [02:04<00:14, 317.53batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  89%|▉| 36572/40960 [02:04<00:13, 319.75batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  89%|▉| 36572/40960 [02:04<00:13, 319.75batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  89%|▉| 36636/40960 [02:04<00:13, 319.38batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  89%|▉| 36636/40960 [02:04<00:13, 319.38batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  90%|▉| 36698/40960 [02:05<00:13, 315.90batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  90%|▉| 36698/40960 [02:05<00:13, 315.90batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  90%|▉| 36765/40960 [02:05<00:13, 321.33batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  90%|▉| 36765/40960 [02:05<00:13, 321.33batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  90%|▉| 36831/40960 [02:05<00:12, 322.62batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  90%|▉| 36831/40960 [02:05<00:12, 322.62batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  90%|▉| 36891/40960 [02:05<00:12, 314.40batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  90%|▉| 36891/40960 [02:05<00:12, 314.40batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  90%|▉| 36953/40960 [02:05<00:12, 312.94batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  90%|▉| 36953/40960 [02:05<00:12, 312.94batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  90%|▉| 37016/40960 [02:06<00:12, 313.55batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  90%|▉| 37016/40960 [02:06<00:12, 313.55batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  91%|▉| 37081/40960 [02:06<00:12, 316.86batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  91%|▉| 37081/40960 [02:06<00:12, 316.86batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  91%|▉| 37141/40960 [02:06<00:12, 310.88batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  91%|▉| 37141/40960 [02:06<00:12, 310.88batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  91%|▉| 37206/40960 [02:06<00:11, 313.88batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  91%|▉| 37206/40960 [02:06<00:11, 313.88batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  91%|▉| 37272/40960 [02:06<00:11, 317.86batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  91%|▉| 37272/40960 [02:06<00:11, 317.86batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  91%|▉| 37335/40960 [02:07<00:11, 315.87batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  91%|▉| 37335/40960 [02:07<00:11, 315.87batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  91%|▉| 37394/40960 [02:07<00:11, 307.97batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  91%|▉| 37394/40960 [02:07<00:11, 307.97batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  91%|▉| 37457/40960 [02:07<00:11, 308.68batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  91%|▉| 37457/40960 [02:07<00:11, 308.68batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  92%|▉| 37518/40960 [02:07<00:11, 306.45batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  92%|▉| 37518/40960 [02:07<00:11, 306.45batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  92%|▉| 37582/40960 [02:07<00:10, 309.82batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  92%|▉| 37582/40960 [02:07<00:10, 309.82batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  92%|▉| 37644/40960 [02:08<00:10, 309.69batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  92%|▉| 37644/40960 [02:08<00:10, 309.69batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  92%|▉| 37707/40960 [02:08<00:10, 310.70batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  92%|▉| 37707/40960 [02:08<00:10, 310.70batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  92%|▉| 37773/40960 [02:08<00:10, 314.99batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  92%|▉| 37773/40960 [02:08<00:10, 314.99batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  92%|▉| 37834/40960 [02:08<00:10, 311.82batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  92%|▉| 37834/40960 [02:08<00:10, 311.82batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  93%|▉| 37899/40960 [02:08<00:09, 315.51batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  93%|▉| 37899/40960 [02:08<00:09, 315.51batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  93%|▉| 37965/40960 [02:09<00:09, 319.21batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  93%|▉| 37965/40960 [02:09<00:09, 319.21batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  93%|▉| 38029/40960 [02:09<00:09, 318.72batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  93%|▉| 38029/40960 [02:09<00:09, 318.72batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  93%|▉| 38094/40960 [02:09<00:08, 319.98batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  93%|▉| 38094/40960 [02:09<00:08, 319.98batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  93%|▉| 38158/40960 [02:09<00:08, 318.32batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  93%|▉| 38158/40960 [02:09<00:08, 318.32batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  93%|▉| 38224/40960 [02:09<00:08, 321.38batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  93%|▉| 38224/40960 [02:09<00:08, 321.38batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  93%|▉| 38288/40960 [02:10<00:08, 320.08batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  93%|▉| 38288/40960 [02:10<00:08, 320.08batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  94%|▉| 38353/40960 [02:10<00:08, 320.33batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  94%|▉| 38353/40960 [02:10<00:08, 320.33batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  94%|▉| 38418/40960 [02:10<00:07, 320.20batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  94%|▉| 38418/40960 [02:10<00:07, 320.20batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  94%|▉| 38480/40960 [02:10<00:07, 316.58batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  94%|▉| 38480/40960 [02:10<00:07, 316.58batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  94%|▉| 38542/40960 [02:10<00:07, 313.37batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  94%|▉| 38542/40960 [02:10<00:07, 313.37batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  94%|▉| 38604/40960 [02:11<00:07, 311.71batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  94%|▉| 38604/40960 [02:11<00:07, 311.71batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  94%|▉| 38668/40960 [02:11<00:07, 313.78batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  94%|▉| 38668/40960 [02:11<00:07, 313.78batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  95%|▉| 38731/40960 [02:11<00:07, 314.10batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  95%|▉| 38731/40960 [02:11<00:07, 314.10batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  95%|▉| 38793/40960 [02:11<00:06, 312.43batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  95%|▉| 38793/40960 [02:11<00:06, 312.43batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  95%|▉| 38848/40960 [02:11<00:07, 301.09batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  95%|▉| 38848/40960 [02:11<00:07, 301.09batches/s, l2_loss: 0.0387 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 38914/40960 [02:12<00:06, 309.44batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  95%|▉| 38914/40960 [02:12<00:06, 309.44batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  95%|▉| 38975/40960 [02:12<00:06, 306.95batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  95%|▉| 38975/40960 [02:12<00:06, 306.95batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  95%|▉| 39035/40960 [02:12<00:06, 304.36batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  95%|▉| 39035/40960 [02:12<00:06, 304.36batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  95%|▉| 39097/40960 [02:12<00:06, 305.35batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  95%|▉| 39097/40960 [02:12<00:06, 305.35batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  96%|▉| 39160/40960 [02:12<00:05, 307.27batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  96%|▉| 39160/40960 [02:12<00:05, 307.27batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  96%|▉| 39227/40960 [02:13<00:05, 314.38batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  96%|▉| 39227/40960 [02:13<00:05, 314.38batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  96%|▉| 39292/40960 [02:13<00:05, 317.00batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  96%|▉| 39292/40960 [02:13<00:05, 317.00batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  96%|▉| 39357/40960 [02:13<00:05, 319.38batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  96%|▉| 39357/40960 [02:13<00:05, 319.38batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  96%|▉| 39403/40960 [02:13<00:05, 291.45batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  96%|▉| 39403/40960 [02:13<00:05, 291.45batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  96%|▉| 39442/40960 [02:13<00:05, 261.57batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  96%|▉| 39442/40960 [02:13<00:05, 261.57batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  96%|▉| 39493/40960 [02:14<00:05, 258.79batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  96%|▉| 39493/40960 [02:14<00:05, 258.79batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  97%|▉| 39547/40960 [02:14<00:05, 261.71batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  97%|▉| 39547/40960 [02:14<00:05, 261.71batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  97%|▉| 39611/40960 [02:14<00:04, 279.08batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  97%|▉| 39611/40960 [02:14<00:04, 279.08batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39676/40960 [02:14<00:04, 291.88batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39676/40960 [02:14<00:04, 291.88batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39738/40960 [02:14<00:04, 296.85batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39738/40960 [02:14<00:04, 296.85batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39800/40960 [02:15<00:03, 300.44batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39800/40960 [02:15<00:03, 300.44batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  97%|▉| 39842/40960 [02:15<00:04, 272.93batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  97%|▉| 39842/40960 [02:15<00:04, 272.93batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  97%|▉| 39887/40960 [02:15<00:04, 257.70batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  97%|▉| 39887/40960 [02:15<00:04, 257.70batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  97%|▉| 39925/40960 [02:15<00:04, 237.16batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  97%|▉| 39925/40960 [02:15<00:04, 237.16batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 39976/40960 [02:15<00:04, 242.24batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 39976/40960 [02:15<00:04, 242.24batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40016/40960 [02:16<00:04, 228.96batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40016/40960 [02:16<00:04, 228.96batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40056/40960 [02:16<00:04, 219.65batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40056/40960 [02:16<00:04, 219.65batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40109/40960 [02:16<00:03, 232.69batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40109/40960 [02:16<00:03, 232.69batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40160/40960 [02:16<00:03, 238.42batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40160/40960 [02:16<00:03, 238.42batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training:  98%|▉| 40224/40960 [02:16<00:02, 262.29batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training:  98%|▉| 40224/40960 [02:16<00:02, 262.29batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training:  98%|▉| 40288/40960 [02:17<00:02, 278.66batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training:  98%|▉| 40288/40960 [02:17<00:02, 278.66batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training:  98%|▉| 40331/40960 [02:17<00:02, 258.91batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training:  98%|▉| 40331/40960 [02:17<00:02, 258.91batches/s, l2_loss: 0.0396 - round_los\u001b[A\n",
      "Training:  99%|▉| 40371/40960 [02:17<00:02, 240.38batches/s, l2_loss: 0.0396 - round_los\u001b[A\n",
      "Training:  99%|▉| 40371/40960 [02:17<00:02, 240.38batches/s, l2_loss: 0.0396 - round_los\u001b[A\n",
      "Training:  99%|▉| 40409/40960 [02:17<00:02, 224.79batches/s, l2_loss: 0.0396 - round_los\u001b[A\n",
      "Training:  99%|▉| 40409/40960 [02:17<00:02, 224.79batches/s, l2_loss: 0.0396 - round_los\u001b[A\n",
      "Training:  99%|▉| 40446/40960 [02:17<00:02, 212.67batches/s, l2_loss: 0.0396 - round_los\u001b[A\n",
      "Training:  99%|▉| 40446/40960 [02:17<00:02, 212.67batches/s, l2_loss: 0.0396 - round_los\u001b[A\n",
      "Training:  99%|▉| 40504/40960 [02:18<00:01, 234.25batches/s, l2_loss: 0.0396 - round_los\u001b[A\n",
      "Training:  99%|▉| 40504/40960 [02:18<00:01, 234.25batches/s, l2_loss: 0.0397 - round_los\u001b[A\n",
      "Training:  99%|▉| 40543/40960 [02:18<00:01, 221.31batches/s, l2_loss: 0.0397 - round_los\u001b[A\n",
      "Training:  99%|▉| 40543/40960 [02:18<00:01, 221.31batches/s, l2_loss: 0.0397 - round_los\u001b[A\n",
      "Training:  99%|▉| 40594/40960 [02:18<00:01, 230.55batches/s, l2_loss: 0.0397 - round_los\u001b[A\n",
      "Training:  99%|▉| 40594/40960 [02:18<00:01, 230.55batches/s, l2_loss: 0.0397 - round_los\u001b[A\n",
      "Training:  99%|▉| 40647/40960 [02:18<00:01, 240.24batches/s, l2_loss: 0.0397 - round_los\u001b[A\n",
      "Training:  99%|▉| 40647/40960 [02:18<00:01, 240.24batches/s, l2_loss: 0.0397 - round_los\u001b[A\n",
      "Training:  99%|▉| 40708/40960 [02:18<00:00, 258.54batches/s, l2_loss: 0.0397 - round_los\u001b[A\n",
      "Training:  99%|▉| 40708/40960 [02:18<00:00, 258.54batches/s, l2_loss: 0.0398 - round_los\u001b[A\n",
      "Training: 100%|▉| 40768/40960 [02:19<00:00, 269.77batches/s, l2_loss: 0.0398 - round_los\u001b[A\n",
      "Training: 100%|▉| 40768/40960 [02:19<00:00, 269.77batches/s, l2_loss: 0.0398 - round_los\u001b[A\n",
      "Training: 100%|▉| 40808/40960 [02:19<00:00, 247.87batches/s, l2_loss: 0.0398 - round_los\u001b[A\n",
      "Training: 100%|▉| 40808/40960 [02:19<00:00, 247.87batches/s, l2_loss: 0.0398 - round_los\u001b[A\n",
      "Training: 100%|▉| 40847/40960 [02:19<00:00, 230.86batches/s, l2_loss: 0.0398 - round_los\u001b[A\n",
      "Training: 100%|▉| 40847/40960 [02:19<00:00, 230.86batches/s, l2_loss: 0.0398 - round_los\u001b[A\n",
      "Training: 100%|▉| 40888/40960 [02:19<00:00, 222.63batches/s, l2_loss: 0.0398 - round_los\u001b[A\n",
      "Training: 100%|▉| 40888/40960 [02:19<00:00, 222.63batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "Training: 100%|▉| 40938/40960 [02:19<00:00, 229.12batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "Training: 100%|▉| 40938/40960 [02:19<00:00, 229.12batches/s, l2_loss: 0.0399 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:01:09.883425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  27%|▎| 7/26 [13:31<39:20, 124.24s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 15:01:13.058183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:01:16.126660: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<11:37:43,  1.02s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<11:37:43,  1.02s/batches, l2_loss: 0.0497 - round_loss:\u001b[A\n",
      "Training:   0%| | 74/40960 [00:01<08:28, 80.37batches/s, l2_loss: 0.0497 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 74/40960 [00:01<08:28, 80.37batches/s, l2_loss: 0.0474 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 130/40960 [00:01<05:20, 127.51batches/s, l2_loss: 0.0474 - round_loss:\u001b[A\n",
      "Training:   0%| | 130/40960 [00:01<05:20, 127.51batches/s, l2_loss: 0.0470 - round_loss:\u001b[A\n",
      "Training:   1%| | 218/40960 [00:01<03:17, 206.50batches/s, l2_loss: 0.0470 - round_loss:\u001b[A\n",
      "Training:   1%| | 218/40960 [00:01<03:17, 206.50batches/s, l2_loss: 0.0459 - round_loss:\u001b[A\n",
      "Training:   1%| | 284/40960 [00:01<02:50, 238.73batches/s, l2_loss: 0.0459 - round_loss:\u001b[A\n",
      "Training:   1%| | 284/40960 [00:01<02:50, 238.73batches/s, l2_loss: 0.0462 - round_loss:\u001b[A\n",
      "Training:   1%| | 345/40960 [00:02<02:38, 256.76batches/s, l2_loss: 0.0462 - round_loss:\u001b[A\n",
      "Training:   1%| | 345/40960 [00:02<02:38, 256.76batches/s, l2_loss: 0.0455 - round_loss:\u001b[A\n",
      "Training:   1%| | 439/40960 [00:02<02:08, 316.42batches/s, l2_loss: 0.0455 - round_loss:\u001b[A\n",
      "Training:   1%| | 439/40960 [00:02<02:08, 316.42batches/s, l2_loss: 0.0448 - round_loss:\u001b[A\n",
      "Training:   1%| | 509/40960 [00:02<02:04, 325.70batches/s, l2_loss: 0.0448 - round_loss:\u001b[A\n",
      "Training:   1%| | 509/40960 [00:02<02:04, 325.70batches/s, l2_loss: 0.0444 - round_loss:\u001b[A\n",
      "Training:   1%| | 586/40960 [00:02<01:58, 341.96batches/s, l2_loss: 0.0444 - round_loss:\u001b[A\n",
      "Training:   1%| | 586/40960 [00:02<01:58, 341.96batches/s, l2_loss: 0.0440 - round_loss:\u001b[A\n",
      "Training:   2%| | 660/40960 [00:02<01:55, 349.36batches/s, l2_loss: 0.0440 - round_loss:\u001b[A\n",
      "Training:   2%| | 660/40960 [00:02<01:55, 349.36batches/s, l2_loss: 0.0436 - round_loss:\u001b[A\n",
      "Training:   2%| | 732/40960 [00:03<01:54, 351.50batches/s, l2_loss: 0.0436 - round_loss:\u001b[A\n",
      "Training:   2%| | 732/40960 [00:03<01:54, 351.50batches/s, l2_loss: 0.0433 - round_loss:\u001b[A\n",
      "Training:   2%| | 822/40960 [00:03<01:45, 379.46batches/s, l2_loss: 0.0433 - round_loss:\u001b[A\n",
      "Training:   2%| | 822/40960 [00:03<01:45, 379.46batches/s, l2_loss: 0.0429 - round_loss:\u001b[A\n",
      "Training:   2%| | 914/40960 [00:03<01:39, 403.04batches/s, l2_loss: 0.0429 - round_loss:\u001b[A\n",
      "Training:   2%| | 914/40960 [00:03<01:39, 403.04batches/s, l2_loss: 0.0425 - round_loss:\u001b[A\n",
      "Training:   2%| | 1007/40960 [00:03<01:34, 421.40batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:   2%| | 1007/40960 [00:03<01:34, 421.40batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:   3%| | 1100/40960 [00:03<01:31, 434.33batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:   3%| | 1100/40960 [00:03<01:31, 434.33batches/s, l2_loss: 0.0419 - round_loss\u001b[A\n",
      "Training:   3%| | 1194/40960 [00:04<01:29, 443.66batches/s, l2_loss: 0.0419 - round_loss\u001b[A\n",
      "Training:   3%| | 1194/40960 [00:04<01:29, 443.66batches/s, l2_loss: 0.0417 - round_loss\u001b[A\n",
      "Training:   3%| | 1288/40960 [00:04<01:27, 451.43batches/s, l2_loss: 0.0417 - round_loss\u001b[A\n",
      "Training:   3%| | 1288/40960 [00:04<01:27, 451.43batches/s, l2_loss: 0.0415 - round_loss\u001b[A\n",
      "Training:   3%| | 1381/40960 [00:04<01:27, 454.15batches/s, l2_loss: 0.0415 - round_loss\u001b[A\n",
      "Training:   3%| | 1381/40960 [00:04<01:27, 454.15batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:   4%| | 1473/40960 [00:04<01:26, 454.54batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:   4%| | 1473/40960 [00:04<01:26, 454.54batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:   4%| | 1567/40960 [00:04<01:25, 458.41batches/s, l2_loss: 0.0411 - round_loss\u001b[A\n",
      "Training:   4%| | 1567/40960 [00:04<01:25, 458.41batches/s, l2_loss: 0.0409 - round_loss\u001b[A\n",
      "Training:   4%| | 1655/40960 [00:05<01:26, 452.38batches/s, l2_loss: 0.0409 - round_loss\u001b[A\n",
      "Training:   4%| | 1655/40960 [00:05<01:26, 452.38batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:   4%| | 1749/40960 [00:05<01:25, 456.27batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:   4%| | 1749/40960 [00:05<01:25, 456.27batches/s, l2_loss: 0.0406 - round_loss\u001b[A\n",
      "Training:   4%| | 1838/40960 [00:05<01:26, 452.46batches/s, l2_loss: 0.0406 - round_loss\u001b[A\n",
      "Training:   4%| | 1838/40960 [00:05<01:26, 452.46batches/s, l2_loss: 0.0405 - round_loss\u001b[A\n",
      "Training:   5%| | 1906/40960 [00:05<01:33, 418.51batches/s, l2_loss: 0.0405 - round_loss\u001b[A\n",
      "Training:   5%| | 1906/40960 [00:05<01:33, 418.51batches/s, l2_loss: 0.0403 - round_loss\u001b[A\n",
      "Training:   5%| | 1987/40960 [00:05<01:34, 414.25batches/s, l2_loss: 0.0403 - round_loss\u001b[A\n",
      "Training:   5%| | 1987/40960 [00:05<01:34, 414.25batches/s, l2_loss: 0.0402 - round_loss\u001b[A\n",
      "Training:   5%| | 2077/40960 [00:06<01:31, 424.18batches/s, l2_loss: 0.0402 - round_loss\u001b[A\n",
      "Training:   5%| | 2077/40960 [00:06<01:31, 424.18batches/s, l2_loss: 0.0400 - round_loss\u001b[A\n",
      "Training:   5%| | 2162/40960 [00:06<01:31, 423.15batches/s, l2_loss: 0.0400 - round_loss\u001b[A\n",
      "Training:   5%| | 2162/40960 [00:06<01:31, 423.15batches/s, l2_loss: 0.0400 - round_loss\u001b[A\n",
      "Training:   5%| | 2220/40960 [00:06<01:41, 382.87batches/s, l2_loss: 0.0400 - round_loss\u001b[A\n",
      "Training:   5%| | 2220/40960 [00:06<01:41, 382.87batches/s, l2_loss: 0.0398 - round_loss\u001b[A\n",
      "Training:   6%| | 2297/40960 [00:06<01:41, 382.05batches/s, l2_loss: 0.0398 - round_loss\u001b[A\n",
      "Training:   6%| | 2297/40960 [00:06<01:41, 382.05batches/s, l2_loss: 0.0398 - round_loss\u001b[A\n",
      "Training:   6%| | 2362/40960 [00:06<01:46, 364.08batches/s, l2_loss: 0.0398 - round_loss\u001b[A\n",
      "Training:   6%| | 2362/40960 [00:06<01:46, 364.08batches/s, l2_loss: 0.0397 - round_loss\u001b[A\n",
      "Training:   6%| | 2456/40960 [00:07<01:37, 394.58batches/s, l2_loss: 0.0397 - round_loss\u001b[A\n",
      "Training:   6%| | 2456/40960 [00:07<01:37, 394.58batches/s, l2_loss: 0.0396 - round_loss\u001b[A\n",
      "Training:   6%| | 2512/40960 [00:07<01:47, 358.41batches/s, l2_loss: 0.0396 - round_loss\u001b[A\n",
      "Training:   6%| | 2512/40960 [00:07<01:47, 358.41batches/s, l2_loss: 0.0395 - round_loss\u001b[A\n",
      "Training:   6%| | 2594/40960 [00:07<01:42, 373.01batches/s, l2_loss: 0.0395 - round_loss\u001b[A\n",
      "Training:   6%| | 2594/40960 [00:07<01:42, 373.01batches/s, l2_loss: 0.0394 - round_loss\u001b[A\n",
      "Training:   6%| | 2648/40960 [00:07<01:52, 341.98batches/s, l2_loss: 0.0394 - round_loss\u001b[A\n",
      "Training:   6%| | 2648/40960 [00:07<01:52, 341.98batches/s, l2_loss: 0.0394 - round_loss\u001b[A\n",
      "Training:   7%| | 2728/40960 [00:07<01:46, 359.19batches/s, l2_loss: 0.0394 - round_loss\u001b[A\n",
      "Training:   7%| | 2728/40960 [00:07<01:46, 359.19batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:   7%| | 2779/40960 [00:08<01:56, 327.91batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:   7%| | 2779/40960 [00:08<01:56, 327.91batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:   7%| | 2863/40960 [00:08<01:47, 355.07batches/s, l2_loss: 0.0393 - round_loss\u001b[A\n",
      "Training:   7%| | 2863/40960 [00:08<01:47, 355.07batches/s, l2_loss: 0.0392 - round_loss\u001b[A\n",
      "Training:   7%| | 2940/40960 [00:08<01:45, 361.94batches/s, l2_loss: 0.0392 - round_loss\u001b[A\n",
      "Training:   7%| | 2940/40960 [00:08<01:45, 361.94batches/s, l2_loss: 0.0391 - round_loss\u001b[A\n",
      "Training:   7%| | 3011/40960 [00:08<01:45, 358.84batches/s, l2_loss: 0.0391 - round_loss\u001b[A\n",
      "Training:   7%| | 3011/40960 [00:08<01:45, 358.84batches/s, l2_loss: 0.0391 - round_loss\u001b[A\n",
      "Training:   8%| | 3084/40960 [00:08<01:45, 359.53batches/s, l2_loss: 0.0391 - round_loss\u001b[A\n",
      "Training:   8%| | 3084/40960 [00:08<01:45, 359.53batches/s, l2_loss: 0.0390 - round_loss\u001b[A\n",
      "Training:   8%| | 3139/40960 [00:09<01:53, 334.26batches/s, l2_loss: 0.0390 - round_loss\u001b[A\n",
      "Training:   8%| | 3139/40960 [00:09<01:53, 334.26batches/s, l2_loss: 0.0389 - round_loss\u001b[A\n",
      "Training:   8%| | 3193/40960 [00:09<02:00, 313.89batches/s, l2_loss: 0.0389 - round_loss\u001b[A\n",
      "Training:   8%| | 3193/40960 [00:09<02:00, 313.89batches/s, l2_loss: 0.0389 - round_loss\u001b[A\n",
      "Training:   8%| | 3253/40960 [00:09<02:01, 309.24batches/s, l2_loss: 0.0389 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3253/40960 [00:09<02:01, 309.24batches/s, l2_loss: 0.0388 - round_loss\u001b[A\n",
      "Training:   8%| | 3306/40960 [00:09<02:07, 294.98batches/s, l2_loss: 0.0388 - round_loss\u001b[A\n",
      "Training:   8%| | 3306/40960 [00:09<02:07, 294.98batches/s, l2_loss: 0.0388 - round_loss\u001b[A\n",
      "Training:   8%| | 3366/40960 [00:09<02:06, 296.33batches/s, l2_loss: 0.0388 - round_loss\u001b[A\n",
      "Training:   8%| | 3366/40960 [00:09<02:06, 296.33batches/s, l2_loss: 0.0388 - round_loss\u001b[A\n",
      "Training:   8%| | 3460/40960 [00:10<01:47, 347.47batches/s, l2_loss: 0.0388 - round_loss\u001b[A\n",
      "Training:   8%| | 3460/40960 [00:10<01:47, 347.47batches/s, l2_loss: 0.0387 - round_loss\u001b[A\n",
      "Training:   9%| | 3530/40960 [00:10<01:47, 346.96batches/s, l2_loss: 0.0387 - round_loss\u001b[A\n",
      "Training:   9%| | 3530/40960 [00:10<01:47, 346.96batches/s, l2_loss: 0.0386 - round_loss\u001b[A\n",
      "Training:   9%| | 3589/40960 [00:10<01:52, 331.01batches/s, l2_loss: 0.0386 - round_loss\u001b[A\n",
      "Training:   9%| | 3589/40960 [00:10<01:52, 331.01batches/s, l2_loss: 0.0386 - round_loss\u001b[A\n",
      "Training:   9%| | 3659/40960 [00:10<01:51, 335.77batches/s, l2_loss: 0.0386 - round_loss\u001b[A\n",
      "Training:   9%| | 3659/40960 [00:10<01:51, 335.77batches/s, l2_loss: 0.0386 - round_loss\u001b[A\n",
      "Training:   9%| | 3717/40960 [00:10<01:55, 321.34batches/s, l2_loss: 0.0386 - round_loss\u001b[A\n",
      "Training:   9%| | 3717/40960 [00:10<01:55, 321.34batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:   9%| | 3785/40960 [00:11<01:54, 325.72batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:   9%| | 3785/40960 [00:11<01:54, 325.72batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:   9%| | 3844/40960 [00:11<01:57, 315.14batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:   9%| | 3844/40960 [00:11<01:57, 315.14batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:  10%| | 3918/40960 [00:11<01:51, 330.93batches/s, l2_loss: 0.0385 - round_loss\u001b[A\n",
      "Training:  10%| | 3918/40960 [00:11<01:51, 330.93batches/s, l2_loss: 0.0384 - round_loss\u001b[A\n",
      "Training:  10%| | 4010/40960 [00:11<01:40, 369.15batches/s, l2_loss: 0.0384 - round_loss\u001b[A\n",
      "Training:  10%| | 4010/40960 [00:11<01:40, 369.15batches/s, l2_loss: 0.0384 - round_loss\u001b[A\n",
      "Training:  10%| | 4103/40960 [00:11<01:32, 396.71batches/s, l2_loss: 0.0384 - round_loss\u001b[A\n",
      "Training:  10%| | 4103/40960 [00:11<01:32, 396.71batches/s, l2_loss: 0.0383 - round_loss\u001b[A\n",
      "Training:  10%| | 4194/40960 [00:12<01:28, 413.83batches/s, l2_loss: 0.0383 - round_loss\u001b[A\n",
      "Training:  10%| | 4194/40960 [00:12<01:28, 413.83batches/s, l2_loss: 0.0383 - round_loss\u001b[A\n",
      "Training:  10%| | 4260/40960 [00:12<01:34, 388.03batches/s, l2_loss: 0.0383 - round_loss\u001b[A\n",
      "Training:  10%| | 4260/40960 [00:12<01:34, 388.03batches/s, l2_loss: 0.0382 - round_loss\u001b[A\n",
      "Training:  11%| | 4324/40960 [00:12<01:39, 366.86batches/s, l2_loss: 0.0382 - round_loss\u001b[A\n",
      "Training:  11%| | 4324/40960 [00:12<01:39, 366.86batches/s, l2_loss: 0.0382 - round_loss\u001b[A\n",
      "Training:  11%| | 4419/40960 [00:12<01:31, 398.32batches/s, l2_loss: 0.0382 - round_loss\u001b[A\n",
      "Training:  11%| | 4419/40960 [00:12<01:31, 398.32batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  11%| | 4511/40960 [00:12<01:27, 415.96batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  11%| | 4511/40960 [00:12<01:27, 415.96batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  11%| | 4601/40960 [00:13<01:25, 426.12batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  11%| | 4601/40960 [00:13<01:25, 426.12batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  11%| | 4693/40960 [00:13<01:23, 435.59batches/s, l2_loss: 0.0381 - round_loss\u001b[A\n",
      "Training:  11%| | 4693/40960 [00:13<01:23, 435.59batches/s, l2_loss: 0.0380 - round_loss\u001b[A\n",
      "Training:  12%| | 4787/40960 [00:13<01:21, 445.05batches/s, l2_loss: 0.0380 - round_loss\u001b[A\n",
      "Training:  12%| | 4787/40960 [00:13<01:21, 445.05batches/s, l2_loss: 0.0380 - round_loss\u001b[A\n",
      "Training:  12%| | 4875/40960 [00:13<01:21, 441.97batches/s, l2_loss: 0.0380 - round_loss\u001b[A\n",
      "Training:  12%| | 4875/40960 [00:13<01:21, 441.97batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  12%| | 4930/40960 [00:13<01:32, 390.88batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  12%| | 4930/40960 [00:13<01:32, 390.88batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  12%| | 4979/40960 [00:14<01:43, 346.34batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  12%| | 4979/40960 [00:14<01:43, 346.34batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  12%| | 5065/40960 [00:14<01:36, 370.94batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  12%| | 5065/40960 [00:14<01:36, 370.94batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5139/40960 [00:14<01:36, 370.52batches/s, l2_loss: 0.0379 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5139/40960 [00:14<01:36, 370.52batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5202/40960 [00:14<01:41, 353.16batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5202/40960 [00:14<01:41, 353.16batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5290/40960 [00:14<01:34, 379.09batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5290/40960 [00:14<01:34, 379.09batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5380/40960 [00:15<01:28, 399.99batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5380/40960 [00:15<01:28, 399.99batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5469/40960 [00:15<01:26, 412.24batches/s, l2_loss: 0.0378 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5469/40960 [00:15<01:26, 412.24batches/s, l2_loss: 0.0377 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5560/40960 [00:15<01:23, 424.76batches/s, l2_loss: 0.0377 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5560/40960 [00:15<01:23, 424.76batches/s, l2_loss: 0.0377 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5654/40960 [00:15<01:20, 437.14batches/s, l2_loss: 0.0377 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5654/40960 [00:15<01:20, 437.14batches/s, l2_loss: 0.0377 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5745/40960 [00:15<01:19, 441.61batches/s, l2_loss: 0.0377 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5745/40960 [00:15<01:19, 441.61batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5839/40960 [00:16<01:18, 450.01batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5839/40960 [00:16<01:18, 450.01batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5931/40960 [00:16<01:17, 452.51batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5931/40960 [00:16<01:17, 452.51batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6024/40960 [00:16<01:16, 455.33batches/s, l2_loss: 0.0376 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6024/40960 [00:16<01:16, 455.33batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6098/40960 [00:16<01:21, 427.83batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6098/40960 [00:16<01:21, 427.83batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6152/40960 [00:16<01:31, 378.92batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6152/40960 [00:16<01:31, 378.92batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6211/40960 [00:17<01:38, 353.35batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6211/40960 [00:17<01:38, 353.35batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6266/40960 [00:17<01:45, 329.29batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6266/40960 [00:17<01:45, 329.29batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6324/40960 [00:17<01:49, 317.38batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6324/40960 [00:17<01:49, 317.38batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6374/40960 [00:17<01:56, 296.49batches/s, l2_loss: 0.0375 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6374/40960 [00:17<01:56, 296.49batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6453/40960 [00:17<01:45, 325.77batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6453/40960 [00:17<01:45, 325.77batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6531/40960 [00:18<01:39, 344.73batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6531/40960 [00:18<01:39, 344.73batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6609/40960 [00:18<01:36, 357.22batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6609/40960 [00:18<01:36, 357.22batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|▏| 6674/40960 [00:18<01:38, 346.91batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6674/40960 [00:18<01:38, 346.91batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6730/40960 [00:18<01:45, 324.94batches/s, l2_loss: 0.0374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6730/40960 [00:18<01:45, 324.94batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6806/40960 [00:18<01:40, 341.19batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6806/40960 [00:18<01:40, 341.19batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6900/40960 [00:19<01:29, 379.42batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6900/40960 [00:19<01:29, 379.42batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6994/40960 [00:19<01:23, 406.35batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6994/40960 [00:19<01:23, 406.35batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7086/40960 [00:19<01:20, 421.12batches/s, l2_loss: 0.0373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7086/40960 [00:19<01:20, 421.12batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7178/40960 [00:19<01:18, 432.63batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7178/40960 [00:19<01:18, 432.63batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7270/40960 [00:19<01:16, 439.91batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7270/40960 [00:19<01:16, 439.91batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7363/40960 [00:20<01:15, 447.23batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7363/40960 [00:20<01:15, 447.23batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7453/40960 [00:20<01:14, 447.73batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7453/40960 [00:20<01:14, 447.73batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7549/40960 [00:20<01:13, 456.53batches/s, l2_loss: 0.0372 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7549/40960 [00:20<01:13, 456.53batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7637/40960 [00:20<01:13, 450.95batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7637/40960 [00:20<01:13, 450.95batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7730/40960 [00:20<01:13, 453.67batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7730/40960 [00:20<01:13, 453.67batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7818/40960 [00:21<01:13, 448.94batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7818/40960 [00:21<01:13, 448.94batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7910/40960 [00:21<01:13, 451.68batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7910/40960 [00:21<01:13, 451.68batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8000/40960 [00:21<01:13, 450.26batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8000/40960 [00:21<01:13, 450.26batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8088/40960 [00:21<01:13, 447.04batches/s, l2_loss: 0.0371 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8088/40960 [00:21<01:13, 447.04batches/s, l2_loss: 0.0370 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8178/40960 [00:21<01:13, 447.29batches/s, l2_loss: 0.0370 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8178/40960 [00:21<01:13, 447.29batches/s, l2_loss: 0.0370 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8257/40960 [00:22<01:15, 431.32batches/s, l2_loss: 0.0370 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8257/40960 [00:22<01:15, 431.32batches/s, l2_loss: 0.0360 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8337/40960 [00:22<01:17, 421.12batches/s, l2_loss: 0.0360 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8337/40960 [00:22<01:17, 421.12batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8420/40960 [00:22<01:17, 418.21batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8420/40960 [00:22<01:17, 418.21batches/s, l2_loss: 0.0360 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8497/40960 [00:22<01:19, 407.46batches/s, l2_loss: 0.0360 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8497/40960 [00:22<01:19, 407.46batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8577/40960 [00:22<01:20, 404.36batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8577/40960 [00:22<01:20, 404.36batches/s, l2_loss: 0.0360 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8660/40960 [00:23<01:19, 406.79batches/s, l2_loss: 0.0360 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8660/40960 [00:23<01:19, 406.79batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8744/40960 [00:23<01:18, 410.07batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8744/40960 [00:23<01:18, 410.07batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8827/40960 [00:23<01:18, 410.84batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8827/40960 [00:23<01:18, 410.84batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8911/40960 [00:23<01:17, 412.43batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8911/40960 [00:23<01:17, 412.43batches/s, l2_loss: 0.0360 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8960/40960 [00:23<01:28, 361.47batches/s, l2_loss: 0.0360 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8960/40960 [00:23<01:28, 361.47batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9023/40960 [00:24<01:32, 347.07batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9023/40960 [00:24<01:32, 347.07batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9105/40960 [00:24<01:27, 365.84batches/s, l2_loss: 0.0361 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9105/40960 [00:24<01:27, 365.84batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9185/40960 [00:24<01:24, 374.80batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9185/40960 [00:24<01:24, 374.80batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9264/40960 [00:24<01:23, 380.06batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9264/40960 [00:24<01:23, 380.06batches/s, l2_loss: 0.0363 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9344/40960 [00:24<01:22, 384.72batches/s, l2_loss: 0.0363 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9344/40960 [00:24<01:22, 384.72batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9427/40960 [00:25<01:20, 393.08batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9427/40960 [00:25<01:20, 393.08batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9509/40960 [00:25<01:19, 397.56batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9509/40960 [00:25<01:19, 397.56batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9589/40960 [00:25<01:18, 397.52batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9589/40960 [00:25<01:18, 397.52batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9671/40960 [00:25<01:18, 400.66batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9671/40960 [00:25<01:18, 400.66batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9750/40960 [00:25<01:18, 398.08batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9750/40960 [00:25<01:18, 398.08batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9808/40960 [00:26<01:25, 365.79batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9808/40960 [00:26<01:25, 365.79batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9852/40960 [00:26<01:36, 321.30batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9852/40960 [00:26<01:36, 321.30batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9904/40960 [00:26<01:43, 300.16batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9904/40960 [00:26<01:43, 300.16batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9987/40960 [00:26<01:32, 333.99batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9987/40960 [00:26<01:32, 333.99batches/s, l2_loss: 0.0362 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10061/40960 [00:26<01:29, 344.05batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▏| 10061/40960 [00:26<01:29, 344.05batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▏| 10121/40960 [00:27<01:33, 330.05batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▏| 10121/40960 [00:27<01:33, 330.05batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▏| 10174/40960 [00:27<01:39, 310.20batches/s, l2_loss: 0.0362 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▏| 10174/40960 [00:27<01:39, 310.20batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  25%|▏| 10238/40960 [00:27<01:38, 312.35batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  25%|▏| 10238/40960 [00:27<01:38, 312.35batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▎| 10311/40960 [00:27<01:33, 326.60batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▎| 10311/40960 [00:27<01:33, 326.60batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▎| 10381/40960 [00:28<01:31, 332.86batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▎| 10381/40960 [00:28<01:31, 332.86batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▎| 10434/40960 [00:28<01:37, 312.05batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  25%|▎| 10434/40960 [00:28<01:37, 312.05batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10486/40960 [00:28<01:43, 295.32batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10486/40960 [00:28<01:43, 295.32batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10541/40960 [00:28<01:45, 288.64batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10541/40960 [00:28<01:45, 288.64batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10591/40960 [00:28<01:49, 276.14batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10591/40960 [00:28<01:49, 276.14batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10640/40960 [00:29<01:53, 266.16batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10640/40960 [00:29<01:53, 266.16batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10692/40960 [00:29<01:54, 263.79batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10692/40960 [00:29<01:54, 263.79batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10771/40960 [00:29<01:39, 302.28batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10771/40960 [00:29<01:39, 302.28batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10827/40960 [00:29<01:41, 295.64batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  26%|▎| 10827/40960 [00:29<01:41, 295.64batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 10903/40960 [00:29<01:33, 320.74batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 10903/40960 [00:29<01:33, 320.74batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 10986/40960 [00:30<01:26, 348.26batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 10986/40960 [00:30<01:26, 348.26batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 11070/40960 [00:30<01:21, 368.58batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 11070/40960 [00:30<01:21, 368.58batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 11154/40960 [00:30<01:17, 382.82batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 11154/40960 [00:30<01:17, 382.82batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 11239/40960 [00:30<01:15, 394.77batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  27%|▎| 11239/40960 [00:30<01:15, 394.77batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11324/40960 [00:30<01:13, 402.62batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11324/40960 [00:30<01:13, 402.62batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11408/40960 [00:31<01:12, 406.65batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11408/40960 [00:31<01:12, 406.65batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11486/40960 [00:31<01:13, 399.19batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11486/40960 [00:31<01:13, 399.19batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11541/40960 [00:31<01:21, 361.63batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11541/40960 [00:31<01:21, 361.63batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11606/40960 [00:31<01:23, 349.67batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11606/40960 [00:31<01:23, 349.67batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11665/40960 [00:31<01:28, 331.87batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  28%|▎| 11665/40960 [00:31<01:28, 331.87batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11719/40960 [00:32<01:33, 313.04batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11719/40960 [00:32<01:33, 313.04batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11775/40960 [00:32<01:36, 303.04batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11775/40960 [00:32<01:36, 303.04batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11851/40960 [00:32<01:29, 325.39batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11851/40960 [00:32<01:29, 325.39batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11909/40960 [00:32<01:32, 313.08batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11909/40960 [00:32<01:32, 313.08batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11963/40960 [00:32<01:36, 299.29batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 11963/40960 [00:32<01:36, 299.29batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  29%|▎| 12024/40960 [00:33<01:36, 300.20batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  29%|▎| 12024/40960 [00:33<01:36, 300.20batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 12073/40960 [00:33<01:42, 282.93batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  29%|▎| 12073/40960 [00:33<01:42, 282.93batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12126/40960 [00:33<01:44, 276.81batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12126/40960 [00:33<01:44, 276.81batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12195/40960 [00:33<01:37, 296.40batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12195/40960 [00:33<01:37, 296.40batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  30%|▎| 12253/40960 [00:33<01:37, 294.35batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  30%|▎| 12253/40960 [00:33<01:37, 294.35batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12308/40960 [00:34<01:39, 287.33batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12308/40960 [00:34<01:39, 287.33batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12361/40960 [00:34<01:42, 279.23batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12361/40960 [00:34<01:42, 279.23batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12410/40960 [00:34<01:46, 267.48batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  30%|▎| 12410/40960 [00:34<01:46, 267.48batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  30%|▎| 12465/40960 [00:34<01:45, 269.01batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  30%|▎| 12465/40960 [00:34<01:45, 269.01batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12519/40960 [00:34<01:45, 268.67batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12519/40960 [00:34<01:45, 268.67batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12581/40960 [00:35<01:41, 280.14batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12581/40960 [00:35<01:41, 280.14batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12660/40960 [00:35<01:30, 313.72batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12660/40960 [00:35<01:30, 313.72batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12743/40960 [00:35<01:22, 343.17batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12743/40960 [00:35<01:22, 343.17batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12824/40960 [00:35<01:17, 361.40batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  31%|▎| 12824/40960 [00:35<01:17, 361.40batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 12906/40960 [00:35<01:14, 375.34batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 12906/40960 [00:35<01:14, 375.34batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  32%|▎| 12957/40960 [00:36<01:22, 339.02batches/s, l2_loss: 0.0362 - round_los\u001b[A\n",
      "Training:  32%|▎| 12957/40960 [00:36<01:22, 339.02batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 13008/40960 [00:36<01:29, 313.76batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 13008/40960 [00:36<01:29, 313.76batches/s, l2_loss: 0.0363 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 13088/40960 [00:36<01:22, 338.30batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 13088/40960 [00:36<01:22, 338.30batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 13158/40960 [00:36<01:21, 340.58batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 13158/40960 [00:36<01:21, 340.58batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 13235/40960 [00:36<01:18, 353.46batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  32%|▎| 13235/40960 [00:36<01:18, 353.46batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13314/40960 [00:37<01:15, 364.76batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13314/40960 [00:37<01:15, 364.76batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13396/40960 [00:37<01:13, 377.03batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13396/40960 [00:37<01:13, 377.03batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13479/40960 [00:37<01:11, 386.93batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13479/40960 [00:37<01:11, 386.93batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13563/40960 [00:37<01:09, 395.91batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13563/40960 [00:37<01:09, 395.91batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13632/40960 [00:37<01:12, 379.41batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13632/40960 [00:37<01:12, 379.41batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13682/40960 [00:38<01:20, 340.25batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  33%|▎| 13682/40960 [00:38<01:20, 340.25batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13737/40960 [00:38<01:25, 320.25batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13737/40960 [00:38<01:25, 320.25batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13795/40960 [00:38<01:27, 310.35batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13795/40960 [00:38<01:27, 310.35batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13846/40960 [00:38<01:32, 293.36batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13846/40960 [00:38<01:32, 293.36batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13896/40960 [00:38<01:37, 278.90batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13896/40960 [00:38<01:37, 278.90batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13955/40960 [00:39<01:35, 282.90batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 13955/40960 [00:39<01:35, 282.90batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 14003/40960 [00:39<01:40, 268.89batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 14003/40960 [00:39<01:40, 268.89batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 14058/40960 [00:39<01:39, 269.43batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 14058/40960 [00:39<01:39, 269.43batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 14107/40960 [00:39<01:42, 261.41batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  34%|▎| 14107/40960 [00:39<01:42, 261.41batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14171/40960 [00:39<01:36, 278.47batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14171/40960 [00:39<01:36, 278.47batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14255/40960 [00:40<01:23, 320.01batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14255/40960 [00:40<01:23, 320.01batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14340/40960 [00:40<01:15, 350.51batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14340/40960 [00:40<01:15, 350.51batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14423/40960 [00:40<01:11, 369.45batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14423/40960 [00:40<01:11, 369.45batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14506/40960 [00:40<01:09, 382.56batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  35%|▎| 14506/40960 [00:40<01:09, 382.56batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14587/40960 [00:40<01:07, 388.77batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14587/40960 [00:40<01:07, 388.77batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14672/40960 [00:41<01:05, 398.59batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14672/40960 [00:41<01:05, 398.59batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14754/40960 [00:41<01:05, 401.48batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14754/40960 [00:41<01:05, 401.48batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14838/40960 [00:41<01:04, 405.87batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14838/40960 [00:41<01:04, 405.87batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14923/40960 [00:41<01:03, 410.55batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  36%|▎| 14923/40960 [00:41<01:03, 410.55batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15007/40960 [00:41<01:02, 412.47batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15007/40960 [00:41<01:02, 412.47batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15093/40960 [00:42<01:02, 416.47batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15093/40960 [00:42<01:02, 416.47batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15176/40960 [00:42<01:01, 415.97batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15176/40960 [00:42<01:01, 415.97batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15259/40960 [00:42<01:01, 414.75batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15259/40960 [00:42<01:01, 414.75batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15344/40960 [00:42<01:01, 417.64batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  37%|▎| 15344/40960 [00:42<01:01, 417.64batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15428/40960 [00:42<01:01, 417.83batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15428/40960 [00:42<01:01, 417.83batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15512/40960 [00:43<01:00, 417.20batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15512/40960 [00:43<01:00, 417.20batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15595/40960 [00:43<01:01, 415.63batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15595/40960 [00:43<01:01, 415.63batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15680/40960 [00:43<01:00, 417.95batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15680/40960 [00:43<01:00, 417.95batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15760/40960 [00:43<01:01, 411.21batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  38%|▍| 15760/40960 [00:43<01:01, 411.21batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  39%|▍| 15843/40960 [00:43<01:01, 411.34batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  39%|▍| 15843/40960 [00:43<01:01, 411.34batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  39%|▍| 15928/40960 [00:44<01:00, 414.63batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  39%|▍| 15928/40960 [00:44<01:00, 414.63batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  39%|▍| 16009/40960 [00:44<01:00, 410.91batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  39%|▍| 16009/40960 [00:44<01:00, 410.91batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  39%|▍| 16089/40960 [00:44<01:01, 407.57batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  39%|▍| 16089/40960 [00:44<01:01, 407.57batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  39%|▍| 16171/40960 [00:44<01:00, 406.91batches/s, l2_loss: 0.0363 - round_los\u001b[A\n",
      "Training:  39%|▍| 16171/40960 [00:44<01:00, 406.91batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16254/40960 [00:44<01:00, 408.63batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16254/40960 [00:44<01:00, 408.63batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16338/40960 [00:45<00:59, 411.68batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16338/40960 [00:45<00:59, 411.68batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16421/40960 [00:45<00:59, 411.94batches/s, l2_loss: 0.0364 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 16421/40960 [00:45<00:59, 411.94batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16505/40960 [00:45<00:59, 413.91batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16505/40960 [00:45<00:59, 413.91batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16588/40960 [00:45<00:58, 413.61batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  40%|▍| 16588/40960 [00:45<00:58, 413.61batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16673/40960 [00:45<00:58, 416.60batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16673/40960 [00:45<00:58, 416.60batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16741/40960 [00:46<01:01, 392.94batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16741/40960 [00:46<01:01, 392.94batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16794/40960 [00:46<01:08, 353.00batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16794/40960 [00:46<01:08, 353.00batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16858/40960 [00:46<01:10, 341.17batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16858/40960 [00:46<01:10, 341.17batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16908/40960 [00:46<01:16, 313.62batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16908/40960 [00:46<01:16, 313.62batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16969/40960 [00:46<01:17, 310.45batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  41%|▍| 16969/40960 [00:46<01:17, 310.45batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17054/40960 [00:47<01:09, 344.13batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17054/40960 [00:47<01:09, 344.13batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17138/40960 [00:47<01:05, 366.10batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17138/40960 [00:47<01:05, 366.10batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17222/40960 [00:47<01:02, 381.55batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17222/40960 [00:47<01:02, 381.55batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17306/40960 [00:47<01:00, 391.71batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17306/40960 [00:47<01:00, 391.71batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17391/40960 [00:47<00:58, 400.60batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  42%|▍| 17391/40960 [00:47<00:58, 400.60batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17475/40960 [00:48<00:57, 406.07batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17475/40960 [00:48<00:57, 406.07batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17557/40960 [00:48<00:57, 406.92batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17557/40960 [00:48<00:57, 406.92batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17640/40960 [00:48<00:57, 408.03batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17640/40960 [00:48<00:57, 408.03batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17721/40960 [00:48<00:57, 406.86batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17721/40960 [00:48<00:57, 406.86batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17775/40960 [00:48<01:03, 364.17batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  43%|▍| 17775/40960 [00:48<01:03, 364.17batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 17826/40960 [00:49<01:10, 329.36batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 17826/40960 [00:49<01:10, 329.36batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 17893/40960 [00:49<01:09, 330.74batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 17893/40960 [00:49<01:09, 330.74batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 17973/40960 [00:49<01:05, 351.17batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 17973/40960 [00:49<01:05, 351.17batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 18055/40960 [00:49<01:02, 368.24batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 18055/40960 [00:49<01:02, 368.24batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 18139/40960 [00:49<00:59, 383.26batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 18139/40960 [00:49<00:59, 383.26batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 18224/40960 [00:50<00:57, 395.71batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  44%|▍| 18224/40960 [00:50<00:57, 395.71batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18307/40960 [00:50<00:56, 400.63batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18307/40960 [00:50<00:56, 400.63batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18373/40960 [00:50<00:59, 377.45batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18373/40960 [00:50<00:59, 377.45batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18430/40960 [00:50<01:04, 349.71batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18430/40960 [00:50<01:04, 349.71batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18488/40960 [00:50<01:08, 330.05batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18488/40960 [00:50<01:08, 330.05batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18545/40960 [00:51<01:11, 315.69batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18545/40960 [00:51<01:11, 315.69batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18630/40960 [00:51<01:04, 347.31batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  45%|▍| 18630/40960 [00:51<01:04, 347.31batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  46%|▍| 18715/40960 [00:51<01:00, 369.75batches/s, l2_loss: 0.0364 - round_los\u001b[A\n",
      "Training:  46%|▍| 18715/40960 [00:51<01:00, 369.75batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  46%|▍| 18799/40960 [00:51<00:57, 384.37batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  46%|▍| 18799/40960 [00:51<00:57, 384.37batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  46%|▍| 18881/40960 [00:51<00:56, 391.13batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  46%|▍| 18881/40960 [00:51<00:56, 391.13batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  46%|▍| 18966/40960 [00:52<00:54, 400.76batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  46%|▍| 18966/40960 [00:52<00:54, 400.76batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19049/40960 [00:52<00:54, 404.35batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19049/40960 [00:52<00:54, 404.35batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19132/40960 [00:52<00:53, 406.87batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19132/40960 [00:52<00:53, 406.87batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19217/40960 [00:52<00:52, 411.84batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19217/40960 [00:52<00:52, 411.84batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19300/40960 [00:52<00:52, 411.73batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19300/40960 [00:53<00:52, 411.73batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19385/40960 [00:53<00:52, 413.55batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19385/40960 [00:53<00:52, 413.55batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19442/40960 [00:53<00:57, 374.19batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  47%|▍| 19442/40960 [00:53<00:57, 374.19batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19513/40960 [00:53<00:58, 367.44batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19513/40960 [00:53<00:58, 367.44batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19595/40960 [00:53<00:56, 379.87batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19595/40960 [00:53<00:56, 379.87batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19676/40960 [00:54<00:55, 386.81batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19676/40960 [00:54<00:55, 386.81batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19762/40960 [00:54<00:53, 398.66batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19762/40960 [00:54<00:53, 398.66batches/s, l2_loss: 0.0365 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|▍| 19848/40960 [00:54<00:51, 407.82batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  48%|▍| 19848/40960 [00:54<00:51, 407.82batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 19927/40960 [00:54<00:52, 402.27batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 19927/40960 [00:54<00:52, 402.27batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 19987/40960 [00:54<00:56, 369.74batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 19987/40960 [00:54<00:56, 369.74batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 20045/40960 [00:55<01:00, 344.94batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 20045/40960 [00:55<01:00, 344.94batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 20117/40960 [00:55<00:59, 348.99batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 20117/40960 [00:55<00:59, 348.99batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 20186/40960 [00:55<00:59, 347.71batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 20186/40960 [00:55<00:59, 347.71batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 20271/40960 [00:55<00:55, 370.78batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  49%|▍| 20271/40960 [00:55<00:55, 370.78batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  50%|▍| 20355/40960 [00:55<00:53, 384.84batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  50%|▍| 20355/40960 [00:55<00:53, 384.84batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  50%|▍| 20439/40960 [00:56<00:52, 394.43batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  50%|▍| 20439/40960 [00:56<00:52, 394.43batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  50%|▌| 20522/40960 [00:56<00:51, 399.82batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  50%|▌| 20522/40960 [00:56<00:51, 399.82batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  50%|▌| 20605/40960 [00:56<00:50, 404.03batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  50%|▌| 20605/40960 [00:56<00:50, 404.03batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  51%|▌| 20690/40960 [00:56<00:49, 409.48batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  51%|▌| 20690/40960 [00:56<00:49, 409.48batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  51%|▌| 20775/40960 [00:56<00:48, 413.82batches/s, l2_loss: 0.0365 - round_los\u001b[A\n",
      "Training:  51%|▌| 20775/40960 [00:56<00:48, 413.82batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  51%|▌| 20859/40960 [00:57<00:48, 414.33batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  51%|▌| 20859/40960 [00:57<00:48, 414.33batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  51%|▌| 20942/40960 [00:57<00:48, 413.95batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  51%|▌| 20942/40960 [00:57<00:48, 413.95batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  51%|▌| 21023/40960 [00:57<00:48, 411.27batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  51%|▌| 21023/40960 [00:57<00:48, 411.27batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  51%|▌| 21092/40960 [00:57<00:50, 390.18batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  51%|▌| 21092/40960 [00:57<00:50, 390.18batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21155/40960 [00:57<00:53, 366.87batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21155/40960 [00:57<00:53, 366.87batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21218/40960 [00:58<00:56, 350.48batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21218/40960 [00:58<00:56, 350.48batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21278/40960 [00:58<00:58, 335.33batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21278/40960 [00:58<00:58, 335.33batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21354/40960 [00:58<00:56, 347.76batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21354/40960 [00:58<00:56, 347.76batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21411/40960 [00:58<00:59, 328.86batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21411/40960 [00:58<00:59, 328.86batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21486/40960 [00:58<00:56, 342.37batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  52%|▌| 21486/40960 [00:58<00:56, 342.37batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21572/40960 [00:59<00:52, 367.39batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21572/40960 [00:59<00:52, 367.39batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21655/40960 [00:59<00:50, 380.99batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21655/40960 [00:59<00:50, 380.99batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21716/40960 [00:59<00:53, 357.04batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21716/40960 [00:59<00:53, 357.04batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21778/40960 [00:59<00:55, 342.87batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21778/40960 [00:59<00:55, 342.87batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21850/40960 [00:59<00:55, 347.16batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21850/40960 [00:59<00:55, 347.16batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21907/40960 [01:00<00:57, 328.58batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  53%|▌| 21907/40960 [01:00<00:57, 328.58batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 21977/40960 [01:00<00:56, 334.67batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 21977/40960 [01:00<00:56, 334.67batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 22062/40960 [01:00<00:52, 360.98batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 22062/40960 [01:00<00:52, 360.98batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 22127/40960 [01:00<00:53, 350.22batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 22127/40960 [01:00<00:53, 350.22batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 22190/40960 [01:00<00:55, 338.77batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 22190/40960 [01:00<00:55, 338.77batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 22268/40960 [01:01<00:52, 353.36batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  54%|▌| 22268/40960 [01:01<00:52, 353.36batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  55%|▌| 22353/40960 [01:01<00:49, 374.13batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  55%|▌| 22353/40960 [01:01<00:49, 374.13batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  55%|▌| 22432/40960 [01:01<00:48, 380.17batches/s, l2_loss: 0.0366 - round_los\u001b[A\n",
      "Training:  55%|▌| 22432/40960 [01:01<00:48, 380.17batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  55%|▌| 22518/40960 [01:01<00:46, 394.13batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  55%|▌| 22518/40960 [01:01<00:46, 394.13batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  55%|▌| 22601/40960 [01:01<00:45, 399.83batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  55%|▌| 22601/40960 [01:01<00:45, 399.83batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  55%|▌| 22685/40960 [01:02<00:45, 404.84batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  55%|▌| 22685/40960 [01:02<00:45, 404.84batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 22766/40960 [01:02<00:44, 404.50batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 22766/40960 [01:02<00:44, 404.50batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 22851/40960 [01:02<00:44, 409.76batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 22851/40960 [01:02<00:44, 409.76batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 22933/40960 [01:02<00:44, 408.28batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 22933/40960 [01:02<00:44, 408.28batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 23015/40960 [01:02<00:43, 408.10batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 23015/40960 [01:02<00:43, 408.10batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 23099/40960 [01:03<00:43, 411.51batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  56%|▌| 23099/40960 [01:03<00:43, 411.51batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23184/40960 [01:03<00:42, 415.05batches/s, l2_loss: 0.0367 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|▌| 23184/40960 [01:03<00:42, 415.05batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23268/40960 [01:03<00:42, 416.00batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23268/40960 [01:03<00:42, 416.00batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23352/40960 [01:03<00:42, 416.57batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23352/40960 [01:03<00:42, 416.57batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23437/40960 [01:03<00:41, 417.80batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23437/40960 [01:03<00:41, 417.80batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23523/40960 [01:04<00:41, 420.17batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  57%|▌| 23523/40960 [01:04<00:41, 420.17batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23604/40960 [01:04<00:41, 415.08batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23604/40960 [01:04<00:41, 415.08batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23689/40960 [01:04<00:41, 417.69batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23689/40960 [01:04<00:41, 417.69batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23772/40960 [01:04<00:41, 415.72batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23772/40960 [01:04<00:41, 415.72batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23854/40960 [01:04<00:41, 413.31batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23854/40960 [01:04<00:41, 413.31batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23937/40960 [01:05<00:41, 413.77batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  58%|▌| 23937/40960 [01:05<00:41, 413.77batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  59%|▌| 24023/40960 [01:05<00:40, 417.68batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  59%|▌| 24023/40960 [01:05<00:40, 417.68batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  59%|▌| 24109/40960 [01:05<00:40, 420.41batches/s, l2_loss: 0.0367 - round_los\u001b[A\n",
      "Training:  59%|▌| 24109/40960 [01:05<00:40, 420.41batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  59%|▌| 24194/40960 [01:05<00:39, 420.37batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  59%|▌| 24194/40960 [01:05<00:39, 420.37batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  59%|▌| 24279/40960 [01:05<00:39, 420.45batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  59%|▌| 24279/40960 [01:05<00:39, 420.45batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  59%|▌| 24362/40960 [01:06<00:39, 418.33batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  59%|▌| 24362/40960 [01:06<00:39, 418.33batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  60%|▌| 24446/40960 [01:06<00:39, 418.51batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  60%|▌| 24446/40960 [01:06<00:39, 418.51batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  60%|▌| 24532/40960 [01:06<00:38, 421.23batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  60%|▌| 24532/40960 [01:06<00:38, 421.23batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  60%|▌| 24613/40960 [01:06<00:39, 415.73batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  60%|▌| 24613/40960 [01:06<00:39, 415.73batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  60%|▌| 24697/40960 [01:06<00:39, 415.93batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  60%|▌| 24697/40960 [01:06<00:39, 415.93batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 24782/40960 [01:07<00:38, 417.34batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 24782/40960 [01:07<00:38, 417.34batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 24868/40960 [01:07<00:38, 420.52batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 24868/40960 [01:07<00:38, 420.52batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 24955/40960 [01:07<00:37, 424.27batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 24955/40960 [01:07<00:37, 424.27batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 25037/40960 [01:07<00:37, 419.11batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 25037/40960 [01:07<00:37, 419.11batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 25117/40960 [01:07<00:38, 411.87batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  61%|▌| 25117/40960 [01:07<00:38, 411.87batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25203/40960 [01:08<00:37, 416.10batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25203/40960 [01:08<00:37, 416.10batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25287/40960 [01:08<00:37, 416.18batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25287/40960 [01:08<00:37, 416.18batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25373/40960 [01:08<00:37, 419.09batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25373/40960 [01:08<00:37, 419.09batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25455/40960 [01:08<00:37, 416.03batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25455/40960 [01:08<00:37, 416.03batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25540/40960 [01:08<00:36, 418.01batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  62%|▌| 25540/40960 [01:08<00:36, 418.01batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  63%|▋| 25625/40960 [01:09<00:36, 420.03batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  63%|▋| 25625/40960 [01:09<00:36, 420.03batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  63%|▋| 25709/40960 [01:09<00:36, 418.72batches/s, l2_loss: 0.0368 - round_los\u001b[A\n",
      "Training:  63%|▋| 25709/40960 [01:09<00:36, 418.72batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  63%|▋| 25790/40960 [01:09<00:36, 414.59batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  63%|▋| 25790/40960 [01:09<00:36, 414.59batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  63%|▋| 25875/40960 [01:09<00:36, 416.45batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  63%|▋| 25875/40960 [01:09<00:36, 416.45batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  63%|▋| 25960/40960 [01:09<00:35, 417.54batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  63%|▋| 25960/40960 [01:09<00:35, 417.54batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26045/40960 [01:10<00:35, 419.40batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26045/40960 [01:10<00:35, 419.40batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26129/40960 [01:10<00:35, 419.54batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26129/40960 [01:10<00:35, 419.54batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26213/40960 [01:10<00:35, 418.45batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26213/40960 [01:10<00:35, 418.45batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26295/40960 [01:10<00:35, 414.71batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26295/40960 [01:10<00:35, 414.71batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26380/40960 [01:10<00:35, 416.37batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  64%|▋| 26380/40960 [01:10<00:35, 416.37batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26463/40960 [01:11<00:34, 414.76batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26463/40960 [01:11<00:34, 414.76batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26548/40960 [01:11<00:34, 416.56batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26548/40960 [01:11<00:34, 416.56batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26633/40960 [01:11<00:34, 418.72batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26633/40960 [01:11<00:34, 418.72batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26719/40960 [01:11<00:33, 421.34batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26719/40960 [01:11<00:33, 421.34batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26803/40960 [01:11<00:33, 420.59batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  65%|▋| 26803/40960 [01:11<00:33, 420.59batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  66%|▋| 26884/40960 [01:12<00:33, 415.84batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  66%|▋| 26884/40960 [01:12<00:33, 415.84batches/s, l2_loss: 0.0369 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|▋| 26968/40960 [01:12<00:33, 416.62batches/s, l2_loss: 0.0369 - round_los\u001b[A\n",
      "Training:  66%|▋| 26968/40960 [01:12<00:33, 416.62batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  66%|▋| 27050/40960 [01:12<00:33, 414.05batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  66%|▋| 27050/40960 [01:12<00:33, 414.05batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  66%|▋| 27134/40960 [01:12<00:33, 414.93batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  66%|▋| 27134/40960 [01:12<00:33, 414.93batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  66%|▋| 27215/40960 [01:12<00:33, 410.94batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  66%|▋| 27215/40960 [01:12<00:33, 410.94batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27300/40960 [01:13<00:32, 414.47batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27300/40960 [01:13<00:32, 414.47batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27384/40960 [01:13<00:32, 415.47batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27384/40960 [01:13<00:32, 415.47batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27470/40960 [01:13<00:32, 418.39batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27470/40960 [01:13<00:32, 418.39batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27554/40960 [01:13<00:32, 418.03batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27554/40960 [01:13<00:32, 418.03batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27638/40960 [01:13<00:31, 417.78batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  67%|▋| 27638/40960 [01:13<00:31, 417.78batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 27721/40960 [01:14<00:31, 416.63batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 27721/40960 [01:14<00:31, 416.63batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 27797/40960 [01:14<00:32, 405.37batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 27797/40960 [01:14<00:32, 405.37batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 27879/40960 [01:14<00:32, 406.33batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 27879/40960 [01:14<00:32, 406.33batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 27964/40960 [01:14<00:31, 410.72batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 27964/40960 [01:14<00:31, 410.72batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 28045/40960 [01:14<00:31, 408.11batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  68%|▋| 28045/40960 [01:14<00:31, 408.11batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  69%|▋| 28129/40960 [01:15<00:31, 410.99batches/s, l2_loss: 0.0370 - round_los\u001b[A\n",
      "Training:  69%|▋| 28129/40960 [01:15<00:31, 410.99batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  69%|▋| 28212/40960 [01:15<00:31, 411.06batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  69%|▋| 28212/40960 [01:15<00:31, 411.06batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  69%|▋| 28295/40960 [01:15<00:30, 411.81batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  69%|▋| 28295/40960 [01:15<00:30, 411.81batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  69%|▋| 28379/40960 [01:15<00:30, 413.46batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  69%|▋| 28379/40960 [01:15<00:30, 413.46batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  69%|▋| 28464/40960 [01:15<00:30, 416.15batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  69%|▋| 28464/40960 [01:15<00:30, 416.15batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  70%|▋| 28550/40960 [01:16<00:29, 419.80batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  70%|▋| 28550/40960 [01:16<00:29, 419.80batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  70%|▋| 28634/40960 [01:16<00:29, 419.61batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  70%|▋| 28634/40960 [01:16<00:29, 419.61batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  70%|▋| 28718/40960 [01:16<00:29, 418.47batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  70%|▋| 28718/40960 [01:16<00:29, 418.47batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  70%|▋| 28799/40960 [01:16<00:29, 413.29batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  70%|▋| 28799/40960 [01:16<00:29, 413.29batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 28883/40960 [01:16<00:29, 415.23batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 28883/40960 [01:16<00:29, 415.23batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 28967/40960 [01:17<00:28, 416.35batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 28967/40960 [01:17<00:28, 416.35batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 29050/40960 [01:17<00:28, 415.40batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 29050/40960 [01:17<00:28, 415.40batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 29131/40960 [01:17<00:28, 411.01batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 29131/40960 [01:17<00:28, 411.01batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 29215/40960 [01:17<00:28, 412.86batches/s, l2_loss: 0.0371 - round_los\u001b[A\n",
      "Training:  71%|▋| 29215/40960 [01:17<00:28, 412.86batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29298/40960 [01:17<00:28, 412.30batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29298/40960 [01:17<00:28, 412.30batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29382/40960 [01:18<00:27, 414.44batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29382/40960 [01:18<00:27, 414.44batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29465/40960 [01:18<00:27, 413.13batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29465/40960 [01:18<00:27, 413.13batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29547/40960 [01:18<00:27, 411.50batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29547/40960 [01:18<00:27, 411.50batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29630/40960 [01:18<00:27, 412.49batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  72%|▋| 29630/40960 [01:18<00:27, 412.49batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29714/40960 [01:18<00:27, 413.25batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29714/40960 [01:18<00:27, 413.25batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29797/40960 [01:19<00:27, 413.25batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29797/40960 [01:19<00:27, 413.25batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29879/40960 [01:19<00:26, 412.28batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29879/40960 [01:19<00:26, 412.28batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29961/40960 [01:19<00:26, 410.88batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29961/40960 [01:19<00:26, 410.88batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 30043/40960 [01:19<00:26, 409.84batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  73%|▋| 30043/40960 [01:19<00:26, 409.84batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  74%|▋| 30129/40960 [01:19<00:26, 414.57batches/s, l2_loss: 0.0372 - round_los\u001b[A\n",
      "Training:  74%|▋| 30129/40960 [01:19<00:26, 414.57batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30209/40960 [01:20<00:26, 410.11batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30209/40960 [01:20<00:26, 410.11batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30291/40960 [01:20<00:26, 409.93batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30291/40960 [01:20<00:26, 409.93batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30374/40960 [01:20<00:25, 411.07batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30374/40960 [01:20<00:25, 411.07batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30457/40960 [01:20<00:25, 411.71batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30457/40960 [01:20<00:25, 411.71batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▋| 30541/40960 [01:20<00:25, 412.94batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▋| 30541/40960 [01:20<00:25, 412.94batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▋| 30624/40960 [01:21<00:25, 413.08batches/s, l2_loss: 0.0373 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▋| 30624/40960 [01:21<00:25, 413.08batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▋| 30706/40960 [01:21<00:24, 410.93batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▋| 30706/40960 [01:21<00:24, 410.93batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▊| 30778/40960 [01:21<00:25, 395.59batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▊| 30778/40960 [01:21<00:25, 395.59batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▊| 30834/40960 [01:21<00:28, 360.59batches/s, l2_loss: 0.0373 - round_los\u001b[A\n",
      "Training:  75%|▊| 30834/40960 [01:21<00:28, 360.59batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  75%|▊| 30904/40960 [01:21<00:28, 356.35batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  75%|▊| 30904/40960 [01:21<00:28, 356.35batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 30984/40960 [01:22<00:27, 368.70batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 30984/40960 [01:22<00:27, 368.70batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 31068/40960 [01:22<00:25, 383.15batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 31068/40960 [01:22<00:25, 383.15batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 31150/40960 [01:22<00:25, 390.65batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 31150/40960 [01:22<00:25, 390.65batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 31205/40960 [01:22<00:27, 355.46batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 31205/40960 [01:22<00:27, 355.46batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 31269/40960 [01:22<00:28, 344.72batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  76%|▊| 31269/40960 [01:22<00:28, 344.72batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  77%|▊| 31352/40960 [01:23<00:26, 364.98batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  77%|▊| 31352/40960 [01:23<00:26, 364.98batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  77%|▊| 31436/40960 [01:23<00:24, 380.98batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  77%|▊| 31436/40960 [01:23<00:24, 380.98batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  77%|▊| 31520/40960 [01:23<00:24, 392.00batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  77%|▊| 31520/40960 [01:23<00:24, 392.00batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  77%|▊| 31604/40960 [01:23<00:23, 399.83batches/s, l2_loss: 0.0374 - round_los\u001b[A\n",
      "Training:  77%|▊| 31604/40960 [01:23<00:23, 399.83batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  77%|▊| 31675/40960 [01:23<00:24, 385.24batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  77%|▊| 31675/40960 [01:23<00:24, 385.24batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  77%|▊| 31725/40960 [01:24<00:26, 343.80batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  77%|▊| 31725/40960 [01:24<00:26, 343.80batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 31778/40960 [01:24<00:28, 319.77batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 31778/40960 [01:24<00:28, 319.77batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 31861/40960 [01:24<00:26, 347.47batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 31861/40960 [01:24<00:26, 347.47batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 31930/40960 [01:24<00:26, 345.56batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 31930/40960 [01:24<00:26, 345.56batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 32012/40960 [01:24<00:24, 364.46batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 32012/40960 [01:24<00:24, 364.46batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 32096/40960 [01:25<00:23, 380.69batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  78%|▊| 32096/40960 [01:25<00:23, 380.69batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  79%|▊| 32167/40960 [01:25<00:23, 372.19batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  79%|▊| 32167/40960 [01:25<00:23, 372.19batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  79%|▊| 32226/40960 [01:25<00:25, 348.55batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  79%|▊| 32226/40960 [01:25<00:25, 348.55batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  79%|▊| 32306/40960 [01:25<00:23, 363.10batches/s, l2_loss: 0.0375 - round_los\u001b[A\n",
      "Training:  79%|▊| 32306/40960 [01:25<00:23, 363.10batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  79%|▊| 32387/40960 [01:26<00:22, 375.14batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  79%|▊| 32387/40960 [01:26<00:22, 375.14batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  79%|▊| 32469/40960 [01:26<00:22, 384.66batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  79%|▊| 32469/40960 [01:26<00:22, 384.66batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  79%|▊| 32529/40960 [01:26<00:23, 358.54batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  79%|▊| 32529/40960 [01:26<00:23, 358.54batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  80%|▊| 32592/40960 [01:26<00:24, 345.23batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  80%|▊| 32592/40960 [01:26<00:24, 345.23batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  80%|▊| 32674/40960 [01:26<00:22, 363.69batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  80%|▊| 32674/40960 [01:26<00:22, 363.69batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  80%|▊| 32756/40960 [01:27<00:21, 376.51batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  80%|▊| 32756/40960 [01:27<00:21, 376.51batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  80%|▊| 32837/40960 [01:27<00:21, 383.62batches/s, l2_loss: 0.0376 - round_los\u001b[A\n",
      "Training:  80%|▊| 32837/40960 [01:27<00:21, 383.62batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  80%|▊| 32892/40960 [01:27<00:22, 350.88batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  80%|▊| 32892/40960 [01:27<00:22, 350.88batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  80%|▊| 32953/40960 [01:27<00:23, 336.95batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  80%|▊| 32953/40960 [01:27<00:23, 336.95batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33003/40960 [01:27<00:25, 309.65batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33003/40960 [01:27<00:25, 309.65batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33061/40960 [01:28<00:26, 303.14batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33061/40960 [01:28<00:26, 303.14batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33139/40960 [01:28<00:23, 328.56batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33139/40960 [01:28<00:23, 328.56batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33205/40960 [01:28<00:23, 327.00batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33205/40960 [01:28<00:23, 327.00batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33256/40960 [01:28<00:25, 303.79batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33256/40960 [01:28<00:25, 303.79batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33305/40960 [01:28<00:26, 284.87batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33305/40960 [01:28<00:26, 284.87batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33356/40960 [01:29<00:27, 275.81batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  81%|▊| 33356/40960 [01:29<00:27, 275.81batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  82%|▊| 33407/40960 [01:29<00:28, 269.09batches/s, l2_loss: 0.0377 - round_los\u001b[A\n",
      "Training:  82%|▊| 33407/40960 [01:29<00:28, 269.09batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33478/40960 [01:29<00:25, 294.48batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33478/40960 [01:29<00:25, 294.48batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33532/40960 [01:29<00:25, 286.04batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33532/40960 [01:29<00:25, 286.04batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33589/40960 [01:29<00:25, 284.67batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33589/40960 [01:29<00:25, 284.67batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33639/40960 [01:30<00:26, 273.57batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33639/40960 [01:30<00:26, 273.57batches/s, l2_loss: 0.0378 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|▊| 33707/40960 [01:30<00:24, 292.55batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33707/40960 [01:30<00:24, 292.55batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33790/40960 [01:30<00:21, 328.57batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  82%|▊| 33790/40960 [01:30<00:21, 328.57batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  83%|▊| 33854/40960 [01:30<00:21, 325.42batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  83%|▊| 33854/40960 [01:30<00:21, 325.42batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  83%|▊| 33924/40960 [01:30<00:21, 332.11batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  83%|▊| 33924/40960 [01:30<00:21, 332.11batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  83%|▊| 33984/40960 [01:31<00:21, 322.07batches/s, l2_loss: 0.0378 - round_los\u001b[A\n",
      "Training:  83%|▊| 33984/40960 [01:31<00:21, 322.07batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  83%|▊| 34053/40960 [01:31<00:21, 328.05batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  83%|▊| 34053/40960 [01:31<00:21, 328.05batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  83%|▊| 34129/40960 [01:31<00:19, 341.94batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  83%|▊| 34129/40960 [01:31<00:19, 341.94batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  83%|▊| 34180/40960 [01:31<00:21, 315.25batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  83%|▊| 34180/40960 [01:31<00:21, 315.25batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  84%|▊| 34258/40960 [01:31<00:19, 337.04batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  84%|▊| 34258/40960 [01:31<00:19, 337.04batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  84%|▊| 34344/40960 [01:32<00:18, 364.05batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  84%|▊| 34344/40960 [01:32<00:18, 364.05batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  84%|▊| 34393/40960 [01:32<00:20, 327.99batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  84%|▊| 34393/40960 [01:32<00:20, 327.99batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  84%|▊| 34443/40960 [01:32<00:21, 303.24batches/s, l2_loss: 0.0379 - round_los\u001b[A\n",
      "Training:  84%|▊| 34443/40960 [01:32<00:21, 303.24batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  84%|▊| 34494/40960 [01:32<00:22, 288.14batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  84%|▊| 34494/40960 [01:32<00:22, 288.14batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  84%|▊| 34575/40960 [01:32<00:19, 322.13batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  84%|▊| 34575/40960 [01:32<00:19, 322.13batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34631/40960 [01:33<00:20, 307.88batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34631/40960 [01:33<00:20, 307.88batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34694/40960 [01:33<00:20, 309.79batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34694/40960 [01:33<00:20, 309.79batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34747/40960 [01:33<00:21, 295.54batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34747/40960 [01:33<00:21, 295.54batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34807/40960 [01:33<00:20, 296.29batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34807/40960 [01:33<00:20, 296.29batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34892/40960 [01:33<00:18, 333.80batches/s, l2_loss: 0.0380 - round_los\u001b[A\n",
      "Training:  85%|▊| 34892/40960 [01:33<00:18, 333.80batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  85%|▊| 34974/40960 [01:34<00:16, 356.07batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  85%|▊| 34974/40960 [01:34<00:16, 356.07batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35032/40960 [01:34<00:17, 335.37batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35032/40960 [01:34<00:17, 335.37batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35096/40960 [01:34<00:17, 329.25batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35096/40960 [01:34<00:17, 329.25batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35147/40960 [01:34<00:18, 306.70batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35147/40960 [01:34<00:18, 306.70batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35225/40960 [01:34<00:17, 331.00batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35225/40960 [01:34<00:17, 331.00batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35302/40960 [01:35<00:16, 346.70batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35302/40960 [01:35<00:16, 346.70batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35354/40960 [01:35<00:17, 319.76batches/s, l2_loss: 0.0381 - round_los\u001b[A\n",
      "Training:  86%|▊| 35354/40960 [01:35<00:17, 319.76batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35437/40960 [01:35<00:15, 347.46batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35437/40960 [01:35<00:15, 347.46batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35521/40960 [01:35<00:14, 367.94batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35521/40960 [01:35<00:14, 367.94batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [01:35<00:15, 347.60batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [01:35<00:15, 347.60batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35631/40960 [01:36<00:16, 318.32batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35631/40960 [01:36<00:16, 318.32batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35695/40960 [01:36<00:16, 317.98batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35695/40960 [01:36<00:16, 317.98batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35744/40960 [01:36<00:17, 295.04batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35744/40960 [01:36<00:17, 295.04batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35807/40960 [01:36<00:17, 300.90batches/s, l2_loss: 0.0382 - round_los\u001b[A\n",
      "Training:  87%|▊| 35807/40960 [01:36<00:17, 300.90batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 35861/40960 [01:36<00:17, 291.31batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 35861/40960 [01:36<00:17, 291.31batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 35939/40960 [01:37<00:15, 320.61batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 35939/40960 [01:37<00:15, 320.61batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 36024/40960 [01:37<00:14, 351.49batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 36024/40960 [01:37<00:14, 351.49batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 36080/40960 [01:37<00:14, 329.24batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 36080/40960 [01:37<00:14, 329.24batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 36141/40960 [01:37<00:14, 321.60batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 36141/40960 [01:37<00:14, 321.60batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 36226/40960 [01:37<00:13, 351.82batches/s, l2_loss: 0.0383 - round_los\u001b[A\n",
      "Training:  88%|▉| 36226/40960 [01:37<00:13, 351.82batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36283/40960 [01:38<00:14, 331.09batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36283/40960 [01:38<00:14, 331.09batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36347/40960 [01:38<00:14, 327.08batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36347/40960 [01:38<00:14, 327.08batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36404/40960 [01:38<00:14, 313.90batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36404/40960 [01:38<00:14, 313.90batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36479/40960 [01:38<00:13, 331.99batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36479/40960 [01:38<00:13, 331.99batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36536/40960 [01:38<00:13, 317.94batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36536/40960 [01:38<00:13, 317.94batches/s, l2_loss: 0.0384 - round_los\u001b[A\n",
      "Training:  89%|▉| 36596/40960 [01:39<00:14, 311.65batches/s, l2_loss: 0.0384 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36596/40960 [01:39<00:14, 311.65batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36676/40960 [01:39<00:12, 337.67batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36676/40960 [01:39<00:12, 337.67batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36733/40960 [01:39<00:13, 320.90batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36733/40960 [01:39<00:13, 320.90batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36788/40960 [01:39<00:13, 305.64batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36788/40960 [01:39<00:13, 305.64batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36842/40960 [01:39<00:14, 294.00batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36842/40960 [01:39<00:14, 294.00batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36898/40960 [01:40<00:14, 289.76batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36898/40960 [01:40<00:14, 289.76batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36952/40960 [01:40<00:14, 282.98batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 36952/40960 [01:40<00:14, 282.98batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 37005/40960 [01:40<00:14, 276.97batches/s, l2_loss: 0.0385 - round_los\u001b[A\n",
      "Training:  90%|▉| 37005/40960 [01:40<00:14, 276.97batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  90%|▉| 37063/40960 [01:40<00:13, 279.69batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  90%|▉| 37063/40960 [01:40<00:13, 279.69batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37140/40960 [01:40<00:12, 310.09batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37140/40960 [01:40<00:12, 310.09batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37193/40960 [01:41<00:12, 296.15batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37193/40960 [01:41<00:12, 296.15batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37261/40960 [01:41<00:11, 308.41batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37261/40960 [01:41<00:11, 308.41batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37343/40960 [01:41<00:10, 338.70batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37343/40960 [01:41<00:10, 338.70batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37427/40960 [01:41<00:09, 362.40batches/s, l2_loss: 0.0386 - round_los\u001b[A\n",
      "Training:  91%|▉| 37427/40960 [01:41<00:09, 362.40batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37487/40960 [01:41<00:10, 342.66batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37487/40960 [01:41<00:10, 342.66batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37535/40960 [01:42<00:10, 311.65batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37535/40960 [01:42<00:10, 311.65batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37590/40960 [01:42<00:11, 300.46batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37590/40960 [01:42<00:11, 300.46batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37642/40960 [01:42<00:11, 287.52batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37642/40960 [01:42<00:11, 287.52batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37694/40960 [01:42<00:11, 278.60batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37694/40960 [01:42<00:11, 278.60batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37772/40960 [01:42<00:10, 311.24batches/s, l2_loss: 0.0387 - round_los\u001b[A\n",
      "Training:  92%|▉| 37772/40960 [01:42<00:10, 311.24batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  92%|▉| 37854/40960 [01:43<00:09, 340.26batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  92%|▉| 37854/40960 [01:43<00:09, 340.26batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 37933/40960 [01:43<00:08, 355.80batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 37933/40960 [01:43<00:08, 355.80batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 38016/40960 [01:43<00:07, 372.97batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 38016/40960 [01:43<00:07, 372.97batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 38082/40960 [01:43<00:08, 359.01batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 38082/40960 [01:43<00:08, 359.01batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 38132/40960 [01:43<00:08, 325.69batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 38132/40960 [01:43<00:08, 325.69batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 38210/40960 [01:44<00:07, 343.80batches/s, l2_loss: 0.0388 - round_los\u001b[A\n",
      "Training:  93%|▉| 38210/40960 [01:44<00:07, 343.80batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  93%|▉| 38293/40960 [01:44<00:07, 364.72batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  93%|▉| 38293/40960 [01:44<00:07, 364.72batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  94%|▉| 38377/40960 [01:44<00:06, 380.16batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  94%|▉| 38377/40960 [01:44<00:06, 380.16batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  94%|▉| 38460/40960 [01:44<00:06, 390.27batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  94%|▉| 38460/40960 [01:44<00:06, 390.27batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  94%|▉| 38539/40960 [01:44<00:06, 391.68batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  94%|▉| 38539/40960 [01:44<00:06, 391.68batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  94%|▉| 38616/40960 [01:45<00:06, 389.49batches/s, l2_loss: 0.0389 - round_los\u001b[A\n",
      "Training:  94%|▉| 38616/40960 [01:45<00:06, 389.49batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  94%|▉| 38699/40960 [01:45<00:05, 396.99batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  94%|▉| 38699/40960 [01:45<00:05, 396.99batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  95%|▉| 38780/40960 [01:45<00:05, 399.12batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  95%|▉| 38780/40960 [01:45<00:05, 399.12batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  95%|▉| 38863/40960 [01:45<00:05, 402.51batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  95%|▉| 38863/40960 [01:45<00:05, 402.51batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  95%|▉| 38946/40960 [01:45<00:04, 406.12batches/s, l2_loss: 0.0390 - round_los\u001b[A\n",
      "Training:  95%|▉| 38946/40960 [01:45<00:04, 406.12batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  95%|▉| 39028/40960 [01:46<00:04, 406.90batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  95%|▉| 39028/40960 [01:46<00:04, 406.90batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  95%|▉| 39112/40960 [01:46<00:04, 410.60batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  95%|▉| 39112/40960 [01:46<00:04, 410.60batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  96%|▉| 39197/40960 [01:46<00:04, 413.79batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  96%|▉| 39197/40960 [01:46<00:04, 413.79batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  96%|▉| 39281/40960 [01:46<00:04, 415.64batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  96%|▉| 39281/40960 [01:46<00:04, 415.64batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  96%|▉| 39367/40960 [01:46<00:03, 419.40batches/s, l2_loss: 0.0391 - round_los\u001b[A\n",
      "Training:  96%|▉| 39367/40960 [01:46<00:03, 419.40batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  96%|▉| 39450/40960 [01:47<00:03, 418.05batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  96%|▉| 39450/40960 [01:47<00:03, 418.05batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39534/40960 [01:47<00:03, 417.64batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39534/40960 [01:47<00:03, 417.64batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39616/40960 [01:47<00:03, 414.76batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39616/40960 [01:47<00:03, 414.76batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39701/40960 [01:47<00:03, 416.82batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39701/40960 [01:47<00:03, 416.82batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39786/40960 [01:47<00:02, 418.10batches/s, l2_loss: 0.0392 - round_los\u001b[A\n",
      "Training:  97%|▉| 39786/40960 [01:47<00:02, 418.10batches/s, l2_loss: 0.0393 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|▉| 39870/40960 [01:48<00:02, 418.05batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  97%|▉| 39870/40960 [01:48<00:02, 418.05batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 39950/40960 [01:48<00:02, 411.88batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 39950/40960 [01:48<00:02, 411.88batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 40033/40960 [01:48<00:02, 411.37batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 40033/40960 [01:48<00:02, 411.37batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 40086/40960 [01:48<00:02, 367.68batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 40086/40960 [01:48<00:02, 367.68batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 40138/40960 [01:48<00:02, 335.46batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 40138/40960 [01:48<00:02, 335.46batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 40203/40960 [01:49<00:02, 331.38batches/s, l2_loss: 0.0393 - round_los\u001b[A\n",
      "Training:  98%|▉| 40203/40960 [01:49<00:02, 331.38batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40287/40960 [01:49<00:01, 357.72batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  98%|▉| 40287/40960 [01:49<00:01, 357.72batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40369/40960 [01:49<00:01, 372.97batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40369/40960 [01:49<00:01, 372.97batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40452/40960 [01:49<00:01, 385.20batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40452/40960 [01:49<00:01, 385.20batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40536/40960 [01:49<00:01, 394.37batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40536/40960 [01:49<00:01, 394.37batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40620/40960 [01:50<00:00, 401.01batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40620/40960 [01:50<00:00, 401.01batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40705/40960 [01:50<00:00, 407.01batches/s, l2_loss: 0.0394 - round_los\u001b[A\n",
      "Training:  99%|▉| 40705/40960 [01:50<00:00, 407.01batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training: 100%|▉| 40790/40960 [01:50<00:00, 411.42batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training: 100%|▉| 40790/40960 [01:50<00:00, 411.42batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training: 100%|▉| 40875/40960 [01:50<00:00, 414.81batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training: 100%|▉| 40875/40960 [01:50<00:00, 414.81batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training: 100%|▉| 40958/40960 [01:50<00:00, 414.36batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "Training: 100%|▉| 40958/40960 [01:50<00:00, 414.36batches/s, l2_loss: 0.0395 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:03:06.428180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  31%|▎| 8/26 [15:26<36:21, 121.20s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 15:03:07.700494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:03:15.210638: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<31:42:24,  2.79s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<31:42:24,  2.79s/batches, l2_loss: 0.1243 - round_loss:\u001b[A\n",
      "Training:   0%| | 52/40960 [00:02<28:25, 23.98batches/s, l2_loss: 0.1243 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 52/40960 [00:03<28:25, 23.98batches/s, l2_loss: 0.1895 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 90/40960 [00:03<15:42, 43.38batches/s, l2_loss: 0.1895 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 90/40960 [00:03<15:42, 43.38batches/s, l2_loss: 0.1873 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 144/40960 [00:03<08:59, 75.67batches/s, l2_loss: 0.1873 - round_loss: \u001b[A\n",
      "Training:   0%| | 144/40960 [00:03<08:59, 75.67batches/s, l2_loss: 0.1700 - round_loss: \u001b[A\n",
      "Training:   0%| | 200/40960 [00:03<06:09, 110.21batches/s, l2_loss: 0.1700 - round_loss:\u001b[A\n",
      "Training:   0%| | 200/40960 [00:03<06:09, 110.21batches/s, l2_loss: 0.1728 - round_loss:\u001b[A\n",
      "Training:   1%| | 264/40960 [00:03<04:29, 150.73batches/s, l2_loss: 0.1728 - round_loss:\u001b[A\n",
      "Training:   1%| | 264/40960 [00:03<04:29, 150.73batches/s, l2_loss: 0.1676 - round_loss:\u001b[A\n",
      "Training:   1%| | 322/40960 [00:04<03:45, 180.55batches/s, l2_loss: 0.1676 - round_loss:\u001b[A\n",
      "Training:   1%| | 322/40960 [00:04<03:45, 180.55batches/s, l2_loss: 0.1647 - round_loss:\u001b[A\n",
      "Training:   1%| | 359/40960 [00:04<03:44, 180.46batches/s, l2_loss: 0.1647 - round_loss:\u001b[A\n",
      "Training:   1%| | 359/40960 [00:04<03:44, 180.46batches/s, l2_loss: 0.1612 - round_loss:\u001b[A\n",
      "Training:   1%| | 408/40960 [00:04<03:26, 196.24batches/s, l2_loss: 0.1612 - round_loss:\u001b[A\n",
      "Training:   1%| | 408/40960 [00:04<03:26, 196.24batches/s, l2_loss: 0.1629 - round_loss:\u001b[A\n",
      "Training:   1%| | 471/40960 [00:04<02:58, 227.23batches/s, l2_loss: 0.1629 - round_loss:\u001b[A\n",
      "Training:   1%| | 471/40960 [00:04<02:58, 227.23batches/s, l2_loss: 0.1623 - round_loss:\u001b[A\n",
      "Training:   1%| | 533/40960 [00:04<02:41, 249.70batches/s, l2_loss: 0.1623 - round_loss:\u001b[A\n",
      "Training:   1%| | 533/40960 [00:04<02:41, 249.70batches/s, l2_loss: 0.1623 - round_loss:\u001b[A\n",
      "Training:   1%| | 586/40960 [00:05<02:39, 252.70batches/s, l2_loss: 0.1623 - round_loss:\u001b[A\n",
      "Training:   1%| | 586/40960 [00:05<02:39, 252.70batches/s, l2_loss: 0.1623 - round_loss:\u001b[A\n",
      "Training:   2%| | 625/40960 [00:05<02:51, 235.64batches/s, l2_loss: 0.1623 - round_loss:\u001b[A\n",
      "Training:   2%| | 625/40960 [00:05<02:51, 235.64batches/s, l2_loss: 0.1603 - round_loss:\u001b[A\n",
      "Training:   2%| | 689/40960 [00:05<02:35, 259.78batches/s, l2_loss: 0.1603 - round_loss:\u001b[A\n",
      "Training:   2%| | 689/40960 [00:05<02:35, 259.78batches/s, l2_loss: 0.1581 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:05<02:28, 271.08batches/s, l2_loss: 0.1581 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:05<02:28, 271.08batches/s, l2_loss: 0.1581 - round_loss:\u001b[A\n",
      "Training:   2%| | 800/40960 [00:05<02:31, 265.74batches/s, l2_loss: 0.1581 - round_loss:\u001b[A\n",
      "Training:   2%| | 800/40960 [00:05<02:31, 265.74batches/s, l2_loss: 0.1579 - round_loss:\u001b[A\n",
      "Training:   2%| | 841/40960 [00:06<02:43, 246.03batches/s, l2_loss: 0.1579 - round_loss:\u001b[A\n",
      "Training:   2%| | 841/40960 [00:06<02:43, 246.03batches/s, l2_loss: 0.1563 - round_loss:\u001b[A\n",
      "Training:   2%| | 900/40960 [00:06<02:34, 259.41batches/s, l2_loss: 0.1563 - round_loss:\u001b[A\n",
      "Training:   2%| | 900/40960 [00:06<02:34, 259.41batches/s, l2_loss: 0.1558 - round_loss:\u001b[A\n",
      "Training:   2%| | 961/40960 [00:06<02:26, 272.30batches/s, l2_loss: 0.1558 - round_loss:\u001b[A\n",
      "Training:   2%| | 961/40960 [00:06<02:26, 272.30batches/s, l2_loss: 0.1555 - round_loss:\u001b[A\n",
      "Training:   2%| | 1022/40960 [00:06<02:21, 281.90batches/s, l2_loss: 0.1555 - round_loss\u001b[A\n",
      "Training:   2%| | 1022/40960 [00:06<02:21, 281.90batches/s, l2_loss: 0.1544 - round_loss\u001b[A\n",
      "Training:   3%| | 1072/40960 [00:06<02:27, 270.90batches/s, l2_loss: 0.1544 - round_loss\u001b[A\n",
      "Training:   3%| | 1072/40960 [00:06<02:27, 270.90batches/s, l2_loss: 0.1530 - round_loss\u001b[A\n",
      "Training:   3%| | 1132/40960 [00:07<02:22, 279.18batches/s, l2_loss: 0.1530 - round_loss\u001b[A\n",
      "Training:   3%| | 1132/40960 [00:07<02:22, 279.18batches/s, l2_loss: 0.1527 - round_loss\u001b[A\n",
      "Training:   3%| | 1191/40960 [00:07<02:20, 282.63batches/s, l2_loss: 0.1527 - round_loss\u001b[A\n",
      "Training:   3%| | 1191/40960 [00:07<02:20, 282.63batches/s, l2_loss: 0.1519 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%| | 1245/40960 [00:07<02:22, 278.79batches/s, l2_loss: 0.1519 - round_loss\u001b[A\n",
      "Training:   3%| | 1245/40960 [00:07<02:22, 278.79batches/s, l2_loss: 0.1509 - round_loss\u001b[A\n",
      "Training:   3%| | 1305/40960 [00:07<02:19, 285.11batches/s, l2_loss: 0.1509 - round_loss\u001b[A\n",
      "Training:   3%| | 1305/40960 [00:07<02:19, 285.11batches/s, l2_loss: 0.1516 - round_loss\u001b[A\n",
      "Training:   3%| | 1367/40960 [00:07<02:15, 291.68batches/s, l2_loss: 0.1516 - round_loss\u001b[A\n",
      "Training:   3%| | 1367/40960 [00:07<02:15, 291.68batches/s, l2_loss: 0.1510 - round_loss\u001b[A\n",
      "Training:   3%| | 1428/40960 [00:08<02:14, 294.62batches/s, l2_loss: 0.1510 - round_loss\u001b[A\n",
      "Training:   3%| | 1428/40960 [00:08<02:14, 294.62batches/s, l2_loss: 0.1504 - round_loss\u001b[A\n",
      "Training:   4%| | 1487/40960 [00:08<02:14, 293.81batches/s, l2_loss: 0.1504 - round_loss\u001b[A\n",
      "Training:   4%| | 1487/40960 [00:08<02:14, 293.81batches/s, l2_loss: 0.1495 - round_loss\u001b[A\n",
      "Training:   4%| | 1546/40960 [00:08<02:14, 294.12batches/s, l2_loss: 0.1495 - round_loss\u001b[A\n",
      "Training:   4%| | 1546/40960 [00:08<02:14, 294.12batches/s, l2_loss: 0.1497 - round_loss\u001b[A\n",
      "Training:   4%| | 1610/40960 [00:08<02:10, 301.54batches/s, l2_loss: 0.1497 - round_loss\u001b[A\n",
      "Training:   4%| | 1610/40960 [00:08<02:10, 301.54batches/s, l2_loss: 0.1490 - round_loss\u001b[A\n",
      "Training:   4%| | 1673/40960 [00:08<02:08, 304.75batches/s, l2_loss: 0.1490 - round_loss\u001b[A\n",
      "Training:   4%| | 1673/40960 [00:08<02:08, 304.75batches/s, l2_loss: 0.1490 - round_loss\u001b[A\n",
      "Training:   4%| | 1734/40960 [00:09<02:09, 303.76batches/s, l2_loss: 0.1490 - round_loss\u001b[A\n",
      "Training:   4%| | 1734/40960 [00:09<02:09, 303.76batches/s, l2_loss: 0.1487 - round_loss\u001b[A\n",
      "Training:   4%| | 1787/40960 [00:09<02:14, 291.18batches/s, l2_loss: 0.1487 - round_loss\u001b[A\n",
      "Training:   4%| | 1787/40960 [00:09<02:14, 291.18batches/s, l2_loss: 0.1484 - round_loss\u001b[A\n",
      "Training:   5%| | 1847/40960 [00:09<02:13, 293.45batches/s, l2_loss: 0.1484 - round_loss\u001b[A\n",
      "Training:   5%| | 1847/40960 [00:09<02:13, 293.45batches/s, l2_loss: 0.1484 - round_loss\u001b[A\n",
      "Training:   5%| | 1901/40960 [00:09<02:16, 285.29batches/s, l2_loss: 0.1484 - round_loss\u001b[A\n",
      "Training:   5%| | 1901/40960 [00:09<02:16, 285.29batches/s, l2_loss: 0.1480 - round_loss\u001b[A\n",
      "Training:   5%| | 1939/40960 [00:09<02:32, 256.09batches/s, l2_loss: 0.1480 - round_loss\u001b[A\n",
      "Training:   5%| | 1939/40960 [00:09<02:32, 256.09batches/s, l2_loss: 0.1475 - round_loss\u001b[A\n",
      "Training:   5%| | 1990/40960 [00:10<02:32, 254.88batches/s, l2_loss: 0.1475 - round_loss\u001b[A\n",
      "Training:   5%| | 1990/40960 [00:10<02:32, 254.88batches/s, l2_loss: 0.1474 - round_loss\u001b[A\n",
      "Training:   5%| | 2043/40960 [00:10<02:31, 257.56batches/s, l2_loss: 0.1474 - round_loss\u001b[A\n",
      "Training:   5%| | 2043/40960 [00:10<02:31, 257.56batches/s, l2_loss: 0.1470 - round_loss\u001b[A\n",
      "Training:   5%| | 2094/40960 [00:10<02:32, 255.50batches/s, l2_loss: 0.1470 - round_loss\u001b[A\n",
      "Training:   5%| | 2094/40960 [00:10<02:32, 255.50batches/s, l2_loss: 0.1468 - round_loss\u001b[A\n",
      "Training:   5%| | 2146/40960 [00:10<02:32, 255.29batches/s, l2_loss: 0.1468 - round_loss\u001b[A\n",
      "Training:   5%| | 2146/40960 [00:10<02:32, 255.29batches/s, l2_loss: 0.1466 - round_loss\u001b[A\n",
      "Training:   5%| | 2189/40960 [00:10<02:39, 242.38batches/s, l2_loss: 0.1466 - round_loss\u001b[A\n",
      "Training:   5%| | 2189/40960 [00:10<02:39, 242.38batches/s, l2_loss: 0.1463 - round_loss\u001b[A\n",
      "Training:   5%| | 2247/40960 [00:11<02:30, 256.48batches/s, l2_loss: 0.1463 - round_loss\u001b[A\n",
      "Training:   5%| | 2247/40960 [00:11<02:30, 256.48batches/s, l2_loss: 0.1460 - round_loss\u001b[A\n",
      "Training:   6%| | 2294/40960 [00:11<02:35, 249.11batches/s, l2_loss: 0.1460 - round_loss\u001b[A\n",
      "Training:   6%| | 2294/40960 [00:11<02:35, 249.11batches/s, l2_loss: 0.1458 - round_loss\u001b[A\n",
      "Training:   6%| | 2331/40960 [00:11<02:48, 229.73batches/s, l2_loss: 0.1458 - round_loss\u001b[A\n",
      "Training:   6%| | 2331/40960 [00:11<02:48, 229.73batches/s, l2_loss: 0.1456 - round_loss\u001b[A\n",
      "Training:   6%| | 2389/40960 [00:11<02:36, 247.04batches/s, l2_loss: 0.1456 - round_loss\u001b[A\n",
      "Training:   6%| | 2389/40960 [00:11<02:36, 247.04batches/s, l2_loss: 0.1456 - round_loss\u001b[A\n",
      "Training:   6%| | 2453/40960 [00:11<02:23, 267.81batches/s, l2_loss: 0.1456 - round_loss\u001b[A\n",
      "Training:   6%| | 2453/40960 [00:11<02:23, 267.81batches/s, l2_loss: 0.1451 - round_loss\u001b[A\n",
      "Training:   6%| | 2511/40960 [00:12<02:20, 273.37batches/s, l2_loss: 0.1451 - round_loss\u001b[A\n",
      "Training:   6%| | 2511/40960 [00:12<02:20, 273.37batches/s, l2_loss: 0.1450 - round_loss\u001b[A\n",
      "Training:   6%| | 2571/40960 [00:12<02:16, 280.86batches/s, l2_loss: 0.1450 - round_loss\u001b[A\n",
      "Training:   6%| | 2571/40960 [00:12<02:16, 280.86batches/s, l2_loss: 0.1447 - round_loss\u001b[A\n",
      "Training:   6%| | 2630/40960 [00:12<02:14, 284.89batches/s, l2_loss: 0.1447 - round_loss\u001b[A\n",
      "Training:   6%| | 2630/40960 [00:12<02:14, 284.89batches/s, l2_loss: 0.1450 - round_loss\u001b[A\n",
      "Training:   7%| | 2673/40960 [00:12<02:25, 262.37batches/s, l2_loss: 0.1450 - round_loss\u001b[A\n",
      "Training:   7%| | 2673/40960 [00:12<02:25, 262.37batches/s, l2_loss: 0.1446 - round_loss\u001b[A\n",
      "Training:   7%| | 2711/40960 [00:12<02:39, 240.15batches/s, l2_loss: 0.1446 - round_loss\u001b[A\n",
      "Training:   7%| | 2711/40960 [00:12<02:39, 240.15batches/s, l2_loss: 0.1441 - round_loss\u001b[A\n",
      "Training:   7%| | 2754/40960 [00:13<02:44, 232.03batches/s, l2_loss: 0.1441 - round_loss\u001b[A\n",
      "Training:   7%| | 2754/40960 [00:13<02:44, 232.03batches/s, l2_loss: 0.1443 - round_loss\u001b[A\n",
      "Training:   7%| | 2811/40960 [00:13<02:34, 246.47batches/s, l2_loss: 0.1443 - round_loss\u001b[A\n",
      "Training:   7%| | 2811/40960 [00:13<02:34, 246.47batches/s, l2_loss: 0.1441 - round_loss\u001b[A\n",
      "Training:   7%| | 2873/40960 [00:13<02:23, 264.82batches/s, l2_loss: 0.1441 - round_loss\u001b[A\n",
      "Training:   7%| | 2873/40960 [00:13<02:23, 264.82batches/s, l2_loss: 0.1435 - round_loss\u001b[A\n",
      "Training:   7%| | 2932/40960 [00:13<02:19, 272.56batches/s, l2_loss: 0.1435 - round_loss\u001b[A\n",
      "Training:   7%| | 2932/40960 [00:13<02:19, 272.56batches/s, l2_loss: 0.1434 - round_loss\u001b[A\n",
      "Training:   7%| | 2971/40960 [00:13<02:33, 247.63batches/s, l2_loss: 0.1434 - round_loss\u001b[A\n",
      "Training:   7%| | 2971/40960 [00:13<02:33, 247.63batches/s, l2_loss: 0.1434 - round_loss\u001b[A\n",
      "Training:   7%| | 3014/40960 [00:14<02:39, 237.82batches/s, l2_loss: 0.1434 - round_loss\u001b[A\n",
      "Training:   7%| | 3014/40960 [00:14<02:39, 237.82batches/s, l2_loss: 0.1433 - round_loss\u001b[A\n",
      "Training:   7%| | 3052/40960 [00:14<02:50, 222.93batches/s, l2_loss: 0.1433 - round_loss\u001b[A\n",
      "Training:   7%| | 3052/40960 [00:14<02:50, 222.93batches/s, l2_loss: 0.1434 - round_loss\u001b[A\n",
      "Training:   8%| | 3098/40960 [00:14<02:48, 224.90batches/s, l2_loss: 0.1434 - round_loss\u001b[A\n",
      "Training:   8%| | 3098/40960 [00:14<02:48, 224.90batches/s, l2_loss: 0.1431 - round_loss\u001b[A\n",
      "Training:   8%| | 3151/40960 [00:14<02:40, 235.91batches/s, l2_loss: 0.1431 - round_loss\u001b[A\n",
      "Training:   8%| | 3151/40960 [00:14<02:40, 235.91batches/s, l2_loss: 0.1432 - round_loss\u001b[A\n",
      "Training:   8%| | 3191/40960 [00:14<02:47, 224.86batches/s, l2_loss: 0.1432 - round_loss\u001b[A\n",
      "Training:   8%| | 3191/40960 [00:14<02:47, 224.86batches/s, l2_loss: 0.1430 - round_loss\u001b[A\n",
      "Training:   8%| | 3232/40960 [00:15<02:52, 218.47batches/s, l2_loss: 0.1430 - round_loss\u001b[A\n",
      "Training:   8%| | 3232/40960 [00:15<02:52, 218.47batches/s, l2_loss: 0.1429 - round_loss\u001b[A\n",
      "Training:   8%| | 3292/40960 [00:15<02:35, 242.05batches/s, l2_loss: 0.1429 - round_loss\u001b[A\n",
      "Training:   8%| | 3292/40960 [00:15<02:35, 242.05batches/s, l2_loss: 0.1425 - round_loss\u001b[A\n",
      "Training:   8%| | 3351/40960 [00:15<02:26, 256.13batches/s, l2_loss: 0.1425 - round_loss\u001b[A\n",
      "Training:   8%| | 3351/40960 [00:15<02:26, 256.13batches/s, l2_loss: 0.1424 - round_loss\u001b[A\n",
      "Training:   8%| | 3391/40960 [00:15<02:36, 239.42batches/s, l2_loss: 0.1424 - round_loss\u001b[A\n",
      "Training:   8%| | 3391/40960 [00:15<02:36, 239.42batches/s, l2_loss: 0.1426 - round_loss\u001b[A\n",
      "Training:   8%| | 3434/40960 [00:15<02:42, 231.58batches/s, l2_loss: 0.1426 - round_loss\u001b[A\n",
      "Training:   8%| | 3434/40960 [00:15<02:42, 231.58batches/s, l2_loss: 0.1424 - round_loss\u001b[A\n",
      "Training:   8%| | 3470/40960 [00:16<02:54, 214.82batches/s, l2_loss: 0.1424 - round_loss\u001b[A\n",
      "Training:   8%| | 3470/40960 [00:16<02:54, 214.82batches/s, l2_loss: 0.1421 - round_loss\u001b[A\n",
      "Training:   9%| | 3517/40960 [00:16<02:49, 220.67batches/s, l2_loss: 0.1421 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%| | 3517/40960 [00:16<02:49, 220.67batches/s, l2_loss: 0.1421 - round_loss\u001b[A\n",
      "Training:   9%| | 3580/40960 [00:16<02:31, 247.55batches/s, l2_loss: 0.1421 - round_loss\u001b[A\n",
      "Training:   9%| | 3580/40960 [00:16<02:31, 247.55batches/s, l2_loss: 0.1420 - round_loss\u001b[A\n",
      "Training:   9%| | 3644/40960 [00:16<02:19, 267.92batches/s, l2_loss: 0.1420 - round_loss\u001b[A\n",
      "Training:   9%| | 3644/40960 [00:16<02:19, 267.92batches/s, l2_loss: 0.1419 - round_loss\u001b[A\n",
      "Training:   9%| | 3702/40960 [00:16<02:16, 273.02batches/s, l2_loss: 0.1419 - round_loss\u001b[A\n",
      "Training:   9%| | 3702/40960 [00:16<02:16, 273.02batches/s, l2_loss: 0.1417 - round_loss\u001b[A\n",
      "Training:   9%| | 3754/40960 [00:17<02:18, 268.27batches/s, l2_loss: 0.1417 - round_loss\u001b[A\n",
      "Training:   9%| | 3754/40960 [00:17<02:18, 268.27batches/s, l2_loss: 0.1417 - round_loss\u001b[A\n",
      "Training:   9%| | 3814/40960 [00:17<02:13, 277.33batches/s, l2_loss: 0.1417 - round_loss\u001b[A\n",
      "Training:   9%| | 3814/40960 [00:17<02:13, 277.33batches/s, l2_loss: 0.1416 - round_loss\u001b[A\n",
      "Training:   9%| | 3873/40960 [00:17<02:11, 282.16batches/s, l2_loss: 0.1416 - round_loss\u001b[A\n",
      "Training:   9%| | 3873/40960 [00:17<02:11, 282.16batches/s, l2_loss: 0.1414 - round_loss\u001b[A\n",
      "Training:  10%| | 3932/40960 [00:17<02:10, 284.69batches/s, l2_loss: 0.1414 - round_loss\u001b[A\n",
      "Training:  10%| | 3932/40960 [00:17<02:10, 284.69batches/s, l2_loss: 0.1413 - round_loss\u001b[A\n",
      "Training:  10%| | 3990/40960 [00:17<02:09, 285.25batches/s, l2_loss: 0.1413 - round_loss\u001b[A\n",
      "Training:  10%| | 3990/40960 [00:17<02:09, 285.25batches/s, l2_loss: 0.1410 - round_loss\u001b[A\n",
      "Training:  10%| | 4047/40960 [00:18<02:10, 283.75batches/s, l2_loss: 0.1410 - round_loss\u001b[A\n",
      "Training:  10%| | 4047/40960 [00:18<02:10, 283.75batches/s, l2_loss: 0.1411 - round_loss\u001b[A\n",
      "Training:  10%| | 4108/40960 [00:18<02:07, 289.90batches/s, l2_loss: 0.1411 - round_loss\u001b[A\n",
      "Training:  10%| | 4108/40960 [00:18<02:07, 289.90batches/s, l2_loss: 0.1408 - round_loss\u001b[A\n",
      "Training:  10%| | 4172/40960 [00:18<02:03, 297.44batches/s, l2_loss: 0.1408 - round_loss\u001b[A\n",
      "Training:  10%| | 4172/40960 [00:18<02:03, 297.44batches/s, l2_loss: 0.1407 - round_loss\u001b[A\n",
      "Training:  10%| | 4233/40960 [00:18<02:03, 298.55batches/s, l2_loss: 0.1407 - round_loss\u001b[A\n",
      "Training:  10%| | 4233/40960 [00:18<02:03, 298.55batches/s, l2_loss: 0.1407 - round_loss\u001b[A\n",
      "Training:  10%| | 4290/40960 [00:18<02:04, 293.89batches/s, l2_loss: 0.1407 - round_loss\u001b[A\n",
      "Training:  10%| | 4290/40960 [00:18<02:04, 293.89batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4350/40960 [00:19<02:04, 295.21batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4350/40960 [00:19<02:04, 295.21batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4408/40960 [00:19<02:04, 292.69batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4408/40960 [00:19<02:04, 292.69batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4469/40960 [00:19<02:03, 295.57batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4469/40960 [00:19<02:03, 295.57batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4508/40960 [00:19<02:17, 264.94batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4508/40960 [00:19<02:17, 264.94batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4547/40960 [00:19<02:29, 242.99batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:  11%| | 4547/40960 [00:19<02:29, 242.99batches/s, l2_loss: 0.1402 - round_loss\u001b[A\n",
      "Training:  11%| | 4586/40960 [00:20<02:39, 228.22batches/s, l2_loss: 0.1402 - round_loss\u001b[A\n",
      "Training:  11%| | 4586/40960 [00:20<02:39, 228.22batches/s, l2_loss: 0.1399 - round_loss\u001b[A\n",
      "Training:  11%| | 4626/40960 [00:20<02:46, 218.67batches/s, l2_loss: 0.1399 - round_loss\u001b[A\n",
      "Training:  11%| | 4626/40960 [00:20<02:46, 218.67batches/s, l2_loss: 0.1399 - round_loss\u001b[A\n",
      "Training:  11%| | 4665/40960 [00:20<02:51, 211.40batches/s, l2_loss: 0.1399 - round_loss\u001b[A\n",
      "Training:  11%| | 4665/40960 [00:20<02:51, 211.40batches/s, l2_loss: 0.1400 - round_loss\u001b[A\n",
      "Training:  11%| | 4701/40960 [00:20<02:59, 201.73batches/s, l2_loss: 0.1400 - round_loss\u001b[A\n",
      "Training:  11%| | 4701/40960 [00:20<02:59, 201.73batches/s, l2_loss: 0.1400 - round_loss\u001b[A\n",
      "Training:  12%| | 4757/40960 [00:20<02:40, 225.04batches/s, l2_loss: 0.1400 - round_loss\u001b[A\n",
      "Training:  12%| | 4757/40960 [00:20<02:40, 225.04batches/s, l2_loss: 0.1397 - round_loss\u001b[A\n",
      "Training:  12%| | 4815/40960 [00:21<02:28, 244.07batches/s, l2_loss: 0.1397 - round_loss\u001b[A\n",
      "Training:  12%| | 4815/40960 [00:21<02:28, 244.07batches/s, l2_loss: 0.1394 - round_loss\u001b[A\n",
      "Training:  12%| | 4872/40960 [00:21<02:21, 255.71batches/s, l2_loss: 0.1394 - round_loss\u001b[A\n",
      "Training:  12%| | 4872/40960 [00:21<02:21, 255.71batches/s, l2_loss: 0.1396 - round_loss\u001b[A\n",
      "Training:  12%| | 4921/40960 [00:21<02:23, 251.17batches/s, l2_loss: 0.1396 - round_loss\u001b[A\n",
      "Training:  12%| | 4921/40960 [00:21<02:23, 251.17batches/s, l2_loss: 0.1393 - round_loss\u001b[A\n",
      "Training:  12%| | 4959/40960 [00:21<02:35, 232.15batches/s, l2_loss: 0.1393 - round_loss\u001b[A\n",
      "Training:  12%| | 4959/40960 [00:21<02:35, 232.15batches/s, l2_loss: 0.1394 - round_loss\u001b[A\n",
      "Training:  12%| | 5010/40960 [00:21<02:30, 238.63batches/s, l2_loss: 0.1394 - round_loss\u001b[A\n",
      "Training:  12%| | 5010/40960 [00:21<02:30, 238.63batches/s, l2_loss: 0.1393 - round_loss\u001b[A\n",
      "Training:  12%| | 5070/40960 [00:22<02:19, 256.63batches/s, l2_loss: 0.1393 - round_loss\u001b[A\n",
      "Training:  12%| | 5070/40960 [00:22<02:19, 256.63batches/s, l2_loss: 0.1395 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5126/40960 [00:22<02:16, 262.92batches/s, l2_loss: 0.1395 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5126/40960 [00:22<02:16, 262.92batches/s, l2_loss: 0.1392 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5168/40960 [00:22<02:25, 246.05batches/s, l2_loss: 0.1392 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5168/40960 [00:22<02:25, 246.05batches/s, l2_loss: 0.1392 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5220/40960 [00:22<02:23, 249.65batches/s, l2_loss: 0.1392 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5220/40960 [00:22<02:23, 249.65batches/s, l2_loss: 0.1392 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5283/40960 [00:22<02:12, 268.56batches/s, l2_loss: 0.1392 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5283/40960 [00:22<02:12, 268.56batches/s, l2_loss: 0.1390 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5340/40960 [00:23<02:10, 273.03batches/s, l2_loss: 0.1390 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5340/40960 [00:23<02:10, 273.03batches/s, l2_loss: 0.1388 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5402/40960 [00:23<02:05, 284.03batches/s, l2_loss: 0.1388 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5402/40960 [00:23<02:05, 284.03batches/s, l2_loss: 0.1388 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5463/40960 [00:23<02:02, 289.30batches/s, l2_loss: 0.1388 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5463/40960 [00:23<02:02, 289.30batches/s, l2_loss: 0.1388 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5525/40960 [00:23<02:00, 294.25batches/s, l2_loss: 0.1388 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5525/40960 [00:23<02:00, 294.25batches/s, l2_loss: 0.1390 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5584/40960 [00:23<02:00, 293.36batches/s, l2_loss: 0.1390 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5584/40960 [00:24<02:00, 293.36batches/s, l2_loss: 0.1388 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5641/40960 [00:24<02:01, 289.70batches/s, l2_loss: 0.1388 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5641/40960 [00:24<02:01, 289.70batches/s, l2_loss: 0.1386 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5700/40960 [00:24<02:01, 290.62batches/s, l2_loss: 0.1386 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5700/40960 [00:24<02:01, 290.62batches/s, l2_loss: 0.1385 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5757/40960 [00:24<02:01, 288.73batches/s, l2_loss: 0.1385 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5757/40960 [00:24<02:01, 288.73batches/s, l2_loss: 0.1385 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5817/40960 [00:24<02:00, 290.98batches/s, l2_loss: 0.1385 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5817/40960 [00:24<02:00, 290.98batches/s, l2_loss: 0.1383 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5880/40960 [00:25<01:57, 297.70batches/s, l2_loss: 0.1383 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5880/40960 [00:25<01:57, 297.70batches/s, l2_loss: 0.1382 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5933/40960 [00:25<02:02, 285.83batches/s, l2_loss: 0.1382 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5933/40960 [00:25<02:02, 285.83batches/s, l2_loss: 0.1383 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 5971/40960 [00:25<02:16, 256.44batches/s, l2_loss: 0.1383 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5971/40960 [00:25<02:16, 256.44batches/s, l2_loss: 0.1382 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6022/40960 [00:25<02:16, 255.58batches/s, l2_loss: 0.1382 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6022/40960 [00:25<02:16, 255.58batches/s, l2_loss: 0.1381 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6060/40960 [00:25<02:28, 234.91batches/s, l2_loss: 0.1381 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6060/40960 [00:25<02:28, 234.91batches/s, l2_loss: 0.1380 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6113/40960 [00:26<02:23, 243.57batches/s, l2_loss: 0.1380 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6113/40960 [00:26<02:23, 243.57batches/s, l2_loss: 0.1381 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6175/40960 [00:26<02:12, 262.52batches/s, l2_loss: 0.1381 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6175/40960 [00:26<02:12, 262.52batches/s, l2_loss: 0.1380 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6237/40960 [00:26<02:05, 276.44batches/s, l2_loss: 0.1380 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6237/40960 [00:26<02:05, 276.44batches/s, l2_loss: 0.1379 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6278/40960 [00:26<02:16, 254.19batches/s, l2_loss: 0.1379 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6278/40960 [00:26<02:16, 254.19batches/s, l2_loss: 0.1379 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6328/40960 [00:26<02:17, 252.73batches/s, l2_loss: 0.1379 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6328/40960 [00:26<02:17, 252.73batches/s, l2_loss: 0.1379 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6388/40960 [00:27<02:09, 266.50batches/s, l2_loss: 0.1379 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6388/40960 [00:27<02:09, 266.50batches/s, l2_loss: 0.1378 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6446/40960 [00:27<02:06, 272.76batches/s, l2_loss: 0.1378 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6446/40960 [00:27<02:06, 272.76batches/s, l2_loss: 0.1377 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6486/40960 [00:27<02:18, 249.53batches/s, l2_loss: 0.1377 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6486/40960 [00:27<02:18, 249.53batches/s, l2_loss: 0.1377 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6540/40960 [00:27<02:14, 255.38batches/s, l2_loss: 0.1377 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6540/40960 [00:27<02:14, 255.38batches/s, l2_loss: 0.1376 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6578/40960 [00:27<02:25, 235.74batches/s, l2_loss: 0.1376 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6578/40960 [00:27<02:25, 235.74batches/s, l2_loss: 0.1376 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6633/40960 [00:28<02:18, 247.13batches/s, l2_loss: 0.1376 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6633/40960 [00:28<02:18, 247.13batches/s, l2_loss: 0.1376 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6696/40960 [00:28<02:08, 267.25batches/s, l2_loss: 0.1376 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6696/40960 [00:28<02:08, 267.25batches/s, l2_loss: 0.1374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6754/40960 [00:28<02:05, 273.62batches/s, l2_loss: 0.1374 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6754/40960 [00:28<02:05, 273.62batches/s, l2_loss: 0.1373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6795/40960 [00:28<02:15, 251.87batches/s, l2_loss: 0.1373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6795/40960 [00:28<02:15, 251.87batches/s, l2_loss: 0.1374 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6835/40960 [00:28<02:24, 235.89batches/s, l2_loss: 0.1374 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6835/40960 [00:28<02:24, 235.89batches/s, l2_loss: 0.1373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6882/40960 [00:29<02:24, 235.32batches/s, l2_loss: 0.1373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6882/40960 [00:29<02:24, 235.32batches/s, l2_loss: 0.1373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6936/40960 [00:29<02:18, 244.96batches/s, l2_loss: 0.1373 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6936/40960 [00:29<02:18, 244.96batches/s, l2_loss: 0.1372 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6983/40960 [00:29<02:21, 240.67batches/s, l2_loss: 0.1372 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6983/40960 [00:29<02:21, 240.67batches/s, l2_loss: 0.1374 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7023/40960 [00:29<02:28, 228.19batches/s, l2_loss: 0.1374 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7023/40960 [00:29<02:28, 228.19batches/s, l2_loss: 0.1372 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7070/40960 [00:29<02:27, 229.61batches/s, l2_loss: 0.1372 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7070/40960 [00:29<02:27, 229.61batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7111/40960 [00:30<02:32, 221.81batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7111/40960 [00:30<02:32, 221.81batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7152/40960 [00:30<02:37, 214.73batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7152/40960 [00:30<02:37, 214.73batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7195/40960 [00:30<02:37, 214.35batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7195/40960 [00:30<02:37, 214.35batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7259/40960 [00:30<02:17, 244.64batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7259/40960 [00:30<02:17, 244.64batches/s, l2_loss: 0.1369 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7319/40960 [00:30<02:09, 260.25batches/s, l2_loss: 0.1369 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7319/40960 [00:30<02:09, 260.25batches/s, l2_loss: 0.1369 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7359/40960 [00:31<02:18, 241.76batches/s, l2_loss: 0.1369 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7359/40960 [00:31<02:18, 241.76batches/s, l2_loss: 0.1368 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7410/40960 [00:31<02:16, 244.98batches/s, l2_loss: 0.1368 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7410/40960 [00:31<02:16, 244.98batches/s, l2_loss: 0.1369 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:31<02:10, 255.69batches/s, l2_loss: 0.1369 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:31<02:10, 255.69batches/s, l2_loss: 0.1368 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7507/40960 [00:31<02:20, 238.92batches/s, l2_loss: 0.1368 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7507/40960 [00:31<02:20, 238.92batches/s, l2_loss: 0.1368 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7545/40960 [00:31<02:29, 223.42batches/s, l2_loss: 0.1368 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7545/40960 [00:31<02:29, 223.42batches/s, l2_loss: 0.1368 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7585/40960 [00:32<02:34, 215.33batches/s, l2_loss: 0.1368 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7585/40960 [00:32<02:34, 215.33batches/s, l2_loss: 0.1367 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7628/40960 [00:32<02:35, 214.43batches/s, l2_loss: 0.1367 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7628/40960 [00:32<02:35, 214.43batches/s, l2_loss: 0.1366 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7692/40960 [00:32<02:15, 245.79batches/s, l2_loss: 0.1366 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7692/40960 [00:32<02:15, 245.79batches/s, l2_loss: 0.1366 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7754/40960 [00:32<02:05, 264.88batches/s, l2_loss: 0.1366 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7754/40960 [00:32<02:05, 264.88batches/s, l2_loss: 0.1365 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7797/40960 [00:32<02:12, 249.61batches/s, l2_loss: 0.1365 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7797/40960 [00:32<02:12, 249.61batches/s, l2_loss: 0.1366 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7860/40960 [00:33<02:03, 268.18batches/s, l2_loss: 0.1366 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7860/40960 [00:33<02:03, 268.18batches/s, l2_loss: 0.1364 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7898/40960 [00:33<02:15, 243.13batches/s, l2_loss: 0.1364 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7898/40960 [00:33<02:15, 243.13batches/s, l2_loss: 0.1366 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7937/40960 [00:33<02:25, 227.71batches/s, l2_loss: 0.1366 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7937/40960 [00:33<02:25, 227.71batches/s, l2_loss: 0.1365 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7993/40960 [00:33<02:15, 242.63batches/s, l2_loss: 0.1365 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7993/40960 [00:33<02:15, 242.63batches/s, l2_loss: 0.1365 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8053/40960 [00:33<02:07, 258.28batches/s, l2_loss: 0.1365 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8053/40960 [00:33<02:07, 258.28batches/s, l2_loss: 0.1364 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8113/40960 [00:34<02:01, 269.99batches/s, l2_loss: 0.1364 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8113/40960 [00:34<02:01, 269.99batches/s, l2_loss: 0.1363 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8160/40960 [00:34<02:06, 258.31batches/s, l2_loss: 0.1363 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 8160/40960 [00:34<02:06, 258.31batches/s, l2_loss: 0.1363 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8197/40960 [00:34<02:19, 235.20batches/s, l2_loss: 0.1363 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8197/40960 [00:34<02:19, 235.20batches/s, l2_loss: 0.2281 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8243/40960 [00:34<02:20, 233.57batches/s, l2_loss: 0.2281 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8243/40960 [00:34<02:20, 233.57batches/s, l2_loss: 0.1249 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8280/40960 [00:34<02:30, 217.84batches/s, l2_loss: 0.1249 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8280/40960 [00:34<02:30, 217.84batches/s, l2_loss: 0.1334 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8316/40960 [00:35<02:38, 205.51batches/s, l2_loss: 0.1334 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8316/40960 [00:35<02:38, 205.51batches/s, l2_loss: 0.1327 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8350/40960 [00:35<02:47, 194.53batches/s, l2_loss: 0.1327 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8350/40960 [00:35<02:47, 194.53batches/s, l2_loss: 0.1285 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8399/40960 [00:35<02:35, 208.80batches/s, l2_loss: 0.1285 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8399/40960 [00:35<02:35, 208.80batches/s, l2_loss: 0.1309 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8448/40960 [00:35<02:28, 218.91batches/s, l2_loss: 0.1309 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8448/40960 [00:35<02:28, 218.91batches/s, l2_loss: 0.1327 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8492/40960 [00:35<02:28, 219.00batches/s, l2_loss: 0.1327 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8492/40960 [00:35<02:28, 219.00batches/s, l2_loss: 0.1325 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8529/40960 [00:36<02:36, 207.55batches/s, l2_loss: 0.1325 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8529/40960 [00:36<02:36, 207.55batches/s, l2_loss: 0.1329 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8565/40960 [00:36<02:43, 198.52batches/s, l2_loss: 0.1329 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8565/40960 [00:36<02:43, 198.52batches/s, l2_loss: 0.1332 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8616/40960 [00:36<02:30, 215.05batches/s, l2_loss: 0.1332 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8616/40960 [00:36<02:30, 215.05batches/s, l2_loss: 0.1337 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8669/40960 [00:36<02:20, 229.38batches/s, l2_loss: 0.1337 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8669/40960 [00:36<02:20, 229.38batches/s, l2_loss: 0.1316 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8721/40960 [00:36<02:15, 237.23batches/s, l2_loss: 0.1316 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8721/40960 [00:36<02:15, 237.23batches/s, l2_loss: 0.1344 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8770/40960 [00:37<02:14, 239.27batches/s, l2_loss: 0.1344 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8770/40960 [00:37<02:14, 239.27batches/s, l2_loss: 0.1356 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8823/40960 [00:37<02:10, 245.83batches/s, l2_loss: 0.1356 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8823/40960 [00:37<02:10, 245.83batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8878/40960 [00:37<02:06, 253.44batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8878/40960 [00:37<02:06, 253.44batches/s, l2_loss: 0.1353 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8938/40960 [00:37<02:00, 266.37batches/s, l2_loss: 0.1353 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8938/40960 [00:37<02:00, 266.37batches/s, l2_loss: 0.1343 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8996/40960 [00:37<01:57, 272.20batches/s, l2_loss: 0.1343 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8996/40960 [00:37<01:57, 272.20batches/s, l2_loss: 0.1343 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9053/40960 [00:38<01:56, 274.86batches/s, l2_loss: 0.1343 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9053/40960 [00:38<01:56, 274.86batches/s, l2_loss: 0.1337 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9113/40960 [00:38<01:52, 282.11batches/s, l2_loss: 0.1337 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9113/40960 [00:38<01:52, 282.11batches/s, l2_loss: 0.1334 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9170/40960 [00:38<01:52, 281.82batches/s, l2_loss: 0.1334 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9170/40960 [00:38<01:52, 281.82batches/s, l2_loss: 0.1327 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9224/40960 [00:38<01:54, 277.42batches/s, l2_loss: 0.1327 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9224/40960 [00:38<01:54, 277.42batches/s, l2_loss: 0.1338 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9279/40960 [00:38<01:54, 276.15batches/s, l2_loss: 0.1338 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9279/40960 [00:38<01:54, 276.15batches/s, l2_loss: 0.1341 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9333/40960 [00:39<01:55, 273.16batches/s, l2_loss: 0.1341 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9333/40960 [00:39<01:55, 273.16batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9391/40960 [00:39<01:54, 276.75batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9391/40960 [00:39<01:54, 276.75batches/s, l2_loss: 0.1346 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9447/40960 [00:39<01:53, 276.97batches/s, l2_loss: 0.1346 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9447/40960 [00:39<01:53, 276.97batches/s, l2_loss: 0.1345 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9502/40960 [00:39<01:54, 274.69batches/s, l2_loss: 0.1345 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9502/40960 [00:39<01:54, 274.69batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9558/40960 [00:39<01:54, 275.01batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9558/40960 [00:39<01:54, 275.01batches/s, l2_loss: 0.1337 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9612/40960 [00:40<01:54, 272.98batches/s, l2_loss: 0.1337 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9612/40960 [00:40<01:54, 272.98batches/s, l2_loss: 0.1339 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9648/40960 [00:40<02:08, 244.55batches/s, l2_loss: 0.1339 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9648/40960 [00:40<02:08, 244.55batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9688/40960 [00:40<02:15, 230.66batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9688/40960 [00:40<02:15, 230.66batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9742/40960 [00:40<02:09, 241.09batches/s, l2_loss: 0.1342 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9742/40960 [00:40<02:09, 241.09batches/s, l2_loss: 0.1341 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9796/40960 [00:40<02:04, 249.39batches/s, l2_loss: 0.1341 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9796/40960 [00:40<02:04, 249.39batches/s, l2_loss: 0.1344 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9853/40960 [00:41<01:59, 259.57batches/s, l2_loss: 0.1344 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9853/40960 [00:41<01:59, 259.57batches/s, l2_loss: 0.1341 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9906/40960 [00:41<01:59, 260.79batches/s, l2_loss: 0.1341 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9906/40960 [00:41<01:59, 260.79batches/s, l2_loss: 0.1339 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9953/40960 [00:41<02:02, 252.75batches/s, l2_loss: 0.1339 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9953/40960 [00:41<02:02, 252.75batches/s, l2_loss: 0.1339 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9996/40960 [00:41<02:08, 240.14batches/s, l2_loss: 0.1339 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9996/40960 [00:41<02:08, 240.14batches/s, l2_loss: 0.1340 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10051/40960 [00:41<02:04, 249.15batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  25%|▏| 10051/40960 [00:41<02:04, 249.15batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  25%|▏| 10105/40960 [00:42<02:01, 253.86batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  25%|▏| 10105/40960 [00:42<02:01, 253.86batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  25%|▏| 10152/40960 [00:42<02:04, 247.25batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  25%|▏| 10152/40960 [00:42<02:04, 247.25batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  25%|▏| 10208/40960 [00:42<01:59, 256.84batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  25%|▏| 10208/40960 [00:42<01:59, 256.84batches/s, l2_loss: 0.1338 - round_los\u001b[A\n",
      "Training:  25%|▎| 10264/40960 [00:42<01:56, 262.41batches/s, l2_loss: 0.1338 - round_los\u001b[A\n",
      "Training:  25%|▎| 10264/40960 [00:42<01:56, 262.41batches/s, l2_loss: 0.1339 - round_los\u001b[A\n",
      "Training:  25%|▎| 10317/40960 [00:43<01:56, 262.14batches/s, l2_loss: 0.1339 - round_los\u001b[A\n",
      "Training:  25%|▎| 10317/40960 [00:43<01:56, 262.14batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  25%|▎| 10376/40960 [00:43<01:52, 270.77batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  25%|▎| 10376/40960 [00:43<01:52, 270.77batches/s, l2_loss: 0.1340 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 10432/40960 [00:43<01:51, 272.58batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  25%|▎| 10432/40960 [00:43<01:51, 272.58batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  26%|▎| 10490/40960 [00:43<01:50, 276.57batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  26%|▎| 10490/40960 [00:43<01:50, 276.57batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  26%|▎| 10549/40960 [00:43<01:47, 281.59batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  26%|▎| 10549/40960 [00:43<01:47, 281.59batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  26%|▎| 10607/40960 [00:44<01:47, 282.24batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  26%|▎| 10607/40960 [00:44<01:47, 282.24batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  26%|▎| 10661/40960 [00:44<01:48, 278.21batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  26%|▎| 10661/40960 [00:44<01:48, 278.21batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  26%|▎| 10719/40960 [00:44<01:47, 281.59batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  26%|▎| 10719/40960 [00:44<01:47, 281.59batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  26%|▎| 10775/40960 [00:44<01:47, 279.79batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  26%|▎| 10775/40960 [00:44<01:47, 279.79batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  26%|▎| 10833/40960 [00:44<01:46, 282.24batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  26%|▎| 10833/40960 [00:44<01:46, 282.24batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  27%|▎| 10891/40960 [00:45<01:46, 283.37batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  27%|▎| 10891/40960 [00:45<01:46, 283.37batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  27%|▎| 10946/40960 [00:45<01:47, 279.23batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  27%|▎| 10946/40960 [00:45<01:47, 279.23batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  27%|▎| 11000/40960 [00:45<01:48, 276.39batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  27%|▎| 11000/40960 [00:45<01:48, 276.39batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  27%|▎| 11049/40960 [00:45<01:52, 266.90batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  27%|▎| 11049/40960 [00:45<01:52, 266.90batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  27%|▎| 11100/40960 [00:45<01:53, 262.88batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  27%|▎| 11100/40960 [00:45<01:53, 262.88batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  27%|▎| 11149/40960 [00:46<01:55, 257.47batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  27%|▎| 11149/40960 [00:46<01:55, 257.47batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  27%|▎| 11208/40960 [00:46<01:50, 268.06batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  27%|▎| 11208/40960 [00:46<01:50, 268.06batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  28%|▎| 11264/40960 [00:46<01:49, 270.46batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  28%|▎| 11264/40960 [00:46<01:49, 270.46batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  28%|▎| 11316/40960 [00:46<01:51, 266.26batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  28%|▎| 11316/40960 [00:46<01:51, 266.26batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  28%|▎| 11368/40960 [00:46<01:51, 264.35batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  28%|▎| 11368/40960 [00:46<01:51, 264.35batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  28%|▎| 11424/40960 [00:47<01:49, 268.69batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  28%|▎| 11424/40960 [00:47<01:49, 268.69batches/s, l2_loss: 0.1339 - round_los\u001b[A\n",
      "Training:  28%|▎| 11481/40960 [00:47<01:48, 272.55batches/s, l2_loss: 0.1339 - round_los\u001b[A\n",
      "Training:  28%|▎| 11481/40960 [00:47<01:48, 272.55batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  28%|▎| 11531/40960 [00:47<01:51, 264.32batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  28%|▎| 11531/40960 [00:47<01:51, 264.32batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  28%|▎| 11581/40960 [00:47<01:53, 259.20batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  28%|▎| 11581/40960 [00:47<01:53, 259.20batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  28%|▎| 11636/40960 [00:47<01:51, 263.12batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  28%|▎| 11636/40960 [00:47<01:51, 263.12batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  29%|▎| 11691/40960 [00:48<01:50, 265.40batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  29%|▎| 11691/40960 [00:48<01:50, 265.40batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  29%|▎| 11745/40960 [00:48<01:50, 264.87batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  29%|▎| 11745/40960 [00:48<01:50, 264.87batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  29%|▎| 11801/40960 [00:48<01:48, 269.14batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  29%|▎| 11801/40960 [00:48<01:48, 269.14batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  29%|▎| 11857/40960 [00:48<01:47, 271.19batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  29%|▎| 11857/40960 [00:48<01:47, 271.19batches/s, l2_loss: 0.1339 - round_los\u001b[A\n",
      "Training:  29%|▎| 11916/40960 [00:48<01:44, 277.37batches/s, l2_loss: 0.1339 - round_los\u001b[A\n",
      "Training:  29%|▎| 11916/40960 [00:48<01:44, 277.37batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  29%|▎| 11973/40960 [00:49<01:44, 278.34batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  29%|▎| 11973/40960 [00:49<01:44, 278.34batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  29%|▎| 12029/40960 [00:49<01:43, 278.68batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  29%|▎| 12029/40960 [00:49<01:43, 278.68batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  30%|▎| 12088/40960 [00:49<01:41, 283.47batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  30%|▎| 12088/40960 [00:49<01:41, 283.47batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  30%|▎| 12136/40960 [00:49<01:47, 269.10batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  30%|▎| 12136/40960 [00:49<01:47, 269.10batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  30%|▎| 12173/40960 [00:49<01:58, 242.08batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  30%|▎| 12173/40960 [00:49<01:58, 242.08batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  30%|▎| 12213/40960 [00:50<02:05, 228.43batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  30%|▎| 12213/40960 [00:50<02:05, 228.43batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  30%|▎| 12250/40960 [00:50<02:14, 214.25batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  30%|▎| 12250/40960 [00:50<02:14, 214.25batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  30%|▎| 12287/40960 [00:50<02:19, 205.48batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  30%|▎| 12287/40960 [00:50<02:19, 205.48batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  30%|▎| 12335/40960 [00:50<02:13, 215.08batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  30%|▎| 12335/40960 [00:50<02:13, 215.08batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  30%|▎| 12394/40960 [00:50<01:59, 238.19batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  30%|▎| 12394/40960 [00:50<01:59, 238.19batches/s, l2_loss: 0.1339 - round_los\u001b[A\n",
      "Training:  30%|▎| 12432/40960 [00:51<02:08, 222.39batches/s, l2_loss: 0.1339 - round_los\u001b[A\n",
      "Training:  30%|▎| 12432/40960 [00:51<02:08, 222.39batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  30%|▎| 12468/40960 [00:51<02:15, 209.73batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  30%|▎| 12468/40960 [00:51<02:15, 209.73batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12504/40960 [00:51<02:21, 200.75batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12504/40960 [00:51<02:21, 200.75batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  31%|▎| 12544/40960 [00:51<02:22, 199.43batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  31%|▎| 12544/40960 [00:51<02:22, 199.43batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12579/40960 [00:51<02:28, 191.59batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12579/40960 [00:51<02:28, 191.59batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  31%|▎| 12617/40960 [00:52<02:28, 191.08batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  31%|▎| 12617/40960 [00:52<02:28, 191.08batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12669/40960 [00:52<02:14, 211.01batches/s, l2_loss: 0.1342 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|▎| 12669/40960 [00:52<02:14, 211.01batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12704/40960 [00:52<02:21, 199.82batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12704/40960 [00:52<02:21, 199.82batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12755/40960 [00:52<02:10, 215.43batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12755/40960 [00:52<02:10, 215.43batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  31%|▎| 12796/40960 [00:52<02:13, 211.22batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  31%|▎| 12796/40960 [00:52<02:13, 211.22batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12832/40960 [00:53<02:19, 201.32batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12832/40960 [00:53<02:19, 201.32batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12866/40960 [00:53<02:26, 191.32batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  31%|▎| 12866/40960 [00:53<02:26, 191.32batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  31%|▎| 12902/40960 [00:53<02:29, 187.61batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  31%|▎| 12902/40960 [00:53<02:29, 187.61batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  32%|▎| 12949/40960 [00:53<02:19, 201.00batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  32%|▎| 12949/40960 [00:53<02:19, 201.00batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  32%|▎| 13009/40960 [00:53<02:01, 230.19batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  32%|▎| 13009/40960 [00:53<02:01, 230.19batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  32%|▎| 13055/40960 [00:54<02:01, 229.73batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  32%|▎| 13055/40960 [00:54<02:01, 229.73batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  32%|▎| 13093/40960 [00:54<02:08, 217.51batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  32%|▎| 13093/40960 [00:54<02:08, 217.51batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  32%|▎| 13143/40960 [00:54<02:03, 225.27batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  32%|▎| 13143/40960 [00:54<02:03, 225.27batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  32%|▎| 13188/40960 [00:54<02:03, 224.24batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  32%|▎| 13188/40960 [00:54<02:03, 224.24batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  32%|▎| 13243/40960 [00:54<01:56, 238.93batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  32%|▎| 13243/40960 [00:54<01:56, 238.93batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  32%|▎| 13300/40960 [00:55<01:49, 251.68batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  32%|▎| 13300/40960 [00:55<01:49, 251.68batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  33%|▎| 13359/40960 [00:55<01:44, 263.69batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  33%|▎| 13359/40960 [00:55<01:44, 263.69batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  33%|▎| 13413/40960 [00:55<01:43, 265.45batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  33%|▎| 13413/40960 [00:55<01:43, 265.45batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  33%|▎| 13470/40960 [00:55<01:41, 270.40batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  33%|▎| 13470/40960 [00:55<01:41, 270.40batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  33%|▎| 13516/40960 [00:55<01:46, 257.84batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  33%|▎| 13516/40960 [00:55<01:46, 257.84batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  33%|▎| 13553/40960 [00:56<01:56, 234.96batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  33%|▎| 13553/40960 [00:56<01:56, 234.96batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  33%|▎| 13608/40960 [00:56<01:50, 246.51batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  33%|▎| 13608/40960 [00:56<01:50, 246.51batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  33%|▎| 13665/40960 [00:56<01:46, 257.12batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  33%|▎| 13665/40960 [00:56<01:46, 257.12batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  34%|▎| 13723/40960 [00:56<01:42, 266.14batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  34%|▎| 13723/40960 [00:56<01:42, 266.14batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  34%|▎| 13776/40960 [00:56<01:42, 265.27batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  34%|▎| 13776/40960 [00:56<01:42, 265.27batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  34%|▎| 13828/40960 [00:57<01:42, 263.50batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  34%|▎| 13828/40960 [00:57<01:42, 263.50batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  34%|▎| 13881/40960 [00:57<01:42, 263.93batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  34%|▎| 13881/40960 [00:57<01:42, 263.93batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  34%|▎| 13931/40960 [00:57<01:44, 259.69batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  34%|▎| 13931/40960 [00:57<01:44, 259.69batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  34%|▎| 13990/40960 [00:57<01:40, 269.39batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  34%|▎| 13990/40960 [00:57<01:40, 269.39batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  34%|▎| 14050/40960 [00:57<01:36, 277.66batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  34%|▎| 14050/40960 [00:57<01:36, 277.66batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  34%|▎| 14107/40960 [00:58<01:36, 278.78batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  34%|▎| 14107/40960 [00:58<01:36, 278.78batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  35%|▎| 14162/40960 [00:58<01:36, 276.62batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  35%|▎| 14162/40960 [00:58<01:36, 276.62batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  35%|▎| 14219/40960 [00:58<01:36, 277.72batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  35%|▎| 14219/40960 [00:58<01:36, 277.72batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  35%|▎| 14276/40960 [00:58<01:35, 278.75batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  35%|▎| 14276/40960 [00:58<01:35, 278.75batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  35%|▎| 14336/40960 [00:58<01:33, 284.23batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  35%|▎| 14336/40960 [00:58<01:33, 284.23batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  35%|▎| 14393/40960 [00:59<01:33, 283.25batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  35%|▎| 14393/40960 [00:59<01:33, 283.25batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  35%|▎| 14449/40960 [00:59<01:34, 281.30batches/s, l2_loss: 0.1340 - round_los\u001b[A\n",
      "Training:  35%|▎| 14449/40960 [00:59<01:34, 281.30batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  35%|▎| 14487/40960 [00:59<01:44, 253.64batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  35%|▎| 14487/40960 [00:59<01:44, 253.64batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  35%|▎| 14526/40960 [00:59<01:52, 235.23batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  35%|▎| 14526/40960 [00:59<01:52, 235.23batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  36%|▎| 14563/40960 [00:59<02:00, 218.67batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  36%|▎| 14563/40960 [00:59<02:00, 218.67batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  36%|▎| 14600/40960 [01:00<02:06, 207.60batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  36%|▎| 14600/40960 [01:00<02:06, 207.60batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14636/40960 [01:00<02:12, 198.46batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14636/40960 [01:00<02:12, 198.46batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  36%|▎| 14679/40960 [01:00<02:09, 202.81batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  36%|▎| 14679/40960 [01:00<02:09, 202.81batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  36%|▎| 14724/40960 [01:00<02:06, 207.92batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  36%|▎| 14724/40960 [01:00<02:06, 207.92batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14768/40960 [01:00<02:04, 210.64batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14768/40960 [01:01<02:04, 210.64batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14806/40960 [01:01<02:08, 204.06batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14806/40960 [01:01<02:08, 204.06batches/s, l2_loss: 0.1342 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|▎| 14846/40960 [01:01<02:09, 202.27batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14846/40960 [01:01<02:09, 202.27batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14882/40960 [01:01<02:14, 194.49batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14882/40960 [01:01<02:14, 194.49batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14928/40960 [01:01<02:07, 204.92batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  36%|▎| 14928/40960 [01:01<02:07, 204.92batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  37%|▎| 14986/40960 [01:02<01:52, 229.89batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  37%|▎| 14986/40960 [01:02<01:52, 229.89batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15024/40960 [01:02<01:59, 216.54batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15024/40960 [01:02<01:59, 216.54batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15069/40960 [01:02<01:58, 217.76batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15069/40960 [01:02<01:58, 217.76batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  37%|▎| 15107/40960 [01:02<02:03, 208.69batches/s, l2_loss: 0.1341 - round_los\u001b[A\n",
      "Training:  37%|▎| 15107/40960 [01:02<02:03, 208.69batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15157/40960 [01:02<01:57, 219.80batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15157/40960 [01:02<01:57, 219.80batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15192/40960 [01:03<02:04, 206.25batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15192/40960 [01:03<02:04, 206.25batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15243/40960 [01:03<01:57, 219.46batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15243/40960 [01:03<01:57, 219.46batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15293/40960 [01:03<01:52, 227.46batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15293/40960 [01:03<01:52, 227.46batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15331/40960 [01:03<01:58, 215.75batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  37%|▎| 15331/40960 [01:03<01:58, 215.75batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15369/40960 [01:03<02:03, 206.82batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15369/40960 [01:03<02:03, 206.82batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  38%|▍| 15412/40960 [01:04<02:02, 208.56batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  38%|▍| 15412/40960 [01:04<02:02, 208.56batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  38%|▍| 15458/40960 [01:04<01:58, 214.67batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  38%|▍| 15458/40960 [01:04<01:58, 214.67batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  38%|▍| 15498/40960 [01:04<02:01, 210.14batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  38%|▍| 15498/40960 [01:04<02:01, 210.14batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15535/40960 [01:04<02:05, 201.81batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15535/40960 [01:04<02:05, 201.81batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15593/40960 [01:04<01:51, 227.21batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15593/40960 [01:04<01:51, 227.21batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15648/40960 [01:05<01:45, 239.77batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15648/40960 [01:05<01:45, 239.77batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  38%|▍| 15686/40960 [01:05<01:53, 223.59batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  38%|▍| 15686/40960 [01:05<01:53, 223.59batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15724/40960 [01:05<01:58, 213.48batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  38%|▍| 15724/40960 [01:05<01:58, 213.48batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  38%|▍| 15761/40960 [01:05<02:03, 204.52batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  38%|▍| 15761/40960 [01:05<02:03, 204.52batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  39%|▍| 15796/40960 [01:05<02:09, 194.85batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  39%|▍| 15796/40960 [01:05<02:09, 194.85batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  39%|▍| 15831/40960 [01:06<02:13, 188.64batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  39%|▍| 15831/40960 [01:06<02:13, 188.64batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  39%|▍| 15886/40960 [01:06<01:57, 213.92batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  39%|▍| 15886/40960 [01:06<01:57, 213.92batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  39%|▍| 15940/40960 [01:06<01:48, 230.30batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  39%|▍| 15940/40960 [01:06<01:48, 230.30batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  39%|▍| 15977/40960 [01:06<01:55, 216.61batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  39%|▍| 15977/40960 [01:06<01:55, 216.61batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  39%|▍| 16014/40960 [01:06<02:01, 205.88batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  39%|▍| 16014/40960 [01:06<02:01, 205.88batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  39%|▍| 16054/40960 [01:07<02:02, 203.94batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  39%|▍| 16054/40960 [01:07<02:02, 203.94batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  39%|▍| 16097/40960 [01:07<02:00, 206.68batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  39%|▍| 16097/40960 [01:07<02:00, 206.68batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  39%|▍| 16141/40960 [01:07<01:58, 209.91batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  39%|▍| 16141/40960 [01:07<01:58, 209.91batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16200/40960 [01:07<01:45, 234.59batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16200/40960 [01:07<01:45, 234.59batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16257/40960 [01:07<01:39, 247.85batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16257/40960 [01:07<01:39, 247.85batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16294/40960 [01:08<01:48, 228.31batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16294/40960 [01:08<01:48, 228.31batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  40%|▍| 16345/40960 [01:08<01:44, 235.21batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  40%|▍| 16345/40960 [01:08<01:44, 235.21batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16397/40960 [01:08<01:41, 241.63batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16397/40960 [01:08<01:41, 241.63batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16451/40960 [01:08<01:38, 249.76batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16451/40960 [01:08<01:38, 249.76batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16508/40960 [01:08<01:34, 259.77batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16508/40960 [01:08<01:34, 259.77batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16565/40960 [01:09<01:31, 267.05batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  40%|▍| 16565/40960 [01:09<01:31, 267.05batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  41%|▍| 16621/40960 [01:09<01:30, 269.82batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  41%|▍| 16621/40960 [01:09<01:30, 269.82batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16677/40960 [01:09<01:29, 272.36batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16677/40960 [01:09<01:29, 272.36batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  41%|▍| 16736/40960 [01:09<01:27, 278.29batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  41%|▍| 16736/40960 [01:09<01:27, 278.29batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16781/40960 [01:09<01:32, 261.71batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16781/40960 [01:09<01:32, 261.71batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16828/40960 [01:10<01:35, 252.22batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16828/40960 [01:10<01:35, 252.22batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16884/40960 [01:10<01:32, 259.27batches/s, l2_loss: 0.1344 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|▍| 16884/40960 [01:10<01:32, 259.27batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16935/40960 [01:10<01:33, 256.59batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  41%|▍| 16935/40960 [01:10<01:33, 256.59batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  41%|▍| 16990/40960 [01:10<01:31, 261.74batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  41%|▍| 16990/40960 [01:10<01:31, 261.74batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17031/40960 [01:10<01:37, 244.67batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17031/40960 [01:10<01:37, 244.67batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  42%|▍| 17066/40960 [01:11<01:46, 223.37batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  42%|▍| 17066/40960 [01:11<01:46, 223.37batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  42%|▍| 17117/40960 [01:11<01:42, 232.53batches/s, l2_loss: 0.1342 - round_los\u001b[A\n",
      "Training:  42%|▍| 17117/40960 [01:11<01:42, 232.53batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  42%|▍| 17153/40960 [01:11<01:50, 215.72batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  42%|▍| 17153/40960 [01:11<01:50, 215.72batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17204/40960 [01:11<01:44, 226.46batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17204/40960 [01:11<01:44, 226.46batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17237/40960 [01:11<01:54, 207.60batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17237/40960 [01:11<01:54, 207.60batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17286/40960 [01:12<01:48, 217.36batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17286/40960 [01:12<01:48, 217.36batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  42%|▍| 17328/40960 [01:12<01:50, 214.74batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  42%|▍| 17328/40960 [01:12<01:50, 214.74batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17367/40960 [01:12<01:53, 207.50batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  42%|▍| 17367/40960 [01:12<01:53, 207.50batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17415/40960 [01:12<01:48, 216.43batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17415/40960 [01:12<01:48, 216.43batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17451/40960 [01:12<01:54, 204.65batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17451/40960 [01:12<01:54, 204.65batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17494/40960 [01:13<01:53, 206.92batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17494/40960 [01:13<01:53, 206.92batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17539/40960 [01:13<01:50, 211.74batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17539/40960 [01:13<01:50, 211.74batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17573/40960 [01:13<01:58, 198.19batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17573/40960 [01:13<01:58, 198.19batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17616/40960 [01:13<01:55, 202.64batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17616/40960 [01:13<01:55, 202.64batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  43%|▍| 17663/40960 [01:13<01:50, 211.66batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  43%|▍| 17663/40960 [01:13<01:50, 211.66batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17701/40960 [01:14<01:53, 205.17batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17701/40960 [01:14<01:53, 205.17batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17744/40960 [01:14<01:51, 208.08batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  43%|▍| 17744/40960 [01:14<01:51, 208.08batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  43%|▍| 17787/40960 [01:14<01:50, 209.00batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  43%|▍| 17787/40960 [01:14<01:50, 209.00batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 17827/40960 [01:14<01:52, 205.40batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 17827/40960 [01:14<01:52, 205.40batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  44%|▍| 17881/40960 [01:14<01:43, 223.78batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  44%|▍| 17881/40960 [01:14<01:43, 223.78batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  44%|▍| 17937/40960 [01:15<01:35, 240.27batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  44%|▍| 17937/40960 [01:15<01:35, 240.27batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 17992/40960 [01:15<01:31, 250.22batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 17992/40960 [01:15<01:31, 250.22batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 18045/40960 [01:15<01:30, 253.39batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 18045/40960 [01:15<01:30, 253.39batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 18098/40960 [01:15<01:29, 255.74batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 18098/40960 [01:15<01:29, 255.74batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 18151/40960 [01:15<01:28, 257.91batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 18151/40960 [01:15<01:28, 257.91batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 18206/40960 [01:16<01:26, 262.05batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  44%|▍| 18206/40960 [01:16<01:26, 262.05batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  45%|▍| 18259/40960 [01:16<01:26, 261.94batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  45%|▍| 18259/40960 [01:16<01:26, 261.94batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  45%|▍| 18315/40960 [01:16<01:24, 267.09batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  45%|▍| 18315/40960 [01:16<01:24, 267.09batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  45%|▍| 18370/40960 [01:16<01:23, 269.11batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  45%|▍| 18370/40960 [01:16<01:23, 269.11batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  45%|▍| 18422/40960 [01:16<01:24, 265.85batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  45%|▍| 18422/40960 [01:16<01:24, 265.85batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  45%|▍| 18469/40960 [01:17<01:27, 256.56batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  45%|▍| 18469/40960 [01:17<01:27, 256.56batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  45%|▍| 18519/40960 [01:17<01:28, 253.67batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  45%|▍| 18519/40960 [01:17<01:28, 253.67batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  45%|▍| 18574/40960 [01:17<01:26, 259.72batches/s, l2_loss: 0.1343 - round_los\u001b[A\n",
      "Training:  45%|▍| 18574/40960 [01:17<01:26, 259.72batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  45%|▍| 18622/40960 [01:17<01:28, 252.75batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  45%|▍| 18622/40960 [01:17<01:28, 252.75batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  46%|▍| 18657/40960 [01:17<01:37, 229.48batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  46%|▍| 18657/40960 [01:17<01:37, 229.48batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18691/40960 [01:18<01:45, 211.49batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18691/40960 [01:18<01:45, 211.49batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18727/40960 [01:18<01:50, 200.56batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18727/40960 [01:18<01:50, 200.56batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  46%|▍| 18773/40960 [01:18<01:46, 208.40batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  46%|▍| 18773/40960 [01:18<01:46, 208.40batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18833/40960 [01:18<01:34, 234.77batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18833/40960 [01:18<01:34, 234.77batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18884/40960 [01:18<01:32, 239.75batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18884/40960 [01:18<01:32, 239.75batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18940/40960 [01:19<01:27, 251.41batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 18940/40960 [01:19<01:27, 251.41batches/s, l2_loss: 0.1345 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|▍| 19000/40960 [01:19<01:22, 264.91batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  46%|▍| 19000/40960 [01:19<01:22, 264.91batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19059/40960 [01:19<01:20, 272.96batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19059/40960 [01:19<01:20, 272.96batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19115/40960 [01:19<01:19, 274.98batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19115/40960 [01:19<01:19, 274.98batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19165/40960 [01:20<01:21, 266.12batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19165/40960 [01:20<01:21, 266.12batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19218/40960 [01:20<01:21, 265.69batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19218/40960 [01:20<01:21, 265.69batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19277/40960 [01:20<01:19, 273.16batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19277/40960 [01:20<01:19, 273.16batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  47%|▍| 19330/40960 [01:20<01:20, 269.36batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  47%|▍| 19330/40960 [01:20<01:20, 269.36batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19371/40960 [01:20<01:26, 249.12batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19371/40960 [01:20<01:26, 249.12batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19426/40960 [01:21<01:23, 256.60batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  47%|▍| 19426/40960 [01:21<01:23, 256.60batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  48%|▍| 19485/40960 [01:21<01:20, 267.71batches/s, l2_loss: 0.1344 - round_los\u001b[A\n",
      "Training:  48%|▍| 19485/40960 [01:21<01:20, 267.71batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  48%|▍| 19533/40960 [01:21<01:22, 259.23batches/s, l2_loss: 0.1345 - round_los\u001b[A\n",
      "Training:  48%|▍| 19533/40960 [01:21<01:22, 259.23batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19584/40960 [01:21<01:23, 257.31batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19584/40960 [01:21<01:23, 257.31batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19637/40960 [01:21<01:22, 259.27batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19637/40960 [01:21<01:22, 259.27batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19687/40960 [01:22<01:22, 256.35batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19687/40960 [01:22<01:22, 256.35batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19743/40960 [01:22<01:20, 262.60batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19743/40960 [01:22<01:20, 262.60batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19801/40960 [01:22<01:18, 269.92batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19801/40960 [01:22<01:18, 269.92batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19858/40960 [01:22<01:17, 273.38batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  48%|▍| 19858/40960 [01:22<01:17, 273.38batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 19915/40960 [01:22<01:16, 276.09batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 19915/40960 [01:22<01:16, 276.09batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 19968/40960 [01:23<01:17, 271.57batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 19968/40960 [01:23<01:17, 271.57batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 20022/40960 [01:23<01:17, 270.78batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 20022/40960 [01:23<01:17, 270.78batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  49%|▍| 20071/40960 [01:23<01:19, 263.09batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  49%|▍| 20071/40960 [01:23<01:19, 263.09batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 20123/40960 [01:23<01:19, 261.35batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 20123/40960 [01:23<01:19, 261.35batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 20174/40960 [01:23<01:20, 259.35batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 20174/40960 [01:23<01:20, 259.35batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 20228/40960 [01:24<01:19, 262.05batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  49%|▍| 20228/40960 [01:24<01:19, 262.05batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▍| 20276/40960 [01:24<01:21, 254.06batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▍| 20276/40960 [01:24<01:21, 254.06batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▍| 20333/40960 [01:24<01:18, 263.13batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▍| 20333/40960 [01:24<01:18, 263.13batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  50%|▍| 20391/40960 [01:24<01:16, 269.81batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  50%|▍| 20391/40960 [01:24<01:16, 269.81batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▍| 20448/40960 [01:24<01:15, 273.16batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▍| 20448/40960 [01:24<01:15, 273.16batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  50%|▌| 20501/40960 [01:25<01:16, 269.09batches/s, l2_loss: 0.1346 - round_los\u001b[A\n",
      "Training:  50%|▌| 20501/40960 [01:25<01:16, 269.09batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▌| 20559/40960 [01:25<01:14, 275.01batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▌| 20559/40960 [01:25<01:14, 275.01batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▌| 20610/40960 [01:25<01:15, 268.16batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▌| 20610/40960 [01:25<01:15, 268.16batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▌| 20662/40960 [01:25<01:16, 264.73batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  50%|▌| 20662/40960 [01:25<01:16, 264.73batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20717/40960 [01:25<01:16, 266.18batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20717/40960 [01:25<01:16, 266.18batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20771/40960 [01:26<01:15, 266.86batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20771/40960 [01:26<01:15, 266.86batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20829/40960 [01:26<01:13, 272.44batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20829/40960 [01:26<01:13, 272.44batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20884/40960 [01:26<01:13, 273.01batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20884/40960 [01:26<01:13, 273.01batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20939/40960 [01:26<01:13, 272.40batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  51%|▌| 20939/40960 [01:26<01:13, 272.40batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  51%|▌| 20992/40960 [01:26<01:14, 269.31batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  51%|▌| 20992/40960 [01:26<01:14, 269.31batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  51%|▌| 21047/40960 [01:27<01:13, 269.73batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  51%|▌| 21047/40960 [01:27<01:13, 269.73batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  52%|▌| 21104/40960 [01:27<01:12, 274.22batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  52%|▌| 21104/40960 [01:27<01:12, 274.22batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  52%|▌| 21162/40960 [01:27<01:10, 278.92batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  52%|▌| 21162/40960 [01:27<01:10, 278.92batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  52%|▌| 21216/40960 [01:27<01:11, 275.20batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  52%|▌| 21216/40960 [01:27<01:11, 275.20batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  52%|▌| 21264/40960 [01:27<01:14, 263.22batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  52%|▌| 21264/40960 [01:27<01:14, 263.22batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  52%|▌| 21310/40960 [01:28<01:17, 252.31batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  52%|▌| 21310/40960 [01:28<01:17, 252.31batches/s, l2_loss: 0.1347 - round_los\u001b[A\n",
      "Training:  52%|▌| 21363/40960 [01:28<01:16, 255.88batches/s, l2_loss: 0.1347 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21363/40960 [01:28<01:16, 255.88batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  52%|▌| 21414/40960 [01:28<01:16, 255.09batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  52%|▌| 21414/40960 [01:28<01:16, 255.09batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  52%|▌| 21463/40960 [01:28<01:17, 250.32batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  52%|▌| 21463/40960 [01:28<01:17, 250.32batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  53%|▌| 21513/40960 [01:28<01:17, 249.37batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  53%|▌| 21513/40960 [01:28<01:17, 249.37batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  53%|▌| 21571/40960 [01:29<01:14, 260.63batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  53%|▌| 21571/40960 [01:29<01:14, 260.63batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  53%|▌| 21627/40960 [01:29<01:12, 265.18batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  53%|▌| 21627/40960 [01:29<01:12, 265.18batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  53%|▌| 21684/40960 [01:29<01:11, 270.02batches/s, l2_loss: 0.1348 - round_los\u001b[A\n",
      "Training:  53%|▌| 21684/40960 [01:29<01:11, 270.02batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  53%|▌| 21741/40960 [01:29<01:10, 273.03batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  53%|▌| 21741/40960 [01:29<01:10, 273.03batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  53%|▌| 21795/40960 [01:29<01:10, 270.66batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  53%|▌| 21795/40960 [01:29<01:10, 270.66batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  53%|▌| 21848/40960 [01:30<01:11, 268.20batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  53%|▌| 21848/40960 [01:30<01:11, 268.20batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  53%|▌| 21904/40960 [01:30<01:10, 270.59batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  53%|▌| 21904/40960 [01:30<01:10, 270.59batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 21956/40960 [01:30<01:11, 266.37batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 21956/40960 [01:30<01:11, 266.37batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 22007/40960 [01:30<01:12, 262.28batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 22007/40960 [01:30<01:12, 262.28batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 22063/40960 [01:30<01:10, 266.49batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 22063/40960 [01:30<01:10, 266.49batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 22118/40960 [01:31<01:10, 268.73batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 22118/40960 [01:31<01:10, 268.73batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 22168/40960 [01:31<01:11, 263.02batches/s, l2_loss: 0.1349 - round_los\u001b[A\n",
      "Training:  54%|▌| 22168/40960 [01:31<01:11, 263.02batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  54%|▌| 22220/40960 [01:31<01:11, 261.49batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  54%|▌| 22220/40960 [01:31<01:11, 261.49batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  54%|▌| 22269/40960 [01:31<01:13, 255.88batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  54%|▌| 22269/40960 [01:31<01:13, 255.88batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  54%|▌| 22317/40960 [01:31<01:14, 251.08batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  54%|▌| 22317/40960 [01:31<01:14, 251.08batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22369/40960 [01:32<01:13, 253.12batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22369/40960 [01:32<01:13, 253.12batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22424/40960 [01:32<01:11, 258.88batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22424/40960 [01:32<01:11, 258.88batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22478/40960 [01:32<01:10, 260.95batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22478/40960 [01:32<01:10, 260.95batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22532/40960 [01:32<01:10, 263.02batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22532/40960 [01:32<01:10, 263.02batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22584/40960 [01:32<01:10, 261.32batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22584/40960 [01:32<01:10, 261.32batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22640/40960 [01:33<01:08, 266.82batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22640/40960 [01:33<01:08, 266.82batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22694/40960 [01:33<01:08, 266.39batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  55%|▌| 22694/40960 [01:33<01:08, 266.39batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  56%|▌| 22748/40960 [01:33<01:08, 266.58batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  56%|▌| 22748/40960 [01:33<01:08, 266.58batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  56%|▌| 22803/40960 [01:33<01:07, 268.93batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  56%|▌| 22803/40960 [01:33<01:07, 268.93batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  56%|▌| 22860/40960 [01:33<01:06, 273.14batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  56%|▌| 22860/40960 [01:33<01:06, 273.14batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  56%|▌| 22919/40960 [01:34<01:04, 278.77batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  56%|▌| 22919/40960 [01:34<01:04, 278.77batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  56%|▌| 22973/40960 [01:34<01:05, 275.54batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  56%|▌| 22973/40960 [01:34<01:05, 275.54batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  56%|▌| 23033/40960 [01:34<01:03, 281.86batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  56%|▌| 23033/40960 [01:34<01:03, 281.86batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  56%|▌| 23091/40960 [01:34<01:02, 283.93batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  56%|▌| 23091/40960 [01:34<01:02, 283.93batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  57%|▌| 23145/40960 [01:34<01:03, 279.01batches/s, l2_loss: 0.1350 - round_los\u001b[A\n",
      "Training:  57%|▌| 23145/40960 [01:34<01:03, 279.01batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  57%|▌| 23196/40960 [01:35<01:05, 270.85batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  57%|▌| 23196/40960 [01:35<01:05, 270.85batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  57%|▌| 23249/40960 [01:35<01:05, 269.03batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  57%|▌| 23249/40960 [01:35<01:05, 269.03batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  57%|▌| 23308/40960 [01:35<01:03, 276.64batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  57%|▌| 23308/40960 [01:35<01:03, 276.64batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  57%|▌| 23365/40960 [01:35<01:03, 278.64batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  57%|▌| 23365/40960 [01:35<01:03, 278.64batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  57%|▌| 23421/40960 [01:35<01:02, 278.77batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  57%|▌| 23421/40960 [01:35<01:02, 278.77batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  57%|▌| 23471/40960 [01:36<01:04, 269.17batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  57%|▌| 23471/40960 [01:36<01:04, 269.17batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  57%|▌| 23520/40960 [01:36<01:06, 260.79batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  57%|▌| 23520/40960 [01:36<01:06, 260.79batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  58%|▌| 23577/40960 [01:36<01:05, 266.88batches/s, l2_loss: 0.1351 - round_los\u001b[A\n",
      "Training:  58%|▌| 23577/40960 [01:36<01:05, 266.88batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23636/40960 [01:36<01:03, 274.39batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23636/40960 [01:36<01:03, 274.39batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23693/40960 [01:36<01:02, 277.07batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23693/40960 [01:36<01:02, 277.07batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23751/40960 [01:37<01:01, 280.05batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23751/40960 [01:37<01:01, 280.05batches/s, l2_loss: 0.1352 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|▌| 23809/40960 [01:37<01:00, 282.97batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23809/40960 [01:37<01:00, 282.97batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23866/40960 [01:37<01:00, 283.21batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23866/40960 [01:37<01:00, 283.21batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23925/40960 [01:37<00:59, 285.46batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  58%|▌| 23925/40960 [01:37<00:59, 285.46batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  59%|▌| 23983/40960 [01:37<00:59, 286.46batches/s, l2_loss: 0.1352 - round_los\u001b[A\n",
      "Training:  59%|▌| 23983/40960 [01:37<00:59, 286.46batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24041/40960 [01:38<00:59, 286.10batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24041/40960 [01:38<00:59, 286.10batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24099/40960 [01:38<00:58, 286.64batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24099/40960 [01:38<00:58, 286.64batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24153/40960 [01:38<00:59, 280.94batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24153/40960 [01:38<00:59, 280.94batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24213/40960 [01:38<00:58, 285.77batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24213/40960 [01:38<00:58, 285.77batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24271/40960 [01:38<00:58, 285.89batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24271/40960 [01:38<00:58, 285.89batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24329/40960 [01:39<00:57, 286.97batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  59%|▌| 24329/40960 [01:39<00:57, 286.97batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24382/40960 [01:39<00:59, 279.69batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24382/40960 [01:39<00:59, 279.69batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24441/40960 [01:39<00:58, 282.99batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24441/40960 [01:39<00:58, 282.99batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24501/40960 [01:39<00:57, 287.45batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24501/40960 [01:39<00:57, 287.45batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24560/40960 [01:39<00:56, 288.97batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24560/40960 [01:39<00:56, 288.97batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24616/40960 [01:40<00:57, 285.84batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24616/40960 [01:40<00:57, 285.84batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24672/40960 [01:40<00:57, 284.01batches/s, l2_loss: 0.1353 - round_los\u001b[A\n",
      "Training:  60%|▌| 24672/40960 [01:40<00:57, 284.01batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  60%|▌| 24721/40960 [01:40<00:59, 271.27batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  60%|▌| 24721/40960 [01:40<00:59, 271.27batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  60%|▌| 24770/40960 [01:40<01:01, 261.63batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  60%|▌| 24770/40960 [01:40<01:01, 261.63batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  61%|▌| 24817/40960 [01:40<01:03, 253.70batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  61%|▌| 24817/40960 [01:41<01:03, 253.70batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  61%|▌| 24868/40960 [01:41<01:03, 253.75batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  61%|▌| 24868/40960 [01:41<01:03, 253.75batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  61%|▌| 24917/40960 [01:41<01:03, 251.06batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  61%|▌| 24917/40960 [01:41<01:03, 251.06batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  61%|▌| 24976/40960 [01:41<01:00, 263.84batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  61%|▌| 24976/40960 [01:41<01:00, 263.84batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  61%|▌| 25035/40960 [01:41<00:58, 272.22batches/s, l2_loss: 0.1354 - round_los\u001b[A\n",
      "Training:  61%|▌| 25035/40960 [01:41<00:58, 272.22batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  61%|▌| 25095/40960 [01:42<00:56, 279.41batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  61%|▌| 25095/40960 [01:42<00:56, 279.41batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  61%|▌| 25152/40960 [01:42<00:56, 280.92batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  61%|▌| 25152/40960 [01:42<00:56, 280.92batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  62%|▌| 25211/40960 [01:42<00:55, 284.16batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  62%|▌| 25211/40960 [01:42<00:55, 284.16batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  62%|▌| 25266/40960 [01:42<00:55, 280.31batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  62%|▌| 25266/40960 [01:42<00:55, 280.31batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  62%|▌| 25322/40960 [01:42<00:56, 278.95batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  62%|▌| 25322/40960 [01:42<00:56, 278.95batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  62%|▌| 25378/40960 [01:43<00:55, 278.39batches/s, l2_loss: 0.1355 - round_los\u001b[A\n",
      "Training:  62%|▌| 25378/40960 [01:43<00:55, 278.39batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  62%|▌| 25435/40960 [01:43<00:55, 279.09batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  62%|▌| 25435/40960 [01:43<00:55, 279.09batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  62%|▌| 25491/40960 [01:43<00:55, 279.00batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  62%|▌| 25491/40960 [01:43<00:55, 279.00batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  62%|▌| 25536/40960 [01:43<00:58, 262.42batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  62%|▌| 25536/40960 [01:43<00:58, 262.42batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  62%|▌| 25590/40960 [01:43<00:58, 263.83batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  62%|▌| 25590/40960 [01:43<00:58, 263.83batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  63%|▋| 25644/40960 [01:44<00:57, 264.47batches/s, l2_loss: 0.1356 - round_los\u001b[A\n",
      "Training:  63%|▋| 25644/40960 [01:44<00:57, 264.47batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25701/40960 [01:44<00:56, 269.69batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25701/40960 [01:44<00:56, 269.69batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25751/40960 [01:44<00:57, 263.53batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25751/40960 [01:44<00:57, 263.53batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25801/40960 [01:44<00:58, 259.10batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25801/40960 [01:44<00:58, 259.10batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25859/40960 [01:44<00:56, 268.12batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25859/40960 [01:44<00:56, 268.12batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25914/40960 [01:45<00:55, 268.98batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25914/40960 [01:45<00:55, 268.98batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25968/40960 [01:45<00:55, 268.16batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  63%|▋| 25968/40960 [01:45<00:55, 268.16batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  64%|▋| 26023/40960 [01:45<00:55, 269.70batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  64%|▋| 26023/40960 [01:45<00:55, 269.70batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  64%|▋| 26080/40960 [01:45<00:54, 273.88batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  64%|▋| 26080/40960 [01:45<00:54, 273.88batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  64%|▋| 26138/40960 [01:45<00:53, 278.46batches/s, l2_loss: 0.1357 - round_los\u001b[A\n",
      "Training:  64%|▋| 26138/40960 [01:45<00:53, 278.46batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  64%|▋| 26196/40960 [01:46<00:52, 280.90batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  64%|▋| 26196/40960 [01:46<00:52, 280.90batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  64%|▋| 26253/40960 [01:46<00:52, 281.31batches/s, l2_loss: 0.1358 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|▋| 26253/40960 [01:46<00:52, 281.31batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  64%|▋| 26310/40960 [01:46<00:52, 281.54batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  64%|▋| 26310/40960 [01:46<00:52, 281.54batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  64%|▋| 26368/40960 [01:46<00:51, 282.93batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  64%|▋| 26368/40960 [01:46<00:51, 282.93batches/s, l2_loss: 0.1359 - round_los\u001b[A\n",
      "Training:  65%|▋| 26427/40960 [01:46<00:50, 286.37batches/s, l2_loss: 0.1359 - round_los\u001b[A\n",
      "Training:  65%|▋| 26427/40960 [01:46<00:50, 286.37batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  65%|▋| 26483/40960 [01:47<00:51, 283.60batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  65%|▋| 26483/40960 [01:47<00:51, 283.60batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  65%|▋| 26531/40960 [01:47<00:53, 269.15batches/s, l2_loss: 0.1358 - round_los\u001b[A\n",
      "Training:  65%|▋| 26531/40960 [01:47<00:53, 269.15batches/s, l2_loss: 0.1359 - round_los\u001b[A\n",
      "Training:  65%|▋| 26587/40960 [01:47<00:52, 271.61batches/s, l2_loss: 0.1359 - round_los\u001b[A\n",
      "Training:  65%|▋| 26587/40960 [01:47<00:52, 271.61batches/s, l2_loss: 0.1359 - round_los\u001b[A\n",
      "Training:  65%|▋| 26639/40960 [01:47<00:53, 267.00batches/s, l2_loss: 0.1359 - round_los\u001b[A\n",
      "Training:  65%|▋| 26639/40960 [01:47<00:53, 267.00batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  65%|▋| 26698/40960 [01:47<00:51, 274.33batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  65%|▋| 26698/40960 [01:47<00:51, 274.33batches/s, l2_loss: 0.1359 - round_los\u001b[A\n",
      "Training:  65%|▋| 26758/40960 [01:48<00:50, 281.03batches/s, l2_loss: 0.1359 - round_los\u001b[A\n",
      "Training:  65%|▋| 26758/40960 [01:48<00:50, 281.03batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  65%|▋| 26814/40960 [01:48<00:50, 279.88batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  65%|▋| 26814/40960 [01:48<00:50, 279.88batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 26871/40960 [01:48<00:50, 280.58batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 26871/40960 [01:48<00:50, 280.58batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 26930/40960 [01:48<00:49, 283.67batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 26930/40960 [01:48<00:49, 283.67batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  66%|▋| 26986/40960 [01:48<00:49, 282.33batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  66%|▋| 26986/40960 [01:48<00:49, 282.33batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 27042/40960 [01:49<00:49, 280.24batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 27042/40960 [01:49<00:49, 280.24batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 27093/40960 [01:49<00:51, 271.56batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 27093/40960 [01:49<00:51, 271.56batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 27143/40960 [01:49<00:52, 263.98batches/s, l2_loss: 0.1360 - round_los\u001b[A\n",
      "Training:  66%|▋| 27143/40960 [01:49<00:52, 263.98batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  66%|▋| 27198/40960 [01:49<00:51, 266.90batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  66%|▋| 27198/40960 [01:49<00:51, 266.90batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  67%|▋| 27256/40960 [01:49<00:50, 273.36batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  67%|▋| 27256/40960 [01:49<00:50, 273.36batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  67%|▋| 27311/40960 [01:50<00:50, 272.80batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  67%|▋| 27311/40960 [01:50<00:50, 272.80batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  67%|▋| 27369/40960 [01:50<00:48, 277.65batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  67%|▋| 27369/40960 [01:50<00:48, 277.65batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  67%|▋| 27423/40960 [01:50<00:49, 274.23batches/s, l2_loss: 0.1361 - round_los\u001b[A\n",
      "Training:  67%|▋| 27423/40960 [01:50<00:49, 274.23batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  67%|▋| 27476/40960 [01:50<00:49, 269.88batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  67%|▋| 27476/40960 [01:50<00:49, 269.88batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  67%|▋| 27533/40960 [01:50<00:49, 273.48batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  67%|▋| 27533/40960 [01:50<00:49, 273.48batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  67%|▋| 27591/40960 [01:51<00:48, 277.35batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  67%|▋| 27591/40960 [01:51<00:48, 277.35batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  68%|▋| 27648/40960 [01:51<00:47, 278.51batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  68%|▋| 27648/40960 [01:51<00:47, 278.51batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 27702/40960 [01:51<00:48, 275.91batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 27702/40960 [01:51<00:48, 275.91batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  68%|▋| 27757/40960 [01:51<00:47, 275.10batches/s, l2_loss: 0.1362 - round_los\u001b[A\n",
      "Training:  68%|▋| 27757/40960 [01:51<00:47, 275.10batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 27813/40960 [01:51<00:47, 276.29batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 27813/40960 [01:51<00:47, 276.29batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 27869/40960 [01:52<00:47, 275.33batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 27869/40960 [01:52<00:47, 275.33batches/s, l2_loss: 0.1364 - round_los\u001b[A\n",
      "Training:  68%|▋| 27925/40960 [01:52<00:47, 276.58batches/s, l2_loss: 0.1364 - round_los\u001b[A\n",
      "Training:  68%|▋| 27925/40960 [01:52<00:47, 276.58batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 27981/40960 [01:52<00:46, 277.60batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 27981/40960 [01:52<00:46, 277.60batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 28036/40960 [01:52<00:46, 275.70batches/s, l2_loss: 0.1363 - round_los\u001b[A\n",
      "Training:  68%|▋| 28036/40960 [01:52<00:46, 275.70batches/s, l2_loss: 0.1364 - round_los\u001b[A\n",
      "Training:  69%|▋| 28094/40960 [01:52<00:46, 279.11batches/s, l2_loss: 0.1364 - round_los\u001b[A\n",
      "Training:  69%|▋| 28094/40960 [01:52<00:46, 279.11batches/s, l2_loss: 0.1364 - round_los\u001b[A\n",
      "Training:  69%|▋| 28154/40960 [01:53<00:45, 284.34batches/s, l2_loss: 0.1364 - round_los\u001b[A\n",
      "Training:  69%|▋| 28154/40960 [01:53<00:45, 284.34batches/s, l2_loss: 0.1364 - round_los\u001b[A\n",
      "Training:  69%|▋| 28212/40960 [01:53<00:44, 284.55batches/s, l2_loss: 0.1364 - round_los\u001b[A\n",
      "Training:  69%|▋| 28212/40960 [01:53<00:44, 284.55batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  69%|▋| 28270/40960 [01:53<00:44, 285.92batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  69%|▋| 28270/40960 [01:53<00:44, 285.92batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  69%|▋| 28328/40960 [01:53<00:44, 286.27batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  69%|▋| 28328/40960 [01:53<00:44, 286.27batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  69%|▋| 28385/40960 [01:53<00:44, 284.92batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  69%|▋| 28385/40960 [01:53<00:44, 284.92batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  69%|▋| 28445/40960 [01:54<00:43, 288.36batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  69%|▋| 28445/40960 [01:54<00:43, 288.36batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  70%|▋| 28502/40960 [01:54<00:43, 286.08batches/s, l2_loss: 0.1365 - round_los\u001b[A\n",
      "Training:  70%|▋| 28502/40960 [01:54<00:43, 286.08batches/s, l2_loss: 0.1366 - round_los\u001b[A\n",
      "Training:  70%|▋| 28558/40960 [01:54<00:43, 283.16batches/s, l2_loss: 0.1366 - round_los\u001b[A\n",
      "Training:  70%|▋| 28558/40960 [01:54<00:43, 283.16batches/s, l2_loss: 0.1366 - round_los\u001b[A\n",
      "Training:  70%|▋| 28617/40960 [01:54<00:43, 286.26batches/s, l2_loss: 0.1366 - round_los\u001b[A\n",
      "Training:  70%|▋| 28617/40960 [01:54<00:43, 286.26batches/s, l2_loss: 0.1367 - round_los\u001b[A\n",
      "Training:  70%|▋| 28672/40960 [01:54<00:43, 282.07batches/s, l2_loss: 0.1367 - round_los\u001b[A\n",
      "Training:  70%|▋| 28672/40960 [01:54<00:43, 282.07batches/s, l2_loss: 0.1366 - round_los\u001b[A\n",
      "Training:  70%|▋| 28725/40960 [01:55<00:44, 276.64batches/s, l2_loss: 0.1366 - round_los\u001b[A\n",
      "Training:  70%|▋| 28725/40960 [01:55<00:44, 276.64batches/s, l2_loss: 0.1366 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28783/40960 [01:55<00:43, 279.86batches/s, l2_loss: 0.1366 - round_los\u001b[A\n",
      "Training:  70%|▋| 28783/40960 [01:55<00:43, 279.86batches/s, l2_loss: 0.1367 - round_los\u001b[A\n",
      "Training:  70%|▋| 28839/40960 [01:55<00:43, 278.71batches/s, l2_loss: 0.1367 - round_los\u001b[A\n",
      "Training:  70%|▋| 28839/40960 [01:55<00:43, 278.71batches/s, l2_loss: 0.1367 - round_los\u001b[A\n",
      "Training:  71%|▋| 28897/40960 [01:55<00:42, 281.41batches/s, l2_loss: 0.1367 - round_los\u001b[A\n",
      "Training:  71%|▋| 28897/40960 [01:55<00:42, 281.41batches/s, l2_loss: 0.1367 - round_los\u001b[A\n",
      "Training:  71%|▋| 28955/40960 [01:55<00:42, 282.41batches/s, l2_loss: 0.1367 - round_los\u001b[A\n",
      "Training:  71%|▋| 28955/40960 [01:55<00:42, 282.41batches/s, l2_loss: 0.1368 - round_los\u001b[A\n",
      "Training:  71%|▋| 29013/40960 [01:56<00:42, 283.64batches/s, l2_loss: 0.1368 - round_los\u001b[A\n",
      "Training:  71%|▋| 29013/40960 [01:56<00:42, 283.64batches/s, l2_loss: 0.1368 - round_los\u001b[A\n",
      "Training:  71%|▋| 29071/40960 [01:56<00:41, 284.26batches/s, l2_loss: 0.1368 - round_los\u001b[A\n",
      "Training:  71%|▋| 29071/40960 [01:56<00:41, 284.26batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  71%|▋| 29130/40960 [01:56<00:41, 286.32batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  71%|▋| 29130/40960 [01:56<00:41, 286.32batches/s, l2_loss: 0.1368 - round_los\u001b[A\n",
      "Training:  71%|▋| 29188/40960 [01:56<00:41, 286.59batches/s, l2_loss: 0.1368 - round_los\u001b[A\n",
      "Training:  71%|▋| 29188/40960 [01:56<00:41, 286.59batches/s, l2_loss: 0.1368 - round_los\u001b[A\n",
      "Training:  71%|▋| 29242/40960 [01:56<00:41, 281.17batches/s, l2_loss: 0.1368 - round_los\u001b[A\n",
      "Training:  71%|▋| 29242/40960 [01:56<00:41, 281.17batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  72%|▋| 29300/40960 [01:57<00:41, 283.27batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  72%|▋| 29300/40960 [01:57<00:41, 283.27batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  72%|▋| 29358/40960 [01:57<00:40, 284.17batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  72%|▋| 29358/40960 [01:57<00:40, 284.17batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  72%|▋| 29417/40960 [01:57<00:40, 286.44batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  72%|▋| 29417/40960 [01:57<00:40, 286.44batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  72%|▋| 29476/40960 [01:57<00:39, 288.01batches/s, l2_loss: 0.1369 - round_los\u001b[A\n",
      "Training:  72%|▋| 29476/40960 [01:57<00:39, 288.01batches/s, l2_loss: 0.1370 - round_los\u001b[A\n",
      "Training:  72%|▋| 29537/40960 [01:57<00:38, 292.97batches/s, l2_loss: 0.1370 - round_los\u001b[A\n",
      "Training:  72%|▋| 29537/40960 [01:57<00:38, 292.97batches/s, l2_loss: 0.1370 - round_los\u001b[A\n",
      "Training:  72%|▋| 29596/40960 [01:58<00:38, 292.50batches/s, l2_loss: 0.1370 - round_los\u001b[A\n",
      "Training:  72%|▋| 29596/40960 [01:58<00:38, 292.50batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  72%|▋| 29652/40960 [01:58<00:39, 288.60batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  72%|▋| 29652/40960 [01:58<00:39, 288.60batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29708/40960 [01:58<00:39, 285.58batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29708/40960 [01:58<00:39, 285.58batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29761/40960 [01:58<00:40, 278.83batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29761/40960 [01:58<00:40, 278.83batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29817/40960 [01:58<00:39, 279.03batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29817/40960 [01:58<00:39, 279.03batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29874/40960 [01:59<00:39, 280.69batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29874/40960 [01:59<00:39, 280.69batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29926/40960 [01:59<00:40, 274.21batches/s, l2_loss: 0.1371 - round_los\u001b[A\n",
      "Training:  73%|▋| 29926/40960 [01:59<00:40, 274.21batches/s, l2_loss: 0.1372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29986/40960 [01:59<00:39, 280.82batches/s, l2_loss: 0.1372 - round_los\u001b[A\n",
      "Training:  73%|▋| 29986/40960 [01:59<00:39, 280.82batches/s, l2_loss: 0.1372 - round_los\u001b[A\n",
      "Training:  73%|▋| 30040/40960 [01:59<00:39, 276.97batches/s, l2_loss: 0.1372 - round_los\u001b[A\n",
      "Training:  73%|▋| 30040/40960 [01:59<00:39, 276.97batches/s, l2_loss: 0.1372 - round_los\u001b[A\n",
      "Training:  73%|▋| 30096/40960 [01:59<00:39, 277.51batches/s, l2_loss: 0.1372 - round_los\u001b[A\n",
      "Training:  73%|▋| 30096/40960 [01:59<00:39, 277.51batches/s, l2_loss: 0.1373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30152/40960 [02:00<00:38, 277.26batches/s, l2_loss: 0.1373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30152/40960 [02:00<00:38, 277.26batches/s, l2_loss: 0.1373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30210/40960 [02:00<00:38, 279.55batches/s, l2_loss: 0.1373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30210/40960 [02:00<00:38, 279.55batches/s, l2_loss: 0.1373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30266/40960 [02:00<00:38, 278.59batches/s, l2_loss: 0.1373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30266/40960 [02:00<00:38, 278.59batches/s, l2_loss: 0.1373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30323/40960 [02:00<00:38, 279.69batches/s, l2_loss: 0.1373 - round_los\u001b[A\n",
      "Training:  74%|▋| 30323/40960 [02:00<00:38, 279.69batches/s, l2_loss: 0.1374 - round_los\u001b[A\n",
      "Training:  74%|▋| 30379/40960 [02:00<00:37, 278.65batches/s, l2_loss: 0.1374 - round_los\u001b[A\n",
      "Training:  74%|▋| 30379/40960 [02:00<00:37, 278.65batches/s, l2_loss: 0.1374 - round_los\u001b[A\n",
      "Training:  74%|▋| 30432/40960 [02:01<00:38, 274.21batches/s, l2_loss: 0.1374 - round_los\u001b[A\n",
      "Training:  74%|▋| 30432/40960 [02:01<00:38, 274.21batches/s, l2_loss: 0.1374 - round_los\u001b[A\n",
      "Training:  74%|▋| 30487/40960 [02:01<00:38, 274.38batches/s, l2_loss: 0.1374 - round_los\u001b[A\n",
      "Training:  74%|▋| 30487/40960 [02:01<00:38, 274.38batches/s, l2_loss: 0.1374 - round_los\u001b[A\n",
      "Training:  75%|▋| 30545/40960 [02:01<00:37, 278.99batches/s, l2_loss: 0.1374 - round_los\u001b[A\n",
      "Training:  75%|▋| 30545/40960 [02:01<00:37, 278.99batches/s, l2_loss: 0.1375 - round_los\u001b[A\n",
      "Training:  75%|▋| 30601/40960 [02:01<00:37, 278.40batches/s, l2_loss: 0.1375 - round_los\u001b[A\n",
      "Training:  75%|▋| 30601/40960 [02:01<00:37, 278.40batches/s, l2_loss: 0.1375 - round_los\u001b[A\n",
      "Training:  75%|▋| 30657/40960 [02:01<00:37, 277.38batches/s, l2_loss: 0.1375 - round_los\u001b[A\n",
      "Training:  75%|▋| 30657/40960 [02:02<00:37, 277.38batches/s, l2_loss: 0.1376 - round_los\u001b[A\n",
      "Training:  75%|▋| 30715/40960 [02:02<00:36, 281.12batches/s, l2_loss: 0.1376 - round_los\u001b[A\n",
      "Training:  75%|▋| 30715/40960 [02:02<00:36, 281.12batches/s, l2_loss: 0.1376 - round_los\u001b[A\n",
      "Training:  75%|▊| 30774/40960 [02:02<00:35, 284.37batches/s, l2_loss: 0.1376 - round_los\u001b[A\n",
      "Training:  75%|▊| 30774/40960 [02:02<00:35, 284.37batches/s, l2_loss: 0.1377 - round_los\u001b[A\n",
      "Training:  75%|▊| 30831/40960 [02:02<00:35, 284.08batches/s, l2_loss: 0.1377 - round_los\u001b[A\n",
      "Training:  75%|▊| 30831/40960 [02:02<00:35, 284.08batches/s, l2_loss: 0.1376 - round_los\u001b[A\n",
      "Training:  75%|▊| 30888/40960 [02:02<00:35, 282.74batches/s, l2_loss: 0.1376 - round_los\u001b[A\n",
      "Training:  75%|▊| 30888/40960 [02:02<00:35, 282.74batches/s, l2_loss: 0.1377 - round_los\u001b[A\n",
      "Training:  76%|▊| 30948/40960 [02:03<00:34, 286.91batches/s, l2_loss: 0.1377 - round_los\u001b[A\n",
      "Training:  76%|▊| 30948/40960 [02:03<00:34, 286.91batches/s, l2_loss: 0.1377 - round_los\u001b[A\n",
      "Training:  76%|▊| 31004/40960 [02:03<00:34, 284.79batches/s, l2_loss: 0.1377 - round_los\u001b[A\n",
      "Training:  76%|▊| 31004/40960 [02:03<00:34, 284.79batches/s, l2_loss: 0.1377 - round_los\u001b[A\n",
      "Training:  76%|▊| 31061/40960 [02:03<00:34, 284.35batches/s, l2_loss: 0.1377 - round_los\u001b[A\n",
      "Training:  76%|▊| 31061/40960 [02:03<00:34, 284.35batches/s, l2_loss: 0.1378 - round_los\u001b[A\n",
      "Training:  76%|▊| 31116/40960 [02:03<00:35, 280.26batches/s, l2_loss: 0.1378 - round_los\u001b[A\n",
      "Training:  76%|▊| 31116/40960 [02:03<00:35, 280.26batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  76%|▊| 31168/40960 [02:03<00:35, 274.08batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  76%|▊| 31168/40960 [02:03<00:35, 274.08batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  76%|▊| 31219/40960 [02:04<00:36, 267.79batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  76%|▊| 31219/40960 [02:04<00:36, 267.79batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  76%|▊| 31276/40960 [02:04<00:35, 272.50batches/s, l2_loss: 0.1379 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31276/40960 [02:04<00:35, 272.50batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  77%|▊| 31336/40960 [02:04<00:34, 280.20batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  77%|▊| 31336/40960 [02:04<00:34, 280.20batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  77%|▊| 31391/40960 [02:04<00:34, 277.31batches/s, l2_loss: 0.1379 - round_los\u001b[A\n",
      "Training:  77%|▊| 31391/40960 [02:04<00:34, 277.31batches/s, l2_loss: 0.1380 - round_los\u001b[A\n",
      "Training:  77%|▊| 31446/40960 [02:04<00:34, 275.73batches/s, l2_loss: 0.1380 - round_los\u001b[A\n",
      "Training:  77%|▊| 31446/40960 [02:04<00:34, 275.73batches/s, l2_loss: 0.1380 - round_los\u001b[A\n",
      "Training:  77%|▊| 31504/40960 [02:05<00:33, 279.45batches/s, l2_loss: 0.1380 - round_los\u001b[A\n",
      "Training:  77%|▊| 31504/40960 [02:05<00:33, 279.45batches/s, l2_loss: 0.1380 - round_los\u001b[A\n",
      "Training:  77%|▊| 31561/40960 [02:05<00:33, 280.24batches/s, l2_loss: 0.1380 - round_los\u001b[A\n",
      "Training:  77%|▊| 31561/40960 [02:05<00:33, 280.24batches/s, l2_loss: 0.1381 - round_los\u001b[A\n",
      "Training:  77%|▊| 31619/40960 [02:05<00:33, 282.19batches/s, l2_loss: 0.1381 - round_los\u001b[A\n",
      "Training:  77%|▊| 31619/40960 [02:05<00:33, 282.19batches/s, l2_loss: 0.1381 - round_los\u001b[A\n",
      "Training:  77%|▊| 31677/40960 [02:05<00:32, 283.89batches/s, l2_loss: 0.1381 - round_los\u001b[A\n",
      "Training:  77%|▊| 31677/40960 [02:05<00:32, 283.89batches/s, l2_loss: 0.1382 - round_los\u001b[A\n",
      "Training:  77%|▊| 31734/40960 [02:05<00:32, 283.56batches/s, l2_loss: 0.1382 - round_los\u001b[A\n",
      "Training:  77%|▊| 31734/40960 [02:05<00:32, 283.56batches/s, l2_loss: 0.1382 - round_los\u001b[A\n",
      "Training:  78%|▊| 31792/40960 [02:06<00:32, 284.30batches/s, l2_loss: 0.1382 - round_los\u001b[A\n",
      "Training:  78%|▊| 31792/40960 [02:06<00:32, 284.30batches/s, l2_loss: 0.1382 - round_los\u001b[A\n",
      "Training:  78%|▊| 31844/40960 [02:06<00:32, 276.49batches/s, l2_loss: 0.1382 - round_los\u001b[A\n",
      "Training:  78%|▊| 31844/40960 [02:06<00:32, 276.49batches/s, l2_loss: 0.1382 - round_los\u001b[A\n",
      "Training:  78%|▊| 31894/40960 [02:06<00:33, 268.00batches/s, l2_loss: 0.1382 - round_los\u001b[A\n",
      "Training:  78%|▊| 31894/40960 [02:06<00:33, 268.00batches/s, l2_loss: 0.1383 - round_los\u001b[A\n",
      "Training:  78%|▊| 31947/40960 [02:06<00:33, 266.28batches/s, l2_loss: 0.1383 - round_los\u001b[A\n",
      "Training:  78%|▊| 31947/40960 [02:06<00:33, 266.28batches/s, l2_loss: 0.1383 - round_los\u001b[A\n",
      "Training:  78%|▊| 32002/40960 [02:06<00:33, 268.59batches/s, l2_loss: 0.1383 - round_los\u001b[A\n",
      "Training:  78%|▊| 32002/40960 [02:06<00:33, 268.59batches/s, l2_loss: 0.1383 - round_los\u001b[A\n",
      "Training:  78%|▊| 32060/40960 [02:07<00:32, 274.06batches/s, l2_loss: 0.1383 - round_los\u001b[A\n",
      "Training:  78%|▊| 32060/40960 [02:07<00:32, 274.06batches/s, l2_loss: 0.1383 - round_los\u001b[A\n",
      "Training:  78%|▊| 32116/40960 [02:07<00:32, 274.71batches/s, l2_loss: 0.1383 - round_los\u001b[A\n",
      "Training:  78%|▊| 32116/40960 [02:07<00:32, 274.71batches/s, l2_loss: 0.1384 - round_los\u001b[A\n",
      "Training:  79%|▊| 32171/40960 [02:07<00:32, 274.63batches/s, l2_loss: 0.1384 - round_los\u001b[A\n",
      "Training:  79%|▊| 32171/40960 [02:07<00:32, 274.63batches/s, l2_loss: 0.1385 - round_los\u001b[A\n",
      "Training:  79%|▊| 32225/40960 [02:07<00:32, 271.72batches/s, l2_loss: 0.1385 - round_los\u001b[A\n",
      "Training:  79%|▊| 32225/40960 [02:07<00:32, 271.72batches/s, l2_loss: 0.1385 - round_los\u001b[A\n",
      "Training:  79%|▊| 32284/40960 [02:07<00:31, 277.85batches/s, l2_loss: 0.1385 - round_los\u001b[A\n",
      "Training:  79%|▊| 32284/40960 [02:07<00:31, 277.85batches/s, l2_loss: 0.1386 - round_los\u001b[A\n",
      "Training:  79%|▊| 32339/40960 [02:08<00:31, 276.89batches/s, l2_loss: 0.1386 - round_los\u001b[A\n",
      "Training:  79%|▊| 32339/40960 [02:08<00:31, 276.89batches/s, l2_loss: 0.1386 - round_los\u001b[A\n",
      "Training:  79%|▊| 32394/40960 [02:08<00:31, 275.30batches/s, l2_loss: 0.1386 - round_los\u001b[A\n",
      "Training:  79%|▊| 32394/40960 [02:08<00:31, 275.30batches/s, l2_loss: 0.1386 - round_los\u001b[A\n",
      "Training:  79%|▊| 32449/40960 [02:08<00:30, 274.84batches/s, l2_loss: 0.1386 - round_los\u001b[A\n",
      "Training:  79%|▊| 32449/40960 [02:08<00:30, 274.84batches/s, l2_loss: 0.1386 - round_los\u001b[A\n",
      "Training:  79%|▊| 32502/40960 [02:08<00:31, 270.39batches/s, l2_loss: 0.1386 - round_los\u001b[A\n",
      "Training:  79%|▊| 32502/40960 [02:08<00:31, 270.39batches/s, l2_loss: 0.1387 - round_los\u001b[A\n",
      "Training:  79%|▊| 32553/40960 [02:08<00:31, 265.73batches/s, l2_loss: 0.1387 - round_los\u001b[A\n",
      "Training:  79%|▊| 32553/40960 [02:08<00:31, 265.73batches/s, l2_loss: 0.1387 - round_los\u001b[A\n",
      "Training:  80%|▊| 32607/40960 [02:09<00:31, 265.71batches/s, l2_loss: 0.1387 - round_los\u001b[A\n",
      "Training:  80%|▊| 32607/40960 [02:09<00:31, 265.71batches/s, l2_loss: 0.1387 - round_los\u001b[A\n",
      "Training:  80%|▊| 32657/40960 [02:09<00:31, 260.67batches/s, l2_loss: 0.1387 - round_los\u001b[A\n",
      "Training:  80%|▊| 32657/40960 [02:09<00:31, 260.67batches/s, l2_loss: 0.1388 - round_los\u001b[A\n",
      "Training:  80%|▊| 32711/40960 [02:09<00:31, 262.83batches/s, l2_loss: 0.1388 - round_los\u001b[A\n",
      "Training:  80%|▊| 32711/40960 [02:09<00:31, 262.83batches/s, l2_loss: 0.1388 - round_los\u001b[A\n",
      "Training:  80%|▊| 32768/40960 [02:09<00:30, 268.88batches/s, l2_loss: 0.1388 - round_los\u001b[A\n",
      "Training:  80%|▊| 32768/40960 [02:09<00:30, 268.88batches/s, l2_loss: 0.1388 - round_los\u001b[A\n",
      "Training:  80%|▊| 32827/40960 [02:09<00:29, 276.40batches/s, l2_loss: 0.1388 - round_los\u001b[A\n",
      "Training:  80%|▊| 32827/40960 [02:09<00:29, 276.40batches/s, l2_loss: 0.1389 - round_los\u001b[A\n",
      "Training:  80%|▊| 32883/40960 [02:10<00:29, 277.22batches/s, l2_loss: 0.1389 - round_los\u001b[A\n",
      "Training:  80%|▊| 32883/40960 [02:10<00:29, 277.22batches/s, l2_loss: 0.1389 - round_los\u001b[A\n",
      "Training:  80%|▊| 32938/40960 [02:10<00:29, 275.81batches/s, l2_loss: 0.1389 - round_los\u001b[A\n",
      "Training:  80%|▊| 32938/40960 [02:10<00:29, 275.81batches/s, l2_loss: 0.1390 - round_los\u001b[A\n",
      "Training:  81%|▊| 32992/40960 [02:10<00:29, 273.06batches/s, l2_loss: 0.1390 - round_los\u001b[A\n",
      "Training:  81%|▊| 32992/40960 [02:10<00:29, 273.06batches/s, l2_loss: 0.1390 - round_los\u001b[A\n",
      "Training:  81%|▊| 33048/40960 [02:10<00:28, 274.59batches/s, l2_loss: 0.1390 - round_los\u001b[A\n",
      "Training:  81%|▊| 33048/40960 [02:10<00:28, 274.59batches/s, l2_loss: 0.1390 - round_los\u001b[A\n",
      "Training:  81%|▊| 33107/40960 [02:10<00:28, 279.51batches/s, l2_loss: 0.1390 - round_los\u001b[A\n",
      "Training:  81%|▊| 33107/40960 [02:10<00:28, 279.51batches/s, l2_loss: 0.1390 - round_los\u001b[A\n",
      "Training:  81%|▊| 33165/40960 [02:11<00:27, 281.61batches/s, l2_loss: 0.1390 - round_los\u001b[A\n",
      "Training:  81%|▊| 33165/40960 [02:11<00:27, 281.61batches/s, l2_loss: 0.1391 - round_los\u001b[A\n",
      "Training:  81%|▊| 33223/40960 [02:11<00:27, 282.97batches/s, l2_loss: 0.1391 - round_los\u001b[A\n",
      "Training:  81%|▊| 33223/40960 [02:11<00:27, 282.97batches/s, l2_loss: 0.1391 - round_los\u001b[A\n",
      "Training:  81%|▊| 33281/40960 [02:11<00:27, 283.99batches/s, l2_loss: 0.1391 - round_los\u001b[A\n",
      "Training:  81%|▊| 33281/40960 [02:11<00:27, 283.99batches/s, l2_loss: 0.1392 - round_los\u001b[A\n",
      "Training:  81%|▊| 33338/40960 [02:11<00:26, 283.81batches/s, l2_loss: 0.1392 - round_los\u001b[A\n",
      "Training:  81%|▊| 33338/40960 [02:11<00:26, 283.81batches/s, l2_loss: 0.1392 - round_los\u001b[A\n",
      "Training:  82%|▊| 33394/40960 [02:11<00:26, 281.67batches/s, l2_loss: 0.1392 - round_los\u001b[A\n",
      "Training:  82%|▊| 33394/40960 [02:11<00:26, 281.67batches/s, l2_loss: 0.1393 - round_los\u001b[A\n",
      "Training:  82%|▊| 33453/40960 [02:12<00:26, 285.01batches/s, l2_loss: 0.1393 - round_los\u001b[A\n",
      "Training:  82%|▊| 33453/40960 [02:12<00:26, 285.01batches/s, l2_loss: 0.1393 - round_los\u001b[A\n",
      "Training:  82%|▊| 33510/40960 [02:12<00:26, 283.68batches/s, l2_loss: 0.1393 - round_los\u001b[A\n",
      "Training:  82%|▊| 33510/40960 [02:12<00:26, 283.68batches/s, l2_loss: 0.1394 - round_los\u001b[A\n",
      "Training:  82%|▊| 33566/40960 [02:12<00:26, 281.49batches/s, l2_loss: 0.1394 - round_los\u001b[A\n",
      "Training:  82%|▊| 33566/40960 [02:12<00:26, 281.49batches/s, l2_loss: 0.1395 - round_los\u001b[A\n",
      "Training:  82%|▊| 33621/40960 [02:12<00:26, 278.33batches/s, l2_loss: 0.1395 - round_los\u001b[A\n",
      "Training:  82%|▊| 33621/40960 [02:12<00:26, 278.33batches/s, l2_loss: 0.1395 - round_los\u001b[A\n",
      "Training:  82%|▊| 33678/40960 [02:12<00:26, 279.36batches/s, l2_loss: 0.1395 - round_los\u001b[A\n",
      "Training:  82%|▊| 33678/40960 [02:12<00:26, 279.36batches/s, l2_loss: 0.1395 - round_los\u001b[A\n",
      "Training:  82%|▊| 33730/40960 [02:13<00:26, 272.41batches/s, l2_loss: 0.1395 - round_los\u001b[A\n",
      "Training:  82%|▊| 33730/40960 [02:13<00:26, 272.41batches/s, l2_loss: 0.1395 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|▊| 33781/40960 [02:13<00:27, 265.69batches/s, l2_loss: 0.1395 - round_los\u001b[A\n",
      "Training:  82%|▊| 33781/40960 [02:13<00:27, 265.69batches/s, l2_loss: 0.1396 - round_los\u001b[A\n",
      "Training:  83%|▊| 33835/40960 [02:13<00:26, 266.78batches/s, l2_loss: 0.1396 - round_los\u001b[A\n",
      "Training:  83%|▊| 33835/40960 [02:13<00:26, 266.78batches/s, l2_loss: 0.1396 - round_los\u001b[A\n",
      "Training:  83%|▊| 33893/40960 [02:13<00:25, 272.88batches/s, l2_loss: 0.1396 - round_los\u001b[A\n",
      "Training:  83%|▊| 33893/40960 [02:13<00:25, 272.88batches/s, l2_loss: 0.1397 - round_los\u001b[A\n",
      "Training:  83%|▊| 33945/40960 [02:13<00:26, 267.39batches/s, l2_loss: 0.1397 - round_los\u001b[A\n",
      "Training:  83%|▊| 33945/40960 [02:13<00:26, 267.39batches/s, l2_loss: 0.1397 - round_los\u001b[A\n",
      "Training:  83%|▊| 34002/40960 [02:14<00:25, 272.39batches/s, l2_loss: 0.1397 - round_los\u001b[A\n",
      "Training:  83%|▊| 34002/40960 [02:14<00:25, 272.39batches/s, l2_loss: 0.1398 - round_los\u001b[A\n",
      "Training:  83%|▊| 34057/40960 [02:14<00:25, 272.09batches/s, l2_loss: 0.1398 - round_los\u001b[A\n",
      "Training:  83%|▊| 34057/40960 [02:14<00:25, 272.09batches/s, l2_loss: 0.1398 - round_los\u001b[A\n",
      "Training:  83%|▊| 34114/40960 [02:14<00:24, 275.02batches/s, l2_loss: 0.1398 - round_los\u001b[A\n",
      "Training:  83%|▊| 34114/40960 [02:14<00:24, 275.02batches/s, l2_loss: 0.1399 - round_los\u001b[A\n",
      "Training:  83%|▊| 34171/40960 [02:14<00:24, 277.49batches/s, l2_loss: 0.1399 - round_los\u001b[A\n",
      "Training:  83%|▊| 34171/40960 [02:14<00:24, 277.49batches/s, l2_loss: 0.1399 - round_los\u001b[A\n",
      "Training:  84%|▊| 34228/40960 [02:14<00:24, 279.61batches/s, l2_loss: 0.1399 - round_los\u001b[A\n",
      "Training:  84%|▊| 34228/40960 [02:14<00:24, 279.61batches/s, l2_loss: 0.1400 - round_los\u001b[A\n",
      "Training:  84%|▊| 34285/40960 [02:15<00:23, 280.01batches/s, l2_loss: 0.1400 - round_los\u001b[A\n",
      "Training:  84%|▊| 34285/40960 [02:15<00:23, 280.01batches/s, l2_loss: 0.1400 - round_los\u001b[A\n",
      "Training:  84%|▊| 34344/40960 [02:15<00:23, 283.87batches/s, l2_loss: 0.1400 - round_los\u001b[A\n",
      "Training:  84%|▊| 34344/40960 [02:15<00:23, 283.87batches/s, l2_loss: 0.1401 - round_los\u001b[A\n",
      "Training:  84%|▊| 34405/40960 [02:15<00:22, 289.04batches/s, l2_loss: 0.1401 - round_los\u001b[A\n",
      "Training:  84%|▊| 34405/40960 [02:15<00:22, 289.04batches/s, l2_loss: 0.1401 - round_los\u001b[A\n",
      "Training:  84%|▊| 34462/40960 [02:15<00:22, 286.85batches/s, l2_loss: 0.1401 - round_los\u001b[A\n",
      "Training:  84%|▊| 34462/40960 [02:15<00:22, 286.85batches/s, l2_loss: 0.1401 - round_los\u001b[A\n",
      "Training:  84%|▊| 34519/40960 [02:15<00:22, 285.14batches/s, l2_loss: 0.1401 - round_los\u001b[A\n",
      "Training:  84%|▊| 34519/40960 [02:15<00:22, 285.14batches/s, l2_loss: 0.1402 - round_los\u001b[A\n",
      "Training:  84%|▊| 34578/40960 [02:16<00:22, 287.89batches/s, l2_loss: 0.1402 - round_los\u001b[A\n",
      "Training:  84%|▊| 34578/40960 [02:16<00:22, 287.89batches/s, l2_loss: 0.1403 - round_los\u001b[A\n",
      "Training:  85%|▊| 34638/40960 [02:16<00:21, 290.31batches/s, l2_loss: 0.1403 - round_los\u001b[A\n",
      "Training:  85%|▊| 34638/40960 [02:16<00:21, 290.31batches/s, l2_loss: 0.1403 - round_los\u001b[A\n",
      "Training:  85%|▊| 34697/40960 [02:16<00:21, 290.79batches/s, l2_loss: 0.1403 - round_los\u001b[A\n",
      "Training:  85%|▊| 34697/40960 [02:16<00:21, 290.79batches/s, l2_loss: 0.1404 - round_los\u001b[A\n",
      "Training:  85%|▊| 34756/40960 [02:16<00:21, 291.43batches/s, l2_loss: 0.1404 - round_los\u001b[A\n",
      "Training:  85%|▊| 34756/40960 [02:16<00:21, 291.43batches/s, l2_loss: 0.1405 - round_los\u001b[A\n",
      "Training:  85%|▊| 34814/40960 [02:16<00:21, 290.05batches/s, l2_loss: 0.1405 - round_los\u001b[A\n",
      "Training:  85%|▊| 34814/40960 [02:16<00:21, 290.05batches/s, l2_loss: 0.1405 - round_los\u001b[A\n",
      "Training:  85%|▊| 34872/40960 [02:17<00:21, 288.81batches/s, l2_loss: 0.1405 - round_los\u001b[A\n",
      "Training:  85%|▊| 34872/40960 [02:17<00:21, 288.81batches/s, l2_loss: 0.1406 - round_los\u001b[A\n",
      "Training:  85%|▊| 34929/40960 [02:17<00:21, 286.47batches/s, l2_loss: 0.1406 - round_los\u001b[A\n",
      "Training:  85%|▊| 34929/40960 [02:17<00:21, 286.47batches/s, l2_loss: 0.1406 - round_los\u001b[A\n",
      "Training:  85%|▊| 34986/40960 [02:17<00:20, 285.34batches/s, l2_loss: 0.1406 - round_los\u001b[A\n",
      "Training:  85%|▊| 34986/40960 [02:17<00:20, 285.34batches/s, l2_loss: 0.1407 - round_los\u001b[A\n",
      "Training:  86%|▊| 35044/40960 [02:17<00:20, 285.67batches/s, l2_loss: 0.1407 - round_los\u001b[A\n",
      "Training:  86%|▊| 35044/40960 [02:17<00:20, 285.67batches/s, l2_loss: 0.1407 - round_los\u001b[A\n",
      "Training:  86%|▊| 35100/40960 [02:17<00:20, 283.73batches/s, l2_loss: 0.1407 - round_los\u001b[A\n",
      "Training:  86%|▊| 35100/40960 [02:17<00:20, 283.73batches/s, l2_loss: 0.1408 - round_los\u001b[A\n",
      "Training:  86%|▊| 35157/40960 [02:18<00:20, 283.30batches/s, l2_loss: 0.1408 - round_los\u001b[A\n",
      "Training:  86%|▊| 35157/40960 [02:18<00:20, 283.30batches/s, l2_loss: 0.1408 - round_los\u001b[A\n",
      "Training:  86%|▊| 35213/40960 [02:18<00:20, 281.04batches/s, l2_loss: 0.1408 - round_los\u001b[A\n",
      "Training:  86%|▊| 35213/40960 [02:18<00:20, 281.04batches/s, l2_loss: 0.1409 - round_los\u001b[A\n",
      "Training:  86%|▊| 35263/40960 [02:18<00:21, 270.81batches/s, l2_loss: 0.1409 - round_los\u001b[A\n",
      "Training:  86%|▊| 35263/40960 [02:18<00:21, 270.81batches/s, l2_loss: 0.1410 - round_los\u001b[A\n",
      "Training:  86%|▊| 35314/40960 [02:18<00:21, 265.60batches/s, l2_loss: 0.1410 - round_los\u001b[A\n",
      "Training:  86%|▊| 35314/40960 [02:18<00:21, 265.60batches/s, l2_loss: 0.1410 - round_los\u001b[A\n",
      "Training:  86%|▊| 35372/40960 [02:18<00:20, 272.34batches/s, l2_loss: 0.1410 - round_los\u001b[A\n",
      "Training:  86%|▊| 35372/40960 [02:18<00:20, 272.34batches/s, l2_loss: 0.1411 - round_los\u001b[A\n",
      "Training:  86%|▊| 35430/40960 [02:19<00:19, 277.25batches/s, l2_loss: 0.1411 - round_los\u001b[A\n",
      "Training:  86%|▊| 35430/40960 [02:19<00:19, 277.25batches/s, l2_loss: 0.1411 - round_los\u001b[A\n",
      "Training:  87%|▊| 35486/40960 [02:19<00:19, 277.44batches/s, l2_loss: 0.1411 - round_los\u001b[A\n",
      "Training:  87%|▊| 35486/40960 [02:19<00:19, 277.44batches/s, l2_loss: 0.1412 - round_los\u001b[A\n",
      "Training:  87%|▊| 35536/40960 [02:19<00:20, 268.61batches/s, l2_loss: 0.1412 - round_los\u001b[A\n",
      "Training:  87%|▊| 35536/40960 [02:19<00:20, 268.61batches/s, l2_loss: 0.1413 - round_los\u001b[A\n",
      "Training:  87%|▊| 35593/40960 [02:19<00:19, 272.46batches/s, l2_loss: 0.1413 - round_los\u001b[A\n",
      "Training:  87%|▊| 35593/40960 [02:19<00:19, 272.46batches/s, l2_loss: 0.1413 - round_los\u001b[A\n",
      "Training:  87%|▊| 35650/40960 [02:19<00:19, 275.48batches/s, l2_loss: 0.1413 - round_los\u001b[A\n",
      "Training:  87%|▊| 35650/40960 [02:19<00:19, 275.48batches/s, l2_loss: 0.1414 - round_los\u001b[A\n",
      "Training:  87%|▊| 35707/40960 [02:20<00:18, 278.06batches/s, l2_loss: 0.1414 - round_los\u001b[A\n",
      "Training:  87%|▊| 35707/40960 [02:20<00:18, 278.06batches/s, l2_loss: 0.1415 - round_los\u001b[A\n",
      "Training:  87%|▊| 35760/40960 [02:20<00:18, 274.11batches/s, l2_loss: 0.1415 - round_los\u001b[A\n",
      "Training:  87%|▊| 35760/40960 [02:20<00:18, 274.11batches/s, l2_loss: 0.1415 - round_los\u001b[A\n",
      "Training:  87%|▊| 35816/40960 [02:20<00:18, 275.62batches/s, l2_loss: 0.1415 - round_los\u001b[A\n",
      "Training:  87%|▊| 35816/40960 [02:20<00:18, 275.62batches/s, l2_loss: 0.1416 - round_los\u001b[A\n",
      "Training:  88%|▉| 35873/40960 [02:20<00:18, 278.10batches/s, l2_loss: 0.1416 - round_los\u001b[A\n",
      "Training:  88%|▉| 35873/40960 [02:20<00:18, 278.10batches/s, l2_loss: 0.1417 - round_los\u001b[A\n",
      "Training:  88%|▉| 35926/40960 [02:20<00:18, 273.03batches/s, l2_loss: 0.1417 - round_los\u001b[A\n",
      "Training:  88%|▉| 35926/40960 [02:20<00:18, 273.03batches/s, l2_loss: 0.1417 - round_los\u001b[A\n",
      "Training:  88%|▉| 35985/40960 [02:21<00:17, 279.17batches/s, l2_loss: 0.1417 - round_los\u001b[A\n",
      "Training:  88%|▉| 35985/40960 [02:21<00:17, 279.17batches/s, l2_loss: 0.1418 - round_los\u001b[A\n",
      "Training:  88%|▉| 36043/40960 [02:21<00:17, 282.14batches/s, l2_loss: 0.1418 - round_los\u001b[A\n",
      "Training:  88%|▉| 36043/40960 [02:21<00:17, 282.14batches/s, l2_loss: 0.1419 - round_los\u001b[A\n",
      "Training:  88%|▉| 36099/40960 [02:21<00:17, 280.61batches/s, l2_loss: 0.1419 - round_los\u001b[A\n",
      "Training:  88%|▉| 36099/40960 [02:21<00:17, 280.61batches/s, l2_loss: 0.1419 - round_los\u001b[A\n",
      "Training:  88%|▉| 36158/40960 [02:21<00:16, 284.06batches/s, l2_loss: 0.1419 - round_los\u001b[A\n",
      "Training:  88%|▉| 36158/40960 [02:21<00:16, 284.06batches/s, l2_loss: 0.1420 - round_los\u001b[A\n",
      "Training:  88%|▉| 36217/40960 [02:21<00:16, 287.04batches/s, l2_loss: 0.1420 - round_los\u001b[A\n",
      "Training:  88%|▉| 36217/40960 [02:21<00:16, 287.04batches/s, l2_loss: 0.1421 - round_los\u001b[A\n",
      "Training:  89%|▉| 36276/40960 [02:22<00:16, 288.12batches/s, l2_loss: 0.1421 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36276/40960 [02:22<00:16, 288.12batches/s, l2_loss: 0.1422 - round_los\u001b[A\n",
      "Training:  89%|▉| 36334/40960 [02:22<00:16, 288.32batches/s, l2_loss: 0.1422 - round_los\u001b[A\n",
      "Training:  89%|▉| 36334/40960 [02:22<00:16, 288.32batches/s, l2_loss: 0.1422 - round_los\u001b[A\n",
      "Training:  89%|▉| 36394/40960 [02:22<00:15, 291.22batches/s, l2_loss: 0.1422 - round_los\u001b[A\n",
      "Training:  89%|▉| 36394/40960 [02:22<00:15, 291.22batches/s, l2_loss: 0.1423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36451/40960 [02:22<00:15, 288.93batches/s, l2_loss: 0.1423 - round_los\u001b[A\n",
      "Training:  89%|▉| 36451/40960 [02:22<00:15, 288.93batches/s, l2_loss: 0.1424 - round_los\u001b[A\n",
      "Training:  89%|▉| 36509/40960 [02:22<00:15, 288.07batches/s, l2_loss: 0.1424 - round_los\u001b[A\n",
      "Training:  89%|▉| 36509/40960 [02:22<00:15, 288.07batches/s, l2_loss: 0.1424 - round_los\u001b[A\n",
      "Training:  89%|▉| 36562/40960 [02:23<00:15, 279.50batches/s, l2_loss: 0.1424 - round_los\u001b[A\n",
      "Training:  89%|▉| 36562/40960 [02:23<00:15, 279.50batches/s, l2_loss: 0.1425 - round_los\u001b[A\n",
      "Training:  89%|▉| 36616/40960 [02:23<00:15, 275.42batches/s, l2_loss: 0.1425 - round_los\u001b[A\n",
      "Training:  89%|▉| 36616/40960 [02:23<00:15, 275.42batches/s, l2_loss: 0.1426 - round_los\u001b[A\n",
      "Training:  90%|▉| 36675/40960 [02:23<00:15, 280.33batches/s, l2_loss: 0.1426 - round_los\u001b[A\n",
      "Training:  90%|▉| 36675/40960 [02:23<00:15, 280.33batches/s, l2_loss: 0.1427 - round_los\u001b[A\n",
      "Training:  90%|▉| 36730/40960 [02:23<00:15, 276.61batches/s, l2_loss: 0.1427 - round_los\u001b[A\n",
      "Training:  90%|▉| 36730/40960 [02:23<00:15, 276.61batches/s, l2_loss: 0.1427 - round_los\u001b[A\n",
      "Training:  90%|▉| 36787/40960 [02:24<00:14, 278.46batches/s, l2_loss: 0.1427 - round_los\u001b[A\n",
      "Training:  90%|▉| 36787/40960 [02:24<00:14, 278.46batches/s, l2_loss: 0.1428 - round_los\u001b[A\n",
      "Training:  90%|▉| 36845/40960 [02:24<00:14, 280.82batches/s, l2_loss: 0.1428 - round_los\u001b[A\n",
      "Training:  90%|▉| 36845/40960 [02:24<00:14, 280.82batches/s, l2_loss: 0.1429 - round_los\u001b[A\n",
      "Training:  90%|▉| 36900/40960 [02:24<00:14, 278.57batches/s, l2_loss: 0.1429 - round_los\u001b[A\n",
      "Training:  90%|▉| 36900/40960 [02:24<00:14, 278.57batches/s, l2_loss: 0.1429 - round_los\u001b[A\n",
      "Training:  90%|▉| 36959/40960 [02:24<00:14, 282.55batches/s, l2_loss: 0.1429 - round_los\u001b[A\n",
      "Training:  90%|▉| 36959/40960 [02:24<00:14, 282.55batches/s, l2_loss: 0.1430 - round_los\u001b[A\n",
      "Training:  90%|▉| 37013/40960 [02:24<00:14, 277.49batches/s, l2_loss: 0.1430 - round_los\u001b[A\n",
      "Training:  90%|▉| 37013/40960 [02:24<00:14, 277.49batches/s, l2_loss: 0.1431 - round_los\u001b[A\n",
      "Training:  90%|▉| 37065/40960 [02:25<00:14, 272.08batches/s, l2_loss: 0.1431 - round_los\u001b[A\n",
      "Training:  90%|▉| 37065/40960 [02:25<00:14, 272.08batches/s, l2_loss: 0.1432 - round_los\u001b[A\n",
      "Training:  91%|▉| 37115/40960 [02:25<00:14, 263.97batches/s, l2_loss: 0.1432 - round_los\u001b[A\n",
      "Training:  91%|▉| 37115/40960 [02:25<00:14, 263.97batches/s, l2_loss: 0.1432 - round_los\u001b[A\n",
      "Training:  91%|▉| 37167/40960 [02:25<00:14, 261.58batches/s, l2_loss: 0.1432 - round_los\u001b[A\n",
      "Training:  91%|▉| 37167/40960 [02:25<00:14, 261.58batches/s, l2_loss: 0.1432 - round_los\u001b[A\n",
      "Training:  91%|▉| 37224/40960 [02:25<00:13, 268.08batches/s, l2_loss: 0.1432 - round_los\u001b[A\n",
      "Training:  91%|▉| 37224/40960 [02:25<00:13, 268.08batches/s, l2_loss: 0.1433 - round_los\u001b[A\n",
      "Training:  91%|▉| 37283/40960 [02:25<00:13, 274.97batches/s, l2_loss: 0.1433 - round_los\u001b[A\n",
      "Training:  91%|▉| 37283/40960 [02:25<00:13, 274.97batches/s, l2_loss: 0.1434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37342/40960 [02:26<00:12, 279.66batches/s, l2_loss: 0.1434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37342/40960 [02:26<00:12, 279.66batches/s, l2_loss: 0.1435 - round_los\u001b[A\n",
      "Training:  91%|▉| 37401/40960 [02:26<00:12, 282.92batches/s, l2_loss: 0.1435 - round_los\u001b[A\n",
      "Training:  91%|▉| 37401/40960 [02:26<00:12, 282.92batches/s, l2_loss: 0.1436 - round_los\u001b[A\n",
      "Training:  91%|▉| 37460/40960 [02:26<00:12, 285.12batches/s, l2_loss: 0.1436 - round_los\u001b[A\n",
      "Training:  91%|▉| 37460/40960 [02:26<00:12, 285.12batches/s, l2_loss: 0.1437 - round_los\u001b[A\n",
      "Training:  92%|▉| 37518/40960 [02:26<00:12, 285.96batches/s, l2_loss: 0.1437 - round_los\u001b[A\n",
      "Training:  92%|▉| 37518/40960 [02:26<00:12, 285.96batches/s, l2_loss: 0.1437 - round_los\u001b[A\n",
      "Training:  92%|▉| 37575/40960 [02:26<00:11, 285.31batches/s, l2_loss: 0.1437 - round_los\u001b[A\n",
      "Training:  92%|▉| 37575/40960 [02:26<00:11, 285.31batches/s, l2_loss: 0.1438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37633/40960 [02:27<00:11, 285.86batches/s, l2_loss: 0.1438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37633/40960 [02:27<00:11, 285.86batches/s, l2_loss: 0.1439 - round_los\u001b[A\n",
      "Training:  92%|▉| 37690/40960 [02:27<00:11, 284.95batches/s, l2_loss: 0.1439 - round_los\u001b[A\n",
      "Training:  92%|▉| 37690/40960 [02:27<00:11, 284.95batches/s, l2_loss: 0.1440 - round_los\u001b[A\n",
      "Training:  92%|▉| 37750/40960 [02:27<00:11, 288.41batches/s, l2_loss: 0.1440 - round_los\u001b[A\n",
      "Training:  92%|▉| 37750/40960 [02:27<00:11, 288.41batches/s, l2_loss: 0.1441 - round_los\u001b[A\n",
      "Training:  92%|▉| 37803/40960 [02:27<00:11, 280.67batches/s, l2_loss: 0.1441 - round_los\u001b[A\n",
      "Training:  92%|▉| 37803/40960 [02:27<00:11, 280.67batches/s, l2_loss: 0.1441 - round_los\u001b[A\n",
      "Training:  92%|▉| 37859/40960 [02:27<00:11, 279.87batches/s, l2_loss: 0.1441 - round_los\u001b[A\n",
      "Training:  92%|▉| 37859/40960 [02:27<00:11, 279.87batches/s, l2_loss: 0.1442 - round_los\u001b[A\n",
      "Training:  93%|▉| 37916/40960 [02:28<00:10, 279.98batches/s, l2_loss: 0.1442 - round_los\u001b[A\n",
      "Training:  93%|▉| 37916/40960 [02:28<00:10, 279.98batches/s, l2_loss: 0.1443 - round_los\u001b[A\n",
      "Training:  93%|▉| 37969/40960 [02:28<00:10, 275.15batches/s, l2_loss: 0.1443 - round_los\u001b[A\n",
      "Training:  93%|▉| 37969/40960 [02:28<00:10, 275.15batches/s, l2_loss: 0.1444 - round_los\u001b[A\n",
      "Training:  93%|▉| 38025/40960 [02:28<00:10, 276.24batches/s, l2_loss: 0.1444 - round_los\u001b[A\n",
      "Training:  93%|▉| 38025/40960 [02:28<00:10, 276.24batches/s, l2_loss: 0.1445 - round_los\u001b[A\n",
      "Training:  93%|▉| 38075/40960 [02:28<00:10, 267.18batches/s, l2_loss: 0.1445 - round_los\u001b[A\n",
      "Training:  93%|▉| 38075/40960 [02:28<00:10, 267.18batches/s, l2_loss: 0.1445 - round_los\u001b[A\n",
      "Training:  93%|▉| 38128/40960 [02:28<00:10, 266.34batches/s, l2_loss: 0.1445 - round_los\u001b[A\n",
      "Training:  93%|▉| 38128/40960 [02:28<00:10, 266.34batches/s, l2_loss: 0.1446 - round_los\u001b[A\n",
      "Training:  93%|▉| 38179/40960 [02:29<00:10, 262.61batches/s, l2_loss: 0.1446 - round_los\u001b[A\n",
      "Training:  93%|▉| 38179/40960 [02:29<00:10, 262.61batches/s, l2_loss: 0.1447 - round_los\u001b[A\n",
      "Training:  93%|▉| 38236/40960 [02:29<00:10, 268.41batches/s, l2_loss: 0.1447 - round_los\u001b[A\n",
      "Training:  93%|▉| 38236/40960 [02:29<00:10, 268.41batches/s, l2_loss: 0.1447 - round_los\u001b[A\n",
      "Training:  93%|▉| 38290/40960 [02:29<00:09, 268.19batches/s, l2_loss: 0.1447 - round_los\u001b[A\n",
      "Training:  93%|▉| 38290/40960 [02:29<00:09, 268.19batches/s, l2_loss: 0.1448 - round_los\u001b[A\n",
      "Training:  94%|▉| 38346/40960 [02:29<00:09, 271.12batches/s, l2_loss: 0.1448 - round_los\u001b[A\n",
      "Training:  94%|▉| 38346/40960 [02:29<00:09, 271.12batches/s, l2_loss: 0.1449 - round_los\u001b[A\n",
      "Training:  94%|▉| 38404/40960 [02:29<00:09, 276.52batches/s, l2_loss: 0.1449 - round_los\u001b[A\n",
      "Training:  94%|▉| 38404/40960 [02:29<00:09, 276.52batches/s, l2_loss: 0.1450 - round_los\u001b[A\n",
      "Training:  94%|▉| 38463/40960 [02:30<00:08, 281.22batches/s, l2_loss: 0.1450 - round_los\u001b[A\n",
      "Training:  94%|▉| 38463/40960 [02:30<00:08, 281.22batches/s, l2_loss: 0.1451 - round_los\u001b[A\n",
      "Training:  94%|▉| 38518/40960 [02:30<00:08, 279.29batches/s, l2_loss: 0.1451 - round_los\u001b[A\n",
      "Training:  94%|▉| 38518/40960 [02:30<00:08, 279.29batches/s, l2_loss: 0.1452 - round_los\u001b[A\n",
      "Training:  94%|▉| 38577/40960 [02:30<00:08, 283.74batches/s, l2_loss: 0.1452 - round_los\u001b[A\n",
      "Training:  94%|▉| 38577/40960 [02:30<00:08, 283.74batches/s, l2_loss: 0.1452 - round_los\u001b[A\n",
      "Training:  94%|▉| 38637/40960 [02:30<00:08, 287.78batches/s, l2_loss: 0.1452 - round_los\u001b[A\n",
      "Training:  94%|▉| 38637/40960 [02:30<00:08, 287.78batches/s, l2_loss: 0.1454 - round_los\u001b[A\n",
      "Training:  94%|▉| 38697/40960 [02:30<00:07, 291.31batches/s, l2_loss: 0.1454 - round_los\u001b[A\n",
      "Training:  94%|▉| 38697/40960 [02:30<00:07, 291.31batches/s, l2_loss: 0.1454 - round_los\u001b[A\n",
      "Training:  95%|▉| 38748/40960 [02:31<00:07, 277.90batches/s, l2_loss: 0.1454 - round_los\u001b[A\n",
      "Training:  95%|▉| 38748/40960 [02:31<00:07, 277.90batches/s, l2_loss: 0.1455 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|▉| 38805/40960 [02:31<00:07, 278.88batches/s, l2_loss: 0.1455 - round_los\u001b[A\n",
      "Training:  95%|▉| 38805/40960 [02:31<00:07, 278.88batches/s, l2_loss: 0.1456 - round_los\u001b[A\n",
      "Training:  95%|▉| 38863/40960 [02:31<00:07, 281.24batches/s, l2_loss: 0.1456 - round_los\u001b[A\n",
      "Training:  95%|▉| 38863/40960 [02:31<00:07, 281.24batches/s, l2_loss: 0.1457 - round_los\u001b[A\n",
      "Training:  95%|▉| 38922/40960 [02:31<00:07, 284.36batches/s, l2_loss: 0.1457 - round_los\u001b[A\n",
      "Training:  95%|▉| 38922/40960 [02:31<00:07, 284.36batches/s, l2_loss: 0.1457 - round_los\u001b[A\n",
      "Training:  95%|▉| 38974/40960 [02:31<00:07, 275.94batches/s, l2_loss: 0.1457 - round_los\u001b[A\n",
      "Training:  95%|▉| 38974/40960 [02:31<00:07, 275.94batches/s, l2_loss: 0.1458 - round_los\u001b[A\n",
      "Training:  95%|▉| 39033/40960 [02:32<00:06, 280.76batches/s, l2_loss: 0.1458 - round_los\u001b[A\n",
      "Training:  95%|▉| 39033/40960 [02:32<00:06, 280.76batches/s, l2_loss: 0.1459 - round_los\u001b[A\n",
      "Training:  95%|▉| 39090/40960 [02:32<00:06, 280.72batches/s, l2_loss: 0.1459 - round_los\u001b[A\n",
      "Training:  95%|▉| 39090/40960 [02:32<00:06, 280.72batches/s, l2_loss: 0.1460 - round_los\u001b[A\n",
      "Training:  96%|▉| 39150/40960 [02:32<00:06, 285.75batches/s, l2_loss: 0.1460 - round_los\u001b[A\n",
      "Training:  96%|▉| 39150/40960 [02:32<00:06, 285.75batches/s, l2_loss: 0.1461 - round_los\u001b[A\n",
      "Training:  96%|▉| 39208/40960 [02:32<00:06, 286.82batches/s, l2_loss: 0.1461 - round_los\u001b[A\n",
      "Training:  96%|▉| 39208/40960 [02:32<00:06, 286.82batches/s, l2_loss: 0.1461 - round_los\u001b[A\n",
      "Training:  96%|▉| 39268/40960 [02:32<00:05, 290.25batches/s, l2_loss: 0.1461 - round_los\u001b[A\n",
      "Training:  96%|▉| 39268/40960 [02:32<00:05, 290.25batches/s, l2_loss: 0.1462 - round_los\u001b[A\n",
      "Training:  96%|▉| 39326/40960 [02:33<00:05, 289.99batches/s, l2_loss: 0.1462 - round_los\u001b[A\n",
      "Training:  96%|▉| 39326/40960 [02:33<00:05, 289.99batches/s, l2_loss: 0.1464 - round_los\u001b[A\n",
      "Training:  96%|▉| 39381/40960 [02:33<00:05, 283.52batches/s, l2_loss: 0.1464 - round_los\u001b[A\n",
      "Training:  96%|▉| 39381/40960 [02:33<00:05, 283.52batches/s, l2_loss: 0.1465 - round_los\u001b[A\n",
      "Training:  96%|▉| 39440/40960 [02:33<00:05, 285.74batches/s, l2_loss: 0.1465 - round_los\u001b[A\n",
      "Training:  96%|▉| 39440/40960 [02:33<00:05, 285.74batches/s, l2_loss: 0.1465 - round_los\u001b[A\n",
      "Training:  96%|▉| 39501/40960 [02:33<00:05, 291.08batches/s, l2_loss: 0.1465 - round_los\u001b[A\n",
      "Training:  96%|▉| 39501/40960 [02:33<00:05, 291.08batches/s, l2_loss: 0.1466 - round_los\u001b[A\n",
      "Training:  97%|▉| 39559/40960 [02:33<00:04, 290.32batches/s, l2_loss: 0.1466 - round_los\u001b[A\n",
      "Training:  97%|▉| 39559/40960 [02:33<00:04, 290.32batches/s, l2_loss: 0.1467 - round_los\u001b[A\n",
      "Training:  97%|▉| 39616/40960 [02:34<00:04, 287.57batches/s, l2_loss: 0.1467 - round_los\u001b[A\n",
      "Training:  97%|▉| 39616/40960 [02:34<00:04, 287.57batches/s, l2_loss: 0.1468 - round_los\u001b[A\n",
      "Training:  97%|▉| 39672/40960 [02:34<00:04, 284.46batches/s, l2_loss: 0.1468 - round_los\u001b[A\n",
      "Training:  97%|▉| 39672/40960 [02:34<00:04, 284.46batches/s, l2_loss: 0.1469 - round_los\u001b[A\n",
      "Training:  97%|▉| 39728/40960 [02:34<00:04, 282.54batches/s, l2_loss: 0.1469 - round_los\u001b[A\n",
      "Training:  97%|▉| 39728/40960 [02:34<00:04, 282.54batches/s, l2_loss: 0.1469 - round_los\u001b[A\n",
      "Training:  97%|▉| 39787/40960 [02:34<00:04, 284.91batches/s, l2_loss: 0.1469 - round_los\u001b[A\n",
      "Training:  97%|▉| 39787/40960 [02:34<00:04, 284.91batches/s, l2_loss: 0.1470 - round_los\u001b[A\n",
      "Training:  97%|▉| 39846/40960 [02:34<00:03, 287.85batches/s, l2_loss: 0.1470 - round_los\u001b[A\n",
      "Training:  97%|▉| 39846/40960 [02:34<00:03, 287.85batches/s, l2_loss: 0.1471 - round_los\u001b[A\n",
      "Training:  97%|▉| 39905/40960 [02:35<00:03, 289.29batches/s, l2_loss: 0.1471 - round_los\u001b[A\n",
      "Training:  97%|▉| 39905/40960 [02:35<00:03, 289.29batches/s, l2_loss: 0.1472 - round_los\u001b[A\n",
      "Training:  98%|▉| 39965/40960 [02:35<00:03, 291.55batches/s, l2_loss: 0.1472 - round_los\u001b[A\n",
      "Training:  98%|▉| 39965/40960 [02:35<00:03, 291.55batches/s, l2_loss: 0.1473 - round_los\u001b[A\n",
      "Training:  98%|▉| 40025/40960 [02:35<00:03, 293.41batches/s, l2_loss: 0.1473 - round_los\u001b[A\n",
      "Training:  98%|▉| 40025/40960 [02:35<00:03, 293.41batches/s, l2_loss: 0.1473 - round_los\u001b[A\n",
      "Training:  98%|▉| 40075/40960 [02:35<00:03, 277.96batches/s, l2_loss: 0.1473 - round_los\u001b[A\n",
      "Training:  98%|▉| 40075/40960 [02:35<00:03, 277.96batches/s, l2_loss: 0.1475 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [02:35<00:03, 253.79batches/s, l2_loss: 0.1475 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [02:35<00:03, 253.79batches/s, l2_loss: 0.1475 - round_los\u001b[A\n",
      "Training:  98%|▉| 40172/40960 [02:36<00:03, 262.36batches/s, l2_loss: 0.1475 - round_los\u001b[A\n",
      "Training:  98%|▉| 40172/40960 [02:36<00:03, 262.36batches/s, l2_loss: 0.1476 - round_los\u001b[A\n",
      "Training:  98%|▉| 40227/40960 [02:36<00:02, 264.85batches/s, l2_loss: 0.1476 - round_los\u001b[A\n",
      "Training:  98%|▉| 40227/40960 [02:36<00:02, 264.85batches/s, l2_loss: 0.1476 - round_los\u001b[A\n",
      "Training:  98%|▉| 40278/40960 [02:36<00:02, 261.46batches/s, l2_loss: 0.1476 - round_los\u001b[A\n",
      "Training:  98%|▉| 40278/40960 [02:36<00:02, 261.46batches/s, l2_loss: 0.1478 - round_los\u001b[A\n",
      "Training:  98%|▉| 40333/40960 [02:36<00:02, 265.39batches/s, l2_loss: 0.1478 - round_los\u001b[A\n",
      "Training:  98%|▉| 40333/40960 [02:36<00:02, 265.39batches/s, l2_loss: 0.1478 - round_los\u001b[A\n",
      "Training:  99%|▉| 40386/40960 [02:36<00:02, 265.15batches/s, l2_loss: 0.1478 - round_los\u001b[A\n",
      "Training:  99%|▉| 40386/40960 [02:36<00:02, 265.15batches/s, l2_loss: 0.1479 - round_los\u001b[A\n",
      "Training:  99%|▉| 40442/40960 [02:37<00:01, 269.45batches/s, l2_loss: 0.1479 - round_los\u001b[A\n",
      "Training:  99%|▉| 40442/40960 [02:37<00:01, 269.45batches/s, l2_loss: 0.1480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40500/40960 [02:37<00:01, 274.41batches/s, l2_loss: 0.1480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40500/40960 [02:37<00:01, 274.41batches/s, l2_loss: 0.1481 - round_los\u001b[A\n",
      "Training:  99%|▉| 40556/40960 [02:37<00:01, 275.24batches/s, l2_loss: 0.1481 - round_los\u001b[A\n",
      "Training:  99%|▉| 40556/40960 [02:37<00:01, 275.24batches/s, l2_loss: 0.1481 - round_los\u001b[A\n",
      "Training:  99%|▉| 40614/40960 [02:37<00:01, 279.53batches/s, l2_loss: 0.1481 - round_los\u001b[A\n",
      "Training:  99%|▉| 40614/40960 [02:37<00:01, 279.53batches/s, l2_loss: 0.1483 - round_los\u001b[A\n",
      "Training:  99%|▉| 40673/40960 [02:37<00:01, 282.75batches/s, l2_loss: 0.1483 - round_los\u001b[A\n",
      "Training:  99%|▉| 40673/40960 [02:37<00:01, 282.75batches/s, l2_loss: 0.1483 - round_los\u001b[A\n",
      "Training:  99%|▉| 40731/40960 [02:38<00:00, 284.82batches/s, l2_loss: 0.1483 - round_los\u001b[A\n",
      "Training:  99%|▉| 40731/40960 [02:38<00:00, 284.82batches/s, l2_loss: 0.1484 - round_los\u001b[A\n",
      "Training: 100%|▉| 40788/40960 [02:38<00:00, 284.23batches/s, l2_loss: 0.1484 - round_los\u001b[A\n",
      "Training: 100%|▉| 40788/40960 [02:38<00:00, 284.23batches/s, l2_loss: 0.1485 - round_los\u001b[A\n",
      "Training: 100%|▉| 40848/40960 [02:38<00:00, 287.93batches/s, l2_loss: 0.1485 - round_los\u001b[A\n",
      "Training: 100%|▉| 40848/40960 [02:38<00:00, 287.93batches/s, l2_loss: 0.1486 - round_los\u001b[A\n",
      "Training: 100%|▉| 40905/40960 [02:38<00:00, 286.97batches/s, l2_loss: 0.1486 - round_los\u001b[A\n",
      "Training: 100%|▉| 40905/40960 [02:38<00:00, 286.97batches/s, l2_loss: 0.1487 - round_los\u001b[A\n",
      "Training: 100%|▉| 40959/40960 [02:38<00:00, 280.93batches/s, l2_loss: 0.1487 - round_los\u001b[A\n",
      "Training: 100%|▉| 40959/40960 [02:38<00:00, 280.93batches/s, l2_loss: 0.1487 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:05:52.019616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  35%|▎| 9/26 [18:14<38:27, 135.74s/blocks, Layers=['model_ResBaGAN_discriminat2025-06-09 15:05:55.403695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:06:02.172841: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<26:24:06,  2.32s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<26:24:06,  2.32s/batches, l2_loss: 0.0304 - round_loss:\u001b[A\n",
      "Training:   0%| | 58/40960 [00:02<21:34, 31.61batches/s, l2_loss: 0.0304 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 58/40960 [00:02<21:34, 31.61batches/s, l2_loss: 0.0639 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 113/40960 [00:02<10:33, 64.47batches/s, l2_loss: 0.0639 - round_loss: \u001b[A\n",
      "Training:   0%| | 113/40960 [00:02<10:33, 64.47batches/s, l2_loss: 0.0531 - round_loss: \u001b[A\n",
      "Training:   0%| | 162/40960 [00:02<07:16, 93.46batches/s, l2_loss: 0.0531 - round_loss: \u001b[A\n",
      "Training:   0%| | 162/40960 [00:02<07:16, 93.46batches/s, l2_loss: 0.0521 - round_loss: \u001b[A\n",
      "Training:   1%| | 220/40960 [00:03<05:13, 129.85batches/s, l2_loss: 0.0521 - round_loss:\u001b[A\n",
      "Training:   1%| | 220/40960 [00:03<05:13, 129.85batches/s, l2_loss: 0.0514 - round_loss:\u001b[A\n",
      "Training:   1%| | 275/40960 [00:03<04:14, 159.74batches/s, l2_loss: 0.0514 - round_loss:\u001b[A\n",
      "Training:   1%| | 275/40960 [00:03<04:14, 159.74batches/s, l2_loss: 0.0551 - round_loss:\u001b[A\n",
      "Training:   1%| | 338/40960 [00:03<03:28, 195.11batches/s, l2_loss: 0.0551 - round_loss:\u001b[A\n",
      "Training:   1%| | 338/40960 [00:03<03:28, 195.11batches/s, l2_loss: 0.0539 - round_loss:\u001b[A\n",
      "Training:   1%| | 399/40960 [00:03<03:02, 221.91batches/s, l2_loss: 0.0539 - round_loss:\u001b[A\n",
      "Training:   1%| | 399/40960 [00:03<03:02, 221.91batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   1%| | 459/40960 [00:03<02:47, 242.08batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   1%| | 459/40960 [00:03<02:47, 242.08batches/s, l2_loss: 0.0534 - round_loss:\u001b[A\n",
      "Training:   1%| | 522/40960 [00:04<02:34, 261.39batches/s, l2_loss: 0.0534 - round_loss:\u001b[A\n",
      "Training:   1%| | 522/40960 [00:04<02:34, 261.39batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   1%| | 584/40960 [00:04<02:26, 274.76batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   1%| | 584/40960 [00:04<02:26, 274.76batches/s, l2_loss: 0.0543 - round_loss:\u001b[A\n",
      "Training:   2%| | 646/40960 [00:04<02:21, 284.52batches/s, l2_loss: 0.0543 - round_loss:\u001b[A\n",
      "Training:   2%| | 646/40960 [00:04<02:21, 284.52batches/s, l2_loss: 0.0544 - round_loss:\u001b[A\n",
      "Training:   2%| | 707/40960 [00:04<02:18, 290.02batches/s, l2_loss: 0.0544 - round_loss:\u001b[A\n",
      "Training:   2%| | 707/40960 [00:04<02:18, 290.02batches/s, l2_loss: 0.0547 - round_loss:\u001b[A\n",
      "Training:   2%| | 750/40960 [00:04<02:31, 266.13batches/s, l2_loss: 0.0547 - round_loss:\u001b[A\n",
      "Training:   2%| | 750/40960 [00:04<02:31, 266.13batches/s, l2_loss: 0.0542 - round_loss:\u001b[A\n",
      "Training:   2%| | 812/40960 [00:05<02:24, 277.66batches/s, l2_loss: 0.0542 - round_loss:\u001b[A\n",
      "Training:   2%| | 812/40960 [00:05<02:24, 277.66batches/s, l2_loss: 0.0535 - round_loss:\u001b[A\n",
      "Training:   2%| | 865/40960 [00:05<02:26, 273.92batches/s, l2_loss: 0.0535 - round_loss:\u001b[A\n",
      "Training:   2%| | 865/40960 [00:05<02:26, 273.92batches/s, l2_loss: 0.0540 - round_loss:\u001b[A\n",
      "Training:   2%| | 916/40960 [00:05<02:29, 268.19batches/s, l2_loss: 0.0540 - round_loss:\u001b[A\n",
      "Training:   2%| | 916/40960 [00:05<02:29, 268.19batches/s, l2_loss: 0.0541 - round_loss:\u001b[A\n",
      "Training:   2%| | 978/40960 [00:05<02:23, 279.35batches/s, l2_loss: 0.0541 - round_loss:\u001b[A\n",
      "Training:   2%| | 978/40960 [00:05<02:23, 279.35batches/s, l2_loss: 0.0538 - round_loss:\u001b[A\n",
      "Training:   3%| | 1042/40960 [00:05<02:17, 290.33batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   3%| | 1042/40960 [00:05<02:17, 290.33batches/s, l2_loss: 0.0542 - round_loss\u001b[A\n",
      "Training:   3%| | 1100/40960 [00:06<02:17, 290.18batches/s, l2_loss: 0.0542 - round_loss\u001b[A\n",
      "Training:   3%| | 1100/40960 [00:06<02:17, 290.18batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   3%| | 1150/40960 [00:06<02:23, 276.71batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   3%| | 1150/40960 [00:06<02:23, 276.71batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1211/40960 [00:06<02:19, 284.38batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1211/40960 [00:06<02:19, 284.38batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1270/40960 [00:06<02:18, 286.07batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1270/40960 [00:06<02:18, 286.07batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1327/40960 [00:06<02:19, 284.99batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1327/40960 [00:06<02:19, 284.99batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1388/40960 [00:07<02:16, 290.84batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   3%| | 1388/40960 [00:07<02:16, 290.84batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   4%| | 1448/40960 [00:07<02:15, 292.43batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   4%| | 1448/40960 [00:07<02:15, 292.43batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   4%| | 1502/40960 [00:07<02:18, 284.48batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   4%| | 1502/40960 [00:07<02:18, 284.48batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   4%| | 1562/40960 [00:07<02:16, 287.97batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   4%| | 1562/40960 [00:07<02:16, 287.97batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   4%| | 1625/40960 [00:07<02:13, 295.43batches/s, l2_loss: 0.0539 - round_loss\u001b[A\n",
      "Training:   4%| | 1625/40960 [00:07<02:13, 295.43batches/s, l2_loss: 0.0541 - round_loss\u001b[A\n",
      "Training:   4%| | 1688/40960 [00:08<02:10, 300.23batches/s, l2_loss: 0.0541 - round_loss\u001b[A\n",
      "Training:   4%| | 1688/40960 [00:08<02:10, 300.23batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   4%| | 1751/40960 [00:08<02:09, 303.51batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   4%| | 1751/40960 [00:08<02:09, 303.51batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   4%| | 1810/40960 [00:08<02:10, 300.64batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   4%| | 1810/40960 [00:08<02:10, 300.64batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 1866/40960 [00:08<02:13, 293.80batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 1866/40960 [00:08<02:13, 293.80batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   5%| | 1924/40960 [00:08<02:14, 291.18batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   5%| | 1924/40960 [00:08<02:14, 291.18batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   5%| | 1983/40960 [00:09<02:13, 292.20batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:   5%| | 1983/40960 [00:09<02:13, 292.20batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2041/40960 [00:09<02:13, 291.45batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2041/40960 [00:09<02:13, 291.45batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   5%| | 2094/40960 [00:09<02:18, 280.92batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   5%| | 2094/40960 [00:09<02:18, 280.92batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2150/40960 [00:09<02:18, 279.42batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   5%| | 2150/40960 [00:09<02:18, 279.42batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   5%| | 2205/40960 [00:10<02:19, 277.24batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   5%| | 2205/40960 [00:10<02:19, 277.24batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   6%| | 2269/40960 [00:10<02:13, 288.79batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   6%| | 2269/40960 [00:10<02:13, 288.79batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   6%| | 2331/40960 [00:10<02:11, 294.17batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   6%| | 2331/40960 [00:10<02:11, 294.17batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   6%| | 2394/40960 [00:10<02:08, 300.23batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   6%| | 2394/40960 [00:10<02:08, 300.23batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   6%| | 2454/40960 [00:10<02:08, 300.04batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   6%| | 2454/40960 [00:10<02:08, 300.04batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   6%| | 2510/40960 [00:11<02:10, 293.56batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   6%| | 2510/40960 [00:11<02:10, 293.56batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   6%| | 2566/40960 [00:11<02:13, 288.18batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%| | 2566/40960 [00:11<02:13, 288.18batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   6%| | 2628/40960 [00:11<02:10, 294.17batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   6%| | 2628/40960 [00:11<02:10, 294.17batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   7%| | 2685/40960 [00:11<02:11, 291.23batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   7%| | 2685/40960 [00:11<02:11, 291.23batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   7%| | 2740/40960 [00:11<02:14, 285.15batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   7%| | 2740/40960 [00:11<02:14, 285.15batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   7%| | 2793/40960 [00:12<02:17, 278.08batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   7%| | 2793/40960 [00:12<02:17, 278.08batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   7%| | 2855/40960 [00:12<02:12, 287.45batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   7%| | 2855/40960 [00:12<02:12, 287.45batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   7%| | 2913/40960 [00:12<02:12, 286.64batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   7%| | 2913/40960 [00:12<02:12, 286.64batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   7%| | 2970/40960 [00:12<02:13, 285.28batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   7%| | 2970/40960 [00:12<02:13, 285.28batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   7%| | 3031/40960 [00:12<02:10, 291.04batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   7%| | 3031/40960 [00:12<02:10, 291.04batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   8%| | 3091/40960 [00:13<02:09, 293.39batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   8%| | 3091/40960 [00:13<02:09, 293.39batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   8%| | 3151/40960 [00:13<02:08, 294.46batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   8%| | 3151/40960 [00:13<02:08, 294.46batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   8%| | 3214/40960 [00:13<02:05, 299.96batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   8%| | 3214/40960 [00:13<02:05, 299.96batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   8%| | 3271/40960 [00:13<02:08, 294.15batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   8%| | 3271/40960 [00:13<02:08, 294.15batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   8%| | 3326/40960 [00:13<02:10, 288.09batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   8%| | 3326/40960 [00:13<02:10, 288.09batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:   8%| | 3389/40960 [00:14<02:07, 294.82batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:   8%| | 3389/40960 [00:14<02:07, 294.82batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   8%| | 3452/40960 [00:14<02:05, 300.02batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   8%| | 3452/40960 [00:14<02:05, 300.02batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:   9%| | 3514/40960 [00:14<02:04, 301.44batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:   9%| | 3514/40960 [00:14<02:04, 301.44batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   9%| | 3577/40960 [00:14<02:02, 304.81batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   9%| | 3577/40960 [00:14<02:02, 304.81batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:   9%| | 3639/40960 [00:14<02:02, 305.34batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:   9%| | 3639/40960 [00:14<02:02, 305.34batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   9%| | 3696/40960 [00:15<02:04, 298.61batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:   9%| | 3696/40960 [00:15<02:04, 298.61batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:   9%| | 3747/40960 [00:15<02:10, 284.92batches/s, l2_loss: 0.0526 - round_loss\u001b[A\n",
      "Training:   9%| | 3747/40960 [00:15<02:10, 284.92batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   9%| | 3807/40960 [00:15<02:09, 287.97batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   9%| | 3807/40960 [00:15<02:09, 287.97batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   9%| | 3869/40960 [00:15<02:06, 293.86batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   9%| | 3869/40960 [00:15<02:06, 293.86batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  10%| | 3924/40960 [00:15<02:09, 286.68batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  10%| | 3924/40960 [00:15<02:09, 286.68batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  10%| | 3981/40960 [00:16<02:09, 286.10batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  10%| | 3981/40960 [00:16<02:09, 286.10batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  10%| | 4041/40960 [00:16<02:07, 290.03batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  10%| | 4041/40960 [00:16<02:07, 290.03batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  10%| | 4103/40960 [00:16<02:04, 295.64batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  10%| | 4103/40960 [00:16<02:04, 295.64batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  10%| | 4163/40960 [00:16<02:04, 295.52batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  10%| | 4163/40960 [00:16<02:04, 295.52batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  10%| | 4225/40960 [00:16<02:03, 298.14batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  10%| | 4225/40960 [00:16<02:03, 298.14batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  10%| | 4288/40960 [00:17<02:01, 301.82batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  10%| | 4288/40960 [00:17<02:01, 301.82batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  11%| | 4350/40960 [00:17<02:00, 304.04batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  11%| | 4350/40960 [00:17<02:00, 304.04batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  11%| | 4410/40960 [00:17<02:00, 302.48batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  11%| | 4410/40960 [00:17<02:00, 302.48batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  11%| | 4469/40960 [00:17<02:02, 298.31batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  11%| | 4469/40960 [00:17<02:02, 298.31batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  11%| | 4531/40960 [00:17<02:01, 300.72batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  11%| | 4531/40960 [00:17<02:01, 300.72batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  11%| | 4591/40960 [00:18<02:01, 300.01batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  11%| | 4591/40960 [00:18<02:01, 300.01batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  11%| | 4656/40960 [00:18<01:58, 307.12batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  11%| | 4656/40960 [00:18<01:58, 307.12batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 4717/40960 [00:18<01:58, 306.12batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 4717/40960 [00:18<01:58, 306.12batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 4776/40960 [00:18<02:00, 301.08batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 4776/40960 [00:18<02:00, 301.08batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 4831/40960 [00:18<02:03, 291.83batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 4831/40960 [00:18<02:03, 291.83batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 4892/40960 [00:19<02:02, 294.35batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 4892/40960 [00:19<02:02, 294.35batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  12%| | 4948/40960 [00:19<02:04, 290.09batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  12%| | 4948/40960 [00:19<02:04, 290.09batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 5008/40960 [00:19<02:03, 291.71batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:  12%| | 5008/40960 [00:19<02:03, 291.71batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  12%| | 5071/40960 [00:19<02:00, 298.03batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  12%| | 5071/40960 [00:19<02:00, 298.03batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5133/40960 [00:19<01:58, 301.14batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5133/40960 [00:19<01:58, 301.14batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5195/40960 [00:20<01:57, 303.15batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5195/40960 [00:20<01:57, 303.15batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|▏| 5258/40960 [00:20<01:56, 306.35batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5258/40960 [00:20<01:56, 306.35batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5321/40960 [00:20<01:55, 307.57batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5321/40960 [00:20<01:55, 307.57batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5382/40960 [00:20<01:56, 305.69batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5382/40960 [00:20<01:56, 305.69batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5444/40960 [00:20<01:55, 306.20batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5444/40960 [00:20<01:55, 306.20batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5505/40960 [00:21<01:56, 304.67batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5505/40960 [00:21<01:56, 304.67batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5569/40960 [00:21<01:54, 308.28batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5569/40960 [00:21<01:54, 308.28batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5632/40960 [00:21<01:53, 310.24batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5632/40960 [00:21<01:53, 310.24batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5695/40960 [00:21<01:53, 310.76batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5695/40960 [00:21<01:53, 310.76batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5755/40960 [00:21<01:54, 307.26batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5755/40960 [00:21<01:54, 307.26batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5820/40960 [00:22<01:52, 311.33batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5820/40960 [00:22<01:52, 311.33batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5882/40960 [00:22<01:53, 310.28batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5882/40960 [00:22<01:53, 310.28batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5944/40960 [00:22<01:53, 309.19batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5944/40960 [00:22<01:53, 309.19batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6001/40960 [00:22<01:56, 301.07batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6001/40960 [00:22<01:56, 301.07batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6059/40960 [00:22<01:57, 297.51batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6059/40960 [00:22<01:57, 297.51batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6098/40960 [00:23<02:11, 265.96batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6098/40960 [00:23<02:11, 265.96batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6156/40960 [00:23<02:08, 271.69batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6156/40960 [00:23<02:08, 271.69batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6215/40960 [00:23<02:05, 277.67batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6215/40960 [00:23<02:05, 277.67batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6277/40960 [00:23<02:00, 287.09batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6277/40960 [00:23<02:00, 287.09batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6340/40960 [00:23<01:57, 295.34batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6340/40960 [00:23<01:57, 295.34batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6403/40960 [00:24<01:54, 300.75batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6403/40960 [00:24<01:54, 300.75batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6458/40960 [00:24<01:58, 291.77batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6458/40960 [00:24<01:58, 291.77batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6518/40960 [00:24<01:57, 292.82batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6518/40960 [00:24<01:57, 292.82batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6569/40960 [00:24<02:02, 280.48batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6569/40960 [00:24<02:02, 280.48batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6631/40960 [00:24<01:58, 289.09batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6631/40960 [00:24<01:58, 289.09batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6693/40960 [00:25<01:56, 294.63batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6693/40960 [00:25<01:56, 294.63batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6750/40960 [00:25<01:58, 288.62batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6750/40960 [00:25<01:58, 288.62batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6803/40960 [00:25<02:01, 279.98batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6803/40960 [00:25<02:01, 279.98batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6857/40960 [00:25<02:03, 275.48batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6857/40960 [00:25<02:03, 275.48batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6909/40960 [00:25<02:05, 270.71batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6909/40960 [00:25<02:05, 270.71batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6964/40960 [00:26<02:05, 271.65batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6964/40960 [00:26<02:05, 271.65batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7016/40960 [00:26<02:06, 267.40batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7016/40960 [00:26<02:06, 267.40batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7081/40960 [00:26<01:59, 283.51batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7081/40960 [00:26<01:59, 283.51batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7141/40960 [00:26<01:57, 287.96batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7141/40960 [00:26<01:57, 287.96batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7203/40960 [00:26<01:54, 293.74batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7203/40960 [00:26<01:54, 293.74batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7259/40960 [00:27<01:56, 288.50batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7259/40960 [00:27<01:56, 288.50batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7308/40960 [00:27<02:02, 273.69batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7308/40960 [00:27<02:02, 273.69batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7366/40960 [00:27<02:00, 278.38batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7366/40960 [00:27<02:00, 278.38batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7416/40960 [00:27<02:04, 268.69batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7416/40960 [00:27<02:04, 268.69batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:27<02:07, 261.90batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7467/40960 [00:27<02:07, 261.90batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7517/40960 [00:28<02:09, 258.34batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7517/40960 [00:28<02:09, 258.34batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7577/40960 [00:28<02:03, 270.71batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7577/40960 [00:28<02:03, 270.71batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7633/40960 [00:28<02:02, 272.27batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7633/40960 [00:28<02:02, 272.27batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7677/40960 [00:28<02:09, 256.30batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7677/40960 [00:28<02:09, 256.30batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7728/40960 [00:28<02:10, 254.41batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7728/40960 [00:28<02:10, 254.41batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7785/40960 [00:29<02:06, 263.05batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|▏| 7785/40960 [00:29<02:06, 263.05batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7840/40960 [00:29<02:04, 265.04batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7840/40960 [00:29<02:04, 265.04batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7898/40960 [00:29<02:01, 271.34batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7898/40960 [00:29<02:01, 271.34batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7954/40960 [00:29<02:00, 273.50batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7954/40960 [00:29<02:00, 273.50batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8006/40960 [00:30<02:02, 268.35batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8006/40960 [00:30<02:02, 268.35batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8062/40960 [00:30<02:01, 271.76batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8062/40960 [00:30<02:01, 271.76batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8107/40960 [00:30<02:07, 257.50batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8107/40960 [00:30<02:07, 257.50batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8165/40960 [00:30<02:02, 266.96batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8165/40960 [00:30<02:02, 266.96batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8224/40960 [00:30<01:59, 274.50batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8224/40960 [00:30<01:59, 274.50batches/s, l2_loss: 0.0448 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8282/40960 [00:31<01:57, 278.37batches/s, l2_loss: 0.0448 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8282/40960 [00:31<01:57, 278.37batches/s, l2_loss: 0.0496 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8335/40960 [00:31<01:59, 273.43batches/s, l2_loss: 0.0496 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8335/40960 [00:31<01:59, 273.43batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8395/40960 [00:31<01:55, 280.75batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8395/40960 [00:31<01:55, 280.75batches/s, l2_loss: 0.0475 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8455/40960 [00:31<01:53, 285.87batches/s, l2_loss: 0.0475 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8455/40960 [00:31<01:53, 285.87batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8513/40960 [00:31<01:53, 286.98batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8513/40960 [00:31<01:53, 286.98batches/s, l2_loss: 0.0483 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8573/40960 [00:32<01:51, 290.25batches/s, l2_loss: 0.0483 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8573/40960 [00:32<01:51, 290.25batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8630/40960 [00:32<01:52, 288.22batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8630/40960 [00:32<01:52, 288.22batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8680/40960 [00:32<01:56, 276.44batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8680/40960 [00:32<01:56, 276.44batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8733/40960 [00:32<01:58, 272.95batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8733/40960 [00:32<01:58, 272.95batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8789/40960 [00:32<01:57, 273.88batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8789/40960 [00:32<01:57, 273.88batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8846/40960 [00:33<01:56, 276.40batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8846/40960 [00:33<01:56, 276.40batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8896/40960 [00:33<01:59, 267.86batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8896/40960 [00:33<01:59, 267.86batches/s, l2_loss: 0.0482 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8954/40960 [00:33<01:56, 274.32batches/s, l2_loss: 0.0482 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8954/40960 [00:33<01:56, 274.32batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9012/40960 [00:33<01:54, 278.18batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9012/40960 [00:33<01:54, 278.18batches/s, l2_loss: 0.0485 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9068/40960 [00:33<01:54, 278.06batches/s, l2_loss: 0.0485 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9068/40960 [00:33<01:54, 278.06batches/s, l2_loss: 0.0483 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9117/40960 [00:34<01:58, 268.06batches/s, l2_loss: 0.0483 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9117/40960 [00:34<01:58, 268.06batches/s, l2_loss: 0.0485 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9168/40960 [00:34<02:00, 264.03batches/s, l2_loss: 0.0485 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9168/40960 [00:34<02:00, 264.03batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9223/40960 [00:34<01:59, 266.23batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9223/40960 [00:34<01:59, 266.23batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9282/40960 [00:34<01:55, 273.73batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9282/40960 [00:34<01:55, 273.73batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9337/40960 [00:34<01:55, 273.57batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9337/40960 [00:34<01:55, 273.57batches/s, l2_loss: 0.0486 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9396/40960 [00:35<01:52, 279.74batches/s, l2_loss: 0.0486 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9396/40960 [00:35<01:52, 279.74batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9455/40960 [00:35<01:51, 283.58batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9455/40960 [00:35<01:51, 283.58batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9515/40960 [00:35<01:49, 287.92batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9515/40960 [00:35<01:49, 287.92batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9573/40960 [00:35<01:49, 287.88batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9573/40960 [00:35<01:49, 287.88batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9631/40960 [00:35<01:48, 287.84batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9631/40960 [00:35<01:48, 287.84batches/s, l2_loss: 0.0487 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9675/40960 [00:36<01:58, 265.11batches/s, l2_loss: 0.0487 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9675/40960 [00:36<01:58, 265.11batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9729/40960 [00:36<01:57, 265.96batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9729/40960 [00:36<01:57, 265.96batches/s, l2_loss: 0.0487 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9773/40960 [00:36<02:04, 251.42batches/s, l2_loss: 0.0487 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9773/40960 [00:36<02:04, 251.42batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9824/40960 [00:36<02:03, 251.44batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9824/40960 [00:36<02:03, 251.44batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9873/40960 [00:36<02:04, 248.89batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9873/40960 [00:36<02:04, 248.89batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9926/40960 [00:37<02:02, 253.10batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9926/40960 [00:37<02:02, 253.10batches/s, l2_loss: 0.0486 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9979/40960 [00:37<02:00, 256.29batches/s, l2_loss: 0.0486 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9979/40960 [00:37<02:00, 256.29batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10033/40960 [00:37<01:58, 260.03batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  24%|▏| 10033/40960 [00:37<01:58, 260.03batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  25%|▏| 10082/40960 [00:37<02:01, 254.54batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  25%|▏| 10082/40960 [00:37<02:01, 254.54batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  25%|▏| 10139/40960 [00:37<01:57, 262.53batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  25%|▏| 10139/40960 [00:37<01:57, 262.53batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  25%|▏| 10184/40960 [00:38<02:02, 250.84batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  25%|▏| 10184/40960 [00:38<02:02, 250.84batches/s, l2_loss: 0.0487 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▏| 10237/40960 [00:38<02:00, 254.69batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  25%|▏| 10237/40960 [00:38<02:00, 254.69batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  25%|▎| 10289/40960 [00:38<01:59, 256.10batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  25%|▎| 10289/40960 [00:38<01:59, 256.10batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  25%|▎| 10345/40960 [00:38<01:56, 261.83batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  25%|▎| 10345/40960 [00:38<01:56, 261.83batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  25%|▎| 10402/40960 [00:38<01:54, 267.83batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  25%|▎| 10402/40960 [00:38<01:54, 267.83batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  26%|▎| 10459/40960 [00:39<01:52, 271.53batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  26%|▎| 10459/40960 [00:39<01:52, 271.53batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  26%|▎| 10516/40960 [00:39<01:50, 274.61batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  26%|▎| 10516/40960 [00:39<01:50, 274.61batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  26%|▎| 10557/40960 [00:39<01:59, 253.75batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  26%|▎| 10557/40960 [00:39<01:59, 253.75batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  26%|▎| 10601/40960 [00:39<02:04, 242.92batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  26%|▎| 10601/40960 [00:39<02:04, 242.92batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  26%|▎| 10651/40960 [00:39<02:04, 242.59batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  26%|▎| 10651/40960 [00:39<02:04, 242.59batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  26%|▎| 10709/40960 [00:40<01:58, 255.57batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  26%|▎| 10709/40960 [00:40<01:58, 255.57batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  26%|▎| 10763/40960 [00:40<01:56, 259.28batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  26%|▎| 10763/40960 [00:40<01:56, 259.28batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  26%|▎| 10820/40960 [00:40<01:53, 265.80batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  26%|▎| 10820/40960 [00:40<01:53, 265.80batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  27%|▎| 10879/40960 [00:40<01:50, 273.29batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  27%|▎| 10879/40960 [00:40<01:50, 273.29batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  27%|▎| 10935/40960 [00:40<01:49, 274.18batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  27%|▎| 10935/40960 [00:40<01:49, 274.18batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  27%|▎| 10977/40960 [00:41<01:57, 254.33batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  27%|▎| 10977/40960 [00:41<01:57, 254.33batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  27%|▎| 11030/40960 [00:41<01:56, 256.17batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  27%|▎| 11030/40960 [00:41<01:56, 256.17batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  27%|▎| 11076/40960 [00:41<02:00, 247.72batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  27%|▎| 11076/40960 [00:41<02:00, 247.72batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  27%|▎| 11116/40960 [00:41<02:08, 232.78batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  27%|▎| 11116/40960 [00:41<02:08, 232.78batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  27%|▎| 11165/40960 [00:41<02:06, 235.51batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  27%|▎| 11165/40960 [00:41<02:06, 235.51batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  27%|▎| 11221/40960 [00:42<01:59, 248.70batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  27%|▎| 11221/40960 [00:42<01:59, 248.70batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  28%|▎| 11277/40960 [00:42<01:55, 257.33batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  28%|▎| 11277/40960 [00:42<01:55, 257.33batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  28%|▎| 11332/40960 [00:42<01:52, 262.37batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  28%|▎| 11332/40960 [00:42<01:52, 262.37batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  28%|▎| 11387/40960 [00:42<01:51, 265.36batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  28%|▎| 11387/40960 [00:42<01:51, 265.36batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  28%|▎| 11446/40960 [00:42<01:48, 273.07batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  28%|▎| 11446/40960 [00:42<01:48, 273.07batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  28%|▎| 11503/40960 [00:43<01:46, 275.77batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  28%|▎| 11503/40960 [00:43<01:46, 275.77batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  28%|▎| 11560/40960 [00:43<01:45, 277.44batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  28%|▎| 11560/40960 [00:43<01:45, 277.44batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  28%|▎| 11611/40960 [00:43<01:48, 269.78batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  28%|▎| 11611/40960 [00:43<01:48, 269.78batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  28%|▎| 11666/40960 [00:43<01:48, 270.93batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  28%|▎| 11666/40960 [00:43<01:48, 270.93batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  29%|▎| 11724/40960 [00:43<01:46, 275.19batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  29%|▎| 11724/40960 [00:43<01:46, 275.19batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  29%|▎| 11780/40960 [00:44<01:45, 275.46batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  29%|▎| 11780/40960 [00:44<01:45, 275.46batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  29%|▎| 11838/40960 [00:44<01:44, 279.11batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  29%|▎| 11838/40960 [00:44<01:44, 279.11batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  29%|▎| 11894/40960 [00:44<01:44, 278.44batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  29%|▎| 11894/40960 [00:44<01:44, 278.44batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  29%|▎| 11947/40960 [00:44<01:45, 274.15batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  29%|▎| 11947/40960 [00:44<01:45, 274.15batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  29%|▎| 11999/40960 [00:44<01:48, 267.07batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  29%|▎| 11999/40960 [00:44<01:48, 267.07batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  29%|▎| 12054/40960 [00:45<01:47, 267.86batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  29%|▎| 12054/40960 [00:45<01:47, 267.86batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12102/40960 [00:45<01:51, 258.58batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12102/40960 [00:45<01:51, 258.58batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  30%|▎| 12142/40960 [00:45<01:59, 240.82batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  30%|▎| 12142/40960 [00:45<01:59, 240.82batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  30%|▎| 12193/40960 [00:45<01:57, 244.07batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  30%|▎| 12193/40960 [00:45<01:57, 244.07batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  30%|▎| 12250/40960 [00:45<01:52, 254.89batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  30%|▎| 12250/40960 [00:45<01:52, 254.89batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12307/40960 [00:46<01:48, 263.72batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12307/40960 [00:46<01:48, 263.72batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  30%|▎| 12358/40960 [00:46<01:49, 260.20batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  30%|▎| 12358/40960 [00:46<01:49, 260.20batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12413/40960 [00:46<01:48, 264.06batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12413/40960 [00:46<01:48, 264.06batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12472/40960 [00:46<01:44, 272.22batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12472/40960 [00:46<01:44, 272.22batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12530/40960 [00:46<01:42, 276.67batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12530/40960 [00:46<01:42, 276.67batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12590/40960 [00:47<01:40, 283.45batches/s, l2_loss: 0.0485 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|▎| 12590/40960 [00:47<01:40, 283.45batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12645/40960 [00:47<01:41, 280.23batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12645/40960 [00:47<01:41, 280.23batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  31%|▎| 12700/40960 [00:47<01:41, 278.02batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  31%|▎| 12700/40960 [00:47<01:41, 278.02batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12754/40960 [00:47<01:42, 274.71batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12754/40960 [00:47<01:42, 274.71batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12795/40960 [00:47<01:50, 253.92batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12795/40960 [00:47<01:50, 253.92batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12843/40960 [00:48<01:52, 249.57batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  31%|▎| 12843/40960 [00:48<01:52, 249.57batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 12903/40960 [00:48<01:46, 263.80batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 12903/40960 [00:48<01:46, 263.80batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 12963/40960 [00:48<01:42, 274.33batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 12963/40960 [00:48<01:42, 274.33batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 13022/40960 [00:48<01:39, 279.84batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 13022/40960 [00:48<01:39, 279.84batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 13079/40960 [00:48<01:39, 280.78batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 13079/40960 [00:48<01:39, 280.78batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  32%|▎| 13139/40960 [00:49<01:37, 285.29batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  32%|▎| 13139/40960 [00:49<01:37, 285.29batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  32%|▎| 13198/40960 [00:49<01:36, 287.98batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  32%|▎| 13198/40960 [00:49<01:36, 287.98batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 13257/40960 [00:49<01:35, 289.08batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  32%|▎| 13257/40960 [00:49<01:35, 289.08batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13315/40960 [00:49<01:35, 288.56batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13315/40960 [00:49<01:35, 288.56batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13374/40960 [00:49<01:35, 289.28batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13374/40960 [00:49<01:35, 289.28batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  33%|▎| 13431/40960 [00:50<01:35, 287.39batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  33%|▎| 13431/40960 [00:50<01:35, 287.39batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  33%|▎| 13489/40960 [00:50<01:35, 287.69batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  33%|▎| 13489/40960 [00:50<01:35, 287.69batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13546/40960 [00:50<01:35, 286.51batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13546/40960 [00:50<01:35, 286.51batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13605/40960 [00:50<01:34, 288.02batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13605/40960 [00:50<01:34, 288.02batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13664/40960 [00:50<01:34, 288.84batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  33%|▎| 13664/40960 [00:51<01:34, 288.84batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 13722/40960 [00:51<01:34, 288.30batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 13722/40960 [00:51<01:34, 288.30batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  34%|▎| 13774/40960 [00:51<01:37, 279.54batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  34%|▎| 13774/40960 [00:51<01:37, 279.54batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 13831/40960 [00:51<01:36, 279.90batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 13831/40960 [00:51<01:36, 279.90batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 13890/40960 [00:51<01:35, 283.26batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 13890/40960 [00:51<01:35, 283.26batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  34%|▎| 13947/40960 [00:52<01:35, 282.42batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  34%|▎| 13947/40960 [00:52<01:35, 282.42batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 14004/40960 [00:52<01:35, 282.16batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 14004/40960 [00:52<01:35, 282.16batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  34%|▎| 14064/40960 [00:52<01:33, 286.61batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  34%|▎| 14064/40960 [00:52<01:33, 286.61batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 14117/40960 [00:52<01:36, 278.94batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  34%|▎| 14117/40960 [00:52<01:36, 278.94batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14170/40960 [00:52<01:38, 272.24batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14170/40960 [00:52<01:38, 272.24batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14214/40960 [00:53<01:45, 254.25batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14214/40960 [00:53<01:45, 254.25batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14271/40960 [00:53<01:41, 263.22batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14271/40960 [00:53<01:41, 263.22batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  35%|▎| 14327/40960 [00:53<01:39, 267.01batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  35%|▎| 14327/40960 [00:53<01:39, 267.01batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14385/40960 [00:53<01:37, 273.03batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14385/40960 [00:53<01:37, 273.03batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  35%|▎| 14444/40960 [00:53<01:35, 278.69batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  35%|▎| 14444/40960 [00:53<01:35, 278.69batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14504/40960 [00:54<01:33, 284.00batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  35%|▎| 14504/40960 [00:54<01:33, 284.00batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14561/40960 [00:54<01:33, 282.87batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14561/40960 [00:54<01:33, 282.87batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  36%|▎| 14617/40960 [00:54<01:33, 281.97batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  36%|▎| 14617/40960 [00:54<01:33, 281.97batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14673/40960 [00:54<01:33, 281.27batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14673/40960 [00:54<01:33, 281.27batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14720/40960 [00:54<01:38, 266.23batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14720/40960 [00:54<01:38, 266.23batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14778/40960 [00:55<01:36, 272.12batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14778/40960 [00:55<01:36, 272.12batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14836/40960 [00:55<01:34, 276.24batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14836/40960 [00:55<01:34, 276.24batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:55<01:32, 280.92batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:55<01:32, 280.92batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  36%|▎| 14947/40960 [00:55<01:34, 274.29batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  36%|▎| 14947/40960 [00:55<01:34, 274.29batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  37%|▎| 15005/40960 [00:55<01:33, 278.30batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  37%|▎| 15005/40960 [00:55<01:33, 278.30batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  37%|▎| 15054/40960 [00:56<01:36, 268.28batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  37%|▎| 15054/40960 [00:56<01:36, 268.28batches/s, l2_loss: 0.0484 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15110/40960 [00:56<01:35, 270.25batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  37%|▎| 15110/40960 [00:56<01:35, 270.25batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  37%|▎| 15167/40960 [00:56<01:34, 273.74batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  37%|▎| 15167/40960 [00:56<01:34, 273.74batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  37%|▎| 15225/40960 [00:56<01:32, 278.30batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  37%|▎| 15225/40960 [00:56<01:32, 278.30batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  37%|▎| 15284/40960 [00:56<01:30, 282.53batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  37%|▎| 15284/40960 [00:56<01:30, 282.53batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  37%|▎| 15341/40960 [00:57<01:30, 283.09batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  37%|▎| 15341/40960 [00:57<01:30, 283.09batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  38%|▍| 15399/40960 [00:57<01:29, 284.33batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  38%|▍| 15399/40960 [00:57<01:29, 284.33batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  38%|▍| 15456/40960 [00:57<01:29, 283.89batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  38%|▍| 15456/40960 [00:57<01:29, 283.89batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  38%|▍| 15514/40960 [00:57<01:29, 284.64batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  38%|▍| 15514/40960 [00:57<01:29, 284.64batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  38%|▍| 15567/40960 [00:57<01:31, 277.62batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  38%|▍| 15567/40960 [00:57<01:31, 277.62batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  38%|▍| 15618/40960 [00:58<01:33, 270.40batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  38%|▍| 15618/40960 [00:58<01:33, 270.40batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  38%|▍| 15673/40960 [00:58<01:33, 270.66batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  38%|▍| 15673/40960 [00:58<01:33, 270.66batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  38%|▍| 15725/40960 [00:58<01:34, 266.39batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  38%|▍| 15725/40960 [00:58<01:34, 266.39batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 15776/40960 [00:58<01:36, 262.10batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 15776/40960 [00:58<01:36, 262.10batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  39%|▍| 15833/40960 [00:58<01:33, 267.79batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  39%|▍| 15833/40960 [00:58<01:33, 267.79batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 15886/40960 [00:59<01:34, 266.30batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 15886/40960 [00:59<01:34, 266.30batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 15934/40960 [00:59<01:37, 256.98batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 15934/40960 [00:59<01:37, 256.98batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 15986/40960 [00:59<01:37, 257.38batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 15986/40960 [00:59<01:37, 257.38batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 16042/40960 [00:59<01:34, 263.58batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  39%|▍| 16042/40960 [00:59<01:34, 263.58batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  39%|▍| 16098/40960 [00:59<01:32, 268.03batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  39%|▍| 16098/40960 [00:59<01:32, 268.03batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  39%|▍| 16151/40960 [01:00<01:32, 266.83batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  39%|▍| 16151/40960 [01:00<01:32, 266.83batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  40%|▍| 16207/40960 [01:00<01:31, 269.20batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  40%|▍| 16207/40960 [01:00<01:31, 269.20batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  40%|▍| 16267/40960 [01:00<01:28, 277.74batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  40%|▍| 16267/40960 [01:00<01:28, 277.74batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16326/40960 [01:00<01:27, 281.80batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16326/40960 [01:00<01:27, 281.80batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  40%|▍| 16380/40960 [01:00<01:28, 278.11batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  40%|▍| 16380/40960 [01:00<01:28, 278.11batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16436/40960 [01:01<01:28, 278.38batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16436/40960 [01:01<01:28, 278.38batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16490/40960 [01:01<01:29, 274.60batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16490/40960 [01:01<01:29, 274.60batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16545/40960 [01:01<01:29, 273.25batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16545/40960 [01:01<01:29, 273.25batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16586/40960 [01:01<01:36, 251.52batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  40%|▍| 16586/40960 [01:01<01:36, 251.52batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16638/40960 [01:01<01:36, 253.06batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16638/40960 [01:01<01:36, 253.06batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16688/40960 [01:02<01:36, 251.03batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16688/40960 [01:02<01:36, 251.03batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  41%|▍| 16737/40960 [01:02<01:37, 248.73batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  41%|▍| 16737/40960 [01:02<01:37, 248.73batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  41%|▍| 16786/40960 [01:02<01:38, 246.19batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  41%|▍| 16786/40960 [01:02<01:38, 246.19batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16835/40960 [01:02<01:38, 245.12batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16835/40960 [01:02<01:38, 245.12batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16893/40960 [01:02<01:33, 258.03batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16893/40960 [01:02<01:33, 258.03batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16952/40960 [01:03<01:29, 268.99batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  41%|▍| 16952/40960 [01:03<01:29, 268.99batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17013/40960 [01:03<01:25, 279.15batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17013/40960 [01:03<01:25, 279.15batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17066/40960 [01:03<01:26, 274.69batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17066/40960 [01:03<01:26, 274.69batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17118/40960 [01:03<01:28, 268.92batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17118/40960 [01:03<01:28, 268.92batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17175/40960 [01:03<01:26, 273.53batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17175/40960 [01:03<01:26, 273.53batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17231/40960 [01:04<01:26, 274.14batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17231/40960 [01:04<01:26, 274.14batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  42%|▍| 17281/40960 [01:04<01:29, 265.09batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  42%|▍| 17281/40960 [01:04<01:29, 265.09batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17333/40960 [01:04<01:29, 263.25batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17333/40960 [01:04<01:29, 263.25batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17392/40960 [01:04<01:26, 272.39batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  42%|▍| 17392/40960 [01:04<01:26, 272.39batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  43%|▍| 17448/40960 [01:04<01:25, 274.49batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  43%|▍| 17448/40960 [01:04<01:25, 274.49batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17498/40960 [01:05<01:28, 266.01batches/s, l2_loss: 0.0483 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17498/40960 [01:05<01:28, 266.01batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  43%|▍| 17552/40960 [01:05<01:27, 266.60batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  43%|▍| 17552/40960 [01:05<01:27, 266.60batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17609/40960 [01:05<01:25, 271.53batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17609/40960 [01:05<01:25, 271.53batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17659/40960 [01:05<01:28, 263.73batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17659/40960 [01:05<01:28, 263.73batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17716/40960 [01:05<01:26, 269.67batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17716/40960 [01:05<01:26, 269.67batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  43%|▍| 17768/40960 [01:06<01:27, 265.97batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  43%|▍| 17768/40960 [01:06<01:27, 265.97batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17806/40960 [01:06<01:35, 242.13batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  43%|▍| 17806/40960 [01:06<01:35, 242.13batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 17861/40960 [01:06<01:31, 251.43batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 17861/40960 [01:06<01:31, 251.43batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  44%|▍| 17918/40960 [01:06<01:28, 260.84batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  44%|▍| 17918/40960 [01:06<01:28, 260.84batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 17972/40960 [01:06<01:27, 261.94batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 17972/40960 [01:06<01:27, 261.94batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 18019/40960 [01:07<01:30, 252.63batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 18019/40960 [01:07<01:30, 252.63batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 18070/40960 [01:07<01:30, 252.24batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 18070/40960 [01:07<01:30, 252.24batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 18125/40960 [01:07<01:28, 258.60batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 18125/40960 [01:07<01:28, 258.60batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 18173/40960 [01:07<01:30, 252.86batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  44%|▍| 18173/40960 [01:07<01:30, 252.86batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  45%|▍| 18229/40960 [01:07<01:27, 260.78batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  45%|▍| 18229/40960 [01:07<01:27, 260.78batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  45%|▍| 18284/40960 [01:08<01:25, 264.81batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  45%|▍| 18284/40960 [01:08<01:25, 264.81batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  45%|▍| 18337/40960 [01:08<01:25, 264.38batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  45%|▍| 18337/40960 [01:08<01:25, 264.38batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  45%|▍| 18390/40960 [01:08<01:25, 263.46batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  45%|▍| 18390/40960 [01:08<01:25, 263.46batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  45%|▍| 18442/40960 [01:08<01:26, 259.87batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  45%|▍| 18442/40960 [01:08<01:26, 259.87batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  45%|▍| 18494/40960 [01:08<01:26, 259.09batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  45%|▍| 18494/40960 [01:08<01:26, 259.09batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  45%|▍| 18545/40960 [01:09<01:27, 257.64batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  45%|▍| 18545/40960 [01:09<01:27, 257.64batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  45%|▍| 18604/40960 [01:09<01:23, 267.64batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  45%|▍| 18604/40960 [01:09<01:23, 267.64batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18664/40960 [01:09<01:20, 276.26batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18664/40960 [01:09<01:20, 276.26batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  46%|▍| 18715/40960 [01:09<01:22, 269.01batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  46%|▍| 18715/40960 [01:09<01:22, 269.01batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18757/40960 [01:10<01:28, 250.96batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18757/40960 [01:10<01:28, 250.96batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  46%|▍| 18814/40960 [01:10<01:25, 260.45batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  46%|▍| 18814/40960 [01:10<01:25, 260.45batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18871/40960 [01:10<01:22, 267.62batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18871/40960 [01:10<01:22, 267.62batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18931/40960 [01:10<01:19, 277.21batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18931/40960 [01:10<01:19, 277.21batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18987/40960 [01:10<01:19, 277.04batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  46%|▍| 18987/40960 [01:10<01:19, 277.04batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  46%|▍| 19046/40960 [01:11<01:17, 281.19batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  46%|▍| 19046/40960 [01:11<01:17, 281.19batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  47%|▍| 19106/40960 [01:11<01:16, 285.84batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  47%|▍| 19106/40960 [01:11<01:16, 285.84batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  47%|▍| 19165/40960 [01:11<01:15, 287.42batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  47%|▍| 19165/40960 [01:11<01:15, 287.42batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  47%|▍| 19222/40960 [01:11<01:16, 285.57batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  47%|▍| 19222/40960 [01:11<01:16, 285.57batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  47%|▍| 19278/40960 [01:11<01:16, 283.27batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  47%|▍| 19278/40960 [01:11<01:16, 283.27batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  47%|▍| 19337/40960 [01:12<01:15, 285.67batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  47%|▍| 19337/40960 [01:12<01:15, 285.67batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  47%|▍| 19397/40960 [01:12<01:14, 288.99batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  47%|▍| 19397/40960 [01:12<01:14, 288.99batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19456/40960 [01:12<01:14, 289.89batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19456/40960 [01:12<01:14, 289.89batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19513/40960 [01:12<01:14, 287.85batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19513/40960 [01:12<01:14, 287.85batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  48%|▍| 19569/40960 [01:12<01:15, 284.40batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  48%|▍| 19569/40960 [01:12<01:15, 284.40batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19627/40960 [01:13<01:15, 283.96batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19627/40960 [01:13<01:15, 283.96batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19682/40960 [01:13<01:15, 280.31batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19682/40960 [01:13<01:15, 280.31batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19740/40960 [01:13<01:15, 281.94batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19740/40960 [01:13<01:15, 281.94batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19796/40960 [01:13<01:15, 280.84batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  48%|▍| 19796/40960 [01:13<01:15, 280.84batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  48%|▍| 19851/40960 [01:13<01:15, 278.57batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  48%|▍| 19851/40960 [01:13<01:15, 278.57batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 19906/40960 [01:14<01:15, 277.20batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 19906/40960 [01:14<01:15, 277.20batches/s, l2_loss: 0.0482 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|▍| 19961/40960 [01:14<01:16, 275.56batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 19961/40960 [01:14<01:16, 275.56batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 20013/40960 [01:14<01:17, 269.72batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 20013/40960 [01:14<01:17, 269.72batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  49%|▍| 20074/40960 [01:14<01:14, 279.62batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  49%|▍| 20074/40960 [01:14<01:14, 279.62batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 20133/40960 [01:14<01:13, 283.52batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 20133/40960 [01:14<01:13, 283.52batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 20192/40960 [01:15<01:12, 286.44batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 20192/40960 [01:15<01:12, 286.44batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 20251/40960 [01:15<01:11, 288.02batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  49%|▍| 20251/40960 [01:15<01:11, 288.02batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▍| 20302/40960 [01:15<01:14, 277.88batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▍| 20302/40960 [01:15<01:14, 277.88batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▍| 20356/40960 [01:15<01:14, 274.86batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▍| 20356/40960 [01:15<01:14, 274.86batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▍| 20411/40960 [01:15<01:14, 274.60batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▍| 20411/40960 [01:15<01:14, 274.60batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▍| 20446/40960 [01:16<01:23, 244.81batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▍| 20446/40960 [01:16<01:23, 244.81batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▌| 20492/40960 [01:16<01:25, 239.07batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▌| 20492/40960 [01:16<01:25, 239.07batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▌| 20550/40960 [01:16<01:20, 253.38batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▌| 20550/40960 [01:16<01:20, 253.38batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▌| 20609/40960 [01:16<01:16, 265.45batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▌| 20609/40960 [01:16<01:16, 265.45batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▌| 20661/40960 [01:16<01:17, 262.12batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  50%|▌| 20661/40960 [01:16<01:17, 262.12batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 20703/40960 [01:17<01:22, 244.26batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 20703/40960 [01:17<01:22, 244.26batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 20755/40960 [01:17<01:21, 246.66batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 20755/40960 [01:17<01:21, 246.66batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 20815/40960 [01:17<01:17, 261.55batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 20815/40960 [01:17<01:17, 261.55batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  51%|▌| 20874/40960 [01:17<01:14, 270.64batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  51%|▌| 20874/40960 [01:17<01:14, 270.64batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 20927/40960 [01:17<01:14, 268.11batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 20927/40960 [01:17<01:14, 268.11batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  51%|▌| 20976/40960 [01:18<01:17, 259.26batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  51%|▌| 20976/40960 [01:18<01:17, 259.26batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 21034/40960 [01:18<01:14, 268.10batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 21034/40960 [01:18<01:14, 268.10batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 21094/40960 [01:18<01:11, 276.54batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  51%|▌| 21094/40960 [01:18<01:11, 276.54batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21149/40960 [01:18<01:11, 276.03batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21149/40960 [01:18<01:11, 276.03batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21204/40960 [01:18<01:11, 274.72batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21204/40960 [01:18<01:11, 274.72batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21259/40960 [01:19<01:11, 274.56batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21259/40960 [01:19<01:11, 274.56batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21317/40960 [01:19<01:10, 279.10batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21317/40960 [01:19<01:10, 279.10batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21374/40960 [01:19<01:09, 280.49batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21374/40960 [01:19<01:09, 280.49batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21432/40960 [01:19<01:09, 282.38batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21432/40960 [01:19<01:09, 282.38batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21483/40960 [01:19<01:11, 274.03batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  52%|▌| 21483/40960 [01:19<01:11, 274.03batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21538/40960 [01:20<01:11, 272.95batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21538/40960 [01:20<01:11, 272.95batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21594/40960 [01:20<01:10, 274.31batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21594/40960 [01:20<01:10, 274.31batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21648/40960 [01:20<01:10, 272.15batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21648/40960 [01:20<01:10, 272.15batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21704/40960 [01:20<01:10, 274.22batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21704/40960 [01:20<01:10, 274.22batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21762/40960 [01:20<01:09, 277.22batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21762/40960 [01:20<01:09, 277.22batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21821/40960 [01:21<01:08, 281.39batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  53%|▌| 21821/40960 [01:21<01:08, 281.39batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  53%|▌| 21877/40960 [01:21<01:08, 279.92batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  53%|▌| 21877/40960 [01:21<01:08, 279.92batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 21939/40960 [01:21<01:05, 288.39batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 21939/40960 [01:21<01:05, 288.39batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 21995/40960 [01:21<01:06, 285.09batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 21995/40960 [01:21<01:06, 285.09batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 22053/40960 [01:21<01:06, 286.10batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 22053/40960 [01:21<01:06, 286.10batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 22112/40960 [01:22<01:05, 288.48batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 22112/40960 [01:22<01:05, 288.48batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 22164/40960 [01:22<01:07, 279.46batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 22164/40960 [01:22<01:07, 279.46batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  54%|▌| 22219/40960 [01:22<01:07, 276.78batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  54%|▌| 22219/40960 [01:22<01:07, 276.78batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 22280/40960 [01:22<01:05, 284.63batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  54%|▌| 22280/40960 [01:22<01:05, 284.63batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22340/40960 [01:22<01:04, 288.92batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22340/40960 [01:22<01:04, 288.92batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  55%|▌| 22400/40960 [01:23<01:03, 291.23batches/s, l2_loss: 0.0481 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22400/40960 [01:23<01:03, 291.23batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22448/40960 [01:23<01:07, 273.76batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22448/40960 [01:23<01:07, 273.76batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22499/40960 [01:23<01:09, 267.01batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22499/40960 [01:23<01:09, 267.01batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  55%|▌| 22555/40960 [01:23<01:07, 270.78batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  55%|▌| 22555/40960 [01:23<01:07, 270.78batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22603/40960 [01:23<01:10, 260.86batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22603/40960 [01:23<01:10, 260.86batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  55%|▌| 22655/40960 [01:24<01:10, 260.06batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  55%|▌| 22655/40960 [01:24<01:10, 260.06batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22711/40960 [01:24<01:08, 265.04batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  55%|▌| 22711/40960 [01:24<01:08, 265.04batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  56%|▌| 22772/40960 [01:24<01:05, 276.17batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  56%|▌| 22772/40960 [01:24<01:05, 276.17batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  56%|▌| 22832/40960 [01:24<01:04, 282.15batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  56%|▌| 22832/40960 [01:24<01:04, 282.15batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 22888/40960 [01:24<01:04, 280.55batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 22888/40960 [01:24<01:04, 280.55batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 22947/40960 [01:25<01:03, 283.83batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 22947/40960 [01:25<01:03, 283.83batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  56%|▌| 23004/40960 [01:25<01:03, 282.61batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  56%|▌| 23004/40960 [01:25<01:03, 282.61batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 23056/40960 [01:25<01:04, 275.81batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 23056/40960 [01:25<01:04, 275.81batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 23114/40960 [01:25<01:03, 278.86batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 23114/40960 [01:25<01:03, 278.86batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23160/40960 [01:25<01:07, 263.69batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23160/40960 [01:25<01:07, 263.69batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23213/40960 [01:26<01:07, 262.79batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23213/40960 [01:26<01:07, 262.79batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23263/40960 [01:26<01:08, 257.77batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23263/40960 [01:26<01:08, 257.77batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23311/40960 [01:26<01:09, 252.40batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23311/40960 [01:26<01:09, 252.40batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23348/40960 [01:26<01:16, 230.44batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23348/40960 [01:26<01:16, 230.44batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23405/40960 [01:26<01:11, 245.83batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23405/40960 [01:26<01:11, 245.83batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23459/40960 [01:27<01:09, 251.73batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23459/40960 [01:27<01:09, 251.73batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  57%|▌| 23516/40960 [01:27<01:06, 260.85batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  57%|▌| 23516/40960 [01:27<01:06, 260.85batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23575/40960 [01:27<01:04, 270.57batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23575/40960 [01:27<01:04, 270.57batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23632/40960 [01:27<01:03, 274.16batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23632/40960 [01:27<01:03, 274.16batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  58%|▌| 23692/40960 [01:27<01:01, 281.24batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  58%|▌| 23692/40960 [01:27<01:01, 281.24batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  58%|▌| 23742/40960 [01:28<01:03, 271.56batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  58%|▌| 23742/40960 [01:28<01:03, 271.56batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  58%|▌| 23797/40960 [01:28<01:03, 271.69batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  58%|▌| 23797/40960 [01:28<01:03, 271.69batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23853/40960 [01:28<01:02, 274.15batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23853/40960 [01:28<01:02, 274.15batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23912/40960 [01:28<01:01, 279.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23912/40960 [01:28<01:01, 279.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 23967/40960 [01:29<01:01, 276.65batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 23967/40960 [01:29<01:01, 276.65batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24020/40960 [01:29<01:02, 271.70batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24020/40960 [01:29<01:02, 271.70batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  59%|▌| 24075/40960 [01:29<01:02, 271.66batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  59%|▌| 24075/40960 [01:29<01:02, 271.66batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24134/40960 [01:29<01:00, 277.85batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24134/40960 [01:29<01:00, 277.85batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24191/40960 [01:29<01:00, 278.67batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24191/40960 [01:29<01:00, 278.67batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24251/40960 [01:30<00:58, 283.55batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24251/40960 [01:30<00:58, 283.55batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24307/40960 [01:30<00:59, 281.22batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24307/40960 [01:30<00:59, 281.22batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24359/40960 [01:30<01:00, 274.67batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24359/40960 [01:30<01:00, 274.67batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24413/40960 [01:30<01:00, 272.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24413/40960 [01:30<01:00, 272.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24470/40960 [01:30<01:00, 274.77batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24470/40960 [01:30<01:00, 274.77batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24523/40960 [01:31<01:00, 270.55batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24523/40960 [01:31<01:00, 270.55batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24577/40960 [01:31<01:00, 270.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24577/40960 [01:31<01:00, 270.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24637/40960 [01:31<00:58, 278.75batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24637/40960 [01:31<00:58, 278.75batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24694/40960 [01:31<00:58, 279.95batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24694/40960 [01:31<00:58, 279.95batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24748/40960 [01:31<00:58, 275.71batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24748/40960 [01:31<00:58, 275.71batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24805/40960 [01:32<00:58, 277.65batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24805/40960 [01:32<00:58, 277.65batches/s, l2_loss: 0.0481 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 24857/40960 [01:32<00:59, 271.38batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24857/40960 [01:32<00:59, 271.38batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24908/40960 [01:32<01:00, 265.22batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24908/40960 [01:32<01:00, 265.22batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24966/40960 [01:32<00:58, 271.94batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24966/40960 [01:32<00:58, 271.94batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25025/40960 [01:32<00:57, 278.63batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25025/40960 [01:32<00:57, 278.63batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25075/40960 [01:33<00:59, 268.47batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25075/40960 [01:33<00:59, 268.47batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25127/40960 [01:33<00:59, 265.24batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25127/40960 [01:33<00:59, 265.24batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25176/40960 [01:33<01:01, 258.50batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25176/40960 [01:33<01:01, 258.50batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25224/40960 [01:33<01:02, 250.14batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25224/40960 [01:33<01:02, 250.14batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25279/40960 [01:33<01:01, 256.94batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25279/40960 [01:33<01:01, 256.94batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25327/40960 [01:34<01:02, 250.99batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25327/40960 [01:34<01:02, 250.99batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25384/40960 [01:34<00:59, 260.93batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25384/40960 [01:34<00:59, 260.93batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25435/40960 [01:34<01:00, 258.48batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25435/40960 [01:34<01:00, 258.48batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25491/40960 [01:34<00:58, 263.62batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25491/40960 [01:34<00:58, 263.62batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25542/40960 [01:34<00:59, 260.08batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25542/40960 [01:34<00:59, 260.08batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25599/40960 [01:35<00:57, 267.25batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25599/40960 [01:35<00:57, 267.25batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25656/40960 [01:35<00:56, 271.66batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25656/40960 [01:35<00:56, 271.66batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25709/40960 [01:35<00:56, 269.19batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25709/40960 [01:35<00:56, 269.19batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25760/40960 [01:35<00:57, 264.69batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25760/40960 [01:35<00:57, 264.69batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25818/40960 [01:35<00:55, 271.31batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25818/40960 [01:35<00:55, 271.31batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25876/40960 [01:36<00:54, 276.35batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25876/40960 [01:36<00:54, 276.35batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25929/40960 [01:36<00:55, 271.58batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25929/40960 [01:36<00:55, 271.58batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25980/40960 [01:36<00:56, 265.05batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  63%|▋| 25980/40960 [01:36<00:56, 265.05batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26035/40960 [01:36<00:55, 267.72batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26035/40960 [01:36<00:55, 267.72batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26092/40960 [01:36<00:54, 271.76batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26092/40960 [01:36<00:54, 271.76batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26140/40960 [01:37<00:56, 261.82batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26140/40960 [01:37<00:56, 261.82batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26184/40960 [01:37<01:00, 246.27batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26184/40960 [01:37<01:00, 246.27batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26234/40960 [01:37<00:59, 245.74batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26234/40960 [01:37<00:59, 245.74batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26282/40960 [01:37<01:00, 242.46batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26282/40960 [01:37<01:00, 242.46batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26340/40960 [01:37<00:57, 255.87batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26340/40960 [01:37<00:57, 255.87batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26397/40960 [01:38<00:55, 263.42batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  64%|▋| 26397/40960 [01:38<00:55, 263.42batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26449/40960 [01:38<00:55, 261.95batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26449/40960 [01:38<00:55, 261.95batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26508/40960 [01:38<00:53, 270.16batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26508/40960 [01:38<00:53, 270.16batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26566/40960 [01:38<00:52, 275.51batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26566/40960 [01:38<00:52, 275.51batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26621/40960 [01:38<00:52, 275.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26621/40960 [01:38<00:52, 275.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26676/40960 [01:39<00:52, 274.13batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26676/40960 [01:39<00:52, 274.13batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26736/40960 [01:39<00:50, 280.48batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26736/40960 [01:39<00:50, 280.48batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26787/40960 [01:39<00:52, 272.21batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  65%|▋| 26787/40960 [01:39<00:52, 272.21batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 26836/40960 [01:39<00:53, 263.79batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 26836/40960 [01:39<00:53, 263.79batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 26895/40960 [01:39<00:51, 272.21batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 26895/40960 [01:39<00:51, 272.21batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 26948/40960 [01:40<00:52, 269.11batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 26948/40960 [01:40<00:52, 269.11batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  66%|▋| 27003/40960 [01:40<00:51, 269.71batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  66%|▋| 27003/40960 [01:40<00:51, 269.71batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 27052/40960 [01:40<00:53, 260.87batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 27052/40960 [01:40<00:53, 260.87batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 27106/40960 [01:40<00:52, 262.80batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 27106/40960 [01:40<00:52, 262.80batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 27156/40960 [01:40<00:53, 256.49batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 27156/40960 [01:40<00:53, 256.49batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  66%|▋| 27209/40960 [01:41<00:53, 257.95batches/s, l2_loss: 0.0481 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|▋| 27209/40960 [01:41<00:53, 257.95batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27259/40960 [01:41<00:53, 255.59batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27259/40960 [01:41<00:53, 255.59batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27310/40960 [01:41<00:53, 255.26batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27310/40960 [01:41<00:53, 255.26batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27363/40960 [01:41<00:52, 257.61batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27363/40960 [01:41<00:52, 257.61batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27400/40960 [01:41<00:57, 235.75batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27400/40960 [01:41<00:57, 235.75batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27453/40960 [01:42<00:55, 243.24batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27453/40960 [01:42<00:55, 243.24batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27509/40960 [01:42<00:52, 254.08batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27509/40960 [01:42<00:52, 254.08batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27564/40960 [01:42<00:51, 258.69batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27564/40960 [01:42<00:51, 258.69batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27621/40960 [01:42<00:50, 264.70batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  67%|▋| 27621/40960 [01:42<00:50, 264.70batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27678/40960 [01:42<00:49, 269.47batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27678/40960 [01:42<00:49, 269.47batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27735/40960 [01:43<00:48, 273.10batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27735/40960 [01:43<00:48, 273.10batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27791/40960 [01:43<00:47, 274.50batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27791/40960 [01:43<00:47, 274.50batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27850/40960 [01:43<00:46, 280.17batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27850/40960 [01:43<00:46, 280.17batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27909/40960 [01:43<00:45, 284.40batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27909/40960 [01:43<00:45, 284.40batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27965/40960 [01:43<00:45, 282.90batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 27965/40960 [01:43<00:45, 282.90batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 28023/40960 [01:44<00:45, 284.91batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  68%|▋| 28023/40960 [01:44<00:45, 284.91batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28081/40960 [01:44<00:45, 285.51batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28081/40960 [01:44<00:45, 285.51batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28139/40960 [01:44<00:44, 286.44batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28139/40960 [01:44<00:44, 286.44batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28194/40960 [01:44<00:45, 281.72batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28194/40960 [01:44<00:45, 281.72batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28247/40960 [01:44<00:45, 276.63batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28247/40960 [01:44<00:45, 276.63batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28302/40960 [01:45<00:46, 274.65batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28302/40960 [01:45<00:46, 274.65batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28357/40960 [01:45<00:45, 274.73batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28357/40960 [01:45<00:45, 274.73batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28415/40960 [01:45<00:45, 278.39batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  69%|▋| 28415/40960 [01:45<00:45, 278.39batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  70%|▋| 28473/40960 [01:45<00:44, 281.00batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  70%|▋| 28473/40960 [01:45<00:44, 281.00batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28521/40960 [01:45<00:46, 267.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28521/40960 [01:45<00:46, 267.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28579/40960 [01:46<00:45, 274.02batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28579/40960 [01:46<00:45, 274.02batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28628/40960 [01:46<00:46, 264.37batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28628/40960 [01:46<00:46, 264.37batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28679/40960 [01:46<00:47, 260.91batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28679/40960 [01:46<00:47, 260.91batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  70%|▋| 28733/40960 [01:46<00:46, 263.39batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  70%|▋| 28733/40960 [01:46<00:46, 263.39batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28794/40960 [01:47<00:44, 274.60batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  70%|▋| 28794/40960 [01:47<00:44, 274.60batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  70%|▋| 28851/40960 [01:47<00:43, 277.70batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  70%|▋| 28851/40960 [01:47<00:43, 277.70batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  71%|▋| 28905/40960 [01:47<00:43, 274.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  71%|▋| 28905/40960 [01:47<00:43, 274.54batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  71%|▋| 28963/40960 [01:47<00:43, 278.75batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  71%|▋| 28963/40960 [01:47<00:43, 278.75batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  71%|▋| 29017/40960 [01:47<00:43, 275.34batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  71%|▋| 29017/40960 [01:47<00:43, 275.34batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  71%|▋| 29074/40960 [01:48<00:42, 277.79batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  71%|▋| 29074/40960 [01:48<00:42, 277.79batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  71%|▋| 29131/40960 [01:48<00:42, 278.76batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  71%|▋| 29131/40960 [01:48<00:42, 278.76batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  71%|▋| 29186/40960 [01:48<00:42, 276.84batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  71%|▋| 29186/40960 [01:48<00:42, 276.84batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  71%|▋| 29245/40960 [01:48<00:41, 280.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  71%|▋| 29245/40960 [01:48<00:41, 280.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  72%|▋| 29302/40960 [01:48<00:41, 281.67batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  72%|▋| 29302/40960 [01:48<00:41, 281.67batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  72%|▋| 29361/40960 [01:49<00:40, 284.36batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  72%|▋| 29361/40960 [01:49<00:40, 284.36batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  72%|▋| 29417/40960 [01:49<00:40, 282.20batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  72%|▋| 29417/40960 [01:49<00:40, 282.20batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  72%|▋| 29471/40960 [01:49<00:41, 277.37batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  72%|▋| 29471/40960 [01:49<00:41, 277.37batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  72%|▋| 29527/40960 [01:49<00:41, 276.80batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  72%|▋| 29527/40960 [01:49<00:41, 276.80batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  72%|▋| 29585/40960 [01:49<00:40, 279.55batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  72%|▋| 29585/40960 [01:49<00:40, 279.55batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  72%|▋| 29643/40960 [01:50<00:40, 281.43batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  72%|▋| 29643/40960 [01:50<00:40, 281.43batches/s, l2_loss: 0.0480 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|▋| 29697/40960 [01:50<00:40, 275.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29697/40960 [01:50<00:40, 275.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29747/40960 [01:50<00:41, 268.25batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29747/40960 [01:50<00:41, 268.25batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29805/40960 [01:50<00:40, 273.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29805/40960 [01:50<00:40, 273.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29864/40960 [01:50<00:39, 279.56batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29864/40960 [01:50<00:39, 279.56batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  73%|▋| 29922/40960 [01:51<00:39, 281.89batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  73%|▋| 29922/40960 [01:51<00:39, 281.89batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29971/40960 [01:51<00:40, 269.49batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 29971/40960 [01:51<00:40, 269.49batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 30032/40960 [01:51<00:39, 278.76batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 30032/40960 [01:51<00:39, 278.76batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 30089/40960 [01:51<00:38, 280.49batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  73%|▋| 30089/40960 [01:51<00:38, 280.49batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30140/40960 [01:51<00:39, 271.08batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30140/40960 [01:51<00:39, 271.08batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  74%|▋| 30198/40960 [01:52<00:38, 276.53batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  74%|▋| 30198/40960 [01:52<00:38, 276.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30256/40960 [01:52<00:38, 280.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30256/40960 [01:52<00:38, 280.01batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  74%|▋| 30315/40960 [01:52<00:37, 284.41batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  74%|▋| 30315/40960 [01:52<00:37, 284.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30374/40960 [01:52<00:36, 287.38batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30374/40960 [01:52<00:36, 287.38batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30433/40960 [01:52<00:36, 289.24batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30433/40960 [01:52<00:36, 289.24batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30486/40960 [01:53<00:37, 280.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  74%|▋| 30486/40960 [01:53<00:37, 280.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▋| 30543/40960 [01:53<00:36, 281.82batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▋| 30543/40960 [01:53<00:36, 281.82batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▋| 30598/40960 [01:53<00:37, 279.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▋| 30598/40960 [01:53<00:37, 279.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▋| 30656/40960 [01:53<00:36, 282.11batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▋| 30656/40960 [01:53<00:36, 282.11batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▋| 30706/40960 [01:53<00:37, 270.93batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▋| 30706/40960 [01:53<00:37, 270.93batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▊| 30763/40960 [01:54<00:37, 273.99batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▊| 30763/40960 [01:54<00:37, 273.99batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▊| 30822/40960 [01:54<00:36, 279.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▊| 30822/40960 [01:54<00:36, 279.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▊| 30873/40960 [01:54<00:37, 270.77batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  75%|▊| 30873/40960 [01:54<00:37, 270.77batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 30933/40960 [01:54<00:36, 278.08batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 30933/40960 [01:54<00:36, 278.08batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 30981/40960 [01:54<00:37, 265.26batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 30981/40960 [01:54<00:37, 265.26batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31030/40960 [01:55<00:38, 258.39batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31030/40960 [01:55<00:38, 258.39batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31086/40960 [01:55<00:37, 263.80batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31086/40960 [01:55<00:37, 263.80batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31146/40960 [01:55<00:35, 273.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31146/40960 [01:55<00:35, 273.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31204/40960 [01:55<00:35, 278.14batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31204/40960 [01:55<00:35, 278.14batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31264/40960 [01:55<00:34, 283.60batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31264/40960 [01:55<00:34, 283.60batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31322/40960 [01:56<00:33, 285.15batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  76%|▊| 31322/40960 [01:56<00:33, 285.15batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31379/40960 [01:56<00:33, 283.72batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31379/40960 [01:56<00:33, 283.72batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31436/40960 [01:56<00:33, 283.86batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31436/40960 [01:56<00:33, 283.86batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31495/40960 [01:56<00:32, 287.17batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31495/40960 [01:56<00:32, 287.17batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31551/40960 [01:56<00:33, 283.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31551/40960 [01:56<00:33, 283.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31610/40960 [01:57<00:32, 286.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31610/40960 [01:57<00:32, 286.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31668/40960 [01:57<00:32, 287.28batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31668/40960 [01:57<00:32, 287.28batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31723/40960 [01:57<00:32, 282.11batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  77%|▊| 31723/40960 [01:57<00:32, 282.11batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 31773/40960 [01:57<00:33, 270.33batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 31773/40960 [01:57<00:33, 270.33batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  78%|▊| 31826/40960 [01:57<00:34, 268.40batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  78%|▊| 31826/40960 [01:57<00:34, 268.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 31882/40960 [01:58<00:33, 270.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 31882/40960 [01:58<00:33, 270.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 31932/40960 [01:58<00:34, 263.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 31932/40960 [01:58<00:34, 263.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 31987/40960 [01:58<00:33, 265.81batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 31987/40960 [01:58<00:33, 265.81batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 32040/40960 [01:58<00:33, 264.81batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 32040/40960 [01:58<00:33, 264.81batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 32097/40960 [01:58<00:32, 269.69batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 32097/40960 [01:58<00:32, 269.69batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  78%|▊| 32153/40960 [01:59<00:32, 271.98batches/s, l2_loss: 0.0480 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|▊| 32153/40960 [01:59<00:32, 271.98batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32212/40960 [01:59<00:31, 278.47batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32212/40960 [01:59<00:31, 278.47batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32268/40960 [01:59<00:31, 277.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32268/40960 [01:59<00:31, 277.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32325/40960 [01:59<00:30, 279.51batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32325/40960 [01:59<00:30, 279.51batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32380/40960 [01:59<00:30, 277.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32380/40960 [01:59<00:30, 277.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32439/40960 [02:00<00:30, 282.50batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32439/40960 [02:00<00:30, 282.50batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32486/40960 [02:00<00:31, 267.18batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32486/40960 [02:00<00:31, 267.18batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32543/40960 [02:00<00:30, 271.60batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  79%|▊| 32543/40960 [02:00<00:30, 271.60batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32603/40960 [02:00<00:29, 279.18batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32603/40960 [02:00<00:29, 279.18batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32660/40960 [02:00<00:29, 280.75batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32660/40960 [02:00<00:29, 280.75batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32712/40960 [02:01<00:30, 272.91batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32712/40960 [02:01<00:30, 272.91batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32767/40960 [02:01<00:30, 272.99batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32767/40960 [02:01<00:30, 272.99batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32818/40960 [02:01<00:30, 267.19batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32818/40960 [02:01<00:30, 267.19batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32874/40960 [02:01<00:29, 270.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32874/40960 [02:01<00:29, 270.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32928/40960 [02:01<00:29, 269.92batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  80%|▊| 32928/40960 [02:01<00:29, 269.92batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 32980/40960 [02:02<00:29, 266.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 32980/40960 [02:02<00:29, 266.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33030/40960 [02:02<00:30, 261.43batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33030/40960 [02:02<00:30, 261.43batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33081/40960 [02:02<00:30, 258.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33081/40960 [02:02<00:30, 258.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33135/40960 [02:02<00:29, 261.51batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33135/40960 [02:02<00:29, 261.51batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33187/40960 [02:02<00:29, 260.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33187/40960 [02:02<00:29, 260.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33237/40960 [02:03<00:30, 255.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33237/40960 [02:03<00:30, 255.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33289/40960 [02:03<00:30, 255.17batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33289/40960 [02:03<00:30, 255.17batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33340/40960 [02:03<00:29, 254.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  81%|▊| 33340/40960 [02:03<00:29, 254.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33395/40960 [02:03<00:29, 260.17batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33395/40960 [02:03<00:29, 260.17batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33455/40960 [02:03<00:27, 271.96batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33455/40960 [02:03<00:27, 271.96batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33508/40960 [02:04<00:27, 269.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33508/40960 [02:04<00:27, 269.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33555/40960 [02:04<00:28, 258.19batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33555/40960 [02:04<00:28, 258.19batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33611/40960 [02:04<00:27, 264.33batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33611/40960 [02:04<00:27, 264.33batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33669/40960 [02:04<00:26, 270.93batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33669/40960 [02:04<00:26, 270.93batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33722/40960 [02:04<00:26, 268.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33722/40960 [02:04<00:26, 268.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33770/40960 [02:05<00:27, 258.92batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  82%|▊| 33770/40960 [02:05<00:27, 258.92batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 33819/40960 [02:05<00:28, 254.23batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 33819/40960 [02:05<00:28, 254.23batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 33869/40960 [02:05<00:28, 252.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 33869/40960 [02:05<00:28, 252.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 33923/40960 [02:05<00:27, 257.42batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 33923/40960 [02:05<00:27, 257.42batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 33981/40960 [02:05<00:26, 266.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 33981/40960 [02:05<00:26, 266.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 34036/40960 [02:06<00:25, 268.35batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 34036/40960 [02:06<00:25, 268.35batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 34094/40960 [02:06<00:25, 273.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 34094/40960 [02:06<00:25, 273.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 34149/40960 [02:06<00:24, 273.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  83%|▊| 34149/40960 [02:06<00:24, 273.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34207/40960 [02:06<00:24, 277.15batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34207/40960 [02:06<00:24, 277.15batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34259/40960 [02:07<00:24, 270.47batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34259/40960 [02:07<00:24, 270.47batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34317/40960 [02:07<00:24, 274.75batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34317/40960 [02:07<00:24, 274.75batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34372/40960 [02:07<00:24, 274.24batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34372/40960 [02:07<00:24, 274.24batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34428/40960 [02:07<00:23, 274.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34428/40960 [02:07<00:23, 274.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34463/40960 [02:07<00:26, 244.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34463/40960 [02:07<00:26, 244.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34520/40960 [02:08<00:25, 255.97batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34520/40960 [02:08<00:25, 255.97batches/s, l2_loss: 0.0480 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|▊| 34576/40960 [02:08<00:24, 262.65batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  84%|▊| 34576/40960 [02:08<00:24, 262.65batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34633/40960 [02:08<00:23, 268.45batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34633/40960 [02:08<00:23, 268.45batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34690/40960 [02:08<00:22, 272.86batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34690/40960 [02:08<00:22, 272.86batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34748/40960 [02:08<00:22, 276.99batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34748/40960 [02:08<00:22, 276.99batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34803/40960 [02:09<00:22, 276.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34803/40960 [02:09<00:22, 276.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34856/40960 [02:09<00:22, 271.32batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34856/40960 [02:09<00:22, 271.32batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34904/40960 [02:09<00:23, 260.96batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34904/40960 [02:09<00:23, 260.96batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34956/40960 [02:09<00:23, 259.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 34956/40960 [02:09<00:23, 259.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 35014/40960 [02:09<00:22, 267.06batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  85%|▊| 35014/40960 [02:09<00:22, 267.06batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35069/40960 [02:10<00:21, 268.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35069/40960 [02:10<00:21, 268.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35128/40960 [02:10<00:21, 275.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35128/40960 [02:10<00:21, 275.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35181/40960 [02:10<00:21, 271.66batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35181/40960 [02:10<00:21, 271.66batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35240/40960 [02:10<00:20, 277.76batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35240/40960 [02:10<00:20, 277.76batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35297/40960 [02:10<00:20, 279.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35297/40960 [02:10<00:20, 279.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35356/40960 [02:11<00:19, 282.73batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35356/40960 [02:11<00:19, 282.73batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35416/40960 [02:11<00:19, 287.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  86%|▊| 35416/40960 [02:11<00:19, 287.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35471/40960 [02:11<00:19, 282.45batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35471/40960 [02:11<00:19, 282.45batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35532/40960 [02:11<00:18, 288.93batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35532/40960 [02:11<00:18, 288.93batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35588/40960 [02:11<00:18, 284.82batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35588/40960 [02:11<00:18, 284.82batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35646/40960 [02:12<00:18, 284.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35646/40960 [02:12<00:18, 284.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35701/40960 [02:12<00:18, 280.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35701/40960 [02:12<00:18, 280.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35755/40960 [02:12<00:18, 275.96batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35755/40960 [02:12<00:18, 275.96batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35812/40960 [02:12<00:18, 278.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  87%|▊| 35812/40960 [02:12<00:18, 278.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 35866/40960 [02:12<00:18, 275.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 35866/40960 [02:12<00:18, 275.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 35914/40960 [02:13<00:19, 264.23batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 35914/40960 [02:13<00:19, 264.23batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 35969/40960 [02:13<00:18, 266.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 35969/40960 [02:13<00:18, 266.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 36022/40960 [02:13<00:18, 265.85batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 36022/40960 [02:13<00:18, 265.85batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 36078/40960 [02:13<00:18, 269.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 36078/40960 [02:13<00:18, 269.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 36138/40960 [02:13<00:17, 277.55batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 36138/40960 [02:13<00:17, 277.55batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 36198/40960 [02:14<00:16, 284.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  88%|▉| 36198/40960 [02:14<00:16, 284.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36256/40960 [02:14<00:16, 285.81batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36256/40960 [02:14<00:16, 285.81batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36313/40960 [02:14<00:16, 284.09batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36313/40960 [02:14<00:16, 284.09batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36356/40960 [02:14<00:17, 261.36batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36356/40960 [02:14<00:17, 261.36batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36412/40960 [02:14<00:17, 266.89batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36412/40960 [02:14<00:17, 266.89batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36468/40960 [02:15<00:16, 270.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36468/40960 [02:15<00:16, 270.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36524/40960 [02:15<00:16, 272.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36524/40960 [02:15<00:16, 272.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36576/40960 [02:15<00:16, 267.28batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36576/40960 [02:15<00:16, 267.28batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36629/40960 [02:15<00:16, 265.73batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  89%|▉| 36629/40960 [02:15<00:16, 265.73batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36678/40960 [02:15<00:16, 259.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36678/40960 [02:15<00:16, 259.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36736/40960 [02:16<00:15, 268.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36736/40960 [02:16<00:15, 268.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36785/40960 [02:16<00:16, 259.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36785/40960 [02:16<00:16, 259.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36842/40960 [02:16<00:15, 266.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36842/40960 [02:16<00:15, 266.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36899/40960 [02:16<00:14, 271.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36899/40960 [02:16<00:14, 271.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36957/40960 [02:16<00:14, 276.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 36957/40960 [02:16<00:14, 276.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  90%|▉| 37013/40960 [02:17<00:14, 275.70batches/s, l2_loss: 0.0480 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 37013/40960 [02:17<00:14, 275.70batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [02:17<00:14, 277.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [02:17<00:14, 277.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37111/40960 [02:17<00:15, 253.72batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37111/40960 [02:17<00:15, 253.72batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37163/40960 [02:17<00:14, 254.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37163/40960 [02:17<00:14, 254.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37213/40960 [02:17<00:14, 252.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37213/40960 [02:17<00:14, 252.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37264/40960 [02:18<00:14, 251.97batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37264/40960 [02:18<00:14, 251.97batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37318/40960 [02:18<00:14, 256.77batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37318/40960 [02:18<00:14, 256.77batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37373/40960 [02:18<00:13, 261.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37373/40960 [02:18<00:13, 261.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37432/40960 [02:18<00:13, 269.90batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  91%|▉| 37432/40960 [02:18<00:13, 269.90batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37486/40960 [02:18<00:12, 269.67batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37486/40960 [02:18<00:12, 269.67batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37544/40960 [02:19<00:12, 274.37batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37544/40960 [02:19<00:12, 274.37batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37602/40960 [02:19<00:12, 278.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37602/40960 [02:19<00:12, 278.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37659/40960 [02:19<00:11, 280.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37659/40960 [02:19<00:11, 280.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37717/40960 [02:19<00:11, 282.45batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37717/40960 [02:19<00:11, 282.45batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37768/40960 [02:19<00:11, 273.23batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37768/40960 [02:19<00:11, 273.23batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37825/40960 [02:20<00:11, 276.02batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37825/40960 [02:20<00:11, 276.02batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37876/40960 [02:20<00:11, 268.03batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  92%|▉| 37876/40960 [02:20<00:11, 268.03batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 37931/40960 [02:20<00:11, 269.92batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 37931/40960 [02:20<00:11, 269.92batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 37985/40960 [02:20<00:11, 268.86batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 37985/40960 [02:20<00:11, 268.86batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38035/40960 [02:20<00:11, 262.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38035/40960 [02:20<00:11, 262.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38088/40960 [02:21<00:10, 262.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38088/40960 [02:21<00:10, 262.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38144/40960 [02:21<00:10, 267.42batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38144/40960 [02:21<00:10, 267.42batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38201/40960 [02:21<00:10, 270.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38201/40960 [02:21<00:10, 270.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38256/40960 [02:21<00:09, 271.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  93%|▉| 38256/40960 [02:21<00:09, 271.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38316/40960 [02:21<00:09, 278.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38316/40960 [02:21<00:09, 278.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38375/40960 [02:22<00:09, 282.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38375/40960 [02:22<00:09, 282.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38430/40960 [02:22<00:09, 279.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38430/40960 [02:22<00:09, 279.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38485/40960 [02:22<00:08, 277.29batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38485/40960 [02:22<00:08, 277.29batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  94%|▉| 38541/40960 [02:22<00:08, 277.35batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  94%|▉| 38541/40960 [02:22<00:08, 277.35batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38601/40960 [02:22<00:08, 283.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38601/40960 [02:22<00:08, 283.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38658/40960 [02:23<00:08, 282.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38658/40960 [02:23<00:08, 282.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38701/40960 [02:23<00:08, 260.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  94%|▉| 38701/40960 [02:23<00:08, 260.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38738/40960 [02:23<00:09, 237.87batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38738/40960 [02:23<00:09, 237.87batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38796/40960 [02:23<00:08, 253.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38796/40960 [02:23<00:08, 253.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38856/40960 [02:23<00:07, 266.02batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38856/40960 [02:23<00:07, 266.02batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38910/40960 [02:24<00:07, 267.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38910/40960 [02:24<00:07, 267.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38964/40960 [02:24<00:07, 266.77batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 38964/40960 [02:24<00:07, 266.77batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 39022/40960 [02:24<00:07, 273.06batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 39022/40960 [02:24<00:07, 273.06batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 39083/40960 [02:24<00:06, 281.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  95%|▉| 39083/40960 [02:24<00:06, 281.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39139/40960 [02:24<00:06, 280.69batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39139/40960 [02:24<00:06, 280.69batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39198/40960 [02:25<00:06, 284.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39198/40960 [02:25<00:06, 284.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39256/40960 [02:25<00:05, 285.32batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39256/40960 [02:25<00:05, 285.32batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39317/40960 [02:25<00:05, 290.33batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39317/40960 [02:25<00:05, 290.33batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39370/40960 [02:25<00:05, 282.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39370/40960 [02:25<00:05, 282.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39422/40960 [02:26<00:05, 275.51batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39422/40960 [02:26<00:05, 275.51batches/s, l2_loss: 0.0480 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|▉| 39472/40960 [02:26<00:05, 266.39batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39472/40960 [02:26<00:05, 266.39batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39525/40960 [02:26<00:05, 265.34batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  96%|▉| 39525/40960 [02:26<00:05, 265.34batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39584/40960 [02:26<00:05, 273.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39584/40960 [02:26<00:05, 273.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39642/40960 [02:26<00:04, 277.86batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39642/40960 [02:26<00:04, 277.86batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39700/40960 [02:27<00:04, 280.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39700/40960 [02:27<00:04, 280.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39757/40960 [02:27<00:04, 280.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39757/40960 [02:27<00:04, 280.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39810/40960 [02:27<00:04, 275.71batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39810/40960 [02:27<00:04, 275.71batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39866/40960 [02:27<00:03, 275.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39866/40960 [02:27<00:03, 275.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39926/40960 [02:27<00:03, 282.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  97%|▉| 39926/40960 [02:27<00:03, 282.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 39981/40960 [02:28<00:03, 280.30batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 39981/40960 [02:28<00:03, 280.30batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  98%|▉| 40034/40960 [02:28<00:03, 274.28batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  98%|▉| 40034/40960 [02:28<00:03, 274.28batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 40087/40960 [02:28<00:03, 270.63batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 40087/40960 [02:28<00:03, 270.63batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 40144/40960 [02:28<00:02, 274.36batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 40144/40960 [02:28<00:02, 274.36batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  98%|▉| 40198/40960 [02:28<00:02, 272.99batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  98%|▉| 40198/40960 [02:28<00:02, 272.99batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 40245/40960 [02:29<00:02, 260.77batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 40245/40960 [02:29<00:02, 260.77batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 40295/40960 [02:29<00:02, 256.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  98%|▉| 40295/40960 [02:29<00:02, 256.41batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  99%|▉| 40352/40960 [02:29<00:02, 264.04batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  99%|▉| 40352/40960 [02:29<00:02, 264.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40406/40960 [02:29<00:02, 265.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40406/40960 [02:29<00:02, 265.59batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  99%|▉| 40454/40960 [02:29<00:01, 256.68batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  99%|▉| 40454/40960 [02:29<00:01, 256.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40505/40960 [02:30<00:01, 255.21batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40505/40960 [02:30<00:01, 255.21batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40561/40960 [02:30<00:01, 262.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40561/40960 [02:30<00:01, 262.46batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40620/40960 [02:30<00:01, 271.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40620/40960 [02:30<00:01, 271.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40671/40960 [02:30<00:01, 265.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40671/40960 [02:30<00:01, 265.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40724/40960 [02:30<00:00, 263.88batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  99%|▉| 40724/40960 [02:30<00:00, 263.88batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training: 100%|▉| 40777/40960 [02:31<00:00, 263.29batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training: 100%|▉| 40777/40960 [02:31<00:00, 263.29batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training: 100%|▉| 40831/40960 [02:31<00:00, 264.68batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training: 100%|▉| 40831/40960 [02:31<00:00, 264.68batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training: 100%|▉| 40890/40960 [02:31<00:00, 273.35batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training: 100%|▉| 40890/40960 [02:31<00:00, 273.35batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training: 100%|▉| 40948/40960 [02:31<00:00, 277.72batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training: 100%|▉| 40948/40960 [02:31<00:00, 277.72batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:08:32.155051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  38%|▍| 10/26 [20:54<38:12, 143.25s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:08:35.489153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:08:42.385849: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<25:26:03,  2.24s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<25:26:03,  2.24s/batches, l2_loss: 0.4666 - round_loss:\u001b[A\n",
      "Training:   0%| | 58/40960 [00:02<20:52, 32.66batches/s, l2_loss: 0.4666 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 58/40960 [00:02<20:52, 32.66batches/s, l2_loss: 0.1427 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 116/40960 [00:02<09:57, 68.38batches/s, l2_loss: 0.1427 - round_loss: \u001b[A\n",
      "Training:   0%| | 116/40960 [00:02<09:57, 68.38batches/s, l2_loss: 0.1490 - round_loss: \u001b[A\n",
      "Training:   0%| | 178/40960 [00:02<06:17, 108.17batches/s, l2_loss: 0.1490 - round_loss:\u001b[A\n",
      "Training:   0%| | 178/40960 [00:02<06:17, 108.17batches/s, l2_loss: 0.1473 - round_loss:\u001b[A\n",
      "Training:   1%| | 236/40960 [00:03<04:45, 142.57batches/s, l2_loss: 0.1473 - round_loss:\u001b[A\n",
      "Training:   1%| | 236/40960 [00:03<04:45, 142.57batches/s, l2_loss: 0.1415 - round_loss:\u001b[A\n",
      "Training:   1%| | 297/40960 [00:03<03:49, 177.21batches/s, l2_loss: 0.1415 - round_loss:\u001b[A\n",
      "Training:   1%| | 297/40960 [00:03<03:49, 177.21batches/s, l2_loss: 0.1380 - round_loss:\u001b[A\n",
      "Training:   1%| | 354/40960 [00:03<03:21, 201.52batches/s, l2_loss: 0.1380 - round_loss:\u001b[A\n",
      "Training:   1%| | 354/40960 [00:03<03:21, 201.52batches/s, l2_loss: 0.1405 - round_loss:\u001b[A\n",
      "Training:   1%| | 412/40960 [00:03<03:01, 223.36batches/s, l2_loss: 0.1405 - round_loss:\u001b[A\n",
      "Training:   1%| | 412/40960 [00:03<03:01, 223.36batches/s, l2_loss: 0.1355 - round_loss:\u001b[A\n",
      "Training:   1%| | 474/40960 [00:03<02:45, 245.15batches/s, l2_loss: 0.1355 - round_loss:\u001b[A\n",
      "Training:   1%| | 474/40960 [00:03<02:45, 245.15batches/s, l2_loss: 0.1337 - round_loss:\u001b[A\n",
      "Training:   1%| | 535/40960 [00:04<02:35, 260.61batches/s, l2_loss: 0.1337 - round_loss:\u001b[A\n",
      "Training:   1%| | 535/40960 [00:04<02:35, 260.61batches/s, l2_loss: 0.1341 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%| | 586/40960 [00:04<02:35, 258.95batches/s, l2_loss: 0.1341 - round_loss:\u001b[A\n",
      "Training:   1%| | 586/40960 [00:04<02:35, 258.95batches/s, l2_loss: 0.1316 - round_loss:\u001b[A\n",
      "Training:   2%| | 647/40960 [00:04<02:28, 271.17batches/s, l2_loss: 0.1316 - round_loss:\u001b[A\n",
      "Training:   2%| | 647/40960 [00:04<02:28, 271.17batches/s, l2_loss: 0.1317 - round_loss:\u001b[A\n",
      "Training:   2%| | 710/40960 [00:04<02:21, 283.63batches/s, l2_loss: 0.1317 - round_loss:\u001b[A\n",
      "Training:   2%| | 710/40960 [00:04<02:21, 283.63batches/s, l2_loss: 0.1322 - round_loss:\u001b[A\n",
      "Training:   2%| | 763/40960 [00:04<02:24, 277.54batches/s, l2_loss: 0.1322 - round_loss:\u001b[A\n",
      "Training:   2%| | 763/40960 [00:04<02:24, 277.54batches/s, l2_loss: 0.1305 - round_loss:\u001b[A\n",
      "Training:   2%| | 820/40960 [00:05<02:24, 278.45batches/s, l2_loss: 0.1305 - round_loss:\u001b[A\n",
      "Training:   2%| | 820/40960 [00:05<02:24, 278.45batches/s, l2_loss: 0.1281 - round_loss:\u001b[A\n",
      "Training:   2%| | 879/40960 [00:05<02:22, 281.71batches/s, l2_loss: 0.1281 - round_loss:\u001b[A\n",
      "Training:   2%| | 879/40960 [00:05<02:22, 281.71batches/s, l2_loss: 0.1282 - round_loss:\u001b[A\n",
      "Training:   2%| | 935/40960 [00:05<02:22, 280.37batches/s, l2_loss: 0.1282 - round_loss:\u001b[A\n",
      "Training:   2%| | 935/40960 [00:05<02:22, 280.37batches/s, l2_loss: 0.1302 - round_loss:\u001b[A\n",
      "Training:   2%| | 988/40960 [00:05<02:24, 275.69batches/s, l2_loss: 0.1302 - round_loss:\u001b[A\n",
      "Training:   2%| | 988/40960 [00:05<02:24, 275.69batches/s, l2_loss: 0.1277 - round_loss:\u001b[A\n",
      "Training:   3%| | 1049/40960 [00:05<02:20, 283.32batches/s, l2_loss: 0.1277 - round_loss\u001b[A\n",
      "Training:   3%| | 1049/40960 [00:05<02:20, 283.32batches/s, l2_loss: 0.1282 - round_loss\u001b[A\n",
      "Training:   3%| | 1108/40960 [00:06<02:19, 285.30batches/s, l2_loss: 0.1282 - round_loss\u001b[A\n",
      "Training:   3%| | 1108/40960 [00:06<02:19, 285.30batches/s, l2_loss: 0.1275 - round_loss\u001b[A\n",
      "Training:   3%| | 1168/40960 [00:06<02:17, 289.05batches/s, l2_loss: 0.1275 - round_loss\u001b[A\n",
      "Training:   3%| | 1168/40960 [00:06<02:17, 289.05batches/s, l2_loss: 0.1254 - round_loss\u001b[A\n",
      "Training:   3%| | 1230/40960 [00:06<02:14, 295.22batches/s, l2_loss: 0.1254 - round_loss\u001b[A\n",
      "Training:   3%| | 1230/40960 [00:06<02:14, 295.22batches/s, l2_loss: 0.1239 - round_loss\u001b[A\n",
      "Training:   3%| | 1285/40960 [00:06<02:17, 288.26batches/s, l2_loss: 0.1239 - round_loss\u001b[A\n",
      "Training:   3%| | 1285/40960 [00:06<02:17, 288.26batches/s, l2_loss: 0.1246 - round_loss\u001b[A\n",
      "Training:   3%| | 1348/40960 [00:06<02:13, 295.84batches/s, l2_loss: 0.1246 - round_loss\u001b[A\n",
      "Training:   3%| | 1348/40960 [00:06<02:13, 295.84batches/s, l2_loss: 0.1230 - round_loss\u001b[A\n",
      "Training:   3%| | 1411/40960 [00:07<02:11, 301.03batches/s, l2_loss: 0.1230 - round_loss\u001b[A\n",
      "Training:   3%| | 1411/40960 [00:07<02:11, 301.03batches/s, l2_loss: 0.1240 - round_loss\u001b[A\n",
      "Training:   4%| | 1460/40960 [00:07<02:19, 282.81batches/s, l2_loss: 0.1240 - round_loss\u001b[A\n",
      "Training:   4%| | 1460/40960 [00:07<02:19, 282.81batches/s, l2_loss: 0.1230 - round_loss\u001b[A\n",
      "Training:   4%| | 1521/40960 [00:07<02:16, 289.18batches/s, l2_loss: 0.1230 - round_loss\u001b[A\n",
      "Training:   4%| | 1521/40960 [00:07<02:16, 289.18batches/s, l2_loss: 0.1232 - round_loss\u001b[A\n",
      "Training:   4%| | 1580/40960 [00:07<02:15, 290.48batches/s, l2_loss: 0.1232 - round_loss\u001b[A\n",
      "Training:   4%| | 1580/40960 [00:07<02:15, 290.48batches/s, l2_loss: 0.1221 - round_loss\u001b[A\n",
      "Training:   4%| | 1640/40960 [00:07<02:14, 292.53batches/s, l2_loss: 0.1221 - round_loss\u001b[A\n",
      "Training:   4%| | 1640/40960 [00:07<02:14, 292.53batches/s, l2_loss: 0.1218 - round_loss\u001b[A\n",
      "Training:   4%| | 1698/40960 [00:08<02:14, 291.37batches/s, l2_loss: 0.1218 - round_loss\u001b[A\n",
      "Training:   4%| | 1698/40960 [00:08<02:14, 291.37batches/s, l2_loss: 0.1219 - round_loss\u001b[A\n",
      "Training:   4%| | 1748/40960 [00:08<02:21, 277.16batches/s, l2_loss: 0.1219 - round_loss\u001b[A\n",
      "Training:   4%| | 1748/40960 [00:08<02:21, 277.16batches/s, l2_loss: 0.1210 - round_loss\u001b[A\n",
      "Training:   4%| | 1811/40960 [00:08<02:16, 287.51batches/s, l2_loss: 0.1210 - round_loss\u001b[A\n",
      "Training:   4%| | 1811/40960 [00:08<02:16, 287.51batches/s, l2_loss: 0.1209 - round_loss\u001b[A\n",
      "Training:   5%| | 1871/40960 [00:08<02:14, 290.56batches/s, l2_loss: 0.1209 - round_loss\u001b[A\n",
      "Training:   5%| | 1871/40960 [00:08<02:14, 290.56batches/s, l2_loss: 0.1204 - round_loss\u001b[A\n",
      "Training:   5%| | 1919/40960 [00:08<02:22, 274.54batches/s, l2_loss: 0.1204 - round_loss\u001b[A\n",
      "Training:   5%| | 1919/40960 [00:08<02:22, 274.54batches/s, l2_loss: 0.1204 - round_loss\u001b[A\n",
      "Training:   5%| | 1963/40960 [00:09<02:31, 256.62batches/s, l2_loss: 0.1204 - round_loss\u001b[A\n",
      "Training:   5%| | 1963/40960 [00:09<02:31, 256.62batches/s, l2_loss: 0.1196 - round_loss\u001b[A\n",
      "Training:   5%| | 2020/40960 [00:09<02:27, 264.00batches/s, l2_loss: 0.1196 - round_loss\u001b[A\n",
      "Training:   5%| | 2020/40960 [00:09<02:27, 264.00batches/s, l2_loss: 0.1203 - round_loss\u001b[A\n",
      "Training:   5%| | 2081/40960 [00:09<02:21, 274.79batches/s, l2_loss: 0.1203 - round_loss\u001b[A\n",
      "Training:   5%| | 2081/40960 [00:09<02:21, 274.79batches/s, l2_loss: 0.1197 - round_loss\u001b[A\n",
      "Training:   5%| | 2138/40960 [00:09<02:19, 277.61batches/s, l2_loss: 0.1197 - round_loss\u001b[A\n",
      "Training:   5%| | 2138/40960 [00:09<02:19, 277.61batches/s, l2_loss: 0.1191 - round_loss\u001b[A\n",
      "Training:   5%| | 2196/40960 [00:09<02:18, 280.81batches/s, l2_loss: 0.1191 - round_loss\u001b[A\n",
      "Training:   5%| | 2196/40960 [00:09<02:18, 280.81batches/s, l2_loss: 0.1193 - round_loss\u001b[A\n",
      "Training:   6%| | 2255/40960 [00:10<02:16, 283.87batches/s, l2_loss: 0.1193 - round_loss\u001b[A\n",
      "Training:   6%| | 2255/40960 [00:10<02:16, 283.87batches/s, l2_loss: 0.1183 - round_loss\u001b[A\n",
      "Training:   6%| | 2298/40960 [00:10<02:28, 260.68batches/s, l2_loss: 0.1183 - round_loss\u001b[A\n",
      "Training:   6%| | 2298/40960 [00:10<02:28, 260.68batches/s, l2_loss: 0.1186 - round_loss\u001b[A\n",
      "Training:   6%| | 2350/40960 [00:10<02:28, 260.00batches/s, l2_loss: 0.1186 - round_loss\u001b[A\n",
      "Training:   6%| | 2350/40960 [00:10<02:28, 260.00batches/s, l2_loss: 0.1187 - round_loss\u001b[A\n",
      "Training:   6%| | 2413/40960 [00:10<02:19, 275.78batches/s, l2_loss: 0.1187 - round_loss\u001b[A\n",
      "Training:   6%| | 2413/40960 [00:10<02:19, 275.78batches/s, l2_loss: 0.1183 - round_loss\u001b[A\n",
      "Training:   6%| | 2474/40960 [00:10<02:15, 283.08batches/s, l2_loss: 0.1183 - round_loss\u001b[A\n",
      "Training:   6%| | 2474/40960 [00:10<02:15, 283.08batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:   6%| | 2520/40960 [00:11<02:23, 267.20batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:   6%| | 2520/40960 [00:11<02:23, 267.20batches/s, l2_loss: 0.1179 - round_loss\u001b[A\n",
      "Training:   6%| | 2568/40960 [00:11<02:29, 257.51batches/s, l2_loss: 0.1179 - round_loss\u001b[A\n",
      "Training:   6%| | 2568/40960 [00:11<02:29, 257.51batches/s, l2_loss: 0.1178 - round_loss\u001b[A\n",
      "Training:   6%| | 2631/40960 [00:11<02:19, 274.11batches/s, l2_loss: 0.1178 - round_loss\u001b[A\n",
      "Training:   6%| | 2631/40960 [00:11<02:19, 274.11batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:   7%| | 2683/40960 [00:11<02:23, 267.17batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:   7%| | 2683/40960 [00:11<02:23, 267.17batches/s, l2_loss: 0.1171 - round_loss\u001b[A\n",
      "Training:   7%| | 2743/40960 [00:11<02:18, 276.16batches/s, l2_loss: 0.1171 - round_loss\u001b[A\n",
      "Training:   7%| | 2743/40960 [00:11<02:18, 276.16batches/s, l2_loss: 0.1172 - round_loss\u001b[A\n",
      "Training:   7%| | 2804/40960 [00:12<02:14, 283.52batches/s, l2_loss: 0.1172 - round_loss\u001b[A\n",
      "Training:   7%| | 2804/40960 [00:12<02:14, 283.52batches/s, l2_loss: 0.1167 - round_loss\u001b[A\n",
      "Training:   7%| | 2864/40960 [00:12<02:12, 287.58batches/s, l2_loss: 0.1167 - round_loss\u001b[A\n",
      "Training:   7%| | 2864/40960 [00:12<02:12, 287.58batches/s, l2_loss: 0.1169 - round_loss\u001b[A\n",
      "Training:   7%| | 2915/40960 [00:12<02:17, 277.15batches/s, l2_loss: 0.1169 - round_loss\u001b[A\n",
      "Training:   7%| | 2915/40960 [00:12<02:17, 277.15batches/s, l2_loss: 0.1165 - round_loss\u001b[A\n",
      "Training:   7%| | 2973/40960 [00:12<02:15, 280.69batches/s, l2_loss: 0.1165 - round_loss\u001b[A\n",
      "Training:   7%| | 2973/40960 [00:12<02:15, 280.69batches/s, l2_loss: 0.1162 - round_loss\u001b[A\n",
      "Training:   7%| | 3037/40960 [00:12<02:10, 291.30batches/s, l2_loss: 0.1162 - round_loss\u001b[A\n",
      "Training:   7%| | 3037/40960 [00:12<02:10, 291.30batches/s, l2_loss: 0.1158 - round_loss\u001b[A\n",
      "Training:   8%| | 3099/40960 [00:13<02:07, 296.14batches/s, l2_loss: 0.1158 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3099/40960 [00:13<02:07, 296.14batches/s, l2_loss: 0.1158 - round_loss\u001b[A\n",
      "Training:   8%| | 3158/40960 [00:13<02:08, 295.32batches/s, l2_loss: 0.1158 - round_loss\u001b[A\n",
      "Training:   8%| | 3158/40960 [00:13<02:08, 295.32batches/s, l2_loss: 0.1159 - round_loss\u001b[A\n",
      "Training:   8%| | 3213/40960 [00:13<02:10, 289.22batches/s, l2_loss: 0.1159 - round_loss\u001b[A\n",
      "Training:   8%| | 3213/40960 [00:13<02:10, 289.22batches/s, l2_loss: 0.1153 - round_loss\u001b[A\n",
      "Training:   8%| | 3271/40960 [00:13<02:10, 287.71batches/s, l2_loss: 0.1153 - round_loss\u001b[A\n",
      "Training:   8%| | 3271/40960 [00:13<02:10, 287.71batches/s, l2_loss: 0.1153 - round_loss\u001b[A\n",
      "Training:   8%| | 3330/40960 [00:13<02:09, 289.64batches/s, l2_loss: 0.1153 - round_loss\u001b[A\n",
      "Training:   8%| | 3330/40960 [00:13<02:09, 289.64batches/s, l2_loss: 0.1150 - round_loss\u001b[A\n",
      "Training:   8%| | 3393/40960 [00:14<02:06, 296.50batches/s, l2_loss: 0.1150 - round_loss\u001b[A\n",
      "Training:   8%| | 3393/40960 [00:14<02:06, 296.50batches/s, l2_loss: 0.1150 - round_loss\u001b[A\n",
      "Training:   8%| | 3456/40960 [00:14<02:04, 300.57batches/s, l2_loss: 0.1150 - round_loss\u001b[A\n",
      "Training:   8%| | 3456/40960 [00:14<02:04, 300.57batches/s, l2_loss: 0.1147 - round_loss\u001b[A\n",
      "Training:   9%| | 3518/40960 [00:14<02:03, 303.33batches/s, l2_loss: 0.1147 - round_loss\u001b[A\n",
      "Training:   9%| | 3518/40960 [00:14<02:03, 303.33batches/s, l2_loss: 0.1148 - round_loss\u001b[A\n",
      "Training:   9%| | 3577/40960 [00:14<02:04, 299.56batches/s, l2_loss: 0.1148 - round_loss\u001b[A\n",
      "Training:   9%| | 3577/40960 [00:14<02:04, 299.56batches/s, l2_loss: 0.1144 - round_loss\u001b[A\n",
      "Training:   9%| | 3638/40960 [00:14<02:04, 299.99batches/s, l2_loss: 0.1144 - round_loss\u001b[A\n",
      "Training:   9%| | 3638/40960 [00:14<02:04, 299.99batches/s, l2_loss: 0.1142 - round_loss\u001b[A\n",
      "Training:   9%| | 3696/40960 [00:15<02:06, 295.08batches/s, l2_loss: 0.1142 - round_loss\u001b[A\n",
      "Training:   9%| | 3696/40960 [00:15<02:06, 295.08batches/s, l2_loss: 0.1139 - round_loss\u001b[A\n",
      "Training:   9%| | 3757/40960 [00:15<02:05, 297.26batches/s, l2_loss: 0.1139 - round_loss\u001b[A\n",
      "Training:   9%| | 3757/40960 [00:15<02:05, 297.26batches/s, l2_loss: 0.1143 - round_loss\u001b[A\n",
      "Training:   9%| | 3816/40960 [00:15<02:05, 296.16batches/s, l2_loss: 0.1143 - round_loss\u001b[A\n",
      "Training:   9%| | 3816/40960 [00:15<02:05, 296.16batches/s, l2_loss: 0.1139 - round_loss\u001b[A\n",
      "Training:   9%| | 3871/40960 [00:15<02:08, 288.41batches/s, l2_loss: 0.1139 - round_loss\u001b[A\n",
      "Training:   9%| | 3871/40960 [00:15<02:08, 288.41batches/s, l2_loss: 0.1135 - round_loss\u001b[A\n",
      "Training:  10%| | 3925/40960 [00:15<02:11, 282.01batches/s, l2_loss: 0.1135 - round_loss\u001b[A\n",
      "Training:  10%| | 3925/40960 [00:15<02:11, 282.01batches/s, l2_loss: 0.1135 - round_loss\u001b[A\n",
      "Training:  10%| | 3986/40960 [00:16<02:08, 288.56batches/s, l2_loss: 0.1135 - round_loss\u001b[A\n",
      "Training:  10%| | 3986/40960 [00:16<02:08, 288.56batches/s, l2_loss: 0.1134 - round_loss\u001b[A\n",
      "Training:  10%| | 4042/40960 [00:16<02:09, 284.69batches/s, l2_loss: 0.1134 - round_loss\u001b[A\n",
      "Training:  10%| | 4042/40960 [00:16<02:09, 284.69batches/s, l2_loss: 0.1133 - round_loss\u001b[A\n",
      "Training:  10%| | 4096/40960 [00:16<02:11, 280.30batches/s, l2_loss: 0.1133 - round_loss\u001b[A\n",
      "Training:  10%| | 4096/40960 [00:16<02:11, 280.30batches/s, l2_loss: 0.1132 - round_loss\u001b[A\n",
      "Training:  10%| | 4157/40960 [00:16<02:08, 286.67batches/s, l2_loss: 0.1132 - round_loss\u001b[A\n",
      "Training:  10%| | 4157/40960 [00:16<02:08, 286.67batches/s, l2_loss: 0.1132 - round_loss\u001b[A\n",
      "Training:  10%| | 4213/40960 [00:16<02:09, 283.89batches/s, l2_loss: 0.1132 - round_loss\u001b[A\n",
      "Training:  10%| | 4213/40960 [00:16<02:09, 283.89batches/s, l2_loss: 0.1130 - round_loss\u001b[A\n",
      "Training:  10%| | 4274/40960 [00:17<02:06, 290.02batches/s, l2_loss: 0.1130 - round_loss\u001b[A\n",
      "Training:  10%| | 4274/40960 [00:17<02:06, 290.02batches/s, l2_loss: 0.1129 - round_loss\u001b[A\n",
      "Training:  11%| | 4331/40960 [00:17<02:07, 287.75batches/s, l2_loss: 0.1129 - round_loss\u001b[A\n",
      "Training:  11%| | 4331/40960 [00:17<02:07, 287.75batches/s, l2_loss: 0.1127 - round_loss\u001b[A\n",
      "Training:  11%| | 4391/40960 [00:17<02:05, 290.81batches/s, l2_loss: 0.1127 - round_loss\u001b[A\n",
      "Training:  11%| | 4391/40960 [00:17<02:05, 290.81batches/s, l2_loss: 0.1125 - round_loss\u001b[A\n",
      "Training:  11%| | 4444/40960 [00:17<02:09, 281.78batches/s, l2_loss: 0.1125 - round_loss\u001b[A\n",
      "Training:  11%| | 4444/40960 [00:17<02:09, 281.78batches/s, l2_loss: 0.1126 - round_loss\u001b[A\n",
      "Training:  11%| | 4496/40960 [00:18<02:12, 274.17batches/s, l2_loss: 0.1126 - round_loss\u001b[A\n",
      "Training:  11%| | 4496/40960 [00:18<02:12, 274.17batches/s, l2_loss: 0.1123 - round_loss\u001b[A\n",
      "Training:  11%| | 4558/40960 [00:18<02:07, 284.58batches/s, l2_loss: 0.1123 - round_loss\u001b[A\n",
      "Training:  11%| | 4558/40960 [00:18<02:07, 284.58batches/s, l2_loss: 0.1124 - round_loss\u001b[A\n",
      "Training:  11%| | 4622/40960 [00:18<02:03, 294.29batches/s, l2_loss: 0.1124 - round_loss\u001b[A\n",
      "Training:  11%| | 4622/40960 [00:18<02:03, 294.29batches/s, l2_loss: 0.1123 - round_loss\u001b[A\n",
      "Training:  11%| | 4686/40960 [00:18<02:00, 300.64batches/s, l2_loss: 0.1123 - round_loss\u001b[A\n",
      "Training:  11%| | 4686/40960 [00:18<02:00, 300.64batches/s, l2_loss: 0.1123 - round_loss\u001b[A\n",
      "Training:  12%| | 4744/40960 [00:18<02:02, 296.24batches/s, l2_loss: 0.1123 - round_loss\u001b[A\n",
      "Training:  12%| | 4744/40960 [00:18<02:02, 296.24batches/s, l2_loss: 0.1120 - round_loss\u001b[A\n",
      "Training:  12%| | 4802/40960 [00:19<02:03, 292.90batches/s, l2_loss: 0.1120 - round_loss\u001b[A\n",
      "Training:  12%| | 4802/40960 [00:19<02:03, 292.90batches/s, l2_loss: 0.1117 - round_loss\u001b[A\n",
      "Training:  12%| | 4853/40960 [00:19<02:08, 281.06batches/s, l2_loss: 0.1117 - round_loss\u001b[A\n",
      "Training:  12%| | 4853/40960 [00:19<02:08, 281.06batches/s, l2_loss: 0.1118 - round_loss\u001b[A\n",
      "Training:  12%| | 4906/40960 [00:19<02:10, 275.27batches/s, l2_loss: 0.1118 - round_loss\u001b[A\n",
      "Training:  12%| | 4906/40960 [00:19<02:10, 275.27batches/s, l2_loss: 0.1117 - round_loss\u001b[A\n",
      "Training:  12%| | 4952/40960 [00:19<02:17, 261.20batches/s, l2_loss: 0.1117 - round_loss\u001b[A\n",
      "Training:  12%| | 4952/40960 [00:19<02:17, 261.20batches/s, l2_loss: 0.1114 - round_loss\u001b[A\n",
      "Training:  12%| | 5007/40960 [00:19<02:16, 264.17batches/s, l2_loss: 0.1114 - round_loss\u001b[A\n",
      "Training:  12%| | 5007/40960 [00:19<02:16, 264.17batches/s, l2_loss: 0.1115 - round_loss\u001b[A\n",
      "Training:  12%| | 5060/40960 [00:20<02:16, 263.29batches/s, l2_loss: 0.1115 - round_loss\u001b[A\n",
      "Training:  12%| | 5060/40960 [00:20<02:16, 263.29batches/s, l2_loss: 0.1115 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5121/40960 [00:20<02:10, 274.67batches/s, l2_loss: 0.1115 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5121/40960 [00:20<02:10, 274.67batches/s, l2_loss: 0.1114 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5173/40960 [00:20<02:12, 269.40batches/s, l2_loss: 0.1114 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5173/40960 [00:20<02:12, 269.40batches/s, l2_loss: 0.1112 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5226/40960 [00:20<02:13, 267.17batches/s, l2_loss: 0.1112 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5226/40960 [00:20<02:13, 267.17batches/s, l2_loss: 0.1112 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5281/40960 [00:20<02:12, 269.02batches/s, l2_loss: 0.1112 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5281/40960 [00:20<02:12, 269.02batches/s, l2_loss: 0.1112 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5344/40960 [00:21<02:06, 282.23batches/s, l2_loss: 0.1112 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5344/40960 [00:21<02:06, 282.23batches/s, l2_loss: 0.1111 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5403/40960 [00:21<02:04, 285.57batches/s, l2_loss: 0.1111 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5403/40960 [00:21<02:04, 285.57batches/s, l2_loss: 0.1111 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5466/40960 [00:21<02:01, 293.13batches/s, l2_loss: 0.1111 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5466/40960 [00:21<02:01, 293.13batches/s, l2_loss: 0.1109 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5519/40960 [00:21<02:05, 283.10batches/s, l2_loss: 0.1109 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5519/40960 [00:21<02:05, 283.10batches/s, l2_loss: 0.1111 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5571/40960 [00:21<02:08, 275.63batches/s, l2_loss: 0.1111 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5571/40960 [00:21<02:08, 275.63batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5628/40960 [00:22<02:07, 276.38batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5628/40960 [00:22<02:07, 276.38batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|▏| 5688/40960 [00:22<02:05, 282.15batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5688/40960 [00:22<02:05, 282.15batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5748/40960 [00:22<02:02, 287.44batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5748/40960 [00:22<02:02, 287.44batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5811/40960 [00:22<01:59, 294.82batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5811/40960 [00:22<01:59, 294.82batches/s, l2_loss: 0.1103 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5867/40960 [00:22<02:01, 289.17batches/s, l2_loss: 0.1103 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5867/40960 [00:22<02:01, 289.17batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5929/40960 [00:23<01:59, 294.37batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5929/40960 [00:23<01:59, 294.37batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5992/40960 [00:23<01:56, 299.34batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5992/40960 [00:23<01:56, 299.34batches/s, l2_loss: 0.1103 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6052/40960 [00:23<01:56, 298.39batches/s, l2_loss: 0.1103 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6052/40960 [00:23<01:56, 298.39batches/s, l2_loss: 0.1104 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6116/40960 [00:23<01:54, 303.49batches/s, l2_loss: 0.1104 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6116/40960 [00:23<01:54, 303.49batches/s, l2_loss: 0.1101 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6171/40960 [00:23<01:58, 292.92batches/s, l2_loss: 0.1101 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6171/40960 [00:23<01:58, 292.92batches/s, l2_loss: 0.1101 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6230/40960 [00:24<01:58, 293.38batches/s, l2_loss: 0.1101 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6230/40960 [00:24<01:58, 293.38batches/s, l2_loss: 0.1100 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6286/40960 [00:24<02:00, 288.32batches/s, l2_loss: 0.1100 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6286/40960 [00:24<02:00, 288.32batches/s, l2_loss: 0.1099 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6345/40960 [00:24<01:59, 289.58batches/s, l2_loss: 0.1099 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6345/40960 [00:24<01:59, 289.58batches/s, l2_loss: 0.1100 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6408/40960 [00:24<01:56, 296.92batches/s, l2_loss: 0.1100 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6408/40960 [00:24<01:56, 296.92batches/s, l2_loss: 0.1097 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6467/40960 [00:24<01:56, 295.74batches/s, l2_loss: 0.1097 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6467/40960 [00:24<01:56, 295.74batches/s, l2_loss: 0.1098 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6529/40960 [00:25<01:54, 299.43batches/s, l2_loss: 0.1098 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6529/40960 [00:25<01:54, 299.43batches/s, l2_loss: 0.1096 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6588/40960 [00:25<01:55, 298.07batches/s, l2_loss: 0.1096 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6588/40960 [00:25<01:55, 298.07batches/s, l2_loss: 0.1095 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6651/40960 [00:25<01:53, 303.06batches/s, l2_loss: 0.1095 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6651/40960 [00:25<01:53, 303.06batches/s, l2_loss: 0.1095 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6712/40960 [00:25<01:53, 302.82batches/s, l2_loss: 0.1095 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6712/40960 [00:25<01:53, 302.82batches/s, l2_loss: 0.1094 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6773/40960 [00:25<01:52, 303.45batches/s, l2_loss: 0.1094 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6773/40960 [00:25<01:52, 303.45batches/s, l2_loss: 0.1094 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6830/40960 [00:26<01:54, 297.55batches/s, l2_loss: 0.1094 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6830/40960 [00:26<01:54, 297.55batches/s, l2_loss: 0.1091 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6888/40960 [00:26<01:55, 294.63batches/s, l2_loss: 0.1091 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6888/40960 [00:26<01:55, 294.63batches/s, l2_loss: 0.1093 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6946/40960 [00:26<01:56, 291.81batches/s, l2_loss: 0.1093 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6946/40960 [00:26<01:56, 291.81batches/s, l2_loss: 0.1091 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6999/40960 [00:26<01:59, 283.13batches/s, l2_loss: 0.1091 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6999/40960 [00:26<01:59, 283.13batches/s, l2_loss: 0.1090 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7061/40960 [00:26<01:56, 290.36batches/s, l2_loss: 0.1090 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7061/40960 [00:26<01:56, 290.36batches/s, l2_loss: 0.1091 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7122/40960 [00:27<01:54, 294.58batches/s, l2_loss: 0.1091 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7122/40960 [00:27<01:54, 294.58batches/s, l2_loss: 0.1090 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7183/40960 [00:27<01:54, 296.14batches/s, l2_loss: 0.1090 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7183/40960 [00:27<01:54, 296.14batches/s, l2_loss: 0.1089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7246/40960 [00:27<01:52, 300.93batches/s, l2_loss: 0.1089 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7246/40960 [00:27<01:52, 300.93batches/s, l2_loss: 0.1090 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7301/40960 [00:27<01:55, 291.91batches/s, l2_loss: 0.1090 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7301/40960 [00:27<01:55, 291.91batches/s, l2_loss: 0.1088 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7361/40960 [00:27<01:54, 293.23batches/s, l2_loss: 0.1088 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7361/40960 [00:27<01:54, 293.23batches/s, l2_loss: 0.1088 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7422/40960 [00:28<01:53, 296.68batches/s, l2_loss: 0.1088 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7422/40960 [00:28<01:53, 296.68batches/s, l2_loss: 0.1087 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7486/40960 [00:28<01:50, 302.00batches/s, l2_loss: 0.1087 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7486/40960 [00:28<01:50, 302.00batches/s, l2_loss: 0.1087 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7548/40960 [00:28<01:49, 303.91batches/s, l2_loss: 0.1087 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7548/40960 [00:28<01:49, 303.91batches/s, l2_loss: 0.1086 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7609/40960 [00:28<01:49, 304.10batches/s, l2_loss: 0.1086 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7609/40960 [00:28<01:49, 304.10batches/s, l2_loss: 0.1086 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7670/40960 [00:28<01:49, 304.14batches/s, l2_loss: 0.1086 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7670/40960 [00:28<01:49, 304.14batches/s, l2_loss: 0.1085 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7724/40960 [00:29<01:53, 293.24batches/s, l2_loss: 0.1085 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7724/40960 [00:29<01:53, 293.24batches/s, l2_loss: 0.1086 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7786/40960 [00:29<01:51, 296.94batches/s, l2_loss: 0.1086 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7786/40960 [00:29<01:51, 296.94batches/s, l2_loss: 0.1085 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7851/40960 [00:29<01:48, 304.45batches/s, l2_loss: 0.1085 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7851/40960 [00:29<01:48, 304.45batches/s, l2_loss: 0.1085 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7914/40960 [00:29<01:47, 306.63batches/s, l2_loss: 0.1085 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7914/40960 [00:29<01:47, 306.63batches/s, l2_loss: 0.1084 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7973/40960 [00:29<01:48, 302.88batches/s, l2_loss: 0.1084 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7973/40960 [00:29<01:48, 302.88batches/s, l2_loss: 0.1083 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8032/40960 [00:30<01:49, 299.66batches/s, l2_loss: 0.1083 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8032/40960 [00:30<01:49, 299.66batches/s, l2_loss: 0.1082 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8086/40960 [00:30<01:53, 289.81batches/s, l2_loss: 0.1082 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8086/40960 [00:30<01:53, 289.81batches/s, l2_loss: 0.1081 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8140/40960 [00:30<01:56, 282.31batches/s, l2_loss: 0.1081 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8140/40960 [00:30<01:56, 282.31batches/s, l2_loss: 0.1082 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8192/40960 [00:30<01:59, 273.51batches/s, l2_loss: 0.1082 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8192/40960 [00:30<01:59, 273.51batches/s, l2_loss: 0.1081 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8238/40960 [00:30<02:06, 259.46batches/s, l2_loss: 0.1081 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8238/40960 [00:30<02:06, 259.46batches/s, l2_loss: 0.1043 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8295/40960 [00:31<02:02, 266.37batches/s, l2_loss: 0.1043 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 8295/40960 [00:31<02:02, 266.37batches/s, l2_loss: 0.1090 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8355/40960 [00:31<01:58, 275.29batches/s, l2_loss: 0.1090 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8355/40960 [00:31<01:58, 275.29batches/s, l2_loss: 0.1035 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8413/40960 [00:31<01:56, 279.09batches/s, l2_loss: 0.1035 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8413/40960 [00:31<01:56, 279.09batches/s, l2_loss: 0.1009 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8471/40960 [00:31<01:55, 281.61batches/s, l2_loss: 0.1009 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8471/40960 [00:31<01:55, 281.61batches/s, l2_loss: 0.1027 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8521/40960 [00:31<01:59, 272.01batches/s, l2_loss: 0.1027 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8521/40960 [00:31<01:59, 272.01batches/s, l2_loss: 0.1012 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8566/40960 [00:32<02:05, 257.70batches/s, l2_loss: 0.1012 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8566/40960 [00:32<02:05, 257.70batches/s, l2_loss: 0.1044 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8624/40960 [00:32<02:01, 267.19batches/s, l2_loss: 0.1044 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8624/40960 [00:32<02:01, 267.19batches/s, l2_loss: 0.1025 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8673/40960 [00:32<02:04, 258.96batches/s, l2_loss: 0.1025 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8673/40960 [00:32<02:04, 258.96batches/s, l2_loss: 0.1006 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8714/40960 [00:32<02:13, 241.77batches/s, l2_loss: 0.1006 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8714/40960 [00:32<02:13, 241.77batches/s, l2_loss: 0.1036 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8765/40960 [00:32<02:11, 244.84batches/s, l2_loss: 0.1036 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8765/40960 [00:32<02:11, 244.84batches/s, l2_loss: 0.1024 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8810/40960 [00:33<02:14, 238.45batches/s, l2_loss: 0.1024 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8810/40960 [00:33<02:14, 238.45batches/s, l2_loss: 0.1021 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8860/40960 [00:33<02:13, 241.15batches/s, l2_loss: 0.1021 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8860/40960 [00:33<02:13, 241.15batches/s, l2_loss: 0.1037 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8916/40960 [00:33<02:07, 252.07batches/s, l2_loss: 0.1037 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8916/40960 [00:33<02:07, 252.07batches/s, l2_loss: 0.1036 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8963/40960 [00:33<02:09, 246.17batches/s, l2_loss: 0.1036 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8963/40960 [00:33<02:09, 246.17batches/s, l2_loss: 0.1040 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9001/40960 [00:33<02:20, 227.90batches/s, l2_loss: 0.1040 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9001/40960 [00:33<02:20, 227.90batches/s, l2_loss: 0.1045 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9050/40960 [00:34<02:17, 232.19batches/s, l2_loss: 0.1045 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9050/40960 [00:34<02:17, 232.19batches/s, l2_loss: 0.1045 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9105/40960 [00:34<02:10, 243.93batches/s, l2_loss: 0.1045 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9105/40960 [00:34<02:10, 243.93batches/s, l2_loss: 0.1038 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9163/40960 [00:34<02:03, 256.58batches/s, l2_loss: 0.1038 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9163/40960 [00:34<02:03, 256.58batches/s, l2_loss: 0.1037 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9219/40960 [00:34<02:00, 263.25batches/s, l2_loss: 0.1037 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9219/40960 [00:34<02:00, 263.25batches/s, l2_loss: 0.1040 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9276/40960 [00:34<01:58, 268.43batches/s, l2_loss: 0.1040 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9276/40960 [00:34<01:58, 268.43batches/s, l2_loss: 0.1041 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9334/40960 [00:35<01:55, 274.83batches/s, l2_loss: 0.1041 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9334/40960 [00:35<01:55, 274.83batches/s, l2_loss: 0.1043 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9393/40960 [00:35<01:52, 279.98batches/s, l2_loss: 0.1043 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9393/40960 [00:35<01:52, 279.98batches/s, l2_loss: 0.1041 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9452/40960 [00:35<01:50, 284.19batches/s, l2_loss: 0.1041 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9452/40960 [00:35<01:50, 284.19batches/s, l2_loss: 0.1045 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9508/40960 [00:35<01:51, 282.07batches/s, l2_loss: 0.1045 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9508/40960 [00:35<01:51, 282.07batches/s, l2_loss: 0.1046 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9566/40960 [00:35<01:50, 283.18batches/s, l2_loss: 0.1046 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9566/40960 [00:35<01:50, 283.18batches/s, l2_loss: 0.1047 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9624/40960 [00:36<01:50, 284.76batches/s, l2_loss: 0.1047 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9624/40960 [00:36<01:50, 284.76batches/s, l2_loss: 0.1043 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9682/40960 [00:36<01:49, 285.71batches/s, l2_loss: 0.1043 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9682/40960 [00:36<01:49, 285.71batches/s, l2_loss: 0.1036 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9743/40960 [00:36<01:47, 290.27batches/s, l2_loss: 0.1036 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9743/40960 [00:36<01:47, 290.27batches/s, l2_loss: 0.1039 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9802/40960 [00:36<01:47, 290.75batches/s, l2_loss: 0.1039 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9802/40960 [00:36<01:47, 290.75batches/s, l2_loss: 0.1040 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9860/40960 [00:36<01:47, 290.19batches/s, l2_loss: 0.1040 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9860/40960 [00:36<01:47, 290.19batches/s, l2_loss: 0.1040 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9921/40960 [00:37<01:45, 294.14batches/s, l2_loss: 0.1040 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9921/40960 [00:37<01:45, 294.14batches/s, l2_loss: 0.1030 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9980/40960 [00:37<01:45, 292.80batches/s, l2_loss: 0.1030 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9980/40960 [00:37<01:45, 292.80batches/s, l2_loss: 0.1041 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10031/40960 [00:37<01:50, 280.95batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  24%|▏| 10031/40960 [00:37<01:50, 280.95batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  25%|▏| 10087/40960 [00:37<01:50, 279.79batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  25%|▏| 10087/40960 [00:37<01:50, 279.79batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  25%|▏| 10147/40960 [00:37<01:48, 285.26batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  25%|▏| 10147/40960 [00:38<01:48, 285.26batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  25%|▏| 10207/40960 [00:38<01:46, 288.65batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  25%|▏| 10207/40960 [00:38<01:46, 288.65batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  25%|▎| 10265/40960 [00:38<01:46, 288.33batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  25%|▎| 10265/40960 [00:38<01:46, 288.33batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  25%|▎| 10323/40960 [00:38<01:46, 288.06batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  25%|▎| 10323/40960 [00:38<01:46, 288.06batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  25%|▎| 10379/40960 [00:38<01:47, 284.78batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  25%|▎| 10379/40960 [00:38<01:47, 284.78batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  25%|▎| 10436/40960 [00:39<01:47, 284.77batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  25%|▎| 10436/40960 [00:39<01:47, 284.77batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  26%|▎| 10486/40960 [00:39<01:51, 273.62batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  26%|▎| 10486/40960 [00:39<01:51, 273.62batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  26%|▎| 10542/40960 [00:39<01:50, 274.25batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  26%|▎| 10542/40960 [00:39<01:50, 274.25batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  26%|▎| 10598/40960 [00:39<01:50, 275.30batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  26%|▎| 10598/40960 [00:39<01:50, 275.30batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  26%|▎| 10649/40960 [00:39<01:52, 268.98batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  26%|▎| 10649/40960 [00:39<01:52, 268.98batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  26%|▎| 10704/40960 [00:40<01:52, 269.45batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  26%|▎| 10704/40960 [00:40<01:52, 269.45batches/s, l2_loss: 0.1036 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10759/40960 [00:40<01:51, 271.05batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  26%|▎| 10759/40960 [00:40<01:51, 271.05batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  26%|▎| 10818/40960 [00:40<01:48, 277.83batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  26%|▎| 10818/40960 [00:40<01:48, 277.83batches/s, l2_loss: 0.1033 - round_los\u001b[A\n",
      "Training:  27%|▎| 10878/40960 [00:40<01:45, 284.25batches/s, l2_loss: 0.1033 - round_los\u001b[A\n",
      "Training:  27%|▎| 10878/40960 [00:40<01:45, 284.25batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  27%|▎| 10935/40960 [00:40<01:46, 283.23batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  27%|▎| 10935/40960 [00:40<01:46, 283.23batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  27%|▎| 10989/40960 [00:41<01:47, 278.31batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  27%|▎| 10989/40960 [00:41<01:47, 278.31batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  27%|▎| 11045/40960 [00:41<01:47, 278.73batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  27%|▎| 11045/40960 [00:41<01:47, 278.73batches/s, l2_loss: 0.1035 - round_los\u001b[A\n",
      "Training:  27%|▎| 11096/40960 [00:41<01:50, 270.60batches/s, l2_loss: 0.1035 - round_los\u001b[A\n",
      "Training:  27%|▎| 11096/40960 [00:41<01:50, 270.60batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  27%|▎| 11147/40960 [00:41<01:52, 264.61batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  27%|▎| 11147/40960 [00:41<01:52, 264.61batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  27%|▎| 11199/40960 [00:41<01:53, 261.94batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  27%|▎| 11199/40960 [00:41<01:53, 261.94batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  27%|▎| 11247/40960 [00:42<01:56, 255.34batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  27%|▎| 11247/40960 [00:42<01:56, 255.34batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  28%|▎| 11293/40960 [00:42<02:00, 246.76batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  28%|▎| 11293/40960 [00:42<02:00, 246.76batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  28%|▎| 11347/40960 [00:42<01:57, 253.01batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  28%|▎| 11347/40960 [00:42<01:57, 253.01batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  28%|▎| 11399/40960 [00:42<01:56, 252.89batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  28%|▎| 11399/40960 [00:42<01:56, 252.89batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  28%|▎| 11454/40960 [00:42<01:54, 258.04batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  28%|▎| 11454/40960 [00:42<01:54, 258.04batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  28%|▎| 11512/40960 [00:43<01:50, 267.25batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  28%|▎| 11512/40960 [00:43<01:50, 267.25batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  28%|▎| 11571/40960 [00:43<01:46, 274.85batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  28%|▎| 11571/40960 [00:43<01:46, 274.85batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  28%|▎| 11631/40960 [00:43<01:44, 281.09batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  28%|▎| 11631/40960 [00:43<01:44, 281.09batches/s, l2_loss: 0.1034 - round_los\u001b[A\n",
      "Training:  29%|▎| 11690/40960 [00:43<01:43, 283.93batches/s, l2_loss: 0.1034 - round_los\u001b[A\n",
      "Training:  29%|▎| 11690/40960 [00:43<01:43, 283.93batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  29%|▎| 11749/40960 [00:43<01:42, 286.38batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  29%|▎| 11749/40960 [00:43<01:42, 286.38batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  29%|▎| 11806/40960 [00:44<01:41, 285.83batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  29%|▎| 11806/40960 [00:44<01:41, 285.83batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  29%|▎| 11863/40960 [00:44<01:42, 284.26batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  29%|▎| 11863/40960 [00:44<01:42, 284.26batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  29%|▎| 11922/40960 [00:44<01:41, 287.35batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  29%|▎| 11922/40960 [00:44<01:41, 287.35batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  29%|▎| 11980/40960 [00:44<01:40, 287.02batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  29%|▎| 11980/40960 [00:44<01:40, 287.02batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  29%|▎| 12039/40960 [00:44<01:40, 287.99batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  29%|▎| 12039/40960 [00:44<01:40, 287.99batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  30%|▎| 12093/40960 [00:45<01:42, 282.32batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  30%|▎| 12093/40960 [00:45<01:42, 282.32batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  30%|▎| 12150/40960 [00:45<01:42, 282.36batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  30%|▎| 12150/40960 [00:45<01:42, 282.36batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  30%|▎| 12210/40960 [00:45<01:40, 286.41batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  30%|▎| 12210/40960 [00:45<01:40, 286.41batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  30%|▎| 12267/40960 [00:45<01:40, 284.38batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  30%|▎| 12267/40960 [00:45<01:40, 284.38batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  30%|▎| 12320/40960 [00:45<01:43, 277.60batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  30%|▎| 12320/40960 [00:45<01:43, 277.60batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  30%|▎| 12370/40960 [00:46<01:46, 267.76batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  30%|▎| 12370/40960 [00:46<01:46, 267.76batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  30%|▎| 12428/40960 [00:46<01:44, 273.20batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  30%|▎| 12428/40960 [00:46<01:44, 273.20batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  30%|▎| 12484/40960 [00:46<01:43, 274.61batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  30%|▎| 12484/40960 [00:46<01:43, 274.61batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  31%|▎| 12540/40960 [00:46<01:43, 275.24batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  31%|▎| 12540/40960 [00:46<01:43, 275.24batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  31%|▎| 12600/40960 [00:46<01:40, 281.94batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  31%|▎| 12600/40960 [00:46<01:40, 281.94batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  31%|▎| 12662/40960 [00:47<01:37, 288.92batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  31%|▎| 12662/40960 [00:47<01:37, 288.92batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  31%|▎| 12720/40960 [00:47<01:38, 287.89batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  31%|▎| 12720/40960 [00:47<01:38, 287.89batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  31%|▎| 12777/40960 [00:47<01:38, 287.00batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  31%|▎| 12777/40960 [00:47<01:38, 287.00batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  31%|▎| 12837/40960 [00:47<01:36, 290.17batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  31%|▎| 12837/40960 [00:47<01:36, 290.17batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  31%|▎| 12893/40960 [00:47<01:37, 286.85batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  31%|▎| 12893/40960 [00:47<01:37, 286.85batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  32%|▎| 12947/40960 [00:48<01:39, 281.31batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  32%|▎| 12947/40960 [00:48<01:39, 281.31batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  32%|▎| 13002/40960 [00:48<01:40, 279.37batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  32%|▎| 13002/40960 [00:48<01:40, 279.37batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  32%|▎| 13057/40960 [00:48<01:40, 277.57batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  32%|▎| 13057/40960 [00:48<01:40, 277.57batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  32%|▎| 13104/40960 [00:48<01:45, 263.30batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  32%|▎| 13104/40960 [00:48<01:45, 263.30batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  32%|▎| 13153/40960 [00:48<01:48, 256.42batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  32%|▎| 13153/40960 [00:48<01:48, 256.42batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  32%|▎| 13207/40960 [00:49<01:46, 259.63batches/s, l2_loss: 0.1038 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 13207/40960 [00:49<01:46, 259.63batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  32%|▎| 13259/40960 [00:49<01:47, 258.08batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  32%|▎| 13259/40960 [00:49<01:47, 258.08batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  32%|▎| 13302/40960 [00:49<01:53, 244.10batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  32%|▎| 13302/40960 [00:49<01:53, 244.10batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  33%|▎| 13350/40960 [00:49<01:53, 242.61batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  33%|▎| 13350/40960 [00:49<01:53, 242.61batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  33%|▎| 13408/40960 [00:49<01:47, 255.96batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  33%|▎| 13408/40960 [00:49<01:47, 255.96batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  33%|▎| 13460/40960 [00:50<01:47, 256.98batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  33%|▎| 13460/40960 [00:50<01:47, 256.98batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  33%|▎| 13513/40960 [00:50<01:46, 258.47batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  33%|▎| 13513/40960 [00:50<01:46, 258.47batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  33%|▎| 13567/40960 [00:50<01:44, 261.61batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  33%|▎| 13567/40960 [00:50<01:44, 261.61batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  33%|▎| 13622/40960 [00:50<01:43, 265.00batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  33%|▎| 13622/40960 [00:50<01:43, 265.00batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  33%|▎| 13679/40960 [00:50<01:40, 270.35batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  33%|▎| 13679/40960 [00:50<01:40, 270.35batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  34%|▎| 13733/40960 [00:51<01:41, 268.70batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  34%|▎| 13733/40960 [00:51<01:41, 268.70batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  34%|▎| 13790/40960 [00:51<01:39, 272.25batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  34%|▎| 13790/40960 [00:51<01:39, 272.25batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  34%|▎| 13850/40960 [00:51<01:36, 279.58batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  34%|▎| 13850/40960 [00:51<01:36, 279.58batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  34%|▎| 13902/40960 [00:51<01:38, 273.69batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  34%|▎| 13902/40960 [00:51<01:38, 273.69batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  34%|▎| 13955/40960 [00:51<01:39, 270.33batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  34%|▎| 13955/40960 [00:51<01:39, 270.33batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  34%|▎| 14009/40960 [00:52<01:40, 268.79batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  34%|▎| 14009/40960 [00:52<01:40, 268.79batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  34%|▎| 14058/40960 [00:52<01:42, 261.34batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  34%|▎| 14058/40960 [00:52<01:42, 261.34batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  34%|▎| 14109/40960 [00:52<01:43, 259.16batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  34%|▎| 14109/40960 [00:52<01:43, 259.16batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  35%|▎| 14163/40960 [00:52<01:42, 262.33batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  35%|▎| 14163/40960 [00:52<01:42, 262.33batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  35%|▎| 14218/40960 [00:52<01:40, 265.83batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  35%|▎| 14218/40960 [00:52<01:40, 265.83batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  35%|▎| 14273/40960 [00:53<01:39, 268.36batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  35%|▎| 14273/40960 [00:53<01:39, 268.36batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  35%|▎| 14332/40960 [00:53<01:36, 275.81batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  35%|▎| 14332/40960 [00:53<01:36, 275.81batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  35%|▎| 14382/40960 [00:53<01:39, 267.94batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  35%|▎| 14382/40960 [00:53<01:39, 267.94batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  35%|▎| 14439/40960 [00:53<01:37, 272.95batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  35%|▎| 14439/40960 [00:53<01:37, 272.95batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  35%|▎| 14497/40960 [00:53<01:35, 277.72batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  35%|▎| 14497/40960 [00:53<01:35, 277.72batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14554/40960 [00:54<01:34, 279.61batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14554/40960 [00:54<01:34, 279.61batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14615/40960 [00:54<01:32, 286.25batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14615/40960 [00:54<01:32, 286.25batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  36%|▎| 14669/40960 [00:54<01:33, 280.95batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  36%|▎| 14669/40960 [00:54<01:33, 280.95batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14723/40960 [00:54<01:34, 277.65batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14723/40960 [00:54<01:34, 277.65batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14781/40960 [00:54<01:33, 280.12batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14781/40960 [00:54<01:33, 280.12batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  36%|▎| 14839/40960 [00:55<01:32, 281.79batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  36%|▎| 14839/40960 [00:55<01:32, 281.79batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:55<01:32, 280.66batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:55<01:32, 280.66batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14949/40960 [00:55<01:33, 277.37batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  36%|▎| 14949/40960 [00:55<01:33, 277.37batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  37%|▎| 15007/40960 [00:55<01:32, 280.63batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  37%|▎| 15007/40960 [00:55<01:32, 280.63batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  37%|▎| 15066/40960 [00:55<01:31, 284.03batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  37%|▎| 15066/40960 [00:55<01:31, 284.03batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  37%|▎| 15125/40960 [00:56<01:30, 286.72batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  37%|▎| 15125/40960 [00:56<01:30, 286.72batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  37%|▎| 15176/40960 [00:56<01:33, 276.09batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  37%|▎| 15176/40960 [00:56<01:33, 276.09batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  37%|▎| 15235/40960 [00:56<01:31, 280.18batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  37%|▎| 15235/40960 [00:56<01:31, 280.18batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  37%|▎| 15290/40960 [00:56<01:32, 278.13batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  37%|▎| 15290/40960 [00:56<01:32, 278.13batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  37%|▎| 15348/40960 [00:56<01:31, 280.98batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  37%|▎| 15348/40960 [00:56<01:31, 280.98batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  38%|▍| 15405/40960 [00:57<01:30, 281.49batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  38%|▍| 15405/40960 [00:57<01:30, 281.49batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  38%|▍| 15457/40960 [00:57<01:32, 274.27batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  38%|▍| 15457/40960 [00:57<01:32, 274.27batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  38%|▍| 15514/40960 [00:57<01:31, 277.14batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  38%|▍| 15514/40960 [00:57<01:31, 277.14batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  38%|▍| 15566/40960 [00:57<01:34, 269.49batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  38%|▍| 15566/40960 [00:57<01:34, 269.49batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  38%|▍| 15616/40960 [00:57<01:36, 263.41batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  38%|▍| 15616/40960 [00:57<01:36, 263.41batches/s, l2_loss: 0.1039 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|▍| 15667/40960 [00:58<01:37, 260.15batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  38%|▍| 15667/40960 [00:58<01:37, 260.15batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  38%|▍| 15717/40960 [00:58<01:38, 256.83batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  38%|▍| 15717/40960 [00:58<01:38, 256.83batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  39%|▍| 15770/40960 [00:58<01:37, 259.07batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  39%|▍| 15770/40960 [00:58<01:37, 259.07batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  39%|▍| 15821/40960 [00:58<01:37, 256.86batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  39%|▍| 15821/40960 [00:58<01:37, 256.86batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  39%|▍| 15879/40960 [00:58<01:34, 265.71batches/s, l2_loss: 0.1036 - round_los\u001b[A\n",
      "Training:  39%|▍| 15879/40960 [00:59<01:34, 265.71batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  39%|▍| 15921/40960 [00:59<01:40, 248.75batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  39%|▍| 15921/40960 [00:59<01:40, 248.75batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  39%|▍| 15978/40960 [00:59<01:36, 258.78batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  39%|▍| 15978/40960 [00:59<01:36, 258.78batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  39%|▍| 16033/40960 [00:59<01:34, 262.41batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  39%|▍| 16033/40960 [00:59<01:34, 262.41batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  39%|▍| 16084/40960 [00:59<01:36, 258.71batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  39%|▍| 16084/40960 [00:59<01:36, 258.71batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  39%|▍| 16140/40960 [01:00<01:34, 264.02batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  39%|▍| 16140/40960 [01:00<01:34, 264.02batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  40%|▍| 16200/40960 [01:00<01:30, 274.23batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  40%|▍| 16200/40960 [01:00<01:30, 274.23batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  40%|▍| 16255/40960 [01:00<01:30, 273.91batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  40%|▍| 16255/40960 [01:00<01:30, 273.91batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  40%|▍| 16303/40960 [01:00<01:33, 263.69batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  40%|▍| 16303/40960 [01:00<01:33, 263.69batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  40%|▍| 16355/40960 [01:00<01:33, 262.43batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  40%|▍| 16355/40960 [01:00<01:33, 262.43batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  40%|▍| 16413/40960 [01:01<01:30, 269.97batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  40%|▍| 16413/40960 [01:01<01:30, 269.97batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  40%|▍| 16472/40960 [01:01<01:28, 276.41batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  40%|▍| 16472/40960 [01:01<01:28, 276.41batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  40%|▍| 16530/40960 [01:01<01:27, 279.73batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  40%|▍| 16530/40960 [01:01<01:27, 279.73batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  40%|▍| 16584/40960 [01:01<01:28, 276.40batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  40%|▍| 16584/40960 [01:01<01:28, 276.40batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  41%|▍| 16643/40960 [01:01<01:26, 281.21batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  41%|▍| 16643/40960 [01:01<01:26, 281.21batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  41%|▍| 16697/40960 [01:02<01:27, 277.42batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  41%|▍| 16697/40960 [01:02<01:27, 277.42batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  41%|▍| 16752/40960 [01:02<01:27, 275.90batches/s, l2_loss: 0.1037 - round_los\u001b[A\n",
      "Training:  41%|▍| 16752/40960 [01:02<01:27, 275.90batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  41%|▍| 16802/40960 [01:02<01:30, 267.08batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  41%|▍| 16802/40960 [01:02<01:30, 267.08batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  41%|▍| 16857/40960 [01:02<01:29, 268.51batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  41%|▍| 16857/40960 [01:02<01:29, 268.51batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  41%|▍| 16906/40960 [01:02<01:32, 259.95batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  41%|▍| 16906/40960 [01:02<01:32, 259.95batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  41%|▍| 16961/40960 [01:03<01:31, 263.08batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  41%|▍| 16961/40960 [01:03<01:31, 263.08batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17018/40960 [01:03<01:28, 269.22batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17018/40960 [01:03<01:28, 269.22batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17077/40960 [01:03<01:26, 276.71batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17077/40960 [01:03<01:26, 276.71batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  42%|▍| 17136/40960 [01:03<01:24, 280.35batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  42%|▍| 17136/40960 [01:03<01:24, 280.35batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  42%|▍| 17196/40960 [01:03<01:23, 284.85batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  42%|▍| 17196/40960 [01:03<01:23, 284.85batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17252/40960 [01:04<01:24, 281.44batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17252/40960 [01:04<01:24, 281.44batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17312/40960 [01:04<01:22, 285.82batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17312/40960 [01:04<01:22, 285.82batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17367/40960 [01:04<01:23, 281.65batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  42%|▍| 17367/40960 [01:04<01:23, 281.65batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  43%|▍| 17421/40960 [01:04<01:25, 276.44batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  43%|▍| 17421/40960 [01:04<01:25, 276.44batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  43%|▍| 17474/40960 [01:04<01:26, 271.46batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  43%|▍| 17474/40960 [01:04<01:26, 271.46batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  43%|▍| 17523/40960 [01:05<01:29, 263.16batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  43%|▍| 17523/40960 [01:05<01:29, 263.16batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  43%|▍| 17580/40960 [01:05<01:27, 268.53batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  43%|▍| 17580/40960 [01:05<01:27, 268.53batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  43%|▍| 17638/40960 [01:05<01:25, 273.80batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  43%|▍| 17638/40960 [01:05<01:25, 273.80batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  43%|▍| 17689/40960 [01:05<01:26, 267.76batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  43%|▍| 17689/40960 [01:05<01:26, 267.76batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  43%|▍| 17747/40960 [01:05<01:24, 273.58batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  43%|▍| 17747/40960 [01:05<01:24, 273.58batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  43%|▍| 17801/40960 [01:06<01:25, 272.37batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  43%|▍| 17801/40960 [01:06<01:25, 272.37batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  44%|▍| 17850/40960 [01:06<01:27, 264.13batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  44%|▍| 17850/40960 [01:06<01:27, 264.13batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  44%|▍| 17896/40960 [01:06<01:31, 252.98batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  44%|▍| 17896/40960 [01:06<01:31, 252.98batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  44%|▍| 17954/40960 [01:06<01:27, 263.48batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  44%|▍| 17954/40960 [01:06<01:27, 263.48batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  44%|▍| 18011/40960 [01:06<01:25, 269.63batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  44%|▍| 18011/40960 [01:06<01:25, 269.63batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  44%|▍| 18071/40960 [01:07<01:22, 278.10batches/s, l2_loss: 0.1039 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 18071/40960 [01:07<01:22, 278.10batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  44%|▍| 18127/40960 [01:07<01:22, 277.40batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  44%|▍| 18127/40960 [01:07<01:22, 277.40batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  44%|▍| 18181/40960 [01:07<01:23, 274.29batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  44%|▍| 18181/40960 [01:07<01:23, 274.29batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  45%|▍| 18238/40960 [01:07<01:22, 276.77batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  45%|▍| 18238/40960 [01:07<01:22, 276.77batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  45%|▍| 18296/40960 [01:07<01:21, 279.69batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  45%|▍| 18296/40960 [01:07<01:21, 279.69batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  45%|▍| 18347/40960 [01:08<01:23, 272.21batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  45%|▍| 18347/40960 [01:08<01:23, 272.21batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  45%|▍| 18402/40960 [01:08<01:22, 272.72batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  45%|▍| 18402/40960 [01:08<01:22, 272.72batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  45%|▍| 18457/40960 [01:08<01:22, 272.85batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  45%|▍| 18457/40960 [01:08<01:22, 272.85batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  45%|▍| 18517/40960 [01:08<01:20, 279.98batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  45%|▍| 18517/40960 [01:08<01:20, 279.98batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  45%|▍| 18575/40960 [01:08<01:19, 282.28batches/s, l2_loss: 0.1038 - round_los\u001b[A\n",
      "Training:  45%|▍| 18575/40960 [01:08<01:19, 282.28batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  45%|▍| 18634/40960 [01:09<01:18, 285.67batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  45%|▍| 18634/40960 [01:09<01:18, 285.67batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18694/40960 [01:09<01:17, 288.22batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18694/40960 [01:09<01:17, 288.22batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18750/40960 [01:09<01:17, 284.78batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18750/40960 [01:09<01:17, 284.78batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  46%|▍| 18806/40960 [01:09<01:18, 282.03batches/s, l2_loss: 0.1039 - round_los\u001b[A\n",
      "Training:  46%|▍| 18806/40960 [01:09<01:18, 282.03batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18863/40960 [01:09<01:18, 281.75batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18863/40960 [01:09<01:18, 281.75batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18919/40960 [01:10<01:18, 281.12batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18919/40960 [01:10<01:18, 281.12batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18974/40960 [01:10<01:18, 278.54batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  46%|▍| 18974/40960 [01:10<01:18, 278.54batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  46%|▍| 19034/40960 [01:10<01:17, 283.56batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  46%|▍| 19034/40960 [01:10<01:17, 283.56batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19086/40960 [01:10<01:19, 274.74batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19086/40960 [01:10<01:19, 274.74batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19135/40960 [01:10<01:22, 265.75batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19135/40960 [01:10<01:22, 265.75batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19184/40960 [01:11<01:23, 259.46batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19184/40960 [01:11<01:23, 259.46batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  47%|▍| 19239/40960 [01:11<01:22, 263.83batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  47%|▍| 19239/40960 [01:11<01:22, 263.83batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  47%|▍| 19295/40960 [01:11<01:20, 267.83batches/s, l2_loss: 0.1040 - round_los\u001b[A\n",
      "Training:  47%|▍| 19295/40960 [01:11<01:20, 267.83batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19348/40960 [01:11<01:21, 265.45batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19348/40960 [01:11<01:21, 265.45batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19404/40960 [01:11<01:20, 269.00batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  47%|▍| 19404/40960 [01:11<01:20, 269.00batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19462/40960 [01:12<01:18, 275.01batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19462/40960 [01:12<01:18, 275.01batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19519/40960 [01:12<01:17, 277.09batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19519/40960 [01:12<01:17, 277.09batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19570/40960 [01:12<01:19, 270.05batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19570/40960 [01:12<01:19, 270.05batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  48%|▍| 19621/40960 [01:12<01:20, 265.41batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  48%|▍| 19621/40960 [01:12<01:20, 265.41batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  48%|▍| 19671/40960 [01:12<01:21, 260.19batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  48%|▍| 19671/40960 [01:12<01:21, 260.19batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  48%|▍| 19715/40960 [01:13<01:25, 247.10batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  48%|▍| 19715/40960 [01:13<01:25, 247.10batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19764/40960 [01:13<01:26, 245.55batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19764/40960 [01:13<01:26, 245.55batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19819/40960 [01:13<01:23, 253.14batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  48%|▍| 19819/40960 [01:13<01:23, 253.14batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  49%|▍| 19871/40960 [01:13<01:23, 253.72batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  49%|▍| 19871/40960 [01:13<01:23, 253.72batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  49%|▍| 19929/40960 [01:13<01:19, 263.50batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  49%|▍| 19929/40960 [01:13<01:19, 263.50batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 19987/40960 [01:14<01:17, 270.35batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 19987/40960 [01:14<01:17, 270.35batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 20045/40960 [01:14<01:15, 275.63batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 20045/40960 [01:14<01:15, 275.63batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 20099/40960 [01:14<01:16, 273.00batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 20099/40960 [01:14<01:16, 273.00batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  49%|▍| 20156/40960 [01:14<01:15, 275.23batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  49%|▍| 20156/40960 [01:14<01:15, 275.23batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 20215/40960 [01:14<01:13, 280.90batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 20215/40960 [01:14<01:13, 280.90batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 20273/40960 [01:15<01:13, 282.19batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  49%|▍| 20273/40960 [01:15<01:13, 282.19batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  50%|▍| 20317/40960 [01:15<01:18, 263.53batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  50%|▍| 20317/40960 [01:15<01:18, 263.53batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  50%|▍| 20376/40960 [01:15<01:15, 272.65batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  50%|▍| 20376/40960 [01:15<01:15, 272.65batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  50%|▍| 20427/40960 [01:15<01:16, 267.03batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  50%|▍| 20427/40960 [01:15<01:16, 267.03batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  50%|▍| 20476/40960 [01:15<01:18, 259.94batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  50%|▍| 20476/40960 [01:15<01:18, 259.94batches/s, l2_loss: 0.1042 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|▌| 20529/40960 [01:16<01:18, 261.29batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  50%|▌| 20529/40960 [01:16<01:18, 261.29batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  50%|▌| 20585/40960 [01:16<01:16, 266.53batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  50%|▌| 20585/40960 [01:16<01:16, 266.53batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  50%|▌| 20635/40960 [01:16<01:17, 261.53batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  50%|▌| 20635/40960 [01:16<01:17, 261.53batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 20687/40960 [01:16<01:17, 260.01batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 20687/40960 [01:16<01:17, 260.01batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  51%|▌| 20739/40960 [01:16<01:18, 258.82batches/s, l2_loss: 0.1041 - round_los\u001b[A\n",
      "Training:  51%|▌| 20739/40960 [01:16<01:18, 258.82batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 20793/40960 [01:17<01:17, 261.47batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 20793/40960 [01:17<01:17, 261.47batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 20850/40960 [01:17<01:15, 267.31batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 20850/40960 [01:17<01:15, 267.31batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 20907/40960 [01:17<01:13, 272.36batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 20907/40960 [01:17<01:13, 272.36batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  51%|▌| 20961/40960 [01:17<01:13, 271.33batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  51%|▌| 20961/40960 [01:17<01:13, 271.33batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 21017/40960 [01:17<01:13, 270.55batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  51%|▌| 21017/40960 [01:17<01:13, 270.55batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  51%|▌| 21067/40960 [01:18<01:16, 261.49batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  51%|▌| 21067/40960 [01:18<01:16, 261.49batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  52%|▌| 21125/40960 [01:18<01:13, 268.53batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  52%|▌| 21125/40960 [01:18<01:13, 268.53batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  52%|▌| 21179/40960 [01:18<01:13, 267.88batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  52%|▌| 21179/40960 [01:18<01:13, 267.88batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  52%|▌| 21237/40960 [01:18<01:12, 273.81batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  52%|▌| 21237/40960 [01:18<01:12, 273.81batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  52%|▌| 21293/40960 [01:19<01:11, 274.57batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  52%|▌| 21293/40960 [01:19<01:11, 274.57batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  52%|▌| 21342/40960 [01:19<01:14, 264.31batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  52%|▌| 21342/40960 [01:19<01:14, 264.31batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  52%|▌| 21385/40960 [01:19<01:18, 249.58batches/s, l2_loss: 0.1042 - round_los\u001b[A\n",
      "Training:  52%|▌| 21385/40960 [01:19<01:18, 249.58batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  52%|▌| 21436/40960 [01:19<01:17, 250.92batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  52%|▌| 21436/40960 [01:19<01:17, 250.92batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  52%|▌| 21495/40960 [01:19<01:14, 262.83batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  52%|▌| 21495/40960 [01:19<01:14, 262.83batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  53%|▌| 21551/40960 [01:20<01:12, 266.43batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  53%|▌| 21551/40960 [01:20<01:12, 266.43batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  53%|▌| 21605/40960 [01:20<01:12, 267.19batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  53%|▌| 21605/40960 [01:20<01:12, 267.19batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  53%|▌| 21663/40960 [01:20<01:10, 272.97batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  53%|▌| 21663/40960 [01:20<01:10, 272.97batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  53%|▌| 21720/40960 [01:20<01:10, 274.64batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  53%|▌| 21720/40960 [01:20<01:10, 274.64batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  53%|▌| 21776/40960 [01:20<01:09, 275.26batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  53%|▌| 21776/40960 [01:20<01:09, 275.26batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  53%|▌| 21835/40960 [01:21<01:08, 280.96batches/s, l2_loss: 0.1043 - round_los\u001b[A\n",
      "Training:  53%|▌| 21835/40960 [01:21<01:08, 280.96batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  53%|▌| 21893/40960 [01:21<01:07, 283.65batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  53%|▌| 21893/40960 [01:21<01:07, 283.65batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 21946/40960 [01:21<01:08, 277.00batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 21946/40960 [01:21<01:08, 277.00batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22004/40960 [01:21<01:07, 280.28batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22004/40960 [01:21<01:07, 280.28batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22062/40960 [01:21<01:06, 283.01batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22062/40960 [01:21<01:06, 283.01batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22119/40960 [01:22<01:07, 280.21batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22119/40960 [01:22<01:07, 280.21batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22177/40960 [01:22<01:06, 282.41batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22177/40960 [01:22<01:06, 282.41batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22236/40960 [01:22<01:05, 285.67batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22236/40960 [01:22<01:05, 285.67batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22291/40960 [01:22<01:06, 282.26batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  54%|▌| 22291/40960 [01:22<01:06, 282.26batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  55%|▌| 22344/40960 [01:22<01:07, 276.41batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  55%|▌| 22344/40960 [01:22<01:07, 276.41batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  55%|▌| 22403/40960 [01:23<01:06, 280.84batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  55%|▌| 22403/40960 [01:23<01:06, 280.84batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  55%|▌| 22461/40960 [01:23<01:05, 283.52batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  55%|▌| 22461/40960 [01:23<01:05, 283.52batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  55%|▌| 22521/40960 [01:23<01:04, 287.85batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  55%|▌| 22521/40960 [01:23<01:04, 287.85batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  55%|▌| 22581/40960 [01:23<01:03, 290.73batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  55%|▌| 22581/40960 [01:23<01:03, 290.73batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  55%|▌| 22637/40960 [01:23<01:03, 287.22batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  55%|▌| 22637/40960 [01:23<01:03, 287.22batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [01:24<01:05, 277.43batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [01:24<01:05, 277.43batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  56%|▌| 22746/40960 [01:24<01:05, 279.40batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  56%|▌| 22746/40960 [01:24<01:05, 279.40batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  56%|▌| 22801/40960 [01:24<01:05, 276.68batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  56%|▌| 22801/40960 [01:24<01:05, 276.68batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  56%|▌| 22853/40960 [01:24<01:06, 270.66batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  56%|▌| 22853/40960 [01:24<01:06, 270.66batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  56%|▌| 22904/40960 [01:24<01:08, 265.01batches/s, l2_loss: 0.1044 - round_los\u001b[A\n",
      "Training:  56%|▌| 22904/40960 [01:24<01:08, 265.01batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  56%|▌| 22961/40960 [01:25<01:06, 270.88batches/s, l2_loss: 0.1045 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|▌| 22961/40960 [01:25<01:06, 270.88batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  56%|▌| 23016/40960 [01:25<01:05, 271.92batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  56%|▌| 23016/40960 [01:25<01:05, 271.92batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  56%|▌| 23073/40960 [01:25<01:04, 275.21batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  56%|▌| 23073/40960 [01:25<01:04, 275.21batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  56%|▌| 23128/40960 [01:25<01:05, 274.32batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  56%|▌| 23128/40960 [01:25<01:05, 274.32batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  57%|▌| 23188/40960 [01:25<01:03, 281.18batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  57%|▌| 23188/40960 [01:25<01:03, 281.18batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  57%|▌| 23248/40960 [01:26<01:01, 286.21batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  57%|▌| 23248/40960 [01:26<01:01, 286.21batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  57%|▌| 23302/40960 [01:26<01:02, 280.77batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  57%|▌| 23302/40960 [01:26<01:02, 280.77batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  57%|▌| 23355/40960 [01:26<01:04, 273.66batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  57%|▌| 23355/40960 [01:26<01:04, 273.66batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  57%|▌| 23414/40960 [01:26<01:02, 279.22batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  57%|▌| 23414/40960 [01:26<01:02, 279.22batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  57%|▌| 23475/40960 [01:26<01:01, 285.34batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  57%|▌| 23475/40960 [01:26<01:01, 285.34batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  57%|▌| 23534/40960 [01:27<01:00, 287.00batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  57%|▌| 23534/40960 [01:27<01:00, 287.00batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  58%|▌| 23593/40960 [01:27<01:00, 288.86batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  58%|▌| 23593/40960 [01:27<01:00, 288.86batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  58%|▌| 23651/40960 [01:27<00:59, 288.93batches/s, l2_loss: 0.1045 - round_los\u001b[A\n",
      "Training:  58%|▌| 23651/40960 [01:27<00:59, 288.93batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  58%|▌| 23704/40960 [01:27<01:01, 281.26batches/s, l2_loss: 0.1046 - round_los\u001b[A\n",
      "Training:  58%|▌| 23704/40960 [01:27<01:01, 281.26batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  58%|▌| 23758/40960 [01:27<01:01, 277.49batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  58%|▌| 23758/40960 [01:27<01:01, 277.49batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  58%|▌| 23814/40960 [01:28<01:01, 278.04batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  58%|▌| 23814/40960 [01:28<01:01, 278.04batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  58%|▌| 23871/40960 [01:28<01:01, 278.99batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  58%|▌| 23871/40960 [01:28<01:01, 278.99batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  58%|▌| 23929/40960 [01:28<01:00, 281.28batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  58%|▌| 23929/40960 [01:28<01:00, 281.28batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 23986/40960 [01:28<01:00, 281.30batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 23986/40960 [01:28<01:00, 281.30batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24043/40960 [01:28<01:00, 280.82batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24043/40960 [01:28<01:00, 280.82batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24098/40960 [01:29<01:00, 278.79batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24098/40960 [01:29<01:00, 278.79batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24159/40960 [01:29<00:58, 285.56batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24159/40960 [01:29<00:58, 285.56batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24220/40960 [01:29<00:57, 291.31batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24220/40960 [01:29<00:57, 291.31batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24276/40960 [01:29<00:58, 287.28batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  59%|▌| 24276/40960 [01:29<00:58, 287.28batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  59%|▌| 24333/40960 [01:29<00:58, 286.28batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  59%|▌| 24333/40960 [01:29<00:58, 286.28batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24389/40960 [01:30<00:58, 283.82batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24389/40960 [01:30<00:58, 283.82batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  60%|▌| 24448/40960 [01:30<00:57, 286.07batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  60%|▌| 24448/40960 [01:30<00:57, 286.07batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24507/40960 [01:30<00:57, 288.54batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24507/40960 [01:30<00:57, 288.54batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24559/40960 [01:30<00:58, 278.20batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24559/40960 [01:30<00:58, 278.20batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24612/40960 [01:30<00:59, 274.21batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24612/40960 [01:30<00:59, 274.21batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  60%|▌| 24662/40960 [01:31<01:01, 265.25batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  60%|▌| 24662/40960 [01:31<01:01, 265.25batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  60%|▌| 24720/40960 [01:31<00:59, 271.08batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  60%|▌| 24720/40960 [01:31<00:59, 271.08batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24778/40960 [01:31<00:58, 275.44batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  60%|▌| 24778/40960 [01:31<00:58, 275.44batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 24832/40960 [01:31<00:59, 273.33batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 24832/40960 [01:31<00:59, 273.33batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 24872/40960 [01:31<01:04, 250.20batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 24872/40960 [01:31<01:04, 250.20batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  61%|▌| 24929/40960 [01:32<01:01, 259.60batches/s, l2_loss: 0.1047 - round_los\u001b[A\n",
      "Training:  61%|▌| 24929/40960 [01:32<01:01, 259.60batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 24983/40960 [01:32<01:01, 261.50batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 24983/40960 [01:32<01:01, 261.50batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 25043/40960 [01:32<00:58, 271.79batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 25043/40960 [01:32<00:58, 271.79batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  61%|▌| 25102/40960 [01:32<00:57, 277.86batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  61%|▌| 25102/40960 [01:32<00:57, 277.86batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 25162/40960 [01:32<00:55, 283.15batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  61%|▌| 25162/40960 [01:32<00:55, 283.15batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  62%|▌| 25217/40960 [01:33<00:56, 279.54batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  62%|▌| 25217/40960 [01:33<00:56, 279.54batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25275/40960 [01:33<00:55, 282.21batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25275/40960 [01:33<00:55, 282.21batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  62%|▌| 25333/40960 [01:33<00:54, 284.16batches/s, l2_loss: 0.1048 - round_los\u001b[A\n",
      "Training:  62%|▌| 25333/40960 [01:33<00:54, 284.16batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25386/40960 [01:33<00:56, 276.85batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25386/40960 [01:33<00:56, 276.85batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25445/40960 [01:33<00:55, 281.18batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25445/40960 [01:33<00:55, 281.18batches/s, l2_loss: 0.1049 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|▌| 25505/40960 [01:34<00:53, 286.75batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25505/40960 [01:34<00:53, 286.75batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25550/40960 [01:34<00:58, 265.48batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  62%|▌| 25550/40960 [01:34<00:58, 265.48batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  63%|▋| 25605/40960 [01:34<00:57, 266.71batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  63%|▋| 25605/40960 [01:34<00:57, 266.71batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  63%|▋| 25657/40960 [01:34<00:57, 264.59batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  63%|▋| 25657/40960 [01:34<00:57, 264.59batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  63%|▋| 25715/40960 [01:34<00:56, 271.85batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  63%|▋| 25715/40960 [01:34<00:56, 271.85batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  63%|▋| 25769/40960 [01:35<00:56, 270.02batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  63%|▋| 25769/40960 [01:35<00:56, 270.02batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  63%|▋| 25828/40960 [01:35<00:54, 276.86batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  63%|▋| 25828/40960 [01:35<00:54, 276.86batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  63%|▋| 25887/40960 [01:35<00:53, 280.96batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  63%|▋| 25887/40960 [01:35<00:53, 280.96batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  63%|▋| 25944/40960 [01:35<00:53, 282.13batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  63%|▋| 25944/40960 [01:35<00:53, 282.13batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  63%|▋| 25991/40960 [01:35<00:56, 266.31batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  63%|▋| 25991/40960 [01:35<00:56, 266.31batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26047/40960 [01:36<00:55, 270.34batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26047/40960 [01:36<00:55, 270.34batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  64%|▋| 26105/40960 [01:36<00:53, 275.66batches/s, l2_loss: 0.1049 - round_los\u001b[A\n",
      "Training:  64%|▋| 26105/40960 [01:36<00:53, 275.66batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26160/40960 [01:36<00:53, 274.99batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26160/40960 [01:36<00:53, 274.99batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26215/40960 [01:36<00:53, 273.62batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26215/40960 [01:36<00:53, 273.62batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26267/40960 [01:36<00:54, 269.04batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26267/40960 [01:36<00:54, 269.04batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26320/40960 [01:37<00:54, 267.45batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26320/40960 [01:37<00:54, 267.45batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26376/40960 [01:37<00:53, 270.65batches/s, l2_loss: 0.1050 - round_los\u001b[A\n",
      "Training:  64%|▋| 26376/40960 [01:37<00:53, 270.65batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26434/40960 [01:37<00:52, 275.78batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26434/40960 [01:37<00:52, 275.78batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26475/40960 [01:37<00:57, 253.43batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26475/40960 [01:37<00:57, 253.43batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26522/40960 [01:38<00:58, 247.51batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26522/40960 [01:38<00:58, 247.51batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26576/40960 [01:38<00:56, 253.83batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26576/40960 [01:38<00:56, 253.83batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26631/40960 [01:38<00:55, 259.53batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26631/40960 [01:38<00:55, 259.53batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26687/40960 [01:38<00:53, 265.22batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26687/40960 [01:38<00:53, 265.22batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26738/40960 [01:38<00:54, 261.27batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26738/40960 [01:38<00:54, 261.27batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26797/40960 [01:39<00:52, 270.06batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  65%|▋| 26797/40960 [01:39<00:52, 270.06batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  66%|▋| 26851/40960 [01:39<00:52, 268.65batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  66%|▋| 26851/40960 [01:39<00:52, 268.65batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  66%|▋| 26903/40960 [01:39<00:52, 265.91batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  66%|▋| 26903/40960 [01:39<00:52, 265.91batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  66%|▋| 26956/40960 [01:39<00:52, 264.46batches/s, l2_loss: 0.1051 - round_los\u001b[A\n",
      "Training:  66%|▋| 26956/40960 [01:39<00:52, 264.46batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  66%|▋| 27013/40960 [01:39<00:51, 270.42batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  66%|▋| 27013/40960 [01:39<00:51, 270.42batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  66%|▋| 27070/40960 [01:40<00:50, 273.96batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  66%|▋| 27070/40960 [01:40<00:50, 273.96batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  66%|▋| 27125/40960 [01:40<00:50, 273.55batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  66%|▋| 27125/40960 [01:40<00:50, 273.55batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  66%|▋| 27179/40960 [01:40<00:50, 271.50batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  66%|▋| 27179/40960 [01:40<00:50, 271.50batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  66%|▋| 27232/40960 [01:40<00:50, 269.51batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  66%|▋| 27232/40960 [01:40<00:50, 269.51batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27291/40960 [01:40<00:49, 276.57batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27291/40960 [01:40<00:49, 276.57batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27348/40960 [01:41<00:48, 278.29batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27348/40960 [01:41<00:48, 278.29batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27408/40960 [01:41<00:47, 283.84batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27408/40960 [01:41<00:47, 283.84batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27464/40960 [01:41<00:47, 281.87batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27464/40960 [01:41<00:47, 281.87batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  67%|▋| 27521/40960 [01:41<00:47, 282.16batches/s, l2_loss: 0.1052 - round_los\u001b[A\n",
      "Training:  67%|▋| 27521/40960 [01:41<00:47, 282.16batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27577/40960 [01:41<00:47, 280.84batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27577/40960 [01:41<00:47, 280.84batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27634/40960 [01:42<00:47, 281.11batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  67%|▋| 27634/40960 [01:42<00:47, 281.11batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  68%|▋| 27691/40960 [01:42<00:47, 281.35batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  68%|▋| 27691/40960 [01:42<00:47, 281.35batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  68%|▋| 27748/40960 [01:42<00:47, 281.06batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  68%|▋| 27748/40960 [01:42<00:47, 281.06batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  68%|▋| 27804/40960 [01:42<00:46, 280.50batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  68%|▋| 27804/40960 [01:42<00:46, 280.50batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  68%|▋| 27860/40960 [01:42<00:46, 280.03batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  68%|▋| 27860/40960 [01:42<00:46, 280.03batches/s, l2_loss: 0.1053 - round_los\u001b[A\n",
      "Training:  68%|▋| 27911/40960 [01:43<00:47, 272.03batches/s, l2_loss: 0.1053 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|▋| 27911/40960 [01:43<00:47, 272.03batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  68%|▋| 27969/40960 [01:43<00:47, 276.19batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  68%|▋| 27969/40960 [01:43<00:47, 276.19batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  68%|▋| 28025/40960 [01:43<00:46, 276.57batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  68%|▋| 28025/40960 [01:43<00:46, 276.57batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  69%|▋| 28083/40960 [01:43<00:45, 280.54batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  69%|▋| 28083/40960 [01:43<00:45, 280.54batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  69%|▋| 28138/40960 [01:43<00:46, 278.42batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  69%|▋| 28138/40960 [01:43<00:46, 278.42batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  69%|▋| 28191/40960 [01:44<00:46, 274.21batches/s, l2_loss: 0.1054 - round_los\u001b[A\n",
      "Training:  69%|▋| 28191/40960 [01:44<00:46, 274.21batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28242/40960 [01:44<00:47, 267.09batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28242/40960 [01:44<00:47, 267.09batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28299/40960 [01:44<00:46, 271.58batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28299/40960 [01:44<00:46, 271.58batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28354/40960 [01:44<00:46, 271.37batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28354/40960 [01:44<00:46, 271.37batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28405/40960 [01:44<00:47, 264.66batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28405/40960 [01:44<00:47, 264.66batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28460/40960 [01:45<00:46, 266.91batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  69%|▋| 28460/40960 [01:45<00:46, 266.91batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  70%|▋| 28517/40960 [01:45<00:45, 271.93batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  70%|▋| 28517/40960 [01:45<00:45, 271.93batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  70%|▋| 28576/40960 [01:45<00:44, 278.45batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  70%|▋| 28576/40960 [01:45<00:44, 278.45batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  70%|▋| 28635/40960 [01:45<00:43, 282.37batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  70%|▋| 28635/40960 [01:45<00:43, 282.37batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  70%|▋| 28689/40960 [01:45<00:44, 277.99batches/s, l2_loss: 0.1055 - round_los\u001b[A\n",
      "Training:  70%|▋| 28689/40960 [01:45<00:44, 277.99batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  70%|▋| 28744/40960 [01:46<00:44, 275.49batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  70%|▋| 28744/40960 [01:46<00:44, 275.49batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  70%|▋| 28800/40960 [01:46<00:44, 275.79batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  70%|▋| 28800/40960 [01:46<00:44, 275.79batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  70%|▋| 28859/40960 [01:46<00:43, 281.14batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  70%|▋| 28859/40960 [01:46<00:43, 281.14batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 28914/40960 [01:46<00:43, 279.20batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 28914/40960 [01:46<00:43, 279.20batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 28973/40960 [01:46<00:42, 283.19batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 28973/40960 [01:46<00:42, 283.19batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 29029/40960 [01:47<00:42, 282.19batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 29029/40960 [01:47<00:42, 282.19batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 29082/40960 [01:47<00:43, 275.39batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 29082/40960 [01:47<00:43, 275.39batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 29140/40960 [01:47<00:42, 278.86batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 29140/40960 [01:47<00:42, 278.86batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 29201/40960 [01:47<00:41, 285.68batches/s, l2_loss: 0.1056 - round_los\u001b[A\n",
      "Training:  71%|▋| 29201/40960 [01:47<00:41, 285.68batches/s, l2_loss: 0.1057 - round_los\u001b[A\n",
      "Training:  71%|▋| 29259/40960 [01:47<00:40, 286.36batches/s, l2_loss: 0.1057 - round_los\u001b[A\n",
      "Training:  71%|▋| 29259/40960 [01:47<00:40, 286.36batches/s, l2_loss: 0.1057 - round_los\u001b[A\n",
      "Training:  72%|▋| 29315/40960 [01:48<00:41, 282.90batches/s, l2_loss: 0.1057 - round_los\u001b[A\n",
      "Training:  72%|▋| 29315/40960 [01:48<00:41, 282.90batches/s, l2_loss: 0.1057 - round_los\u001b[A\n",
      "Training:  72%|▋| 29374/40960 [01:48<00:40, 285.37batches/s, l2_loss: 0.1057 - round_los\u001b[A\n",
      "Training:  72%|▋| 29374/40960 [01:48<00:40, 285.37batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  72%|▋| 29434/40960 [01:48<00:39, 288.80batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  72%|▋| 29434/40960 [01:48<00:39, 288.80batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  72%|▋| 29492/40960 [01:48<00:39, 288.64batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  72%|▋| 29492/40960 [01:48<00:39, 288.64batches/s, l2_loss: 0.1057 - round_los\u001b[A\n",
      "Training:  72%|▋| 29553/40960 [01:48<00:38, 292.55batches/s, l2_loss: 0.1057 - round_los\u001b[A\n",
      "Training:  72%|▋| 29553/40960 [01:48<00:38, 292.55batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  72%|▋| 29604/40960 [01:49<00:40, 279.60batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  72%|▋| 29604/40960 [01:49<00:40, 279.60batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  72%|▋| 29661/40960 [01:49<00:40, 281.00batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  72%|▋| 29661/40960 [01:49<00:40, 281.00batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  73%|▋| 29720/40960 [01:49<00:39, 284.20batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  73%|▋| 29720/40960 [01:49<00:39, 284.20batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  73%|▋| 29781/40960 [01:49<00:38, 289.90batches/s, l2_loss: 0.1058 - round_los\u001b[A\n",
      "Training:  73%|▋| 29781/40960 [01:49<00:38, 289.90batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 29836/40960 [01:49<00:39, 284.01batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 29836/40960 [01:49<00:39, 284.01batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 29887/40960 [01:50<00:40, 274.40batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 29887/40960 [01:50<00:40, 274.40batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 29941/40960 [01:50<00:40, 270.85batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 29941/40960 [01:50<00:40, 270.85batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 29996/40960 [01:50<00:40, 271.83batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 29996/40960 [01:50<00:40, 271.83batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 30056/40960 [01:50<00:39, 279.34batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  73%|▋| 30056/40960 [01:50<00:39, 279.34batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30108/40960 [01:50<00:39, 273.35batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30108/40960 [01:50<00:39, 273.35batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  74%|▋| 30165/40960 [01:51<00:39, 276.49batches/s, l2_loss: 0.1059 - round_los\u001b[A\n",
      "Training:  74%|▋| 30165/40960 [01:51<00:39, 276.49batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30216/40960 [01:51<00:40, 268.26batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30216/40960 [01:51<00:40, 268.26batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30272/40960 [01:51<00:39, 270.84batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30272/40960 [01:51<00:39, 270.84batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30331/40960 [01:51<00:38, 277.21batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  74%|▋| 30331/40960 [01:51<00:38, 277.21batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30391/40960 [01:51<00:37, 282.85batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30391/40960 [01:51<00:37, 282.85batches/s, l2_loss: 0.1060 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|▋| 30449/40960 [01:52<00:36, 284.72batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30449/40960 [01:52<00:36, 284.72batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30507/40960 [01:52<00:36, 285.12batches/s, l2_loss: 0.1060 - round_los\u001b[A\n",
      "Training:  74%|▋| 30507/40960 [01:52<00:36, 285.12batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30566/40960 [01:52<00:36, 287.14batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30566/40960 [01:52<00:36, 287.14batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30625/40960 [01:52<00:35, 288.88batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30625/40960 [01:52<00:35, 288.88batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30682/40960 [01:52<00:35, 286.72batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▋| 30682/40960 [01:52<00:35, 286.72batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30740/40960 [01:53<00:35, 286.51batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30740/40960 [01:53<00:35, 286.51batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30793/40960 [01:53<00:36, 278.81batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30793/40960 [01:53<00:36, 278.81batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30849/40960 [01:53<00:36, 278.61batches/s, l2_loss: 0.1061 - round_los\u001b[A\n",
      "Training:  75%|▊| 30849/40960 [01:53<00:36, 278.61batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  75%|▊| 30908/40960 [01:53<00:35, 282.43batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  75%|▊| 30908/40960 [01:53<00:35, 282.43batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  76%|▊| 30964/40960 [01:53<00:35, 281.55batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  76%|▊| 30964/40960 [01:53<00:35, 281.55batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  76%|▊| 31018/40960 [01:54<00:35, 276.69batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  76%|▊| 31018/40960 [01:54<00:35, 276.69batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  76%|▊| 31074/40960 [01:54<00:35, 276.57batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  76%|▊| 31074/40960 [01:54<00:35, 276.57batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  76%|▊| 31130/40960 [01:54<00:35, 277.03batches/s, l2_loss: 0.1062 - round_los\u001b[A\n",
      "Training:  76%|▊| 31130/40960 [01:54<00:35, 277.03batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  76%|▊| 31186/40960 [01:54<00:35, 277.81batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  76%|▊| 31186/40960 [01:54<00:35, 277.81batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  76%|▊| 31234/40960 [01:54<00:36, 266.17batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  76%|▊| 31234/40960 [01:54<00:36, 266.17batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  76%|▊| 31280/40960 [01:55<00:38, 254.69batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  76%|▊| 31280/40960 [01:55<00:38, 254.69batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  77%|▊| 31337/40960 [01:55<00:36, 263.59batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  77%|▊| 31337/40960 [01:55<00:36, 263.59batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31387/40960 [01:55<00:37, 258.13batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31387/40960 [01:55<00:37, 258.13batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  77%|▊| 31432/40960 [01:55<00:38, 246.16batches/s, l2_loss: 0.1063 - round_los\u001b[A\n",
      "Training:  77%|▊| 31432/40960 [01:55<00:38, 246.16batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31485/40960 [01:55<00:37, 250.14batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31485/40960 [01:55<00:37, 250.14batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31544/40960 [01:56<00:35, 262.31batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31544/40960 [01:56<00:35, 262.31batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31601/40960 [01:56<00:34, 268.47batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31601/40960 [01:56<00:34, 268.47batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31654/40960 [01:56<00:34, 266.69batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31654/40960 [01:56<00:34, 266.69batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31708/40960 [01:56<00:34, 267.25batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  77%|▊| 31708/40960 [01:56<00:34, 267.25batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  78%|▊| 31766/40960 [01:56<00:33, 273.86batches/s, l2_loss: 0.1064 - round_los\u001b[A\n",
      "Training:  78%|▊| 31766/40960 [01:56<00:33, 273.86batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 31815/40960 [01:57<00:34, 263.93batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 31815/40960 [01:57<00:34, 263.93batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 31874/40960 [01:57<00:33, 272.23batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 31874/40960 [01:57<00:33, 272.23batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 31930/40960 [01:57<00:32, 273.95batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 31930/40960 [01:57<00:32, 273.95batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 31985/40960 [01:57<00:32, 273.46batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 31985/40960 [01:57<00:32, 273.46batches/s, l2_loss: 0.1066 - round_los\u001b[A\n",
      "Training:  78%|▊| 32040/40960 [01:58<00:32, 272.03batches/s, l2_loss: 0.1066 - round_los\u001b[A\n",
      "Training:  78%|▊| 32040/40960 [01:58<00:32, 272.03batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 32095/40960 [01:58<00:32, 271.76batches/s, l2_loss: 0.1065 - round_los\u001b[A\n",
      "Training:  78%|▊| 32095/40960 [01:58<00:32, 271.76batches/s, l2_loss: 0.1066 - round_los\u001b[A\n",
      "Training:  78%|▊| 32152/40960 [01:58<00:32, 274.39batches/s, l2_loss: 0.1066 - round_los\u001b[A\n",
      "Training:  78%|▊| 32152/40960 [01:58<00:32, 274.39batches/s, l2_loss: 0.1066 - round_los\u001b[A\n",
      "Training:  79%|▊| 32210/40960 [01:58<00:31, 278.40batches/s, l2_loss: 0.1066 - round_los\u001b[A\n",
      "Training:  79%|▊| 32210/40960 [01:58<00:31, 278.40batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32269/40960 [01:58<00:30, 282.45batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32269/40960 [01:58<00:30, 282.45batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32325/40960 [01:59<00:30, 280.13batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32325/40960 [01:59<00:30, 280.13batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32383/40960 [01:59<00:30, 282.97batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32383/40960 [01:59<00:30, 282.97batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32438/40960 [01:59<00:30, 280.60batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32438/40960 [01:59<00:30, 280.60batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32493/40960 [01:59<00:30, 278.85batches/s, l2_loss: 0.1067 - round_los\u001b[A\n",
      "Training:  79%|▊| 32493/40960 [01:59<00:30, 278.85batches/s, l2_loss: 0.1068 - round_los\u001b[A\n",
      "Training:  79%|▊| 32547/40960 [01:59<00:30, 276.11batches/s, l2_loss: 0.1068 - round_los\u001b[A\n",
      "Training:  79%|▊| 32547/40960 [01:59<00:30, 276.11batches/s, l2_loss: 0.1068 - round_los\u001b[A\n",
      "Training:  80%|▊| 32606/40960 [02:00<00:29, 281.50batches/s, l2_loss: 0.1068 - round_los\u001b[A\n",
      "Training:  80%|▊| 32606/40960 [02:00<00:29, 281.50batches/s, l2_loss: 0.1068 - round_los\u001b[A\n",
      "Training:  80%|▊| 32661/40960 [02:00<00:29, 279.53batches/s, l2_loss: 0.1068 - round_los\u001b[A\n",
      "Training:  80%|▊| 32661/40960 [02:00<00:29, 279.53batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32714/40960 [02:00<00:30, 274.47batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32714/40960 [02:00<00:30, 274.47batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32769/40960 [02:00<00:29, 273.89batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32769/40960 [02:00<00:29, 273.89batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32827/40960 [02:00<00:29, 277.30batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32827/40960 [02:00<00:29, 277.30batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32877/40960 [02:01<00:30, 268.24batches/s, l2_loss: 0.1069 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32877/40960 [02:01<00:30, 268.24batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32927/40960 [02:01<00:30, 261.54batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  80%|▊| 32927/40960 [02:01<00:30, 261.54batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  81%|▊| 32985/40960 [02:01<00:29, 268.78batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  81%|▊| 32985/40960 [02:01<00:29, 268.78batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  81%|▊| 33040/40960 [02:01<00:29, 269.54batches/s, l2_loss: 0.1069 - round_los\u001b[A\n",
      "Training:  81%|▊| 33040/40960 [02:01<00:29, 269.54batches/s, l2_loss: 0.1070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33098/40960 [02:01<00:28, 274.27batches/s, l2_loss: 0.1070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33098/40960 [02:01<00:28, 274.27batches/s, l2_loss: 0.1070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33154/40960 [02:02<00:28, 275.59batches/s, l2_loss: 0.1070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33154/40960 [02:02<00:28, 275.59batches/s, l2_loss: 0.1070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33207/40960 [02:02<00:28, 269.87batches/s, l2_loss: 0.1070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33207/40960 [02:02<00:28, 269.87batches/s, l2_loss: 0.1070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33268/40960 [02:02<00:27, 279.55batches/s, l2_loss: 0.1070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33268/40960 [02:02<00:27, 279.55batches/s, l2_loss: 0.1071 - round_los\u001b[A\n",
      "Training:  81%|▊| 33315/40960 [02:02<00:28, 263.76batches/s, l2_loss: 0.1071 - round_los\u001b[A\n",
      "Training:  81%|▊| 33315/40960 [02:02<00:28, 263.76batches/s, l2_loss: 0.1071 - round_los\u001b[A\n",
      "Training:  81%|▊| 33358/40960 [02:02<00:30, 246.15batches/s, l2_loss: 0.1071 - round_los\u001b[A\n",
      "Training:  81%|▊| 33358/40960 [02:02<00:30, 246.15batches/s, l2_loss: 0.1071 - round_los\u001b[A\n",
      "Training:  82%|▊| 33415/40960 [02:03<00:29, 257.42batches/s, l2_loss: 0.1071 - round_los\u001b[A\n",
      "Training:  82%|▊| 33415/40960 [02:03<00:29, 257.42batches/s, l2_loss: 0.1071 - round_los\u001b[A\n",
      "Training:  82%|▊| 33472/40960 [02:03<00:28, 264.40batches/s, l2_loss: 0.1071 - round_los\u001b[A\n",
      "Training:  82%|▊| 33472/40960 [02:03<00:28, 264.40batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33529/40960 [02:03<00:27, 269.75batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33529/40960 [02:03<00:27, 269.75batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33584/40960 [02:03<00:27, 270.46batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33584/40960 [02:03<00:27, 270.46batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33642/40960 [02:03<00:26, 275.66batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33642/40960 [02:03<00:26, 275.66batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33701/40960 [02:04<00:25, 280.95batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33701/40960 [02:04<00:25, 280.95batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33757/40960 [02:04<00:25, 280.18batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  82%|▊| 33757/40960 [02:04<00:25, 280.18batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  83%|▊| 33814/40960 [02:04<00:25, 281.14batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  83%|▊| 33814/40960 [02:04<00:25, 281.14batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  83%|▊| 33864/40960 [02:04<00:26, 269.60batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  83%|▊| 33864/40960 [02:04<00:26, 269.60batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33912/40960 [02:04<00:27, 260.24batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33912/40960 [02:04<00:27, 260.24batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33965/40960 [02:05<00:26, 260.99batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  83%|▊| 33965/40960 [02:05<00:26, 260.99batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  83%|▊| 34019/40960 [02:05<00:26, 263.00batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  83%|▊| 34019/40960 [02:05<00:26, 263.00batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  83%|▊| 34075/40960 [02:05<00:25, 267.46batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  83%|▊| 34075/40960 [02:05<00:25, 267.46batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  83%|▊| 34134/40960 [02:05<00:24, 275.30batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  83%|▊| 34134/40960 [02:05<00:24, 275.30batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  83%|▊| 34191/40960 [02:05<00:24, 277.38batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  83%|▊| 34191/40960 [02:05<00:24, 277.38batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  84%|▊| 34249/40960 [02:06<00:23, 280.43batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  84%|▊| 34249/40960 [02:06<00:23, 280.43batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  84%|▊| 34309/40960 [02:06<00:23, 286.05batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  84%|▊| 34309/40960 [02:06<00:23, 286.05batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  84%|▊| 34362/40960 [02:06<00:23, 279.48batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  84%|▊| 34362/40960 [02:06<00:23, 279.48batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  84%|▊| 34421/40960 [02:06<00:23, 283.09batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  84%|▊| 34421/40960 [02:06<00:23, 283.09batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  84%|▊| 34465/40960 [02:06<00:24, 262.85batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  84%|▊| 34465/40960 [02:06<00:24, 262.85batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  84%|▊| 34522/40960 [02:07<00:23, 268.32batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  84%|▊| 34522/40960 [02:07<00:23, 268.32batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  84%|▊| 34579/40960 [02:07<00:23, 273.27batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  84%|▊| 34579/40960 [02:07<00:23, 273.27batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  85%|▊| 34633/40960 [02:07<00:23, 271.62batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  85%|▊| 34633/40960 [02:07<00:23, 271.62batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  85%|▊| 34690/40960 [02:07<00:22, 275.52batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  85%|▊| 34690/40960 [02:07<00:22, 275.52batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  85%|▊| 34743/40960 [02:07<00:22, 272.16batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  85%|▊| 34743/40960 [02:07<00:22, 272.16batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  85%|▊| 34800/40960 [02:08<00:22, 275.90batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  85%|▊| 34800/40960 [02:08<00:22, 275.90batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  85%|▊| 34857/40960 [02:08<00:21, 278.55batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  85%|▊| 34857/40960 [02:08<00:21, 278.55batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  85%|▊| 34917/40960 [02:08<00:21, 284.45batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  85%|▊| 34917/40960 [02:08<00:21, 284.45batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  85%|▊| 34975/40960 [02:08<00:21, 284.82batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  85%|▊| 34975/40960 [02:08<00:21, 284.82batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  86%|▊| 35031/40960 [02:08<00:21, 282.20batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  86%|▊| 35031/40960 [02:08<00:21, 282.20batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  86%|▊| 35089/40960 [02:09<00:20, 283.82batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  86%|▊| 35089/40960 [02:09<00:20, 283.82batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  86%|▊| 35146/40960 [02:09<00:20, 283.27batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  86%|▊| 35146/40960 [02:09<00:20, 283.27batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  86%|▊| 35208/40960 [02:09<00:19, 290.06batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  86%|▊| 35208/40960 [02:09<00:19, 290.06batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  86%|▊| 35264/40960 [02:09<00:19, 286.28batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  86%|▊| 35264/40960 [02:09<00:19, 286.28batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  86%|▊| 35322/40960 [02:09<00:19, 286.65batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  86%|▊| 35322/40960 [02:09<00:19, 286.65batches/s, l2_loss: 0.1082 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|▊| 35380/40960 [02:10<00:19, 286.51batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  86%|▊| 35380/40960 [02:10<00:19, 286.51batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  86%|▊| 35428/40960 [02:10<00:20, 271.19batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  86%|▊| 35428/40960 [02:10<00:20, 271.19batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  87%|▊| 35485/40960 [02:10<00:19, 274.32batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  87%|▊| 35485/40960 [02:10<00:19, 274.32batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  87%|▊| 35524/40960 [02:10<00:21, 250.08batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  87%|▊| 35524/40960 [02:10<00:21, 250.08batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  87%|▊| 35573/40960 [02:10<00:21, 246.68batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  87%|▊| 35573/40960 [02:10<00:21, 246.68batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  87%|▊| 35611/40960 [02:11<00:23, 229.78batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  87%|▊| 35611/40960 [02:11<00:23, 229.78batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  87%|▊| 35664/40960 [02:11<00:22, 239.75batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  87%|▊| 35664/40960 [02:11<00:22, 239.75batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  87%|▊| 35719/40960 [02:11<00:20, 249.67batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  87%|▊| 35719/40960 [02:11<00:20, 249.67batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  87%|▊| 35771/40960 [02:11<00:20, 251.93batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  87%|▊| 35771/40960 [02:11<00:20, 251.93batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  87%|▊| 35819/40960 [02:11<00:20, 247.08batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  87%|▊| 35819/40960 [02:11<00:20, 247.08batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  88%|▉| 35872/40960 [02:12<00:20, 251.60batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  88%|▉| 35872/40960 [02:12<00:20, 251.60batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  88%|▉| 35913/40960 [02:12<00:21, 235.67batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  88%|▉| 35913/40960 [02:12<00:21, 235.67batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  88%|▉| 35957/40960 [02:12<00:21, 228.31batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  88%|▉| 35957/40960 [02:12<00:21, 228.31batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36008/40960 [02:12<00:21, 235.44batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36008/40960 [02:12<00:21, 235.44batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36063/40960 [02:12<00:19, 246.88batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36063/40960 [02:12<00:19, 246.88batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36119/40960 [02:13<00:18, 255.88batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  88%|▉| 36119/40960 [02:13<00:18, 255.88batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  88%|▉| 36179/40960 [02:13<00:17, 268.15batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  88%|▉| 36179/40960 [02:13<00:17, 268.15batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  88%|▉| 36234/40960 [02:13<00:17, 268.74batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  88%|▉| 36234/40960 [02:13<00:17, 268.74batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  89%|▉| 36290/40960 [02:13<00:17, 271.77batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  89%|▉| 36290/40960 [02:13<00:17, 271.77batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  89%|▉| 36345/40960 [02:13<00:16, 271.57batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  89%|▉| 36345/40960 [02:13<00:16, 271.57batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  89%|▉| 36405/40960 [02:14<00:16, 279.83batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  89%|▉| 36405/40960 [02:14<00:16, 279.83batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  89%|▉| 36464/40960 [02:14<00:15, 283.25batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  89%|▉| 36464/40960 [02:14<00:15, 283.25batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  89%|▉| 36515/40960 [02:14<00:16, 273.85batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  89%|▉| 36515/40960 [02:14<00:16, 273.85batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  89%|▉| 36571/40960 [02:14<00:15, 275.62batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  89%|▉| 36571/40960 [02:14<00:15, 275.62batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  89%|▉| 36628/40960 [02:14<00:15, 277.17batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  89%|▉| 36628/40960 [02:14<00:15, 277.17batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  90%|▉| 36684/40960 [02:15<00:15, 276.67batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  90%|▉| 36684/40960 [02:15<00:15, 276.67batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  90%|▉| 36736/40960 [02:15<00:15, 271.49batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  90%|▉| 36736/40960 [02:15<00:15, 271.49batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  90%|▉| 36794/40960 [02:15<00:15, 276.40batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  90%|▉| 36794/40960 [02:15<00:15, 276.40batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  90%|▉| 36843/40960 [02:15<00:15, 266.96batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  90%|▉| 36843/40960 [02:15<00:15, 266.96batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  90%|▉| 36896/40960 [02:15<00:15, 265.65batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  90%|▉| 36896/40960 [02:16<00:15, 265.65batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  90%|▉| 36947/40960 [02:16<00:15, 262.31batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  90%|▉| 36947/40960 [02:16<00:15, 262.31batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  90%|▉| 37006/40960 [02:16<00:14, 271.34batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  90%|▉| 37006/40960 [02:16<00:14, 271.34batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  90%|▉| 37063/40960 [02:16<00:14, 274.22batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  90%|▉| 37063/40960 [02:16<00:14, 274.22batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  91%|▉| 37113/40960 [02:16<00:14, 266.04batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  91%|▉| 37113/40960 [02:16<00:14, 266.04batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  91%|▉| 37167/40960 [02:17<00:14, 266.21batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  91%|▉| 37167/40960 [02:17<00:14, 266.21batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  91%|▉| 37221/40960 [02:17<00:14, 266.33batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  91%|▉| 37221/40960 [02:17<00:14, 266.33batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  91%|▉| 37277/40960 [02:17<00:13, 269.19batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  91%|▉| 37277/40960 [02:17<00:13, 269.19batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  91%|▉| 37324/40960 [02:17<00:14, 258.01batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  91%|▉| 37324/40960 [02:17<00:14, 258.01batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  91%|▉| 37367/40960 [02:17<00:14, 242.40batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  91%|▉| 37367/40960 [02:17<00:14, 242.40batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  91%|▉| 37419/40960 [02:18<00:14, 247.39batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  91%|▉| 37419/40960 [02:18<00:14, 247.39batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  91%|▉| 37471/40960 [02:18<00:13, 250.07batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  91%|▉| 37471/40960 [02:18<00:13, 250.07batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  92%|▉| 37527/40960 [02:18<00:13, 258.65batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  92%|▉| 37527/40960 [02:18<00:13, 258.65batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  92%|▉| 37580/40960 [02:18<00:12, 260.16batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  92%|▉| 37580/40960 [02:18<00:12, 260.16batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  92%|▉| 37638/40960 [02:18<00:12, 268.06batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  92%|▉| 37638/40960 [02:18<00:12, 268.06batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  92%|▉| 37697/40960 [02:19<00:11, 275.95batches/s, l2_loss: 0.1098 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37697/40960 [02:19<00:11, 275.95batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  92%|▉| 37755/40960 [02:19<00:11, 279.38batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  92%|▉| 37755/40960 [02:19<00:11, 279.38batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  92%|▉| 37814/40960 [02:19<00:11, 283.67batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  92%|▉| 37814/40960 [02:19<00:11, 283.67batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  92%|▉| 37868/40960 [02:19<00:11, 279.42batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  92%|▉| 37868/40960 [02:19<00:11, 279.42batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  93%|▉| 37917/40960 [02:19<00:11, 266.72batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  93%|▉| 37917/40960 [02:19<00:11, 266.72batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  93%|▉| 37973/40960 [02:20<00:11, 269.62batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  93%|▉| 37973/40960 [02:20<00:11, 269.62batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  93%|▉| 38033/40960 [02:20<00:10, 278.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  93%|▉| 38033/40960 [02:20<00:10, 278.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  93%|▉| 38089/40960 [02:20<00:10, 278.32batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  93%|▉| 38089/40960 [02:20<00:10, 278.32batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  93%|▉| 38146/40960 [02:20<00:10, 279.91batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  93%|▉| 38146/40960 [02:20<00:10, 279.91batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  93%|▉| 38204/40960 [02:20<00:09, 282.13batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  93%|▉| 38204/40960 [02:20<00:09, 282.13batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  93%|▉| 38254/40960 [02:21<00:09, 272.25batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  93%|▉| 38254/40960 [02:21<00:09, 272.25batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  94%|▉| 38306/40960 [02:21<00:09, 267.95batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  94%|▉| 38306/40960 [02:21<00:09, 267.95batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  94%|▉| 38361/40960 [02:21<00:09, 269.30batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  94%|▉| 38361/40960 [02:21<00:09, 269.30batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  94%|▉| 38417/40960 [02:21<00:09, 271.48batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  94%|▉| 38417/40960 [02:21<00:09, 271.48batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  94%|▉| 38473/40960 [02:21<00:09, 273.15batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  94%|▉| 38473/40960 [02:21<00:09, 273.15batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  94%|▉| 38514/40960 [02:22<00:09, 250.93batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  94%|▉| 38514/40960 [02:22<00:09, 250.93batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  94%|▉| 38557/40960 [02:22<00:10, 239.88batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  94%|▉| 38557/40960 [02:22<00:10, 239.88batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  94%|▉| 38612/40960 [02:22<00:09, 249.84batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  94%|▉| 38612/40960 [02:22<00:09, 249.84batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  94%|▉| 38665/40960 [02:22<00:09, 254.09batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  94%|▉| 38665/40960 [02:22<00:09, 254.09batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  95%|▉| 38713/40960 [02:22<00:09, 247.94batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  95%|▉| 38713/40960 [02:22<00:09, 247.94batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  95%|▉| 38771/40960 [02:23<00:08, 260.06batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  95%|▉| 38771/40960 [02:23<00:08, 260.06batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  95%|▉| 38827/40960 [02:23<00:08, 265.60batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  95%|▉| 38827/40960 [02:23<00:08, 265.60batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  95%|▉| 38886/40960 [02:23<00:07, 273.78batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  95%|▉| 38886/40960 [02:23<00:07, 273.78batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  95%|▉| 38946/40960 [02:23<00:07, 280.78batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  95%|▉| 38946/40960 [02:23<00:07, 280.78batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  95%|▉| 38997/40960 [02:23<00:07, 272.90batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  95%|▉| 38997/40960 [02:23<00:07, 272.90batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  95%|▉| 39058/40960 [02:24<00:06, 282.34batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  95%|▉| 39058/40960 [02:24<00:06, 282.34batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  95%|▉| 39114/40960 [02:24<00:06, 280.48batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  95%|▉| 39114/40960 [02:24<00:06, 280.48batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  96%|▉| 39166/40960 [02:24<00:06, 272.92batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  96%|▉| 39166/40960 [02:24<00:06, 272.92batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  96%|▉| 39223/40960 [02:24<00:06, 276.26batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  96%|▉| 39223/40960 [02:24<00:06, 276.26batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  96%|▉| 39276/40960 [02:24<00:06, 272.89batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  96%|▉| 39276/40960 [02:24<00:06, 272.89batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  96%|▉| 39331/40960 [02:25<00:05, 272.75batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  96%|▉| 39331/40960 [02:25<00:05, 272.75batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  96%|▉| 39386/40960 [02:25<00:05, 272.86batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  96%|▉| 39386/40960 [02:25<00:05, 272.86batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  96%|▉| 39438/40960 [02:25<00:05, 268.98batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  96%|▉| 39438/40960 [02:25<00:05, 268.98batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  96%|▉| 39491/40960 [02:25<00:05, 267.58batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  96%|▉| 39491/40960 [02:25<00:05, 267.58batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  97%|▉| 39543/40960 [02:25<00:05, 265.24batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  97%|▉| 39543/40960 [02:25<00:05, 265.24batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  97%|▉| 39594/40960 [02:26<00:05, 261.21batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  97%|▉| 39594/40960 [02:26<00:05, 261.21batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  97%|▉| 39647/40960 [02:26<00:05, 261.48batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  97%|▉| 39647/40960 [02:26<00:05, 261.48batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  97%|▉| 39697/40960 [02:26<00:04, 256.55batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  97%|▉| 39697/40960 [02:26<00:04, 256.55batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  97%|▉| 39754/40960 [02:26<00:04, 264.45batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  97%|▉| 39754/40960 [02:26<00:04, 264.45batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  97%|▉| 39812/40960 [02:26<00:04, 271.36batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  97%|▉| 39812/40960 [02:26<00:04, 271.36batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  97%|▉| 39870/40960 [02:27<00:03, 276.57batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  97%|▉| 39870/40960 [02:27<00:03, 276.57batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  97%|▉| 39916/40960 [02:27<00:04, 260.80batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  97%|▉| 39916/40960 [02:27<00:04, 260.80batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  98%|▉| 39969/40960 [02:27<00:03, 261.43batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  98%|▉| 39969/40960 [02:27<00:03, 261.43batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  98%|▉| 40027/40960 [02:27<00:03, 269.22batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  98%|▉| 40027/40960 [02:27<00:03, 269.22batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  98%|▉| 40078/40960 [02:27<00:03, 262.82batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  98%|▉| 40078/40960 [02:27<00:03, 262.82batches/s, l2_loss: 0.1119 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40136/40960 [02:28<00:03, 269.98batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  98%|▉| 40136/40960 [02:28<00:03, 269.98batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  98%|▉| 40193/40960 [02:28<00:02, 273.89batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  98%|▉| 40193/40960 [02:28<00:02, 273.89batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  98%|▉| 40250/40960 [02:28<00:02, 276.66batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  98%|▉| 40250/40960 [02:28<00:02, 276.66batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  98%|▉| 40305/40960 [02:28<00:02, 275.66batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  98%|▉| 40305/40960 [02:28<00:02, 275.66batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  99%|▉| 40358/40960 [02:28<00:02, 271.81batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  99%|▉| 40358/40960 [02:28<00:02, 271.81batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  99%|▉| 40406/40960 [02:29<00:02, 260.65batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  99%|▉| 40406/40960 [02:29<00:02, 260.65batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  99%|▉| 40461/40960 [02:29<00:01, 263.57batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  99%|▉| 40461/40960 [02:29<00:01, 263.57batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  99%|▉| 40519/40960 [02:29<00:01, 271.27batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  99%|▉| 40519/40960 [02:29<00:01, 271.27batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  99%|▉| 40575/40960 [02:29<00:01, 273.32batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  99%|▉| 40575/40960 [02:29<00:01, 273.32batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  99%|▉| 40634/40960 [02:29<00:01, 278.62batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  99%|▉| 40634/40960 [02:29<00:01, 278.62batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  99%|▉| 40690/40960 [02:30<00:00, 278.02batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  99%|▉| 40690/40960 [02:30<00:00, 278.02batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  99%|▉| 40743/40960 [02:30<00:00, 272.80batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  99%|▉| 40743/40960 [02:30<00:00, 272.80batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40794/40960 [02:30<00:00, 266.58batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40794/40960 [02:30<00:00, 266.58batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40845/40960 [02:30<00:00, 262.01batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40845/40960 [02:30<00:00, 262.01batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40900/40960 [02:30<00:00, 265.11batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training: 100%|▉| 40900/40960 [02:30<00:00, 265.11batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training: 100%|▉| 40956/40960 [02:31<00:00, 269.16batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training: 100%|▉| 40956/40960 [02:31<00:00, 269.16batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:11:11.818487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  42%|▍| 11/26 [23:34<37:04, 148.31s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:11:15.265950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:11:17.891397: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<10:24:22,  1.09batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:24:22,  1.09batches/s, l2_loss: 0.0566 - round_loss:\u001b[A\n",
      "Training:   0%| | 94/40960 [00:01<06:06, 111.36batches/s, l2_loss: 0.0566 - round_loss: \u001b[A\n",
      "Training:   0%| | 94/40960 [00:01<06:06, 111.36batches/s, l2_loss: 0.0775 - round_loss: \u001b[A\n",
      "Training:   0%| | 187/40960 [00:01<03:23, 200.72batches/s, l2_loss: 0.0775 - round_loss:\u001b[A\n",
      "Training:   0%| | 187/40960 [00:01<03:23, 200.72batches/s, l2_loss: 0.0702 - round_loss:\u001b[A\n",
      "Training:   1%| | 281/40960 [00:01<02:29, 271.87batches/s, l2_loss: 0.0702 - round_loss:\u001b[A\n",
      "Training:   1%| | 281/40960 [00:01<02:29, 271.87batches/s, l2_loss: 0.0699 - round_loss:\u001b[A\n",
      "Training:   1%| | 373/40960 [00:01<02:05, 323.32batches/s, l2_loss: 0.0699 - round_loss:\u001b[A\n",
      "Training:   1%| | 373/40960 [00:01<02:05, 323.32batches/s, l2_loss: 0.0694 - round_loss:\u001b[A\n",
      "Training:   1%| | 465/40960 [00:01<01:51, 361.78batches/s, l2_loss: 0.0694 - round_loss:\u001b[A\n",
      "Training:   1%| | 465/40960 [00:01<01:51, 361.78batches/s, l2_loss: 0.0694 - round_loss:\u001b[A\n",
      "Training:   1%| | 560/40960 [00:02<01:42, 393.50batches/s, l2_loss: 0.0694 - round_loss:\u001b[A\n",
      "Training:   1%| | 560/40960 [00:02<01:42, 393.50batches/s, l2_loss: 0.0664 - round_loss:\u001b[A\n",
      "Training:   2%| | 654/40960 [00:02<01:37, 415.36batches/s, l2_loss: 0.0664 - round_loss:\u001b[A\n",
      "Training:   2%| | 654/40960 [00:02<01:37, 415.36batches/s, l2_loss: 0.0671 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:02<01:32, 432.38batches/s, l2_loss: 0.0671 - round_loss:\u001b[A\n",
      "Training:   2%| | 749/40960 [00:02<01:32, 432.38batches/s, l2_loss: 0.0658 - round_loss:\u001b[A\n",
      "Training:   2%| | 842/40960 [00:02<01:30, 440.87batches/s, l2_loss: 0.0658 - round_loss:\u001b[A\n",
      "Training:   2%| | 842/40960 [00:02<01:30, 440.87batches/s, l2_loss: 0.0659 - round_loss:\u001b[A\n",
      "Training:   2%| | 935/40960 [00:02<01:29, 447.57batches/s, l2_loss: 0.0659 - round_loss:\u001b[A\n",
      "Training:   2%| | 935/40960 [00:02<01:29, 447.57batches/s, l2_loss: 0.0652 - round_loss:\u001b[A\n",
      "Training:   3%| | 1029/40960 [00:03<01:28, 453.59batches/s, l2_loss: 0.0652 - round_loss\u001b[A\n",
      "Training:   3%| | 1029/40960 [00:03<01:28, 453.59batches/s, l2_loss: 0.0644 - round_loss\u001b[A\n",
      "Training:   3%| | 1123/40960 [00:03<01:27, 457.20batches/s, l2_loss: 0.0644 - round_loss\u001b[A\n",
      "Training:   3%| | 1123/40960 [00:03<01:27, 457.20batches/s, l2_loss: 0.0641 - round_loss\u001b[A\n",
      "Training:   3%| | 1217/40960 [00:03<01:26, 460.15batches/s, l2_loss: 0.0641 - round_loss\u001b[A\n",
      "Training:   3%| | 1217/40960 [00:03<01:26, 460.15batches/s, l2_loss: 0.0630 - round_loss\u001b[A\n",
      "Training:   3%| | 1310/40960 [00:03<01:25, 461.32batches/s, l2_loss: 0.0630 - round_loss\u001b[A\n",
      "Training:   3%| | 1310/40960 [00:03<01:25, 461.32batches/s, l2_loss: 0.0633 - round_loss\u001b[A\n",
      "Training:   3%| | 1404/40960 [00:03<01:25, 463.14batches/s, l2_loss: 0.0633 - round_loss\u001b[A\n",
      "Training:   3%| | 1404/40960 [00:03<01:25, 463.14batches/s, l2_loss: 0.0630 - round_loss\u001b[A\n",
      "Training:   4%| | 1498/40960 [00:04<01:25, 463.91batches/s, l2_loss: 0.0630 - round_loss\u001b[A\n",
      "Training:   4%| | 1498/40960 [00:04<01:25, 463.91batches/s, l2_loss: 0.0625 - round_loss\u001b[A\n",
      "Training:   4%| | 1589/40960 [00:04<01:25, 460.48batches/s, l2_loss: 0.0625 - round_loss\u001b[A\n",
      "Training:   4%| | 1589/40960 [00:04<01:25, 460.48batches/s, l2_loss: 0.0622 - round_loss\u001b[A\n",
      "Training:   4%| | 1681/40960 [00:04<01:25, 459.31batches/s, l2_loss: 0.0622 - round_loss\u001b[A\n",
      "Training:   4%| | 1681/40960 [00:04<01:25, 459.31batches/s, l2_loss: 0.0620 - round_loss\u001b[A\n",
      "Training:   4%| | 1775/40960 [00:04<01:24, 461.83batches/s, l2_loss: 0.0620 - round_loss\u001b[A\n",
      "Training:   4%| | 1775/40960 [00:04<01:24, 461.83batches/s, l2_loss: 0.0614 - round_loss\u001b[A\n",
      "Training:   5%| | 1868/40960 [00:04<01:24, 462.51batches/s, l2_loss: 0.0614 - round_loss\u001b[A\n",
      "Training:   5%| | 1868/40960 [00:04<01:24, 462.51batches/s, l2_loss: 0.0615 - round_loss\u001b[A\n",
      "Training:   5%| | 1962/40960 [00:05<01:23, 464.52batches/s, l2_loss: 0.0615 - round_loss\u001b[A\n",
      "Training:   5%| | 1962/40960 [00:05<01:23, 464.52batches/s, l2_loss: 0.0619 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 2054/40960 [00:05<01:24, 463.12batches/s, l2_loss: 0.0619 - round_loss\u001b[A\n",
      "Training:   5%| | 2054/40960 [00:05<01:24, 463.12batches/s, l2_loss: 0.0611 - round_loss\u001b[A\n",
      "Training:   5%| | 2148/40960 [00:05<01:23, 463.79batches/s, l2_loss: 0.0611 - round_loss\u001b[A\n",
      "Training:   5%| | 2148/40960 [00:05<01:23, 463.79batches/s, l2_loss: 0.0609 - round_loss\u001b[A\n",
      "Training:   5%| | 2242/40960 [00:05<01:23, 464.16batches/s, l2_loss: 0.0609 - round_loss\u001b[A\n",
      "Training:   5%| | 2242/40960 [00:05<01:23, 464.16batches/s, l2_loss: 0.0609 - round_loss\u001b[A\n",
      "Training:   6%| | 2336/40960 [00:05<01:23, 465.00batches/s, l2_loss: 0.0609 - round_loss\u001b[A\n",
      "Training:   6%| | 2336/40960 [00:05<01:23, 465.00batches/s, l2_loss: 0.0606 - round_loss\u001b[A\n",
      "Training:   6%| | 2429/40960 [00:06<01:23, 463.99batches/s, l2_loss: 0.0606 - round_loss\u001b[A\n",
      "Training:   6%| | 2429/40960 [00:06<01:23, 463.99batches/s, l2_loss: 0.0604 - round_loss\u001b[A\n",
      "Training:   6%| | 2523/40960 [00:06<01:22, 464.60batches/s, l2_loss: 0.0604 - round_loss\u001b[A\n",
      "Training:   6%| | 2523/40960 [00:06<01:22, 464.60batches/s, l2_loss: 0.0601 - round_loss\u001b[A\n",
      "Training:   6%| | 2617/40960 [00:06<01:22, 464.77batches/s, l2_loss: 0.0601 - round_loss\u001b[A\n",
      "Training:   6%| | 2617/40960 [00:06<01:22, 464.77batches/s, l2_loss: 0.0599 - round_loss\u001b[A\n",
      "Training:   7%| | 2711/40960 [00:06<01:22, 465.32batches/s, l2_loss: 0.0599 - round_loss\u001b[A\n",
      "Training:   7%| | 2711/40960 [00:06<01:22, 465.32batches/s, l2_loss: 0.0598 - round_loss\u001b[A\n",
      "Training:   7%| | 2806/40960 [00:06<01:21, 467.58batches/s, l2_loss: 0.0598 - round_loss\u001b[A\n",
      "Training:   7%| | 2806/40960 [00:06<01:21, 467.58batches/s, l2_loss: 0.0596 - round_loss\u001b[A\n",
      "Training:   7%| | 2901/40960 [00:07<01:21, 468.79batches/s, l2_loss: 0.0596 - round_loss\u001b[A\n",
      "Training:   7%| | 2901/40960 [00:07<01:21, 468.79batches/s, l2_loss: 0.0598 - round_loss\u001b[A\n",
      "Training:   7%| | 2995/40960 [00:07<01:20, 468.85batches/s, l2_loss: 0.0598 - round_loss\u001b[A\n",
      "Training:   7%| | 2995/40960 [00:07<01:20, 468.85batches/s, l2_loss: 0.0594 - round_loss\u001b[A\n",
      "Training:   8%| | 3089/40960 [00:07<01:20, 468.13batches/s, l2_loss: 0.0594 - round_loss\u001b[A\n",
      "Training:   8%| | 3089/40960 [00:07<01:20, 468.13batches/s, l2_loss: 0.0592 - round_loss\u001b[A\n",
      "Training:   8%| | 3184/40960 [00:07<01:20, 469.44batches/s, l2_loss: 0.0592 - round_loss\u001b[A\n",
      "Training:   8%| | 3184/40960 [00:07<01:20, 469.44batches/s, l2_loss: 0.0592 - round_loss\u001b[A\n",
      "Training:   8%| | 3278/40960 [00:07<01:20, 467.78batches/s, l2_loss: 0.0592 - round_loss\u001b[A\n",
      "Training:   8%| | 3278/40960 [00:07<01:20, 467.78batches/s, l2_loss: 0.0590 - round_loss\u001b[A\n",
      "Training:   8%| | 3370/40960 [00:08<01:20, 464.38batches/s, l2_loss: 0.0590 - round_loss\u001b[A\n",
      "Training:   8%| | 3370/40960 [00:08<01:20, 464.38batches/s, l2_loss: 0.0588 - round_loss\u001b[A\n",
      "Training:   8%| | 3465/40960 [00:08<01:20, 466.65batches/s, l2_loss: 0.0588 - round_loss\u001b[A\n",
      "Training:   8%| | 3465/40960 [00:08<01:20, 466.65batches/s, l2_loss: 0.0588 - round_loss\u001b[A\n",
      "Training:   9%| | 3559/40960 [00:08<01:20, 467.35batches/s, l2_loss: 0.0588 - round_loss\u001b[A\n",
      "Training:   9%| | 3559/40960 [00:08<01:20, 467.35batches/s, l2_loss: 0.0587 - round_loss\u001b[A\n",
      "Training:   9%| | 3652/40960 [00:08<01:19, 466.46batches/s, l2_loss: 0.0587 - round_loss\u001b[A\n",
      "Training:   9%| | 3652/40960 [00:08<01:19, 466.46batches/s, l2_loss: 0.0586 - round_loss\u001b[A\n",
      "Training:   9%| | 3745/40960 [00:08<01:19, 465.66batches/s, l2_loss: 0.0586 - round_loss\u001b[A\n",
      "Training:   9%| | 3745/40960 [00:08<01:19, 465.66batches/s, l2_loss: 0.0585 - round_loss\u001b[A\n",
      "Training:   9%| | 3837/40960 [00:09<01:20, 463.07batches/s, l2_loss: 0.0585 - round_loss\u001b[A\n",
      "Training:   9%| | 3837/40960 [00:09<01:20, 463.07batches/s, l2_loss: 0.0583 - round_loss\u001b[A\n",
      "Training:  10%| | 3930/40960 [00:09<01:19, 463.30batches/s, l2_loss: 0.0583 - round_loss\u001b[A\n",
      "Training:  10%| | 3930/40960 [00:09<01:19, 463.30batches/s, l2_loss: 0.0582 - round_loss\u001b[A\n",
      "Training:  10%| | 4022/40960 [00:09<01:19, 462.03batches/s, l2_loss: 0.0582 - round_loss\u001b[A\n",
      "Training:  10%| | 4022/40960 [00:09<01:19, 462.03batches/s, l2_loss: 0.0582 - round_loss\u001b[A\n",
      "Training:  10%| | 4115/40960 [00:09<01:19, 462.21batches/s, l2_loss: 0.0582 - round_loss\u001b[A\n",
      "Training:  10%| | 4115/40960 [00:09<01:19, 462.21batches/s, l2_loss: 0.0580 - round_loss\u001b[A\n",
      "Training:  10%| | 4209/40960 [00:09<01:19, 464.31batches/s, l2_loss: 0.0580 - round_loss\u001b[A\n",
      "Training:  10%| | 4209/40960 [00:09<01:19, 464.31batches/s, l2_loss: 0.0578 - round_loss\u001b[A\n",
      "Training:  11%| | 4303/40960 [00:10<01:18, 465.59batches/s, l2_loss: 0.0578 - round_loss\u001b[A\n",
      "Training:  11%| | 4303/40960 [00:10<01:18, 465.59batches/s, l2_loss: 0.0578 - round_loss\u001b[A\n",
      "Training:  11%| | 4398/40960 [00:10<01:18, 467.61batches/s, l2_loss: 0.0578 - round_loss\u001b[A\n",
      "Training:  11%| | 4398/40960 [00:10<01:18, 467.61batches/s, l2_loss: 0.0577 - round_loss\u001b[A\n",
      "Training:  11%| | 4493/40960 [00:10<01:17, 468.16batches/s, l2_loss: 0.0577 - round_loss\u001b[A\n",
      "Training:  11%| | 4493/40960 [00:10<01:17, 468.16batches/s, l2_loss: 0.0577 - round_loss\u001b[A\n",
      "Training:  11%| | 4587/40960 [00:10<01:17, 468.35batches/s, l2_loss: 0.0577 - round_loss\u001b[A\n",
      "Training:  11%| | 4587/40960 [00:10<01:17, 468.35batches/s, l2_loss: 0.0576 - round_loss\u001b[A\n",
      "Training:  11%| | 4680/40960 [00:10<01:17, 467.27batches/s, l2_loss: 0.0576 - round_loss\u001b[A\n",
      "Training:  11%| | 4680/40960 [00:10<01:17, 467.27batches/s, l2_loss: 0.0576 - round_loss\u001b[A\n",
      "Training:  12%| | 4773/40960 [00:11<01:17, 465.92batches/s, l2_loss: 0.0576 - round_loss\u001b[A\n",
      "Training:  12%| | 4773/40960 [00:11<01:17, 465.92batches/s, l2_loss: 0.0574 - round_loss\u001b[A\n",
      "Training:  12%| | 4866/40960 [00:11<01:17, 464.85batches/s, l2_loss: 0.0574 - round_loss\u001b[A\n",
      "Training:  12%| | 4866/40960 [00:11<01:17, 464.85batches/s, l2_loss: 0.0573 - round_loss\u001b[A\n",
      "Training:  12%| | 4960/40960 [00:11<01:17, 465.57batches/s, l2_loss: 0.0573 - round_loss\u001b[A\n",
      "Training:  12%| | 4960/40960 [00:11<01:17, 465.57batches/s, l2_loss: 0.0571 - round_loss\u001b[A\n",
      "Training:  12%| | 5053/40960 [00:11<01:17, 464.09batches/s, l2_loss: 0.0571 - round_loss\u001b[A\n",
      "Training:  12%| | 5053/40960 [00:11<01:17, 464.09batches/s, l2_loss: 0.0571 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5148/40960 [00:11<01:16, 465.98batches/s, l2_loss: 0.0571 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5148/40960 [00:11<01:16, 465.98batches/s, l2_loss: 0.0570 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5239/40960 [00:12<01:17, 462.55batches/s, l2_loss: 0.0570 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5239/40960 [00:12<01:17, 462.55batches/s, l2_loss: 0.0570 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5333/40960 [00:12<01:16, 464.66batches/s, l2_loss: 0.0570 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5333/40960 [00:12<01:16, 464.66batches/s, l2_loss: 0.0570 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5426/40960 [00:12<01:16, 464.11batches/s, l2_loss: 0.0570 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5426/40960 [00:12<01:16, 464.11batches/s, l2_loss: 0.0570 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5520/40960 [00:12<01:16, 465.21batches/s, l2_loss: 0.0570 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5520/40960 [00:12<01:16, 465.21batches/s, l2_loss: 0.0568 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5613/40960 [00:12<01:16, 464.91batches/s, l2_loss: 0.0568 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5613/40960 [00:12<01:16, 464.91batches/s, l2_loss: 0.0567 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5705/40960 [00:13<01:16, 462.94batches/s, l2_loss: 0.0567 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5705/40960 [00:13<01:16, 462.94batches/s, l2_loss: 0.0566 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5798/40960 [00:13<01:15, 462.69batches/s, l2_loss: 0.0566 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5798/40960 [00:13<01:15, 462.69batches/s, l2_loss: 0.0566 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5892/40960 [00:13<01:15, 464.09batches/s, l2_loss: 0.0566 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5892/40960 [00:13<01:15, 464.09batches/s, l2_loss: 0.0565 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5986/40960 [00:13<01:15, 464.57batches/s, l2_loss: 0.0565 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5986/40960 [00:13<01:15, 464.57batches/s, l2_loss: 0.0565 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6079/40960 [00:13<01:15, 464.06batches/s, l2_loss: 0.0565 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6079/40960 [00:13<01:15, 464.06batches/s, l2_loss: 0.0564 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6173/40960 [00:14<01:14, 465.53batches/s, l2_loss: 0.0564 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|▏| 6173/40960 [00:14<01:14, 465.53batches/s, l2_loss: 0.0563 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6265/40960 [00:14<01:14, 462.78batches/s, l2_loss: 0.0563 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6265/40960 [00:14<01:14, 462.78batches/s, l2_loss: 0.0563 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6360/40960 [00:14<01:14, 465.07batches/s, l2_loss: 0.0563 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6360/40960 [00:14<01:14, 465.07batches/s, l2_loss: 0.0563 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6455/40960 [00:14<01:13, 467.59batches/s, l2_loss: 0.0563 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6455/40960 [00:14<01:13, 467.59batches/s, l2_loss: 0.0561 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6550/40960 [00:14<01:13, 469.62batches/s, l2_loss: 0.0561 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6550/40960 [00:14<01:13, 469.62batches/s, l2_loss: 0.0561 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6641/40960 [00:15<01:13, 465.12batches/s, l2_loss: 0.0561 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6641/40960 [00:15<01:13, 465.12batches/s, l2_loss: 0.0561 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6734/40960 [00:15<01:13, 464.64batches/s, l2_loss: 0.0561 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6734/40960 [00:15<01:13, 464.64batches/s, l2_loss: 0.0560 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6826/40960 [00:15<01:13, 463.04batches/s, l2_loss: 0.0560 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6826/40960 [00:15<01:13, 463.04batches/s, l2_loss: 0.0560 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6919/40960 [00:15<01:13, 463.44batches/s, l2_loss: 0.0560 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6919/40960 [00:15<01:13, 463.44batches/s, l2_loss: 0.0559 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7014/40960 [00:15<01:12, 465.76batches/s, l2_loss: 0.0559 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7014/40960 [00:15<01:12, 465.76batches/s, l2_loss: 0.0559 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7107/40960 [00:16<01:12, 464.20batches/s, l2_loss: 0.0559 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7107/40960 [00:16<01:12, 464.20batches/s, l2_loss: 0.0558 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7201/40960 [00:16<01:12, 464.75batches/s, l2_loss: 0.0558 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7201/40960 [00:16<01:12, 464.75batches/s, l2_loss: 0.0558 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7295/40960 [00:16<01:12, 466.08batches/s, l2_loss: 0.0558 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7295/40960 [00:16<01:12, 466.08batches/s, l2_loss: 0.0557 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7387/40960 [00:16<01:12, 463.83batches/s, l2_loss: 0.0557 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7387/40960 [00:16<01:12, 463.83batches/s, l2_loss: 0.0557 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7480/40960 [00:16<01:12, 463.37batches/s, l2_loss: 0.0557 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7480/40960 [00:17<01:12, 463.37batches/s, l2_loss: 0.0556 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7574/40960 [00:17<01:11, 465.10batches/s, l2_loss: 0.0556 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7574/40960 [00:17<01:11, 465.10batches/s, l2_loss: 0.0556 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7668/40960 [00:17<01:11, 466.19batches/s, l2_loss: 0.0556 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7668/40960 [00:17<01:11, 466.19batches/s, l2_loss: 0.0555 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7762/40960 [00:17<01:11, 465.93batches/s, l2_loss: 0.0555 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7762/40960 [00:17<01:11, 465.93batches/s, l2_loss: 0.0555 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7856/40960 [00:17<01:10, 466.94batches/s, l2_loss: 0.0555 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7856/40960 [00:17<01:10, 466.94batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7950/40960 [00:18<01:10, 467.19batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7950/40960 [00:18<01:10, 467.19batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8044/40960 [00:18<01:10, 467.91batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8044/40960 [00:18<01:10, 467.91batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8139/40960 [00:18<01:09, 469.40batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8139/40960 [00:18<01:09, 469.40batches/s, l2_loss: 0.0553 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8228/40960 [00:18<01:10, 461.46batches/s, l2_loss: 0.0553 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8228/40960 [00:18<01:10, 461.46batches/s, l2_loss: 0.0394 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8311/40960 [00:18<01:12, 447.26batches/s, l2_loss: 0.0394 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8311/40960 [00:18<01:12, 447.26batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8394/40960 [00:19<01:14, 436.88batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8394/40960 [00:19<01:14, 436.88batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8479/40960 [00:19<01:15, 432.42batches/s, l2_loss: 0.0514 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8479/40960 [00:19<01:15, 432.42batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8564/40960 [00:19<01:15, 430.17batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8564/40960 [00:19<01:15, 430.17batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8649/40960 [00:19<01:15, 427.33batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8649/40960 [00:19<01:15, 427.33batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8729/40960 [00:19<01:16, 418.60batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8729/40960 [00:19<01:16, 418.60batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8811/40960 [00:20<01:17, 415.07batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8811/40960 [00:20<01:17, 415.07batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8893/40960 [00:20<01:17, 413.22batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8893/40960 [00:20<01:17, 413.22batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8976/40960 [00:20<01:17, 413.23batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8976/40960 [00:20<01:17, 413.23batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9059/40960 [00:20<01:17, 413.53batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9059/40960 [00:20<01:17, 413.53batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9145/40960 [00:20<01:16, 417.11batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9145/40960 [00:20<01:16, 417.11batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9231/40960 [00:21<01:15, 419.78batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9231/40960 [00:21<01:15, 419.78batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9315/40960 [00:21<01:15, 418.92batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9315/40960 [00:21<01:15, 418.92batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9400/40960 [00:21<01:15, 420.03batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9400/40960 [00:21<01:15, 420.03batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9485/40960 [00:21<01:14, 420.60batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9485/40960 [00:21<01:14, 420.60batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9569/40960 [00:21<01:14, 420.41batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9569/40960 [00:21<01:14, 420.41batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9651/40960 [00:22<01:15, 415.66batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9651/40960 [00:22<01:15, 415.66batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9734/40960 [00:22<01:15, 414.49batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9734/40960 [00:22<01:15, 414.49batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9817/40960 [00:22<01:15, 413.63batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9817/40960 [00:22<01:15, 413.63batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9893/40960 [00:22<01:16, 403.57batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9893/40960 [00:22<01:16, 403.57batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9975/40960 [00:22<01:16, 404.87batches/s, l2_loss: 0.0534 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9975/40960 [00:22<01:16, 404.87batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10060/40960 [00:23<01:15, 409.69batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  25%|▏| 10060/40960 [00:23<01:15, 409.69batches/s, l2_loss: 0.0534 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▏| 10144/40960 [00:23<01:14, 412.69batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  25%|▏| 10144/40960 [00:23<01:14, 412.69batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  25%|▏| 10227/40960 [00:23<01:14, 411.86batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  25%|▏| 10227/40960 [00:23<01:14, 411.86batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  25%|▎| 10309/40960 [00:23<01:14, 410.50batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  25%|▎| 10309/40960 [00:23<01:14, 410.50batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  25%|▎| 10392/40960 [00:23<01:14, 411.70batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  25%|▎| 10392/40960 [00:23<01:14, 411.70batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  26%|▎| 10476/40960 [00:24<01:13, 412.87batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  26%|▎| 10476/40960 [00:24<01:13, 412.87batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  26%|▎| 10562/40960 [00:24<01:12, 416.77batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  26%|▎| 10562/40960 [00:24<01:12, 416.77batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  26%|▎| 10646/40960 [00:24<01:12, 416.93batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  26%|▎| 10646/40960 [00:24<01:12, 416.93batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  26%|▎| 10729/40960 [00:24<01:12, 415.98batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  26%|▎| 10729/40960 [00:24<01:12, 415.98batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  26%|▎| 10812/40960 [00:24<01:12, 414.68batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  26%|▎| 10812/40960 [00:24<01:12, 414.68batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 10898/40960 [00:25<01:11, 418.05batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 10898/40960 [00:25<01:11, 418.05batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 10983/40960 [00:25<01:11, 419.00batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 10983/40960 [00:25<01:11, 419.00batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 11069/40960 [00:25<01:10, 421.60batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 11069/40960 [00:25<01:10, 421.60batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 11151/40960 [00:25<01:11, 417.54batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 11151/40960 [00:25<01:11, 417.54batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 11234/40960 [00:25<01:11, 416.15batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  27%|▎| 11234/40960 [00:25<01:11, 416.15batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  28%|▎| 11317/40960 [00:26<01:11, 415.65batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  28%|▎| 11317/40960 [00:26<01:11, 415.65batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  28%|▎| 11402/40960 [00:26<01:10, 417.11batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  28%|▎| 11402/40960 [00:26<01:10, 417.11batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  28%|▎| 11484/40960 [00:26<01:11, 414.81batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  28%|▎| 11484/40960 [00:26<01:11, 414.81batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  28%|▎| 11566/40960 [00:26<01:11, 412.67batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  28%|▎| 11566/40960 [00:26<01:11, 412.67batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  28%|▎| 11647/40960 [00:26<01:11, 410.18batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  28%|▎| 11647/40960 [00:26<01:11, 410.18batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  29%|▎| 11732/40960 [00:27<01:10, 414.36batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  29%|▎| 11732/40960 [00:27<01:10, 414.36batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  29%|▎| 11816/40960 [00:27<01:10, 414.61batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  29%|▎| 11816/40960 [00:27<01:10, 414.61batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  29%|▎| 11899/40960 [00:27<01:10, 413.50batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  29%|▎| 11899/40960 [00:27<01:10, 413.50batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  29%|▎| 11981/40960 [00:27<01:10, 410.93batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  29%|▎| 11981/40960 [00:27<01:10, 410.93batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  29%|▎| 12063/40960 [00:27<01:10, 410.62batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  29%|▎| 12063/40960 [00:27<01:10, 410.62batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  30%|▎| 12142/40960 [00:28<01:11, 405.38batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  30%|▎| 12142/40960 [00:28<01:11, 405.38batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  30%|▎| 12221/40960 [00:28<01:11, 402.07batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  30%|▎| 12221/40960 [00:28<01:11, 402.07batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  30%|▎| 12299/40960 [00:28<01:12, 397.72batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  30%|▎| 12299/40960 [00:28<01:12, 397.72batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  30%|▎| 12380/40960 [00:28<01:11, 399.63batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  30%|▎| 12380/40960 [00:28<01:11, 399.63batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  30%|▎| 12464/40960 [00:28<01:10, 405.22batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  30%|▎| 12464/40960 [00:28<01:10, 405.22batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  31%|▎| 12548/40960 [00:29<01:09, 408.87batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  31%|▎| 12548/40960 [00:29<01:09, 408.87batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  31%|▎| 12629/40960 [00:29<01:09, 407.48batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  31%|▎| 12629/40960 [00:29<01:09, 407.48batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  31%|▎| 12701/40960 [00:29<01:12, 392.29batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  31%|▎| 12701/40960 [00:29<01:12, 392.29batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  31%|▎| 12780/40960 [00:29<01:12, 391.20batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  31%|▎| 12780/40960 [00:29<01:12, 391.20batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  31%|▎| 12860/40960 [00:29<01:11, 393.24batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  31%|▎| 12860/40960 [00:29<01:11, 393.24batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 12946/40960 [00:30<01:09, 403.61batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 12946/40960 [00:30<01:09, 403.61batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 13032/40960 [00:30<01:07, 410.86batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 13032/40960 [00:30<01:07, 410.86batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 13115/40960 [00:30<01:07, 411.99batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 13115/40960 [00:30<01:07, 411.99batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 13197/40960 [00:30<01:07, 410.16batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 13197/40960 [00:30<01:07, 410.16batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 13282/40960 [00:30<01:06, 413.56batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  32%|▎| 13282/40960 [00:30<01:06, 413.56batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  33%|▎| 13364/40960 [00:31<01:07, 411.80batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  33%|▎| 13364/40960 [00:31<01:07, 411.80batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  33%|▎| 13447/40960 [00:31<01:06, 412.06batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  33%|▎| 13447/40960 [00:31<01:06, 412.06batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  33%|▎| 13532/40960 [00:31<01:06, 414.55batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  33%|▎| 13532/40960 [00:31<01:06, 414.55batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  33%|▎| 13616/40960 [00:31<01:05, 416.04batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  33%|▎| 13616/40960 [00:31<01:05, 416.04batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  33%|▎| 13700/40960 [00:31<01:05, 416.60batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  33%|▎| 13700/40960 [00:31<01:05, 416.60batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  34%|▎| 13784/40960 [00:32<01:05, 416.31batches/s, l2_loss: 0.0531 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|▎| 13784/40960 [00:32<01:05, 416.31batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  34%|▎| 13869/40960 [00:32<01:04, 417.59batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  34%|▎| 13869/40960 [00:32<01:04, 417.59batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  34%|▎| 13951/40960 [00:32<01:05, 415.08batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  34%|▎| 13951/40960 [00:32<01:05, 415.08batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  34%|▎| 14039/40960 [00:32<01:03, 421.55batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  34%|▎| 14039/40960 [00:32<01:03, 421.55batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  34%|▎| 14128/40960 [00:32<01:02, 427.28batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  34%|▎| 14128/40960 [00:32<01:02, 427.28batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  35%|▎| 14216/40960 [00:33<01:02, 430.14batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  35%|▎| 14216/40960 [00:33<01:02, 430.14batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  35%|▎| 14301/40960 [00:33<01:02, 427.46batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  35%|▎| 14301/40960 [00:33<01:02, 427.46batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  35%|▎| 14385/40960 [00:33<01:02, 425.23batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  35%|▎| 14385/40960 [00:33<01:02, 425.23batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  35%|▎| 14469/40960 [00:33<01:02, 423.67batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  35%|▎| 14469/40960 [00:33<01:02, 423.67batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14551/40960 [00:33<01:03, 418.21batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14551/40960 [00:33<01:03, 418.21batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14637/40960 [00:34<01:02, 421.43batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14637/40960 [00:34<01:02, 421.43batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14725/40960 [00:34<01:01, 426.01batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14725/40960 [00:34<01:01, 426.01batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14808/40960 [00:34<01:01, 422.56batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14808/40960 [00:34<01:01, 422.56batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14893/40960 [00:34<01:01, 422.91batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  36%|▎| 14893/40960 [00:34<01:01, 422.91batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 14979/40960 [00:34<01:01, 424.15batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 14979/40960 [00:34<01:01, 424.15batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 15065/40960 [00:35<01:00, 425.20batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 15065/40960 [00:35<01:00, 425.20batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 15151/40960 [00:35<01:00, 426.08batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 15151/40960 [00:35<01:00, 426.08batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 15235/40960 [00:35<01:00, 423.02batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 15235/40960 [00:35<01:00, 423.02batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 15318/40960 [00:35<01:00, 420.40batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  37%|▎| 15318/40960 [00:35<01:00, 420.40batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  38%|▍| 15404/40960 [00:35<01:00, 422.05batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  38%|▍| 15404/40960 [00:35<01:00, 422.05batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  38%|▍| 15487/40960 [00:36<01:00, 419.84batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  38%|▍| 15487/40960 [00:36<01:00, 419.84batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  38%|▍| 15568/40960 [00:36<01:01, 414.69batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  38%|▍| 15568/40960 [00:36<01:01, 414.69batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  38%|▍| 15655/40960 [00:36<01:00, 419.72batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  38%|▍| 15655/40960 [00:36<01:00, 419.72batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  38%|▍| 15742/40960 [00:36<00:59, 424.13batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  38%|▍| 15742/40960 [00:36<00:59, 424.13batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 15827/40960 [00:36<00:59, 423.25batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 15827/40960 [00:36<00:59, 423.25batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 15912/40960 [00:37<00:59, 423.72batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 15912/40960 [00:37<00:59, 423.72batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 15999/40960 [00:37<00:58, 426.05batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 15999/40960 [00:37<00:58, 426.05batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 16083/40960 [00:37<00:58, 423.18batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 16083/40960 [00:37<00:58, 423.18batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 16171/40960 [00:37<00:58, 426.81batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  39%|▍| 16171/40960 [00:37<00:58, 426.81batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  40%|▍| 16258/40960 [00:37<00:57, 428.21batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  40%|▍| 16258/40960 [00:37<00:57, 428.21batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  40%|▍| 16339/40960 [00:38<00:58, 420.95batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  40%|▍| 16339/40960 [00:38<00:58, 420.95batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  40%|▍| 16419/40960 [00:38<00:59, 413.61batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  40%|▍| 16419/40960 [00:38<00:59, 413.61batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  40%|▍| 16504/40960 [00:38<00:58, 416.94batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  40%|▍| 16504/40960 [00:38<00:58, 416.94batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  41%|▍| 16589/40960 [00:38<00:58, 418.31batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  41%|▍| 16589/40960 [00:38<00:58, 418.31batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  41%|▍| 16675/40960 [00:38<00:57, 421.00batches/s, l2_loss: 0.0530 - round_los\u001b[A\n",
      "Training:  41%|▍| 16675/40960 [00:38<00:57, 421.00batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  41%|▍| 16762/40960 [00:39<00:57, 424.39batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  41%|▍| 16762/40960 [00:39<00:57, 424.39batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  41%|▍| 16848/40960 [00:39<00:56, 425.18batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  41%|▍| 16848/40960 [00:39<00:56, 425.18batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  41%|▍| 16932/40960 [00:39<00:56, 423.53batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  41%|▍| 16932/40960 [00:39<00:56, 423.53batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  42%|▍| 17014/40960 [00:39<00:57, 418.62batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  42%|▍| 17014/40960 [00:39<00:57, 418.62batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  42%|▍| 17101/40960 [00:39<00:56, 423.34batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  42%|▍| 17101/40960 [00:39<00:56, 423.34batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  42%|▍| 17186/40960 [00:40<00:56, 423.51batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  42%|▍| 17186/40960 [00:40<00:56, 423.51batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  42%|▍| 17272/40960 [00:40<00:55, 424.48batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  42%|▍| 17272/40960 [00:40<00:55, 424.48batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  42%|▍| 17358/40960 [00:40<00:55, 424.79batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  42%|▍| 17358/40960 [00:40<00:55, 424.79batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17442/40960 [00:40<00:55, 421.93batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17442/40960 [00:40<00:55, 421.93batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17529/40960 [00:40<00:55, 424.76batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17529/40960 [00:40<00:55, 424.76batches/s, l2_loss: 0.0531 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17615/40960 [00:41<00:54, 425.98batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17615/40960 [00:41<00:54, 425.98batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17696/40960 [00:41<00:55, 418.62batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17696/40960 [00:41<00:55, 418.62batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17779/40960 [00:41<00:55, 416.66batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  43%|▍| 17779/40960 [00:41<00:55, 416.66batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  44%|▍| 17864/40960 [00:41<00:55, 419.03batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  44%|▍| 17864/40960 [00:41<00:55, 419.03batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  44%|▍| 17948/40960 [00:41<00:54, 419.21batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  44%|▍| 17948/40960 [00:41<00:54, 419.21batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  44%|▍| 18033/40960 [00:42<00:54, 419.66batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  44%|▍| 18033/40960 [00:42<00:54, 419.66batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  44%|▍| 18120/40960 [00:42<00:53, 422.97batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  44%|▍| 18120/40960 [00:42<00:53, 422.97batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  44%|▍| 18207/40960 [00:42<00:53, 426.28batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  44%|▍| 18207/40960 [00:42<00:53, 426.28batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18293/40960 [00:42<00:53, 427.28batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18293/40960 [00:42<00:53, 427.28batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18379/40960 [00:42<00:52, 427.73batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18379/40960 [00:42<00:52, 427.73batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18462/40960 [00:43<00:53, 422.73batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18462/40960 [00:43<00:53, 422.73batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18548/40960 [00:43<00:52, 424.72batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18548/40960 [00:43<00:52, 424.72batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18632/40960 [00:43<00:52, 422.07batches/s, l2_loss: 0.0531 - round_los\u001b[A\n",
      "Training:  45%|▍| 18632/40960 [00:43<00:52, 422.07batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  46%|▍| 18719/40960 [00:43<00:52, 424.98batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  46%|▍| 18719/40960 [00:43<00:52, 424.98batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  46%|▍| 18804/40960 [00:43<00:52, 423.82batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  46%|▍| 18804/40960 [00:43<00:52, 423.82batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  46%|▍| 18884/40960 [00:44<00:52, 416.71batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  46%|▍| 18884/40960 [00:44<00:52, 416.71batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  46%|▍| 18968/40960 [00:44<00:52, 417.06batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  46%|▍| 18968/40960 [00:44<00:52, 417.06batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19052/40960 [00:44<00:52, 417.51batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19052/40960 [00:44<00:52, 417.51batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19138/40960 [00:44<00:51, 420.57batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19138/40960 [00:44<00:51, 420.57batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19219/40960 [00:44<00:52, 415.85batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19219/40960 [00:44<00:52, 415.85batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19303/40960 [00:45<00:52, 416.05batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19303/40960 [00:45<00:52, 416.05batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19388/40960 [00:45<00:51, 418.32batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  47%|▍| 19388/40960 [00:45<00:51, 418.32batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19474/40960 [00:45<00:50, 421.51batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19474/40960 [00:45<00:50, 421.51batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19561/40960 [00:45<00:50, 424.43batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19561/40960 [00:45<00:50, 424.43batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19643/40960 [00:45<00:50, 419.74batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19643/40960 [00:45<00:50, 419.74batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19723/40960 [00:46<00:51, 412.95batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19723/40960 [00:46<00:51, 412.95batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19803/40960 [00:46<00:51, 408.18batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  48%|▍| 19803/40960 [00:46<00:51, 408.18batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 19887/40960 [00:46<00:51, 411.30batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 19887/40960 [00:46<00:51, 411.30batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 19971/40960 [00:46<00:50, 413.44batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 19971/40960 [00:46<00:50, 413.44batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 20056/40960 [00:46<00:50, 416.76batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 20056/40960 [00:46<00:50, 416.76batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 20139/40960 [00:47<00:50, 414.72batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 20139/40960 [00:47<00:50, 414.72batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 20222/40960 [00:47<00:50, 413.58batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  49%|▍| 20222/40960 [00:47<00:50, 413.58batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  50%|▍| 20304/40960 [00:47<00:50, 412.26batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  50%|▍| 20304/40960 [00:47<00:50, 412.26batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  50%|▍| 20390/40960 [00:47<00:49, 417.48batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  50%|▍| 20390/40960 [00:47<00:49, 417.48batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  50%|▍| 20471/40960 [00:47<00:49, 412.81batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  50%|▍| 20471/40960 [00:47<00:49, 412.81batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  50%|▌| 20551/40960 [00:48<00:49, 408.87batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  50%|▌| 20551/40960 [00:48<00:49, 408.87batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  50%|▌| 20634/40960 [00:48<00:49, 409.32batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  50%|▌| 20634/40960 [00:48<00:49, 409.32batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  51%|▌| 20718/40960 [00:48<00:49, 411.98batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  51%|▌| 20718/40960 [00:48<00:49, 411.98batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  51%|▌| 20802/40960 [00:48<00:48, 413.47batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  51%|▌| 20802/40960 [00:48<00:48, 413.47batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  51%|▌| 20886/40960 [00:48<00:48, 414.63batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  51%|▌| 20886/40960 [00:48<00:48, 414.63batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  51%|▌| 20974/40960 [00:49<00:47, 420.95batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  51%|▌| 20974/40960 [00:49<00:47, 420.95batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  51%|▌| 21059/40960 [00:49<00:47, 421.63batches/s, l2_loss: 0.0532 - round_los\u001b[A\n",
      "Training:  51%|▌| 21059/40960 [00:49<00:47, 421.63batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21145/40960 [00:49<00:46, 422.99batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21145/40960 [00:49<00:46, 422.99batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21231/40960 [00:49<00:46, 423.81batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21231/40960 [00:49<00:46, 423.81batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21316/40960 [00:49<00:46, 423.46batches/s, l2_loss: 0.0533 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21316/40960 [00:49<00:46, 423.46batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21402/40960 [00:50<00:46, 424.19batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21402/40960 [00:50<00:46, 424.19batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21487/40960 [00:50<00:45, 424.19batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  52%|▌| 21487/40960 [00:50<00:45, 424.19batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21570/40960 [00:50<00:46, 420.12batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21570/40960 [00:50<00:46, 420.12batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21655/40960 [00:50<00:45, 420.86batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21655/40960 [00:50<00:45, 420.86batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21739/40960 [00:50<00:45, 420.27batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21739/40960 [00:50<00:45, 420.27batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21821/40960 [00:51<00:45, 416.93batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21821/40960 [00:51<00:45, 416.93batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21908/40960 [00:51<00:45, 422.12batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  53%|▌| 21908/40960 [00:51<00:45, 422.12batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  54%|▌| 21992/40960 [00:51<00:45, 421.18batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  54%|▌| 21992/40960 [00:51<00:45, 421.18batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  54%|▌| 22079/40960 [00:51<00:44, 424.18batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  54%|▌| 22079/40960 [00:51<00:44, 424.18batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  54%|▌| 22165/40960 [00:51<00:44, 425.07batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  54%|▌| 22165/40960 [00:52<00:44, 425.07batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  54%|▌| 22248/40960 [00:52<00:44, 421.71batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  54%|▌| 22248/40960 [00:52<00:44, 421.71batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  55%|▌| 22333/40960 [00:52<00:44, 422.49batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  55%|▌| 22333/40960 [00:52<00:44, 422.49batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  55%|▌| 22419/40960 [00:52<00:43, 424.70batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  55%|▌| 22419/40960 [00:52<00:43, 424.70batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  55%|▌| 22502/40960 [00:52<00:43, 421.26batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  55%|▌| 22502/40960 [00:52<00:43, 421.26batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  55%|▌| 22589/40960 [00:53<00:43, 424.39batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  55%|▌| 22589/40960 [00:53<00:43, 424.39batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  55%|▌| 22674/40960 [00:53<00:43, 424.08batches/s, l2_loss: 0.0533 - round_los\u001b[A\n",
      "Training:  55%|▌| 22674/40960 [00:53<00:43, 424.08batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 22758/40960 [00:53<00:43, 421.91batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 22758/40960 [00:53<00:43, 421.91batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 22841/40960 [00:53<00:43, 419.02batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 22841/40960 [00:53<00:43, 419.02batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 22923/40960 [00:53<00:43, 416.14batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 22923/40960 [00:53<00:43, 416.14batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 23004/40960 [00:54<00:43, 412.69batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 23004/40960 [00:54<00:43, 412.69batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 23092/40960 [00:54<00:42, 419.41batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  56%|▌| 23092/40960 [00:54<00:42, 419.41batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  57%|▌| 23175/40960 [00:54<00:42, 417.72batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  57%|▌| 23175/40960 [00:54<00:42, 417.72batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  57%|▌| 23260/40960 [00:54<00:42, 419.68batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  57%|▌| 23260/40960 [00:54<00:42, 419.68batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  57%|▌| 23346/40960 [00:54<00:41, 422.06batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  57%|▌| 23346/40960 [00:54<00:41, 422.06batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  57%|▌| 23433/40960 [00:55<00:41, 425.57batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  57%|▌| 23433/40960 [00:55<00:41, 425.57batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  57%|▌| 23520/40960 [00:55<00:40, 428.33batches/s, l2_loss: 0.0534 - round_los\u001b[A\n",
      "Training:  57%|▌| 23520/40960 [00:55<00:40, 428.33batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23605/40960 [00:55<00:40, 426.47batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23605/40960 [00:55<00:40, 426.47batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23691/40960 [00:55<00:40, 426.31batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23691/40960 [00:55<00:40, 426.31batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23775/40960 [00:55<00:40, 423.57batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23775/40960 [00:55<00:40, 423.57batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23860/40960 [00:56<00:40, 423.39batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23860/40960 [00:56<00:40, 423.39batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23942/40960 [00:56<00:40, 418.28batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  58%|▌| 23942/40960 [00:56<00:40, 418.28batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24025/40960 [00:56<00:40, 416.57batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24025/40960 [00:56<00:40, 416.57batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24112/40960 [00:56<00:39, 421.38batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24112/40960 [00:56<00:39, 421.38batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24194/40960 [00:56<00:40, 417.77batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24194/40960 [00:56<00:40, 417.77batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24277/40960 [00:57<00:40, 415.44batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24277/40960 [00:57<00:40, 415.44batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24363/40960 [00:57<00:39, 419.11batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  59%|▌| 24363/40960 [00:57<00:39, 419.11batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  60%|▌| 24445/40960 [00:57<00:39, 416.06batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  60%|▌| 24445/40960 [00:57<00:39, 416.06batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  60%|▌| 24531/40960 [00:57<00:39, 419.17batches/s, l2_loss: 0.0535 - round_los\u001b[A\n",
      "Training:  60%|▌| 24531/40960 [00:57<00:39, 419.17batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  60%|▌| 24616/40960 [00:57<00:38, 419.56batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  60%|▌| 24616/40960 [00:57<00:38, 419.56batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  60%|▌| 24700/40960 [00:58<00:38, 418.73batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  60%|▌| 24700/40960 [00:58<00:38, 418.73batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 24785/40960 [00:58<00:38, 419.54batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 24785/40960 [00:58<00:38, 419.54batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 24870/40960 [00:58<00:38, 420.54batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 24870/40960 [00:58<00:38, 420.54batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 24955/40960 [00:58<00:38, 420.87batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 24955/40960 [00:58<00:38, 420.87batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 25041/40960 [00:58<00:37, 423.02batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 25041/40960 [00:58<00:37, 423.02batches/s, l2_loss: 0.0536 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 25128/40960 [00:59<00:37, 426.56batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  61%|▌| 25128/40960 [00:59<00:37, 426.56batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  62%|▌| 25211/40960 [00:59<00:37, 421.78batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  62%|▌| 25211/40960 [00:59<00:37, 421.78batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  62%|▌| 25295/40960 [00:59<00:37, 420.37batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  62%|▌| 25295/40960 [00:59<00:37, 420.37batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  62%|▌| 25379/40960 [00:59<00:37, 419.69batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  62%|▌| 25379/40960 [00:59<00:37, 419.69batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  62%|▌| 25461/40960 [00:59<00:37, 416.44batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  62%|▌| 25461/40960 [00:59<00:37, 416.44batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  62%|▌| 25542/40960 [01:00<00:37, 411.66batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  62%|▌| 25542/40960 [01:00<00:37, 411.66batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  63%|▋| 25625/40960 [01:00<00:37, 412.28batches/s, l2_loss: 0.0536 - round_los\u001b[A\n",
      "Training:  63%|▋| 25625/40960 [01:00<00:37, 412.28batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  63%|▋| 25711/40960 [01:00<00:36, 416.88batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  63%|▋| 25711/40960 [01:00<00:36, 416.88batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  63%|▋| 25799/40960 [01:00<00:35, 423.44batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  63%|▋| 25799/40960 [01:00<00:35, 423.44batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  63%|▋| 25885/40960 [01:00<00:35, 425.02batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  63%|▋| 25885/40960 [01:00<00:35, 425.02batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  63%|▋| 25970/40960 [01:01<00:35, 424.29batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  63%|▋| 25970/40960 [01:01<00:35, 424.29batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  64%|▋| 26052/40960 [01:01<00:35, 419.83batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  64%|▋| 26052/40960 [01:01<00:35, 419.83batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  64%|▋| 26135/40960 [01:01<00:35, 417.24batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  64%|▋| 26135/40960 [01:01<00:35, 417.24batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  64%|▋| 26216/40960 [01:01<00:35, 412.71batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  64%|▋| 26216/40960 [01:01<00:35, 412.71batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  64%|▋| 26300/40960 [01:01<00:35, 414.63batches/s, l2_loss: 0.0537 - round_los\u001b[A\n",
      "Training:  64%|▋| 26300/40960 [01:01<00:35, 414.63batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  64%|▋| 26386/40960 [01:02<00:34, 418.49batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  64%|▋| 26386/40960 [01:02<00:34, 418.49batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26469/40960 [01:02<00:34, 417.11batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26469/40960 [01:02<00:34, 417.11batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26557/40960 [01:02<00:34, 422.70batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26557/40960 [01:02<00:34, 422.70batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26643/40960 [01:02<00:33, 423.45batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26643/40960 [01:02<00:33, 423.45batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26729/40960 [01:02<00:33, 425.27batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26729/40960 [01:02<00:33, 425.27batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26811/40960 [01:03<00:33, 420.23batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  65%|▋| 26811/40960 [01:03<00:33, 420.23batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  66%|▋| 26895/40960 [01:03<00:33, 419.36batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  66%|▋| 26895/40960 [01:03<00:33, 419.36batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  66%|▋| 26979/40960 [01:03<00:33, 419.51batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  66%|▋| 26979/40960 [01:03<00:33, 419.51batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  66%|▋| 27064/40960 [01:03<00:33, 420.43batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  66%|▋| 27064/40960 [01:03<00:33, 420.43batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  66%|▋| 27152/40960 [01:03<00:32, 425.66batches/s, l2_loss: 0.0538 - round_los\u001b[A\n",
      "Training:  66%|▋| 27152/40960 [01:03<00:32, 425.66batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27240/40960 [01:04<00:32, 428.62batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27240/40960 [01:04<00:32, 428.62batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27326/40960 [01:04<00:31, 428.86batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27326/40960 [01:04<00:31, 428.86batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27413/40960 [01:04<00:31, 430.57batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27413/40960 [01:04<00:31, 430.57batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27499/40960 [01:04<00:31, 430.30batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27499/40960 [01:04<00:31, 430.30batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27584/40960 [01:04<00:31, 427.61batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  67%|▋| 27584/40960 [01:04<00:31, 427.61batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  68%|▋| 27669/40960 [01:05<00:31, 425.63batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  68%|▋| 27669/40960 [01:05<00:31, 425.63batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  68%|▋| 27754/40960 [01:05<00:31, 424.66batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  68%|▋| 27754/40960 [01:05<00:31, 424.66batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  68%|▋| 27838/40960 [01:05<00:31, 422.80batches/s, l2_loss: 0.0539 - round_los\u001b[A\n",
      "Training:  68%|▋| 27838/40960 [01:05<00:31, 422.80batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  68%|▋| 27922/40960 [01:05<00:30, 421.41batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  68%|▋| 27922/40960 [01:05<00:30, 421.41batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  68%|▋| 28007/40960 [01:05<00:30, 422.08batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  68%|▋| 28007/40960 [01:05<00:30, 422.08batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28093/40960 [01:06<00:30, 423.10batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28093/40960 [01:06<00:30, 423.10batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28179/40960 [01:06<00:30, 423.73batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28179/40960 [01:06<00:30, 423.73batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28266/40960 [01:06<00:29, 426.26batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28266/40960 [01:06<00:29, 426.26batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28348/40960 [01:06<00:29, 420.81batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28348/40960 [01:06<00:29, 420.81batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28433/40960 [01:06<00:29, 421.39batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  69%|▋| 28433/40960 [01:06<00:29, 421.39batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  70%|▋| 28518/40960 [01:07<00:29, 421.50batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  70%|▋| 28518/40960 [01:07<00:29, 421.50batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  70%|▋| 28603/40960 [01:07<00:29, 422.21batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  70%|▋| 28603/40960 [01:07<00:29, 422.21batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  70%|▋| 28684/40960 [01:07<00:29, 415.89batches/s, l2_loss: 0.0540 - round_los\u001b[A\n",
      "Training:  70%|▋| 28684/40960 [01:07<00:29, 415.89batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  70%|▋| 28767/40960 [01:07<00:29, 414.85batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  70%|▋| 28767/40960 [01:07<00:29, 414.85batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  70%|▋| 28853/40960 [01:07<00:28, 418.17batches/s, l2_loss: 0.0541 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28853/40960 [01:07<00:28, 418.17batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  71%|▋| 28937/40960 [01:08<00:28, 418.54batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  71%|▋| 28937/40960 [01:08<00:28, 418.54batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  71%|▋| 29022/40960 [01:08<00:28, 419.83batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  71%|▋| 29022/40960 [01:08<00:28, 419.83batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  71%|▋| 29107/40960 [01:08<00:28, 420.53batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  71%|▋| 29107/40960 [01:08<00:28, 420.53batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  71%|▋| 29188/40960 [01:08<00:28, 414.65batches/s, l2_loss: 0.0541 - round_los\u001b[A\n",
      "Training:  71%|▋| 29188/40960 [01:08<00:28, 414.65batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  71%|▋| 29272/40960 [01:08<00:28, 416.19batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  71%|▋| 29272/40960 [01:08<00:28, 416.19batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  72%|▋| 29356/40960 [01:09<00:27, 417.15batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  72%|▋| 29356/40960 [01:09<00:27, 417.15batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  72%|▋| 29442/40960 [01:09<00:27, 420.95batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  72%|▋| 29442/40960 [01:09<00:27, 420.95batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  72%|▋| 29526/40960 [01:09<00:27, 419.78batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  72%|▋| 29526/40960 [01:09<00:27, 419.78batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  72%|▋| 29606/40960 [01:09<00:27, 413.02batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  72%|▋| 29606/40960 [01:09<00:27, 413.02batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  72%|▋| 29692/40960 [01:09<00:26, 417.36batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  72%|▋| 29692/40960 [01:09<00:26, 417.36batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  73%|▋| 29778/40960 [01:10<00:26, 420.69batches/s, l2_loss: 0.0542 - round_los\u001b[A\n",
      "Training:  73%|▋| 29778/40960 [01:10<00:26, 420.69batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  73%|▋| 29861/40960 [01:10<00:26, 417.52batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  73%|▋| 29861/40960 [01:10<00:26, 417.52batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  73%|▋| 29945/40960 [01:10<00:26, 418.07batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  73%|▋| 29945/40960 [01:10<00:26, 418.07batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  73%|▋| 30028/40960 [01:10<00:26, 416.33batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  73%|▋| 30028/40960 [01:10<00:26, 416.33batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  74%|▋| 30114/40960 [01:10<00:25, 420.18batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  74%|▋| 30114/40960 [01:10<00:25, 420.18batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  74%|▋| 30196/40960 [01:11<00:25, 416.87batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  74%|▋| 30196/40960 [01:11<00:25, 416.87batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  74%|▋| 30282/40960 [01:11<00:25, 419.77batches/s, l2_loss: 0.0543 - round_los\u001b[A\n",
      "Training:  74%|▋| 30282/40960 [01:11<00:25, 419.77batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  74%|▋| 30362/40960 [01:11<00:25, 413.32batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  74%|▋| 30362/40960 [01:11<00:25, 413.32batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  74%|▋| 30446/40960 [01:11<00:25, 414.89batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  74%|▋| 30446/40960 [01:11<00:25, 414.89batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  75%|▋| 30533/40960 [01:11<00:24, 420.19batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  75%|▋| 30533/40960 [01:11<00:24, 420.19batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  75%|▋| 30618/40960 [01:12<00:24, 421.26batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  75%|▋| 30618/40960 [01:12<00:24, 421.26batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  75%|▋| 30699/40960 [01:12<00:24, 416.30batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  75%|▋| 30699/40960 [01:12<00:24, 416.30batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  75%|▊| 30785/40960 [01:12<00:24, 419.32batches/s, l2_loss: 0.0544 - round_los\u001b[A\n",
      "Training:  75%|▊| 30785/40960 [01:12<00:24, 419.32batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  75%|▊| 30870/40960 [01:12<00:23, 420.86batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  75%|▊| 30870/40960 [01:12<00:23, 420.86batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  76%|▊| 30958/40960 [01:12<00:23, 425.90batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  76%|▊| 30958/40960 [01:12<00:23, 425.90batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  76%|▊| 31041/40960 [01:13<00:23, 422.37batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  76%|▊| 31041/40960 [01:13<00:23, 422.37batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  76%|▊| 31126/40960 [01:13<00:23, 422.83batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  76%|▊| 31126/40960 [01:13<00:23, 422.83batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  76%|▊| 31205/40960 [01:13<00:23, 413.66batches/s, l2_loss: 0.0545 - round_los\u001b[A\n",
      "Training:  76%|▊| 31205/40960 [01:13<00:23, 413.66batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  76%|▊| 31290/40960 [01:13<00:23, 415.62batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  76%|▊| 31290/40960 [01:13<00:23, 415.62batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31373/40960 [01:13<00:23, 414.01batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31373/40960 [01:13<00:23, 414.01batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31455/40960 [01:14<00:23, 412.60batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31455/40960 [01:14<00:23, 412.60batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31532/40960 [01:14<00:23, 403.53batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31532/40960 [01:14<00:23, 403.53batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31614/40960 [01:14<00:23, 405.20batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31614/40960 [01:14<00:23, 405.20batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31701/40960 [01:14<00:22, 413.52batches/s, l2_loss: 0.0546 - round_los\u001b[A\n",
      "Training:  77%|▊| 31701/40960 [01:14<00:22, 413.52batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 31788/40960 [01:14<00:21, 418.76batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 31788/40960 [01:14<00:21, 418.76batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 31873/40960 [01:15<00:21, 420.08batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 31873/40960 [01:15<00:21, 420.08batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 31958/40960 [01:15<00:21, 420.50batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 31958/40960 [01:15<00:21, 420.50batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 32043/40960 [01:15<00:21, 420.82batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 32043/40960 [01:15<00:21, 420.82batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 32127/40960 [01:15<00:21, 420.52batches/s, l2_loss: 0.0547 - round_los\u001b[A\n",
      "Training:  78%|▊| 32127/40960 [01:15<00:21, 420.52batches/s, l2_loss: 0.0548 - round_los\u001b[A\n",
      "Training:  79%|▊| 32214/40960 [01:15<00:20, 423.50batches/s, l2_loss: 0.0548 - round_los\u001b[A\n",
      "Training:  79%|▊| 32214/40960 [01:15<00:20, 423.50batches/s, l2_loss: 0.0548 - round_los\u001b[A\n",
      "Training:  79%|▊| 32300/40960 [01:16<00:20, 424.44batches/s, l2_loss: 0.0548 - round_los\u001b[A\n",
      "Training:  79%|▊| 32300/40960 [01:16<00:20, 424.44batches/s, l2_loss: 0.0548 - round_los\u001b[A\n",
      "Training:  79%|▊| 32389/40960 [01:16<00:19, 430.15batches/s, l2_loss: 0.0548 - round_los\u001b[A\n",
      "Training:  79%|▊| 32389/40960 [01:16<00:19, 430.15batches/s, l2_loss: 0.0548 - round_los\u001b[A\n",
      "Training:  79%|▊| 32471/40960 [01:16<00:20, 423.97batches/s, l2_loss: 0.0548 - round_los\u001b[A\n",
      "Training:  79%|▊| 32471/40960 [01:16<00:20, 423.97batches/s, l2_loss: 0.0549 - round_los\u001b[A\n",
      "Training:  79%|▊| 32555/40960 [01:16<00:19, 421.93batches/s, l2_loss: 0.0549 - round_los\u001b[A\n",
      "Training:  79%|▊| 32555/40960 [01:16<00:19, 421.93batches/s, l2_loss: 0.0549 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32642/40960 [01:16<00:19, 424.75batches/s, l2_loss: 0.0549 - round_los\u001b[A\n",
      "Training:  80%|▊| 32642/40960 [01:16<00:19, 424.75batches/s, l2_loss: 0.0549 - round_los\u001b[A\n",
      "Training:  80%|▊| 32724/40960 [01:17<00:19, 420.31batches/s, l2_loss: 0.0549 - round_los\u001b[A\n",
      "Training:  80%|▊| 32724/40960 [01:17<00:19, 420.31batches/s, l2_loss: 0.0549 - round_los\u001b[A\n",
      "Training:  80%|▊| 32807/40960 [01:17<00:19, 417.90batches/s, l2_loss: 0.0549 - round_los\u001b[A\n",
      "Training:  80%|▊| 32807/40960 [01:17<00:19, 417.90batches/s, l2_loss: 0.0550 - round_los\u001b[A\n",
      "Training:  80%|▊| 32893/40960 [01:17<00:19, 420.40batches/s, l2_loss: 0.0550 - round_los\u001b[A\n",
      "Training:  80%|▊| 32893/40960 [01:17<00:19, 420.40batches/s, l2_loss: 0.0550 - round_los\u001b[A\n",
      "Training:  81%|▊| 32978/40960 [01:17<00:18, 420.99batches/s, l2_loss: 0.0550 - round_los\u001b[A\n",
      "Training:  81%|▊| 32978/40960 [01:17<00:18, 420.99batches/s, l2_loss: 0.0550 - round_los\u001b[A\n",
      "Training:  81%|▊| 33066/40960 [01:17<00:18, 426.37batches/s, l2_loss: 0.0550 - round_los\u001b[A\n",
      "Training:  81%|▊| 33066/40960 [01:17<00:18, 426.37batches/s, l2_loss: 0.0550 - round_los\u001b[A\n",
      "Training:  81%|▊| 33153/40960 [01:18<00:18, 428.56batches/s, l2_loss: 0.0550 - round_los\u001b[A\n",
      "Training:  81%|▊| 33153/40960 [01:18<00:18, 428.56batches/s, l2_loss: 0.0551 - round_los\u001b[A\n",
      "Training:  81%|▊| 33240/40960 [01:18<00:17, 429.50batches/s, l2_loss: 0.0551 - round_los\u001b[A\n",
      "Training:  81%|▊| 33240/40960 [01:18<00:17, 429.50batches/s, l2_loss: 0.0551 - round_los\u001b[A\n",
      "Training:  81%|▊| 33326/40960 [01:18<00:17, 429.24batches/s, l2_loss: 0.0551 - round_los\u001b[A\n",
      "Training:  81%|▊| 33326/40960 [01:18<00:17, 429.24batches/s, l2_loss: 0.0551 - round_los\u001b[A\n",
      "Training:  82%|▊| 33414/40960 [01:18<00:17, 430.97batches/s, l2_loss: 0.0551 - round_los\u001b[A\n",
      "Training:  82%|▊| 33414/40960 [01:18<00:17, 430.97batches/s, l2_loss: 0.0551 - round_los\u001b[A\n",
      "Training:  82%|▊| 33500/40960 [01:18<00:17, 429.36batches/s, l2_loss: 0.0551 - round_los\u001b[A\n",
      "Training:  82%|▊| 33500/40960 [01:18<00:17, 429.36batches/s, l2_loss: 0.0552 - round_los\u001b[A\n",
      "Training:  82%|▊| 33583/40960 [01:19<00:17, 424.08batches/s, l2_loss: 0.0552 - round_los\u001b[A\n",
      "Training:  82%|▊| 33583/40960 [01:19<00:17, 424.08batches/s, l2_loss: 0.0552 - round_los\u001b[A\n",
      "Training:  82%|▊| 33663/40960 [01:19<00:17, 416.83batches/s, l2_loss: 0.0552 - round_los\u001b[A\n",
      "Training:  82%|▊| 33663/40960 [01:19<00:17, 416.83batches/s, l2_loss: 0.0552 - round_los\u001b[A\n",
      "Training:  82%|▊| 33748/40960 [01:19<00:17, 419.19batches/s, l2_loss: 0.0552 - round_los\u001b[A\n",
      "Training:  82%|▊| 33748/40960 [01:19<00:17, 419.19batches/s, l2_loss: 0.0552 - round_los\u001b[A\n",
      "Training:  83%|▊| 33831/40960 [01:19<00:17, 417.08batches/s, l2_loss: 0.0552 - round_los\u001b[A\n",
      "Training:  83%|▊| 33831/40960 [01:19<00:17, 417.08batches/s, l2_loss: 0.0553 - round_los\u001b[A\n",
      "Training:  83%|▊| 33914/40960 [01:19<00:16, 415.19batches/s, l2_loss: 0.0553 - round_los\u001b[A\n",
      "Training:  83%|▊| 33914/40960 [01:19<00:16, 415.19batches/s, l2_loss: 0.0553 - round_los\u001b[A\n",
      "Training:  83%|▊| 33999/40960 [01:20<00:16, 418.10batches/s, l2_loss: 0.0553 - round_los\u001b[A\n",
      "Training:  83%|▊| 33999/40960 [01:20<00:16, 418.10batches/s, l2_loss: 0.0553 - round_los\u001b[A\n",
      "Training:  83%|▊| 34080/40960 [01:20<00:16, 413.86batches/s, l2_loss: 0.0553 - round_los\u001b[A\n",
      "Training:  83%|▊| 34080/40960 [01:20<00:16, 413.86batches/s, l2_loss: 0.0553 - round_los\u001b[A\n",
      "Training:  83%|▊| 34166/40960 [01:20<00:16, 418.00batches/s, l2_loss: 0.0553 - round_los\u001b[A\n",
      "Training:  83%|▊| 34166/40960 [01:20<00:16, 418.00batches/s, l2_loss: 0.0554 - round_los\u001b[A\n",
      "Training:  84%|▊| 34250/40960 [01:20<00:16, 418.22batches/s, l2_loss: 0.0554 - round_los\u001b[A\n",
      "Training:  84%|▊| 34250/40960 [01:20<00:16, 418.22batches/s, l2_loss: 0.0554 - round_los\u001b[A\n",
      "Training:  84%|▊| 34336/40960 [01:20<00:15, 420.65batches/s, l2_loss: 0.0554 - round_los\u001b[A\n",
      "Training:  84%|▊| 34336/40960 [01:20<00:15, 420.65batches/s, l2_loss: 0.0554 - round_los\u001b[A\n",
      "Training:  84%|▊| 34419/40960 [01:21<00:15, 417.54batches/s, l2_loss: 0.0554 - round_los\u001b[A\n",
      "Training:  84%|▊| 34419/40960 [01:21<00:15, 417.54batches/s, l2_loss: 0.0555 - round_los\u001b[A\n",
      "Training:  84%|▊| 34503/40960 [01:21<00:15, 417.58batches/s, l2_loss: 0.0555 - round_los\u001b[A\n",
      "Training:  84%|▊| 34503/40960 [01:21<00:15, 417.58batches/s, l2_loss: 0.0555 - round_los\u001b[A\n",
      "Training:  84%|▊| 34583/40960 [01:21<00:15, 411.65batches/s, l2_loss: 0.0555 - round_los\u001b[A\n",
      "Training:  84%|▊| 34583/40960 [01:21<00:15, 411.65batches/s, l2_loss: 0.0555 - round_los\u001b[A\n",
      "Training:  85%|▊| 34667/40960 [01:21<00:15, 413.06batches/s, l2_loss: 0.0555 - round_los\u001b[A\n",
      "Training:  85%|▊| 34667/40960 [01:21<00:15, 413.06batches/s, l2_loss: 0.0556 - round_los\u001b[A\n",
      "Training:  85%|▊| 34752/40960 [01:21<00:14, 415.66batches/s, l2_loss: 0.0556 - round_los\u001b[A\n",
      "Training:  85%|▊| 34752/40960 [01:21<00:14, 415.66batches/s, l2_loss: 0.0556 - round_los\u001b[A\n",
      "Training:  85%|▊| 34837/40960 [01:22<00:14, 418.18batches/s, l2_loss: 0.0556 - round_los\u001b[A\n",
      "Training:  85%|▊| 34837/40960 [01:22<00:14, 418.18batches/s, l2_loss: 0.0556 - round_los\u001b[A\n",
      "Training:  85%|▊| 34924/40960 [01:22<00:14, 422.19batches/s, l2_loss: 0.0556 - round_los\u001b[A\n",
      "Training:  85%|▊| 34924/40960 [01:22<00:14, 422.19batches/s, l2_loss: 0.0556 - round_los\u001b[A\n",
      "Training:  85%|▊| 35011/40960 [01:22<00:13, 425.98batches/s, l2_loss: 0.0556 - round_los\u001b[A\n",
      "Training:  85%|▊| 35011/40960 [01:22<00:13, 425.98batches/s, l2_loss: 0.0557 - round_los\u001b[A\n",
      "Training:  86%|▊| 35097/40960 [01:22<00:13, 426.28batches/s, l2_loss: 0.0557 - round_los\u001b[A\n",
      "Training:  86%|▊| 35097/40960 [01:22<00:13, 426.28batches/s, l2_loss: 0.0557 - round_los\u001b[A\n",
      "Training:  86%|▊| 35185/40960 [01:22<00:13, 429.98batches/s, l2_loss: 0.0557 - round_los\u001b[A\n",
      "Training:  86%|▊| 35185/40960 [01:22<00:13, 429.98batches/s, l2_loss: 0.0557 - round_los\u001b[A\n",
      "Training:  86%|▊| 35267/40960 [01:23<00:13, 423.25batches/s, l2_loss: 0.0557 - round_los\u001b[A\n",
      "Training:  86%|▊| 35267/40960 [01:23<00:13, 423.25batches/s, l2_loss: 0.0557 - round_los\u001b[A\n",
      "Training:  86%|▊| 35350/40960 [01:23<00:13, 419.84batches/s, l2_loss: 0.0557 - round_los\u001b[A\n",
      "Training:  86%|▊| 35350/40960 [01:23<00:13, 419.84batches/s, l2_loss: 0.0558 - round_los\u001b[A\n",
      "Training:  87%|▊| 35433/40960 [01:23<00:13, 418.29batches/s, l2_loss: 0.0558 - round_los\u001b[A\n",
      "Training:  87%|▊| 35433/40960 [01:23<00:13, 418.29batches/s, l2_loss: 0.0558 - round_los\u001b[A\n",
      "Training:  87%|▊| 35519/40960 [01:23<00:12, 420.28batches/s, l2_loss: 0.0558 - round_los\u001b[A\n",
      "Training:  87%|▊| 35519/40960 [01:23<00:12, 420.28batches/s, l2_loss: 0.0558 - round_los\u001b[A\n",
      "Training:  87%|▊| 35604/40960 [01:23<00:12, 420.29batches/s, l2_loss: 0.0558 - round_los\u001b[A\n",
      "Training:  87%|▊| 35604/40960 [01:23<00:12, 420.29batches/s, l2_loss: 0.0559 - round_los\u001b[A\n",
      "Training:  87%|▊| 35690/40960 [01:24<00:12, 421.72batches/s, l2_loss: 0.0559 - round_los\u001b[A\n",
      "Training:  87%|▊| 35690/40960 [01:24<00:12, 421.72batches/s, l2_loss: 0.0559 - round_los\u001b[A\n",
      "Training:  87%|▊| 35771/40960 [01:24<00:12, 416.35batches/s, l2_loss: 0.0559 - round_los\u001b[A\n",
      "Training:  87%|▊| 35771/40960 [01:24<00:12, 416.35batches/s, l2_loss: 0.0560 - round_los\u001b[A\n",
      "Training:  88%|▉| 35855/40960 [01:24<00:12, 416.53batches/s, l2_loss: 0.0560 - round_los\u001b[A\n",
      "Training:  88%|▉| 35855/40960 [01:24<00:12, 416.53batches/s, l2_loss: 0.0560 - round_los\u001b[A\n",
      "Training:  88%|▉| 35939/40960 [01:24<00:12, 416.74batches/s, l2_loss: 0.0560 - round_los\u001b[A\n",
      "Training:  88%|▉| 35939/40960 [01:24<00:12, 416.74batches/s, l2_loss: 0.0560 - round_los\u001b[A\n",
      "Training:  88%|▉| 36024/40960 [01:24<00:11, 418.49batches/s, l2_loss: 0.0560 - round_los\u001b[A\n",
      "Training:  88%|▉| 36024/40960 [01:24<00:11, 418.49batches/s, l2_loss: 0.0561 - round_los\u001b[A\n",
      "Training:  88%|▉| 36105/40960 [01:25<00:11, 413.46batches/s, l2_loss: 0.0561 - round_los\u001b[A\n",
      "Training:  88%|▉| 36105/40960 [01:25<00:11, 413.46batches/s, l2_loss: 0.0561 - round_los\u001b[A\n",
      "Training:  88%|▉| 36188/40960 [01:25<00:11, 413.93batches/s, l2_loss: 0.0561 - round_los\u001b[A\n",
      "Training:  88%|▉| 36188/40960 [01:25<00:11, 413.93batches/s, l2_loss: 0.0561 - round_los\u001b[A\n",
      "Training:  89%|▉| 36273/40960 [01:25<00:11, 416.31batches/s, l2_loss: 0.0561 - round_los\u001b[A\n",
      "Training:  89%|▉| 36273/40960 [01:25<00:11, 416.31batches/s, l2_loss: 0.0562 - round_los\u001b[A\n",
      "Training:  89%|▉| 36359/40960 [01:25<00:10, 419.34batches/s, l2_loss: 0.0562 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36359/40960 [01:25<00:10, 419.34batches/s, l2_loss: 0.0562 - round_los\u001b[A\n",
      "Training:  89%|▉| 36444/40960 [01:25<00:10, 419.95batches/s, l2_loss: 0.0562 - round_los\u001b[A\n",
      "Training:  89%|▉| 36444/40960 [01:25<00:10, 419.95batches/s, l2_loss: 0.0562 - round_los\u001b[A\n",
      "Training:  89%|▉| 36528/40960 [01:26<00:10, 419.07batches/s, l2_loss: 0.0562 - round_los\u001b[A\n",
      "Training:  89%|▉| 36528/40960 [01:26<00:10, 419.07batches/s, l2_loss: 0.0563 - round_los\u001b[A\n",
      "Training:  89%|▉| 36615/40960 [01:26<00:10, 423.25batches/s, l2_loss: 0.0563 - round_los\u001b[A\n",
      "Training:  89%|▉| 36615/40960 [01:26<00:10, 423.25batches/s, l2_loss: 0.0563 - round_los\u001b[A\n",
      "Training:  90%|▉| 36701/40960 [01:26<00:10, 423.89batches/s, l2_loss: 0.0563 - round_los\u001b[A\n",
      "Training:  90%|▉| 36701/40960 [01:26<00:10, 423.89batches/s, l2_loss: 0.0564 - round_los\u001b[A\n",
      "Training:  90%|▉| 36783/40960 [01:26<00:09, 419.58batches/s, l2_loss: 0.0564 - round_los\u001b[A\n",
      "Training:  90%|▉| 36783/40960 [01:26<00:09, 419.58batches/s, l2_loss: 0.0564 - round_los\u001b[A\n",
      "Training:  90%|▉| 36867/40960 [01:26<00:09, 419.20batches/s, l2_loss: 0.0564 - round_los\u001b[A\n",
      "Training:  90%|▉| 36867/40960 [01:26<00:09, 419.20batches/s, l2_loss: 0.0564 - round_los\u001b[A\n",
      "Training:  90%|▉| 36953/40960 [01:27<00:09, 421.74batches/s, l2_loss: 0.0564 - round_los\u001b[A\n",
      "Training:  90%|▉| 36953/40960 [01:27<00:09, 421.74batches/s, l2_loss: 0.0565 - round_los\u001b[A\n",
      "Training:  90%|▉| 37041/40960 [01:27<00:09, 426.13batches/s, l2_loss: 0.0565 - round_los\u001b[A\n",
      "Training:  90%|▉| 37041/40960 [01:27<00:09, 426.13batches/s, l2_loss: 0.0565 - round_los\u001b[A\n",
      "Training:  91%|▉| 37127/40960 [01:27<00:08, 426.43batches/s, l2_loss: 0.0565 - round_los\u001b[A\n",
      "Training:  91%|▉| 37127/40960 [01:27<00:08, 426.43batches/s, l2_loss: 0.0566 - round_los\u001b[A\n",
      "Training:  91%|▉| 37213/40960 [01:27<00:08, 426.25batches/s, l2_loss: 0.0566 - round_los\u001b[A\n",
      "Training:  91%|▉| 37213/40960 [01:27<00:08, 426.25batches/s, l2_loss: 0.0566 - round_los\u001b[A\n",
      "Training:  91%|▉| 37299/40960 [01:28<00:08, 426.29batches/s, l2_loss: 0.0566 - round_los\u001b[A\n",
      "Training:  91%|▉| 37299/40960 [01:28<00:08, 426.29batches/s, l2_loss: 0.0566 - round_los\u001b[A\n",
      "Training:  91%|▉| 37384/40960 [01:28<00:08, 425.21batches/s, l2_loss: 0.0566 - round_los\u001b[A\n",
      "Training:  91%|▉| 37384/40960 [01:28<00:08, 425.21batches/s, l2_loss: 0.0567 - round_los\u001b[A\n",
      "Training:  91%|▉| 37470/40960 [01:28<00:08, 426.60batches/s, l2_loss: 0.0567 - round_los\u001b[A\n",
      "Training:  91%|▉| 37470/40960 [01:28<00:08, 426.60batches/s, l2_loss: 0.0567 - round_los\u001b[A\n",
      "Training:  92%|▉| 37555/40960 [01:28<00:08, 425.05batches/s, l2_loss: 0.0567 - round_los\u001b[A\n",
      "Training:  92%|▉| 37555/40960 [01:28<00:08, 425.05batches/s, l2_loss: 0.0568 - round_los\u001b[A\n",
      "Training:  92%|▉| 37642/40960 [01:28<00:07, 427.45batches/s, l2_loss: 0.0568 - round_los\u001b[A\n",
      "Training:  92%|▉| 37642/40960 [01:28<00:07, 427.45batches/s, l2_loss: 0.0568 - round_los\u001b[A\n",
      "Training:  92%|▉| 37726/40960 [01:29<00:07, 424.53batches/s, l2_loss: 0.0568 - round_los\u001b[A\n",
      "Training:  92%|▉| 37726/40960 [01:29<00:07, 424.53batches/s, l2_loss: 0.0569 - round_los\u001b[A\n",
      "Training:  92%|▉| 37811/40960 [01:29<00:07, 423.94batches/s, l2_loss: 0.0569 - round_los\u001b[A\n",
      "Training:  92%|▉| 37811/40960 [01:29<00:07, 423.94batches/s, l2_loss: 0.0569 - round_los\u001b[A\n",
      "Training:  93%|▉| 37895/40960 [01:29<00:07, 422.39batches/s, l2_loss: 0.0569 - round_los\u001b[A\n",
      "Training:  93%|▉| 37895/40960 [01:29<00:07, 422.39batches/s, l2_loss: 0.0570 - round_los\u001b[A\n",
      "Training:  93%|▉| 37977/40960 [01:29<00:07, 418.25batches/s, l2_loss: 0.0570 - round_los\u001b[A\n",
      "Training:  93%|▉| 37977/40960 [01:29<00:07, 418.25batches/s, l2_loss: 0.0570 - round_los\u001b[A\n",
      "Training:  93%|▉| 38062/40960 [01:29<00:06, 420.08batches/s, l2_loss: 0.0570 - round_los\u001b[A\n",
      "Training:  93%|▉| 38062/40960 [01:29<00:06, 420.08batches/s, l2_loss: 0.0570 - round_los\u001b[A\n",
      "Training:  93%|▉| 38149/40960 [01:30<00:06, 424.21batches/s, l2_loss: 0.0570 - round_los\u001b[A\n",
      "Training:  93%|▉| 38149/40960 [01:30<00:06, 424.21batches/s, l2_loss: 0.0571 - round_los\u001b[A\n",
      "Training:  93%|▉| 38234/40960 [01:30<00:06, 423.85batches/s, l2_loss: 0.0571 - round_los\u001b[A\n",
      "Training:  93%|▉| 38234/40960 [01:30<00:06, 423.85batches/s, l2_loss: 0.0571 - round_los\u001b[A\n",
      "Training:  94%|▉| 38319/40960 [01:30<00:06, 423.49batches/s, l2_loss: 0.0571 - round_los\u001b[A\n",
      "Training:  94%|▉| 38319/40960 [01:30<00:06, 423.49batches/s, l2_loss: 0.0572 - round_los\u001b[A\n",
      "Training:  94%|▉| 38405/40960 [01:30<00:06, 424.83batches/s, l2_loss: 0.0572 - round_los\u001b[A\n",
      "Training:  94%|▉| 38405/40960 [01:30<00:06, 424.83batches/s, l2_loss: 0.0572 - round_los\u001b[A\n",
      "Training:  94%|▉| 38491/40960 [01:30<00:05, 425.90batches/s, l2_loss: 0.0572 - round_los\u001b[A\n",
      "Training:  94%|▉| 38491/40960 [01:30<00:05, 425.90batches/s, l2_loss: 0.0573 - round_los\u001b[A\n",
      "Training:  94%|▉| 38574/40960 [01:31<00:05, 422.57batches/s, l2_loss: 0.0573 - round_los\u001b[A\n",
      "Training:  94%|▉| 38574/40960 [01:31<00:05, 422.57batches/s, l2_loss: 0.0573 - round_los\u001b[A\n",
      "Training:  94%|▉| 38658/40960 [01:31<00:05, 420.76batches/s, l2_loss: 0.0573 - round_los\u001b[A\n",
      "Training:  94%|▉| 38658/40960 [01:31<00:05, 420.76batches/s, l2_loss: 0.0574 - round_los\u001b[A\n",
      "Training:  95%|▉| 38744/40960 [01:31<00:05, 421.93batches/s, l2_loss: 0.0574 - round_los\u001b[A\n",
      "Training:  95%|▉| 38744/40960 [01:31<00:05, 421.93batches/s, l2_loss: 0.0574 - round_los\u001b[A\n",
      "Training:  95%|▉| 38827/40960 [01:31<00:05, 419.33batches/s, l2_loss: 0.0574 - round_los\u001b[A\n",
      "Training:  95%|▉| 38827/40960 [01:31<00:05, 419.33batches/s, l2_loss: 0.0575 - round_los\u001b[A\n",
      "Training:  95%|▉| 38915/40960 [01:31<00:04, 425.07batches/s, l2_loss: 0.0575 - round_los\u001b[A\n",
      "Training:  95%|▉| 38915/40960 [01:31<00:04, 425.07batches/s, l2_loss: 0.0575 - round_los\u001b[A\n",
      "Training:  95%|▉| 39001/40960 [01:32<00:04, 426.21batches/s, l2_loss: 0.0575 - round_los\u001b[A\n",
      "Training:  95%|▉| 39001/40960 [01:32<00:04, 426.21batches/s, l2_loss: 0.0576 - round_los\u001b[A\n",
      "Training:  95%|▉| 39087/40960 [01:32<00:04, 426.96batches/s, l2_loss: 0.0576 - round_los\u001b[A\n",
      "Training:  95%|▉| 39087/40960 [01:32<00:04, 426.96batches/s, l2_loss: 0.0576 - round_los\u001b[A\n",
      "Training:  96%|▉| 39172/40960 [01:32<00:04, 425.93batches/s, l2_loss: 0.0576 - round_los\u001b[A\n",
      "Training:  96%|▉| 39172/40960 [01:32<00:04, 425.93batches/s, l2_loss: 0.0576 - round_los\u001b[A\n",
      "Training:  96%|▉| 39258/40960 [01:32<00:03, 426.80batches/s, l2_loss: 0.0576 - round_los\u001b[A\n",
      "Training:  96%|▉| 39258/40960 [01:32<00:03, 426.80batches/s, l2_loss: 0.0577 - round_los\u001b[A\n",
      "Training:  96%|▉| 39342/40960 [01:32<00:03, 423.95batches/s, l2_loss: 0.0577 - round_los\u001b[A\n",
      "Training:  96%|▉| 39342/40960 [01:32<00:03, 423.95batches/s, l2_loss: 0.0577 - round_los\u001b[A\n",
      "Training:  96%|▉| 39428/40960 [01:33<00:03, 425.08batches/s, l2_loss: 0.0577 - round_los\u001b[A\n",
      "Training:  96%|▉| 39428/40960 [01:33<00:03, 425.08batches/s, l2_loss: 0.0578 - round_los\u001b[A\n",
      "Training:  96%|▉| 39512/40960 [01:33<00:03, 422.96batches/s, l2_loss: 0.0578 - round_los\u001b[A\n",
      "Training:  96%|▉| 39512/40960 [01:33<00:03, 422.96batches/s, l2_loss: 0.0578 - round_los\u001b[A\n",
      "Training:  97%|▉| 39597/40960 [01:33<00:03, 423.54batches/s, l2_loss: 0.0578 - round_los\u001b[A\n",
      "Training:  97%|▉| 39597/40960 [01:33<00:03, 423.54batches/s, l2_loss: 0.0579 - round_los\u001b[A\n",
      "Training:  97%|▉| 39681/40960 [01:33<00:03, 421.69batches/s, l2_loss: 0.0579 - round_los\u001b[A\n",
      "Training:  97%|▉| 39681/40960 [01:33<00:03, 421.69batches/s, l2_loss: 0.0579 - round_los\u001b[A\n",
      "Training:  97%|▉| 39765/40960 [01:33<00:02, 420.50batches/s, l2_loss: 0.0579 - round_los\u001b[A\n",
      "Training:  97%|▉| 39765/40960 [01:33<00:02, 420.50batches/s, l2_loss: 0.0580 - round_los\u001b[A\n",
      "Training:  97%|▉| 39849/40960 [01:34<00:02, 419.59batches/s, l2_loss: 0.0580 - round_los\u001b[A\n",
      "Training:  97%|▉| 39849/40960 [01:34<00:02, 419.59batches/s, l2_loss: 0.0580 - round_los\u001b[A\n",
      "Training:  97%|▉| 39935/40960 [01:34<00:02, 421.49batches/s, l2_loss: 0.0580 - round_los\u001b[A\n",
      "Training:  97%|▉| 39935/40960 [01:34<00:02, 421.49batches/s, l2_loss: 0.0581 - round_los\u001b[A\n",
      "Training:  98%|▉| 40020/40960 [01:34<00:02, 421.91batches/s, l2_loss: 0.0581 - round_los\u001b[A\n",
      "Training:  98%|▉| 40020/40960 [01:34<00:02, 421.91batches/s, l2_loss: 0.0581 - round_los\u001b[A\n",
      "Training:  98%|▉| 40104/40960 [01:34<00:02, 420.75batches/s, l2_loss: 0.0581 - round_los\u001b[A\n",
      "Training:  98%|▉| 40104/40960 [01:34<00:02, 420.75batches/s, l2_loss: 0.0582 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40187/40960 [01:34<00:01, 418.85batches/s, l2_loss: 0.0582 - round_los\u001b[A\n",
      "Training:  98%|▉| 40187/40960 [01:34<00:01, 418.85batches/s, l2_loss: 0.0582 - round_los\u001b[A\n",
      "Training:  98%|▉| 40272/40960 [01:35<00:01, 420.57batches/s, l2_loss: 0.0582 - round_los\u001b[A\n",
      "Training:  98%|▉| 40272/40960 [01:35<00:01, 420.57batches/s, l2_loss: 0.0583 - round_los\u001b[A\n",
      "Training:  99%|▉| 40359/40960 [01:35<00:01, 423.51batches/s, l2_loss: 0.0583 - round_los\u001b[A\n",
      "Training:  99%|▉| 40359/40960 [01:35<00:01, 423.51batches/s, l2_loss: 0.0583 - round_los\u001b[A\n",
      "Training:  99%|▉| 40444/40960 [01:35<00:01, 423.64batches/s, l2_loss: 0.0583 - round_los\u001b[A\n",
      "Training:  99%|▉| 40444/40960 [01:35<00:01, 423.64batches/s, l2_loss: 0.0584 - round_los\u001b[A\n",
      "Training:  99%|▉| 40530/40960 [01:35<00:01, 424.34batches/s, l2_loss: 0.0584 - round_los\u001b[A\n",
      "Training:  99%|▉| 40530/40960 [01:35<00:01, 424.34batches/s, l2_loss: 0.0584 - round_los\u001b[A\n",
      "Training:  99%|▉| 40616/40960 [01:35<00:00, 424.50batches/s, l2_loss: 0.0584 - round_los\u001b[A\n",
      "Training:  99%|▉| 40616/40960 [01:35<00:00, 424.50batches/s, l2_loss: 0.0585 - round_los\u001b[A\n",
      "Training:  99%|▉| 40703/40960 [01:36<00:00, 426.81batches/s, l2_loss: 0.0585 - round_los\u001b[A\n",
      "Training:  99%|▉| 40703/40960 [01:36<00:00, 426.81batches/s, l2_loss: 0.0585 - round_los\u001b[A\n",
      "Training: 100%|▉| 40784/40960 [01:36<00:00, 419.83batches/s, l2_loss: 0.0585 - round_los\u001b[A\n",
      "Training: 100%|▉| 40784/40960 [01:36<00:00, 419.83batches/s, l2_loss: 0.0586 - round_los\u001b[A\n",
      "Training: 100%|▉| 40866/40960 [01:36<00:00, 415.44batches/s, l2_loss: 0.0586 - round_los\u001b[A\n",
      "Training: 100%|▉| 40866/40960 [01:36<00:00, 415.44batches/s, l2_loss: 0.0586 - round_los\u001b[A\n",
      "Training: 100%|▉| 40952/40960 [01:36<00:00, 418.69batches/s, l2_loss: 0.0586 - round_los\u001b[A\n",
      "Training: 100%|▉| 40952/40960 [01:36<00:00, 418.69batches/s, l2_loss: 0.0587 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:12:54.008001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  46%|▍| 12/26 [25:14<31:10, 133.62s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:12:55.268404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:12:59.161478: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<14:27:24,  1.27s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<14:27:24,  1.27s/batches, l2_loss: 0.1126 - round_loss:\u001b[A\n",
      "Training:   0%| | 44/40960 [00:01<17:03, 39.97batches/s, l2_loss: 0.1126 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 44/40960 [00:01<17:03, 39.97batches/s, l2_loss: 0.1816 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 105/40960 [00:01<07:11, 94.64batches/s, l2_loss: 0.1816 - round_loss: \u001b[A\n",
      "Training:   0%| | 105/40960 [00:01<07:11, 94.64batches/s, l2_loss: 0.1613 - round_loss: \u001b[A\n",
      "Training:   0%| | 182/40960 [00:01<04:14, 160.42batches/s, l2_loss: 0.1613 - round_loss:\u001b[A\n",
      "Training:   0%| | 182/40960 [00:01<04:14, 160.42batches/s, l2_loss: 0.1570 - round_loss:\u001b[A\n",
      "Training:   1%| | 260/40960 [00:02<03:07, 216.65batches/s, l2_loss: 0.1570 - round_loss:\u001b[A\n",
      "Training:   1%| | 260/40960 [00:02<03:07, 216.65batches/s, l2_loss: 0.1563 - round_loss:\u001b[A\n",
      "Training:   1%| | 339/40960 [00:02<02:34, 262.54batches/s, l2_loss: 0.1563 - round_loss:\u001b[A\n",
      "Training:   1%| | 339/40960 [00:02<02:34, 262.54batches/s, l2_loss: 0.1555 - round_loss:\u001b[A\n",
      "Training:   1%| | 409/40960 [00:02<02:21, 286.11batches/s, l2_loss: 0.1555 - round_loss:\u001b[A\n",
      "Training:   1%| | 409/40960 [00:02<02:21, 286.11batches/s, l2_loss: 0.1517 - round_loss:\u001b[A\n",
      "Training:   1%| | 480/40960 [00:02<02:12, 305.11batches/s, l2_loss: 0.1517 - round_loss:\u001b[A\n",
      "Training:   1%| | 480/40960 [00:02<02:12, 305.11batches/s, l2_loss: 0.1504 - round_loss:\u001b[A\n",
      "Training:   1%| | 560/40960 [00:02<02:01, 331.91batches/s, l2_loss: 0.1504 - round_loss:\u001b[A\n",
      "Training:   1%| | 560/40960 [00:02<02:01, 331.91batches/s, l2_loss: 0.1497 - round_loss:\u001b[A\n",
      "Training:   2%| | 639/40960 [00:03<01:55, 349.83batches/s, l2_loss: 0.1497 - round_loss:\u001b[A\n",
      "Training:   2%| | 639/40960 [00:03<01:55, 349.83batches/s, l2_loss: 0.1478 - round_loss:\u001b[A\n",
      "Training:   2%| | 718/40960 [00:03<01:51, 362.22batches/s, l2_loss: 0.1478 - round_loss:\u001b[A\n",
      "Training:   2%| | 718/40960 [00:03<01:51, 362.22batches/s, l2_loss: 0.1476 - round_loss:\u001b[A\n",
      "Training:   2%| | 796/40960 [00:03<01:48, 370.35batches/s, l2_loss: 0.1476 - round_loss:\u001b[A\n",
      "Training:   2%| | 796/40960 [00:03<01:48, 370.35batches/s, l2_loss: 0.1450 - round_loss:\u001b[A\n",
      "Training:   2%| | 876/40960 [00:03<01:46, 377.95batches/s, l2_loss: 0.1450 - round_loss:\u001b[A\n",
      "Training:   2%| | 876/40960 [00:03<01:46, 377.95batches/s, l2_loss: 0.1440 - round_loss:\u001b[A\n",
      "Training:   2%| | 956/40960 [00:03<01:44, 383.18batches/s, l2_loss: 0.1440 - round_loss:\u001b[A\n",
      "Training:   2%| | 956/40960 [00:03<01:44, 383.18batches/s, l2_loss: 0.1431 - round_loss:\u001b[A\n",
      "Training:   3%| | 1037/40960 [00:04<01:42, 388.95batches/s, l2_loss: 0.1431 - round_loss\u001b[A\n",
      "Training:   3%| | 1037/40960 [00:04<01:42, 388.95batches/s, l2_loss: 0.1415 - round_loss\u001b[A\n",
      "Training:   3%| | 1116/40960 [00:04<01:42, 390.59batches/s, l2_loss: 0.1415 - round_loss\u001b[A\n",
      "Training:   3%| | 1116/40960 [00:04<01:42, 390.59batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:   3%| | 1195/40960 [00:04<01:41, 391.85batches/s, l2_loss: 0.1403 - round_loss\u001b[A\n",
      "Training:   3%| | 1195/40960 [00:04<01:41, 391.85batches/s, l2_loss: 0.1410 - round_loss\u001b[A\n",
      "Training:   3%| | 1274/40960 [00:04<01:41, 391.26batches/s, l2_loss: 0.1410 - round_loss\u001b[A\n",
      "Training:   3%| | 1274/40960 [00:04<01:41, 391.26batches/s, l2_loss: 0.1395 - round_loss\u001b[A\n",
      "Training:   3%| | 1353/40960 [00:04<01:41, 391.19batches/s, l2_loss: 0.1395 - round_loss\u001b[A\n",
      "Training:   3%| | 1353/40960 [00:04<01:41, 391.19batches/s, l2_loss: 0.1386 - round_loss\u001b[A\n",
      "Training:   3%| | 1433/40960 [00:05<01:40, 392.94batches/s, l2_loss: 0.1386 - round_loss\u001b[A\n",
      "Training:   3%| | 1433/40960 [00:05<01:40, 392.94batches/s, l2_loss: 0.1383 - round_loss\u001b[A\n",
      "Training:   4%| | 1513/40960 [00:05<01:40, 393.83batches/s, l2_loss: 0.1383 - round_loss\u001b[A\n",
      "Training:   4%| | 1513/40960 [00:05<01:40, 393.83batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:   4%| | 1589/40960 [00:05<01:41, 388.71batches/s, l2_loss: 0.1371 - round_loss\u001b[A\n",
      "Training:   4%| | 1589/40960 [00:05<01:41, 388.71batches/s, l2_loss: 0.1367 - round_loss\u001b[A\n",
      "Training:   4%| | 1667/40960 [00:05<01:41, 388.13batches/s, l2_loss: 0.1367 - round_loss\u001b[A\n",
      "Training:   4%| | 1667/40960 [00:05<01:41, 388.13batches/s, l2_loss: 0.1359 - round_loss\u001b[A\n",
      "Training:   4%| | 1744/40960 [00:05<01:41, 386.63batches/s, l2_loss: 0.1359 - round_loss\u001b[A\n",
      "Training:   4%| | 1744/40960 [00:05<01:41, 386.63batches/s, l2_loss: 0.1358 - round_loss\u001b[A\n",
      "Training:   4%| | 1825/40960 [00:06<01:40, 391.30batches/s, l2_loss: 0.1358 - round_loss\u001b[A\n",
      "Training:   4%| | 1825/40960 [00:06<01:40, 391.30batches/s, l2_loss: 0.1348 - round_loss\u001b[A\n",
      "Training:   5%| | 1900/40960 [00:06<01:41, 384.92batches/s, l2_loss: 0.1348 - round_loss\u001b[A\n",
      "Training:   5%| | 1900/40960 [00:06<01:41, 384.92batches/s, l2_loss: 0.1340 - round_loss\u001b[A\n",
      "Training:   5%| | 1978/40960 [00:06<01:40, 386.37batches/s, l2_loss: 0.1340 - round_loss\u001b[A\n",
      "Training:   5%| | 1978/40960 [00:06<01:40, 386.37batches/s, l2_loss: 0.1336 - round_loss\u001b[A\n",
      "Training:   5%| | 2060/40960 [00:06<01:38, 393.26batches/s, l2_loss: 0.1336 - round_loss\u001b[A\n",
      "Training:   5%| | 2060/40960 [00:06<01:38, 393.26batches/s, l2_loss: 0.1334 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 2140/40960 [00:06<01:38, 394.97batches/s, l2_loss: 0.1334 - round_loss\u001b[A\n",
      "Training:   5%| | 2140/40960 [00:06<01:38, 394.97batches/s, l2_loss: 0.1328 - round_loss\u001b[A\n",
      "Training:   5%| | 2218/40960 [00:07<01:38, 393.07batches/s, l2_loss: 0.1328 - round_loss\u001b[A\n",
      "Training:   5%| | 2218/40960 [00:07<01:38, 393.07batches/s, l2_loss: 0.1323 - round_loss\u001b[A\n",
      "Training:   6%| | 2296/40960 [00:07<01:38, 391.89batches/s, l2_loss: 0.1323 - round_loss\u001b[A\n",
      "Training:   6%| | 2296/40960 [00:07<01:38, 391.89batches/s, l2_loss: 0.1318 - round_loss\u001b[A\n",
      "Training:   6%| | 2370/40960 [00:07<01:40, 384.51batches/s, l2_loss: 0.1318 - round_loss\u001b[A\n",
      "Training:   6%| | 2370/40960 [00:07<01:40, 384.51batches/s, l2_loss: 0.1314 - round_loss\u001b[A\n",
      "Training:   6%| | 2448/40960 [00:07<01:39, 386.02batches/s, l2_loss: 0.1314 - round_loss\u001b[A\n",
      "Training:   6%| | 2448/40960 [00:07<01:39, 386.02batches/s, l2_loss: 0.1310 - round_loss\u001b[A\n",
      "Training:   6%| | 2528/40960 [00:07<01:38, 389.31batches/s, l2_loss: 0.1310 - round_loss\u001b[A\n",
      "Training:   6%| | 2528/40960 [00:07<01:38, 389.31batches/s, l2_loss: 0.1308 - round_loss\u001b[A\n",
      "Training:   6%| | 2609/40960 [00:08<01:37, 393.73batches/s, l2_loss: 0.1308 - round_loss\u001b[A\n",
      "Training:   6%| | 2609/40960 [00:08<01:37, 393.73batches/s, l2_loss: 0.1302 - round_loss\u001b[A\n",
      "Training:   7%| | 2687/40960 [00:08<01:37, 391.96batches/s, l2_loss: 0.1302 - round_loss\u001b[A\n",
      "Training:   7%| | 2687/40960 [00:08<01:37, 391.96batches/s, l2_loss: 0.1298 - round_loss\u001b[A\n",
      "Training:   7%| | 2769/40960 [00:08<01:36, 396.79batches/s, l2_loss: 0.1298 - round_loss\u001b[A\n",
      "Training:   7%| | 2769/40960 [00:08<01:36, 396.79batches/s, l2_loss: 0.1296 - round_loss\u001b[A\n",
      "Training:   7%| | 2851/40960 [00:08<01:35, 399.44batches/s, l2_loss: 0.1296 - round_loss\u001b[A\n",
      "Training:   7%| | 2851/40960 [00:08<01:35, 399.44batches/s, l2_loss: 0.1288 - round_loss\u001b[A\n",
      "Training:   7%| | 2928/40960 [00:08<01:36, 394.58batches/s, l2_loss: 0.1288 - round_loss\u001b[A\n",
      "Training:   7%| | 2928/40960 [00:08<01:36, 394.58batches/s, l2_loss: 0.1285 - round_loss\u001b[A\n",
      "Training:   7%| | 3005/40960 [00:09<01:37, 391.14batches/s, l2_loss: 0.1285 - round_loss\u001b[A\n",
      "Training:   7%| | 3005/40960 [00:09<01:37, 391.14batches/s, l2_loss: 0.1285 - round_loss\u001b[A\n",
      "Training:   8%| | 3085/40960 [00:09<01:36, 393.07batches/s, l2_loss: 0.1285 - round_loss\u001b[A\n",
      "Training:   8%| | 3085/40960 [00:09<01:36, 393.07batches/s, l2_loss: 0.1280 - round_loss\u001b[A\n",
      "Training:   8%| | 3164/40960 [00:09<01:36, 393.32batches/s, l2_loss: 0.1280 - round_loss\u001b[A\n",
      "Training:   8%| | 3164/40960 [00:09<01:36, 393.32batches/s, l2_loss: 0.1278 - round_loss\u001b[A\n",
      "Training:   8%| | 3245/40960 [00:09<01:35, 396.21batches/s, l2_loss: 0.1278 - round_loss\u001b[A\n",
      "Training:   8%| | 3245/40960 [00:09<01:35, 396.21batches/s, l2_loss: 0.1272 - round_loss\u001b[A\n",
      "Training:   8%| | 3323/40960 [00:09<01:35, 393.69batches/s, l2_loss: 0.1272 - round_loss\u001b[A\n",
      "Training:   8%| | 3323/40960 [00:09<01:35, 393.69batches/s, l2_loss: 0.1271 - round_loss\u001b[A\n",
      "Training:   8%| | 3404/40960 [00:10<01:34, 395.63batches/s, l2_loss: 0.1271 - round_loss\u001b[A\n",
      "Training:   8%| | 3404/40960 [00:10<01:34, 395.63batches/s, l2_loss: 0.1270 - round_loss\u001b[A\n",
      "Training:   9%| | 3485/40960 [00:10<01:34, 398.15batches/s, l2_loss: 0.1270 - round_loss\u001b[A\n",
      "Training:   9%| | 3485/40960 [00:10<01:34, 398.15batches/s, l2_loss: 0.1265 - round_loss\u001b[A\n",
      "Training:   9%| | 3565/40960 [00:10<01:33, 398.70batches/s, l2_loss: 0.1265 - round_loss\u001b[A\n",
      "Training:   9%| | 3565/40960 [00:10<01:33, 398.70batches/s, l2_loss: 0.1263 - round_loss\u001b[A\n",
      "Training:   9%| | 3646/40960 [00:10<01:33, 399.11batches/s, l2_loss: 0.1263 - round_loss\u001b[A\n",
      "Training:   9%| | 3646/40960 [00:10<01:33, 399.11batches/s, l2_loss: 0.1261 - round_loss\u001b[A\n",
      "Training:   9%| | 3726/40960 [00:10<01:33, 398.10batches/s, l2_loss: 0.1261 - round_loss\u001b[A\n",
      "Training:   9%| | 3726/40960 [00:10<01:33, 398.10batches/s, l2_loss: 0.1257 - round_loss\u001b[A\n",
      "Training:   9%| | 3806/40960 [00:11<01:33, 397.38batches/s, l2_loss: 0.1257 - round_loss\u001b[A\n",
      "Training:   9%| | 3806/40960 [00:11<01:33, 397.38batches/s, l2_loss: 0.1256 - round_loss\u001b[A\n",
      "Training:   9%| | 3885/40960 [00:11<01:33, 395.59batches/s, l2_loss: 0.1256 - round_loss\u001b[A\n",
      "Training:   9%| | 3885/40960 [00:11<01:33, 395.59batches/s, l2_loss: 0.1255 - round_loss\u001b[A\n",
      "Training:  10%| | 3965/40960 [00:11<01:33, 395.68batches/s, l2_loss: 0.1255 - round_loss\u001b[A\n",
      "Training:  10%| | 3965/40960 [00:11<01:33, 395.68batches/s, l2_loss: 0.1251 - round_loss\u001b[A\n",
      "Training:  10%| | 4048/40960 [00:11<01:32, 400.04batches/s, l2_loss: 0.1251 - round_loss\u001b[A\n",
      "Training:  10%| | 4048/40960 [00:11<01:32, 400.04batches/s, l2_loss: 0.1249 - round_loss\u001b[A\n",
      "Training:  10%| | 4129/40960 [00:11<01:31, 401.36batches/s, l2_loss: 0.1249 - round_loss\u001b[A\n",
      "Training:  10%| | 4129/40960 [00:11<01:31, 401.36batches/s, l2_loss: 0.1244 - round_loss\u001b[A\n",
      "Training:  10%| | 4210/40960 [00:12<01:31, 401.92batches/s, l2_loss: 0.1244 - round_loss\u001b[A\n",
      "Training:  10%| | 4210/40960 [00:12<01:31, 401.92batches/s, l2_loss: 0.1242 - round_loss\u001b[A\n",
      "Training:  10%| | 4291/40960 [00:12<01:31, 402.01batches/s, l2_loss: 0.1242 - round_loss\u001b[A\n",
      "Training:  10%| | 4291/40960 [00:12<01:31, 402.01batches/s, l2_loss: 0.1243 - round_loss\u001b[A\n",
      "Training:  11%| | 4374/40960 [00:12<01:30, 404.56batches/s, l2_loss: 0.1243 - round_loss\u001b[A\n",
      "Training:  11%| | 4374/40960 [00:12<01:30, 404.56batches/s, l2_loss: 0.1239 - round_loss\u001b[A\n",
      "Training:  11%| | 4454/40960 [00:12<01:30, 402.34batches/s, l2_loss: 0.1239 - round_loss\u001b[A\n",
      "Training:  11%| | 4454/40960 [00:12<01:30, 402.34batches/s, l2_loss: 0.1236 - round_loss\u001b[A\n",
      "Training:  11%| | 4532/40960 [00:12<01:31, 398.26batches/s, l2_loss: 0.1236 - round_loss\u001b[A\n",
      "Training:  11%| | 4532/40960 [00:12<01:31, 398.26batches/s, l2_loss: 0.1235 - round_loss\u001b[A\n",
      "Training:  11%| | 4611/40960 [00:13<01:31, 397.18batches/s, l2_loss: 0.1235 - round_loss\u001b[A\n",
      "Training:  11%| | 4611/40960 [00:13<01:31, 397.18batches/s, l2_loss: 0.1233 - round_loss\u001b[A\n",
      "Training:  11%| | 4691/40960 [00:13<01:31, 397.61batches/s, l2_loss: 0.1233 - round_loss\u001b[A\n",
      "Training:  11%| | 4691/40960 [00:13<01:31, 397.61batches/s, l2_loss: 0.1231 - round_loss\u001b[A\n",
      "Training:  12%| | 4771/40960 [00:13<01:30, 398.32batches/s, l2_loss: 0.1231 - round_loss\u001b[A\n",
      "Training:  12%| | 4771/40960 [00:13<01:30, 398.32batches/s, l2_loss: 0.1230 - round_loss\u001b[A\n",
      "Training:  12%| | 4849/40960 [00:13<01:31, 395.71batches/s, l2_loss: 0.1230 - round_loss\u001b[A\n",
      "Training:  12%| | 4849/40960 [00:13<01:31, 395.71batches/s, l2_loss: 0.1227 - round_loss\u001b[A\n",
      "Training:  12%| | 4926/40960 [00:13<01:32, 391.48batches/s, l2_loss: 0.1227 - round_loss\u001b[A\n",
      "Training:  12%| | 4926/40960 [00:13<01:32, 391.48batches/s, l2_loss: 0.1226 - round_loss\u001b[A\n",
      "Training:  12%| | 5009/40960 [00:14<01:30, 397.13batches/s, l2_loss: 0.1226 - round_loss\u001b[A\n",
      "Training:  12%| | 5009/40960 [00:14<01:30, 397.13batches/s, l2_loss: 0.1225 - round_loss\u001b[A\n",
      "Training:  12%| | 5091/40960 [00:14<01:29, 400.56batches/s, l2_loss: 0.1225 - round_loss\u001b[A\n",
      "Training:  12%| | 5091/40960 [00:14<01:29, 400.56batches/s, l2_loss: 0.1223 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5172/40960 [00:14<01:29, 400.96batches/s, l2_loss: 0.1223 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5172/40960 [00:14<01:29, 400.96batches/s, l2_loss: 0.1220 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5252/40960 [00:14<01:29, 399.70batches/s, l2_loss: 0.1220 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5252/40960 [00:14<01:29, 399.70batches/s, l2_loss: 0.1219 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5331/40960 [00:14<01:29, 397.51batches/s, l2_loss: 0.1219 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5331/40960 [00:14<01:29, 397.51batches/s, l2_loss: 0.1218 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5412/40960 [00:15<01:29, 398.79batches/s, l2_loss: 0.1218 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5412/40960 [00:15<01:29, 398.79batches/s, l2_loss: 0.1215 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5491/40960 [00:15<01:29, 397.56batches/s, l2_loss: 0.1215 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5491/40960 [00:15<01:29, 397.56batches/s, l2_loss: 0.1215 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5571/40960 [00:15<01:28, 398.17batches/s, l2_loss: 0.1215 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5571/40960 [00:15<01:28, 398.17batches/s, l2_loss: 0.1212 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5649/40960 [00:15<01:29, 394.57batches/s, l2_loss: 0.1212 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|▏| 5649/40960 [00:15<01:29, 394.57batches/s, l2_loss: 0.1211 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5728/40960 [00:15<01:29, 393.33batches/s, l2_loss: 0.1211 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5728/40960 [00:15<01:29, 393.33batches/s, l2_loss: 0.1211 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5806/40960 [00:16<01:29, 391.13batches/s, l2_loss: 0.1211 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5806/40960 [00:16<01:29, 391.13batches/s, l2_loss: 0.1208 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5888/40960 [00:16<01:28, 396.20batches/s, l2_loss: 0.1208 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5888/40960 [00:16<01:28, 396.20batches/s, l2_loss: 0.1207 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5966/40960 [00:16<01:28, 394.18batches/s, l2_loss: 0.1207 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5966/40960 [00:16<01:28, 394.18batches/s, l2_loss: 0.1205 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6044/40960 [00:16<01:28, 392.53batches/s, l2_loss: 0.1205 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6044/40960 [00:16<01:28, 392.53batches/s, l2_loss: 0.1204 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6124/40960 [00:16<01:28, 394.41batches/s, l2_loss: 0.1204 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6124/40960 [00:16<01:28, 394.41batches/s, l2_loss: 0.1203 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6204/40960 [00:17<01:27, 395.55batches/s, l2_loss: 0.1203 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6204/40960 [00:17<01:27, 395.55batches/s, l2_loss: 0.1203 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6284/40960 [00:17<01:27, 396.41batches/s, l2_loss: 0.1203 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6284/40960 [00:17<01:27, 396.41batches/s, l2_loss: 0.1200 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6361/40960 [00:17<01:28, 392.04batches/s, l2_loss: 0.1200 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6361/40960 [00:17<01:28, 392.04batches/s, l2_loss: 0.1198 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6439/40960 [00:17<01:28, 390.25batches/s, l2_loss: 0.1198 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6439/40960 [00:17<01:28, 390.25batches/s, l2_loss: 0.1198 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6521/40960 [00:17<01:26, 395.95batches/s, l2_loss: 0.1198 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6521/40960 [00:17<01:26, 395.95batches/s, l2_loss: 0.1197 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6600/40960 [00:18<01:27, 394.78batches/s, l2_loss: 0.1197 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6600/40960 [00:18<01:27, 394.78batches/s, l2_loss: 0.1196 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6681/40960 [00:18<01:26, 397.58batches/s, l2_loss: 0.1196 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6681/40960 [00:18<01:26, 397.58batches/s, l2_loss: 0.1195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6760/40960 [00:18<01:26, 396.07batches/s, l2_loss: 0.1195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6760/40960 [00:18<01:26, 396.07batches/s, l2_loss: 0.1193 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6842/40960 [00:18<01:25, 398.76batches/s, l2_loss: 0.1193 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6842/40960 [00:18<01:25, 398.76batches/s, l2_loss: 0.1192 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6923/40960 [00:18<01:25, 400.27batches/s, l2_loss: 0.1192 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6923/40960 [00:18<01:25, 400.27batches/s, l2_loss: 0.1191 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7001/40960 [00:19<01:25, 396.89batches/s, l2_loss: 0.1191 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7001/40960 [00:19<01:25, 396.89batches/s, l2_loss: 0.1188 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7081/40960 [00:19<01:25, 397.24batches/s, l2_loss: 0.1188 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7081/40960 [00:19<01:25, 397.24batches/s, l2_loss: 0.1189 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7162/40960 [00:19<01:24, 399.55batches/s, l2_loss: 0.1189 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7162/40960 [00:19<01:24, 399.55batches/s, l2_loss: 0.1188 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7243/40960 [00:19<01:24, 400.25batches/s, l2_loss: 0.1188 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7243/40960 [00:19<01:24, 400.25batches/s, l2_loss: 0.1186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7323/40960 [00:19<01:24, 399.09batches/s, l2_loss: 0.1186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7323/40960 [00:19<01:24, 399.09batches/s, l2_loss: 0.1186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7405/40960 [00:20<01:23, 401.07batches/s, l2_loss: 0.1186 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7405/40960 [00:20<01:23, 401.07batches/s, l2_loss: 0.1184 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7487/40960 [00:20<01:23, 402.77batches/s, l2_loss: 0.1184 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7487/40960 [00:20<01:23, 402.77batches/s, l2_loss: 0.1184 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7568/40960 [00:20<01:22, 402.93batches/s, l2_loss: 0.1184 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7568/40960 [00:20<01:22, 402.93batches/s, l2_loss: 0.1184 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7647/40960 [00:20<01:23, 399.78batches/s, l2_loss: 0.1184 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7647/40960 [00:20<01:23, 399.78batches/s, l2_loss: 0.1182 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7728/40960 [00:20<01:22, 400.72batches/s, l2_loss: 0.1182 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7728/40960 [00:20<01:22, 400.72batches/s, l2_loss: 0.1180 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7809/40960 [00:21<01:22, 400.93batches/s, l2_loss: 0.1180 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7809/40960 [00:21<01:22, 400.93batches/s, l2_loss: 0.1179 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7887/40960 [00:21<01:23, 396.93batches/s, l2_loss: 0.1179 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7887/40960 [00:21<01:23, 396.93batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7967/40960 [00:21<01:23, 396.91batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7967/40960 [00:21<01:23, 396.91batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8042/40960 [00:21<01:24, 390.12batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8042/40960 [00:21<01:24, 390.12batches/s, l2_loss: 0.1176 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8124/40960 [00:21<01:22, 395.80batches/s, l2_loss: 0.1176 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8124/40960 [00:22<01:22, 395.80batches/s, l2_loss: 0.1176 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8200/40960 [00:22<01:23, 390.24batches/s, l2_loss: 0.1176 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8200/40960 [00:22<01:23, 390.24batches/s, l2_loss: 0.1035 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8273/40960 [00:22<01:25, 382.38batches/s, l2_loss: 0.1035 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8273/40960 [00:22<01:25, 382.38batches/s, l2_loss: 0.1237 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8348/40960 [00:22<01:25, 379.32batches/s, l2_loss: 0.1237 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8348/40960 [00:22<01:25, 379.32batches/s, l2_loss: 0.1054 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8426/40960 [00:22<01:25, 381.45batches/s, l2_loss: 0.1054 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8426/40960 [00:22<01:25, 381.45batches/s, l2_loss: 0.1113 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8496/40960 [00:23<01:27, 372.06batches/s, l2_loss: 0.1113 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8496/40960 [00:23<01:27, 372.06batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8571/40960 [00:23<01:27, 371.75batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8571/40960 [00:23<01:27, 371.75batches/s, l2_loss: 0.1107 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8645/40960 [00:23<01:27, 370.12batches/s, l2_loss: 0.1107 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8645/40960 [00:23<01:27, 370.12batches/s, l2_loss: 0.1105 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8721/40960 [00:23<01:26, 372.91batches/s, l2_loss: 0.1105 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8721/40960 [00:23<01:26, 372.91batches/s, l2_loss: 0.1104 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8797/40960 [00:23<01:26, 373.91batches/s, l2_loss: 0.1104 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8797/40960 [00:23<01:26, 373.91batches/s, l2_loss: 0.1117 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8874/40960 [00:24<01:25, 375.87batches/s, l2_loss: 0.1117 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8874/40960 [00:24<01:25, 375.87batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8946/40960 [00:24<01:26, 370.23batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8946/40960 [00:24<01:26, 370.23batches/s, l2_loss: 0.1112 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9017/40960 [00:24<01:27, 365.58batches/s, l2_loss: 0.1112 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9017/40960 [00:24<01:27, 365.58batches/s, l2_loss: 0.1100 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9092/40960 [00:24<01:26, 367.36batches/s, l2_loss: 0.1100 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9092/40960 [00:24<01:26, 367.36batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|▏| 9168/40960 [00:24<01:25, 369.98batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9168/40960 [00:24<01:25, 369.98batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9240/40960 [00:25<01:26, 366.19batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9240/40960 [00:25<01:26, 366.19batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9314/40960 [00:25<01:26, 366.32batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9314/40960 [00:25<01:26, 366.32batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9376/40960 [00:25<01:30, 348.63batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9376/40960 [00:25<01:30, 348.63batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9433/40960 [00:25<01:36, 328.02batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9433/40960 [00:25<01:36, 328.02batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9503/40960 [00:25<01:34, 333.77batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9503/40960 [00:25<01:34, 333.77batches/s, l2_loss: 0.1104 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9574/40960 [00:26<01:32, 339.98batches/s, l2_loss: 0.1104 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9574/40960 [00:26<01:32, 339.98batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9645/40960 [00:26<01:30, 344.38batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9645/40960 [00:26<01:30, 344.38batches/s, l2_loss: 0.1109 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9719/40960 [00:26<01:29, 350.92batches/s, l2_loss: 0.1109 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9719/40960 [00:26<01:29, 350.92batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9770/40960 [00:26<01:37, 321.13batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9770/40960 [00:26<01:37, 321.13batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9840/40960 [00:26<01:34, 328.74batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9840/40960 [00:26<01:34, 328.74batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9913/40960 [00:27<01:31, 338.85batches/s, l2_loss: 0.1108 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9913/40960 [00:27<01:31, 338.85batches/s, l2_loss: 0.1109 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9986/40960 [00:27<01:29, 346.02batches/s, l2_loss: 0.1109 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9986/40960 [00:27<01:29, 346.02batches/s, l2_loss: 0.1106 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10057/40960 [00:27<01:28, 348.15batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  25%|▏| 10057/40960 [00:27<01:28, 348.15batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  25%|▏| 10124/40960 [00:27<01:29, 344.12batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  25%|▏| 10124/40960 [00:27<01:29, 344.12batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  25%|▏| 10178/40960 [00:27<01:35, 320.88batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  25%|▏| 10178/40960 [00:27<01:35, 320.88batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  25%|▏| 10236/40960 [00:28<01:38, 310.77batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  25%|▏| 10236/40960 [00:28<01:38, 310.77batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  25%|▎| 10306/40960 [00:28<01:35, 321.68batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  25%|▎| 10306/40960 [00:28<01:35, 321.68batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  25%|▎| 10377/40960 [00:28<01:32, 331.38batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  25%|▎| 10377/40960 [00:28<01:32, 331.38batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  26%|▎| 10452/40960 [00:28<01:28, 344.27batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  26%|▎| 10452/40960 [00:28<01:28, 344.27batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  26%|▎| 10526/40960 [00:28<01:26, 351.42batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  26%|▎| 10526/40960 [00:28<01:26, 351.42batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  26%|▎| 10602/40960 [00:29<01:24, 359.85batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  26%|▎| 10602/40960 [00:29<01:24, 359.85batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  26%|▎| 10675/40960 [00:29<01:23, 360.79batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  26%|▎| 10675/40960 [00:29<01:23, 360.79batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  26%|▎| 10746/40960 [00:29<01:24, 358.06batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  26%|▎| 10746/40960 [00:29<01:24, 358.06batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  26%|▎| 10821/40960 [00:29<01:23, 361.99batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  26%|▎| 10821/40960 [00:29<01:23, 361.99batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  27%|▎| 10898/40960 [00:29<01:21, 368.16batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  27%|▎| 10898/40960 [00:29<01:21, 368.16batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  27%|▎| 10969/40960 [00:30<01:22, 363.79batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  27%|▎| 10969/40960 [00:30<01:22, 363.79batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  27%|▎| 11038/40960 [00:30<01:23, 356.59batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  27%|▎| 11038/40960 [00:30<01:23, 356.59batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  27%|▎| 11105/40960 [00:30<01:25, 348.76batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  27%|▎| 11105/40960 [00:30<01:25, 348.76batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  27%|▎| 11180/40960 [00:30<01:23, 356.12batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  27%|▎| 11180/40960 [00:30<01:23, 356.12batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  27%|▎| 11253/40960 [00:30<01:23, 357.51batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  27%|▎| 11253/40960 [00:30<01:23, 357.51batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  28%|▎| 11328/40960 [00:31<01:21, 361.50batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  28%|▎| 11328/40960 [00:31<01:21, 361.50batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  28%|▎| 11401/40960 [00:31<01:21, 361.94batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  28%|▎| 11401/40960 [00:31<01:21, 361.94batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  28%|▎| 11470/40960 [00:31<01:23, 354.58batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  28%|▎| 11470/40960 [00:31<01:23, 354.58batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  28%|▎| 11536/40960 [00:31<01:24, 346.60batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  28%|▎| 11536/40960 [00:31<01:24, 346.60batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  28%|▎| 11609/40960 [00:31<01:23, 351.62batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  28%|▎| 11609/40960 [00:31<01:23, 351.62batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  29%|▎| 11683/40960 [00:32<01:22, 355.96batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  29%|▎| 11683/40960 [00:32<01:22, 355.96batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  29%|▎| 11756/40960 [00:32<01:21, 357.67batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  29%|▎| 11756/40960 [00:32<01:21, 357.67batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  29%|▎| 11829/40960 [00:32<01:20, 359.76batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  29%|▎| 11829/40960 [00:32<01:20, 359.76batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  29%|▎| 11905/40960 [00:32<01:19, 365.04batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  29%|▎| 11905/40960 [00:32<01:19, 365.04batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  29%|▎| 11978/40960 [00:32<01:19, 364.35batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  29%|▎| 11978/40960 [00:32<01:19, 364.35batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  29%|▎| 12053/40960 [00:33<01:18, 367.22batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  29%|▎| 12053/40960 [00:33<01:18, 367.22batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  30%|▎| 12119/40960 [00:33<01:21, 355.16batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  30%|▎| 12119/40960 [00:33<01:21, 355.16batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  30%|▎| 12185/40960 [00:33<01:22, 347.40batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  30%|▎| 12185/40960 [00:33<01:22, 347.40batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  30%|▎| 12250/40960 [00:33<01:24, 340.37batches/s, l2_loss: 0.1102 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 12250/40960 [00:33<01:24, 340.37batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  30%|▎| 12320/40960 [00:33<01:23, 342.10batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  30%|▎| 12320/40960 [00:33<01:23, 342.10batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  30%|▎| 12395/40960 [00:34<01:21, 350.97batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  30%|▎| 12395/40960 [00:34<01:21, 350.97batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  30%|▎| 12470/40960 [00:34<01:19, 357.48batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  30%|▎| 12470/40960 [00:34<01:19, 357.48batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  31%|▎| 12545/40960 [00:34<01:18, 362.05batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  31%|▎| 12545/40960 [00:34<01:18, 362.05batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  31%|▎| 12615/40960 [00:34<01:19, 358.08batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  31%|▎| 12615/40960 [00:34<01:19, 358.08batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  31%|▎| 12686/40960 [00:34<01:19, 356.77batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  31%|▎| 12686/40960 [00:34<01:19, 356.77batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  31%|▎| 12753/40960 [00:35<01:20, 349.23batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  31%|▎| 12753/40960 [00:35<01:20, 349.23batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  31%|▎| 12816/40960 [00:35<01:23, 338.15batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  31%|▎| 12816/40960 [00:35<01:23, 338.15batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  31%|▎| 12874/40960 [00:35<01:27, 321.33batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  31%|▎| 12874/40960 [00:35<01:27, 321.33batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  32%|▎| 12941/40960 [00:35<01:26, 324.74batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  32%|▎| 12941/40960 [00:35<01:26, 324.74batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13006/40960 [00:35<01:26, 323.67batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13006/40960 [00:35<01:26, 323.67batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13071/40960 [00:36<01:26, 323.71batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13071/40960 [00:36<01:26, 323.71batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13133/40960 [00:36<01:27, 319.06batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13133/40960 [00:36<01:27, 319.06batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13203/40960 [00:36<01:24, 327.81batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13203/40960 [00:36<01:24, 327.81batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13262/40960 [00:36<01:27, 316.78batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  32%|▎| 13262/40960 [00:36<01:27, 316.78batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  33%|▎| 13322/40960 [00:36<01:28, 310.63batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  33%|▎| 13322/40960 [00:36<01:28, 310.63batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  33%|▎| 13378/40960 [00:37<01:31, 300.44batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  33%|▎| 13378/40960 [00:37<01:31, 300.44batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  33%|▎| 13445/40960 [00:37<01:28, 309.81batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  33%|▎| 13445/40960 [00:37<01:28, 309.81batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  33%|▎| 13505/40960 [00:37<01:29, 306.71batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  33%|▎| 13505/40960 [00:37<01:29, 306.71batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  33%|▎| 13572/40960 [00:37<01:27, 314.07batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  33%|▎| 13572/40960 [00:37<01:27, 314.07batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  33%|▎| 13644/40960 [00:37<01:23, 326.45batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  33%|▎| 13644/40960 [00:37<01:23, 326.45batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  33%|▎| 13708/40960 [00:38<01:24, 322.88batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  33%|▎| 13708/40960 [00:38<01:24, 322.88batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  34%|▎| 13774/40960 [00:38<01:23, 324.49batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  34%|▎| 13774/40960 [00:38<01:23, 324.49batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  34%|▎| 13848/40960 [00:38<01:20, 337.63batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  34%|▎| 13848/40960 [00:38<01:20, 337.63batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  34%|▎| 13923/40960 [00:38<01:17, 347.79batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  34%|▎| 13923/40960 [00:38<01:17, 347.79batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  34%|▎| 13995/40960 [00:38<01:17, 350.08batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  34%|▎| 13995/40960 [00:38<01:17, 350.08batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  34%|▎| 14068/40960 [00:39<01:16, 353.47batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  34%|▎| 14068/40960 [00:39<01:16, 353.47batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  35%|▎| 14139/40960 [00:39<01:16, 352.40batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  35%|▎| 14139/40960 [00:39<01:16, 352.40batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  35%|▎| 14214/40960 [00:39<01:14, 357.98batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  35%|▎| 14214/40960 [00:39<01:14, 357.98batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  35%|▎| 14285/40960 [00:39<01:14, 356.79batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  35%|▎| 14285/40960 [00:39<01:14, 356.79batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  35%|▎| 14361/40960 [00:39<01:13, 363.61batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  35%|▎| 14361/40960 [00:39<01:13, 363.61batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  35%|▎| 14436/40960 [00:40<01:12, 366.33batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  35%|▎| 14436/40960 [00:40<01:12, 366.33batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  35%|▎| 14503/40960 [00:40<01:14, 355.06batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  35%|▎| 14503/40960 [00:40<01:14, 355.06batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  36%|▎| 14564/40960 [00:40<01:17, 338.99batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  36%|▎| 14564/40960 [00:40<01:17, 338.99batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  36%|▎| 14633/40960 [00:40<01:17, 340.33batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  36%|▎| 14633/40960 [00:40<01:17, 340.33batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  36%|▎| 14706/40960 [00:40<01:15, 347.56batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  36%|▎| 14706/40960 [00:40<01:15, 347.56batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  36%|▎| 14781/40960 [00:41<01:13, 354.78batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  36%|▎| 14781/40960 [00:41<01:13, 354.78batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  36%|▎| 14857/40960 [00:41<01:12, 361.17batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  36%|▎| 14857/40960 [00:41<01:12, 361.17batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  36%|▎| 14933/40960 [00:41<01:11, 366.30batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  36%|▎| 14933/40960 [00:41<01:11, 366.30batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15009/40960 [00:41<01:10, 369.48batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15009/40960 [00:41<01:10, 369.48batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15078/40960 [00:41<01:11, 361.99batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15078/40960 [00:41<01:11, 361.99batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15146/40960 [00:42<01:12, 355.26batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15146/40960 [00:42<01:12, 355.26batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15216/40960 [00:42<01:12, 353.18batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15216/40960 [00:42<01:12, 353.18batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  37%|▎| 15284/40960 [00:42<01:13, 348.72batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  37%|▎| 15284/40960 [00:42<01:13, 348.72batches/s, l2_loss: 0.1101 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15356/40960 [00:42<01:12, 351.71batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  37%|▎| 15356/40960 [00:42<01:12, 351.71batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  38%|▍| 15429/40960 [00:42<01:11, 354.81batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  38%|▍| 15429/40960 [00:42<01:11, 354.81batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  38%|▍| 15497/40960 [00:43<01:12, 349.68batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  38%|▍| 15497/40960 [00:43<01:12, 349.68batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  38%|▍| 15566/40960 [00:43<01:13, 347.49batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  38%|▍| 15566/40960 [00:43<01:13, 347.49batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  38%|▍| 15633/40960 [00:43<01:13, 343.00batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  38%|▍| 15633/40960 [00:43<01:13, 343.00batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  38%|▍| 15709/40960 [00:43<01:11, 352.70batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  38%|▍| 15709/40960 [00:43<01:11, 352.70batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  39%|▍| 15785/40960 [00:43<01:09, 360.49batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  39%|▍| 15785/40960 [00:43<01:09, 360.49batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  39%|▍| 15851/40960 [00:44<01:11, 351.24batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  39%|▍| 15851/40960 [00:44<01:11, 351.24batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  39%|▍| 15924/40960 [00:44<01:10, 354.72batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  39%|▍| 15924/40960 [00:44<01:10, 354.72batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  39%|▍| 15996/40960 [00:44<01:10, 355.06batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  39%|▍| 15996/40960 [00:44<01:10, 355.06batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16070/40960 [00:44<01:09, 358.68batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16070/40960 [00:44<01:09, 358.68batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16140/40960 [00:44<01:09, 354.95batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16140/40960 [00:44<01:09, 354.95batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16215/40960 [00:45<01:08, 359.58batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16215/40960 [00:45<01:08, 359.58batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  40%|▍| 16288/40960 [00:45<01:08, 361.08batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  40%|▍| 16288/40960 [00:45<01:08, 361.08batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16363/40960 [00:45<01:07, 364.38batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16363/40960 [00:45<01:07, 364.38batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  40%|▍| 16439/40960 [00:45<01:06, 367.94batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  40%|▍| 16439/40960 [00:45<01:06, 367.94batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  40%|▍| 16512/40960 [00:45<01:06, 366.93batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  40%|▍| 16512/40960 [00:45<01:06, 366.93batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16587/40960 [00:46<01:06, 368.12batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16587/40960 [00:46<01:06, 368.12batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16661/40960 [00:46<01:06, 368.02batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16661/40960 [00:46<01:06, 368.02batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16735/40960 [00:46<01:05, 367.64batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16735/40960 [00:46<01:05, 367.64batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16811/40960 [00:46<01:05, 370.03batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16811/40960 [00:46<01:05, 370.03batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  41%|▍| 16885/40960 [00:46<01:05, 369.90batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  41%|▍| 16885/40960 [00:46<01:05, 369.90batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  41%|▍| 16944/40960 [00:47<01:09, 345.75batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  41%|▍| 16944/40960 [00:47<01:09, 345.75batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17010/40960 [00:47<01:10, 340.97batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17010/40960 [00:47<01:10, 340.97batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17087/40960 [00:47<01:07, 353.20batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17087/40960 [00:47<01:07, 353.20batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17164/40960 [00:47<01:05, 362.50batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17164/40960 [00:47<01:05, 362.50batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17236/40960 [00:47<01:05, 361.69batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17236/40960 [00:47<01:05, 361.69batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17303/40960 [00:48<01:06, 353.37batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17303/40960 [00:48<01:06, 353.37batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17375/40960 [00:48<01:06, 354.18batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17375/40960 [00:48<01:06, 354.18batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17450/40960 [00:48<01:05, 360.30batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17450/40960 [00:48<01:05, 360.30batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17523/40960 [00:48<01:05, 360.35batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17523/40960 [00:48<01:05, 360.35batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17592/40960 [00:49<01:05, 354.90batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17592/40960 [00:49<01:05, 354.90batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17666/40960 [00:49<01:05, 357.82batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17666/40960 [00:49<01:05, 357.82batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17739/40960 [00:49<01:04, 358.72batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17739/40960 [00:49<01:04, 358.72batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17814/40960 [00:49<01:03, 362.76batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  43%|▍| 17814/40960 [00:49<01:03, 362.76batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  44%|▍| 17885/40960 [00:49<01:04, 358.50batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  44%|▍| 17885/40960 [00:49<01:04, 358.50batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  44%|▍| 17952/40960 [00:50<01:05, 351.38batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  44%|▍| 17952/40960 [00:50<01:05, 351.38batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18018/40960 [00:50<01:06, 344.96batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18018/40960 [00:50<01:06, 344.96batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  44%|▍| 18092/40960 [00:50<01:04, 351.97batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  44%|▍| 18092/40960 [00:50<01:04, 351.97batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18166/40960 [00:50<01:03, 356.66batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18166/40960 [00:50<01:03, 356.66batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18242/40960 [00:50<01:02, 362.55batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18242/40960 [00:50<01:02, 362.55batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  45%|▍| 18313/40960 [00:51<01:03, 359.13batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  45%|▍| 18313/40960 [00:51<01:03, 359.13batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18384/40960 [00:51<01:03, 357.26batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18384/40960 [00:51<01:03, 357.26batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18456/40960 [00:51<01:03, 357.12batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18456/40960 [00:51<01:03, 357.12batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18523/40960 [00:51<01:04, 348.68batches/s, l2_loss: 0.1100 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 18523/40960 [00:51<01:04, 348.68batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18594/40960 [00:51<01:04, 349.29batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  45%|▍| 18594/40960 [00:51<01:04, 349.29batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  46%|▍| 18666/40960 [00:52<01:03, 352.18batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  46%|▍| 18666/40960 [00:52<01:03, 352.18batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  46%|▍| 18735/40960 [00:52<01:03, 349.61batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  46%|▍| 18735/40960 [00:52<01:03, 349.61batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  46%|▍| 18806/40960 [00:52<01:03, 350.67batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  46%|▍| 18806/40960 [00:52<01:03, 350.67batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  46%|▍| 18869/40960 [00:52<01:05, 338.03batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  46%|▍| 18869/40960 [00:52<01:05, 338.03batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  46%|▍| 18916/40960 [00:52<01:11, 306.51batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  46%|▍| 18916/40960 [00:52<01:11, 306.51batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  46%|▍| 18970/40960 [00:53<01:15, 293.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  46%|▍| 18970/40960 [00:53<01:15, 293.15batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  46%|▍| 19023/40960 [00:53<01:17, 282.81batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  46%|▍| 19023/40960 [00:53<01:17, 282.81batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  47%|▍| 19082/40960 [00:53<01:16, 285.37batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  47%|▍| 19082/40960 [00:53<01:16, 285.37batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19155/40960 [00:53<01:10, 308.66batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19155/40960 [00:53<01:10, 308.66batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19218/40960 [00:53<01:10, 309.05batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19218/40960 [00:53<01:10, 309.05batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19291/40960 [00:54<01:06, 324.99batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19291/40960 [00:54<01:06, 324.99batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19360/40960 [00:54<01:05, 330.05batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19360/40960 [00:54<01:05, 330.05batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19431/40960 [00:54<01:03, 336.45batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  47%|▍| 19431/40960 [00:54<01:03, 336.45batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19504/40960 [00:54<01:02, 343.78batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19504/40960 [00:54<01:02, 343.78batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19577/40960 [00:54<01:01, 350.02batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19577/40960 [00:54<01:01, 350.02batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19653/40960 [00:55<00:59, 358.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19653/40960 [00:55<00:59, 358.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19717/40960 [00:55<01:01, 345.64batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19717/40960 [00:55<01:01, 345.64batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19786/40960 [00:55<01:01, 345.03batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19786/40960 [00:55<01:01, 345.03batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19859/40960 [00:55<01:00, 350.74batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  48%|▍| 19859/40960 [00:55<01:00, 350.74batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  49%|▍| 19934/40960 [00:55<00:58, 357.47batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  49%|▍| 19934/40960 [00:55<00:58, 357.47batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  49%|▍| 20009/40960 [00:56<00:57, 361.61batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  49%|▍| 20009/40960 [00:56<00:57, 361.61batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  49%|▍| 20083/40960 [00:56<00:57, 363.14batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  49%|▍| 20083/40960 [00:56<00:57, 363.14batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  49%|▍| 20160/40960 [00:56<00:56, 369.57batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  49%|▍| 20160/40960 [00:56<00:56, 369.57batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  49%|▍| 20232/40960 [00:56<00:56, 365.06batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  49%|▍| 20232/40960 [00:56<00:56, 365.06batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▍| 20308/40960 [00:56<00:56, 368.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▍| 20308/40960 [00:56<00:56, 368.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▍| 20384/40960 [00:57<00:55, 370.45batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▍| 20384/40960 [00:57<00:55, 370.45batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▍| 20454/40960 [00:57<00:56, 363.63batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▍| 20454/40960 [00:57<00:56, 363.63batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  50%|▌| 20521/40960 [00:57<00:57, 354.76batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  50%|▌| 20521/40960 [00:57<00:57, 354.76batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▌| 20595/40960 [00:57<00:56, 358.68batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▌| 20595/40960 [00:57<00:56, 358.68batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▌| 20665/40960 [00:57<00:57, 355.80batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  50%|▌| 20665/40960 [00:57<00:57, 355.80batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  51%|▌| 20740/40960 [00:58<00:55, 361.45batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  51%|▌| 20740/40960 [00:58<00:55, 361.45batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  51%|▌| 20813/40960 [00:58<00:55, 362.13batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  51%|▌| 20813/40960 [00:58<00:55, 362.13batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  51%|▌| 20886/40960 [00:58<00:55, 362.35batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  51%|▌| 20886/40960 [00:58<00:55, 362.35batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  51%|▌| 20961/40960 [00:58<00:54, 365.72batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  51%|▌| 20961/40960 [00:58<00:54, 365.72batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  51%|▌| 21035/40960 [00:58<00:54, 365.90batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  51%|▌| 21035/40960 [00:58<00:54, 365.90batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  52%|▌| 21102/40960 [00:59<00:55, 355.35batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  52%|▌| 21102/40960 [00:59<00:55, 355.35batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  52%|▌| 21177/40960 [00:59<00:54, 360.56batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  52%|▌| 21177/40960 [00:59<00:54, 360.56batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  52%|▌| 21253/40960 [00:59<00:53, 365.37batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  52%|▌| 21253/40960 [00:59<00:53, 365.37batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  52%|▌| 21325/40960 [00:59<00:54, 362.91batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  52%|▌| 21325/40960 [00:59<00:54, 362.91batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  52%|▌| 21398/40960 [00:59<00:54, 362.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  52%|▌| 21398/40960 [00:59<00:54, 362.15batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  52%|▌| 21469/40960 [01:00<00:54, 359.18batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  52%|▌| 21469/40960 [01:00<00:54, 359.18batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21542/40960 [01:00<00:53, 360.41batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21542/40960 [01:00<00:53, 360.41batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21618/40960 [01:00<00:52, 365.75batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21618/40960 [01:00<00:52, 365.75batches/s, l2_loss: 0.1102 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|▌| 21688/40960 [01:00<00:53, 360.94batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21688/40960 [01:00<00:53, 360.94batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21758/40960 [01:00<00:53, 357.51batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21758/40960 [01:00<00:53, 357.51batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21833/40960 [01:01<00:52, 362.24batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  53%|▌| 21833/40960 [01:01<00:52, 362.24batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  53%|▌| 21903/40960 [01:01<00:53, 358.22batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  53%|▌| 21903/40960 [01:01<00:53, 358.22batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  54%|▌| 21977/40960 [01:01<00:52, 361.38batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  54%|▌| 21977/40960 [01:01<00:52, 361.38batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  54%|▌| 22052/40960 [01:01<00:51, 365.38batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  54%|▌| 22052/40960 [01:01<00:51, 365.38batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  54%|▌| 22123/40960 [01:01<00:52, 361.32batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  54%|▌| 22123/40960 [01:01<00:52, 361.32batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  54%|▌| 22198/40960 [01:02<00:51, 364.08batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  54%|▌| 22198/40960 [01:02<00:51, 364.08batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  54%|▌| 22270/40960 [01:02<00:51, 362.30batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  54%|▌| 22270/40960 [01:02<00:51, 362.30batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  55%|▌| 22342/40960 [01:02<00:51, 360.14batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  55%|▌| 22342/40960 [01:02<00:51, 360.14batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22412/40960 [01:02<00:52, 356.65batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22412/40960 [01:02<00:52, 356.65batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22485/40960 [01:02<00:51, 358.19batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22485/40960 [01:02<00:51, 358.19batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22560/40960 [01:03<00:50, 362.59batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22560/40960 [01:03<00:50, 362.59batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22634/40960 [01:03<00:50, 364.74batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22634/40960 [01:03<00:50, 364.74batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22708/40960 [01:03<00:49, 365.39batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  55%|▌| 22708/40960 [01:03<00:49, 365.39batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 22783/40960 [01:03<00:49, 367.65batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 22783/40960 [01:03<00:49, 367.65batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 22854/40960 [01:03<00:49, 362.97batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 22854/40960 [01:03<00:49, 362.97batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 22924/40960 [01:04<00:50, 357.63batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 22924/40960 [01:04<00:50, 357.63batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 22995/40960 [01:04<00:50, 355.34batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 22995/40960 [01:04<00:50, 355.34batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  56%|▌| 23066/40960 [01:04<00:50, 355.05batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  56%|▌| 23066/40960 [01:04<00:50, 355.05batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 23142/40960 [01:04<00:49, 361.45batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  56%|▌| 23142/40960 [01:04<00:49, 361.45batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23216/40960 [01:04<00:48, 363.06batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23216/40960 [01:04<00:48, 363.06batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23292/40960 [01:05<00:48, 367.85batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23292/40960 [01:05<00:48, 367.85batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23368/40960 [01:05<00:47, 370.78batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23368/40960 [01:05<00:47, 370.78batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23442/40960 [01:05<00:47, 369.10batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23442/40960 [01:05<00:47, 369.10batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23517/40960 [01:05<00:47, 370.15batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  57%|▌| 23517/40960 [01:05<00:47, 370.15batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23591/40960 [01:05<00:46, 369.64batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23591/40960 [01:05<00:46, 369.64batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23668/40960 [01:06<00:46, 372.91batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23668/40960 [01:06<00:46, 372.91batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23742/40960 [01:06<00:46, 372.04batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23742/40960 [01:06<00:46, 372.04batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23812/40960 [01:06<00:47, 364.11batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23812/40960 [01:06<00:47, 364.11batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23888/40960 [01:06<00:46, 368.37batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  58%|▌| 23888/40960 [01:06<00:46, 368.37batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  59%|▌| 23962/40960 [01:06<00:46, 368.43batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  59%|▌| 23962/40960 [01:06<00:46, 368.43batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  59%|▌| 24036/40960 [01:07<00:46, 367.70batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  59%|▌| 24036/40960 [01:07<00:46, 367.70batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  59%|▌| 24110/40960 [01:07<00:45, 367.97batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  59%|▌| 24110/40960 [01:07<00:45, 367.97batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  59%|▌| 24184/40960 [01:07<00:45, 367.43batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  59%|▌| 24184/40960 [01:07<00:45, 367.43batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  59%|▌| 24256/40960 [01:07<00:45, 363.91batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  59%|▌| 24256/40960 [01:07<00:45, 363.91batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  59%|▌| 24323/40960 [01:07<00:47, 352.52batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  59%|▌| 24323/40960 [01:07<00:47, 352.52batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24389/40960 [01:08<00:47, 345.63batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24389/40960 [01:08<00:47, 345.63batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  60%|▌| 24462/40960 [01:08<00:46, 351.14batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  60%|▌| 24462/40960 [01:08<00:46, 351.14batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24536/40960 [01:08<00:46, 355.56batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24536/40960 [01:08<00:46, 355.56batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24610/40960 [01:08<00:45, 359.08batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24610/40960 [01:08<00:45, 359.08batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24685/40960 [01:08<00:44, 362.69batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24685/40960 [01:08<00:44, 362.69batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24755/40960 [01:09<00:45, 356.78batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  60%|▌| 24755/40960 [01:09<00:45, 356.78batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [01:09<00:45, 355.34batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [01:09<00:45, 355.34batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  61%|▌| 24897/40960 [01:09<00:45, 354.01batches/s, l2_loss: 0.1105 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 24897/40960 [01:09<00:45, 354.01batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  61%|▌| 24972/40960 [01:09<00:44, 359.33batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  61%|▌| 24972/40960 [01:09<00:44, 359.33batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  61%|▌| 25041/40960 [01:09<00:45, 353.67batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  61%|▌| 25041/40960 [01:09<00:45, 353.67batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  61%|▌| 25112/40960 [01:10<00:44, 353.05batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  61%|▌| 25112/40960 [01:10<00:44, 353.05batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  61%|▌| 25172/40960 [01:10<00:47, 335.75batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  61%|▌| 25172/40960 [01:10<00:47, 335.75batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25231/40960 [01:10<00:48, 321.64batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25231/40960 [01:10<00:48, 321.64batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25290/40960 [01:10<00:49, 313.65batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25290/40960 [01:10<00:49, 313.65batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25361/40960 [01:10<00:47, 325.77batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25361/40960 [01:10<00:47, 325.77batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25424/40960 [01:11<00:48, 321.33batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25424/40960 [01:11<00:48, 321.33batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25491/40960 [01:11<00:47, 325.28batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  62%|▌| 25491/40960 [01:11<00:47, 325.28batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  62%|▌| 25566/40960 [01:11<00:45, 338.52batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  62%|▌| 25566/40960 [01:11<00:45, 338.52batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 25641/40960 [01:11<00:43, 349.33batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 25641/40960 [01:11<00:43, 349.33batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  63%|▋| 25714/40960 [01:11<00:43, 353.12batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  63%|▋| 25714/40960 [01:11<00:43, 353.12batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 25787/40960 [01:12<00:42, 355.76batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 25787/40960 [01:12<00:42, 355.76batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 25855/40960 [01:12<00:43, 350.07batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 25855/40960 [01:12<00:43, 350.07batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 25930/40960 [01:12<00:42, 357.17batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 25930/40960 [01:12<00:42, 357.17batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 26004/40960 [01:12<00:41, 360.92batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  63%|▋| 26004/40960 [01:12<00:41, 360.92batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  64%|▋| 26078/40960 [01:12<00:41, 362.84batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  64%|▋| 26078/40960 [01:12<00:41, 362.84batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  64%|▋| 26153/40960 [01:13<00:40, 366.24batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  64%|▋| 26153/40960 [01:13<00:40, 366.24batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  64%|▋| 26227/40960 [01:13<00:40, 366.63batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  64%|▋| 26227/40960 [01:13<00:40, 366.63batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  64%|▋| 26298/40960 [01:13<00:40, 362.33batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  64%|▋| 26298/40960 [01:13<00:40, 362.33batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  64%|▋| 26368/40960 [01:13<00:40, 357.04batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  64%|▋| 26368/40960 [01:13<00:40, 357.04batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  65%|▋| 26440/40960 [01:14<00:40, 356.91batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  65%|▋| 26440/40960 [01:14<00:40, 356.91batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  65%|▋| 26506/40960 [01:14<00:41, 347.95batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  65%|▋| 26506/40960 [01:14<00:41, 347.95batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  65%|▋| 26579/40960 [01:14<00:40, 351.56batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  65%|▋| 26579/40960 [01:14<00:40, 351.56batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  65%|▋| 26654/40960 [01:14<00:39, 357.80batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  65%|▋| 26654/40960 [01:14<00:39, 357.80batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  65%|▋| 26731/40960 [01:14<00:39, 364.59batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  65%|▋| 26731/40960 [01:14<00:39, 364.59batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  65%|▋| 26809/40960 [01:15<00:38, 372.06batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  65%|▋| 26809/40960 [01:15<00:38, 372.06batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 26885/40960 [01:15<00:37, 373.56batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 26885/40960 [01:15<00:37, 373.56batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 26958/40960 [01:15<00:37, 370.27batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 26958/40960 [01:15<00:37, 370.27batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 27032/40960 [01:15<00:37, 368.90batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 27032/40960 [01:15<00:37, 368.90batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 27105/40960 [01:15<00:37, 367.46batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 27105/40960 [01:15<00:37, 367.46batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 27174/40960 [01:16<00:38, 360.74batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  66%|▋| 27174/40960 [01:16<00:38, 360.74batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27246/40960 [01:16<00:38, 360.41batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27246/40960 [01:16<00:38, 360.41batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27322/40960 [01:16<00:37, 365.88batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27322/40960 [01:16<00:37, 365.88batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27394/40960 [01:16<00:37, 363.44batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27394/40960 [01:16<00:37, 363.44batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27463/40960 [01:16<00:37, 356.52batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27463/40960 [01:16<00:37, 356.52batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  67%|▋| 27536/40960 [01:17<00:37, 358.25batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  67%|▋| 27536/40960 [01:17<00:37, 358.25batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27607/40960 [01:17<00:37, 356.18batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  67%|▋| 27607/40960 [01:17<00:37, 356.18batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27679/40960 [01:17<00:37, 356.42batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27679/40960 [01:17<00:37, 356.42batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27752/40960 [01:17<00:36, 357.71batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27752/40960 [01:17<00:36, 357.71batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27828/40960 [01:17<00:36, 363.79batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27828/40960 [01:17<00:36, 363.79batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27903/40960 [01:18<00:35, 366.53batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27903/40960 [01:18<00:35, 366.53batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27961/40960 [01:18<00:38, 341.13batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 27961/40960 [01:18<00:38, 341.13batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 28007/40960 [01:18<00:42, 306.12batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  68%|▋| 28007/40960 [01:18<00:42, 306.12batches/s, l2_loss: 0.1111 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|▋| 28080/40960 [01:18<00:39, 323.11batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  69%|▋| 28080/40960 [01:18<00:39, 323.11batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  69%|▋| 28154/40960 [01:18<00:38, 336.79batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  69%|▋| 28154/40960 [01:18<00:38, 336.79batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  69%|▋| 28229/40960 [01:19<00:36, 347.02batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  69%|▋| 28229/40960 [01:19<00:36, 347.02batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  69%|▋| 28299/40960 [01:19<00:36, 347.56batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  69%|▋| 28299/40960 [01:19<00:36, 347.56batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  69%|▋| 28371/40960 [01:19<00:35, 350.31batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  69%|▋| 28371/40960 [01:19<00:35, 350.31batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  69%|▋| 28444/40960 [01:19<00:35, 353.79batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  69%|▋| 28444/40960 [01:19<00:35, 353.79batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  70%|▋| 28515/40960 [01:19<00:35, 353.10batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  70%|▋| 28515/40960 [01:19<00:35, 353.10batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28587/40960 [01:20<00:34, 354.58batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28587/40960 [01:20<00:34, 354.58batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28661/40960 [01:20<00:34, 358.79batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28661/40960 [01:20<00:34, 358.79batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28735/40960 [01:20<00:33, 361.17batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28735/40960 [01:20<00:33, 361.17batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28810/40960 [01:20<00:33, 365.04batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  70%|▋| 28810/40960 [01:20<00:33, 365.04batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  71%|▋| 28884/40960 [01:20<00:33, 365.45batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  71%|▋| 28884/40960 [01:20<00:33, 365.45batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  71%|▋| 28960/40960 [01:21<00:32, 369.67batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  71%|▋| 28960/40960 [01:21<00:32, 369.67batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29032/40960 [01:21<00:32, 366.31batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29032/40960 [01:21<00:32, 366.31batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29106/40960 [01:21<00:32, 366.74batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29106/40960 [01:21<00:32, 366.74batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29182/40960 [01:21<00:31, 369.58batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29182/40960 [01:21<00:31, 369.58batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29252/40960 [01:21<00:32, 362.85batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  71%|▋| 29252/40960 [01:21<00:32, 362.85batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29326/40960 [01:22<00:31, 364.04batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29326/40960 [01:22<00:31, 364.04batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29399/40960 [01:22<00:31, 363.40batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29399/40960 [01:22<00:31, 363.40batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29474/40960 [01:22<00:31, 365.41batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29474/40960 [01:22<00:31, 365.41batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29547/40960 [01:22<00:31, 364.12batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29547/40960 [01:22<00:31, 364.12batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  72%|▋| 29616/40960 [01:22<00:31, 358.34batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  72%|▋| 29616/40960 [01:22<00:31, 358.34batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29689/40960 [01:23<00:31, 358.30batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  72%|▋| 29689/40960 [01:23<00:31, 358.30batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  73%|▋| 29763/40960 [01:23<00:31, 361.08batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  73%|▋| 29763/40960 [01:23<00:31, 361.08batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  73%|▋| 29836/40960 [01:23<00:30, 361.29batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  73%|▋| 29836/40960 [01:23<00:30, 361.29batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  73%|▋| 29913/40960 [01:23<00:30, 367.14batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  73%|▋| 29913/40960 [01:23<00:30, 367.14batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  73%|▋| 29990/40960 [01:23<00:29, 371.78batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  73%|▋| 29990/40960 [01:23<00:29, 371.78batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  73%|▋| 30066/40960 [01:24<00:29, 372.93batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  73%|▋| 30066/40960 [01:24<00:29, 372.93batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  74%|▋| 30132/40960 [01:24<00:30, 359.99batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  74%|▋| 30132/40960 [01:24<00:30, 359.99batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  74%|▋| 30206/40960 [01:24<00:29, 362.43batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  74%|▋| 30206/40960 [01:24<00:29, 362.43batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  74%|▋| 30281/40960 [01:24<00:29, 365.46batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  74%|▋| 30281/40960 [01:24<00:29, 365.46batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  74%|▋| 30348/40960 [01:24<00:29, 355.67batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  74%|▋| 30348/40960 [01:24<00:29, 355.67batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  74%|▋| 30409/40960 [01:25<00:31, 339.66batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  74%|▋| 30409/40960 [01:25<00:31, 339.66batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  74%|▋| 30474/40960 [01:25<00:31, 334.06batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  74%|▋| 30474/40960 [01:25<00:31, 334.06batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  75%|▋| 30542/40960 [01:25<00:31, 335.79batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  75%|▋| 30542/40960 [01:25<00:31, 335.79batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  75%|▋| 30611/40960 [01:25<00:30, 337.88batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  75%|▋| 30611/40960 [01:25<00:30, 337.88batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  75%|▋| 30687/40960 [01:25<00:29, 349.47batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  75%|▋| 30687/40960 [01:25<00:29, 349.47batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  75%|▊| 30763/40960 [01:26<00:28, 357.89batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  75%|▊| 30763/40960 [01:26<00:28, 357.89batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  75%|▊| 30837/40960 [01:26<00:28, 360.59batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  75%|▊| 30837/40960 [01:26<00:28, 360.59batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  75%|▊| 30912/40960 [01:26<00:27, 364.61batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  75%|▊| 30912/40960 [01:26<00:27, 364.61batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  76%|▊| 30982/40960 [01:26<00:27, 360.15batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  76%|▊| 30982/40960 [01:26<00:27, 360.15batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  76%|▊| 31057/40960 [01:26<00:27, 363.71batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  76%|▊| 31057/40960 [01:26<00:27, 363.71batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  76%|▊| 31132/40960 [01:27<00:26, 366.52batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  76%|▊| 31132/40960 [01:27<00:26, 366.52batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  76%|▊| 31206/40960 [01:27<00:26, 367.31batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  76%|▊| 31206/40960 [01:27<00:26, 367.31batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  76%|▊| 31280/40960 [01:27<00:26, 366.86batches/s, l2_loss: 0.1121 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31280/40960 [01:27<00:26, 366.86batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  77%|▊| 31353/40960 [01:27<00:26, 365.87batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  77%|▊| 31353/40960 [01:27<00:26, 365.87batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  77%|▊| 31428/40960 [01:27<00:25, 367.23batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  77%|▊| 31428/40960 [01:27<00:25, 367.23batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  77%|▊| 31501/40960 [01:28<00:25, 365.45batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  77%|▊| 31501/40960 [01:28<00:25, 365.45batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  77%|▊| 31571/40960 [01:28<00:26, 360.13batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  77%|▊| 31571/40960 [01:28<00:26, 360.13batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  77%|▊| 31643/40960 [01:28<00:25, 360.01batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  77%|▊| 31643/40960 [01:28<00:25, 360.01batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  77%|▊| 31718/40960 [01:28<00:25, 363.11batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  77%|▊| 31718/40960 [01:28<00:25, 363.11batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  78%|▊| 31786/40960 [01:28<00:25, 355.95batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  78%|▊| 31786/40960 [01:28<00:25, 355.95batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 31841/40960 [01:29<00:27, 329.09batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 31841/40960 [01:29<00:27, 329.09batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 31907/40960 [01:29<00:27, 328.72batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 31907/40960 [01:29<00:27, 328.72batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 31981/40960 [01:29<00:26, 340.63batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 31981/40960 [01:29<00:26, 340.63batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 32055/40960 [01:29<00:25, 349.36batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 32055/40960 [01:29<00:25, 349.36batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 32116/40960 [01:29<00:26, 332.83batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  78%|▊| 32116/40960 [01:29<00:26, 332.83batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  79%|▊| 32186/40960 [01:30<00:25, 337.55batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  79%|▊| 32186/40960 [01:30<00:25, 337.55batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  79%|▊| 32252/40960 [01:30<00:26, 333.92batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  79%|▊| 32252/40960 [01:30<00:26, 333.92batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  79%|▊| 32307/40960 [01:30<00:27, 313.58batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  79%|▊| 32307/40960 [01:30<00:27, 313.58batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  79%|▊| 32379/40960 [01:30<00:26, 326.18batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  79%|▊| 32379/40960 [01:30<00:26, 326.18batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training:  79%|▊| 32453/40960 [01:30<00:25, 337.40batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training:  79%|▊| 32453/40960 [01:30<00:25, 337.40batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training:  79%|▊| 32521/40960 [01:31<00:25, 336.64batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training:  79%|▊| 32521/40960 [01:31<00:25, 336.64batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32593/40960 [01:31<00:24, 343.46batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32593/40960 [01:31<00:24, 343.46batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32667/40960 [01:31<00:23, 350.50batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32667/40960 [01:31<00:23, 350.50batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32741/40960 [01:31<00:23, 355.67batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  80%|▊| 32741/40960 [01:31<00:23, 355.67batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32814/40960 [01:31<00:22, 358.31batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32814/40960 [01:31<00:22, 358.31batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32889/40960 [01:32<00:22, 361.58batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32889/40960 [01:32<00:22, 361.58batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32965/40960 [01:32<00:21, 365.80batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32965/40960 [01:32<00:21, 365.80batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  81%|▊| 33041/40960 [01:32<00:21, 369.05batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  81%|▊| 33041/40960 [01:32<00:21, 369.05batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  81%|▊| 33111/40960 [01:32<00:21, 363.04batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  81%|▊| 33111/40960 [01:32<00:21, 363.04batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  81%|▊| 33183/40960 [01:32<00:21, 361.66batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  81%|▊| 33183/40960 [01:32<00:21, 361.66batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  81%|▊| 33254/40960 [01:33<00:21, 359.29batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  81%|▊| 33254/40960 [01:33<00:21, 359.29batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  81%|▊| 33325/40960 [01:33<00:21, 357.72batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  81%|▊| 33325/40960 [01:33<00:21, 357.72batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  82%|▊| 33399/40960 [01:33<00:20, 361.30batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  82%|▊| 33399/40960 [01:33<00:20, 361.30batches/s, l2_loss: 0.1131 - round_los\u001b[A\n",
      "Training:  82%|▊| 33473/40960 [01:33<00:20, 362.65batches/s, l2_loss: 0.1131 - round_los\u001b[A\n",
      "Training:  82%|▊| 33473/40960 [01:33<00:20, 362.65batches/s, l2_loss: 0.1131 - round_los\u001b[A\n",
      "Training:  82%|▊| 33544/40960 [01:33<00:20, 360.00batches/s, l2_loss: 0.1131 - round_los\u001b[A\n",
      "Training:  82%|▊| 33544/40960 [01:33<00:20, 360.00batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33616/40960 [01:34<00:20, 358.31batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33616/40960 [01:34<00:20, 358.31batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33685/40960 [01:34<00:20, 353.86batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33685/40960 [01:34<00:20, 353.86batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33762/40960 [01:34<00:19, 363.03batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33762/40960 [01:34<00:19, 363.03batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  83%|▊| 33834/40960 [01:34<00:19, 360.26batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  83%|▊| 33834/40960 [01:34<00:19, 360.26batches/s, l2_loss: 0.1133 - round_los\u001b[A\n",
      "Training:  83%|▊| 33907/40960 [01:34<00:19, 360.09batches/s, l2_loss: 0.1133 - round_los\u001b[A\n",
      "Training:  83%|▊| 33907/40960 [01:34<00:19, 360.09batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  83%|▊| 33963/40960 [01:35<00:20, 333.61batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  83%|▊| 33963/40960 [01:35<00:20, 333.61batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  83%|▊| 34037/40960 [01:35<00:20, 343.21batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  83%|▊| 34037/40960 [01:35<00:20, 343.21batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  83%|▊| 34111/40960 [01:35<00:19, 350.18batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  83%|▊| 34111/40960 [01:35<00:19, 350.18batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  83%|▊| 34184/40960 [01:35<00:19, 354.40batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  83%|▊| 34184/40960 [01:35<00:19, 354.40batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  84%|▊| 34258/40960 [01:35<00:18, 358.56batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  84%|▊| 34258/40960 [01:35<00:18, 358.56batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  84%|▊| 34335/40960 [01:36<00:18, 366.14batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  84%|▊| 34335/40960 [01:36<00:18, 366.14batches/s, l2_loss: 0.1136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34407/40960 [01:36<00:18, 362.92batches/s, l2_loss: 0.1136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34407/40960 [01:36<00:18, 362.92batches/s, l2_loss: 0.1136 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|▊| 34483/40960 [01:36<00:17, 367.25batches/s, l2_loss: 0.1136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34483/40960 [01:36<00:17, 367.25batches/s, l2_loss: 0.1137 - round_los\u001b[A\n",
      "Training:  84%|▊| 34556/40960 [01:36<00:17, 365.95batches/s, l2_loss: 0.1137 - round_los\u001b[A\n",
      "Training:  84%|▊| 34556/40960 [01:36<00:17, 365.95batches/s, l2_loss: 0.1137 - round_los\u001b[A\n",
      "Training:  85%|▊| 34632/40960 [01:36<00:17, 370.03batches/s, l2_loss: 0.1137 - round_los\u001b[A\n",
      "Training:  85%|▊| 34632/40960 [01:36<00:17, 370.03batches/s, l2_loss: 0.1137 - round_los\u001b[A\n",
      "Training:  85%|▊| 34705/40960 [01:37<00:16, 368.48batches/s, l2_loss: 0.1137 - round_los\u001b[A\n",
      "Training:  85%|▊| 34705/40960 [01:37<00:16, 368.48batches/s, l2_loss: 0.1138 - round_los\u001b[A\n",
      "Training:  85%|▊| 34780/40960 [01:37<00:16, 370.37batches/s, l2_loss: 0.1138 - round_los\u001b[A\n",
      "Training:  85%|▊| 34780/40960 [01:37<00:16, 370.37batches/s, l2_loss: 0.1138 - round_los\u001b[A\n",
      "Training:  85%|▊| 34855/40960 [01:37<00:16, 371.38batches/s, l2_loss: 0.1138 - round_los\u001b[A\n",
      "Training:  85%|▊| 34855/40960 [01:37<00:16, 371.38batches/s, l2_loss: 0.1139 - round_los\u001b[A\n",
      "Training:  85%|▊| 34929/40960 [01:37<00:16, 370.17batches/s, l2_loss: 0.1139 - round_los\u001b[A\n",
      "Training:  85%|▊| 34929/40960 [01:37<00:16, 370.17batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  85%|▊| 35004/40960 [01:37<00:16, 371.48batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  85%|▊| 35004/40960 [01:37<00:16, 371.48batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  86%|▊| 35076/40960 [01:38<00:15, 368.01batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  86%|▊| 35076/40960 [01:38<00:15, 368.01batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  86%|▊| 35151/40960 [01:38<00:15, 370.04batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  86%|▊| 35151/40960 [01:38<00:15, 370.04batches/s, l2_loss: 0.1141 - round_los\u001b[A\n",
      "Training:  86%|▊| 35223/40960 [01:38<00:15, 365.50batches/s, l2_loss: 0.1141 - round_los\u001b[A\n",
      "Training:  86%|▊| 35223/40960 [01:38<00:15, 365.50batches/s, l2_loss: 0.1141 - round_los\u001b[A\n",
      "Training:  86%|▊| 35296/40960 [01:38<00:15, 363.66batches/s, l2_loss: 0.1141 - round_los\u001b[A\n",
      "Training:  86%|▊| 35296/40960 [01:38<00:15, 363.66batches/s, l2_loss: 0.1142 - round_los\u001b[A\n",
      "Training:  86%|▊| 35371/40960 [01:39<00:15, 366.15batches/s, l2_loss: 0.1142 - round_los\u001b[A\n",
      "Training:  86%|▊| 35371/40960 [01:39<00:15, 366.15batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35449/40960 [01:39<00:14, 372.20batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35449/40960 [01:39<00:14, 372.20batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35525/40960 [01:39<00:14, 374.47batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35525/40960 [01:39<00:14, 374.47batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35599/40960 [01:39<00:14, 371.62batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35599/40960 [01:39<00:14, 371.62batches/s, l2_loss: 0.1144 - round_los\u001b[A\n",
      "Training:  87%|▊| 35673/40960 [01:39<00:14, 370.69batches/s, l2_loss: 0.1144 - round_los\u001b[A\n",
      "Training:  87%|▊| 35673/40960 [01:39<00:14, 370.69batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  87%|▊| 35746/40960 [01:40<00:14, 368.46batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  87%|▊| 35746/40960 [01:40<00:14, 368.46batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  87%|▊| 35818/40960 [01:40<00:14, 365.37batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  87%|▊| 35818/40960 [01:40<00:14, 365.37batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  88%|▉| 35893/40960 [01:40<00:13, 367.17batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  88%|▉| 35893/40960 [01:40<00:13, 367.17batches/s, l2_loss: 0.1146 - round_los\u001b[A\n",
      "Training:  88%|▉| 35966/40960 [01:40<00:13, 366.26batches/s, l2_loss: 0.1146 - round_los\u001b[A\n",
      "Training:  88%|▉| 35966/40960 [01:40<00:13, 366.26batches/s, l2_loss: 0.1147 - round_los\u001b[A\n",
      "Training:  88%|▉| 36040/40960 [01:40<00:13, 366.71batches/s, l2_loss: 0.1147 - round_los\u001b[A\n",
      "Training:  88%|▉| 36040/40960 [01:40<00:13, 366.71batches/s, l2_loss: 0.1147 - round_los\u001b[A\n",
      "Training:  88%|▉| 36112/40960 [01:41<00:13, 363.26batches/s, l2_loss: 0.1147 - round_los\u001b[A\n",
      "Training:  88%|▉| 36112/40960 [01:41<00:13, 363.26batches/s, l2_loss: 0.1148 - round_los\u001b[A\n",
      "Training:  88%|▉| 36185/40960 [01:41<00:13, 362.49batches/s, l2_loss: 0.1148 - round_los\u001b[A\n",
      "Training:  88%|▉| 36185/40960 [01:41<00:13, 362.49batches/s, l2_loss: 0.1148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36259/40960 [01:41<00:12, 364.55batches/s, l2_loss: 0.1148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36259/40960 [01:41<00:12, 364.55batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36332/40960 [01:41<00:12, 364.34batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36332/40960 [01:41<00:12, 364.34batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36408/40960 [01:41<00:12, 368.67batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36408/40960 [01:41<00:12, 368.67batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36479/40960 [01:42<00:12, 364.52batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  89%|▉| 36479/40960 [01:42<00:12, 364.52batches/s, l2_loss: 0.1150 - round_los\u001b[A\n",
      "Training:  89%|▉| 36547/40960 [01:42<00:12, 355.63batches/s, l2_loss: 0.1150 - round_los\u001b[A\n",
      "Training:  89%|▉| 36547/40960 [01:42<00:12, 355.63batches/s, l2_loss: 0.1151 - round_los\u001b[A\n",
      "Training:  89%|▉| 36622/40960 [01:42<00:12, 361.37batches/s, l2_loss: 0.1151 - round_los\u001b[A\n",
      "Training:  89%|▉| 36622/40960 [01:42<00:12, 361.37batches/s, l2_loss: 0.1152 - round_los\u001b[A\n",
      "Training:  90%|▉| 36687/40960 [01:42<00:12, 349.60batches/s, l2_loss: 0.1152 - round_los\u001b[A\n",
      "Training:  90%|▉| 36687/40960 [01:42<00:12, 349.60batches/s, l2_loss: 0.1152 - round_los\u001b[A\n",
      "Training:  90%|▉| 36751/40960 [01:42<00:12, 339.62batches/s, l2_loss: 0.1152 - round_los\u001b[A\n",
      "Training:  90%|▉| 36751/40960 [01:42<00:12, 339.62batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  90%|▉| 36814/40960 [01:43<00:12, 332.10batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  90%|▉| 36814/40960 [01:43<00:12, 332.10batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  90%|▉| 36882/40960 [01:43<00:12, 333.32batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  90%|▉| 36882/40960 [01:43<00:12, 333.32batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  90%|▉| 36954/40960 [01:43<00:11, 340.85batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  90%|▉| 36954/40960 [01:43<00:11, 340.85batches/s, l2_loss: 0.1154 - round_los\u001b[A\n",
      "Training:  90%|▉| 37028/40960 [01:43<00:11, 349.16batches/s, l2_loss: 0.1154 - round_los\u001b[A\n",
      "Training:  90%|▉| 37028/40960 [01:43<00:11, 349.16batches/s, l2_loss: 0.1155 - round_los\u001b[A\n",
      "Training:  91%|▉| 37104/40960 [01:43<00:10, 357.36batches/s, l2_loss: 0.1155 - round_los\u001b[A\n",
      "Training:  91%|▉| 37104/40960 [01:43<00:10, 357.36batches/s, l2_loss: 0.1155 - round_los\u001b[A\n",
      "Training:  91%|▉| 37177/40960 [01:44<00:10, 358.47batches/s, l2_loss: 0.1155 - round_los\u001b[A\n",
      "Training:  91%|▉| 37177/40960 [01:44<00:10, 358.47batches/s, l2_loss: 0.1156 - round_los\u001b[A\n",
      "Training:  91%|▉| 37252/40960 [01:44<00:10, 362.70batches/s, l2_loss: 0.1156 - round_los\u001b[A\n",
      "Training:  91%|▉| 37252/40960 [01:44<00:10, 362.70batches/s, l2_loss: 0.1156 - round_los\u001b[A\n",
      "Training:  91%|▉| 37323/40960 [01:44<00:10, 359.82batches/s, l2_loss: 0.1156 - round_los\u001b[A\n",
      "Training:  91%|▉| 37323/40960 [01:44<00:10, 359.82batches/s, l2_loss: 0.1157 - round_los\u001b[A\n",
      "Training:  91%|▉| 37394/40960 [01:44<00:09, 357.27batches/s, l2_loss: 0.1157 - round_los\u001b[A\n",
      "Training:  91%|▉| 37394/40960 [01:44<00:09, 357.27batches/s, l2_loss: 0.1157 - round_los\u001b[A\n",
      "Training:  91%|▉| 37466/40960 [01:44<00:09, 357.65batches/s, l2_loss: 0.1157 - round_los\u001b[A\n",
      "Training:  91%|▉| 37466/40960 [01:44<00:09, 357.65batches/s, l2_loss: 0.1158 - round_los\u001b[A\n",
      "Training:  92%|▉| 37539/40960 [01:45<00:09, 358.89batches/s, l2_loss: 0.1158 - round_los\u001b[A\n",
      "Training:  92%|▉| 37539/40960 [01:45<00:09, 358.89batches/s, l2_loss: 0.1159 - round_los\u001b[A\n",
      "Training:  92%|▉| 37606/40960 [01:45<00:09, 350.34batches/s, l2_loss: 0.1159 - round_los\u001b[A\n",
      "Training:  92%|▉| 37606/40960 [01:45<00:09, 350.34batches/s, l2_loss: 0.1159 - round_los\u001b[A\n",
      "Training:  92%|▉| 37668/40960 [01:45<00:09, 337.34batches/s, l2_loss: 0.1159 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37668/40960 [01:45<00:09, 337.34batches/s, l2_loss: 0.1160 - round_los\u001b[A\n",
      "Training:  92%|▉| 37735/40960 [01:45<00:09, 336.21batches/s, l2_loss: 0.1160 - round_los\u001b[A\n",
      "Training:  92%|▉| 37735/40960 [01:45<00:09, 336.21batches/s, l2_loss: 0.1160 - round_los\u001b[A\n",
      "Training:  92%|▉| 37804/40960 [01:45<00:09, 338.33batches/s, l2_loss: 0.1160 - round_los\u001b[A\n",
      "Training:  92%|▉| 37804/40960 [01:45<00:09, 338.33batches/s, l2_loss: 0.1161 - round_los\u001b[A\n",
      "Training:  92%|▉| 37881/40960 [01:46<00:08, 351.07batches/s, l2_loss: 0.1161 - round_los\u001b[A\n",
      "Training:  92%|▉| 37881/40960 [01:46<00:08, 351.07batches/s, l2_loss: 0.1162 - round_los\u001b[A\n",
      "Training:  93%|▉| 37951/40960 [01:46<00:08, 349.69batches/s, l2_loss: 0.1162 - round_los\u001b[A\n",
      "Training:  93%|▉| 37951/40960 [01:46<00:08, 349.69batches/s, l2_loss: 0.1162 - round_los\u001b[A\n",
      "Training:  93%|▉| 38023/40960 [01:46<00:08, 351.33batches/s, l2_loss: 0.1162 - round_los\u001b[A\n",
      "Training:  93%|▉| 38023/40960 [01:46<00:08, 351.33batches/s, l2_loss: 0.1163 - round_los\u001b[A\n",
      "Training:  93%|▉| 38075/40960 [01:46<00:08, 323.79batches/s, l2_loss: 0.1163 - round_los\u001b[A\n",
      "Training:  93%|▉| 38075/40960 [01:46<00:08, 323.79batches/s, l2_loss: 0.1163 - round_los\u001b[A\n",
      "Training:  93%|▉| 38125/40960 [01:46<00:09, 301.59batches/s, l2_loss: 0.1163 - round_los\u001b[A\n",
      "Training:  93%|▉| 38125/40960 [01:46<00:09, 301.59batches/s, l2_loss: 0.1164 - round_los\u001b[A\n",
      "Training:  93%|▉| 38190/40960 [01:47<00:08, 307.82batches/s, l2_loss: 0.1164 - round_los\u001b[A\n",
      "Training:  93%|▉| 38190/40960 [01:47<00:08, 307.82batches/s, l2_loss: 0.1164 - round_los\u001b[A\n",
      "Training:  93%|▉| 38261/40960 [01:47<00:08, 320.68batches/s, l2_loss: 0.1164 - round_los\u001b[A\n",
      "Training:  93%|▉| 38261/40960 [01:47<00:08, 320.68batches/s, l2_loss: 0.1165 - round_los\u001b[A\n",
      "Training:  94%|▉| 38335/40960 [01:47<00:07, 335.02batches/s, l2_loss: 0.1165 - round_los\u001b[A\n",
      "Training:  94%|▉| 38335/40960 [01:47<00:07, 335.02batches/s, l2_loss: 0.1165 - round_los\u001b[A\n",
      "Training:  94%|▉| 38411/40960 [01:47<00:07, 348.01batches/s, l2_loss: 0.1165 - round_los\u001b[A\n",
      "Training:  94%|▉| 38411/40960 [01:47<00:07, 348.01batches/s, l2_loss: 0.1166 - round_los\u001b[A\n",
      "Training:  94%|▉| 38478/40960 [01:47<00:07, 343.08batches/s, l2_loss: 0.1166 - round_los\u001b[A\n",
      "Training:  94%|▉| 38478/40960 [01:47<00:07, 343.08batches/s, l2_loss: 0.1167 - round_los\u001b[A\n",
      "Training:  94%|▉| 38538/40960 [01:48<00:07, 329.28batches/s, l2_loss: 0.1167 - round_los\u001b[A\n",
      "Training:  94%|▉| 38538/40960 [01:48<00:07, 329.28batches/s, l2_loss: 0.1167 - round_los\u001b[A\n",
      "Training:  94%|▉| 38605/40960 [01:48<00:07, 330.09batches/s, l2_loss: 0.1167 - round_los\u001b[A\n",
      "Training:  94%|▉| 38605/40960 [01:48<00:07, 330.09batches/s, l2_loss: 0.1168 - round_los\u001b[A\n",
      "Training:  94%|▉| 38664/40960 [01:48<00:07, 318.64batches/s, l2_loss: 0.1168 - round_los\u001b[A\n",
      "Training:  94%|▉| 38664/40960 [01:48<00:07, 318.64batches/s, l2_loss: 0.1169 - round_los\u001b[A\n",
      "Training:  95%|▉| 38733/40960 [01:48<00:06, 326.27batches/s, l2_loss: 0.1169 - round_los\u001b[A\n",
      "Training:  95%|▉| 38733/40960 [01:48<00:06, 326.27batches/s, l2_loss: 0.1169 - round_los\u001b[A\n",
      "Training:  95%|▉| 38807/40960 [01:48<00:06, 338.82batches/s, l2_loss: 0.1169 - round_los\u001b[A\n",
      "Training:  95%|▉| 38807/40960 [01:48<00:06, 338.82batches/s, l2_loss: 0.1170 - round_los\u001b[A\n",
      "Training:  95%|▉| 38881/40960 [01:49<00:05, 347.41batches/s, l2_loss: 0.1170 - round_los\u001b[A\n",
      "Training:  95%|▉| 38881/40960 [01:49<00:05, 347.41batches/s, l2_loss: 0.1170 - round_los\u001b[A\n",
      "Training:  95%|▉| 38956/40960 [01:49<00:05, 354.41batches/s, l2_loss: 0.1170 - round_los\u001b[A\n",
      "Training:  95%|▉| 38956/40960 [01:49<00:05, 354.41batches/s, l2_loss: 0.1171 - round_los\u001b[A\n",
      "Training:  95%|▉| 39033/40960 [01:49<00:05, 362.64batches/s, l2_loss: 0.1171 - round_los\u001b[A\n",
      "Training:  95%|▉| 39033/40960 [01:49<00:05, 362.64batches/s, l2_loss: 0.1172 - round_los\u001b[A\n",
      "Training:  95%|▉| 39108/40960 [01:49<00:05, 365.23batches/s, l2_loss: 0.1172 - round_los\u001b[A\n",
      "Training:  95%|▉| 39108/40960 [01:49<00:05, 365.23batches/s, l2_loss: 0.1172 - round_los\u001b[A\n",
      "Training:  96%|▉| 39184/40960 [01:49<00:04, 369.36batches/s, l2_loss: 0.1172 - round_los\u001b[A\n",
      "Training:  96%|▉| 39184/40960 [01:49<00:04, 369.36batches/s, l2_loss: 0.1173 - round_los\u001b[A\n",
      "Training:  96%|▉| 39257/40960 [01:50<00:04, 367.82batches/s, l2_loss: 0.1173 - round_los\u001b[A\n",
      "Training:  96%|▉| 39257/40960 [01:50<00:04, 367.82batches/s, l2_loss: 0.1174 - round_los\u001b[A\n",
      "Training:  96%|▉| 39331/40960 [01:50<00:04, 367.31batches/s, l2_loss: 0.1174 - round_los\u001b[A\n",
      "Training:  96%|▉| 39331/40960 [01:50<00:04, 367.31batches/s, l2_loss: 0.1174 - round_los\u001b[A\n",
      "Training:  96%|▉| 39406/40960 [01:50<00:04, 368.49batches/s, l2_loss: 0.1174 - round_los\u001b[A\n",
      "Training:  96%|▉| 39406/40960 [01:50<00:04, 368.49batches/s, l2_loss: 0.1175 - round_los\u001b[A\n",
      "Training:  96%|▉| 39477/40960 [01:50<00:04, 363.68batches/s, l2_loss: 0.1175 - round_los\u001b[A\n",
      "Training:  96%|▉| 39477/40960 [01:50<00:04, 363.68batches/s, l2_loss: 0.1176 - round_los\u001b[A\n",
      "Training:  97%|▉| 39549/40960 [01:50<00:03, 361.19batches/s, l2_loss: 0.1176 - round_los\u001b[A\n",
      "Training:  97%|▉| 39549/40960 [01:50<00:03, 361.19batches/s, l2_loss: 0.1176 - round_los\u001b[A\n",
      "Training:  97%|▉| 39621/40960 [01:51<00:03, 360.06batches/s, l2_loss: 0.1176 - round_los\u001b[A\n",
      "Training:  97%|▉| 39621/40960 [01:51<00:03, 360.06batches/s, l2_loss: 0.1177 - round_los\u001b[A\n",
      "Training:  97%|▉| 39691/40960 [01:51<00:03, 356.73batches/s, l2_loss: 0.1177 - round_los\u001b[A\n",
      "Training:  97%|▉| 39691/40960 [01:51<00:03, 356.73batches/s, l2_loss: 0.1178 - round_los\u001b[A\n",
      "Training:  97%|▉| 39767/40960 [01:51<00:03, 363.18batches/s, l2_loss: 0.1178 - round_los\u001b[A\n",
      "Training:  97%|▉| 39767/40960 [01:51<00:03, 363.18batches/s, l2_loss: 0.1178 - round_los\u001b[A\n",
      "Training:  97%|▉| 39839/40960 [01:51<00:03, 360.77batches/s, l2_loss: 0.1178 - round_los\u001b[A\n",
      "Training:  97%|▉| 39839/40960 [01:51<00:03, 360.77batches/s, l2_loss: 0.1179 - round_los\u001b[A\n",
      "Training:  97%|▉| 39912/40960 [01:51<00:02, 361.41batches/s, l2_loss: 0.1179 - round_los\u001b[A\n",
      "Training:  97%|▉| 39912/40960 [01:51<00:02, 361.41batches/s, l2_loss: 0.1179 - round_los\u001b[A\n",
      "Training:  98%|▉| 39989/40960 [01:52<00:02, 367.51batches/s, l2_loss: 0.1179 - round_los\u001b[A\n",
      "Training:  98%|▉| 39989/40960 [01:52<00:02, 367.51batches/s, l2_loss: 0.1180 - round_los\u001b[A\n",
      "Training:  98%|▉| 40064/40960 [01:52<00:02, 368.89batches/s, l2_loss: 0.1180 - round_los\u001b[A\n",
      "Training:  98%|▉| 40064/40960 [01:52<00:02, 368.89batches/s, l2_loss: 0.1181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40137/40960 [01:52<00:02, 367.09batches/s, l2_loss: 0.1181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40137/40960 [01:52<00:02, 367.09batches/s, l2_loss: 0.1182 - round_los\u001b[A\n",
      "Training:  98%|▉| 40208/40960 [01:52<00:02, 363.31batches/s, l2_loss: 0.1182 - round_los\u001b[A\n",
      "Training:  98%|▉| 40208/40960 [01:52<00:02, 363.31batches/s, l2_loss: 0.1182 - round_los\u001b[A\n",
      "Training:  98%|▉| 40282/40960 [01:52<00:01, 363.91batches/s, l2_loss: 0.1182 - round_los\u001b[A\n",
      "Training:  98%|▉| 40282/40960 [01:52<00:01, 363.91batches/s, l2_loss: 0.1183 - round_los\u001b[A\n",
      "Training:  99%|▉| 40356/40960 [01:53<00:01, 365.06batches/s, l2_loss: 0.1183 - round_los\u001b[A\n",
      "Training:  99%|▉| 40356/40960 [01:53<00:01, 365.06batches/s, l2_loss: 0.1183 - round_los\u001b[A\n",
      "Training:  99%|▉| 40422/40960 [01:53<00:01, 353.70batches/s, l2_loss: 0.1183 - round_los\u001b[A\n",
      "Training:  99%|▉| 40422/40960 [01:53<00:01, 353.70batches/s, l2_loss: 0.1184 - round_los\u001b[A\n",
      "Training:  99%|▉| 40494/40960 [01:53<00:01, 353.94batches/s, l2_loss: 0.1184 - round_los\u001b[A\n",
      "Training:  99%|▉| 40494/40960 [01:53<00:01, 353.94batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  99%|▉| 40563/40960 [01:53<00:01, 349.24batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  99%|▉| 40563/40960 [01:53<00:01, 349.24batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  99%|▉| 40623/40960 [01:53<00:01, 334.01batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  99%|▉| 40623/40960 [01:53<00:01, 334.01batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  99%|▉| 40689/40960 [01:54<00:00, 331.26batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  99%|▉| 40689/40960 [01:54<00:00, 331.26batches/s, l2_loss: 0.1186 - round_los\u001b[A\n",
      "Training:  99%|▉| 40755/40960 [01:54<00:00, 330.34batches/s, l2_loss: 0.1186 - round_los\u001b[A\n",
      "Training:  99%|▉| 40755/40960 [01:54<00:00, 330.34batches/s, l2_loss: 0.1187 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|▉| 40820/40960 [01:54<00:00, 328.73batches/s, l2_loss: 0.1187 - round_los\u001b[A\n",
      "Training: 100%|▉| 40820/40960 [01:54<00:00, 328.73batches/s, l2_loss: 0.1187 - round_los\u001b[A\n",
      "Training: 100%|▉| 40885/40960 [01:54<00:00, 326.33batches/s, l2_loss: 0.1187 - round_los\u001b[A\n",
      "Training: 100%|▉| 40885/40960 [01:54<00:00, 326.33batches/s, l2_loss: 0.1188 - round_los\u001b[A\n",
      "Training: 100%|▉| 40958/40960 [01:54<00:00, 337.82batches/s, l2_loss: 0.1188 - round_los\u001b[A\n",
      "Training: 100%|▉| 40958/40960 [01:54<00:00, 337.82batches/s, l2_loss: 0.1188 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:14:53.204491: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  50%|▌| 13/26 [27:14<28:03, 129.46s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:14:55.160716: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:14:57.636716: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                                | 1/40960 [00:00<9:46:00,  1.16batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<9:46:00,  1.16batches/s, l2_loss: 0.0316 - round_loss: \u001b[A\n",
      "Training:   0%| | 95/40960 [00:01<05:45, 118.23batches/s, l2_loss: 0.0316 - round_loss: \u001b[A\n",
      "Training:   0%| | 95/40960 [00:01<05:45, 118.23batches/s, l2_loss: 0.0582 - round_loss: \u001b[A\n",
      "Training:   0%| | 189/40960 [00:01<03:13, 210.31batches/s, l2_loss: 0.0582 - round_loss:\u001b[A\n",
      "Training:   0%| | 189/40960 [00:01<03:13, 210.31batches/s, l2_loss: 0.0579 - round_loss:\u001b[A\n",
      "Training:   1%| | 284/40960 [00:01<02:24, 281.84batches/s, l2_loss: 0.0579 - round_loss:\u001b[A\n",
      "Training:   1%| | 284/40960 [00:01<02:24, 281.84batches/s, l2_loss: 0.0560 - round_loss:\u001b[A\n",
      "Training:   1%| | 378/40960 [00:01<02:01, 333.87batches/s, l2_loss: 0.0560 - round_loss:\u001b[A\n",
      "Training:   1%| | 378/40960 [00:01<02:01, 333.87batches/s, l2_loss: 0.0563 - round_loss:\u001b[A\n",
      "Training:   1%| | 473/40960 [00:01<01:48, 373.96batches/s, l2_loss: 0.0563 - round_loss:\u001b[A\n",
      "Training:   1%| | 473/40960 [00:01<01:48, 373.96batches/s, l2_loss: 0.0561 - round_loss:\u001b[A\n",
      "Training:   1%| | 568/40960 [00:02<01:40, 401.98batches/s, l2_loss: 0.0561 - round_loss:\u001b[A\n",
      "Training:   1%| | 568/40960 [00:02<01:40, 401.98batches/s, l2_loss: 0.0556 - round_loss:\u001b[A\n",
      "Training:   2%| | 664/40960 [00:02<01:35, 423.68batches/s, l2_loss: 0.0556 - round_loss:\u001b[A\n",
      "Training:   2%| | 664/40960 [00:02<01:35, 423.68batches/s, l2_loss: 0.0557 - round_loss:\u001b[A\n",
      "Training:   2%| | 759/40960 [00:02<01:31, 437.82batches/s, l2_loss: 0.0557 - round_loss:\u001b[A\n",
      "Training:   2%| | 759/40960 [00:02<01:31, 437.82batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   2%| | 850/40960 [00:02<01:30, 442.86batches/s, l2_loss: 0.0545 - round_loss:\u001b[A\n",
      "Training:   2%| | 850/40960 [00:02<01:30, 442.86batches/s, l2_loss: 0.0542 - round_loss:\u001b[A\n",
      "Training:   2%| | 945/40960 [00:02<01:28, 451.35batches/s, l2_loss: 0.0542 - round_loss:\u001b[A\n",
      "Training:   2%| | 945/40960 [00:02<01:28, 451.35batches/s, l2_loss: 0.0535 - round_loss:\u001b[A\n",
      "Training:   3%| | 1040/40960 [00:03<01:27, 457.40batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   3%| | 1040/40960 [00:03<01:27, 457.40batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   3%| | 1134/40960 [00:03<01:26, 460.09batches/s, l2_loss: 0.0537 - round_loss\u001b[A\n",
      "Training:   3%| | 1134/40960 [00:03<01:26, 460.09batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   3%| | 1229/40960 [00:03<01:25, 464.37batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   3%| | 1229/40960 [00:03<01:25, 464.37batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   3%| | 1324/40960 [00:03<01:24, 466.38batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   3%| | 1324/40960 [00:03<01:24, 466.38batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   3%| | 1417/40960 [00:03<01:24, 465.93batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   3%| | 1417/40960 [00:03<01:24, 465.93batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   4%| | 1510/40960 [00:04<01:24, 465.19batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   4%| | 1510/40960 [00:04<01:24, 465.19batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   4%| | 1605/40960 [00:04<01:24, 467.78batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   4%| | 1605/40960 [00:04<01:24, 467.78batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   4%| | 1699/40960 [00:04<01:23, 467.65batches/s, l2_loss: 0.0532 - round_loss\u001b[A\n",
      "Training:   4%| | 1699/40960 [00:04<01:23, 467.65batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:   4%| | 1793/40960 [00:04<01:23, 467.38batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:   4%| | 1793/40960 [00:04<01:23, 467.38batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   5%| | 1888/40960 [00:04<01:23, 468.69batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   5%| | 1888/40960 [00:04<01:23, 468.69batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:   5%| | 1983/40960 [00:05<01:22, 469.65batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:   5%| | 1983/40960 [00:05<01:22, 469.65batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   5%| | 2081/40960 [00:05<01:21, 474.73batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:   5%| | 2081/40960 [00:05<01:21, 474.73batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:   5%| | 2176/40960 [00:05<01:21, 473.84batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:   5%| | 2176/40960 [00:05<01:21, 473.84batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:   6%| | 2269/40960 [00:05<01:22, 470.01batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:   6%| | 2269/40960 [00:05<01:22, 470.01batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:   6%| | 2362/40960 [00:05<01:22, 468.44batches/s, l2_loss: 0.0521 - round_loss\u001b[A\n",
      "Training:   6%| | 2362/40960 [00:05<01:22, 468.44batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:   6%| | 2457/40960 [00:06<01:21, 469.78batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:   6%| | 2457/40960 [00:06<01:21, 469.78batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:   6%| | 2551/40960 [00:06<01:21, 468.65batches/s, l2_loss: 0.0518 - round_loss\u001b[A\n",
      "Training:   6%| | 2551/40960 [00:06<01:21, 468.65batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:   6%| | 2645/40960 [00:06<01:21, 467.90batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:   6%| | 2645/40960 [00:06<01:21, 467.90batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:   7%| | 2739/40960 [00:06<01:21, 467.76batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:   7%| | 2739/40960 [00:06<01:21, 467.76batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:   7%| | 2833/40960 [00:06<01:21, 467.96batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:   7%| | 2833/40960 [00:06<01:21, 467.96batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:   7%| | 2928/40960 [00:07<01:20, 469.54batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:   7%| | 2928/40960 [00:07<01:20, 469.54batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:   7%| | 3024/40960 [00:07<01:20, 472.25batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:   7%| | 3024/40960 [00:07<01:20, 472.25batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:   8%| | 3119/40960 [00:07<01:20, 472.50batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:   8%| | 3119/40960 [00:07<01:20, 472.50batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:   8%| | 3215/40960 [00:07<01:19, 473.49batches/s, l2_loss: 0.0512 - round_loss\u001b[A\n",
      "Training:   8%| | 3215/40960 [00:07<01:19, 473.49batches/s, l2_loss: 0.0510 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3310/40960 [00:07<01:19, 472.97batches/s, l2_loss: 0.0510 - round_loss\u001b[A\n",
      "Training:   8%| | 3310/40960 [00:07<01:19, 472.97batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:   8%| | 3404/40960 [00:08<01:19, 471.60batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:   8%| | 3404/40960 [00:08<01:19, 471.60batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:   9%| | 3500/40960 [00:08<01:19, 472.67batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:   9%| | 3500/40960 [00:08<01:19, 472.67batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:   9%| | 3594/40960 [00:08<01:19, 471.27batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:   9%| | 3594/40960 [00:08<01:19, 471.27batches/s, l2_loss: 0.0507 - round_loss\u001b[A\n",
      "Training:   9%| | 3687/40960 [00:08<01:19, 469.29batches/s, l2_loss: 0.0507 - round_loss\u001b[A\n",
      "Training:   9%| | 3687/40960 [00:08<01:19, 469.29batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:   9%| | 3783/40960 [00:08<01:18, 471.03batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:   9%| | 3783/40960 [00:08<01:18, 471.03batches/s, l2_loss: 0.0505 - round_loss\u001b[A\n",
      "Training:   9%| | 3878/40960 [00:09<01:18, 470.80batches/s, l2_loss: 0.0505 - round_loss\u001b[A\n",
      "Training:   9%| | 3878/40960 [00:09<01:18, 470.80batches/s, l2_loss: 0.0507 - round_loss\u001b[A\n",
      "Training:  10%| | 3972/40960 [00:09<01:18, 470.46batches/s, l2_loss: 0.0507 - round_loss\u001b[A\n",
      "Training:  10%| | 3972/40960 [00:09<01:18, 470.46batches/s, l2_loss: 0.0505 - round_loss\u001b[A\n",
      "Training:  10%| | 4067/40960 [00:09<01:18, 471.00batches/s, l2_loss: 0.0505 - round_loss\u001b[A\n",
      "Training:  10%| | 4067/40960 [00:09<01:18, 471.00batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  10%| | 4161/40960 [00:09<01:18, 469.49batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  10%| | 4161/40960 [00:09<01:18, 469.49batches/s, l2_loss: 0.0506 - round_loss\u001b[A\n",
      "Training:  10%| | 4256/40960 [00:09<01:17, 470.78batches/s, l2_loss: 0.0506 - round_loss\u001b[A\n",
      "Training:  10%| | 4256/40960 [00:09<01:17, 470.78batches/s, l2_loss: 0.0503 - round_loss\u001b[A\n",
      "Training:  11%| | 4350/40960 [00:10<01:17, 470.40batches/s, l2_loss: 0.0503 - round_loss\u001b[A\n",
      "Training:  11%| | 4350/40960 [00:10<01:17, 470.40batches/s, l2_loss: 0.0503 - round_loss\u001b[A\n",
      "Training:  11%| | 4446/40960 [00:10<01:17, 472.34batches/s, l2_loss: 0.0503 - round_loss\u001b[A\n",
      "Training:  11%| | 4446/40960 [00:10<01:17, 472.34batches/s, l2_loss: 0.0503 - round_loss\u001b[A\n",
      "Training:  11%| | 4542/40960 [00:10<01:16, 473.92batches/s, l2_loss: 0.0503 - round_loss\u001b[A\n",
      "Training:  11%| | 4542/40960 [00:10<01:16, 473.92batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:  11%| | 4637/40960 [00:10<01:16, 473.71batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:  11%| | 4637/40960 [00:10<01:16, 473.71batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:  12%| | 4732/40960 [00:10<01:16, 473.18batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:  12%| | 4732/40960 [00:10<01:16, 473.18batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  12%| | 4824/40960 [00:11<01:17, 468.80batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  12%| | 4824/40960 [00:11<01:17, 468.80batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  12%| | 4917/40960 [00:11<01:17, 466.92batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  12%| | 4917/40960 [00:11<01:17, 466.92batches/s, l2_loss: 0.0500 - round_loss\u001b[A\n",
      "Training:  12%| | 5009/40960 [00:11<01:17, 463.90batches/s, l2_loss: 0.0500 - round_loss\u001b[A\n",
      "Training:  12%| | 5009/40960 [00:11<01:17, 463.90batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  12%| | 5105/40960 [00:11<01:16, 467.32batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  12%| | 5105/40960 [00:11<01:16, 467.32batches/s, l2_loss: 0.0500 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5196/40960 [00:11<01:17, 463.10batches/s, l2_loss: 0.0500 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5196/40960 [00:11<01:17, 463.10batches/s, l2_loss: 0.0500 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5290/40960 [00:12<01:16, 464.48batches/s, l2_loss: 0.0500 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5290/40960 [00:12<01:16, 464.48batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5383/40960 [00:12<01:16, 464.63batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5383/40960 [00:12<01:16, 464.63batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5478/40960 [00:12<01:16, 466.75batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5478/40960 [00:12<01:16, 466.75batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5573/40960 [00:12<01:15, 468.86batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5573/40960 [00:12<01:15, 468.86batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5666/40960 [00:12<01:15, 466.64batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5666/40960 [00:12<01:15, 466.64batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5760/40960 [00:13<01:15, 466.34batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5760/40960 [00:13<01:15, 466.34batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5855/40960 [00:13<01:15, 467.73batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5855/40960 [00:13<01:15, 467.73batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5949/40960 [00:13<01:14, 467.30batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5949/40960 [00:13<01:14, 467.30batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6045/40960 [00:13<01:14, 469.65batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6045/40960 [00:13<01:14, 469.65batches/s, l2_loss: 0.0496 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6140/40960 [00:13<01:14, 470.39batches/s, l2_loss: 0.0496 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6140/40960 [00:13<01:14, 470.39batches/s, l2_loss: 0.0496 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6235/40960 [00:14<01:13, 471.57batches/s, l2_loss: 0.0496 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6235/40960 [00:14<01:13, 471.57batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6330/40960 [00:14<01:13, 472.58batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6330/40960 [00:14<01:13, 472.58batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:14<01:13, 472.63batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:14<01:13, 472.63batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6520/40960 [00:14<01:12, 472.83batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6520/40960 [00:14<01:12, 472.83batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6614/40960 [00:14<01:12, 471.59batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6614/40960 [00:14<01:12, 471.59batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6711/40960 [00:15<01:12, 474.72batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6711/40960 [00:15<01:12, 474.72batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6803/40960 [00:15<01:12, 469.76batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6803/40960 [00:15<01:12, 469.76batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6896/40960 [00:15<01:12, 467.94batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6896/40960 [00:15<01:12, 467.94batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6987/40960 [00:15<01:13, 463.92batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6987/40960 [00:15<01:13, 463.92batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7081/40960 [00:15<01:12, 465.17batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7081/40960 [00:15<01:12, 465.17batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7172/40960 [00:16<01:13, 461.92batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7172/40960 [00:16<01:13, 461.92batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7263/40960 [00:16<01:13, 459.06batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7263/40960 [00:16<01:13, 459.06batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7357/40960 [00:16<01:12, 461.38batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7357/40960 [00:16<01:12, 461.38batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7451/40960 [00:16<01:12, 463.67batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|▏| 7451/40960 [00:16<01:12, 463.67batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7546/40960 [00:16<01:11, 465.77batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7546/40960 [00:16<01:11, 465.77batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7638/40960 [00:17<01:11, 462.88batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7638/40960 [00:17<01:11, 462.88batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7732/40960 [00:17<01:11, 464.60batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7732/40960 [00:17<01:11, 464.60batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7827/40960 [00:17<01:10, 467.27batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7827/40960 [00:17<01:10, 467.27batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7918/40960 [00:17<01:11, 462.23batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7918/40960 [00:17<01:11, 462.23batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8011/40960 [00:17<01:11, 462.90batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8011/40960 [00:17<01:11, 462.90batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8107/40960 [00:18<01:10, 467.18batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8107/40960 [00:18<01:10, 467.18batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8199/40960 [00:18<01:10, 463.99batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8199/40960 [00:18<01:10, 463.99batches/s, l2_loss: 0.0327 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8280/40960 [00:18<01:13, 445.47batches/s, l2_loss: 0.0327 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8280/40960 [00:18<01:13, 445.47batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8359/40960 [00:18<01:15, 429.02batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8359/40960 [00:18<01:15, 429.02batches/s, l2_loss: 0.0481 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8444/40960 [00:18<01:16, 427.20batches/s, l2_loss: 0.0481 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8444/40960 [00:18<01:16, 427.20batches/s, l2_loss: 0.0477 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8527/40960 [00:19<01:16, 422.72batches/s, l2_loss: 0.0477 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8527/40960 [00:19<01:16, 422.72batches/s, l2_loss: 0.0487 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8611/40960 [00:19<01:16, 421.37batches/s, l2_loss: 0.0487 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8611/40960 [00:19<01:16, 421.37batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8695/40960 [00:19<01:16, 420.19batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8695/40960 [00:19<01:16, 420.19batches/s, l2_loss: 0.0482 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8779/40960 [00:19<01:16, 419.43batches/s, l2_loss: 0.0482 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8779/40960 [00:19<01:16, 419.43batches/s, l2_loss: 0.0479 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8863/40960 [00:19<01:16, 419.12batches/s, l2_loss: 0.0479 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8863/40960 [00:19<01:16, 419.12batches/s, l2_loss: 0.0474 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8948/40960 [00:20<01:16, 420.11batches/s, l2_loss: 0.0474 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8948/40960 [00:20<01:16, 420.11batches/s, l2_loss: 0.0482 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9032/40960 [00:20<01:16, 419.90batches/s, l2_loss: 0.0482 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9032/40960 [00:20<01:16, 419.90batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9117/40960 [00:20<01:15, 420.49batches/s, l2_loss: 0.0484 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9117/40960 [00:20<01:15, 420.49batches/s, l2_loss: 0.0476 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9200/40960 [00:20<01:15, 418.85batches/s, l2_loss: 0.0476 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9200/40960 [00:20<01:15, 418.85batches/s, l2_loss: 0.0480 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9284/40960 [00:20<01:15, 417.76batches/s, l2_loss: 0.0480 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9284/40960 [00:20<01:15, 417.76batches/s, l2_loss: 0.0476 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9369/40960 [00:21<01:15, 419.07batches/s, l2_loss: 0.0476 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9369/40960 [00:21<01:15, 419.07batches/s, l2_loss: 0.0478 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9454/40960 [00:21<01:15, 420.05batches/s, l2_loss: 0.0478 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9454/40960 [00:21<01:15, 420.05batches/s, l2_loss: 0.0482 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9541/40960 [00:21<01:14, 424.26batches/s, l2_loss: 0.0482 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9541/40960 [00:21<01:14, 424.26batches/s, l2_loss: 0.0477 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9625/40960 [00:21<01:14, 422.08batches/s, l2_loss: 0.0477 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9625/40960 [00:21<01:14, 422.08batches/s, l2_loss: 0.0478 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9707/40960 [00:21<01:14, 417.82batches/s, l2_loss: 0.0478 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9707/40960 [00:21<01:14, 417.82batches/s, l2_loss: 0.0477 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9793/40960 [00:22<01:14, 420.83batches/s, l2_loss: 0.0477 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9793/40960 [00:22<01:14, 420.83batches/s, l2_loss: 0.0479 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9877/40960 [00:22<01:13, 420.23batches/s, l2_loss: 0.0479 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9877/40960 [00:22<01:13, 420.23batches/s, l2_loss: 0.0479 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9963/40960 [00:22<01:13, 423.12batches/s, l2_loss: 0.0479 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9963/40960 [00:22<01:13, 423.12batches/s, l2_loss: 0.0480 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10049/40960 [00:22<01:12, 424.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  25%|▏| 10049/40960 [00:22<01:12, 424.53batches/s, l2_loss: 0.0477 - round_los\u001b[A\n",
      "Training:  25%|▏| 10133/40960 [00:22<01:13, 421.85batches/s, l2_loss: 0.0477 - round_los\u001b[A\n",
      "Training:  25%|▏| 10133/40960 [00:22<01:13, 421.85batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  25%|▏| 10219/40960 [00:23<01:12, 423.46batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  25%|▏| 10219/40960 [00:23<01:12, 423.46batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  25%|▎| 10304/40960 [00:23<01:12, 422.48batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  25%|▎| 10304/40960 [00:23<01:12, 422.48batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  25%|▎| 10387/40960 [00:23<01:12, 419.20batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  25%|▎| 10387/40960 [00:23<01:12, 419.20batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  26%|▎| 10472/40960 [00:23<01:12, 419.84batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  26%|▎| 10472/40960 [00:23<01:12, 419.84batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  26%|▎| 10558/40960 [00:23<01:12, 421.85batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  26%|▎| 10558/40960 [00:23<01:12, 421.85batches/s, l2_loss: 0.0477 - round_los\u001b[A\n",
      "Training:  26%|▎| 10644/40960 [00:24<01:11, 424.19batches/s, l2_loss: 0.0477 - round_los\u001b[A\n",
      "Training:  26%|▎| 10644/40960 [00:24<01:11, 424.19batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  26%|▎| 10728/40960 [00:24<01:11, 422.74batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  26%|▎| 10728/40960 [00:24<01:11, 422.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  26%|▎| 10811/40960 [00:24<01:11, 420.32batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  26%|▎| 10811/40960 [00:24<01:11, 420.32batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  27%|▎| 10894/40960 [00:24<01:11, 418.61batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  27%|▎| 10894/40960 [00:24<01:11, 418.61batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  27%|▎| 10977/40960 [00:24<01:12, 416.36batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  27%|▎| 10977/40960 [00:24<01:12, 416.36batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  27%|▎| 11059/40960 [00:25<01:12, 413.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  27%|▎| 11059/40960 [00:25<01:12, 413.95batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  27%|▎| 11145/40960 [00:25<01:11, 418.52batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  27%|▎| 11145/40960 [00:25<01:11, 418.52batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  27%|▎| 11228/40960 [00:25<01:11, 417.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  27%|▎| 11228/40960 [00:25<01:11, 417.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|▎| 11315/40960 [00:25<01:10, 421.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  28%|▎| 11315/40960 [00:25<01:10, 421.27batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  28%|▎| 11397/40960 [00:25<01:10, 417.00batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  28%|▎| 11397/40960 [00:25<01:10, 417.00batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  28%|▎| 11480/40960 [00:26<01:10, 415.38batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  28%|▎| 11480/40960 [00:26<01:10, 415.38batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  28%|▎| 11564/40960 [00:26<01:10, 416.76batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  28%|▎| 11564/40960 [00:26<01:10, 416.76batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  28%|▎| 11645/40960 [00:26<01:10, 413.13batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  28%|▎| 11645/40960 [00:26<01:10, 413.13batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  29%|▎| 11730/40960 [00:26<01:10, 416.13batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  29%|▎| 11730/40960 [00:26<01:10, 416.13batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  29%|▎| 11808/40960 [00:26<01:11, 408.13batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  29%|▎| 11808/40960 [00:27<01:11, 408.13batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  29%|▎| 11895/40960 [00:27<01:09, 415.81batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  29%|▎| 11895/40960 [00:27<01:09, 415.81batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  29%|▎| 11977/40960 [00:27<01:10, 413.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  29%|▎| 11977/40960 [00:27<01:10, 413.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  29%|▎| 12064/40960 [00:27<01:08, 419.47batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  29%|▎| 12064/40960 [00:27<01:08, 419.47batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  30%|▎| 12145/40960 [00:27<01:09, 414.64batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  30%|▎| 12145/40960 [00:27<01:09, 414.64batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  30%|▎| 12228/40960 [00:28<01:09, 414.38batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  30%|▎| 12228/40960 [00:28<01:09, 414.38batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  30%|▎| 12311/40960 [00:28<01:09, 413.76batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  30%|▎| 12311/40960 [00:28<01:09, 413.76batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  30%|▎| 12393/40960 [00:28<01:09, 411.47batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  30%|▎| 12393/40960 [00:28<01:09, 411.47batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  30%|▎| 12480/40960 [00:28<01:08, 418.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  30%|▎| 12480/40960 [00:28<01:08, 418.10batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  31%|▎| 12566/40960 [00:28<01:07, 421.61batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  31%|▎| 12566/40960 [00:28<01:07, 421.61batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  31%|▎| 12651/40960 [00:29<01:06, 422.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  31%|▎| 12651/40960 [00:29<01:06, 422.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  31%|▎| 12734/40960 [00:29<01:07, 418.85batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  31%|▎| 12734/40960 [00:29<01:07, 418.85batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  31%|▎| 12818/40960 [00:29<01:07, 419.09batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  31%|▎| 12818/40960 [00:29<01:07, 419.09batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  31%|▎| 12901/40960 [00:29<01:07, 416.52batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  31%|▎| 12901/40960 [00:29<01:07, 416.52batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  32%|▎| 12983/40960 [00:29<01:07, 414.49batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  32%|▎| 12983/40960 [00:29<01:07, 414.49batches/s, l2_loss: 0.0478 - round_los\u001b[A\n",
      "Training:  32%|▎| 13063/40960 [00:30<01:08, 409.66batches/s, l2_loss: 0.0478 - round_los\u001b[A\n",
      "Training:  32%|▎| 13063/40960 [00:30<01:08, 409.66batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  32%|▎| 13148/40960 [00:30<01:07, 413.26batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  32%|▎| 13148/40960 [00:30<01:07, 413.26batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  32%|▎| 13233/40960 [00:30<01:06, 416.41batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  32%|▎| 13233/40960 [00:30<01:06, 416.41batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  33%|▎| 13316/40960 [00:30<01:06, 415.32batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  33%|▎| 13316/40960 [00:30<01:06, 415.32batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  33%|▎| 13395/40960 [00:30<01:07, 409.07batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  33%|▎| 13395/40960 [00:30<01:07, 409.07batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  33%|▎| 13481/40960 [00:31<01:06, 414.25batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  33%|▎| 13481/40960 [00:31<01:06, 414.25batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  33%|▎| 13566/40960 [00:31<01:05, 416.61batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  33%|▎| 13566/40960 [00:31<01:05, 416.61batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  33%|▎| 13646/40960 [00:31<01:06, 411.02batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  33%|▎| 13646/40960 [00:31<01:06, 411.02batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  34%|▎| 13733/40960 [00:31<01:05, 417.65batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  34%|▎| 13733/40960 [00:31<01:05, 417.65batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  34%|▎| 13816/40960 [00:31<01:05, 416.80batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  34%|▎| 13816/40960 [00:31<01:05, 416.80batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  34%|▎| 13901/40960 [00:32<01:04, 419.24batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  34%|▎| 13901/40960 [00:32<01:04, 419.24batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  34%|▎| 13985/40960 [00:32<01:04, 418.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  34%|▎| 13985/40960 [00:32<01:04, 418.94batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  34%|▎| 14070/40960 [00:32<01:03, 420.68batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  34%|▎| 14070/40960 [00:32<01:03, 420.68batches/s, l2_loss: 0.0478 - round_los\u001b[A\n",
      "Training:  35%|▎| 14154/40960 [00:32<01:03, 419.48batches/s, l2_loss: 0.0478 - round_los\u001b[A\n",
      "Training:  35%|▎| 14154/40960 [00:32<01:03, 419.48batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  35%|▎| 14237/40960 [00:32<01:03, 418.07batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  35%|▎| 14237/40960 [00:32<01:03, 418.07batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  35%|▎| 14323/40960 [00:33<01:03, 420.58batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  35%|▎| 14323/40960 [00:33<01:03, 420.58batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  35%|▎| 14408/40960 [00:33<01:03, 421.18batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  35%|▎| 14408/40960 [00:33<01:03, 421.18batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  35%|▎| 14494/40960 [00:33<01:02, 422.79batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  35%|▎| 14494/40960 [00:33<01:02, 422.79batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  36%|▎| 14578/40960 [00:33<01:02, 421.65batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  36%|▎| 14578/40960 [00:33<01:02, 421.65batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  36%|▎| 14666/40960 [00:33<01:01, 427.12batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  36%|▎| 14666/40960 [00:33<01:01, 427.12batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  36%|▎| 14753/40960 [00:34<01:01, 428.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  36%|▎| 14753/40960 [00:34<01:01, 428.04batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  36%|▎| 14839/40960 [00:34<01:01, 428.09batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  36%|▎| 14839/40960 [00:34<01:01, 428.09batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  36%|▎| 14922/40960 [00:34<01:01, 423.69batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  36%|▎| 14922/40960 [00:34<01:01, 423.69batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15008/40960 [00:34<01:01, 424.25batches/s, l2_loss: 0.0479 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15008/40960 [00:34<01:01, 424.25batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15093/40960 [00:34<01:00, 424.33batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15093/40960 [00:34<01:00, 424.33batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15179/40960 [00:35<01:00, 425.59batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15179/40960 [00:35<01:00, 425.59batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  37%|▎| 15265/40960 [00:35<01:00, 426.39batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  37%|▎| 15265/40960 [00:35<01:00, 426.39batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15353/40960 [00:35<00:59, 429.56batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15353/40960 [00:35<00:59, 429.56batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  38%|▍| 15440/40960 [00:35<00:59, 429.78batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  38%|▍| 15440/40960 [00:35<00:59, 429.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  38%|▍| 15526/40960 [00:35<00:59, 429.68batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  38%|▍| 15526/40960 [00:35<00:59, 429.68batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  38%|▍| 15613/40960 [00:36<00:58, 429.97batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  38%|▍| 15613/40960 [00:36<00:58, 429.97batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  38%|▍| 15699/40960 [00:36<00:58, 428.71batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  38%|▍| 15699/40960 [00:36<00:58, 428.71batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  39%|▍| 15786/40960 [00:36<00:58, 429.30batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  39%|▍| 15786/40960 [00:36<00:58, 429.30batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  39%|▍| 15871/40960 [00:36<00:58, 427.82batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  39%|▍| 15871/40960 [00:36<00:58, 427.82batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  39%|▍| 15958/40960 [00:36<00:58, 428.92batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  39%|▍| 15958/40960 [00:36<00:58, 428.92batches/s, l2_loss: 0.0478 - round_los\u001b[A\n",
      "Training:  39%|▍| 16045/40960 [00:37<00:57, 429.78batches/s, l2_loss: 0.0478 - round_los\u001b[A\n",
      "Training:  39%|▍| 16045/40960 [00:37<00:57, 429.78batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  39%|▍| 16132/40960 [00:37<00:57, 430.40batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  39%|▍| 16132/40960 [00:37<00:57, 430.40batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16218/40960 [00:37<00:57, 429.83batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16218/40960 [00:37<00:57, 429.83batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16302/40960 [00:37<00:57, 426.84batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16302/40960 [00:37<00:57, 426.84batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16385/40960 [00:37<00:58, 421.54batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16385/40960 [00:37<00:58, 421.54batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16469/40960 [00:38<00:58, 420.35batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16469/40960 [00:38<00:58, 420.35batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16553/40960 [00:38<00:58, 420.11batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  40%|▍| 16553/40960 [00:38<00:58, 420.11batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16638/40960 [00:38<00:57, 420.95batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16638/40960 [00:38<00:57, 420.95batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16725/40960 [00:38<00:57, 425.00batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16725/40960 [00:38<00:57, 425.00batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16809/40960 [00:38<00:57, 423.15batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16809/40960 [00:38<00:57, 423.15batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16894/40960 [00:39<00:56, 423.48batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16894/40960 [00:39<00:56, 423.48batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16980/40960 [00:39<00:56, 424.26batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  41%|▍| 16980/40960 [00:39<00:56, 424.26batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  42%|▍| 17063/40960 [00:39<00:56, 420.91batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  42%|▍| 17063/40960 [00:39<00:56, 420.91batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  42%|▍| 17147/40960 [00:39<00:56, 419.75batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  42%|▍| 17147/40960 [00:39<00:56, 419.75batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  42%|▍| 17228/40960 [00:39<00:57, 414.17batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  42%|▍| 17228/40960 [00:39<00:57, 414.17batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  42%|▍| 17310/40960 [00:40<00:57, 412.04batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  42%|▍| 17310/40960 [00:40<00:57, 412.04batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  42%|▍| 17396/40960 [00:40<00:56, 416.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  42%|▍| 17396/40960 [00:40<00:56, 416.95batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  43%|▍| 17479/40960 [00:40<00:56, 416.09batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  43%|▍| 17479/40960 [00:40<00:56, 416.09batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  43%|▍| 17564/40960 [00:40<00:55, 417.93batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  43%|▍| 17564/40960 [00:40<00:55, 417.93batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  43%|▍| 17650/40960 [00:40<00:55, 421.39batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  43%|▍| 17650/40960 [00:40<00:55, 421.39batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  43%|▍| 17735/40960 [00:41<00:55, 421.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  43%|▍| 17735/40960 [00:41<00:55, 421.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  44%|▍| 17820/40960 [00:41<00:54, 422.26batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  44%|▍| 17820/40960 [00:41<00:54, 422.26batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  44%|▍| 17905/40960 [00:41<00:54, 421.49batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  44%|▍| 17905/40960 [00:41<00:54, 421.49batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  44%|▍| 17989/40960 [00:41<00:54, 420.30batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  44%|▍| 17989/40960 [00:41<00:54, 420.30batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  44%|▍| 18073/40960 [00:41<00:54, 419.90batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  44%|▍| 18073/40960 [00:41<00:54, 419.90batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  44%|▍| 18156/40960 [00:42<00:54, 418.25batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  44%|▍| 18156/40960 [00:42<00:54, 418.25batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  45%|▍| 18240/40960 [00:42<00:54, 418.01batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  45%|▍| 18240/40960 [00:42<00:54, 418.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  45%|▍| 18324/40960 [00:42<00:54, 417.34batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  45%|▍| 18324/40960 [00:42<00:54, 417.34batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  45%|▍| 18407/40960 [00:42<00:54, 415.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  45%|▍| 18407/40960 [00:42<00:54, 415.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  45%|▍| 18491/40960 [00:42<00:53, 416.69batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  45%|▍| 18491/40960 [00:42<00:53, 416.69batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  45%|▍| 18575/40960 [00:43<00:53, 416.40batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  45%|▍| 18575/40960 [00:43<00:53, 416.40batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  46%|▍| 18660/40960 [00:43<00:53, 418.71batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  46%|▍| 18660/40960 [00:43<00:53, 418.71batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  46%|▍| 18744/40960 [00:43<00:53, 418.14batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  46%|▍| 18744/40960 [00:43<00:53, 418.14batches/s, l2_loss: 0.0479 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|▍| 18831/40960 [00:43<00:52, 421.98batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  46%|▍| 18831/40960 [00:43<00:52, 421.98batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  46%|▍| 18917/40960 [00:43<00:52, 423.57batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  46%|▍| 18917/40960 [00:43<00:52, 423.57batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  46%|▍| 19002/40960 [00:44<00:51, 423.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  46%|▍| 19002/40960 [00:44<00:51, 423.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  47%|▍| 19086/40960 [00:44<00:51, 422.01batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  47%|▍| 19086/40960 [00:44<00:51, 422.01batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  47%|▍| 19170/40960 [00:44<00:51, 420.39batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  47%|▍| 19170/40960 [00:44<00:51, 420.39batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  47%|▍| 19257/40960 [00:44<00:51, 423.78batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  47%|▍| 19257/40960 [00:44<00:51, 423.78batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  47%|▍| 19342/40960 [00:44<00:51, 423.22batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  47%|▍| 19342/40960 [00:44<00:51, 423.22batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  47%|▍| 19422/40960 [00:45<00:51, 416.19batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  47%|▍| 19422/40960 [00:45<00:51, 416.19batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  48%|▍| 19507/40960 [00:45<00:51, 418.00batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  48%|▍| 19507/40960 [00:45<00:51, 418.00batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  48%|▍| 19591/40960 [00:45<00:51, 417.06batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  48%|▍| 19591/40960 [00:45<00:51, 417.06batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  48%|▍| 19674/40960 [00:45<00:51, 415.98batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  48%|▍| 19674/40960 [00:45<00:51, 415.98batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  48%|▍| 19756/40960 [00:45<00:51, 412.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  48%|▍| 19756/40960 [00:45<00:51, 412.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  48%|▍| 19839/40960 [00:46<00:51, 412.29batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  48%|▍| 19839/40960 [00:46<00:51, 412.29batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 19923/40960 [00:46<00:50, 413.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 19923/40960 [00:46<00:50, 413.94batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 20009/40960 [00:46<00:50, 418.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 20009/40960 [00:46<00:50, 418.54batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 20095/40960 [00:46<00:49, 421.05batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 20095/40960 [00:46<00:49, 421.05batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 20178/40960 [00:46<00:49, 419.12batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 20178/40960 [00:46<00:49, 419.12batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 20261/40960 [00:47<00:49, 417.65batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  49%|▍| 20261/40960 [00:47<00:49, 417.65batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  50%|▍| 20346/40960 [00:47<00:49, 419.29batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  50%|▍| 20346/40960 [00:47<00:49, 419.29batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  50%|▍| 20428/40960 [00:47<00:49, 415.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  50%|▍| 20428/40960 [00:47<00:49, 415.74batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  50%|▌| 20511/40960 [00:47<00:49, 415.07batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  50%|▌| 20511/40960 [00:47<00:49, 415.07batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  50%|▌| 20596/40960 [00:47<00:48, 416.89batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  50%|▌| 20596/40960 [00:47<00:48, 416.89batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  50%|▌| 20679/40960 [00:48<00:48, 415.10batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  50%|▌| 20679/40960 [00:48<00:48, 415.10batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  51%|▌| 20763/40960 [00:48<00:48, 416.44batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  51%|▌| 20763/40960 [00:48<00:48, 416.44batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  51%|▌| 20848/40960 [00:48<00:48, 418.07batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  51%|▌| 20848/40960 [00:48<00:48, 418.07batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  51%|▌| 20934/40960 [00:48<00:47, 420.50batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  51%|▌| 20934/40960 [00:48<00:47, 420.50batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  51%|▌| 21020/40960 [00:48<00:47, 422.30batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  51%|▌| 21020/40960 [00:48<00:47, 422.30batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  52%|▌| 21107/40960 [00:49<00:46, 425.25batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  52%|▌| 21107/40960 [00:49<00:46, 425.25batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  52%|▌| 21193/40960 [00:49<00:46, 425.87batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  52%|▌| 21193/40960 [00:49<00:46, 425.87batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  52%|▌| 21279/40960 [00:49<00:46, 425.87batches/s, l2_loss: 0.0479 - round_los\u001b[A\n",
      "Training:  52%|▌| 21279/40960 [00:49<00:46, 425.87batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  52%|▌| 21362/40960 [00:49<00:46, 421.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  52%|▌| 21362/40960 [00:49<00:46, 421.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  52%|▌| 21448/40960 [00:49<00:46, 423.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  52%|▌| 21448/40960 [00:49<00:46, 423.53batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21533/40960 [00:50<00:45, 423.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21533/40960 [00:50<00:45, 423.40batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21617/40960 [00:50<00:45, 421.55batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21617/40960 [00:50<00:45, 421.55batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21702/40960 [00:50<00:45, 421.37batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21702/40960 [00:50<00:45, 421.37batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21787/40960 [00:50<00:45, 421.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21787/40960 [00:50<00:45, 421.78batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21872/40960 [00:50<00:45, 421.28batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  53%|▌| 21872/40960 [00:50<00:45, 421.28batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 21959/40960 [00:51<00:44, 424.65batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 21959/40960 [00:51<00:44, 424.65batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 22043/40960 [00:51<00:44, 421.85batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 22043/40960 [00:51<00:44, 421.85batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 22127/40960 [00:51<00:44, 420.60batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 22127/40960 [00:51<00:44, 420.60batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 22214/40960 [00:51<00:44, 423.70batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 22214/40960 [00:51<00:44, 423.70batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 22301/40960 [00:51<00:43, 425.79batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  54%|▌| 22301/40960 [00:51<00:43, 425.79batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22387/40960 [00:52<00:43, 426.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22387/40960 [00:52<00:43, 426.16batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22472/40960 [00:52<00:43, 425.35batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22472/40960 [00:52<00:43, 425.35batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22554/40960 [00:52<00:43, 419.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22554/40960 [00:52<00:43, 419.95batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22638/40960 [00:52<00:43, 419.08batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22638/40960 [00:52<00:43, 419.08batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22719/40960 [00:52<00:43, 414.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  55%|▌| 22719/40960 [00:52<00:43, 414.62batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  56%|▌| 22801/40960 [00:53<00:43, 413.08batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  56%|▌| 22801/40960 [00:53<00:43, 413.08batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  56%|▌| 22888/40960 [00:53<00:43, 418.20batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  56%|▌| 22888/40960 [00:53<00:43, 418.20batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  56%|▌| 22973/40960 [00:53<00:42, 419.39batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  56%|▌| 22973/40960 [00:53<00:42, 419.39batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 23057/40960 [00:53<00:42, 418.35batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 23057/40960 [00:53<00:42, 418.35batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 23140/40960 [00:53<00:42, 417.07batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  56%|▌| 23140/40960 [00:53<00:42, 417.07batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  57%|▌| 23224/40960 [00:54<00:42, 417.42batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  57%|▌| 23224/40960 [00:54<00:42, 417.42batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23306/40960 [00:54<00:42, 414.59batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23306/40960 [00:54<00:42, 414.59batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23389/40960 [00:54<00:42, 413.17batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23389/40960 [00:54<00:42, 413.17batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23473/40960 [00:54<00:42, 413.82batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  57%|▌| 23473/40960 [00:54<00:42, 413.82batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23559/40960 [00:54<00:41, 418.56batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23559/40960 [00:54<00:41, 418.56batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23643/40960 [00:55<00:41, 418.52batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23643/40960 [00:55<00:41, 418.52batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  58%|▌| 23725/40960 [00:55<00:41, 415.82batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  58%|▌| 23725/40960 [00:55<00:41, 415.82batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23809/40960 [00:55<00:41, 416.74batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23809/40960 [00:55<00:41, 416.74batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23892/40960 [00:55<00:41, 415.82batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  58%|▌| 23892/40960 [00:55<00:41, 415.82batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  59%|▌| 23978/40960 [00:55<00:40, 418.72batches/s, l2_loss: 0.0480 - round_los\u001b[A\n",
      "Training:  59%|▌| 23978/40960 [00:55<00:40, 418.72batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24062/40960 [00:56<00:40, 418.23batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24062/40960 [00:56<00:40, 418.23batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24148/40960 [00:56<00:39, 420.70batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24148/40960 [00:56<00:39, 420.70batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24235/40960 [00:56<00:39, 424.71batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24235/40960 [00:56<00:39, 424.71batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24321/40960 [00:56<00:39, 425.37batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24321/40960 [00:56<00:39, 425.37batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24404/40960 [00:56<00:39, 422.20batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24404/40960 [00:56<00:39, 422.20batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24489/40960 [00:57<00:38, 423.01batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24489/40960 [00:57<00:38, 423.01batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24576/40960 [00:57<00:38, 425.71batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24576/40960 [00:57<00:38, 425.71batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24657/40960 [00:57<00:38, 419.21batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24657/40960 [00:57<00:38, 419.21batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24743/40960 [00:57<00:38, 422.12batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  60%|▌| 24743/40960 [00:57<00:38, 422.12batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [00:57<00:38, 419.79batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [00:57<00:38, 419.79batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24912/40960 [00:58<00:38, 422.06batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24912/40960 [00:58<00:38, 422.06batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24997/40960 [00:58<00:37, 421.87batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24997/40960 [00:58<00:37, 421.87batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25083/40960 [00:58<00:37, 423.64batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25083/40960 [00:58<00:37, 423.64batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25169/40960 [00:58<00:37, 424.24batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25169/40960 [00:58<00:37, 424.24batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25253/40960 [00:58<00:37, 422.87batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25253/40960 [00:58<00:37, 422.87batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25336/40960 [00:59<00:37, 420.43batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25336/40960 [00:59<00:37, 420.43batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25418/40960 [00:59<00:37, 416.99batches/s, l2_loss: 0.0481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25418/40960 [00:59<00:37, 416.99batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25503/40960 [00:59<00:36, 418.49batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25503/40960 [00:59<00:36, 418.49batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25588/40960 [00:59<00:36, 419.37batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25588/40960 [00:59<00:36, 419.37batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25673/40960 [00:59<00:36, 420.09batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25673/40960 [00:59<00:36, 420.09batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25760/40960 [01:00<00:35, 423.45batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25760/40960 [01:00<00:35, 423.45batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25845/40960 [01:00<00:35, 423.38batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25845/40960 [01:00<00:35, 423.38batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25931/40960 [01:00<00:35, 424.33batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25931/40960 [01:00<00:35, 424.33batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26018/40960 [01:00<00:34, 426.98batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26018/40960 [01:00<00:34, 426.98batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26103/40960 [01:00<00:34, 426.31batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26103/40960 [01:00<00:34, 426.31batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26189/40960 [01:01<00:34, 425.98batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26189/40960 [01:01<00:34, 425.98batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26274/40960 [01:01<00:34, 424.30batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26274/40960 [01:01<00:34, 424.30batches/s, l2_loss: 0.0482 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|▋| 26359/40960 [01:01<00:34, 424.26batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  64%|▋| 26359/40960 [01:01<00:34, 424.26batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26441/40960 [01:01<00:34, 418.86batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26441/40960 [01:01<00:34, 418.86batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26527/40960 [01:01<00:34, 421.50batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26527/40960 [01:01<00:34, 421.50batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26612/40960 [01:02<00:34, 421.29batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26612/40960 [01:02<00:34, 421.29batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26698/40960 [01:02<00:33, 423.14batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26698/40960 [01:02<00:33, 423.14batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26780/40960 [01:02<00:33, 418.04batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  65%|▋| 26780/40960 [01:02<00:33, 418.04batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  66%|▋| 26866/40960 [01:02<00:33, 421.49batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  66%|▋| 26866/40960 [01:02<00:33, 421.49batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  66%|▋| 26951/40960 [01:02<00:33, 422.25batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  66%|▋| 26951/40960 [01:03<00:33, 422.25batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  66%|▋| 27036/40960 [01:03<00:32, 422.77batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  66%|▋| 27036/40960 [01:03<00:32, 422.77batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  66%|▋| 27123/40960 [01:03<00:32, 425.27batches/s, l2_loss: 0.0482 - round_los\u001b[A\n",
      "Training:  66%|▋| 27123/40960 [01:03<00:32, 425.27batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  66%|▋| 27209/40960 [01:03<00:32, 425.53batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  66%|▋| 27209/40960 [01:03<00:32, 425.53batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27296/40960 [01:03<00:32, 426.96batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27296/40960 [01:03<00:32, 426.96batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27382/40960 [01:04<00:31, 427.35batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27382/40960 [01:04<00:31, 427.35batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27468/40960 [01:04<00:31, 427.88batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27468/40960 [01:04<00:31, 427.88batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27553/40960 [01:04<00:31, 426.91batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27553/40960 [01:04<00:31, 426.91batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27639/40960 [01:04<00:31, 427.41batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  67%|▋| 27639/40960 [01:04<00:31, 427.41batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  68%|▋| 27722/40960 [01:04<00:31, 423.09batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  68%|▋| 27722/40960 [01:04<00:31, 423.09batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  68%|▋| 27808/40960 [01:05<00:30, 424.68batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  68%|▋| 27808/40960 [01:05<00:30, 424.68batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  68%|▋| 27895/40960 [01:05<00:30, 427.70batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  68%|▋| 27895/40960 [01:05<00:30, 427.70batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  68%|▋| 27978/40960 [01:05<00:30, 422.34batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  68%|▋| 27978/40960 [01:05<00:30, 422.34batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  69%|▋| 28063/40960 [01:05<00:30, 422.75batches/s, l2_loss: 0.0483 - round_los\u001b[A\n",
      "Training:  69%|▋| 28063/40960 [01:05<00:30, 422.75batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  69%|▋| 28144/40960 [01:05<00:30, 417.15batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  69%|▋| 28144/40960 [01:05<00:30, 417.15batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  69%|▋| 28229/40960 [01:06<00:30, 418.69batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  69%|▋| 28229/40960 [01:06<00:30, 418.69batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  69%|▋| 28312/40960 [01:06<00:30, 417.31batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  69%|▋| 28312/40960 [01:06<00:30, 417.31batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  69%|▋| 28396/40960 [01:06<00:30, 417.37batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  69%|▋| 28396/40960 [01:06<00:30, 417.37batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28477/40960 [01:06<00:30, 413.32batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28477/40960 [01:06<00:30, 413.32batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28561/40960 [01:06<00:29, 414.18batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28561/40960 [01:06<00:29, 414.18batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28647/40960 [01:07<00:29, 418.10batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28647/40960 [01:07<00:29, 418.10batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28729/40960 [01:07<00:29, 415.50batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28729/40960 [01:07<00:29, 415.50batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28813/40960 [01:07<00:29, 415.64batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  70%|▋| 28813/40960 [01:07<00:29, 415.64batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 28899/40960 [01:07<00:28, 419.18batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 28899/40960 [01:07<00:28, 419.18batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 28985/40960 [01:07<00:28, 421.59batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 28985/40960 [01:07<00:28, 421.59batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 29072/40960 [01:08<00:27, 424.74batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 29072/40960 [01:08<00:27, 424.74batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 29158/40960 [01:08<00:27, 425.43batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 29158/40960 [01:08<00:27, 425.43batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 29240/40960 [01:08<00:27, 420.82batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  71%|▋| 29240/40960 [01:08<00:27, 420.82batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  72%|▋| 29324/40960 [01:08<00:27, 419.36batches/s, l2_loss: 0.0484 - round_los\u001b[A\n",
      "Training:  72%|▋| 29324/40960 [01:08<00:27, 419.36batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  72%|▋| 29408/40960 [01:08<00:27, 418.19batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  72%|▋| 29408/40960 [01:08<00:27, 418.19batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  72%|▋| 29490/40960 [01:09<00:27, 415.58batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  72%|▋| 29490/40960 [01:09<00:27, 415.58batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  72%|▋| 29570/40960 [01:09<00:27, 409.93batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  72%|▋| 29570/40960 [01:09<00:27, 409.93batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  72%|▋| 29651/40960 [01:09<00:27, 408.10batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  72%|▋| 29651/40960 [01:09<00:27, 408.10batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 29730/40960 [01:09<00:27, 403.47batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 29730/40960 [01:09<00:27, 403.47batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 29815/40960 [01:09<00:27, 409.14batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 29815/40960 [01:09<00:27, 409.14batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 29900/40960 [01:10<00:26, 413.50batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 29900/40960 [01:10<00:26, 413.50batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 29987/40960 [01:10<00:26, 418.58batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 29987/40960 [01:10<00:26, 418.58batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  73%|▋| 30070/40960 [01:10<00:26, 417.01batches/s, l2_loss: 0.0485 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|▋| 30070/40960 [01:10<00:26, 417.01batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  74%|▋| 30151/40960 [01:10<00:26, 413.19batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  74%|▋| 30151/40960 [01:10<00:26, 413.19batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  74%|▋| 30235/40960 [01:10<00:25, 414.26batches/s, l2_loss: 0.0485 - round_los\u001b[A\n",
      "Training:  74%|▋| 30235/40960 [01:10<00:25, 414.26batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  74%|▋| 30317/40960 [01:11<00:25, 412.35batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  74%|▋| 30317/40960 [01:11<00:25, 412.35batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  74%|▋| 30403/40960 [01:11<00:25, 417.03batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  74%|▋| 30403/40960 [01:11<00:25, 417.03batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  74%|▋| 30488/40960 [01:11<00:25, 418.34batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  74%|▋| 30488/40960 [01:11<00:25, 418.34batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  75%|▋| 30576/40960 [01:11<00:24, 423.50batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  75%|▋| 30576/40960 [01:11<00:24, 423.50batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  75%|▋| 30662/40960 [01:11<00:24, 424.94batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  75%|▋| 30662/40960 [01:11<00:24, 424.94batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  75%|▊| 30746/40960 [01:12<00:24, 422.14batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  75%|▊| 30746/40960 [01:12<00:24, 422.14batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  75%|▊| 30832/40960 [01:12<00:23, 423.20batches/s, l2_loss: 0.0486 - round_los\u001b[A\n",
      "Training:  75%|▊| 30832/40960 [01:12<00:23, 423.20batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  75%|▊| 30917/40960 [01:12<00:23, 422.54batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  75%|▊| 30917/40960 [01:12<00:23, 422.54batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31003/40960 [01:12<00:23, 423.91batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31003/40960 [01:12<00:23, 423.91batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31088/40960 [01:12<00:23, 423.33batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31088/40960 [01:12<00:23, 423.33batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31169/40960 [01:13<00:23, 416.59batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31169/40960 [01:13<00:23, 416.59batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31252/40960 [01:13<00:23, 415.07batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31252/40960 [01:13<00:23, 415.07batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31334/40960 [01:13<00:23, 412.82batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  76%|▊| 31334/40960 [01:13<00:23, 412.82batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  77%|▊| 31417/40960 [01:13<00:23, 412.63batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  77%|▊| 31417/40960 [01:13<00:23, 412.63batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  77%|▊| 31501/40960 [01:13<00:22, 414.58batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  77%|▊| 31501/40960 [01:13<00:22, 414.58batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  77%|▊| 31584/40960 [01:14<00:22, 414.33batches/s, l2_loss: 0.0487 - round_los\u001b[A\n",
      "Training:  77%|▊| 31584/40960 [01:14<00:22, 414.33batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  77%|▊| 31669/40960 [01:14<00:22, 416.24batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  77%|▊| 31669/40960 [01:14<00:22, 416.24batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 31754/40960 [01:14<00:22, 418.12batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 31754/40960 [01:14<00:22, 418.12batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 31838/40960 [01:14<00:21, 418.25batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 31838/40960 [01:14<00:21, 418.25batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 31920/40960 [01:14<00:21, 414.79batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 31920/40960 [01:14<00:21, 414.79batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 32002/40960 [01:15<00:21, 412.51batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 32002/40960 [01:15<00:21, 412.51batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 32083/40960 [01:15<00:21, 410.24batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  78%|▊| 32083/40960 [01:15<00:21, 410.24batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  79%|▊| 32164/40960 [01:15<00:21, 408.40batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  79%|▊| 32164/40960 [01:15<00:21, 408.40batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  79%|▊| 32245/40960 [01:15<00:21, 407.18batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  79%|▊| 32245/40960 [01:15<00:21, 407.18batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  79%|▊| 32329/40960 [01:15<00:21, 410.62batches/s, l2_loss: 0.0488 - round_los\u001b[A\n",
      "Training:  79%|▊| 32329/40960 [01:15<00:21, 410.62batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  79%|▊| 32414/40960 [01:16<00:20, 414.61batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  79%|▊| 32414/40960 [01:16<00:20, 414.61batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  79%|▊| 32499/40960 [01:16<00:20, 417.67batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  79%|▊| 32499/40960 [01:16<00:20, 417.67batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32584/40960 [01:16<00:19, 419.75batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32584/40960 [01:16<00:19, 419.75batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32672/40960 [01:16<00:19, 424.56batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32672/40960 [01:16<00:19, 424.56batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32759/40960 [01:16<00:19, 426.33batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32759/40960 [01:16<00:19, 426.33batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32843/40960 [01:17<00:19, 423.41batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32843/40960 [01:17<00:19, 423.41batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32930/40960 [01:17<00:18, 425.65batches/s, l2_loss: 0.0489 - round_los\u001b[A\n",
      "Training:  80%|▊| 32930/40960 [01:17<00:18, 425.65batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33018/40960 [01:17<00:18, 429.03batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33018/40960 [01:17<00:18, 429.03batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33101/40960 [01:17<00:18, 423.41batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33101/40960 [01:17<00:18, 423.41batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33188/40960 [01:17<00:18, 425.46batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33188/40960 [01:17<00:18, 425.46batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33273/40960 [01:18<00:18, 424.13batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33273/40960 [01:18<00:18, 424.13batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33359/40960 [01:18<00:17, 424.57batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  81%|▊| 33359/40960 [01:18<00:17, 424.57batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  82%|▊| 33444/40960 [01:18<00:17, 424.36batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  82%|▊| 33444/40960 [01:18<00:17, 424.36batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  82%|▊| 33530/40960 [01:18<00:17, 425.88batches/s, l2_loss: 0.0490 - round_los\u001b[A\n",
      "Training:  82%|▊| 33530/40960 [01:18<00:17, 425.88batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  82%|▊| 33616/40960 [01:18<00:17, 426.27batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  82%|▊| 33616/40960 [01:18<00:17, 426.27batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  82%|▊| 33705/40960 [01:19<00:16, 430.54batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  82%|▊| 33705/40960 [01:19<00:16, 430.54batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 33793/40960 [01:19<00:16, 432.48batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 33793/40960 [01:19<00:16, 432.48batches/s, l2_loss: 0.0491 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 33878/40960 [01:19<00:16, 429.03batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 33878/40960 [01:19<00:16, 429.03batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 33963/40960 [01:19<00:16, 426.79batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 33963/40960 [01:19<00:16, 426.79batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 34047/40960 [01:19<00:16, 424.34batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 34047/40960 [01:19<00:16, 424.34batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 34125/40960 [01:20<00:16, 413.43batches/s, l2_loss: 0.0491 - round_los\u001b[A\n",
      "Training:  83%|▊| 34125/40960 [01:20<00:16, 413.43batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34211/40960 [01:20<00:16, 417.89batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34211/40960 [01:20<00:16, 417.89batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34295/40960 [01:20<00:15, 417.41batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34295/40960 [01:20<00:15, 417.41batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34381/40960 [01:20<00:15, 421.08batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34381/40960 [01:20<00:15, 421.08batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34464/40960 [01:20<00:15, 419.01batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34464/40960 [01:20<00:15, 419.01batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34550/40960 [01:21<00:15, 421.99batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  84%|▊| 34550/40960 [01:21<00:15, 421.99batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  85%|▊| 34634/40960 [01:21<00:15, 421.21batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  85%|▊| 34634/40960 [01:21<00:15, 421.21batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  85%|▊| 34720/40960 [01:21<00:14, 422.48batches/s, l2_loss: 0.0492 - round_los\u001b[A\n",
      "Training:  85%|▊| 34720/40960 [01:21<00:14, 422.48batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  85%|▊| 34801/40960 [01:21<00:14, 417.00batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  85%|▊| 34801/40960 [01:21<00:14, 417.00batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  85%|▊| 34888/40960 [01:21<00:14, 421.01batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  85%|▊| 34888/40960 [01:21<00:14, 421.01batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  85%|▊| 34973/40960 [01:22<00:14, 421.46batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  85%|▊| 34973/40960 [01:22<00:14, 421.46batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  86%|▊| 35058/40960 [01:22<00:13, 422.37batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  86%|▊| 35058/40960 [01:22<00:13, 422.37batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  86%|▊| 35142/40960 [01:22<00:13, 421.00batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  86%|▊| 35142/40960 [01:22<00:13, 421.00batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  86%|▊| 35222/40960 [01:22<00:13, 413.90batches/s, l2_loss: 0.0493 - round_los\u001b[A\n",
      "Training:  86%|▊| 35222/40960 [01:22<00:13, 413.90batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  86%|▊| 35303/40960 [01:22<00:13, 410.77batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  86%|▊| 35303/40960 [01:22<00:13, 410.77batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  86%|▊| 35387/40960 [01:23<00:13, 413.01batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  86%|▊| 35387/40960 [01:23<00:13, 413.01batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  87%|▊| 35468/40960 [01:23<00:13, 409.98batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  87%|▊| 35468/40960 [01:23<00:13, 409.98batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  87%|▊| 35549/40960 [01:23<00:13, 407.14batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  87%|▊| 35549/40960 [01:23<00:13, 407.14batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  87%|▊| 35633/40960 [01:23<00:12, 410.28batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  87%|▊| 35633/40960 [01:23<00:12, 410.28batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  87%|▊| 35715/40960 [01:23<00:12, 409.95batches/s, l2_loss: 0.0494 - round_los\u001b[A\n",
      "Training:  87%|▊| 35715/40960 [01:23<00:12, 409.95batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  87%|▊| 35797/40960 [01:24<00:12, 409.81batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  87%|▊| 35797/40960 [01:24<00:12, 409.81batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 35880/40960 [01:24<00:12, 410.89batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 35880/40960 [01:24<00:12, 410.89batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 35960/40960 [01:24<00:12, 406.56batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 35960/40960 [01:24<00:12, 406.56batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 36039/40960 [01:24<00:12, 401.96batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 36039/40960 [01:24<00:12, 401.96batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 36124/40960 [01:24<00:11, 407.58batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 36124/40960 [01:24<00:11, 407.58batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 36209/40960 [01:25<00:11, 412.56batches/s, l2_loss: 0.0495 - round_los\u001b[A\n",
      "Training:  88%|▉| 36209/40960 [01:25<00:11, 412.56batches/s, l2_loss: 0.0496 - round_los\u001b[A\n",
      "Training:  89%|▉| 36297/40960 [01:25<00:11, 419.88batches/s, l2_loss: 0.0496 - round_los\u001b[A\n",
      "Training:  89%|▉| 36297/40960 [01:25<00:11, 419.88batches/s, l2_loss: 0.0496 - round_los\u001b[A\n",
      "Training:  89%|▉| 36381/40960 [01:25<00:10, 419.92batches/s, l2_loss: 0.0496 - round_los\u001b[A\n",
      "Training:  89%|▉| 36381/40960 [01:25<00:10, 419.92batches/s, l2_loss: 0.0496 - round_los\u001b[A\n",
      "Training:  89%|▉| 36466/40960 [01:25<00:10, 420.82batches/s, l2_loss: 0.0496 - round_los\u001b[A\n",
      "Training:  89%|▉| 36466/40960 [01:25<00:10, 420.82batches/s, l2_loss: 0.0496 - round_los\u001b[A\n",
      "Training:  89%|▉| 36551/40960 [01:25<00:10, 421.88batches/s, l2_loss: 0.0496 - round_los\u001b[A\n",
      "Training:  89%|▉| 36551/40960 [01:25<00:10, 421.88batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  89%|▉| 36634/40960 [01:26<00:10, 419.78batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  89%|▉| 36634/40960 [01:26<00:10, 419.78batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 36715/40960 [01:26<00:10, 414.19batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 36715/40960 [01:26<00:10, 414.19batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 36798/40960 [01:26<00:10, 413.25batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 36798/40960 [01:26<00:10, 413.25batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 36880/40960 [01:26<00:09, 412.11batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 36880/40960 [01:26<00:09, 412.11batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 36967/40960 [01:26<00:09, 418.39batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 36967/40960 [01:26<00:09, 418.39batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 37053/40960 [01:27<00:09, 421.67batches/s, l2_loss: 0.0497 - round_los\u001b[A\n",
      "Training:  90%|▉| 37053/40960 [01:27<00:09, 421.67batches/s, l2_loss: 0.0498 - round_los\u001b[A\n",
      "Training:  91%|▉| 37139/40960 [01:27<00:09, 422.78batches/s, l2_loss: 0.0498 - round_los\u001b[A\n",
      "Training:  91%|▉| 37139/40960 [01:27<00:09, 422.78batches/s, l2_loss: 0.0498 - round_los\u001b[A\n",
      "Training:  91%|▉| 37224/40960 [01:27<00:08, 422.41batches/s, l2_loss: 0.0498 - round_los\u001b[A\n",
      "Training:  91%|▉| 37224/40960 [01:27<00:08, 422.41batches/s, l2_loss: 0.0498 - round_los\u001b[A\n",
      "Training:  91%|▉| 37306/40960 [01:27<00:08, 418.31batches/s, l2_loss: 0.0498 - round_los\u001b[A\n",
      "Training:  91%|▉| 37306/40960 [01:27<00:08, 418.31batches/s, l2_loss: 0.0498 - round_los\u001b[A\n",
      "Training:  91%|▉| 37388/40960 [01:27<00:08, 415.53batches/s, l2_loss: 0.0498 - round_los\u001b[A\n",
      "Training:  91%|▉| 37388/40960 [01:27<00:08, 415.53batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  91%|▉| 37475/40960 [01:28<00:08, 421.11batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  91%|▉| 37475/40960 [01:28<00:08, 421.11batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  92%|▉| 37556/40960 [01:28<00:08, 414.97batches/s, l2_loss: 0.0499 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37556/40960 [01:28<00:08, 414.97batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  92%|▉| 37638/40960 [01:28<00:08, 413.02batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  92%|▉| 37638/40960 [01:28<00:08, 413.02batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  92%|▉| 37721/40960 [01:28<00:07, 412.60batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  92%|▉| 37721/40960 [01:28<00:07, 412.60batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  92%|▉| 37807/40960 [01:28<00:07, 417.48batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  92%|▉| 37807/40960 [01:28<00:07, 417.48batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  93%|▉| 37892/40960 [01:29<00:07, 418.41batches/s, l2_loss: 0.0499 - round_los\u001b[A\n",
      "Training:  93%|▉| 37892/40960 [01:29<00:07, 418.41batches/s, l2_loss: 0.0500 - round_los\u001b[A\n",
      "Training:  93%|▉| 37975/40960 [01:29<00:07, 416.51batches/s, l2_loss: 0.0500 - round_los\u001b[A\n",
      "Training:  93%|▉| 37975/40960 [01:29<00:07, 416.51batches/s, l2_loss: 0.0500 - round_los\u001b[A\n",
      "Training:  93%|▉| 38059/40960 [01:29<00:06, 417.42batches/s, l2_loss: 0.0500 - round_los\u001b[A\n",
      "Training:  93%|▉| 38059/40960 [01:29<00:06, 417.42batches/s, l2_loss: 0.0500 - round_los\u001b[A\n",
      "Training:  93%|▉| 38146/40960 [01:29<00:06, 421.84batches/s, l2_loss: 0.0500 - round_los\u001b[A\n",
      "Training:  93%|▉| 38146/40960 [01:29<00:06, 421.84batches/s, l2_loss: 0.0500 - round_los\u001b[A\n",
      "Training:  93%|▉| 38232/40960 [01:29<00:06, 422.72batches/s, l2_loss: 0.0500 - round_los\u001b[A\n",
      "Training:  93%|▉| 38232/40960 [01:29<00:06, 422.72batches/s, l2_loss: 0.0501 - round_los\u001b[A\n",
      "Training:  94%|▉| 38318/40960 [01:30<00:06, 424.40batches/s, l2_loss: 0.0501 - round_los\u001b[A\n",
      "Training:  94%|▉| 38318/40960 [01:30<00:06, 424.40batches/s, l2_loss: 0.0501 - round_los\u001b[A\n",
      "Training:  94%|▉| 38404/40960 [01:30<00:06, 425.68batches/s, l2_loss: 0.0501 - round_los\u001b[A\n",
      "Training:  94%|▉| 38404/40960 [01:30<00:06, 425.68batches/s, l2_loss: 0.0501 - round_los\u001b[A\n",
      "Training:  94%|▉| 38485/40960 [01:30<00:05, 418.30batches/s, l2_loss: 0.0501 - round_los\u001b[A\n",
      "Training:  94%|▉| 38485/40960 [01:30<00:05, 418.30batches/s, l2_loss: 0.0501 - round_los\u001b[A\n",
      "Training:  94%|▉| 38568/40960 [01:30<00:05, 416.02batches/s, l2_loss: 0.0501 - round_los\u001b[A\n",
      "Training:  94%|▉| 38568/40960 [01:30<00:05, 416.02batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  94%|▉| 38650/40960 [01:30<00:05, 412.90batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  94%|▉| 38650/40960 [01:30<00:05, 412.90batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 38735/40960 [01:31<00:05, 415.84batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 38735/40960 [01:31<00:05, 415.84batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 38818/40960 [01:31<00:05, 415.18batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 38818/40960 [01:31<00:05, 415.18batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 38902/40960 [01:31<00:04, 415.48batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 38902/40960 [01:31<00:04, 415.48batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 38987/40960 [01:31<00:04, 417.36batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 38987/40960 [01:31<00:04, 417.36batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 39071/40960 [01:31<00:04, 416.73batches/s, l2_loss: 0.0502 - round_los\u001b[A\n",
      "Training:  95%|▉| 39071/40960 [01:31<00:04, 416.73batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39159/40960 [01:32<00:04, 422.43batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39159/40960 [01:32<00:04, 422.43batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39245/40960 [01:32<00:04, 423.53batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39245/40960 [01:32<00:04, 423.53batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39328/40960 [01:32<00:03, 419.48batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39328/40960 [01:32<00:03, 419.48batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39415/40960 [01:32<00:03, 423.40batches/s, l2_loss: 0.0503 - round_los\u001b[A\n",
      "Training:  96%|▉| 39415/40960 [01:32<00:03, 423.40batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  96%|▉| 39499/40960 [01:32<00:03, 422.17batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  96%|▉| 39499/40960 [01:32<00:03, 422.17batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  97%|▉| 39584/40960 [01:33<00:03, 421.82batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  97%|▉| 39584/40960 [01:33<00:03, 421.82batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  97%|▉| 39669/40960 [01:33<00:03, 422.05batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  97%|▉| 39669/40960 [01:33<00:03, 422.05batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  97%|▉| 39753/40960 [01:33<00:02, 420.93batches/s, l2_loss: 0.0504 - round_los\u001b[A\n",
      "Training:  97%|▉| 39753/40960 [01:33<00:02, 420.93batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  97%|▉| 39836/40960 [01:33<00:02, 418.58batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  97%|▉| 39836/40960 [01:33<00:02, 418.58batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  97%|▉| 39917/40960 [01:33<00:02, 414.05batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  97%|▉| 39917/40960 [01:33<00:02, 414.05batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  98%|▉| 39999/40960 [01:34<00:02, 411.41batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  98%|▉| 39999/40960 [01:34<00:02, 411.41batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  98%|▉| 40078/40960 [01:34<00:02, 406.41batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  98%|▉| 40078/40960 [01:34<00:02, 406.41batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  98%|▉| 40161/40960 [01:34<00:01, 407.63batches/s, l2_loss: 0.0505 - round_los\u001b[A\n",
      "Training:  98%|▉| 40161/40960 [01:34<00:01, 407.63batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  98%|▉| 40247/40960 [01:34<00:01, 413.61batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  98%|▉| 40247/40960 [01:34<00:01, 413.61batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  98%|▉| 40330/40960 [01:34<00:01, 413.14batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  98%|▉| 40330/40960 [01:34<00:01, 413.14batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  99%|▉| 40416/40960 [01:35<00:01, 417.33batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  99%|▉| 40416/40960 [01:35<00:01, 417.33batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  99%|▉| 40500/40960 [01:35<00:01, 417.72batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  99%|▉| 40500/40960 [01:35<00:01, 417.72batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  99%|▉| 40584/40960 [01:35<00:00, 418.21batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  99%|▉| 40584/40960 [01:35<00:00, 418.21batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  99%|▉| 40665/40960 [01:35<00:00, 413.46batches/s, l2_loss: 0.0506 - round_los\u001b[A\n",
      "Training:  99%|▉| 40665/40960 [01:35<00:00, 413.46batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  99%|▉| 40750/40960 [01:35<00:00, 416.69batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training:  99%|▉| 40750/40960 [01:35<00:00, 416.69batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training: 100%|▉| 40835/40960 [01:36<00:00, 418.92batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training: 100%|▉| 40835/40960 [01:36<00:00, 418.92batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training: 100%|▉| 40919/40960 [01:36<00:00, 417.88batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "Training: 100%|▉| 40919/40960 [01:36<00:00, 417.88batches/s, l2_loss: 0.0507 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:16:33.606551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  54%|▌| 14/26 [28:53<24:05, 120.47s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:16:34.862429: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:16:40.088678: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<18:39:53,  1.64s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<18:39:53,  1.64s/batches, l2_loss: 0.2368 - round_loss:\u001b[A\n",
      "Training:   0%| | 67/40960 [00:01<13:47, 49.39batches/s, l2_loss: 0.2368 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 67/40960 [00:01<13:47, 49.39batches/s, l2_loss: 0.1554 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 138/40960 [00:02<06:38, 102.54batches/s, l2_loss: 0.1554 - round_loss:\u001b[A\n",
      "Training:   0%| | 138/40960 [00:02<06:38, 102.54batches/s, l2_loss: 0.1516 - round_loss:\u001b[A\n",
      "Training:   1%| | 207/40960 [00:02<04:31, 149.85batches/s, l2_loss: 0.1516 - round_loss:\u001b[A\n",
      "Training:   1%| | 207/40960 [00:02<04:31, 149.85batches/s, l2_loss: 0.1434 - round_loss:\u001b[A\n",
      "Training:   1%| | 259/40960 [00:02<03:53, 174.08batches/s, l2_loss: 0.1434 - round_loss:\u001b[A\n",
      "Training:   1%| | 259/40960 [00:02<03:53, 174.08batches/s, l2_loss: 0.1450 - round_loss:\u001b[A\n",
      "Training:   1%| | 324/40960 [00:02<03:13, 209.97batches/s, l2_loss: 0.1450 - round_loss:\u001b[A\n",
      "Training:   1%| | 324/40960 [00:02<03:13, 209.97batches/s, l2_loss: 0.1425 - round_loss:\u001b[A\n",
      "Training:   1%| | 393/40960 [00:02<02:46, 243.87batches/s, l2_loss: 0.1425 - round_loss:\u001b[A\n",
      "Training:   1%| | 393/40960 [00:02<02:46, 243.87batches/s, l2_loss: 0.1423 - round_loss:\u001b[A\n",
      "Training:   1%| | 457/40960 [00:03<02:33, 263.69batches/s, l2_loss: 0.1423 - round_loss:\u001b[A\n",
      "Training:   1%| | 457/40960 [00:03<02:33, 263.69batches/s, l2_loss: 0.1415 - round_loss:\u001b[A\n",
      "Training:   1%| | 518/40960 [00:03<02:27, 274.49batches/s, l2_loss: 0.1415 - round_loss:\u001b[A\n",
      "Training:   1%| | 518/40960 [00:03<02:27, 274.49batches/s, l2_loss: 0.1407 - round_loss:\u001b[A\n",
      "Training:   1%| | 578/40960 [00:03<02:23, 281.40batches/s, l2_loss: 0.1407 - round_loss:\u001b[A\n",
      "Training:   1%| | 578/40960 [00:03<02:23, 281.40batches/s, l2_loss: 0.1386 - round_loss:\u001b[A\n",
      "Training:   2%| | 643/40960 [00:03<02:17, 292.25batches/s, l2_loss: 0.1386 - round_loss:\u001b[A\n",
      "Training:   2%| | 643/40960 [00:03<02:17, 292.25batches/s, l2_loss: 0.1377 - round_loss:\u001b[A\n",
      "Training:   2%| | 699/40960 [00:03<02:19, 288.12batches/s, l2_loss: 0.1377 - round_loss:\u001b[A\n",
      "Training:   2%| | 699/40960 [00:03<02:19, 288.12batches/s, l2_loss: 0.1367 - round_loss:\u001b[A\n",
      "Training:   2%| | 759/40960 [00:04<02:17, 291.57batches/s, l2_loss: 0.1367 - round_loss:\u001b[A\n",
      "Training:   2%| | 759/40960 [00:04<02:17, 291.57batches/s, l2_loss: 0.1361 - round_loss:\u001b[A\n",
      "Training:   2%| | 819/40960 [00:04<02:16, 293.06batches/s, l2_loss: 0.1361 - round_loss:\u001b[A\n",
      "Training:   2%| | 819/40960 [00:04<02:16, 293.06batches/s, l2_loss: 0.1353 - round_loss:\u001b[A\n",
      "Training:   2%| | 879/40960 [00:04<02:16, 293.64batches/s, l2_loss: 0.1353 - round_loss:\u001b[A\n",
      "Training:   2%| | 879/40960 [00:04<02:16, 293.64batches/s, l2_loss: 0.1341 - round_loss:\u001b[A\n",
      "Training:   2%| | 943/40960 [00:04<02:12, 301.02batches/s, l2_loss: 0.1341 - round_loss:\u001b[A\n",
      "Training:   2%| | 943/40960 [00:04<02:12, 301.02batches/s, l2_loss: 0.1332 - round_loss:\u001b[A\n",
      "Training:   2%| | 1004/40960 [00:04<02:12, 302.17batches/s, l2_loss: 0.1332 - round_loss\u001b[A\n",
      "Training:   2%| | 1004/40960 [00:04<02:12, 302.17batches/s, l2_loss: 0.1326 - round_loss\u001b[A\n",
      "Training:   3%| | 1063/40960 [00:05<02:13, 299.00batches/s, l2_loss: 0.1326 - round_loss\u001b[A\n",
      "Training:   3%| | 1063/40960 [00:05<02:13, 299.00batches/s, l2_loss: 0.1320 - round_loss\u001b[A\n",
      "Training:   3%| | 1131/40960 [00:05<02:08, 309.99batches/s, l2_loss: 0.1320 - round_loss\u001b[A\n",
      "Training:   3%| | 1131/40960 [00:05<02:08, 309.99batches/s, l2_loss: 0.1323 - round_loss\u001b[A\n",
      "Training:   3%| | 1203/40960 [00:05<02:02, 324.32batches/s, l2_loss: 0.1323 - round_loss\u001b[A\n",
      "Training:   3%| | 1203/40960 [00:05<02:02, 324.32batches/s, l2_loss: 0.1322 - round_loss\u001b[A\n",
      "Training:   3%| | 1273/40960 [00:05<01:59, 331.11batches/s, l2_loss: 0.1322 - round_loss\u001b[A\n",
      "Training:   3%| | 1273/40960 [00:05<01:59, 331.11batches/s, l2_loss: 0.1308 - round_loss\u001b[A\n",
      "Training:   3%| | 1337/40960 [00:05<02:01, 327.37batches/s, l2_loss: 0.1308 - round_loss\u001b[A\n",
      "Training:   3%| | 1337/40960 [00:05<02:01, 327.37batches/s, l2_loss: 0.1306 - round_loss\u001b[A\n",
      "Training:   3%| | 1406/40960 [00:06<01:59, 332.33batches/s, l2_loss: 0.1306 - round_loss\u001b[A\n",
      "Training:   3%| | 1406/40960 [00:06<01:59, 332.33batches/s, l2_loss: 0.1297 - round_loss\u001b[A\n",
      "Training:   4%| | 1477/40960 [00:06<01:56, 338.19batches/s, l2_loss: 0.1297 - round_loss\u001b[A\n",
      "Training:   4%| | 1477/40960 [00:06<01:56, 338.19batches/s, l2_loss: 0.1294 - round_loss\u001b[A\n",
      "Training:   4%| | 1546/40960 [00:06<01:55, 340.23batches/s, l2_loss: 0.1294 - round_loss\u001b[A\n",
      "Training:   4%| | 1546/40960 [00:06<01:55, 340.23batches/s, l2_loss: 0.1294 - round_loss\u001b[A\n",
      "Training:   4%| | 1616/40960 [00:06<01:55, 341.69batches/s, l2_loss: 0.1294 - round_loss\u001b[A\n",
      "Training:   4%| | 1616/40960 [00:06<01:55, 341.69batches/s, l2_loss: 0.1288 - round_loss\u001b[A\n",
      "Training:   4%| | 1684/40960 [00:06<01:55, 340.18batches/s, l2_loss: 0.1288 - round_loss\u001b[A\n",
      "Training:   4%| | 1684/40960 [00:06<01:55, 340.18batches/s, l2_loss: 0.1276 - round_loss\u001b[A\n",
      "Training:   4%| | 1747/40960 [00:07<01:58, 331.37batches/s, l2_loss: 0.1276 - round_loss\u001b[A\n",
      "Training:   4%| | 1747/40960 [00:07<01:58, 331.37batches/s, l2_loss: 0.1273 - round_loss\u001b[A\n",
      "Training:   4%| | 1807/40960 [00:07<02:01, 321.10batches/s, l2_loss: 0.1273 - round_loss\u001b[A\n",
      "Training:   4%| | 1807/40960 [00:07<02:01, 321.10batches/s, l2_loss: 0.1273 - round_loss\u001b[A\n",
      "Training:   5%| | 1873/40960 [00:07<02:01, 322.69batches/s, l2_loss: 0.1273 - round_loss\u001b[A\n",
      "Training:   5%| | 1873/40960 [00:07<02:01, 322.69batches/s, l2_loss: 0.1269 - round_loss\u001b[A\n",
      "Training:   5%| | 1921/40960 [00:07<02:12, 295.09batches/s, l2_loss: 0.1269 - round_loss\u001b[A\n",
      "Training:   5%| | 1921/40960 [00:07<02:12, 295.09batches/s, l2_loss: 0.1264 - round_loss\u001b[A\n",
      "Training:   5%| | 1976/40960 [00:07<02:14, 288.91batches/s, l2_loss: 0.1264 - round_loss\u001b[A\n",
      "Training:   5%| | 1976/40960 [00:07<02:14, 288.91batches/s, l2_loss: 0.1261 - round_loss\u001b[A\n",
      "Training:   5%| | 2038/40960 [00:08<02:12, 294.62batches/s, l2_loss: 0.1261 - round_loss\u001b[A\n",
      "Training:   5%| | 2038/40960 [00:08<02:12, 294.62batches/s, l2_loss: 0.1258 - round_loss\u001b[A\n",
      "Training:   5%| | 2096/40960 [00:08<02:12, 292.51batches/s, l2_loss: 0.1258 - round_loss\u001b[A\n",
      "Training:   5%| | 2096/40960 [00:08<02:12, 292.51batches/s, l2_loss: 0.1255 - round_loss\u001b[A\n",
      "Training:   5%| | 2168/40960 [00:08<02:04, 311.85batches/s, l2_loss: 0.1255 - round_loss\u001b[A\n",
      "Training:   5%| | 2168/40960 [00:08<02:04, 311.85batches/s, l2_loss: 0.1251 - round_loss\u001b[A\n",
      "Training:   5%| | 2241/40960 [00:08<01:58, 326.90batches/s, l2_loss: 0.1251 - round_loss\u001b[A\n",
      "Training:   5%| | 2241/40960 [00:08<01:58, 326.90batches/s, l2_loss: 0.1244 - round_loss\u001b[A\n",
      "Training:   6%| | 2309/40960 [00:08<01:56, 330.64batches/s, l2_loss: 0.1244 - round_loss\u001b[A\n",
      "Training:   6%| | 2309/40960 [00:08<01:56, 330.64batches/s, l2_loss: 0.1244 - round_loss\u001b[A\n",
      "Training:   6%| | 2382/40960 [00:09<01:53, 340.63batches/s, l2_loss: 0.1244 - round_loss\u001b[A\n",
      "Training:   6%| | 2382/40960 [00:09<01:53, 340.63batches/s, l2_loss: 0.1242 - round_loss\u001b[A\n",
      "Training:   6%| | 2452/40960 [00:09<01:52, 342.70batches/s, l2_loss: 0.1242 - round_loss\u001b[A\n",
      "Training:   6%| | 2452/40960 [00:09<01:52, 342.70batches/s, l2_loss: 0.1242 - round_loss\u001b[A\n",
      "Training:   6%| | 2516/40960 [00:09<01:54, 334.33batches/s, l2_loss: 0.1242 - round_loss\u001b[A\n",
      "Training:   6%| | 2516/40960 [00:09<01:54, 334.33batches/s, l2_loss: 0.1236 - round_loss\u001b[A\n",
      "Training:   6%| | 2578/40960 [00:09<01:57, 325.49batches/s, l2_loss: 0.1236 - round_loss\u001b[A\n",
      "Training:   6%| | 2578/40960 [00:09<01:57, 325.49batches/s, l2_loss: 0.1232 - round_loss\u001b[A\n",
      "Training:   6%| | 2648/40960 [00:09<01:55, 331.67batches/s, l2_loss: 0.1232 - round_loss\u001b[A\n",
      "Training:   6%| | 2648/40960 [00:09<01:55, 331.67batches/s, l2_loss: 0.1230 - round_loss\u001b[A\n",
      "Training:   7%| | 2718/40960 [00:10<01:53, 336.03batches/s, l2_loss: 0.1230 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 2718/40960 [00:10<01:53, 336.03batches/s, l2_loss: 0.1225 - round_loss\u001b[A\n",
      "Training:   7%| | 2784/40960 [00:10<01:54, 333.03batches/s, l2_loss: 0.1225 - round_loss\u001b[A\n",
      "Training:   7%| | 2784/40960 [00:10<01:54, 333.03batches/s, l2_loss: 0.1223 - round_loss\u001b[A\n",
      "Training:   7%| | 2844/40960 [00:10<01:58, 322.37batches/s, l2_loss: 0.1223 - round_loss\u001b[A\n",
      "Training:   7%| | 2844/40960 [00:10<01:58, 322.37batches/s, l2_loss: 0.1224 - round_loss\u001b[A\n",
      "Training:   7%| | 2910/40960 [00:10<01:57, 324.50batches/s, l2_loss: 0.1224 - round_loss\u001b[A\n",
      "Training:   7%| | 2910/40960 [00:10<01:57, 324.50batches/s, l2_loss: 0.1220 - round_loss\u001b[A\n",
      "Training:   7%| | 2983/40960 [00:10<01:53, 335.23batches/s, l2_loss: 0.1220 - round_loss\u001b[A\n",
      "Training:   7%| | 2983/40960 [00:10<01:53, 335.23batches/s, l2_loss: 0.1217 - round_loss\u001b[A\n",
      "Training:   7%| | 3052/40960 [00:11<01:52, 337.46batches/s, l2_loss: 0.1217 - round_loss\u001b[A\n",
      "Training:   7%| | 3052/40960 [00:11<01:52, 337.46batches/s, l2_loss: 0.1215 - round_loss\u001b[A\n",
      "Training:   8%| | 3118/40960 [00:11<01:53, 334.19batches/s, l2_loss: 0.1215 - round_loss\u001b[A\n",
      "Training:   8%| | 3118/40960 [00:11<01:53, 334.19batches/s, l2_loss: 0.1214 - round_loss\u001b[A\n",
      "Training:   8%| | 3187/40960 [00:11<01:52, 337.22batches/s, l2_loss: 0.1214 - round_loss\u001b[A\n",
      "Training:   8%| | 3187/40960 [00:11<01:52, 337.22batches/s, l2_loss: 0.1211 - round_loss\u001b[A\n",
      "Training:   8%| | 3256/40960 [00:11<01:51, 338.89batches/s, l2_loss: 0.1211 - round_loss\u001b[A\n",
      "Training:   8%| | 3256/40960 [00:11<01:51, 338.89batches/s, l2_loss: 0.1208 - round_loss\u001b[A\n",
      "Training:   8%| | 3324/40960 [00:11<01:51, 339.05batches/s, l2_loss: 0.1208 - round_loss\u001b[A\n",
      "Training:   8%| | 3324/40960 [00:11<01:51, 339.05batches/s, l2_loss: 0.1206 - round_loss\u001b[A\n",
      "Training:   8%| | 3394/40960 [00:12<01:49, 342.03batches/s, l2_loss: 0.1206 - round_loss\u001b[A\n",
      "Training:   8%| | 3394/40960 [00:12<01:49, 342.03batches/s, l2_loss: 0.1202 - round_loss\u001b[A\n",
      "Training:   8%| | 3464/40960 [00:12<01:49, 343.88batches/s, l2_loss: 0.1202 - round_loss\u001b[A\n",
      "Training:   8%| | 3464/40960 [00:12<01:49, 343.88batches/s, l2_loss: 0.1201 - round_loss\u001b[A\n",
      "Training:   9%| | 3532/40960 [00:12<01:49, 342.38batches/s, l2_loss: 0.1201 - round_loss\u001b[A\n",
      "Training:   9%| | 3532/40960 [00:12<01:49, 342.38batches/s, l2_loss: 0.1202 - round_loss\u001b[A\n",
      "Training:   9%| | 3602/40960 [00:12<01:48, 344.63batches/s, l2_loss: 0.1202 - round_loss\u001b[A\n",
      "Training:   9%| | 3602/40960 [00:12<01:48, 344.63batches/s, l2_loss: 0.1197 - round_loss\u001b[A\n",
      "Training:   9%| | 3672/40960 [00:12<01:47, 345.29batches/s, l2_loss: 0.1197 - round_loss\u001b[A\n",
      "Training:   9%| | 3672/40960 [00:12<01:47, 345.29batches/s, l2_loss: 0.1196 - round_loss\u001b[A\n",
      "Training:   9%| | 3742/40960 [00:13<01:47, 345.43batches/s, l2_loss: 0.1196 - round_loss\u001b[A\n",
      "Training:   9%| | 3742/40960 [00:13<01:47, 345.43batches/s, l2_loss: 0.1196 - round_loss\u001b[A\n",
      "Training:   9%| | 3810/40960 [00:13<01:48, 342.66batches/s, l2_loss: 0.1196 - round_loss\u001b[A\n",
      "Training:   9%| | 3810/40960 [00:13<01:48, 342.66batches/s, l2_loss: 0.1192 - round_loss\u001b[A\n",
      "Training:   9%| | 3880/40960 [00:13<01:47, 344.66batches/s, l2_loss: 0.1192 - round_loss\u001b[A\n",
      "Training:   9%| | 3880/40960 [00:13<01:47, 344.66batches/s, l2_loss: 0.1194 - round_loss\u001b[A\n",
      "Training:  10%| | 3950/40960 [00:13<01:46, 346.03batches/s, l2_loss: 0.1194 - round_loss\u001b[A\n",
      "Training:  10%| | 3950/40960 [00:13<01:46, 346.03batches/s, l2_loss: 0.1190 - round_loss\u001b[A\n",
      "Training:  10%| | 4018/40960 [00:13<01:47, 343.36batches/s, l2_loss: 0.1190 - round_loss\u001b[A\n",
      "Training:  10%| | 4018/40960 [00:13<01:47, 343.36batches/s, l2_loss: 0.1188 - round_loss\u001b[A\n",
      "Training:  10%| | 4086/40960 [00:14<01:48, 341.37batches/s, l2_loss: 0.1188 - round_loss\u001b[A\n",
      "Training:  10%| | 4086/40960 [00:14<01:48, 341.37batches/s, l2_loss: 0.1185 - round_loss\u001b[A\n",
      "Training:  10%| | 4151/40960 [00:14<01:49, 336.17batches/s, l2_loss: 0.1185 - round_loss\u001b[A\n",
      "Training:  10%| | 4151/40960 [00:14<01:49, 336.17batches/s, l2_loss: 0.1183 - round_loss\u001b[A\n",
      "Training:  10%| | 4222/40960 [00:14<01:47, 341.31batches/s, l2_loss: 0.1183 - round_loss\u001b[A\n",
      "Training:  10%| | 4222/40960 [00:14<01:47, 341.31batches/s, l2_loss: 0.1183 - round_loss\u001b[A\n",
      "Training:  10%| | 4294/40960 [00:14<01:46, 345.84batches/s, l2_loss: 0.1183 - round_loss\u001b[A\n",
      "Training:  10%| | 4294/40960 [00:14<01:46, 345.84batches/s, l2_loss: 0.1179 - round_loss\u001b[A\n",
      "Training:  11%| | 4366/40960 [00:14<01:44, 349.02batches/s, l2_loss: 0.1179 - round_loss\u001b[A\n",
      "Training:  11%| | 4366/40960 [00:14<01:44, 349.02batches/s, l2_loss: 0.1181 - round_loss\u001b[A\n",
      "Training:  11%| | 4436/40960 [00:15<01:44, 348.03batches/s, l2_loss: 0.1181 - round_loss\u001b[A\n",
      "Training:  11%| | 4436/40960 [00:15<01:44, 348.03batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:  11%| | 4507/40960 [00:15<01:44, 349.39batches/s, l2_loss: 0.1177 - round_loss\u001b[A\n",
      "Training:  11%| | 4507/40960 [00:15<01:44, 349.39batches/s, l2_loss: 0.1176 - round_loss\u001b[A\n",
      "Training:  11%| | 4578/40960 [00:15<01:43, 350.65batches/s, l2_loss: 0.1176 - round_loss\u001b[A\n",
      "Training:  11%| | 4578/40960 [00:15<01:43, 350.65batches/s, l2_loss: 0.1175 - round_loss\u001b[A\n",
      "Training:  11%| | 4648/40960 [00:15<01:44, 349.10batches/s, l2_loss: 0.1175 - round_loss\u001b[A\n",
      "Training:  11%| | 4648/40960 [00:15<01:44, 349.10batches/s, l2_loss: 0.1173 - round_loss\u001b[A\n",
      "Training:  12%| | 4715/40960 [00:15<01:45, 344.13batches/s, l2_loss: 0.1173 - round_loss\u001b[A\n",
      "Training:  12%| | 4715/40960 [00:15<01:45, 344.13batches/s, l2_loss: 0.1170 - round_loss\u001b[A\n",
      "Training:  12%| | 4783/40960 [00:16<01:45, 342.08batches/s, l2_loss: 0.1170 - round_loss\u001b[A\n",
      "Training:  12%| | 4783/40960 [00:16<01:45, 342.08batches/s, l2_loss: 0.1173 - round_loss\u001b[A\n",
      "Training:  12%| | 4852/40960 [00:16<01:45, 342.77batches/s, l2_loss: 0.1173 - round_loss\u001b[A\n",
      "Training:  12%| | 4852/40960 [00:16<01:45, 342.77batches/s, l2_loss: 0.1169 - round_loss\u001b[A\n",
      "Training:  12%| | 4922/40960 [00:16<01:44, 344.17batches/s, l2_loss: 0.1169 - round_loss\u001b[A\n",
      "Training:  12%| | 4922/40960 [00:16<01:44, 344.17batches/s, l2_loss: 0.1169 - round_loss\u001b[A\n",
      "Training:  12%| | 4992/40960 [00:16<01:44, 344.76batches/s, l2_loss: 0.1169 - round_loss\u001b[A\n",
      "Training:  12%| | 4992/40960 [00:16<01:44, 344.76batches/s, l2_loss: 0.1167 - round_loss\u001b[A\n",
      "Training:  12%| | 5064/40960 [00:16<01:42, 348.76batches/s, l2_loss: 0.1167 - round_loss\u001b[A\n",
      "Training:  12%| | 5064/40960 [00:16<01:42, 348.76batches/s, l2_loss: 0.1166 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5134/40960 [00:17<01:42, 348.89batches/s, l2_loss: 0.1166 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5134/40960 [00:17<01:42, 348.89batches/s, l2_loss: 0.1164 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5193/40960 [00:17<01:47, 331.71batches/s, l2_loss: 0.1164 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5193/40960 [00:17<01:47, 331.71batches/s, l2_loss: 0.1164 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5235/40960 [00:17<02:01, 293.93batches/s, l2_loss: 0.1164 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5235/40960 [00:17<02:01, 293.93batches/s, l2_loss: 0.1162 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5275/40960 [00:17<02:15, 263.37batches/s, l2_loss: 0.1162 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5275/40960 [00:17<02:15, 263.37batches/s, l2_loss: 0.1162 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5329/40960 [00:17<02:14, 264.63batches/s, l2_loss: 0.1162 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5329/40960 [00:17<02:14, 264.63batches/s, l2_loss: 0.1162 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5386/40960 [00:18<02:11, 270.60batches/s, l2_loss: 0.1162 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5386/40960 [00:18<02:11, 270.60batches/s, l2_loss: 0.1160 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5438/40960 [00:18<02:13, 266.31batches/s, l2_loss: 0.1160 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5438/40960 [00:18<02:13, 266.31batches/s, l2_loss: 0.1159 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5487/40960 [00:18<02:16, 258.98batches/s, l2_loss: 0.1159 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5487/40960 [00:18<02:16, 258.98batches/s, l2_loss: 0.1158 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5550/40960 [00:18<02:09, 272.87batches/s, l2_loss: 0.1158 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5550/40960 [00:18<02:09, 272.87batches/s, l2_loss: 0.1158 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5606/40960 [00:18<02:08, 274.47batches/s, l2_loss: 0.1158 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5606/40960 [00:19<02:08, 274.47batches/s, l2_loss: 0.1156 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|▏| 5664/40960 [00:19<02:07, 277.31batches/s, l2_loss: 0.1156 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5664/40960 [00:19<02:07, 277.31batches/s, l2_loss: 0.1154 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5724/40960 [00:19<02:04, 283.98batches/s, l2_loss: 0.1154 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5724/40960 [00:19<02:04, 283.98batches/s, l2_loss: 0.1154 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5789/40960 [00:19<01:58, 295.99batches/s, l2_loss: 0.1154 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5789/40960 [00:19<01:58, 295.99batches/s, l2_loss: 0.1152 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5858/40960 [00:19<01:53, 309.40batches/s, l2_loss: 0.1152 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5858/40960 [00:19<01:53, 309.40batches/s, l2_loss: 0.1151 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5927/40960 [00:20<01:49, 319.01batches/s, l2_loss: 0.1151 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5927/40960 [00:20<01:49, 319.01batches/s, l2_loss: 0.1150 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5995/40960 [00:20<01:47, 324.03batches/s, l2_loss: 0.1150 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5995/40960 [00:20<01:47, 324.03batches/s, l2_loss: 0.1149 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6064/40960 [00:20<01:45, 329.68batches/s, l2_loss: 0.1149 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6064/40960 [00:20<01:45, 329.68batches/s, l2_loss: 0.1148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6132/40960 [00:20<01:45, 331.64batches/s, l2_loss: 0.1148 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6132/40960 [00:20<01:45, 331.64batches/s, l2_loss: 0.1149 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6195/40960 [00:20<01:46, 326.21batches/s, l2_loss: 0.1149 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6195/40960 [00:20<01:46, 326.21batches/s, l2_loss: 0.1147 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6252/40960 [00:21<01:51, 312.13batches/s, l2_loss: 0.1147 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6252/40960 [00:21<01:51, 312.13batches/s, l2_loss: 0.1146 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6314/40960 [00:21<01:51, 311.12batches/s, l2_loss: 0.1146 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6314/40960 [00:21<01:51, 311.12batches/s, l2_loss: 0.1147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6382/40960 [00:21<01:48, 319.20batches/s, l2_loss: 0.1147 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6382/40960 [00:21<01:48, 319.20batches/s, l2_loss: 0.1145 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6451/40960 [00:21<01:45, 326.89batches/s, l2_loss: 0.1145 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6451/40960 [00:21<01:45, 326.89batches/s, l2_loss: 0.1144 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6515/40960 [00:21<01:46, 322.97batches/s, l2_loss: 0.1144 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6515/40960 [00:21<01:46, 322.97batches/s, l2_loss: 0.1143 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6575/40960 [00:22<01:48, 315.48batches/s, l2_loss: 0.1143 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6575/40960 [00:22<01:48, 315.48batches/s, l2_loss: 0.1141 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6643/40960 [00:22<01:46, 322.27batches/s, l2_loss: 0.1141 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6643/40960 [00:22<01:46, 322.27batches/s, l2_loss: 0.1140 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6705/40960 [00:22<01:47, 317.58batches/s, l2_loss: 0.1140 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6705/40960 [00:22<01:47, 317.58batches/s, l2_loss: 0.1141 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6769/40960 [00:22<01:47, 317.88batches/s, l2_loss: 0.1141 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6769/40960 [00:22<01:47, 317.88batches/s, l2_loss: 0.1140 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6837/40960 [00:22<01:45, 324.17batches/s, l2_loss: 0.1140 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6837/40960 [00:22<01:45, 324.17batches/s, l2_loss: 0.1138 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6904/40960 [00:23<01:44, 325.86batches/s, l2_loss: 0.1138 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6904/40960 [00:23<01:44, 325.86batches/s, l2_loss: 0.1137 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6976/40960 [00:23<01:41, 334.80batches/s, l2_loss: 0.1137 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6976/40960 [00:23<01:41, 334.80batches/s, l2_loss: 0.1138 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7045/40960 [00:23<01:40, 337.62batches/s, l2_loss: 0.1138 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7045/40960 [00:23<01:40, 337.62batches/s, l2_loss: 0.1136 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7115/40960 [00:23<01:39, 340.66batches/s, l2_loss: 0.1136 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7115/40960 [00:23<01:39, 340.66batches/s, l2_loss: 0.1136 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7186/40960 [00:23<01:38, 344.40batches/s, l2_loss: 0.1136 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7186/40960 [00:23<01:38, 344.40batches/s, l2_loss: 0.1134 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7248/40960 [00:24<01:40, 333.95batches/s, l2_loss: 0.1134 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7248/40960 [00:24<01:40, 333.95batches/s, l2_loss: 0.1135 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7309/40960 [00:24<01:43, 324.21batches/s, l2_loss: 0.1135 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7309/40960 [00:24<01:43, 324.21batches/s, l2_loss: 0.1134 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7366/40960 [00:24<01:47, 312.26batches/s, l2_loss: 0.1134 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7366/40960 [00:24<01:47, 312.26batches/s, l2_loss: 0.1133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7423/40960 [00:24<01:50, 304.11batches/s, l2_loss: 0.1133 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7423/40960 [00:24<01:50, 304.11batches/s, l2_loss: 0.1132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7488/40960 [00:24<01:47, 310.07batches/s, l2_loss: 0.1132 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7488/40960 [00:24<01:47, 310.07batches/s, l2_loss: 0.1131 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7547/40960 [00:25<01:49, 303.91batches/s, l2_loss: 0.1131 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7547/40960 [00:25<01:49, 303.91batches/s, l2_loss: 0.1130 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7613/40960 [00:25<01:47, 310.98batches/s, l2_loss: 0.1130 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7613/40960 [00:25<01:47, 310.98batches/s, l2_loss: 0.1131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7679/40960 [00:25<01:45, 315.52batches/s, l2_loss: 0.1131 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7679/40960 [00:25<01:45, 315.52batches/s, l2_loss: 0.1129 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7747/40960 [00:25<01:43, 322.34batches/s, l2_loss: 0.1129 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7747/40960 [00:25<01:43, 322.34batches/s, l2_loss: 0.1129 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7814/40960 [00:25<01:41, 325.32batches/s, l2_loss: 0.1129 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7814/40960 [00:25<01:41, 325.32batches/s, l2_loss: 0.1128 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7885/40960 [00:26<01:39, 333.40batches/s, l2_loss: 0.1128 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7885/40960 [00:26<01:39, 333.40batches/s, l2_loss: 0.1128 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7957/40960 [00:26<01:37, 339.95batches/s, l2_loss: 0.1128 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7957/40960 [00:26<01:37, 339.95batches/s, l2_loss: 0.1126 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8027/40960 [00:26<01:36, 342.53batches/s, l2_loss: 0.1126 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8027/40960 [00:26<01:36, 342.53batches/s, l2_loss: 0.1126 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8096/40960 [00:26<01:36, 342.16batches/s, l2_loss: 0.1126 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8096/40960 [00:26<01:36, 342.16batches/s, l2_loss: 0.1124 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8168/40960 [00:26<01:34, 347.04batches/s, l2_loss: 0.1124 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8168/40960 [00:26<01:34, 347.04batches/s, l2_loss: 0.1124 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8232/40960 [00:27<01:36, 338.84batches/s, l2_loss: 0.1124 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8232/40960 [00:27<01:36, 338.84batches/s, l2_loss: 0.0965 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8286/40960 [00:27<01:42, 318.09batches/s, l2_loss: 0.0965 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8286/40960 [00:27<01:42, 318.09batches/s, l2_loss: 0.1070 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8342/40960 [00:27<01:46, 305.41batches/s, l2_loss: 0.1070 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8342/40960 [00:27<01:46, 305.41batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8402/40960 [00:27<01:47, 302.55batches/s, l2_loss: 0.1102 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8402/40960 [00:27<01:47, 302.55batches/s, l2_loss: 0.1072 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8466/40960 [00:27<01:45, 307.69batches/s, l2_loss: 0.1072 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8466/40960 [00:27<01:45, 307.69batches/s, l2_loss: 0.1071 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8530/40960 [00:28<01:44, 310.77batches/s, l2_loss: 0.1071 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|▏| 8530/40960 [00:28<01:44, 310.77batches/s, l2_loss: 0.1074 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8584/40960 [00:28<01:48, 298.12batches/s, l2_loss: 0.1074 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8584/40960 [00:28<01:48, 298.12batches/s, l2_loss: 0.1066 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8637/40960 [00:28<01:52, 287.72batches/s, l2_loss: 0.1066 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8637/40960 [00:28<01:52, 287.72batches/s, l2_loss: 0.1055 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8703/40960 [00:28<01:47, 299.93batches/s, l2_loss: 0.1055 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8703/40960 [00:28<01:47, 299.93batches/s, l2_loss: 0.1070 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8768/40960 [00:28<01:44, 307.12batches/s, l2_loss: 0.1070 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8768/40960 [00:28<01:44, 307.12batches/s, l2_loss: 0.1070 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8823/40960 [00:29<01:48, 296.69batches/s, l2_loss: 0.1070 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8823/40960 [00:29<01:48, 296.69batches/s, l2_loss: 0.1071 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8882/40960 [00:29<01:49, 293.97batches/s, l2_loss: 0.1071 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8882/40960 [00:29<01:49, 293.97batches/s, l2_loss: 0.1082 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8941/40960 [00:29<01:48, 294.10batches/s, l2_loss: 0.1082 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8941/40960 [00:29<01:48, 294.10batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9001/40960 [00:29<01:48, 295.35batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9001/40960 [00:29<01:48, 295.35batches/s, l2_loss: 0.1066 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9053/40960 [00:29<01:52, 284.57batches/s, l2_loss: 0.1066 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9053/40960 [00:29<01:52, 284.57batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9109/40960 [00:30<01:52, 282.18batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9109/40960 [00:30<01:52, 282.18batches/s, l2_loss: 0.1078 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9167/40960 [00:30<01:52, 282.73batches/s, l2_loss: 0.1078 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9167/40960 [00:30<01:52, 282.73batches/s, l2_loss: 0.1070 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9225/40960 [00:30<01:51, 284.17batches/s, l2_loss: 0.1070 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9225/40960 [00:30<01:51, 284.17batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9280/40960 [00:30<01:52, 280.55batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9280/40960 [00:30<01:52, 280.55batches/s, l2_loss: 0.1079 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9347/40960 [00:30<01:46, 296.30batches/s, l2_loss: 0.1079 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9347/40960 [00:30<01:46, 296.30batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9409/40960 [00:31<01:45, 300.04batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9409/40960 [00:31<01:45, 300.04batches/s, l2_loss: 0.1075 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9474/40960 [00:31<01:42, 306.80batches/s, l2_loss: 0.1075 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9474/40960 [00:31<01:42, 306.80batches/s, l2_loss: 0.1074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9538/40960 [00:31<01:41, 310.55batches/s, l2_loss: 0.1074 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9538/40960 [00:31<01:41, 310.55batches/s, l2_loss: 0.1075 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9605/40960 [00:31<01:39, 316.56batches/s, l2_loss: 0.1075 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9605/40960 [00:31<01:39, 316.56batches/s, l2_loss: 0.1074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9672/40960 [00:31<01:37, 321.05batches/s, l2_loss: 0.1074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9672/40960 [00:31<01:37, 321.05batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9738/40960 [00:32<01:36, 322.40batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9738/40960 [00:32<01:36, 322.40batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9806/40960 [00:32<01:35, 327.17batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9806/40960 [00:32<01:35, 327.17batches/s, l2_loss: 0.1079 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9872/40960 [00:32<01:35, 326.49batches/s, l2_loss: 0.1079 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9872/40960 [00:32<01:35, 326.49batches/s, l2_loss: 0.1072 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9937/40960 [00:32<01:35, 325.40batches/s, l2_loss: 0.1072 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9937/40960 [00:32<01:35, 325.40batches/s, l2_loss: 0.1074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9994/40960 [00:32<01:39, 312.16batches/s, l2_loss: 0.1074 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9994/40960 [00:32<01:39, 312.16batches/s, l2_loss: 0.1073 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10055/40960 [00:33<01:39, 309.88batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  25%|▏| 10055/40960 [00:33<01:39, 309.88batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  25%|▏| 10120/40960 [00:33<01:38, 314.18batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  25%|▏| 10120/40960 [00:33<01:38, 314.18batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  25%|▏| 10189/40960 [00:33<01:35, 321.98batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  25%|▏| 10189/40960 [00:33<01:35, 321.98batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  25%|▎| 10254/40960 [00:33<01:35, 322.70batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  25%|▎| 10254/40960 [00:33<01:35, 322.70batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  25%|▎| 10318/40960 [00:33<01:35, 321.39batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  25%|▎| 10318/40960 [00:33<01:35, 321.39batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  25%|▎| 10383/40960 [00:34<01:35, 321.36batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  25%|▎| 10383/40960 [00:34<01:35, 321.36batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  26%|▎| 10449/40960 [00:34<01:34, 323.62batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  26%|▎| 10449/40960 [00:34<01:34, 323.62batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  26%|▎| 10517/40960 [00:34<01:32, 328.38batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  26%|▎| 10517/40960 [00:34<01:32, 328.38batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  26%|▎| 10586/40960 [00:34<01:31, 332.11batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  26%|▎| 10586/40960 [00:34<01:31, 332.11batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10652/40960 [00:34<01:31, 330.64batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  26%|▎| 10652/40960 [00:34<01:31, 330.64batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  26%|▎| 10719/40960 [00:35<01:31, 331.38batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  26%|▎| 10719/40960 [00:35<01:31, 331.38batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  26%|▎| 10785/40960 [00:35<01:31, 329.66batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  26%|▎| 10785/40960 [00:35<01:31, 329.66batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  26%|▎| 10834/40960 [00:35<01:39, 301.56batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  26%|▎| 10834/40960 [00:35<01:39, 301.56batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  27%|▎| 10898/40960 [00:35<01:37, 306.93batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  27%|▎| 10898/40960 [00:35<01:37, 306.93batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  27%|▎| 10961/40960 [00:35<01:37, 309.01batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  27%|▎| 10961/40960 [00:35<01:37, 309.01batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11029/40960 [00:36<01:34, 317.51batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11029/40960 [00:36<01:34, 317.51batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11097/40960 [00:36<01:32, 323.75batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11097/40960 [00:36<01:32, 323.75batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11164/40960 [00:36<01:31, 325.48batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  27%|▎| 11164/40960 [00:36<01:31, 325.48batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  27%|▎| 11224/40960 [00:36<01:34, 316.26batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  27%|▎| 11224/40960 [00:36<01:34, 316.26batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  28%|▎| 11281/40960 [00:36<01:37, 305.50batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  28%|▎| 11281/40960 [00:36<01:37, 305.50batches/s, l2_loss: 0.1073 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|▎| 11347/40960 [00:37<01:35, 311.61batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  28%|▎| 11347/40960 [00:37<01:35, 311.61batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11413/40960 [00:37<01:33, 316.78batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11413/40960 [00:37<01:33, 316.78batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  28%|▎| 11471/40960 [00:37<01:35, 308.11batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  28%|▎| 11471/40960 [00:37<01:35, 308.11batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11519/40960 [00:37<01:42, 286.28batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11519/40960 [00:37<01:42, 286.28batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11576/40960 [00:37<01:43, 284.90batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  28%|▎| 11576/40960 [00:37<01:43, 284.90batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  28%|▎| 11631/40960 [00:38<01:44, 280.74batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  28%|▎| 11631/40960 [00:38<01:44, 280.74batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  29%|▎| 11688/40960 [00:38<01:44, 281.16batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  29%|▎| 11688/40960 [00:38<01:44, 281.16batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  29%|▎| 11751/40960 [00:38<01:40, 290.95batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  29%|▎| 11751/40960 [00:38<01:40, 290.95batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11816/40960 [00:38<01:36, 300.49batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  29%|▎| 11816/40960 [00:38<01:36, 300.49batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  29%|▎| 11883/40960 [00:38<01:33, 309.93batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  29%|▎| 11883/40960 [00:38<01:33, 309.93batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  29%|▎| 11948/40960 [00:39<01:32, 313.95batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  29%|▎| 11948/40960 [00:39<01:32, 313.95batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  29%|▎| 11994/40960 [00:39<01:41, 286.05batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  29%|▎| 11994/40960 [00:39<01:41, 286.05batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  29%|▎| 12047/40960 [00:39<01:43, 278.78batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  29%|▎| 12047/40960 [00:39<01:43, 278.78batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12102/40960 [00:39<01:44, 277.29batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12102/40960 [00:39<01:44, 277.29batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12168/40960 [00:39<01:38, 291.46batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12168/40960 [00:39<01:38, 291.46batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12225/40960 [00:40<01:39, 288.56batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12225/40960 [00:40<01:39, 288.56batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12287/40960 [00:40<01:37, 293.90batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12287/40960 [00:40<01:37, 293.90batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12350/40960 [00:40<01:35, 299.00batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12350/40960 [00:40<01:35, 299.00batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  30%|▎| 12413/40960 [00:40<01:34, 302.87batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  30%|▎| 12413/40960 [00:40<01:34, 302.87batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12479/40960 [00:40<01:31, 310.44batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  30%|▎| 12479/40960 [00:40<01:31, 310.44batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  31%|▎| 12536/40960 [00:41<01:34, 301.36batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  31%|▎| 12536/40960 [00:41<01:34, 301.36batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  31%|▎| 12599/40960 [00:41<01:33, 303.80batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  31%|▎| 12599/40960 [00:41<01:33, 303.80batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12664/40960 [00:41<01:31, 310.03batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12664/40960 [00:41<01:31, 310.03batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12725/40960 [00:41<01:31, 308.48batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12725/40960 [00:41<01:31, 308.48batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12789/40960 [00:41<01:30, 311.75batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12789/40960 [00:42<01:30, 311.75batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12853/40960 [00:42<01:29, 314.08batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  31%|▎| 12853/40960 [00:42<01:29, 314.08batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  32%|▎| 12908/40960 [00:42<01:33, 301.27batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  32%|▎| 12908/40960 [00:42<01:33, 301.27batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  32%|▎| 12968/40960 [00:42<01:33, 299.48batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  32%|▎| 12968/40960 [00:42<01:33, 299.48batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  32%|▎| 13030/40960 [00:42<01:32, 302.43batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  32%|▎| 13030/40960 [00:42<01:32, 302.43batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13085/40960 [00:43<01:35, 292.95batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13085/40960 [00:43<01:35, 292.95batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  32%|▎| 13146/40960 [00:43<01:33, 295.96batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  32%|▎| 13146/40960 [00:43<01:33, 295.96batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13208/40960 [00:43<01:32, 299.15batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  32%|▎| 13208/40960 [00:43<01:32, 299.15batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  32%|▎| 13269/40960 [00:43<01:32, 300.19batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  32%|▎| 13269/40960 [00:43<01:32, 300.19batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  33%|▎| 13333/40960 [00:43<01:30, 305.75batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  33%|▎| 13333/40960 [00:43<01:30, 305.75batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13394/40960 [00:44<01:30, 305.16batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13394/40960 [00:44<01:30, 305.16batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13458/40960 [00:44<01:28, 309.41batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  33%|▎| 13458/40960 [00:44<01:28, 309.41batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  33%|▎| 13523/40960 [00:44<01:27, 313.97batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  33%|▎| 13523/40960 [00:44<01:27, 313.97batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  33%|▎| 13584/40960 [00:44<01:28, 309.93batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  33%|▎| 13584/40960 [00:44<01:28, 309.93batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  33%|▎| 13642/40960 [00:44<01:30, 302.90batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  33%|▎| 13642/40960 [00:44<01:30, 302.90batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  33%|▎| 13702/40960 [00:45<01:30, 301.45batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  33%|▎| 13702/40960 [00:45<01:30, 301.45batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13767/40960 [00:45<01:28, 306.80batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13767/40960 [00:45<01:28, 306.80batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13826/40960 [00:45<01:29, 302.62batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13826/40960 [00:45<01:29, 302.62batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13890/40960 [00:45<01:28, 306.53batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  34%|▎| 13890/40960 [00:45<01:28, 306.53batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  34%|▎| 13952/40960 [00:45<01:28, 306.33batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  34%|▎| 13952/40960 [00:45<01:28, 306.33batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  34%|▎| 14021/40960 [00:46<01:25, 316.59batches/s, l2_loss: 0.1074 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|▎| 14021/40960 [00:46<01:25, 316.59batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  34%|▎| 14087/40960 [00:46<01:23, 320.33batches/s, l2_loss: 0.1072 - round_los\u001b[A\n",
      "Training:  34%|▎| 14087/40960 [00:46<01:23, 320.33batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  35%|▎| 14151/40960 [00:46<01:23, 319.86batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  35%|▎| 14151/40960 [00:46<01:23, 319.86batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  35%|▎| 14217/40960 [00:46<01:23, 321.92batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  35%|▎| 14217/40960 [00:46<01:23, 321.92batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14284/40960 [00:46<01:22, 324.99batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14284/40960 [00:46<01:22, 324.99batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  35%|▎| 14349/40960 [00:47<01:21, 324.78batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  35%|▎| 14349/40960 [00:47<01:21, 324.78batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14405/40960 [00:47<01:25, 310.69batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14405/40960 [00:47<01:25, 310.69batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  35%|▎| 14459/40960 [00:47<01:29, 297.59batches/s, l2_loss: 0.1073 - round_los\u001b[A\n",
      "Training:  35%|▎| 14459/40960 [00:47<01:29, 297.59batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14507/40960 [00:47<01:34, 280.11batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  35%|▎| 14507/40960 [00:47<01:34, 280.11batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14554/40960 [00:47<01:39, 264.57batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14554/40960 [00:47<01:39, 264.57batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14616/40960 [00:48<01:35, 277.22batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14616/40960 [00:48<01:35, 277.22batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  36%|▎| 14673/40960 [00:48<01:34, 279.24batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  36%|▎| 14673/40960 [00:48<01:34, 279.24batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  36%|▎| 14733/40960 [00:48<01:32, 284.99batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  36%|▎| 14733/40960 [00:48<01:32, 284.99batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14796/40960 [00:48<01:29, 292.89batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  36%|▎| 14796/40960 [00:48<01:29, 292.89batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  36%|▎| 14859/40960 [00:48<01:27, 299.46batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  36%|▎| 14859/40960 [00:48<01:27, 299.46batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  36%|▎| 14910/40960 [00:49<01:31, 283.37batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  36%|▎| 14910/40960 [00:49<01:31, 283.37batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 14969/40960 [00:49<01:31, 283.73batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 14969/40960 [00:49<01:31, 283.73batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15027/40960 [00:49<01:31, 284.82batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15027/40960 [00:49<01:31, 284.82batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15087/40960 [00:49<01:29, 288.78batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15087/40960 [00:49<01:29, 288.78batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  37%|▎| 15150/40960 [00:49<01:27, 295.28batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  37%|▎| 15150/40960 [00:49<01:27, 295.28batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15213/40960 [00:50<01:25, 299.92batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15213/40960 [00:50<01:25, 299.92batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  37%|▎| 15274/40960 [00:50<01:25, 301.04batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  37%|▎| 15274/40960 [00:50<01:25, 301.04batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15332/40960 [00:50<01:26, 297.16batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  37%|▎| 15332/40960 [00:50<01:26, 297.16batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15392/40960 [00:50<01:26, 297.26batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15392/40960 [00:50<01:26, 297.26batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15443/40960 [00:50<01:30, 282.42batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15443/40960 [00:50<01:30, 282.42batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15502/40960 [00:51<01:29, 285.04batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  38%|▍| 15502/40960 [00:51<01:29, 285.04batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15561/40960 [00:51<01:28, 287.26batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15561/40960 [00:51<01:28, 287.26batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15624/40960 [00:51<01:26, 294.28batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15624/40960 [00:51<01:26, 294.28batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15685/40960 [00:51<01:25, 297.11batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15685/40960 [00:51<01:25, 297.11batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15749/40960 [00:51<01:23, 303.04batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  38%|▍| 15749/40960 [00:51<01:23, 303.04batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  39%|▍| 15813/40960 [00:52<01:21, 306.91batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  39%|▍| 15813/40960 [00:52<01:21, 306.91batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  39%|▍| 15870/40960 [00:52<01:23, 299.03batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  39%|▍| 15870/40960 [00:52<01:23, 299.03batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15924/40960 [00:52<01:26, 289.06batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15924/40960 [00:52<01:26, 289.06batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15981/40960 [00:52<01:26, 287.12batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  39%|▍| 15981/40960 [00:52<01:26, 287.12batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  39%|▍| 16043/40960 [00:52<01:24, 293.92batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  39%|▍| 16043/40960 [00:52<01:24, 293.92batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  39%|▍| 16103/40960 [00:53<01:24, 294.82batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  39%|▍| 16103/40960 [00:53<01:24, 294.82batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  39%|▍| 16157/40960 [00:53<01:26, 286.95batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  39%|▍| 16157/40960 [00:53<01:26, 286.95batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16199/40960 [00:53<01:34, 262.17batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16199/40960 [00:53<01:34, 262.17batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16254/40960 [00:53<01:33, 265.37batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16254/40960 [00:53<01:33, 265.37batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  40%|▍| 16312/40960 [00:53<01:30, 272.32batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  40%|▍| 16312/40960 [00:53<01:30, 272.32batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16376/40960 [00:54<01:25, 286.40batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  40%|▍| 16376/40960 [00:54<01:25, 286.40batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  40%|▍| 16442/40960 [00:54<01:21, 299.21batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  40%|▍| 16442/40960 [00:54<01:21, 299.21batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  40%|▍| 16509/40960 [00:54<01:19, 308.72batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  40%|▍| 16509/40960 [00:54<01:19, 308.72batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  40%|▍| 16574/40960 [00:54<01:17, 313.46batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  40%|▍| 16574/40960 [00:54<01:17, 313.46batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16635/40960 [00:54<01:18, 310.37batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16635/40960 [00:54<01:18, 310.37batches/s, l2_loss: 0.1075 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|▍| 16702/40960 [00:55<01:16, 316.45batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16702/40960 [00:55<01:16, 316.45batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16759/40960 [00:55<01:19, 305.94batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  41%|▍| 16759/40960 [00:55<01:19, 305.94batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16815/40960 [00:55<01:21, 297.99batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16815/40960 [00:55<01:21, 297.99batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16875/40960 [00:55<01:20, 297.58batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16875/40960 [00:55<01:20, 297.58batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16937/40960 [00:55<01:20, 299.68batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  41%|▍| 16937/40960 [00:55<01:20, 299.68batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  42%|▍| 17002/40960 [00:56<01:18, 306.66batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  42%|▍| 17002/40960 [00:56<01:18, 306.66batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  42%|▍| 17064/40960 [00:56<01:17, 307.35batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  42%|▍| 17064/40960 [00:56<01:17, 307.35batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  42%|▍| 17124/40960 [00:56<01:18, 303.71batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  42%|▍| 17124/40960 [00:56<01:18, 303.71batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  42%|▍| 17189/40960 [00:56<01:16, 309.98batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  42%|▍| 17189/40960 [00:56<01:16, 309.98batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17254/40960 [00:56<01:15, 313.84batches/s, l2_loss: 0.1074 - round_los\u001b[A\n",
      "Training:  42%|▍| 17254/40960 [00:56<01:15, 313.84batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  42%|▍| 17322/40960 [00:57<01:13, 321.04batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  42%|▍| 17322/40960 [00:57<01:13, 321.04batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  42%|▍| 17382/40960 [00:57<01:15, 314.15batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  42%|▍| 17382/40960 [00:57<01:15, 314.15batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17442/40960 [00:57<01:16, 308.14batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17442/40960 [00:57<01:16, 308.14batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  43%|▍| 17503/40960 [00:57<01:16, 307.15batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  43%|▍| 17503/40960 [00:57<01:16, 307.15batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17566/40960 [00:57<01:15, 308.41batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17566/40960 [00:57<01:15, 308.41batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17626/40960 [00:58<01:16, 305.17batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17626/40960 [00:58<01:16, 305.17batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17693/40960 [00:58<01:14, 313.86batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17693/40960 [00:58<01:14, 313.86batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17753/40960 [00:58<01:15, 308.09batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  43%|▍| 17753/40960 [00:58<01:15, 308.09batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  44%|▍| 17818/40960 [00:58<01:14, 312.69batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  44%|▍| 17818/40960 [00:58<01:14, 312.69batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 17883/40960 [00:58<01:12, 316.34batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 17883/40960 [00:58<01:12, 316.34batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 17947/40960 [00:59<01:12, 317.15batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 17947/40960 [00:59<01:12, 317.15batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 18007/40960 [00:59<01:13, 310.91batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 18007/40960 [00:59<01:13, 310.91batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 18065/40960 [00:59<01:15, 303.48batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 18065/40960 [00:59<01:15, 303.48batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 18123/40960 [00:59<01:16, 296.98batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  44%|▍| 18123/40960 [00:59<01:16, 296.98batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  44%|▍| 18187/40960 [00:59<01:15, 302.57batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  44%|▍| 18187/40960 [00:59<01:15, 302.57batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  45%|▍| 18252/40960 [01:00<01:13, 307.97batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  45%|▍| 18252/40960 [01:00<01:13, 307.97batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18317/40960 [01:00<01:12, 312.84batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18317/40960 [01:00<01:12, 312.84batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18374/40960 [01:00<01:14, 302.99batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18374/40960 [01:00<01:14, 302.99batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18437/40960 [01:00<01:13, 306.12batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18437/40960 [01:00<01:13, 306.12batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18500/40960 [01:00<01:13, 307.28batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18500/40960 [01:00<01:13, 307.28batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  45%|▍| 18567/40960 [01:01<01:10, 315.41batches/s, l2_loss: 0.1075 - round_los\u001b[A\n",
      "Training:  45%|▍| 18567/40960 [01:01<01:10, 315.41batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18634/40960 [01:01<01:09, 319.71batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  45%|▍| 18634/40960 [01:01<01:09, 319.71batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  46%|▍| 18700/40960 [01:01<01:09, 322.20batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  46%|▍| 18700/40960 [01:01<01:09, 322.20batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 18762/40960 [01:01<01:09, 317.60batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 18762/40960 [01:01<01:09, 317.60batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 18828/40960 [01:01<01:09, 320.61batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 18828/40960 [01:01<01:09, 320.61batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 18894/40960 [01:02<01:08, 323.05batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 18894/40960 [01:02<01:08, 323.05batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 18962/40960 [01:02<01:07, 327.31batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 18962/40960 [01:02<01:07, 327.31batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 19027/40960 [01:02<01:07, 325.93batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  46%|▍| 19027/40960 [01:02<01:07, 325.93batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  47%|▍| 19087/40960 [01:02<01:08, 317.39batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  47%|▍| 19087/40960 [01:02<01:08, 317.39batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  47%|▍| 19147/40960 [01:02<01:10, 310.78batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  47%|▍| 19147/40960 [01:03<01:10, 310.78batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  47%|▍| 19194/40960 [01:03<01:15, 287.72batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  47%|▍| 19194/40960 [01:03<01:15, 287.72batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  47%|▍| 19252/40960 [01:03<01:15, 287.85batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  47%|▍| 19252/40960 [01:03<01:15, 287.85batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  47%|▍| 19318/40960 [01:03<01:12, 300.34batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  47%|▍| 19318/40960 [01:03<01:12, 300.34batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  47%|▍| 19377/40960 [01:03<01:12, 297.88batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  47%|▍| 19377/40960 [01:03<01:12, 297.88batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  47%|▍| 19442/40960 [01:04<01:10, 304.76batches/s, l2_loss: 0.1077 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|▍| 19442/40960 [01:04<01:10, 304.76batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19510/40960 [01:04<01:08, 313.96batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19510/40960 [01:04<01:08, 313.96batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19574/40960 [01:04<01:07, 315.17batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19574/40960 [01:04<01:07, 315.17batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19639/40960 [01:04<01:07, 317.31batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19639/40960 [01:04<01:07, 317.31batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  48%|▍| 19701/40960 [01:04<01:07, 314.79batches/s, l2_loss: 0.1076 - round_los\u001b[A\n",
      "Training:  48%|▍| 19701/40960 [01:04<01:07, 314.79batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19760/40960 [01:05<01:08, 307.57batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19760/40960 [01:05<01:08, 307.57batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19824/40960 [01:05<01:08, 310.37batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  48%|▍| 19824/40960 [01:05<01:08, 310.37batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 19882/40960 [01:05<01:09, 303.95batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 19882/40960 [01:05<01:09, 303.95batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 19946/40960 [01:05<01:08, 307.40batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 19946/40960 [01:05<01:08, 307.40batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20008/40960 [01:05<01:08, 307.85batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20008/40960 [01:05<01:08, 307.85batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20070/40960 [01:06<01:07, 307.54batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20070/40960 [01:06<01:07, 307.54batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20133/40960 [01:06<01:07, 309.33batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20133/40960 [01:06<01:07, 309.33batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20196/40960 [01:06<01:06, 310.62batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20196/40960 [01:06<01:06, 310.62batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20263/40960 [01:06<01:05, 316.88batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  49%|▍| 20263/40960 [01:06<01:05, 316.88batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  50%|▍| 20327/40960 [01:06<01:05, 316.95batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  50%|▍| 20327/40960 [01:06<01:05, 316.95batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  50%|▍| 20390/40960 [01:07<01:05, 315.15batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  50%|▍| 20390/40960 [01:07<01:05, 315.15batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  50%|▍| 20455/40960 [01:07<01:04, 317.65batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  50%|▍| 20455/40960 [01:07<01:04, 317.65batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  50%|▌| 20507/40960 [01:07<01:08, 299.30batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  50%|▌| 20507/40960 [01:07<01:08, 299.30batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  50%|▌| 20568/40960 [01:07<01:07, 300.54batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  50%|▌| 20568/40960 [01:07<01:07, 300.54batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  50%|▌| 20631/40960 [01:07<01:06, 303.98batches/s, l2_loss: 0.1077 - round_los\u001b[A\n",
      "Training:  50%|▌| 20631/40960 [01:07<01:06, 303.98batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20696/40960 [01:08<01:05, 308.85batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20696/40960 [01:08<01:05, 308.85batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20759/40960 [01:08<01:05, 309.97batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20759/40960 [01:08<01:05, 309.97batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20823/40960 [01:08<01:04, 312.40batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20823/40960 [01:08<01:04, 312.40batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20884/40960 [01:08<01:04, 309.05batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20884/40960 [01:08<01:04, 309.05batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20949/40960 [01:08<01:04, 312.47batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 20949/40960 [01:08<01:04, 312.47batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 21013/40960 [01:09<01:03, 313.38batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 21013/40960 [01:09<01:03, 313.38batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 21078/40960 [01:09<01:02, 316.56batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  51%|▌| 21078/40960 [01:09<01:02, 316.56batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  52%|▌| 21143/40960 [01:09<01:02, 319.01batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  52%|▌| 21143/40960 [01:09<01:02, 319.01batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  52%|▌| 21210/40960 [01:09<01:01, 323.76batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  52%|▌| 21210/40960 [01:09<01:01, 323.76batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  52%|▌| 21276/40960 [01:09<01:00, 325.46batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  52%|▌| 21276/40960 [01:09<01:00, 325.46batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  52%|▌| 21340/40960 [01:10<01:00, 322.32batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  52%|▌| 21340/40960 [01:10<01:00, 322.32batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  52%|▌| 21395/40960 [01:10<01:03, 307.22batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  52%|▌| 21395/40960 [01:10<01:03, 307.22batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  52%|▌| 21461/40960 [01:10<01:02, 312.73batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  52%|▌| 21461/40960 [01:10<01:02, 312.73batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  53%|▌| 21526/40960 [01:10<01:01, 315.34batches/s, l2_loss: 0.1078 - round_los\u001b[A\n",
      "Training:  53%|▌| 21526/40960 [01:10<01:01, 315.34batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  53%|▌| 21593/40960 [01:10<01:00, 320.14batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  53%|▌| 21593/40960 [01:10<01:00, 320.14batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21648/40960 [01:11<01:03, 305.49batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21648/40960 [01:11<01:03, 305.49batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21706/40960 [01:11<01:04, 300.80batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21706/40960 [01:11<01:04, 300.80batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21767/40960 [01:11<01:03, 301.35batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21767/40960 [01:11<01:03, 301.35batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21829/40960 [01:11<01:03, 303.53batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21829/40960 [01:11<01:03, 303.53batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21894/40960 [01:11<01:01, 308.98batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  53%|▌| 21894/40960 [01:11<01:01, 308.98batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  54%|▌| 21961/40960 [01:12<01:00, 315.84batches/s, l2_loss: 0.1079 - round_los\u001b[A\n",
      "Training:  54%|▌| 21961/40960 [01:12<01:00, 315.84batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22030/40960 [01:12<00:58, 323.70batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22030/40960 [01:12<00:58, 323.70batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22097/40960 [01:12<00:57, 325.93batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22097/40960 [01:12<00:57, 325.93batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22164/40960 [01:12<00:57, 328.33batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22164/40960 [01:12<00:57, 328.33batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22228/40960 [01:12<00:57, 324.46batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22228/40960 [01:12<00:57, 324.46batches/s, l2_loss: 0.1080 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|▌| 22289/40960 [01:13<00:58, 317.95batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  54%|▌| 22289/40960 [01:13<00:58, 317.95batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22350/40960 [01:13<00:59, 313.77batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22350/40960 [01:13<00:59, 313.77batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22410/40960 [01:13<01:00, 309.01batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22410/40960 [01:13<01:00, 309.01batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22467/40960 [01:13<01:01, 301.55batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22467/40960 [01:13<01:01, 301.55batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22530/40960 [01:13<01:00, 304.95batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22530/40960 [01:13<01:00, 304.95batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22596/40960 [01:14<00:58, 311.58batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22596/40960 [01:14<00:58, 311.58batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22659/40960 [01:14<00:58, 311.87batches/s, l2_loss: 0.1080 - round_los\u001b[A\n",
      "Training:  55%|▌| 22659/40960 [01:14<00:58, 311.87batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  55%|▌| 22721/40960 [01:14<00:58, 310.42batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  55%|▌| 22721/40960 [01:14<00:58, 310.42batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 22789/40960 [01:14<00:57, 317.99batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 22789/40960 [01:14<00:57, 317.99batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 22851/40960 [01:14<00:57, 314.51batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 22851/40960 [01:14<00:57, 314.51batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 22917/40960 [01:15<00:56, 318.72batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 22917/40960 [01:15<00:56, 318.72batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 22985/40960 [01:15<00:55, 324.72batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 22985/40960 [01:15<00:55, 324.72batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 23053/40960 [01:15<00:54, 329.06batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 23053/40960 [01:15<00:54, 329.06batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 23120/40960 [01:15<00:54, 329.34batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  56%|▌| 23120/40960 [01:15<00:54, 329.34batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  57%|▌| 23187/40960 [01:15<00:53, 330.24batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  57%|▌| 23187/40960 [01:15<00:53, 330.24batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  57%|▌| 23251/40960 [01:16<00:54, 325.85batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  57%|▌| 23251/40960 [01:16<00:54, 325.85batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  57%|▌| 23317/40960 [01:16<00:54, 326.61batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  57%|▌| 23317/40960 [01:16<00:54, 326.61batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  57%|▌| 23377/40960 [01:16<00:55, 318.30batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  57%|▌| 23377/40960 [01:16<00:55, 318.30batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  57%|▌| 23434/40960 [01:16<00:56, 307.55batches/s, l2_loss: 0.1081 - round_los\u001b[A\n",
      "Training:  57%|▌| 23434/40960 [01:16<00:56, 307.55batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  57%|▌| 23495/40960 [01:16<00:57, 306.14batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  57%|▌| 23495/40960 [01:16<00:57, 306.14batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  58%|▌| 23563/40960 [01:17<00:55, 315.87batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  58%|▌| 23563/40960 [01:17<00:55, 315.87batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  58%|▌| 23623/40960 [01:17<00:55, 309.80batches/s, l2_loss: 0.1082 - round_los\u001b[A\n",
      "Training:  58%|▌| 23623/40960 [01:17<00:55, 309.80batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23675/40960 [01:17<00:58, 294.22batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23675/40960 [01:17<00:58, 294.22batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23739/40960 [01:17<00:57, 299.25batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23739/40960 [01:17<00:57, 299.25batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23797/40960 [01:17<00:57, 296.48batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23797/40960 [01:17<00:57, 296.48batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23861/40960 [01:18<00:56, 303.43batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23861/40960 [01:18<00:56, 303.43batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23923/40960 [01:18<00:55, 304.62batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  58%|▌| 23923/40960 [01:18<00:55, 304.62batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 23982/40960 [01:18<00:56, 301.33batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 23982/40960 [01:18<00:56, 301.33batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24042/40960 [01:18<00:56, 299.31batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24042/40960 [01:18<00:56, 299.31batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24106/40960 [01:18<00:55, 305.18batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24106/40960 [01:18<00:55, 305.18batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24168/40960 [01:19<00:54, 306.33batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24168/40960 [01:19<00:54, 306.33batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24233/40960 [01:19<00:53, 311.16batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24233/40960 [01:19<00:53, 311.16batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24292/40960 [01:19<00:54, 306.30batches/s, l2_loss: 0.1083 - round_los\u001b[A\n",
      "Training:  59%|▌| 24292/40960 [01:19<00:54, 306.30batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  59%|▌| 24352/40960 [01:19<00:54, 304.13batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  59%|▌| 24352/40960 [01:19<00:54, 304.13batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24407/40960 [01:19<00:56, 293.87batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24407/40960 [01:19<00:56, 293.87batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24471/40960 [01:20<00:54, 300.54batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24471/40960 [01:20<00:54, 300.54batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24533/40960 [01:20<00:54, 303.29batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24533/40960 [01:20<00:54, 303.29batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24598/40960 [01:20<00:53, 308.47batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24598/40960 [01:20<00:53, 308.47batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24664/40960 [01:20<00:51, 314.29batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24664/40960 [01:20<00:51, 314.29batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24724/40960 [01:20<00:52, 308.77batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24724/40960 [01:20<00:52, 308.77batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24780/40960 [01:21<00:54, 298.94batches/s, l2_loss: 0.1084 - round_los\u001b[A\n",
      "Training:  60%|▌| 24780/40960 [01:21<00:54, 298.94batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 24839/40960 [01:21<00:54, 296.89batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 24839/40960 [01:21<00:54, 296.89batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 24905/40960 [01:21<00:52, 306.01batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 24905/40960 [01:21<00:52, 306.01batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 24972/40960 [01:21<00:50, 313.67batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 24972/40960 [01:21<00:50, 313.67batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 25030/40960 [01:21<00:52, 305.84batches/s, l2_loss: 0.1085 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 25030/40960 [01:21<00:52, 305.84batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 25081/40960 [01:22<00:54, 289.40batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 25081/40960 [01:22<00:54, 289.40batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 25143/40960 [01:22<00:53, 295.52batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  61%|▌| 25143/40960 [01:22<00:53, 295.52batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25209/40960 [01:22<00:51, 305.00batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25209/40960 [01:22<00:51, 305.00batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25270/40960 [01:22<00:51, 304.72batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25270/40960 [01:22<00:51, 304.72batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  62%|▌| 25311/40960 [01:22<00:57, 272.63batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  62%|▌| 25311/40960 [01:22<00:57, 272.63batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25377/40960 [01:23<00:53, 289.29batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25377/40960 [01:23<00:53, 289.29batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  62%|▌| 25441/40960 [01:23<00:52, 297.93batches/s, l2_loss: 0.1085 - round_los\u001b[A\n",
      "Training:  62%|▌| 25441/40960 [01:23<00:52, 297.93batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25496/40960 [01:23<00:53, 290.54batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25496/40960 [01:23<00:53, 290.54batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25543/40960 [01:23<00:56, 271.73batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  62%|▌| 25543/40960 [01:23<00:56, 271.73batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  62%|▋| 25600/40960 [01:23<00:55, 275.12batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  62%|▋| 25600/40960 [01:23<00:55, 275.12batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25655/40960 [01:24<00:55, 275.09batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25655/40960 [01:24<00:55, 275.09batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25721/40960 [01:24<00:52, 290.96batches/s, l2_loss: 0.1086 - round_los\u001b[A\n",
      "Training:  63%|▋| 25721/40960 [01:24<00:52, 290.96batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  63%|▋| 25783/40960 [01:24<00:51, 294.88batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  63%|▋| 25783/40960 [01:24<00:51, 294.88batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  63%|▋| 25848/40960 [01:24<00:49, 303.42batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  63%|▋| 25848/40960 [01:24<00:49, 303.42batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  63%|▋| 25913/40960 [01:24<00:48, 309.54batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  63%|▋| 25913/40960 [01:24<00:48, 309.54batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  63%|▋| 25975/40960 [01:25<00:48, 309.45batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  63%|▋| 25975/40960 [01:25<00:48, 309.45batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  64%|▋| 26028/40960 [01:25<00:50, 295.76batches/s, l2_loss: 0.1087 - round_los\u001b[A\n",
      "Training:  64%|▋| 26028/40960 [01:25<00:50, 295.76batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26092/40960 [01:25<00:49, 301.57batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26092/40960 [01:25<00:49, 301.57batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26156/40960 [01:25<00:48, 307.04batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26156/40960 [01:25<00:48, 307.04batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26221/40960 [01:25<00:47, 312.16batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26221/40960 [01:25<00:47, 312.16batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26285/40960 [01:26<00:46, 313.81batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26285/40960 [01:26<00:46, 313.81batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26349/40960 [01:26<00:46, 315.05batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26349/40960 [01:26<00:46, 315.05batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26413/40960 [01:26<00:45, 316.33batches/s, l2_loss: 0.1088 - round_los\u001b[A\n",
      "Training:  64%|▋| 26413/40960 [01:26<00:45, 316.33batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26470/40960 [01:26<00:47, 306.83batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26470/40960 [01:26<00:47, 306.83batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26536/40960 [01:26<00:46, 312.47batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26536/40960 [01:27<00:46, 312.47batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26603/40960 [01:27<00:45, 319.00batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26603/40960 [01:27<00:45, 319.00batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26668/40960 [01:27<00:44, 319.43batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26668/40960 [01:27<00:44, 319.43batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26733/40960 [01:27<00:44, 319.34batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26733/40960 [01:27<00:44, 319.34batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26801/40960 [01:27<00:43, 324.27batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  65%|▋| 26801/40960 [01:27<00:43, 324.27batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  66%|▋| 26869/40960 [01:28<00:42, 328.47batches/s, l2_loss: 0.1089 - round_los\u001b[A\n",
      "Training:  66%|▋| 26869/40960 [01:28<00:42, 328.47batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 26928/40960 [01:28<00:44, 317.60batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 26928/40960 [01:28<00:44, 317.60batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 26995/40960 [01:28<00:43, 322.34batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 26995/40960 [01:28<00:43, 322.34batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 27062/40960 [01:28<00:42, 325.59batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 27062/40960 [01:28<00:42, 325.59batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 27127/40960 [01:28<00:42, 325.22batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 27127/40960 [01:28<00:42, 325.22batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 27194/40960 [01:29<00:41, 327.97batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  66%|▋| 27194/40960 [01:29<00:41, 327.97batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  67%|▋| 27258/40960 [01:29<00:42, 324.61batches/s, l2_loss: 0.1090 - round_los\u001b[A\n",
      "Training:  67%|▋| 27258/40960 [01:29<00:42, 324.61batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27318/40960 [01:29<00:43, 317.05batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27318/40960 [01:29<00:43, 317.05batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27383/40960 [01:29<00:42, 318.51batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27383/40960 [01:29<00:42, 318.51batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27443/40960 [01:29<00:43, 311.77batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27443/40960 [01:29<00:43, 311.77batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27507/40960 [01:30<00:42, 314.09batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27507/40960 [01:30<00:42, 314.09batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27573/40960 [01:30<00:42, 317.73batches/s, l2_loss: 0.1091 - round_los\u001b[A\n",
      "Training:  67%|▋| 27573/40960 [01:30<00:42, 317.73batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  67%|▋| 27631/40960 [01:30<00:43, 308.86batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  67%|▋| 27631/40960 [01:30<00:43, 308.86batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  68%|▋| 27693/40960 [01:30<00:43, 308.03batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  68%|▋| 27693/40960 [01:30<00:43, 308.03batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  68%|▋| 27758/40960 [01:30<00:42, 312.93batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  68%|▋| 27758/40960 [01:30<00:42, 312.93batches/s, l2_loss: 0.1092 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|▋| 27824/40960 [01:31<00:41, 316.88batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  68%|▋| 27824/40960 [01:31<00:41, 316.88batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  68%|▋| 27890/40960 [01:31<00:40, 319.28batches/s, l2_loss: 0.1092 - round_los\u001b[A\n",
      "Training:  68%|▋| 27890/40960 [01:31<00:40, 319.28batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  68%|▋| 27952/40960 [01:31<00:41, 316.32batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  68%|▋| 27952/40960 [01:31<00:41, 316.32batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  68%|▋| 28019/40960 [01:31<00:40, 321.46batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  68%|▋| 28019/40960 [01:31<00:40, 321.46batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  69%|▋| 28084/40960 [01:31<00:39, 322.52batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  69%|▋| 28084/40960 [01:31<00:39, 322.52batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  69%|▋| 28149/40960 [01:32<00:39, 322.51batches/s, l2_loss: 0.1093 - round_los\u001b[A\n",
      "Training:  69%|▋| 28149/40960 [01:32<00:39, 322.51batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  69%|▋| 28214/40960 [01:32<00:39, 322.61batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  69%|▋| 28214/40960 [01:32<00:39, 322.61batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  69%|▋| 28278/40960 [01:32<00:39, 321.15batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  69%|▋| 28278/40960 [01:32<00:39, 321.15batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  69%|▋| 28345/40960 [01:32<00:38, 324.28batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  69%|▋| 28345/40960 [01:32<00:38, 324.28batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  69%|▋| 28414/40960 [01:32<00:38, 329.31batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  69%|▋| 28414/40960 [01:32<00:38, 329.31batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  70%|▋| 28479/40960 [01:33<00:38, 326.73batches/s, l2_loss: 0.1094 - round_los\u001b[A\n",
      "Training:  70%|▋| 28479/40960 [01:33<00:38, 326.73batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  70%|▋| 28544/40960 [01:33<00:38, 325.70batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  70%|▋| 28544/40960 [01:33<00:38, 325.70batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  70%|▋| 28607/40960 [01:33<00:38, 322.47batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  70%|▋| 28607/40960 [01:33<00:38, 322.47batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  70%|▋| 28673/40960 [01:33<00:38, 322.02batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  70%|▋| 28673/40960 [01:33<00:38, 322.02batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  70%|▋| 28736/40960 [01:33<00:38, 318.75batches/s, l2_loss: 0.1095 - round_los\u001b[A\n",
      "Training:  70%|▋| 28736/40960 [01:33<00:38, 318.75batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  70%|▋| 28801/40960 [01:34<00:38, 319.40batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  70%|▋| 28801/40960 [01:34<00:38, 319.40batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  70%|▋| 28869/40960 [01:34<00:37, 324.10batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  70%|▋| 28869/40960 [01:34<00:37, 324.10batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  71%|▋| 28937/40960 [01:34<00:36, 327.91batches/s, l2_loss: 0.1096 - round_los\u001b[A\n",
      "Training:  71%|▋| 28937/40960 [01:34<00:36, 327.91batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29004/40960 [01:34<00:36, 328.94batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29004/40960 [01:34<00:36, 328.94batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29069/40960 [01:34<00:36, 327.22batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29069/40960 [01:34<00:36, 327.22batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29135/40960 [01:35<00:36, 327.34batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29135/40960 [01:35<00:36, 327.34batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29191/40960 [01:35<00:37, 313.08batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29191/40960 [01:35<00:37, 313.08batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29252/40960 [01:35<00:37, 310.40batches/s, l2_loss: 0.1097 - round_los\u001b[A\n",
      "Training:  71%|▋| 29252/40960 [01:35<00:37, 310.40batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  72%|▋| 29315/40960 [01:35<00:37, 310.88batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  72%|▋| 29315/40960 [01:35<00:37, 310.88batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  72%|▋| 29382/40960 [01:35<00:36, 316.77batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  72%|▋| 29382/40960 [01:35<00:36, 316.77batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  72%|▋| 29450/40960 [01:36<00:35, 322.75batches/s, l2_loss: 0.1098 - round_los\u001b[A\n",
      "Training:  72%|▋| 29450/40960 [01:36<00:35, 322.75batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  72%|▋| 29515/40960 [01:36<00:35, 322.37batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  72%|▋| 29515/40960 [01:36<00:35, 322.37batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  72%|▋| 29580/40960 [01:36<00:35, 323.00batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  72%|▋| 29580/40960 [01:36<00:35, 323.00batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  72%|▋| 29639/40960 [01:36<00:36, 313.11batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  72%|▋| 29639/40960 [01:36<00:36, 313.11batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  73%|▋| 29702/40960 [01:36<00:36, 312.53batches/s, l2_loss: 0.1099 - round_los\u001b[A\n",
      "Training:  73%|▋| 29702/40960 [01:36<00:36, 312.53batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  73%|▋| 29757/40960 [01:37<00:37, 300.98batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  73%|▋| 29757/40960 [01:37<00:37, 300.98batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  73%|▋| 29816/40960 [01:37<00:37, 298.33batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  73%|▋| 29816/40960 [01:37<00:37, 298.33batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  73%|▋| 29883/40960 [01:37<00:35, 308.40batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  73%|▋| 29883/40960 [01:37<00:35, 308.40batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  73%|▋| 29943/40960 [01:37<00:36, 304.70batches/s, l2_loss: 0.1100 - round_los\u001b[A\n",
      "Training:  73%|▋| 29943/40960 [01:37<00:36, 304.70batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  73%|▋| 30007/40960 [01:37<00:35, 307.82batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  73%|▋| 30007/40960 [01:37<00:35, 307.82batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  73%|▋| 30065/40960 [01:38<00:36, 301.26batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  73%|▋| 30065/40960 [01:38<00:36, 301.26batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  74%|▋| 30124/40960 [01:38<00:36, 298.95batches/s, l2_loss: 0.1101 - round_los\u001b[A\n",
      "Training:  74%|▋| 30124/40960 [01:38<00:36, 298.95batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  74%|▋| 30187/40960 [01:38<00:35, 303.39batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  74%|▋| 30187/40960 [01:38<00:35, 303.39batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  74%|▋| 30248/40960 [01:38<00:35, 302.81batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  74%|▋| 30248/40960 [01:38<00:35, 302.81batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  74%|▋| 30311/40960 [01:38<00:34, 306.10batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  74%|▋| 30311/40960 [01:38<00:34, 306.10batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  74%|▋| 30364/40960 [01:39<00:36, 293.23batches/s, l2_loss: 0.1102 - round_los\u001b[A\n",
      "Training:  74%|▋| 30364/40960 [01:39<00:36, 293.23batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  74%|▋| 30415/40960 [01:39<00:37, 281.34batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  74%|▋| 30415/40960 [01:39<00:37, 281.34batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  74%|▋| 30470/40960 [01:39<00:37, 278.96batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  74%|▋| 30470/40960 [01:39<00:37, 278.96batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  75%|▋| 30532/40960 [01:39<00:36, 286.95batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  75%|▋| 30532/40960 [01:39<00:36, 286.95batches/s, l2_loss: 0.1103 - round_los\u001b[A\n",
      "Training:  75%|▋| 30595/40960 [01:39<00:35, 294.92batches/s, l2_loss: 0.1103 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▋| 30595/40960 [01:39<00:35, 294.92batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  75%|▋| 30660/40960 [01:40<00:33, 303.10batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  75%|▋| 30660/40960 [01:40<00:33, 303.10batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  75%|▊| 30723/40960 [01:40<00:33, 305.82batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  75%|▊| 30723/40960 [01:40<00:33, 305.82batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  75%|▊| 30788/40960 [01:40<00:32, 310.87batches/s, l2_loss: 0.1104 - round_los\u001b[A\n",
      "Training:  75%|▊| 30788/40960 [01:40<00:32, 310.87batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  75%|▊| 30848/40960 [01:40<00:32, 307.19batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  75%|▊| 30848/40960 [01:40<00:32, 307.19batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  75%|▊| 30913/40960 [01:40<00:32, 311.49batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  75%|▊| 30913/40960 [01:40<00:32, 311.49batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  76%|▊| 30974/40960 [01:41<00:32, 309.43batches/s, l2_loss: 0.1105 - round_los\u001b[A\n",
      "Training:  76%|▊| 30974/40960 [01:41<00:32, 309.43batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  76%|▊| 31032/40960 [01:41<00:32, 303.06batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  76%|▊| 31032/40960 [01:41<00:32, 303.06batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  76%|▊| 31096/40960 [01:41<00:32, 307.85batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  76%|▊| 31096/40960 [01:41<00:32, 307.85batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  76%|▊| 31149/40960 [01:41<00:33, 294.40batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  76%|▊| 31149/40960 [01:41<00:33, 294.40batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  76%|▊| 31207/40960 [01:41<00:33, 291.93batches/s, l2_loss: 0.1106 - round_los\u001b[A\n",
      "Training:  76%|▊| 31207/40960 [01:41<00:33, 291.93batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  76%|▊| 31273/40960 [01:42<00:32, 302.53batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  76%|▊| 31273/40960 [01:42<00:32, 302.53batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  77%|▊| 31340/40960 [01:42<00:30, 311.42batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  77%|▊| 31340/40960 [01:42<00:30, 311.42batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  77%|▊| 31404/40960 [01:42<00:30, 313.78batches/s, l2_loss: 0.1107 - round_los\u001b[A\n",
      "Training:  77%|▊| 31404/40960 [01:42<00:30, 313.78batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  77%|▊| 31468/40960 [01:42<00:30, 315.18batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  77%|▊| 31468/40960 [01:42<00:30, 315.18batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  77%|▊| 31533/40960 [01:42<00:29, 316.99batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  77%|▊| 31533/40960 [01:42<00:29, 316.99batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  77%|▊| 31592/40960 [01:43<00:30, 309.91batches/s, l2_loss: 0.1108 - round_los\u001b[A\n",
      "Training:  77%|▊| 31592/40960 [01:43<00:30, 309.91batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  77%|▊| 31651/40960 [01:43<00:30, 303.91batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  77%|▊| 31651/40960 [01:43<00:30, 303.91batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  77%|▊| 31706/40960 [01:43<00:31, 293.39batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  77%|▊| 31706/40960 [01:43<00:31, 293.39batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  78%|▊| 31767/40960 [01:43<00:31, 295.22batches/s, l2_loss: 0.1109 - round_los\u001b[A\n",
      "Training:  78%|▊| 31767/40960 [01:43<00:31, 295.22batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  78%|▊| 31823/40960 [01:43<00:31, 289.32batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  78%|▊| 31823/40960 [01:43<00:31, 289.32batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  78%|▊| 31884/40960 [01:44<00:30, 292.84batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  78%|▊| 31884/40960 [01:44<00:30, 292.84batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  78%|▊| 31938/40960 [01:44<00:31, 285.30batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  78%|▊| 31938/40960 [01:44<00:31, 285.30batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  78%|▊| 31988/40960 [01:44<00:32, 274.58batches/s, l2_loss: 0.1110 - round_los\u001b[A\n",
      "Training:  78%|▊| 31988/40960 [01:44<00:32, 274.58batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  78%|▊| 32042/40960 [01:44<00:32, 272.65batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  78%|▊| 32042/40960 [01:44<00:32, 272.65batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  78%|▊| 32093/40960 [01:44<00:33, 265.39batches/s, l2_loss: 0.1111 - round_los\u001b[A\n",
      "Training:  78%|▊| 32093/40960 [01:44<00:33, 265.39batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  78%|▊| 32153/40960 [01:45<00:32, 274.75batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  78%|▊| 32153/40960 [01:45<00:32, 274.75batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  79%|▊| 32213/40960 [01:45<00:31, 281.76batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  79%|▊| 32213/40960 [01:45<00:31, 281.76batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  79%|▊| 32270/40960 [01:45<00:30, 281.76batches/s, l2_loss: 0.1112 - round_los\u001b[A\n",
      "Training:  79%|▊| 32270/40960 [01:45<00:30, 281.76batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  79%|▊| 32332/40960 [01:45<00:29, 288.61batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  79%|▊| 32332/40960 [01:45<00:29, 288.61batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  79%|▊| 32398/40960 [01:45<00:28, 300.17batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  79%|▊| 32398/40960 [01:45<00:28, 300.17batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  79%|▊| 32460/40960 [01:46<00:28, 301.75batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  79%|▊| 32460/40960 [01:46<00:28, 301.75batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  79%|▊| 32523/40960 [01:46<00:27, 303.76batches/s, l2_loss: 0.1113 - round_los\u001b[A\n",
      "Training:  79%|▊| 32523/40960 [01:46<00:27, 303.76batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  80%|▊| 32579/40960 [01:46<00:28, 296.69batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  80%|▊| 32579/40960 [01:46<00:28, 296.69batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  80%|▊| 32645/40960 [01:46<00:27, 305.63batches/s, l2_loss: 0.1114 - round_los\u001b[A\n",
      "Training:  80%|▊| 32645/40960 [01:46<00:27, 305.63batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  80%|▊| 32707/40960 [01:46<00:26, 306.19batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  80%|▊| 32707/40960 [01:46<00:26, 306.19batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  80%|▊| 32770/40960 [01:47<00:26, 307.67batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  80%|▊| 32770/40960 [01:47<00:26, 307.67batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  80%|▊| 32817/40960 [01:47<00:28, 285.76batches/s, l2_loss: 0.1115 - round_los\u001b[A\n",
      "Training:  80%|▊| 32817/40960 [01:47<00:28, 285.76batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32870/40960 [01:47<00:29, 278.29batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32870/40960 [01:47<00:29, 278.29batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32918/40960 [01:47<00:30, 264.86batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32918/40960 [01:47<00:30, 264.86batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32970/40960 [01:47<00:30, 263.41batches/s, l2_loss: 0.1116 - round_los\u001b[A\n",
      "Training:  80%|▊| 32970/40960 [01:47<00:30, 263.41batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  81%|▊| 33030/40960 [01:48<00:28, 273.46batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  81%|▊| 33030/40960 [01:48<00:28, 273.46batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  81%|▊| 33084/40960 [01:48<00:29, 271.48batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  81%|▊| 33084/40960 [01:48<00:29, 271.48batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  81%|▊| 33148/40960 [01:48<00:27, 284.86batches/s, l2_loss: 0.1117 - round_los\u001b[A\n",
      "Training:  81%|▊| 33148/40960 [01:48<00:27, 284.86batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  81%|▊| 33214/40960 [01:48<00:25, 298.27batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  81%|▊| 33214/40960 [01:48<00:25, 298.27batches/s, l2_loss: 0.1118 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|▊| 33281/40960 [01:48<00:24, 308.40batches/s, l2_loss: 0.1118 - round_los\u001b[A\n",
      "Training:  81%|▊| 33281/40960 [01:49<00:24, 308.40batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  81%|▊| 33349/40960 [01:49<00:23, 317.72batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  81%|▊| 33349/40960 [01:49<00:23, 317.72batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  82%|▊| 33415/40960 [01:49<00:23, 321.16batches/s, l2_loss: 0.1119 - round_los\u001b[A\n",
      "Training:  82%|▊| 33415/40960 [01:49<00:23, 321.16batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  82%|▊| 33482/40960 [01:49<00:23, 324.68batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  82%|▊| 33482/40960 [01:49<00:23, 324.68batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  82%|▊| 33545/40960 [01:49<00:23, 321.00batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  82%|▊| 33545/40960 [01:49<00:23, 321.00batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  82%|▊| 33600/40960 [01:50<00:23, 306.75batches/s, l2_loss: 0.1120 - round_los\u001b[A\n",
      "Training:  82%|▊| 33600/40960 [01:50<00:23, 306.75batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  82%|▊| 33665/40960 [01:50<00:23, 311.48batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  82%|▊| 33665/40960 [01:50<00:23, 311.48batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  82%|▊| 33732/40960 [01:50<00:22, 318.02batches/s, l2_loss: 0.1121 - round_los\u001b[A\n",
      "Training:  82%|▊| 33732/40960 [01:50<00:22, 318.02batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  82%|▊| 33789/40960 [01:50<00:23, 307.58batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  82%|▊| 33789/40960 [01:50<00:23, 307.58batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  83%|▊| 33856/40960 [01:50<00:22, 314.54batches/s, l2_loss: 0.1122 - round_los\u001b[A\n",
      "Training:  83%|▊| 33856/40960 [01:50<00:22, 314.54batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  83%|▊| 33915/40960 [01:51<00:22, 308.37batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  83%|▊| 33915/40960 [01:51<00:22, 308.37batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  83%|▊| 33980/40960 [01:51<00:22, 312.96batches/s, l2_loss: 0.1123 - round_los\u001b[A\n",
      "Training:  83%|▊| 33980/40960 [01:51<00:22, 312.96batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  83%|▊| 34045/40960 [01:51<00:21, 315.50batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  83%|▊| 34045/40960 [01:51<00:21, 315.50batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  83%|▊| 34112/40960 [01:51<00:21, 320.60batches/s, l2_loss: 0.1124 - round_los\u001b[A\n",
      "Training:  83%|▊| 34112/40960 [01:51<00:21, 320.60batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  83%|▊| 34173/40960 [01:51<00:21, 314.84batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  83%|▊| 34173/40960 [01:51<00:21, 314.84batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  84%|▊| 34238/40960 [01:52<00:21, 317.06batches/s, l2_loss: 0.1125 - round_los\u001b[A\n",
      "Training:  84%|▊| 34238/40960 [01:52<00:21, 317.06batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training:  84%|▊| 34296/40960 [01:52<00:21, 308.99batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training:  84%|▊| 34296/40960 [01:52<00:21, 308.99batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training:  84%|▊| 34360/40960 [01:52<00:21, 311.04batches/s, l2_loss: 0.1126 - round_los\u001b[A\n",
      "Training:  84%|▊| 34360/40960 [01:52<00:21, 311.04batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34423/40960 [01:52<00:20, 311.76batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34423/40960 [01:52<00:20, 311.76batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34487/40960 [01:52<00:20, 311.81batches/s, l2_loss: 0.1127 - round_los\u001b[A\n",
      "Training:  84%|▊| 34487/40960 [01:52<00:20, 311.81batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  84%|▊| 34553/40960 [01:53<00:20, 316.95batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  84%|▊| 34553/40960 [01:53<00:20, 316.95batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  84%|▊| 34607/40960 [01:53<00:21, 299.58batches/s, l2_loss: 0.1128 - round_los\u001b[A\n",
      "Training:  84%|▊| 34607/40960 [01:53<00:21, 299.58batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  85%|▊| 34646/40960 [01:53<00:23, 267.88batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  85%|▊| 34646/40960 [01:53<00:23, 267.88batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  85%|▊| 34709/40960 [01:53<00:22, 281.44batches/s, l2_loss: 0.1129 - round_los\u001b[A\n",
      "Training:  85%|▊| 34709/40960 [01:53<00:22, 281.44batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  85%|▊| 34775/40960 [01:53<00:20, 295.49batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  85%|▊| 34775/40960 [01:53<00:20, 295.49batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  85%|▊| 34833/40960 [01:54<00:20, 292.10batches/s, l2_loss: 0.1130 - round_los\u001b[A\n",
      "Training:  85%|▊| 34833/40960 [01:54<00:20, 292.10batches/s, l2_loss: 0.1131 - round_los\u001b[A\n",
      "Training:  85%|▊| 34896/40960 [01:54<00:20, 298.10batches/s, l2_loss: 0.1131 - round_los\u001b[A\n",
      "Training:  85%|▊| 34896/40960 [01:54<00:20, 298.10batches/s, l2_loss: 0.1131 - round_los\u001b[A\n",
      "Training:  85%|▊| 34962/40960 [01:54<00:19, 307.40batches/s, l2_loss: 0.1131 - round_los\u001b[A\n",
      "Training:  85%|▊| 34962/40960 [01:54<00:19, 307.40batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  86%|▊| 35029/40960 [01:54<00:18, 315.03batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  86%|▊| 35029/40960 [01:54<00:18, 315.03batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  86%|▊| 35098/40960 [01:54<00:18, 323.41batches/s, l2_loss: 0.1132 - round_los\u001b[A\n",
      "Training:  86%|▊| 35098/40960 [01:54<00:18, 323.41batches/s, l2_loss: 0.1133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35164/40960 [01:55<00:17, 324.02batches/s, l2_loss: 0.1133 - round_los\u001b[A\n",
      "Training:  86%|▊| 35164/40960 [01:55<00:17, 324.02batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  86%|▊| 35227/40960 [01:55<00:17, 321.08batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  86%|▊| 35227/40960 [01:55<00:17, 321.08batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  86%|▊| 35293/40960 [01:55<00:17, 322.98batches/s, l2_loss: 0.1134 - round_los\u001b[A\n",
      "Training:  86%|▊| 35293/40960 [01:55<00:17, 322.98batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  86%|▊| 35353/40960 [01:55<00:17, 315.83batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  86%|▊| 35353/40960 [01:55<00:17, 315.83batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  86%|▊| 35416/40960 [01:55<00:17, 314.96batches/s, l2_loss: 0.1135 - round_los\u001b[A\n",
      "Training:  86%|▊| 35416/40960 [01:55<00:17, 314.96batches/s, l2_loss: 0.1136 - round_los\u001b[A\n",
      "Training:  87%|▊| 35474/40960 [01:56<00:17, 307.20batches/s, l2_loss: 0.1136 - round_los\u001b[A\n",
      "Training:  87%|▊| 35474/40960 [01:56<00:17, 307.20batches/s, l2_loss: 0.1136 - round_los\u001b[A\n",
      "Training:  87%|▊| 35535/40960 [01:56<00:17, 306.50batches/s, l2_loss: 0.1136 - round_los\u001b[A\n",
      "Training:  87%|▊| 35535/40960 [01:56<00:17, 306.50batches/s, l2_loss: 0.1137 - round_los\u001b[A\n",
      "Training:  87%|▊| 35586/40960 [01:56<00:18, 290.83batches/s, l2_loss: 0.1137 - round_los\u001b[A\n",
      "Training:  87%|▊| 35586/40960 [01:56<00:18, 290.83batches/s, l2_loss: 0.1138 - round_los\u001b[A\n",
      "Training:  87%|▊| 35642/40960 [01:56<00:18, 287.00batches/s, l2_loss: 0.1138 - round_los\u001b[A\n",
      "Training:  87%|▊| 35642/40960 [01:56<00:18, 287.00batches/s, l2_loss: 0.1138 - round_los\u001b[A\n",
      "Training:  87%|▊| 35701/40960 [01:56<00:18, 289.24batches/s, l2_loss: 0.1138 - round_los\u001b[A\n",
      "Training:  87%|▊| 35701/40960 [01:56<00:18, 289.24batches/s, l2_loss: 0.1139 - round_los\u001b[A\n",
      "Training:  87%|▊| 35755/40960 [01:57<00:18, 282.94batches/s, l2_loss: 0.1139 - round_los\u001b[A\n",
      "Training:  87%|▊| 35755/40960 [01:57<00:18, 282.94batches/s, l2_loss: 0.1139 - round_los\u001b[A\n",
      "Training:  87%|▊| 35809/40960 [01:57<00:18, 277.81batches/s, l2_loss: 0.1139 - round_los\u001b[A\n",
      "Training:  87%|▊| 35809/40960 [01:57<00:18, 277.81batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  88%|▉| 35866/40960 [01:57<00:18, 279.34batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  88%|▉| 35866/40960 [01:57<00:18, 279.34batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  88%|▉| 35920/40960 [01:57<00:18, 276.43batches/s, l2_loss: 0.1140 - round_los\u001b[A\n",
      "Training:  88%|▉| 35920/40960 [01:57<00:18, 276.43batches/s, l2_loss: 0.1141 - round_los\u001b[A\n",
      "Training:  88%|▉| 35973/40960 [01:57<00:18, 270.59batches/s, l2_loss: 0.1141 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|▉| 35973/40960 [01:57<00:18, 270.59batches/s, l2_loss: 0.1142 - round_los\u001b[A\n",
      "Training:  88%|▉| 36038/40960 [01:58<00:17, 285.63batches/s, l2_loss: 0.1142 - round_los\u001b[A\n",
      "Training:  88%|▉| 36038/40960 [01:58<00:17, 285.63batches/s, l2_loss: 0.1142 - round_los\u001b[A\n",
      "Training:  88%|▉| 36101/40960 [01:58<00:16, 293.83batches/s, l2_loss: 0.1142 - round_los\u001b[A\n",
      "Training:  88%|▉| 36101/40960 [01:58<00:16, 293.83batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  88%|▉| 36166/40960 [01:58<00:15, 302.25batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  88%|▉| 36166/40960 [01:58<00:15, 302.25batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  88%|▉| 36231/40960 [01:58<00:15, 307.98batches/s, l2_loss: 0.1143 - round_los\u001b[A\n",
      "Training:  88%|▉| 36231/40960 [01:58<00:15, 307.98batches/s, l2_loss: 0.1144 - round_los\u001b[A\n",
      "Training:  89%|▉| 36286/40960 [01:58<00:15, 296.61batches/s, l2_loss: 0.1144 - round_los\u001b[A\n",
      "Training:  89%|▉| 36286/40960 [01:58<00:15, 296.61batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  89%|▉| 36344/40960 [01:59<00:15, 294.60batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  89%|▉| 36344/40960 [01:59<00:15, 294.60batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  89%|▉| 36399/40960 [01:59<00:15, 287.47batches/s, l2_loss: 0.1145 - round_los\u001b[A\n",
      "Training:  89%|▉| 36399/40960 [01:59<00:15, 287.47batches/s, l2_loss: 0.1146 - round_los\u001b[A\n",
      "Training:  89%|▉| 36458/40960 [01:59<00:15, 287.86batches/s, l2_loss: 0.1146 - round_los\u001b[A\n",
      "Training:  89%|▉| 36458/40960 [01:59<00:15, 287.86batches/s, l2_loss: 0.1146 - round_los\u001b[A\n",
      "Training:  89%|▉| 36520/40960 [01:59<00:15, 293.83batches/s, l2_loss: 0.1146 - round_los\u001b[A\n",
      "Training:  89%|▉| 36520/40960 [01:59<00:15, 293.83batches/s, l2_loss: 0.1147 - round_los\u001b[A\n",
      "Training:  89%|▉| 36579/40960 [01:59<00:14, 294.01batches/s, l2_loss: 0.1147 - round_los\u001b[A\n",
      "Training:  89%|▉| 36579/40960 [01:59<00:14, 294.01batches/s, l2_loss: 0.1147 - round_los\u001b[A\n",
      "Training:  89%|▉| 36645/40960 [02:00<00:14, 304.31batches/s, l2_loss: 0.1147 - round_los\u001b[A\n",
      "Training:  89%|▉| 36645/40960 [02:00<00:14, 304.31batches/s, l2_loss: 0.1148 - round_los\u001b[A\n",
      "Training:  90%|▉| 36705/40960 [02:00<00:14, 302.38batches/s, l2_loss: 0.1148 - round_los\u001b[A\n",
      "Training:  90%|▉| 36705/40960 [02:00<00:14, 302.38batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36762/40960 [02:00<00:14, 295.54batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36762/40960 [02:00<00:14, 295.54batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36827/40960 [02:00<00:13, 303.58batches/s, l2_loss: 0.1149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36827/40960 [02:00<00:13, 303.58batches/s, l2_loss: 0.1150 - round_los\u001b[A\n",
      "Training:  90%|▉| 36879/40960 [02:00<00:14, 290.25batches/s, l2_loss: 0.1150 - round_los\u001b[A\n",
      "Training:  90%|▉| 36879/40960 [02:00<00:14, 290.25batches/s, l2_loss: 0.1151 - round_los\u001b[A\n",
      "Training:  90%|▉| 36931/40960 [02:01<00:14, 281.07batches/s, l2_loss: 0.1151 - round_los\u001b[A\n",
      "Training:  90%|▉| 36931/40960 [02:01<00:14, 281.07batches/s, l2_loss: 0.1151 - round_los\u001b[A\n",
      "Training:  90%|▉| 36983/40960 [02:01<00:14, 273.66batches/s, l2_loss: 0.1151 - round_los\u001b[A\n",
      "Training:  90%|▉| 36983/40960 [02:01<00:14, 273.66batches/s, l2_loss: 0.1152 - round_los\u001b[A\n",
      "Training:  90%|▉| 37042/40960 [02:01<00:13, 280.03batches/s, l2_loss: 0.1152 - round_los\u001b[A\n",
      "Training:  90%|▉| 37042/40960 [02:01<00:13, 280.03batches/s, l2_loss: 0.1152 - round_los\u001b[A\n",
      "Training:  91%|▉| 37090/40960 [02:01<00:14, 266.40batches/s, l2_loss: 0.1152 - round_los\u001b[A\n",
      "Training:  91%|▉| 37090/40960 [02:01<00:14, 266.40batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  91%|▉| 37149/40960 [02:01<00:13, 272.47batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  91%|▉| 37149/40960 [02:01<00:13, 272.47batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  91%|▉| 37197/40960 [02:02<00:14, 262.65batches/s, l2_loss: 0.1153 - round_los\u001b[A\n",
      "Training:  91%|▉| 37197/40960 [02:02<00:14, 262.65batches/s, l2_loss: 0.1154 - round_los\u001b[A\n",
      "Training:  91%|▉| 37259/40960 [02:02<00:13, 276.56batches/s, l2_loss: 0.1154 - round_los\u001b[A\n",
      "Training:  91%|▉| 37259/40960 [02:02<00:13, 276.56batches/s, l2_loss: 0.1155 - round_los\u001b[A\n",
      "Training:  91%|▉| 37314/40960 [02:02<00:13, 276.09batches/s, l2_loss: 0.1155 - round_los\u001b[A\n",
      "Training:  91%|▉| 37314/40960 [02:02<00:13, 276.09batches/s, l2_loss: 0.1155 - round_los\u001b[A\n",
      "Training:  91%|▉| 37372/40960 [02:02<00:12, 279.20batches/s, l2_loss: 0.1155 - round_los\u001b[A\n",
      "Training:  91%|▉| 37372/40960 [02:02<00:12, 279.20batches/s, l2_loss: 0.1156 - round_los\u001b[A\n",
      "Training:  91%|▉| 37433/40960 [02:02<00:12, 285.63batches/s, l2_loss: 0.1156 - round_los\u001b[A\n",
      "Training:  91%|▉| 37433/40960 [02:02<00:12, 285.63batches/s, l2_loss: 0.1157 - round_los\u001b[A\n",
      "Training:  92%|▉| 37492/40960 [02:03<00:12, 287.64batches/s, l2_loss: 0.1157 - round_los\u001b[A\n",
      "Training:  92%|▉| 37492/40960 [02:03<00:12, 287.64batches/s, l2_loss: 0.1157 - round_los\u001b[A\n",
      "Training:  92%|▉| 37545/40960 [02:03<00:12, 280.85batches/s, l2_loss: 0.1157 - round_los\u001b[A\n",
      "Training:  92%|▉| 37545/40960 [02:03<00:12, 280.85batches/s, l2_loss: 0.1158 - round_los\u001b[A\n",
      "Training:  92%|▉| 37602/40960 [02:03<00:12, 279.14batches/s, l2_loss: 0.1158 - round_los\u001b[A\n",
      "Training:  92%|▉| 37602/40960 [02:03<00:12, 279.14batches/s, l2_loss: 0.1159 - round_los\u001b[A\n",
      "Training:  92%|▉| 37661/40960 [02:03<00:11, 283.29batches/s, l2_loss: 0.1159 - round_los\u001b[A\n",
      "Training:  92%|▉| 37661/40960 [02:03<00:11, 283.29batches/s, l2_loss: 0.1159 - round_los\u001b[A\n",
      "Training:  92%|▉| 37723/40960 [02:03<00:11, 290.74batches/s, l2_loss: 0.1159 - round_los\u001b[A\n",
      "Training:  92%|▉| 37723/40960 [02:03<00:11, 290.74batches/s, l2_loss: 0.1160 - round_los\u001b[A\n",
      "Training:  92%|▉| 37791/40960 [02:04<00:10, 304.91batches/s, l2_loss: 0.1160 - round_los\u001b[A\n",
      "Training:  92%|▉| 37791/40960 [02:04<00:10, 304.91batches/s, l2_loss: 0.1161 - round_los\u001b[A\n",
      "Training:  92%|▉| 37848/40960 [02:04<00:10, 297.63batches/s, l2_loss: 0.1161 - round_los\u001b[A\n",
      "Training:  92%|▉| 37848/40960 [02:04<00:10, 297.63batches/s, l2_loss: 0.1161 - round_los\u001b[A\n",
      "Training:  93%|▉| 37908/40960 [02:04<00:10, 297.48batches/s, l2_loss: 0.1161 - round_los\u001b[A\n",
      "Training:  93%|▉| 37908/40960 [02:04<00:10, 297.48batches/s, l2_loss: 0.1162 - round_los\u001b[A\n",
      "Training:  93%|▉| 37962/40960 [02:04<00:10, 288.78batches/s, l2_loss: 0.1162 - round_los\u001b[A\n",
      "Training:  93%|▉| 37962/40960 [02:04<00:10, 288.78batches/s, l2_loss: 0.1162 - round_los\u001b[A\n",
      "Training:  93%|▉| 38024/40960 [02:04<00:09, 294.08batches/s, l2_loss: 0.1162 - round_los\u001b[A\n",
      "Training:  93%|▉| 38024/40960 [02:04<00:09, 294.08batches/s, l2_loss: 0.1163 - round_los\u001b[A\n",
      "Training:  93%|▉| 38081/40960 [02:05<00:09, 288.90batches/s, l2_loss: 0.1163 - round_los\u001b[A\n",
      "Training:  93%|▉| 38081/40960 [02:05<00:09, 288.90batches/s, l2_loss: 0.1164 - round_los\u001b[A\n",
      "Training:  93%|▉| 38145/40960 [02:05<00:09, 297.59batches/s, l2_loss: 0.1164 - round_los\u001b[A\n",
      "Training:  93%|▉| 38145/40960 [02:05<00:09, 297.59batches/s, l2_loss: 0.1164 - round_los\u001b[A\n",
      "Training:  93%|▉| 38213/40960 [02:05<00:08, 308.40batches/s, l2_loss: 0.1164 - round_los\u001b[A\n",
      "Training:  93%|▉| 38213/40960 [02:05<00:08, 308.40batches/s, l2_loss: 0.1165 - round_los\u001b[A\n",
      "Training:  93%|▉| 38281/40960 [02:05<00:08, 317.75batches/s, l2_loss: 0.1165 - round_los\u001b[A\n",
      "Training:  93%|▉| 38281/40960 [02:05<00:08, 317.75batches/s, l2_loss: 0.1166 - round_los\u001b[A\n",
      "Training:  94%|▉| 38347/40960 [02:05<00:08, 320.70batches/s, l2_loss: 0.1166 - round_los\u001b[A\n",
      "Training:  94%|▉| 38347/40960 [02:05<00:08, 320.70batches/s, l2_loss: 0.1166 - round_los\u001b[A\n",
      "Training:  94%|▉| 38411/40960 [02:06<00:07, 319.35batches/s, l2_loss: 0.1166 - round_los\u001b[A\n",
      "Training:  94%|▉| 38411/40960 [02:06<00:07, 319.35batches/s, l2_loss: 0.1168 - round_los\u001b[A\n",
      "Training:  94%|▉| 38479/40960 [02:06<00:07, 324.70batches/s, l2_loss: 0.1168 - round_los\u001b[A\n",
      "Training:  94%|▉| 38479/40960 [02:06<00:07, 324.70batches/s, l2_loss: 0.1168 - round_los\u001b[A\n",
      "Training:  94%|▉| 38543/40960 [02:06<00:07, 322.93batches/s, l2_loss: 0.1168 - round_los\u001b[A\n",
      "Training:  94%|▉| 38543/40960 [02:06<00:07, 322.93batches/s, l2_loss: 0.1169 - round_los\u001b[A\n",
      "Training:  94%|▉| 38604/40960 [02:06<00:07, 315.88batches/s, l2_loss: 0.1169 - round_los\u001b[A\n",
      "Training:  94%|▉| 38604/40960 [02:06<00:07, 315.88batches/s, l2_loss: 0.1170 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|▉| 38666/40960 [02:06<00:07, 313.76batches/s, l2_loss: 0.1170 - round_los\u001b[A\n",
      "Training:  94%|▉| 38666/40960 [02:06<00:07, 313.76batches/s, l2_loss: 0.1170 - round_los\u001b[A\n",
      "Training:  95%|▉| 38729/40960 [02:07<00:07, 313.82batches/s, l2_loss: 0.1170 - round_los\u001b[A\n",
      "Training:  95%|▉| 38729/40960 [02:07<00:07, 313.82batches/s, l2_loss: 0.1171 - round_los\u001b[A\n",
      "Training:  95%|▉| 38795/40960 [02:07<00:06, 318.54batches/s, l2_loss: 0.1171 - round_los\u001b[A\n",
      "Training:  95%|▉| 38795/40960 [02:07<00:06, 318.54batches/s, l2_loss: 0.1172 - round_los\u001b[A\n",
      "Training:  95%|▉| 38858/40960 [02:07<00:06, 317.39batches/s, l2_loss: 0.1172 - round_los\u001b[A\n",
      "Training:  95%|▉| 38858/40960 [02:07<00:06, 317.39batches/s, l2_loss: 0.1173 - round_los\u001b[A\n",
      "Training:  95%|▉| 38925/40960 [02:07<00:06, 321.93batches/s, l2_loss: 0.1173 - round_los\u001b[A\n",
      "Training:  95%|▉| 38925/40960 [02:07<00:06, 321.93batches/s, l2_loss: 0.1173 - round_los\u001b[A\n",
      "Training:  95%|▉| 38991/40960 [02:07<00:06, 323.04batches/s, l2_loss: 0.1173 - round_los\u001b[A\n",
      "Training:  95%|▉| 38991/40960 [02:07<00:06, 323.04batches/s, l2_loss: 0.1174 - round_los\u001b[A\n",
      "Training:  95%|▉| 39052/40960 [02:08<00:06, 317.41batches/s, l2_loss: 0.1174 - round_los\u001b[A\n",
      "Training:  95%|▉| 39052/40960 [02:08<00:06, 317.41batches/s, l2_loss: 0.1175 - round_los\u001b[A\n",
      "Training:  96%|▉| 39117/40960 [02:08<00:05, 319.23batches/s, l2_loss: 0.1175 - round_los\u001b[A\n",
      "Training:  96%|▉| 39117/40960 [02:08<00:05, 319.23batches/s, l2_loss: 0.1176 - round_los\u001b[A\n",
      "Training:  96%|▉| 39169/40960 [02:08<00:05, 300.88batches/s, l2_loss: 0.1176 - round_los\u001b[A\n",
      "Training:  96%|▉| 39169/40960 [02:08<00:05, 300.88batches/s, l2_loss: 0.1176 - round_los\u001b[A\n",
      "Training:  96%|▉| 39231/40960 [02:08<00:05, 303.24batches/s, l2_loss: 0.1176 - round_los\u001b[A\n",
      "Training:  96%|▉| 39231/40960 [02:08<00:05, 303.24batches/s, l2_loss: 0.1177 - round_los\u001b[A\n",
      "Training:  96%|▉| 39293/40960 [02:08<00:05, 303.54batches/s, l2_loss: 0.1177 - round_los\u001b[A\n",
      "Training:  96%|▉| 39293/40960 [02:08<00:05, 303.54batches/s, l2_loss: 0.1178 - round_los\u001b[A\n",
      "Training:  96%|▉| 39354/40960 [02:09<00:05, 302.70batches/s, l2_loss: 0.1178 - round_los\u001b[A\n",
      "Training:  96%|▉| 39354/40960 [02:09<00:05, 302.70batches/s, l2_loss: 0.1178 - round_los\u001b[A\n",
      "Training:  96%|▉| 39415/40960 [02:09<00:05, 303.11batches/s, l2_loss: 0.1178 - round_los\u001b[A\n",
      "Training:  96%|▉| 39415/40960 [02:09<00:05, 303.11batches/s, l2_loss: 0.1179 - round_los\u001b[A\n",
      "Training:  96%|▉| 39480/40960 [02:09<00:04, 308.80batches/s, l2_loss: 0.1179 - round_los\u001b[A\n",
      "Training:  96%|▉| 39480/40960 [02:09<00:04, 308.80batches/s, l2_loss: 0.1180 - round_los\u001b[A\n",
      "Training:  97%|▉| 39546/40960 [02:09<00:04, 314.08batches/s, l2_loss: 0.1180 - round_los\u001b[A\n",
      "Training:  97%|▉| 39546/40960 [02:09<00:04, 314.08batches/s, l2_loss: 0.1180 - round_los\u001b[A\n",
      "Training:  97%|▉| 39608/40960 [02:09<00:04, 311.98batches/s, l2_loss: 0.1180 - round_los\u001b[A\n",
      "Training:  97%|▉| 39608/40960 [02:09<00:04, 311.98batches/s, l2_loss: 0.1181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39672/40960 [02:10<00:04, 313.74batches/s, l2_loss: 0.1181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39672/40960 [02:10<00:04, 313.74batches/s, l2_loss: 0.1182 - round_los\u001b[A\n",
      "Training:  97%|▉| 39733/40960 [02:10<00:03, 309.39batches/s, l2_loss: 0.1182 - round_los\u001b[A\n",
      "Training:  97%|▉| 39733/40960 [02:10<00:03, 309.39batches/s, l2_loss: 0.1183 - round_los\u001b[A\n",
      "Training:  97%|▉| 39798/40960 [02:10<00:03, 313.76batches/s, l2_loss: 0.1183 - round_los\u001b[A\n",
      "Training:  97%|▉| 39798/40960 [02:10<00:03, 313.76batches/s, l2_loss: 0.1183 - round_los\u001b[A\n",
      "Training:  97%|▉| 39862/40960 [02:10<00:03, 315.30batches/s, l2_loss: 0.1183 - round_los\u001b[A\n",
      "Training:  97%|▉| 39862/40960 [02:10<00:03, 315.30batches/s, l2_loss: 0.1184 - round_los\u001b[A\n",
      "Training:  97%|▉| 39926/40960 [02:10<00:03, 316.18batches/s, l2_loss: 0.1184 - round_los\u001b[A\n",
      "Training:  97%|▉| 39926/40960 [02:10<00:03, 316.18batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  98%|▉| 39990/40960 [02:11<00:03, 315.24batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  98%|▉| 39990/40960 [02:11<00:03, 315.24batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  98%|▉| 40035/40960 [02:11<00:03, 287.66batches/s, l2_loss: 0.1185 - round_los\u001b[A\n",
      "Training:  98%|▉| 40035/40960 [02:11<00:03, 287.66batches/s, l2_loss: 0.1186 - round_los\u001b[A\n",
      "Training:  98%|▉| 40086/40960 [02:11<00:03, 277.47batches/s, l2_loss: 0.1186 - round_los\u001b[A\n",
      "Training:  98%|▉| 40086/40960 [02:11<00:03, 277.47batches/s, l2_loss: 0.1186 - round_los\u001b[A\n",
      "Training:  98%|▉| 40143/40960 [02:11<00:02, 278.51batches/s, l2_loss: 0.1186 - round_los\u001b[A\n",
      "Training:  98%|▉| 40143/40960 [02:11<00:02, 278.51batches/s, l2_loss: 0.1187 - round_los\u001b[A\n",
      "Training:  98%|▉| 40202/40960 [02:12<00:02, 282.40batches/s, l2_loss: 0.1187 - round_los\u001b[A\n",
      "Training:  98%|▉| 40202/40960 [02:12<00:02, 282.40batches/s, l2_loss: 0.1187 - round_los\u001b[A\n",
      "Training:  98%|▉| 40263/40960 [02:12<00:02, 288.58batches/s, l2_loss: 0.1187 - round_los\u001b[A\n",
      "Training:  98%|▉| 40263/40960 [02:12<00:02, 288.58batches/s, l2_loss: 0.1188 - round_los\u001b[A\n",
      "Training:  98%|▉| 40323/40960 [02:12<00:02, 291.98batches/s, l2_loss: 0.1188 - round_los\u001b[A\n",
      "Training:  98%|▉| 40323/40960 [02:12<00:02, 291.98batches/s, l2_loss: 0.1189 - round_los\u001b[A\n",
      "Training:  99%|▉| 40382/40960 [02:12<00:01, 292.29batches/s, l2_loss: 0.1189 - round_los\u001b[A\n",
      "Training:  99%|▉| 40382/40960 [02:12<00:01, 292.29batches/s, l2_loss: 0.1190 - round_los\u001b[A\n",
      "Training:  99%|▉| 40446/40960 [02:12<00:01, 300.02batches/s, l2_loss: 0.1190 - round_los\u001b[A\n",
      "Training:  99%|▉| 40446/40960 [02:12<00:01, 300.02batches/s, l2_loss: 0.1190 - round_los\u001b[A\n",
      "Training:  99%|▉| 40498/40960 [02:13<00:01, 286.62batches/s, l2_loss: 0.1190 - round_los\u001b[A\n",
      "Training:  99%|▉| 40498/40960 [02:13<00:01, 286.62batches/s, l2_loss: 0.1191 - round_los\u001b[A\n",
      "Training:  99%|▉| 40559/40960 [02:13<00:01, 290.92batches/s, l2_loss: 0.1191 - round_los\u001b[A\n",
      "Training:  99%|▉| 40559/40960 [02:13<00:01, 290.92batches/s, l2_loss: 0.1191 - round_los\u001b[A\n",
      "Training:  99%|▉| 40610/40960 [02:13<00:01, 279.50batches/s, l2_loss: 0.1191 - round_los\u001b[A\n",
      "Training:  99%|▉| 40610/40960 [02:13<00:01, 279.50batches/s, l2_loss: 0.1192 - round_los\u001b[A\n",
      "Training:  99%|▉| 40677/40960 [02:13<00:00, 295.42batches/s, l2_loss: 0.1192 - round_los\u001b[A\n",
      "Training:  99%|▉| 40677/40960 [02:13<00:00, 295.42batches/s, l2_loss: 0.1192 - round_los\u001b[A\n",
      "Training:  99%|▉| 40743/40960 [02:13<00:00, 305.58batches/s, l2_loss: 0.1192 - round_los\u001b[A\n",
      "Training:  99%|▉| 40743/40960 [02:13<00:00, 305.58batches/s, l2_loss: 0.1193 - round_los\u001b[A\n",
      "Training: 100%|▉| 40800/40960 [02:14<00:00, 298.12batches/s, l2_loss: 0.1193 - round_los\u001b[A\n",
      "Training: 100%|▉| 40800/40960 [02:14<00:00, 298.12batches/s, l2_loss: 0.1194 - round_los\u001b[A\n",
      "Training: 100%|▉| 40850/40960 [02:14<00:00, 282.28batches/s, l2_loss: 0.1194 - round_los\u001b[A\n",
      "Training: 100%|▉| 40850/40960 [02:14<00:00, 282.28batches/s, l2_loss: 0.1194 - round_los\u001b[A\n",
      "Training: 100%|▉| 40909/40960 [02:14<00:00, 285.13batches/s, l2_loss: 0.1194 - round_los\u001b[A\n",
      "Training: 100%|▉| 40909/40960 [02:14<00:00, 285.13batches/s, l2_loss: 0.1195 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:18:53.434705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  58%|▌| 15/26 [31:14<23:13, 126.68s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:18:55.937095: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:18:58.427416: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                | 1/40960 [00:00<9:37:47,  1.18batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<9:37:47,  1.18batches/s, l2_loss: 0.0334 - round_loss: \u001b[A\n",
      "Training:   0%| | 97/40960 [00:01<05:35, 121.95batches/s, l2_loss: 0.0334 - round_loss: \u001b[A\n",
      "Training:   0%| | 97/40960 [00:01<05:35, 121.95batches/s, l2_loss: 0.0483 - round_loss: \u001b[A\n",
      "Training:   0%| | 193/40960 [00:01<03:08, 216.52batches/s, l2_loss: 0.0483 - round_loss:\u001b[A\n",
      "Training:   0%| | 193/40960 [00:01<03:08, 216.52batches/s, l2_loss: 0.0487 - round_loss:\u001b[A\n",
      "Training:   1%| | 289/40960 [00:01<02:20, 288.47batches/s, l2_loss: 0.0487 - round_loss:\u001b[A\n",
      "Training:   1%| | 289/40960 [00:01<02:20, 288.47batches/s, l2_loss: 0.0481 - round_loss:\u001b[A\n",
      "Training:   1%| | 385/40960 [00:01<01:58, 341.69batches/s, l2_loss: 0.0481 - round_loss:\u001b[A\n",
      "Training:   1%| | 385/40960 [00:01<01:58, 341.69batches/s, l2_loss: 0.0480 - round_loss:\u001b[A\n",
      "Training:   1%| | 480/40960 [00:01<01:46, 379.28batches/s, l2_loss: 0.0480 - round_loss:\u001b[A\n",
      "Training:   1%| | 480/40960 [00:01<01:46, 379.28batches/s, l2_loss: 0.0475 - round_loss:\u001b[A\n",
      "Training:   1%| | 575/40960 [00:02<01:39, 406.16batches/s, l2_loss: 0.0475 - round_loss:\u001b[A\n",
      "Training:   1%| | 575/40960 [00:02<01:39, 406.16batches/s, l2_loss: 0.0472 - round_loss:\u001b[A\n",
      "Training:   2%| | 670/40960 [00:02<01:34, 425.59batches/s, l2_loss: 0.0472 - round_loss:\u001b[A\n",
      "Training:   2%| | 670/40960 [00:02<01:34, 425.59batches/s, l2_loss: 0.0472 - round_loss:\u001b[A\n",
      "Training:   2%| | 762/40960 [00:02<01:32, 435.47batches/s, l2_loss: 0.0472 - round_loss:\u001b[A\n",
      "Training:   2%| | 762/40960 [00:02<01:32, 435.47batches/s, l2_loss: 0.0468 - round_loss:\u001b[A\n",
      "Training:   2%| | 854/40960 [00:02<01:30, 441.11batches/s, l2_loss: 0.0468 - round_loss:\u001b[A\n",
      "Training:   2%| | 854/40960 [00:02<01:30, 441.11batches/s, l2_loss: 0.0468 - round_loss:\u001b[A\n",
      "Training:   2%| | 950/40960 [00:02<01:28, 451.52batches/s, l2_loss: 0.0468 - round_loss:\u001b[A\n",
      "Training:   2%| | 950/40960 [00:02<01:28, 451.52batches/s, l2_loss: 0.0462 - round_loss:\u001b[A\n",
      "Training:   3%| | 1046/40960 [00:03<01:27, 458.65batches/s, l2_loss: 0.0462 - round_loss\u001b[A\n",
      "Training:   3%| | 1046/40960 [00:03<01:27, 458.65batches/s, l2_loss: 0.0460 - round_loss\u001b[A\n",
      "Training:   3%| | 1141/40960 [00:03<01:25, 463.08batches/s, l2_loss: 0.0460 - round_loss\u001b[A\n",
      "Training:   3%| | 1141/40960 [00:03<01:25, 463.08batches/s, l2_loss: 0.0459 - round_loss\u001b[A\n",
      "Training:   3%| | 1237/40960 [00:03<01:24, 467.48batches/s, l2_loss: 0.0459 - round_loss\u001b[A\n",
      "Training:   3%| | 1237/40960 [00:03<01:24, 467.48batches/s, l2_loss: 0.0457 - round_loss\u001b[A\n",
      "Training:   3%| | 1332/40960 [00:03<01:24, 468.93batches/s, l2_loss: 0.0457 - round_loss\u001b[A\n",
      "Training:   3%| | 1332/40960 [00:03<01:24, 468.93batches/s, l2_loss: 0.0455 - round_loss\u001b[A\n",
      "Training:   3%| | 1424/40960 [00:03<01:24, 465.85batches/s, l2_loss: 0.0455 - round_loss\u001b[A\n",
      "Training:   3%| | 1424/40960 [00:03<01:24, 465.85batches/s, l2_loss: 0.0454 - round_loss\u001b[A\n",
      "Training:   4%| | 1519/40960 [00:04<01:24, 467.95batches/s, l2_loss: 0.0454 - round_loss\u001b[A\n",
      "Training:   4%| | 1519/40960 [00:04<01:24, 467.95batches/s, l2_loss: 0.0454 - round_loss\u001b[A\n",
      "Training:   4%| | 1616/40960 [00:04<01:23, 472.37batches/s, l2_loss: 0.0454 - round_loss\u001b[A\n",
      "Training:   4%| | 1616/40960 [00:04<01:23, 472.37batches/s, l2_loss: 0.0452 - round_loss\u001b[A\n",
      "Training:   4%| | 1711/40960 [00:04<01:23, 472.60batches/s, l2_loss: 0.0452 - round_loss\u001b[A\n",
      "Training:   4%| | 1711/40960 [00:04<01:23, 472.60batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:   4%| | 1805/40960 [00:04<01:23, 470.99batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:   4%| | 1805/40960 [00:04<01:23, 470.99batches/s, l2_loss: 0.0450 - round_loss\u001b[A\n",
      "Training:   5%| | 1900/40960 [00:04<01:22, 471.20batches/s, l2_loss: 0.0450 - round_loss\u001b[A\n",
      "Training:   5%| | 1900/40960 [00:04<01:22, 471.20batches/s, l2_loss: 0.0448 - round_loss\u001b[A\n",
      "Training:   5%| | 1997/40960 [00:05<01:22, 474.26batches/s, l2_loss: 0.0448 - round_loss\u001b[A\n",
      "Training:   5%| | 1997/40960 [00:05<01:22, 474.26batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:   5%| | 2092/40960 [00:05<01:22, 473.71batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:   5%| | 2092/40960 [00:05<01:22, 473.71batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:   5%| | 2186/40960 [00:05<01:22, 472.16batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:   5%| | 2186/40960 [00:05<01:22, 472.16batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:   6%| | 2281/40960 [00:05<01:21, 472.02batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:   6%| | 2281/40960 [00:05<01:21, 472.02batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:   6%| | 2376/40960 [00:05<01:21, 472.64batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:   6%| | 2376/40960 [00:05<01:21, 472.64batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:   6%| | 2473/40960 [00:06<01:21, 474.87batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:   6%| | 2473/40960 [00:06<01:21, 474.87batches/s, l2_loss: 0.0442 - round_loss\u001b[A\n",
      "Training:   6%| | 2567/40960 [00:06<01:21, 472.03batches/s, l2_loss: 0.0442 - round_loss\u001b[A\n",
      "Training:   6%| | 2567/40960 [00:06<01:21, 472.03batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   7%| | 2664/40960 [00:06<01:20, 475.16batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   7%| | 2664/40960 [00:06<01:20, 475.16batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   7%| | 2760/40960 [00:06<01:20, 475.94batches/s, l2_loss: 0.0441 - round_loss\u001b[A\n",
      "Training:   7%| | 2760/40960 [00:06<01:20, 475.94batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   7%| | 2855/40960 [00:06<01:20, 475.14batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   7%| | 2855/40960 [00:06<01:20, 475.14batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   7%| | 2952/40960 [00:07<01:19, 477.12batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   7%| | 2952/40960 [00:07<01:19, 477.12batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   7%| | 3047/40960 [00:07<01:19, 475.54batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   7%| | 3047/40960 [00:07<01:19, 475.54batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   8%| | 3142/40960 [00:07<01:19, 475.33batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:   8%| | 3142/40960 [00:07<01:19, 475.33batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   8%| | 3238/40960 [00:07<01:19, 475.70batches/s, l2_loss: 0.0437 - round_loss\u001b[A\n",
      "Training:   8%| | 3238/40960 [00:07<01:19, 475.70batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   8%| | 3331/40960 [00:07<01:19, 471.45batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   8%| | 3331/40960 [00:07<01:19, 471.45batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   8%| | 3427/40960 [00:08<01:19, 473.52batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   8%| | 3427/40960 [00:08<01:19, 473.52batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   9%| | 3523/40960 [00:08<01:18, 475.05batches/s, l2_loss: 0.0436 - round_loss\u001b[A\n",
      "Training:   9%| | 3523/40960 [00:08<01:18, 475.05batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   9%| | 3620/40960 [00:08<01:18, 477.14batches/s, l2_loss: 0.0435 - round_loss\u001b[A\n",
      "Training:   9%| | 3620/40960 [00:08<01:18, 477.14batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3716/40960 [00:08<01:18, 476.62batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3716/40960 [00:08<01:18, 476.62batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3810/40960 [00:08<01:18, 474.03batches/s, l2_loss: 0.0434 - round_loss\u001b[A\n",
      "Training:   9%| | 3810/40960 [00:08<01:18, 474.03batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 3904/40960 [00:09<01:18, 472.37batches/s, l2_loss: 0.0433 - round_loss\u001b[A\n",
      "Training:  10%| | 3904/40960 [00:09<01:18, 472.37batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 4000/40960 [00:09<01:18, 473.66batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 4000/40960 [00:09<01:18, 473.66batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 4095/40960 [00:09<01:17, 473.94batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 4095/40960 [00:09<01:17, 473.94batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n",
      "Training:  10%| | 4189/40960 [00:09<01:17, 472.50batches/s, l2_loss: 0.0432 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 4189/40960 [00:09<01:17, 472.50batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  10%| | 4281/40960 [00:09<01:18, 467.54batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  10%| | 4281/40960 [00:09<01:18, 467.54batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  11%| | 4377/40960 [00:10<01:17, 470.90batches/s, l2_loss: 0.0431 - round_loss\u001b[A\n",
      "Training:  11%| | 4377/40960 [00:10<01:17, 470.90batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  11%| | 4473/40960 [00:10<01:17, 473.27batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  11%| | 4473/40960 [00:10<01:17, 473.27batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  11%| | 4570/40960 [00:10<01:16, 476.77batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  11%| | 4570/40960 [00:10<01:16, 476.77batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  11%| | 4666/40960 [00:10<01:16, 476.73batches/s, l2_loss: 0.0430 - round_loss\u001b[A\n",
      "Training:  11%| | 4666/40960 [00:10<01:16, 476.73batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  12%| | 4761/40960 [00:10<01:16, 474.99batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  12%| | 4761/40960 [00:10<01:16, 474.99batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  12%| | 4854/40960 [00:11<01:16, 471.72batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  12%| | 4854/40960 [00:11<01:16, 471.72batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  12%| | 4948/40960 [00:11<01:16, 470.95batches/s, l2_loss: 0.0429 - round_loss\u001b[A\n",
      "Training:  12%| | 4948/40960 [00:11<01:16, 470.95batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  12%| | 5042/40960 [00:11<01:16, 470.62batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  12%| | 5042/40960 [00:11<01:16, 470.62batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5138/40960 [00:11<01:15, 472.19batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5138/40960 [00:11<01:15, 472.19batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5235/40960 [00:11<01:15, 475.09batches/s, l2_loss: 0.0428 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5235/40960 [00:11<01:15, 475.09batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5331/40960 [00:12<01:14, 475.36batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5331/40960 [00:12<01:14, 475.36batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5425/40960 [00:12<01:15, 473.54batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5425/40960 [00:12<01:15, 473.54batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5520/40960 [00:12<01:14, 472.82batches/s, l2_loss: 0.0427 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5520/40960 [00:12<01:14, 472.82batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5616/40960 [00:12<01:14, 474.01batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5616/40960 [00:12<01:14, 474.01batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5712/40960 [00:12<01:14, 474.32batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5712/40960 [00:12<01:14, 474.32batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5806/40960 [00:13<01:14, 472.78batches/s, l2_loss: 0.0426 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5806/40960 [00:13<01:14, 472.78batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5902/40960 [00:13<01:13, 474.07batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5902/40960 [00:13<01:13, 474.07batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5996/40960 [00:13<01:13, 472.71batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5996/40960 [00:13<01:13, 472.71batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6091/40960 [00:13<01:13, 473.31batches/s, l2_loss: 0.0425 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6091/40960 [00:13<01:13, 473.31batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6187/40960 [00:13<01:13, 473.94batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6187/40960 [00:13<01:13, 473.94batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6284/40960 [00:14<01:12, 476.82batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6284/40960 [00:14<01:12, 476.82batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6380/40960 [00:14<01:12, 477.63batches/s, l2_loss: 0.0424 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6380/40960 [00:14<01:12, 477.63batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6476/40960 [00:14<01:12, 478.26batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6476/40960 [00:14<01:12, 478.26batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6572/40960 [00:14<01:11, 477.62batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6572/40960 [00:14<01:11, 477.62batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6668/40960 [00:14<01:11, 477.82batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6668/40960 [00:14<01:11, 477.82batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6761/40960 [00:15<01:12, 472.61batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6761/40960 [00:15<01:12, 472.61batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6859/40960 [00:15<01:11, 476.68batches/s, l2_loss: 0.0423 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6859/40960 [00:15<01:11, 476.68batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6954/40960 [00:15<01:11, 475.89batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6954/40960 [00:15<01:11, 475.89batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7049/40960 [00:15<01:11, 474.43batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7049/40960 [00:15<01:11, 474.43batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7140/40960 [00:15<01:12, 468.55batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7140/40960 [00:15<01:12, 468.55batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7236/40960 [00:16<01:11, 470.55batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7236/40960 [00:16<01:11, 470.55batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7331/40960 [00:16<01:11, 470.90batches/s, l2_loss: 0.0422 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7331/40960 [00:16<01:11, 470.90batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7424/40960 [00:16<01:11, 468.21batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7424/40960 [00:16<01:11, 468.21batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7520/40960 [00:16<01:10, 471.61batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7520/40960 [00:16<01:10, 471.61batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7616/40960 [00:16<01:10, 473.05batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7616/40960 [00:16<01:10, 473.05batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7710/40960 [00:17<01:10, 471.89batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7710/40960 [00:17<01:10, 471.89batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7804/40960 [00:17<01:10, 471.04batches/s, l2_loss: 0.0421 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7804/40960 [00:17<01:10, 471.04batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7901/40960 [00:17<01:09, 474.65batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7901/40960 [00:17<01:09, 474.65batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7996/40960 [00:17<01:09, 473.79batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7996/40960 [00:17<01:09, 473.79batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8092/40960 [00:17<01:09, 474.95batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8092/40960 [00:17<01:09, 474.95batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8186/40960 [00:18<01:09, 473.23batches/s, l2_loss: 0.0420 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8186/40960 [00:18<01:09, 473.23batches/s, l2_loss: 0.0419 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8271/40960 [00:18<01:11, 457.15batches/s, l2_loss: 0.0419 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8271/40960 [00:18<01:11, 457.15batches/s, l2_loss: 0.0366 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8356/40960 [00:18<01:13, 446.26batches/s, l2_loss: 0.0366 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8356/40960 [00:18<01:13, 446.26batches/s, l2_loss: 0.0405 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|▏| 8442/40960 [00:18<01:13, 440.71batches/s, l2_loss: 0.0405 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8442/40960 [00:18<01:13, 440.71batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8527/40960 [00:18<01:14, 435.77batches/s, l2_loss: 0.0407 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8527/40960 [00:18<01:14, 435.77batches/s, l2_loss: 0.0403 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8611/40960 [00:19<01:15, 430.61batches/s, l2_loss: 0.0403 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8611/40960 [00:19<01:15, 430.61batches/s, l2_loss: 0.0410 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8695/40960 [00:19<01:15, 427.21batches/s, l2_loss: 0.0410 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8695/40960 [00:19<01:15, 427.21batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8779/40960 [00:19<01:15, 423.70batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8779/40960 [00:19<01:15, 423.70batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8864/40960 [00:19<01:15, 422.56batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8864/40960 [00:19<01:15, 422.56batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8950/40960 [00:19<01:15, 423.40batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8950/40960 [00:19<01:15, 423.40batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9032/40960 [00:20<01:16, 419.11batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9032/40960 [00:20<01:16, 419.11batches/s, l2_loss: 0.0412 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9115/40960 [00:20<01:16, 417.01batches/s, l2_loss: 0.0412 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9115/40960 [00:20<01:16, 417.01batches/s, l2_loss: 0.0412 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9201/40960 [00:20<01:15, 420.38batches/s, l2_loss: 0.0412 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9201/40960 [00:20<01:15, 420.38batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9285/40960 [00:20<01:15, 419.46batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9285/40960 [00:20<01:15, 419.46batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9371/40960 [00:20<01:14, 422.10batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9371/40960 [00:20<01:14, 422.10batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9456/40960 [00:21<01:14, 422.93batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9456/40960 [00:21<01:14, 422.93batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9543/40960 [00:21<01:13, 425.06batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9543/40960 [00:21<01:13, 425.06batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9629/40960 [00:21<01:13, 425.62batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9629/40960 [00:21<01:13, 425.62batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9712/40960 [00:21<01:13, 422.27batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9712/40960 [00:21<01:13, 422.27batches/s, l2_loss: 0.0412 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9795/40960 [00:21<01:14, 418.97batches/s, l2_loss: 0.0412 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9795/40960 [00:21<01:14, 418.97batches/s, l2_loss: 0.0415 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9880/40960 [00:22<01:14, 419.67batches/s, l2_loss: 0.0415 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9880/40960 [00:22<01:14, 419.67batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9964/40960 [00:22<01:14, 418.21batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9964/40960 [00:22<01:14, 418.21batches/s, l2_loss: 0.0414 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10049/40960 [00:22<01:13, 420.06batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  25%|▏| 10049/40960 [00:22<01:13, 420.06batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  25%|▏| 10134/40960 [00:22<01:13, 420.45batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  25%|▏| 10134/40960 [00:22<01:13, 420.45batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  25%|▏| 10217/40960 [00:22<01:13, 417.63batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  25%|▏| 10217/40960 [00:22<01:13, 417.63batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  25%|▎| 10299/40960 [00:23<01:13, 415.00batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  25%|▎| 10299/40960 [00:23<01:13, 415.00batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  25%|▎| 10386/40960 [00:23<01:12, 419.66batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  25%|▎| 10386/40960 [00:23<01:12, 419.66batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  26%|▎| 10470/40960 [00:23<01:12, 418.85batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  26%|▎| 10470/40960 [00:23<01:12, 418.85batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  26%|▎| 10557/40960 [00:23<01:11, 422.54batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  26%|▎| 10557/40960 [00:23<01:11, 422.54batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  26%|▎| 10643/40960 [00:23<01:11, 424.50batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  26%|▎| 10643/40960 [00:23<01:11, 424.50batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  26%|▎| 10728/40960 [00:24<01:11, 424.34batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  26%|▎| 10728/40960 [00:24<01:11, 424.34batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  26%|▎| 10809/40960 [00:24<01:12, 417.72batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  26%|▎| 10809/40960 [00:24<01:12, 417.72batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  27%|▎| 10895/40960 [00:24<01:11, 421.01batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  27%|▎| 10895/40960 [00:24<01:11, 421.01batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  27%|▎| 10981/40960 [00:24<01:10, 423.54batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  27%|▎| 10981/40960 [00:24<01:10, 423.54batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  27%|▎| 11066/40960 [00:24<01:10, 423.56batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  27%|▎| 11066/40960 [00:24<01:10, 423.56batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  27%|▎| 11151/40960 [00:25<01:10, 423.50batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  27%|▎| 11151/40960 [00:25<01:10, 423.50batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  27%|▎| 11235/40960 [00:25<01:10, 421.94batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  27%|▎| 11235/40960 [00:25<01:10, 421.94batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11322/40960 [00:25<01:09, 424.48batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11322/40960 [00:25<01:09, 424.48batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11406/40960 [00:25<01:10, 422.16batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11406/40960 [00:25<01:10, 422.16batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11491/40960 [00:25<01:09, 422.08batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11491/40960 [00:25<01:09, 422.08batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11578/40960 [00:26<01:09, 425.01batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11578/40960 [00:26<01:09, 425.01batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11663/40960 [00:26<01:09, 424.09batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  28%|▎| 11663/40960 [00:26<01:09, 424.09batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  29%|▎| 11749/40960 [00:26<01:08, 424.96batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  29%|▎| 11749/40960 [00:26<01:08, 424.96batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  29%|▎| 11833/40960 [00:26<01:08, 422.70batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  29%|▎| 11833/40960 [00:26<01:08, 422.70batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  29%|▎| 11918/40960 [00:26<01:08, 423.21batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  29%|▎| 11918/40960 [00:26<01:08, 423.21batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  29%|▎| 12003/40960 [00:27<01:08, 422.61batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  29%|▎| 12003/40960 [00:27<01:08, 422.61batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  30%|▎| 12087/40960 [00:27<01:08, 421.76batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  30%|▎| 12087/40960 [00:27<01:08, 421.76batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  30%|▎| 12174/40960 [00:27<01:07, 425.40batches/s, l2_loss: 0.0413 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 12174/40960 [00:27<01:07, 425.40batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  30%|▎| 12259/40960 [00:27<01:07, 424.41batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  30%|▎| 12259/40960 [00:27<01:07, 424.41batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  30%|▎| 12343/40960 [00:27<01:07, 422.41batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  30%|▎| 12343/40960 [00:27<01:07, 422.41batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  30%|▎| 12428/40960 [00:28<01:07, 422.59batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  30%|▎| 12428/40960 [00:28<01:07, 422.59batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12512/40960 [00:28<01:07, 420.36batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12512/40960 [00:28<01:07, 420.36batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12596/40960 [00:28<01:07, 419.29batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12596/40960 [00:28<01:07, 419.29batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12682/40960 [00:28<01:06, 422.24batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12682/40960 [00:28<01:06, 422.24batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12769/40960 [00:29<01:06, 425.53batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12769/40960 [00:29<01:06, 425.53batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12855/40960 [00:29<01:05, 426.17batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  31%|▎| 12855/40960 [00:29<01:05, 426.17batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  32%|▎| 12940/40960 [00:29<01:05, 424.63batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  32%|▎| 12940/40960 [00:29<01:05, 424.63batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  32%|▎| 13026/40960 [00:29<01:05, 424.84batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  32%|▎| 13026/40960 [00:29<01:05, 424.84batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  32%|▎| 13112/40960 [00:29<01:05, 426.30batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  32%|▎| 13112/40960 [00:29<01:05, 426.30batches/s, l2_loss: 0.0412 - round_los\u001b[A\n",
      "Training:  32%|▎| 13198/40960 [00:30<01:05, 427.07batches/s, l2_loss: 0.0412 - round_los\u001b[A\n",
      "Training:  32%|▎| 13198/40960 [00:30<01:05, 427.07batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  32%|▎| 13283/40960 [00:30<01:04, 426.12batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  32%|▎| 13283/40960 [00:30<01:04, 426.12batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13364/40960 [00:30<01:05, 419.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13364/40960 [00:30<01:05, 419.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13447/40960 [00:30<01:05, 418.26batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13447/40960 [00:30<01:05, 418.26batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13534/40960 [00:30<01:04, 422.29batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13534/40960 [00:30<01:04, 422.29batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13620/40960 [00:31<01:04, 424.38batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13620/40960 [00:31<01:04, 424.38batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13706/40960 [00:31<01:04, 425.12batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  33%|▎| 13706/40960 [00:31<01:04, 425.12batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  34%|▎| 13791/40960 [00:31<01:04, 423.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  34%|▎| 13791/40960 [00:31<01:04, 423.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  34%|▎| 13877/40960 [00:31<01:03, 425.58batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  34%|▎| 13877/40960 [00:31<01:03, 425.58batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  34%|▎| 13959/40960 [00:31<01:04, 420.40batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  34%|▎| 13959/40960 [00:31<01:04, 420.40batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  34%|▎| 14046/40960 [00:32<01:03, 424.72batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  34%|▎| 14046/40960 [00:32<01:03, 424.72batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  35%|▎| 14134/40960 [00:32<01:02, 428.60batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  35%|▎| 14134/40960 [00:32<01:02, 428.60batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  35%|▎| 14218/40960 [00:32<01:02, 425.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  35%|▎| 14218/40960 [00:32<01:02, 425.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  35%|▎| 14304/40960 [00:32<01:02, 426.21batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  35%|▎| 14304/40960 [00:32<01:02, 426.21batches/s, l2_loss: 0.0412 - round_los\u001b[A\n",
      "Training:  35%|▎| 14391/40960 [00:32<01:02, 428.40batches/s, l2_loss: 0.0412 - round_los\u001b[A\n",
      "Training:  35%|▎| 14391/40960 [00:32<01:02, 428.40batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  35%|▎| 14477/40960 [00:33<01:01, 428.83batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  35%|▎| 14477/40960 [00:33<01:01, 428.83batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14565/40960 [00:33<01:01, 431.55batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14565/40960 [00:33<01:01, 431.55batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14653/40960 [00:33<01:00, 433.53batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14653/40960 [00:33<01:00, 433.53batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14738/40960 [00:33<01:00, 430.49batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14738/40960 [00:33<01:00, 430.49batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14823/40960 [00:33<01:01, 427.49batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14823/40960 [00:33<01:01, 427.49batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14908/40960 [00:34<01:01, 426.45batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  36%|▎| 14908/40960 [00:34<01:01, 426.45batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 14992/40960 [00:34<01:01, 423.87batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 14992/40960 [00:34<01:01, 423.87batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 15078/40960 [00:34<01:00, 425.23batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 15078/40960 [00:34<01:00, 425.23batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 15161/40960 [00:34<01:01, 421.69batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 15161/40960 [00:34<01:01, 421.69batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 15247/40960 [00:34<01:00, 423.63batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 15247/40960 [00:34<01:00, 423.63batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 15327/40960 [00:35<01:01, 415.75batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  37%|▎| 15327/40960 [00:35<01:01, 415.75batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15414/40960 [00:35<01:00, 421.08batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15414/40960 [00:35<01:00, 421.08batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15500/40960 [00:35<01:00, 423.71batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15500/40960 [00:35<01:00, 423.71batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15582/40960 [00:35<01:00, 419.55batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15582/40960 [00:35<01:00, 419.55batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15667/40960 [00:35<01:00, 420.32batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15667/40960 [00:35<01:00, 420.32batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15753/40960 [00:36<00:59, 422.60batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  38%|▍| 15753/40960 [00:36<00:59, 422.60batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 15837/40960 [00:36<00:59, 421.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 15837/40960 [00:36<00:59, 421.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 15924/40960 [00:36<00:58, 425.47batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 15924/40960 [00:36<00:58, 425.47batches/s, l2_loss: 0.0413 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|▍| 16009/40960 [00:36<00:58, 425.03batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 16009/40960 [00:36<00:58, 425.03batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 16093/40960 [00:36<00:58, 423.07batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 16093/40960 [00:36<00:58, 423.07batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 16179/40960 [00:37<00:58, 424.21batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  39%|▍| 16179/40960 [00:37<00:58, 424.21batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  40%|▍| 16264/40960 [00:37<00:58, 423.32batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  40%|▍| 16264/40960 [00:37<00:58, 423.32batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  40%|▍| 16350/40960 [00:37<00:58, 423.90batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  40%|▍| 16350/40960 [00:37<00:58, 423.90batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  40%|▍| 16434/40960 [00:37<00:58, 422.70batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  40%|▍| 16434/40960 [00:37<00:58, 422.70batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  40%|▍| 16518/40960 [00:37<00:58, 421.01batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  40%|▍| 16518/40960 [00:37<00:58, 421.01batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16598/40960 [00:38<00:58, 414.18batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16598/40960 [00:38<00:58, 414.18batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16681/40960 [00:38<00:58, 413.22batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16681/40960 [00:38<00:58, 413.22batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16768/40960 [00:38<00:57, 419.28batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16768/40960 [00:38<00:57, 419.28batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16854/40960 [00:38<00:57, 421.88batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16854/40960 [00:38<00:57, 421.88batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16939/40960 [00:38<00:56, 421.55batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  41%|▍| 16939/40960 [00:38<00:56, 421.55batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17021/40960 [00:39<00:57, 416.98batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17021/40960 [00:39<00:57, 416.98batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17105/40960 [00:39<00:57, 417.84batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17105/40960 [00:39<00:57, 417.84batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17190/40960 [00:39<00:56, 419.45batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17190/40960 [00:39<00:56, 419.45batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17272/40960 [00:39<00:56, 416.56batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17272/40960 [00:39<00:56, 416.56batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17358/40960 [00:39<00:56, 420.05batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  42%|▍| 17358/40960 [00:39<00:56, 420.05batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17441/40960 [00:40<00:56, 418.41batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17441/40960 [00:40<00:56, 418.41batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17527/40960 [00:40<00:55, 421.54batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17527/40960 [00:40<00:55, 421.54batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17613/40960 [00:40<00:55, 423.96batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17613/40960 [00:40<00:55, 423.96batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17701/40960 [00:40<00:54, 427.43batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17701/40960 [00:40<00:54, 427.43batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17787/40960 [00:40<00:54, 426.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  43%|▍| 17787/40960 [00:40<00:54, 426.78batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  44%|▍| 17866/40960 [00:41<00:55, 416.75batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  44%|▍| 17866/40960 [00:41<00:55, 416.75batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  44%|▍| 17948/40960 [00:41<00:55, 414.67batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  44%|▍| 17948/40960 [00:41<00:55, 414.67batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  44%|▍| 18034/40960 [00:41<00:54, 418.00batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  44%|▍| 18034/40960 [00:41<00:54, 418.00batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  44%|▍| 18123/40960 [00:41<00:53, 424.72batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  44%|▍| 18123/40960 [00:41<00:53, 424.72batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  44%|▍| 18209/40960 [00:41<00:53, 426.07batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  44%|▍| 18209/40960 [00:41<00:53, 426.07batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18297/40960 [00:42<00:52, 429.34batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18297/40960 [00:42<00:52, 429.34batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18381/40960 [00:42<00:53, 425.54batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18381/40960 [00:42<00:53, 425.54batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18466/40960 [00:42<00:52, 424.78batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18466/40960 [00:42<00:52, 424.78batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18549/40960 [00:42<00:53, 421.67batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18549/40960 [00:42<00:53, 421.67batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18633/40960 [00:42<00:53, 419.34batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  45%|▍| 18633/40960 [00:42<00:53, 419.34batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  46%|▍| 18717/40960 [00:43<00:53, 419.42batches/s, l2_loss: 0.0413 - round_los\u001b[A\n",
      "Training:  46%|▍| 18717/40960 [00:43<00:53, 419.42batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  46%|▍| 18804/40960 [00:43<00:52, 422.79batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  46%|▍| 18804/40960 [00:43<00:52, 422.79batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  46%|▍| 18886/40960 [00:43<00:52, 418.40batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  46%|▍| 18886/40960 [00:43<00:52, 418.40batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  46%|▍| 18973/40960 [00:43<00:51, 423.20batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  46%|▍| 18973/40960 [00:43<00:51, 423.20batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19061/40960 [00:43<00:51, 426.84batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19061/40960 [00:43<00:51, 426.84batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19148/40960 [00:44<00:50, 428.59batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19148/40960 [00:44<00:50, 428.59batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19234/40960 [00:44<00:50, 428.77batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19234/40960 [00:44<00:50, 428.77batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19320/40960 [00:44<00:50, 429.00batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19320/40960 [00:44<00:50, 429.00batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19405/40960 [00:44<00:50, 426.64batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  47%|▍| 19405/40960 [00:44<00:50, 426.64batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19492/40960 [00:44<00:50, 428.12batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19492/40960 [00:44<00:50, 428.12batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19574/40960 [00:45<00:50, 422.21batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19574/40960 [00:45<00:50, 422.21batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19660/40960 [00:45<00:50, 423.13batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19660/40960 [00:45<00:50, 423.13batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19744/40960 [00:45<00:50, 421.84batches/s, l2_loss: 0.0414 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|▍| 19744/40960 [00:45<00:50, 421.84batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19830/40960 [00:45<00:49, 422.96batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  48%|▍| 19830/40960 [00:45<00:49, 422.96batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 19918/40960 [00:45<00:49, 427.86batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 19918/40960 [00:45<00:49, 427.86batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 20002/40960 [00:46<00:49, 424.97batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 20002/40960 [00:46<00:49, 424.97batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 20084/40960 [00:46<00:49, 419.37batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 20084/40960 [00:46<00:49, 419.37batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 20168/40960 [00:46<00:49, 419.51batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 20168/40960 [00:46<00:49, 419.51batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 20245/40960 [00:46<00:50, 408.71batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  49%|▍| 20245/40960 [00:46<00:50, 408.71batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▍| 20332/40960 [00:46<00:49, 415.43batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▍| 20332/40960 [00:46<00:49, 415.43batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▍| 20416/40960 [00:47<00:49, 416.29batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▍| 20416/40960 [00:47<00:49, 416.29batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▌| 20499/40960 [00:47<00:49, 414.98batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▌| 20499/40960 [00:47<00:49, 414.98batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▌| 20582/40960 [00:47<00:49, 414.35batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▌| 20582/40960 [00:47<00:49, 414.35batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▌| 20667/40960 [00:47<00:48, 416.41batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  50%|▌| 20667/40960 [00:47<00:48, 416.41batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  51%|▌| 20751/40960 [00:47<00:48, 417.23batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  51%|▌| 20751/40960 [00:47<00:48, 417.23batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  51%|▌| 20836/40960 [00:48<00:47, 419.27batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  51%|▌| 20836/40960 [00:48<00:47, 419.27batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  51%|▌| 20924/40960 [00:48<00:47, 424.22batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  51%|▌| 20924/40960 [00:48<00:47, 424.22batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  51%|▌| 21004/40960 [00:48<00:47, 416.98batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  51%|▌| 21004/40960 [00:48<00:47, 416.98batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  51%|▌| 21089/40960 [00:48<00:47, 418.35batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  51%|▌| 21089/40960 [00:48<00:47, 418.35batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  52%|▌| 21175/40960 [00:48<00:47, 420.63batches/s, l2_loss: 0.0414 - round_los\u001b[A\n",
      "Training:  52%|▌| 21175/40960 [00:48<00:47, 420.63batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  52%|▌| 21260/40960 [00:49<00:46, 420.57batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  52%|▌| 21260/40960 [00:49<00:46, 420.57batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  52%|▌| 21342/40960 [00:49<00:47, 416.74batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  52%|▌| 21342/40960 [00:49<00:47, 416.74batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  52%|▌| 21428/40960 [00:49<00:46, 420.36batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  52%|▌| 21428/40960 [00:49<00:46, 420.36batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21506/40960 [00:49<00:47, 410.93batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21506/40960 [00:49<00:47, 410.93batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21586/40960 [00:49<00:47, 406.31batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21586/40960 [00:49<00:47, 406.31batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21672/40960 [00:50<00:46, 412.78batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21672/40960 [00:50<00:46, 412.78batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21756/40960 [00:50<00:46, 413.85batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21756/40960 [00:50<00:46, 413.85batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21841/40960 [00:50<00:45, 416.52batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  53%|▌| 21841/40960 [00:50<00:45, 416.52batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 21926/40960 [00:50<00:45, 417.73batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 21926/40960 [00:50<00:45, 417.73batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 22011/40960 [00:50<00:45, 419.33batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 22011/40960 [00:50<00:45, 419.33batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 22097/40960 [00:51<00:44, 421.79batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 22097/40960 [00:51<00:44, 421.79batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 22184/40960 [00:51<00:44, 424.46batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 22184/40960 [00:51<00:44, 424.46batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 22266/40960 [00:51<00:44, 418.82batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  54%|▌| 22266/40960 [00:51<00:44, 418.82batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22350/40960 [00:51<00:44, 418.03batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22350/40960 [00:51<00:44, 418.03batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22437/40960 [00:51<00:43, 422.92batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22437/40960 [00:51<00:43, 422.92batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22523/40960 [00:52<00:43, 424.33batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22523/40960 [00:52<00:43, 424.33batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22608/40960 [00:52<00:43, 424.27batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22608/40960 [00:52<00:43, 424.27batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22693/40960 [00:52<00:43, 424.24batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  55%|▌| 22693/40960 [00:52<00:43, 424.24batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  56%|▌| 22777/40960 [00:52<00:43, 422.04batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  56%|▌| 22777/40960 [00:52<00:43, 422.04batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  56%|▌| 22862/40960 [00:52<00:42, 422.51batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  56%|▌| 22862/40960 [00:52<00:42, 422.51batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  56%|▌| 22947/40960 [00:53<00:42, 422.85batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  56%|▌| 22947/40960 [00:53<00:42, 422.85batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  56%|▌| 23033/40960 [00:53<00:42, 423.61batches/s, l2_loss: 0.0415 - round_los\u001b[A\n",
      "Training:  56%|▌| 23033/40960 [00:53<00:42, 423.61batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  56%|▌| 23121/40960 [00:53<00:41, 427.59batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  56%|▌| 23121/40960 [00:53<00:41, 427.59batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23203/40960 [00:53<00:42, 421.38batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23203/40960 [00:53<00:42, 421.38batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23287/40960 [00:53<00:42, 420.48batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23287/40960 [00:53<00:42, 420.48batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23375/40960 [00:54<00:41, 424.89batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23375/40960 [00:54<00:41, 424.89batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23458/40960 [00:54<00:41, 421.30batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23458/40960 [00:54<00:41, 421.30batches/s, l2_loss: 0.0416 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|▌| 23545/40960 [00:54<00:40, 424.83batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  57%|▌| 23545/40960 [00:54<00:40, 424.83batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  58%|▌| 23630/40960 [00:54<00:40, 424.46batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  58%|▌| 23630/40960 [00:54<00:40, 424.46batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  58%|▌| 23716/40960 [00:54<00:40, 425.20batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  58%|▌| 23716/40960 [00:54<00:40, 425.20batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  58%|▌| 23802/40960 [00:55<00:40, 425.72batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  58%|▌| 23802/40960 [00:55<00:40, 425.72batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  58%|▌| 23888/40960 [00:55<00:39, 427.00batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  58%|▌| 23888/40960 [00:55<00:39, 427.00batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 23973/40960 [00:55<00:39, 425.24batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 23973/40960 [00:55<00:39, 425.24batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 24058/40960 [00:55<00:39, 424.70batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 24058/40960 [00:55<00:39, 424.70batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 24144/40960 [00:55<00:39, 424.97batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 24144/40960 [00:55<00:39, 424.97batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 24228/40960 [00:56<00:39, 423.45batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 24228/40960 [00:56<00:39, 423.45batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 24316/40960 [00:56<00:38, 427.93batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  59%|▌| 24316/40960 [00:56<00:38, 427.93batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24402/40960 [00:56<00:38, 427.28batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24402/40960 [00:56<00:38, 427.28batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24488/40960 [00:56<00:38, 427.27batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24488/40960 [00:56<00:38, 427.27batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24570/40960 [00:56<00:38, 421.37batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24570/40960 [00:56<00:38, 421.37batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24654/40960 [00:57<00:38, 419.75batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24654/40960 [00:57<00:38, 419.75batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24737/40960 [00:57<00:38, 417.96batches/s, l2_loss: 0.0416 - round_los\u001b[A\n",
      "Training:  60%|▌| 24737/40960 [00:57<00:38, 417.96batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 24821/40960 [00:57<00:38, 418.41batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 24821/40960 [00:57<00:38, 418.41batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 24907/40960 [00:57<00:38, 420.35batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 24907/40960 [00:57<00:38, 420.35batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 24991/40960 [00:57<00:38, 419.18batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 24991/40960 [00:57<00:38, 419.18batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 25076/40960 [00:58<00:37, 420.41batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 25076/40960 [00:58<00:37, 420.41batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 25161/40960 [00:58<00:37, 421.59batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  61%|▌| 25161/40960 [00:58<00:37, 421.59batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25242/40960 [00:58<00:37, 416.49batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25242/40960 [00:58<00:37, 416.49batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25326/40960 [00:58<00:37, 417.03batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25326/40960 [00:58<00:37, 417.03batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25412/40960 [00:58<00:37, 419.84batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25412/40960 [00:58<00:37, 419.84batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25500/40960 [00:59<00:36, 425.25batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25500/40960 [00:59<00:36, 425.25batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25584/40960 [00:59<00:36, 422.61batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  62%|▌| 25584/40960 [00:59<00:36, 422.61batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  63%|▋| 25671/40960 [00:59<00:35, 426.22batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  63%|▋| 25671/40960 [00:59<00:35, 426.22batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  63%|▋| 25755/40960 [00:59<00:35, 423.81batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  63%|▋| 25755/40960 [00:59<00:35, 423.81batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  63%|▋| 25841/40960 [00:59<00:35, 424.45batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  63%|▋| 25841/40960 [00:59<00:35, 424.45batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  63%|▋| 25927/40960 [01:00<00:35, 425.23batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  63%|▋| 25927/40960 [01:00<00:35, 425.23batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  64%|▋| 26015/40960 [01:00<00:34, 429.09batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  64%|▋| 26015/40960 [01:00<00:34, 429.09batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  64%|▋| 26103/40960 [01:00<00:34, 431.32batches/s, l2_loss: 0.0417 - round_los\u001b[A\n",
      "Training:  64%|▋| 26103/40960 [01:00<00:34, 431.32batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  64%|▋| 26191/40960 [01:00<00:34, 433.80batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  64%|▋| 26191/40960 [01:00<00:34, 433.80batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  64%|▋| 26276/40960 [01:00<00:34, 430.90batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  64%|▋| 26276/40960 [01:00<00:34, 430.90batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  64%|▋| 26360/40960 [01:01<00:34, 427.10batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  64%|▋| 26360/40960 [01:01<00:34, 427.10batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26444/40960 [01:01<00:34, 424.88batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26444/40960 [01:01<00:34, 424.88batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26529/40960 [01:01<00:33, 424.52batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26529/40960 [01:01<00:33, 424.52batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26615/40960 [01:01<00:33, 425.16batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26615/40960 [01:01<00:33, 425.16batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26702/40960 [01:01<00:33, 426.83batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26702/40960 [01:01<00:33, 426.83batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26787/40960 [01:02<00:33, 424.95batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  65%|▋| 26787/40960 [01:02<00:33, 424.95batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 26871/40960 [01:02<00:33, 423.47batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 26871/40960 [01:02<00:33, 423.47batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 26957/40960 [01:02<00:32, 425.13batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 26957/40960 [01:02<00:32, 425.13batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 27041/40960 [01:02<00:32, 422.79batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 27041/40960 [01:02<00:32, 422.79batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 27125/40960 [01:02<00:32, 420.73batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 27125/40960 [01:02<00:32, 420.73batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 27207/40960 [01:03<00:33, 416.59batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  66%|▋| 27207/40960 [01:03<00:33, 416.59batches/s, l2_loss: 0.0418 - round_los\u001b[A\n",
      "Training:  67%|▋| 27294/40960 [01:03<00:32, 421.27batches/s, l2_loss: 0.0418 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|▋| 27294/40960 [01:03<00:32, 421.27batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  67%|▋| 27378/40960 [01:03<00:32, 419.77batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  67%|▋| 27378/40960 [01:03<00:32, 419.77batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  67%|▋| 27459/40960 [01:03<00:32, 414.68batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  67%|▋| 27459/40960 [01:03<00:32, 414.68batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  67%|▋| 27544/40960 [01:03<00:32, 416.75batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  67%|▋| 27544/40960 [01:03<00:32, 416.75batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  67%|▋| 27630/40960 [01:04<00:31, 419.84batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  67%|▋| 27630/40960 [01:04<00:31, 419.84batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 27716/40960 [01:04<00:31, 421.93batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 27716/40960 [01:04<00:31, 421.93batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 27800/40960 [01:04<00:31, 420.72batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 27800/40960 [01:04<00:31, 420.72batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 27884/40960 [01:04<00:31, 419.37batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 27884/40960 [01:04<00:31, 419.37batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 27971/40960 [01:04<00:30, 422.72batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 27971/40960 [01:05<00:30, 422.72batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 28052/40960 [01:05<00:31, 416.04batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  68%|▋| 28052/40960 [01:05<00:31, 416.04batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  69%|▋| 28119/40960 [01:05<00:32, 391.03batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  69%|▋| 28119/40960 [01:05<00:32, 391.03batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  69%|▋| 28205/40960 [01:05<00:31, 401.85batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  69%|▋| 28205/40960 [01:05<00:31, 401.85batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  69%|▋| 28290/40960 [01:05<00:31, 407.71batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  69%|▋| 28290/40960 [01:05<00:31, 407.71batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  69%|▋| 28377/40960 [01:06<00:30, 415.19batches/s, l2_loss: 0.0419 - round_los\u001b[A\n",
      "Training:  69%|▋| 28377/40960 [01:06<00:30, 415.19batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  69%|▋| 28460/40960 [01:06<00:30, 414.83batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  69%|▋| 28460/40960 [01:06<00:30, 414.83batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  70%|▋| 28549/40960 [01:06<00:29, 423.19batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  70%|▋| 28549/40960 [01:06<00:29, 423.19batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  70%|▋| 28636/40960 [01:06<00:28, 426.51batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  70%|▋| 28636/40960 [01:06<00:28, 426.51batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  70%|▋| 28718/40960 [01:06<00:29, 421.25batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  70%|▋| 28718/40960 [01:06<00:29, 421.25batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  70%|▋| 28804/40960 [01:07<00:28, 422.99batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  70%|▋| 28804/40960 [01:07<00:28, 422.99batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 28891/40960 [01:07<00:28, 425.80batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 28891/40960 [01:07<00:28, 425.80batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 28979/40960 [01:07<00:27, 429.04batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 28979/40960 [01:07<00:27, 429.04batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 29065/40960 [01:07<00:27, 429.25batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 29065/40960 [01:07<00:27, 429.25batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 29151/40960 [01:07<00:27, 429.19batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 29151/40960 [01:07<00:27, 429.19batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 29235/40960 [01:08<00:27, 425.75batches/s, l2_loss: 0.0420 - round_los\u001b[A\n",
      "Training:  71%|▋| 29235/40960 [01:08<00:27, 425.75batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29317/40960 [01:08<00:27, 419.66batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29317/40960 [01:08<00:27, 419.66batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29400/40960 [01:08<00:27, 417.44batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29400/40960 [01:08<00:27, 417.44batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29480/40960 [01:08<00:27, 412.23batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29480/40960 [01:08<00:27, 412.23batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29565/40960 [01:08<00:27, 415.68batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29565/40960 [01:08<00:27, 415.68batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29649/40960 [01:09<00:27, 415.62batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  72%|▋| 29649/40960 [01:09<00:27, 415.62batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 29736/40960 [01:09<00:26, 420.17batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 29736/40960 [01:09<00:26, 420.17batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 29822/40960 [01:09<00:26, 421.91batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 29822/40960 [01:09<00:26, 421.91batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 29906/40960 [01:09<00:26, 420.67batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 29906/40960 [01:09<00:26, 420.67batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 29992/40960 [01:09<00:25, 423.01batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 29992/40960 [01:09<00:25, 423.01batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 30078/40960 [01:10<00:25, 424.45batches/s, l2_loss: 0.0421 - round_los\u001b[A\n",
      "Training:  73%|▋| 30078/40960 [01:10<00:25, 424.45batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30163/40960 [01:10<00:25, 423.27batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30163/40960 [01:10<00:25, 423.27batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30249/40960 [01:10<00:25, 424.63batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30249/40960 [01:10<00:25, 424.63batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30331/40960 [01:10<00:25, 418.96batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30331/40960 [01:10<00:25, 418.96batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30416/40960 [01:10<00:25, 419.67batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30416/40960 [01:10<00:25, 419.67batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30498/40960 [01:11<00:25, 416.03batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  74%|▋| 30498/40960 [01:11<00:25, 416.03batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  75%|▋| 30578/40960 [01:11<00:25, 411.22batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  75%|▋| 30578/40960 [01:11<00:25, 411.22batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  75%|▋| 30661/40960 [01:11<00:25, 410.88batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  75%|▋| 30661/40960 [01:11<00:25, 410.88batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  75%|▊| 30747/40960 [01:11<00:24, 416.34batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  75%|▊| 30747/40960 [01:11<00:24, 416.34batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  75%|▊| 30831/40960 [01:11<00:24, 416.90batches/s, l2_loss: 0.0422 - round_los\u001b[A\n",
      "Training:  75%|▊| 30831/40960 [01:11<00:24, 416.90batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▊| 30916/40960 [01:12<00:24, 418.42batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  75%|▊| 30916/40960 [01:12<00:24, 418.42batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31000/40960 [01:12<00:23, 418.25batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31000/40960 [01:12<00:23, 418.25batches/s, l2_loss: 0.0423 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31086/40960 [01:12<00:23, 420.88batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31086/40960 [01:12<00:23, 420.88batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31170/40960 [01:12<00:23, 419.10batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31170/40960 [01:12<00:23, 419.10batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31251/40960 [01:12<00:23, 414.69batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  76%|▊| 31251/40960 [01:12<00:23, 414.69batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31335/40960 [01:13<00:23, 415.04batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31335/40960 [01:13<00:23, 415.04batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31421/40960 [01:13<00:22, 417.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31421/40960 [01:13<00:22, 417.61batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31506/40960 [01:13<00:22, 418.46batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31506/40960 [01:13<00:22, 418.46batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31590/40960 [01:13<00:22, 418.10batches/s, l2_loss: 0.0423 - round_los\u001b[A\n",
      "Training:  77%|▊| 31590/40960 [01:13<00:22, 418.10batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  77%|▊| 31675/40960 [01:13<00:22, 418.62batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  77%|▊| 31675/40960 [01:13<00:22, 418.62batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 31759/40960 [01:14<00:22, 417.99batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 31759/40960 [01:14<00:22, 417.99batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 31843/40960 [01:14<00:21, 418.41batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 31843/40960 [01:14<00:21, 418.41batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 31929/40960 [01:14<00:21, 421.78batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 31929/40960 [01:14<00:21, 421.78batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 32015/40960 [01:14<00:21, 423.03batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 32015/40960 [01:14<00:21, 423.03batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 32102/40960 [01:14<00:20, 425.66batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  78%|▊| 32102/40960 [01:14<00:20, 425.66batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  79%|▊| 32188/40960 [01:15<00:20, 426.69batches/s, l2_loss: 0.0424 - round_los\u001b[A\n",
      "Training:  79%|▊| 32188/40960 [01:15<00:20, 426.69batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  79%|▊| 32273/40960 [01:15<00:20, 425.27batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  79%|▊| 32273/40960 [01:15<00:20, 425.27batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  79%|▊| 32355/40960 [01:15<00:20, 419.99batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  79%|▊| 32355/40960 [01:15<00:20, 419.99batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  79%|▊| 32440/40960 [01:15<00:20, 420.54batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  79%|▊| 32440/40960 [01:15<00:20, 420.54batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  79%|▊| 32527/40960 [01:15<00:19, 423.53batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  79%|▊| 32527/40960 [01:15<00:19, 423.53batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32613/40960 [01:16<00:19, 424.57batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32613/40960 [01:16<00:19, 424.57batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32698/40960 [01:16<00:19, 424.50batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32698/40960 [01:16<00:19, 424.50batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32782/40960 [01:16<00:19, 422.07batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32782/40960 [01:16<00:19, 422.07batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32868/40960 [01:16<00:19, 423.62batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32868/40960 [01:16<00:19, 423.62batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32954/40960 [01:16<00:18, 424.95batches/s, l2_loss: 0.0425 - round_los\u001b[A\n",
      "Training:  80%|▊| 32954/40960 [01:16<00:18, 424.95batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33036/40960 [01:17<00:18, 419.37batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33036/40960 [01:17<00:18, 419.37batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33123/40960 [01:17<00:18, 423.71batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33123/40960 [01:17<00:18, 423.71batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33208/40960 [01:17<00:18, 423.15batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33208/40960 [01:17<00:18, 423.15batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33292/40960 [01:17<00:18, 421.50batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33292/40960 [01:17<00:18, 421.50batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33378/40960 [01:17<00:17, 423.86batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  81%|▊| 33378/40960 [01:17<00:17, 423.86batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  82%|▊| 33459/40960 [01:18<00:18, 416.69batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  82%|▊| 33459/40960 [01:18<00:18, 416.69batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  82%|▊| 33544/40960 [01:18<00:17, 418.97batches/s, l2_loss: 0.0426 - round_los\u001b[A\n",
      "Training:  82%|▊| 33544/40960 [01:18<00:17, 418.97batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  82%|▊| 33629/40960 [01:18<00:17, 419.99batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  82%|▊| 33629/40960 [01:18<00:17, 419.99batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  82%|▊| 33716/40960 [01:18<00:17, 423.80batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  82%|▊| 33716/40960 [01:18<00:17, 423.80batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  83%|▊| 33801/40960 [01:18<00:16, 423.01batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  83%|▊| 33801/40960 [01:18<00:16, 423.01batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  83%|▊| 33886/40960 [01:19<00:16, 422.92batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  83%|▊| 33886/40960 [01:19<00:16, 422.92batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  83%|▊| 33972/40960 [01:19<00:16, 424.42batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  83%|▊| 33972/40960 [01:19<00:16, 424.42batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  83%|▊| 34059/40960 [01:19<00:16, 426.57batches/s, l2_loss: 0.0427 - round_los\u001b[A\n",
      "Training:  83%|▊| 34059/40960 [01:19<00:16, 426.57batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  83%|▊| 34142/40960 [01:19<00:16, 423.11batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  83%|▊| 34142/40960 [01:19<00:16, 423.11batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34228/40960 [01:19<00:15, 424.96batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34228/40960 [01:19<00:15, 424.96batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34310/40960 [01:20<00:15, 419.88batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34310/40960 [01:20<00:15, 419.88batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34393/40960 [01:20<00:15, 417.60batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34393/40960 [01:20<00:15, 417.60batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34475/40960 [01:20<00:15, 414.68batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34475/40960 [01:20<00:15, 414.68batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34561/40960 [01:20<00:15, 418.75batches/s, l2_loss: 0.0428 - round_los\u001b[A\n",
      "Training:  84%|▊| 34561/40960 [01:20<00:15, 418.75batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34646/40960 [01:20<00:15, 420.38batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34646/40960 [01:20<00:15, 420.38batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34732/40960 [01:21<00:14, 422.60batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34732/40960 [01:21<00:14, 422.60batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34816/40960 [01:21<00:14, 420.62batches/s, l2_loss: 0.0429 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34816/40960 [01:21<00:14, 420.62batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34901/40960 [01:21<00:14, 421.93batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34901/40960 [01:21<00:14, 421.93batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34988/40960 [01:21<00:14, 424.51batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  85%|▊| 34988/40960 [01:21<00:14, 424.51batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  86%|▊| 35071/40960 [01:21<00:13, 421.27batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  86%|▊| 35071/40960 [01:21<00:13, 421.27batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  86%|▊| 35157/40960 [01:22<00:13, 423.58batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  86%|▊| 35157/40960 [01:22<00:13, 423.58batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  86%|▊| 35241/40960 [01:22<00:13, 421.04batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  86%|▊| 35241/40960 [01:22<00:13, 421.04batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  86%|▊| 35325/40960 [01:22<00:13, 419.79batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  86%|▊| 35325/40960 [01:22<00:13, 419.79batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  86%|▊| 35409/40960 [01:22<00:13, 418.97batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  86%|▊| 35409/40960 [01:22<00:13, 418.97batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  87%|▊| 35496/40960 [01:22<00:12, 422.90batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  87%|▊| 35496/40960 [01:22<00:12, 422.90batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [01:23<00:12, 423.36batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [01:23<00:12, 423.36batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  87%|▊| 35667/40960 [01:23<00:12, 424.41batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  87%|▊| 35667/40960 [01:23<00:12, 424.41batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  87%|▊| 35753/40960 [01:23<00:12, 424.84batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  87%|▊| 35753/40960 [01:23<00:12, 424.84batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  87%|▊| 35838/40960 [01:23<00:12, 423.38batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  87%|▊| 35838/40960 [01:23<00:12, 423.38batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  88%|▉| 35916/40960 [01:23<00:12, 412.83batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  88%|▉| 35916/40960 [01:23<00:12, 412.83batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  88%|▉| 35999/40960 [01:24<00:12, 413.23batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  88%|▉| 35999/40960 [01:24<00:12, 413.23batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  88%|▉| 36082/40960 [01:24<00:11, 413.19batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  88%|▉| 36082/40960 [01:24<00:11, 413.19batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  88%|▉| 36168/40960 [01:24<00:11, 418.19batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  88%|▉| 36168/40960 [01:24<00:11, 418.19batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  89%|▉| 36254/40960 [01:24<00:11, 420.89batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  89%|▉| 36254/40960 [01:24<00:11, 420.89batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  89%|▉| 36340/40960 [01:24<00:10, 423.29batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  89%|▉| 36340/40960 [01:24<00:10, 423.29batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  89%|▉| 36425/40960 [01:25<00:10, 422.63batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  89%|▉| 36425/40960 [01:25<00:10, 422.63batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  89%|▉| 36510/40960 [01:25<00:10, 421.67batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  89%|▉| 36510/40960 [01:25<00:10, 421.67batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  89%|▉| 36590/40960 [01:25<00:10, 414.99batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  89%|▉| 36590/40960 [01:25<00:10, 414.99batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  90%|▉| 36678/40960 [01:25<00:10, 421.20batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  90%|▉| 36678/40960 [01:25<00:10, 421.20batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  90%|▉| 36763/40960 [01:25<00:09, 421.78batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  90%|▉| 36763/40960 [01:25<00:09, 421.78batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  90%|▉| 36851/40960 [01:26<00:09, 426.50batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  90%|▉| 36851/40960 [01:26<00:09, 426.50batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  90%|▉| 36935/40960 [01:26<00:09, 423.82batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  90%|▉| 36935/40960 [01:26<00:09, 423.82batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  90%|▉| 37022/40960 [01:26<00:09, 426.49batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  90%|▉| 37022/40960 [01:26<00:09, 426.49batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37105/40960 [01:26<00:09, 422.55batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37105/40960 [01:26<00:09, 422.55batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37191/40960 [01:26<00:08, 424.21batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37191/40960 [01:26<00:08, 424.21batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37276/40960 [01:27<00:08, 423.13batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37276/40960 [01:27<00:08, 423.13batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37357/40960 [01:27<00:08, 417.32batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  91%|▉| 37357/40960 [01:27<00:08, 417.32batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  91%|▉| 37443/40960 [01:27<00:08, 420.60batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  91%|▉| 37443/40960 [01:27<00:08, 420.60batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  92%|▉| 37530/40960 [01:27<00:08, 423.99batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  92%|▉| 37530/40960 [01:27<00:08, 423.99batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  92%|▉| 37614/40960 [01:27<00:07, 422.25batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  92%|▉| 37614/40960 [01:27<00:07, 422.25batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  92%|▉| 37698/40960 [01:28<00:07, 420.77batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  92%|▉| 37698/40960 [01:28<00:07, 420.77batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  92%|▉| 37785/40960 [01:28<00:07, 424.16batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  92%|▉| 37785/40960 [01:28<00:07, 424.16batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  92%|▉| 37871/40960 [01:28<00:07, 424.24batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  92%|▉| 37871/40960 [01:28<00:07, 424.24batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  93%|▉| 37953/40960 [01:28<00:07, 419.11batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  93%|▉| 37953/40960 [01:28<00:07, 419.11batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  93%|▉| 38041/40960 [01:28<00:06, 424.66batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  93%|▉| 38041/40960 [01:28<00:06, 424.66batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  93%|▉| 38128/40960 [01:29<00:06, 427.50batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  93%|▉| 38128/40960 [01:29<00:06, 427.50batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  93%|▉| 38215/40960 [01:29<00:06, 429.05batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  93%|▉| 38215/40960 [01:29<00:06, 429.05batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  94%|▉| 38298/40960 [01:29<00:06, 423.46batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  94%|▉| 38298/40960 [01:29<00:06, 423.46batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  94%|▉| 38381/40960 [01:29<00:06, 419.84batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  94%|▉| 38381/40960 [01:29<00:06, 419.84batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  94%|▉| 38467/40960 [01:29<00:05, 422.72batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  94%|▉| 38467/40960 [01:29<00:05, 422.72batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  94%|▉| 38552/40960 [01:30<00:05, 422.73batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  94%|▉| 38552/40960 [01:30<00:05, 422.73batches/s, l2_loss: 0.0438 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|▉| 38638/40960 [01:30<00:05, 424.49batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  94%|▉| 38638/40960 [01:30<00:05, 424.49batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  95%|▉| 38724/40960 [01:30<00:05, 424.78batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  95%|▉| 38724/40960 [01:30<00:05, 424.78batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  95%|▉| 38811/40960 [01:30<00:05, 427.53batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  95%|▉| 38811/40960 [01:30<00:05, 427.53batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  95%|▉| 38893/40960 [01:30<00:04, 421.93batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  95%|▉| 38893/40960 [01:30<00:04, 421.93batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  95%|▉| 38980/40960 [01:31<00:04, 425.02batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  95%|▉| 38980/40960 [01:31<00:04, 425.02batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  95%|▉| 39066/40960 [01:31<00:04, 425.39batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  95%|▉| 39066/40960 [01:31<00:04, 425.39batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  96%|▉| 39153/40960 [01:31<00:04, 427.49batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  96%|▉| 39153/40960 [01:31<00:04, 427.49batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  96%|▉| 39239/40960 [01:31<00:04, 427.19batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  96%|▉| 39239/40960 [01:31<00:04, 427.19batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  96%|▉| 39326/40960 [01:31<00:03, 428.49batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  96%|▉| 39326/40960 [01:31<00:03, 428.49batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  96%|▉| 39412/40960 [01:32<00:03, 428.85batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  96%|▉| 39412/40960 [01:32<00:03, 428.85batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39500/40960 [01:32<00:03, 431.14batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39500/40960 [01:32<00:03, 431.14batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  97%|▉| 39586/40960 [01:32<00:03, 430.12batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  97%|▉| 39586/40960 [01:32<00:03, 430.12batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  97%|▉| 39671/40960 [01:32<00:03, 428.35batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  97%|▉| 39671/40960 [01:32<00:03, 428.35batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  97%|▉| 39757/40960 [01:32<00:02, 428.67batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  97%|▉| 39757/40960 [01:32<00:02, 428.67batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39840/40960 [01:33<00:02, 423.96batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39840/40960 [01:33<00:02, 423.96batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39928/40960 [01:33<00:02, 427.95batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39928/40960 [01:33<00:02, 427.95batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40014/40960 [01:33<00:02, 427.98batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40014/40960 [01:33<00:02, 427.98batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40099/40960 [01:33<00:02, 426.61batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40099/40960 [01:33<00:02, 426.61batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40181/40960 [01:33<00:01, 420.60batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40181/40960 [01:33<00:01, 420.60batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40265/40960 [01:34<00:01, 418.96batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40265/40960 [01:34<00:01, 418.96batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40351/40960 [01:34<00:01, 421.39batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40351/40960 [01:34<00:01, 421.39batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40436/40960 [01:34<00:01, 422.21batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40436/40960 [01:34<00:01, 422.21batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40524/40960 [01:34<00:01, 426.68batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40524/40960 [01:34<00:01, 426.68batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40610/40960 [01:34<00:00, 427.04batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40610/40960 [01:34<00:00, 427.04batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40694/40960 [01:35<00:00, 424.64batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40694/40960 [01:35<00:00, 424.64batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training: 100%|▉| 40780/40960 [01:35<00:00, 426.13batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training: 100%|▉| 40780/40960 [01:35<00:00, 426.13batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training: 100%|▉| 40866/40960 [01:35<00:00, 427.07batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training: 100%|▉| 40866/40960 [01:35<00:00, 427.07batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training: 100%|▉| 40949/40960 [01:35<00:00, 422.88batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training: 100%|▉| 40949/40960 [01:35<00:00, 422.88batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:20:33.717242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  62%|▌| 16/26 [32:53<19:43, 118.36s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:20:34.991173: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:20:41.512149: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<24:32:05,  2.16s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<24:32:05,  2.16s/batches, l2_loss: 0.0625 - round_loss:\u001b[A\n",
      "Training:   0%| | 54/40960 [00:02<21:45, 31.33batches/s, l2_loss: 0.0625 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 54/40960 [00:02<21:45, 31.33batches/s, l2_loss: 0.0940 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 106/40960 [00:02<10:39, 63.85batches/s, l2_loss: 0.0940 - round_loss: \u001b[A\n",
      "Training:   0%| | 106/40960 [00:02<10:39, 63.85batches/s, l2_loss: 0.0998 - round_loss: \u001b[A\n",
      "Training:   0%| | 161/40960 [00:02<06:50, 99.29batches/s, l2_loss: 0.0998 - round_loss: \u001b[A\n",
      "Training:   0%| | 161/40960 [00:02<06:50, 99.29batches/s, l2_loss: 0.1008 - round_loss: \u001b[A\n",
      "Training:   1%| | 223/40960 [00:02<04:50, 140.11batches/s, l2_loss: 0.1008 - round_loss:\u001b[A\n",
      "Training:   1%| | 223/40960 [00:02<04:50, 140.11batches/s, l2_loss: 0.1002 - round_loss:\u001b[A\n",
      "Training:   1%| | 282/40960 [00:03<03:54, 173.30batches/s, l2_loss: 0.1002 - round_loss:\u001b[A\n",
      "Training:   1%| | 282/40960 [00:03<03:54, 173.30batches/s, l2_loss: 0.0974 - round_loss:\u001b[A\n",
      "Training:   1%| | 336/40960 [00:03<03:27, 195.73batches/s, l2_loss: 0.0974 - round_loss:\u001b[A\n",
      "Training:   1%| | 336/40960 [00:03<03:27, 195.73batches/s, l2_loss: 0.0953 - round_loss:\u001b[A\n",
      "Training:   1%| | 393/40960 [00:03<03:05, 218.21batches/s, l2_loss: 0.0953 - round_loss:\u001b[A\n",
      "Training:   1%| | 393/40960 [00:03<03:05, 218.21batches/s, l2_loss: 0.0976 - round_loss:\u001b[A\n",
      "Training:   1%| | 452/40960 [00:03<02:49, 238.48batches/s, l2_loss: 0.0976 - round_loss:\u001b[A\n",
      "Training:   1%| | 452/40960 [00:03<02:49, 238.48batches/s, l2_loss: 0.0962 - round_loss:\u001b[A\n",
      "Training:   1%| | 502/40960 [00:03<02:47, 241.13batches/s, l2_loss: 0.0962 - round_loss:\u001b[A\n",
      "Training:   1%| | 502/40960 [00:03<02:47, 241.13batches/s, l2_loss: 0.0971 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%| | 562/40960 [00:04<02:37, 256.54batches/s, l2_loss: 0.0971 - round_loss:\u001b[A\n",
      "Training:   1%| | 562/40960 [00:04<02:37, 256.54batches/s, l2_loss: 0.0973 - round_loss:\u001b[A\n",
      "Training:   2%| | 619/40960 [00:04<02:32, 264.00batches/s, l2_loss: 0.0973 - round_loss:\u001b[A\n",
      "Training:   2%| | 619/40960 [00:04<02:32, 264.00batches/s, l2_loss: 0.0968 - round_loss:\u001b[A\n",
      "Training:   2%| | 670/40960 [00:04<02:34, 260.00batches/s, l2_loss: 0.0968 - round_loss:\u001b[A\n",
      "Training:   2%| | 670/40960 [00:04<02:34, 260.00batches/s, l2_loss: 0.0971 - round_loss:\u001b[A\n",
      "Training:   2%| | 722/40960 [00:04<02:35, 259.04batches/s, l2_loss: 0.0971 - round_loss:\u001b[A\n",
      "Training:   2%| | 722/40960 [00:04<02:35, 259.04batches/s, l2_loss: 0.0974 - round_loss:\u001b[A\n",
      "Training:   2%| | 772/40960 [00:04<02:37, 255.55batches/s, l2_loss: 0.0974 - round_loss:\u001b[A\n",
      "Training:   2%| | 772/40960 [00:04<02:37, 255.55batches/s, l2_loss: 0.0972 - round_loss:\u001b[A\n",
      "Training:   2%| | 822/40960 [00:05<02:38, 253.63batches/s, l2_loss: 0.0972 - round_loss:\u001b[A\n",
      "Training:   2%| | 822/40960 [00:05<02:38, 253.63batches/s, l2_loss: 0.0964 - round_loss:\u001b[A\n",
      "Training:   2%| | 874/40960 [00:05<02:37, 254.78batches/s, l2_loss: 0.0964 - round_loss:\u001b[A\n",
      "Training:   2%| | 874/40960 [00:05<02:37, 254.78batches/s, l2_loss: 0.0969 - round_loss:\u001b[A\n",
      "Training:   2%| | 928/40960 [00:05<02:34, 258.89batches/s, l2_loss: 0.0969 - round_loss:\u001b[A\n",
      "Training:   2%| | 928/40960 [00:05<02:34, 258.89batches/s, l2_loss: 0.0980 - round_loss:\u001b[A\n",
      "Training:   2%| | 980/40960 [00:05<02:34, 259.11batches/s, l2_loss: 0.0980 - round_loss:\u001b[A\n",
      "Training:   2%| | 980/40960 [00:05<02:34, 259.11batches/s, l2_loss: 0.0972 - round_loss:\u001b[A\n",
      "Training:   3%| | 1042/40960 [00:05<02:26, 273.15batches/s, l2_loss: 0.0972 - round_loss\u001b[A\n",
      "Training:   3%| | 1042/40960 [00:06<02:26, 273.15batches/s, l2_loss: 0.0965 - round_loss\u001b[A\n",
      "Training:   3%| | 1097/40960 [00:06<02:26, 272.21batches/s, l2_loss: 0.0965 - round_loss\u001b[A\n",
      "Training:   3%| | 1097/40960 [00:06<02:26, 272.21batches/s, l2_loss: 0.0967 - round_loss\u001b[A\n",
      "Training:   3%| | 1147/40960 [00:06<02:29, 265.49batches/s, l2_loss: 0.0967 - round_loss\u001b[A\n",
      "Training:   3%| | 1147/40960 [00:06<02:29, 265.49batches/s, l2_loss: 0.0968 - round_loss\u001b[A\n",
      "Training:   3%| | 1200/40960 [00:06<02:30, 264.49batches/s, l2_loss: 0.0968 - round_loss\u001b[A\n",
      "Training:   3%| | 1200/40960 [00:06<02:30, 264.49batches/s, l2_loss: 0.0961 - round_loss\u001b[A\n",
      "Training:   3%| | 1252/40960 [00:06<02:31, 261.83batches/s, l2_loss: 0.0961 - round_loss\u001b[A\n",
      "Training:   3%| | 1252/40960 [00:06<02:31, 261.83batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   3%| | 1292/40960 [00:07<02:43, 242.69batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   3%| | 1292/40960 [00:07<02:43, 242.69batches/s, l2_loss: 0.0968 - round_loss\u001b[A\n",
      "Training:   3%| | 1346/40960 [00:07<02:38, 249.72batches/s, l2_loss: 0.0968 - round_loss\u001b[A\n",
      "Training:   3%| | 1346/40960 [00:07<02:38, 249.72batches/s, l2_loss: 0.0965 - round_loss\u001b[A\n",
      "Training:   3%| | 1401/40960 [00:07<02:34, 256.23batches/s, l2_loss: 0.0965 - round_loss\u001b[A\n",
      "Training:   3%| | 1401/40960 [00:07<02:34, 256.23batches/s, l2_loss: 0.0966 - round_loss\u001b[A\n",
      "Training:   4%| | 1463/40960 [00:07<02:25, 271.12batches/s, l2_loss: 0.0966 - round_loss\u001b[A\n",
      "Training:   4%| | 1463/40960 [00:07<02:25, 271.12batches/s, l2_loss: 0.0961 - round_loss\u001b[A\n",
      "Training:   4%| | 1524/40960 [00:07<02:20, 280.80batches/s, l2_loss: 0.0961 - round_loss\u001b[A\n",
      "Training:   4%| | 1524/40960 [00:07<02:20, 280.80batches/s, l2_loss: 0.0964 - round_loss\u001b[A\n",
      "Training:   4%| | 1587/40960 [00:08<02:15, 290.74batches/s, l2_loss: 0.0964 - round_loss\u001b[A\n",
      "Training:   4%| | 1587/40960 [00:08<02:15, 290.74batches/s, l2_loss: 0.0968 - round_loss\u001b[A\n",
      "Training:   4%| | 1643/40960 [00:08<02:17, 286.32batches/s, l2_loss: 0.0968 - round_loss\u001b[A\n",
      "Training:   4%| | 1643/40960 [00:08<02:17, 286.32batches/s, l2_loss: 0.0964 - round_loss\u001b[A\n",
      "Training:   4%| | 1699/40960 [00:08<02:18, 282.71batches/s, l2_loss: 0.0964 - round_loss\u001b[A\n",
      "Training:   4%| | 1699/40960 [00:08<02:18, 282.71batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   4%| | 1741/40960 [00:08<02:30, 260.12batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   4%| | 1741/40960 [00:08<02:30, 260.12batches/s, l2_loss: 0.0960 - round_loss\u001b[A\n",
      "Training:   4%| | 1804/40960 [00:08<02:21, 275.88batches/s, l2_loss: 0.0960 - round_loss\u001b[A\n",
      "Training:   4%| | 1804/40960 [00:08<02:21, 275.88batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   5%| | 1864/40960 [00:09<02:18, 282.07batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   5%| | 1864/40960 [00:09<02:18, 282.07batches/s, l2_loss: 0.0957 - round_loss\u001b[A\n",
      "Training:   5%| | 1927/40960 [00:09<02:14, 291.19batches/s, l2_loss: 0.0957 - round_loss\u001b[A\n",
      "Training:   5%| | 1927/40960 [00:09<02:14, 291.19batches/s, l2_loss: 0.0958 - round_loss\u001b[A\n",
      "Training:   5%| | 1989/40960 [00:09<02:11, 296.32batches/s, l2_loss: 0.0958 - round_loss\u001b[A\n",
      "Training:   5%| | 1989/40960 [00:09<02:11, 296.32batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   5%| | 2051/40960 [00:09<02:09, 300.23batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   5%| | 2051/40960 [00:09<02:09, 300.23batches/s, l2_loss: 0.0957 - round_loss\u001b[A\n",
      "Training:   5%| | 2112/40960 [00:09<02:09, 300.14batches/s, l2_loss: 0.0957 - round_loss\u001b[A\n",
      "Training:   5%| | 2112/40960 [00:09<02:09, 300.14batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   5%| | 2167/40960 [00:10<02:13, 291.49batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:   5%| | 2167/40960 [00:10<02:13, 291.49batches/s, l2_loss: 0.0956 - round_loss\u001b[A\n",
      "Training:   5%| | 2211/40960 [00:10<02:23, 269.32batches/s, l2_loss: 0.0956 - round_loss\u001b[A\n",
      "Training:   5%| | 2211/40960 [00:10<02:23, 269.32batches/s, l2_loss: 0.0955 - round_loss\u001b[A\n",
      "Training:   6%| | 2266/40960 [00:10<02:23, 269.60batches/s, l2_loss: 0.0955 - round_loss\u001b[A\n",
      "Training:   6%| | 2266/40960 [00:10<02:23, 269.60batches/s, l2_loss: 0.0956 - round_loss\u001b[A\n",
      "Training:   6%| | 2320/40960 [00:10<02:23, 268.88batches/s, l2_loss: 0.0956 - round_loss\u001b[A\n",
      "Training:   6%| | 2320/40960 [00:10<02:23, 268.88batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:   6%| | 2373/40960 [00:10<02:24, 267.45batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:   6%| | 2373/40960 [00:10<02:24, 267.45batches/s, l2_loss: 0.0952 - round_loss\u001b[A\n",
      "Training:   6%| | 2432/40960 [00:11<02:20, 274.96batches/s, l2_loss: 0.0952 - round_loss\u001b[A\n",
      "Training:   6%| | 2432/40960 [00:11<02:20, 274.96batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:   6%| | 2494/40960 [00:11<02:15, 284.88batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:   6%| | 2494/40960 [00:11<02:15, 284.88batches/s, l2_loss: 0.0957 - round_loss\u001b[A\n",
      "Training:   6%| | 2553/40960 [00:11<02:13, 287.13batches/s, l2_loss: 0.0957 - round_loss\u001b[A\n",
      "Training:   6%| | 2553/40960 [00:11<02:13, 287.13batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:   6%| | 2612/40960 [00:11<02:12, 289.05batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:   6%| | 2612/40960 [00:11<02:12, 289.05batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:   7%| | 2674/40960 [00:11<02:09, 294.67batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:   7%| | 2674/40960 [00:11<02:09, 294.67batches/s, l2_loss: 0.0952 - round_loss\u001b[A\n",
      "Training:   7%| | 2734/40960 [00:12<02:09, 294.61batches/s, l2_loss: 0.0952 - round_loss\u001b[A\n",
      "Training:   7%| | 2734/40960 [00:12<02:09, 294.61batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:   7%| | 2789/40960 [00:12<02:12, 287.29batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:   7%| | 2789/40960 [00:12<02:12, 287.29batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:   7%| | 2838/40960 [00:12<02:19, 273.33batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:   7%| | 2838/40960 [00:12<02:19, 273.33batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:   7%| | 2891/40960 [00:12<02:20, 270.11batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:   7%| | 2891/40960 [00:12<02:20, 270.11batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:   7%| | 2950/40960 [00:12<02:17, 276.46batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:   7%| | 2950/40960 [00:12<02:17, 276.46batches/s, l2_loss: 0.0949 - round_loss\u001b[A\n",
      "Training:   7%| | 3011/40960 [00:13<02:13, 284.21batches/s, l2_loss: 0.0949 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 3011/40960 [00:13<02:13, 284.21batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:   7%| | 3068/40960 [00:13<02:13, 283.70batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:   7%| | 3068/40960 [00:13<02:13, 283.70batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:   8%| | 3121/40960 [00:13<02:16, 277.53batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:   8%| | 3121/40960 [00:13<02:16, 277.53batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n",
      "Training:   8%| | 3180/40960 [00:13<02:14, 281.17batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n",
      "Training:   8%| | 3180/40960 [00:13<02:14, 281.17batches/s, l2_loss: 0.0944 - round_loss\u001b[A\n",
      "Training:   8%| | 3231/40960 [00:13<02:18, 273.00batches/s, l2_loss: 0.0944 - round_loss\u001b[A\n",
      "Training:   8%| | 3231/40960 [00:13<02:18, 273.00batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n",
      "Training:   8%| | 3283/40960 [00:14<02:20, 269.09batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n",
      "Training:   8%| | 3283/40960 [00:14<02:20, 269.09batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:   8%| | 3342/40960 [00:14<02:16, 275.93batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:   8%| | 3342/40960 [00:14<02:16, 275.93batches/s, l2_loss: 0.0944 - round_loss\u001b[A\n",
      "Training:   8%| | 3394/40960 [00:14<02:18, 270.88batches/s, l2_loss: 0.0944 - round_loss\u001b[A\n",
      "Training:   8%| | 3394/40960 [00:14<02:18, 270.88batches/s, l2_loss: 0.0943 - round_loss\u001b[A\n",
      "Training:   8%| | 3447/40960 [00:14<02:19, 268.18batches/s, l2_loss: 0.0943 - round_loss\u001b[A\n",
      "Training:   8%| | 3447/40960 [00:14<02:19, 268.18batches/s, l2_loss: 0.0944 - round_loss\u001b[A\n",
      "Training:   9%| | 3501/40960 [00:14<02:19, 268.34batches/s, l2_loss: 0.0944 - round_loss\u001b[A\n",
      "Training:   9%| | 3501/40960 [00:14<02:19, 268.34batches/s, l2_loss: 0.0942 - round_loss\u001b[A\n",
      "Training:   9%| | 3551/40960 [00:15<02:22, 262.17batches/s, l2_loss: 0.0942 - round_loss\u001b[A\n",
      "Training:   9%| | 3551/40960 [00:15<02:22, 262.17batches/s, l2_loss: 0.0943 - round_loss\u001b[A\n",
      "Training:   9%| | 3601/40960 [00:15<02:25, 257.09batches/s, l2_loss: 0.0943 - round_loss\u001b[A\n",
      "Training:   9%| | 3601/40960 [00:15<02:25, 257.09batches/s, l2_loss: 0.0943 - round_loss\u001b[A\n",
      "Training:   9%| | 3655/40960 [00:15<02:23, 259.65batches/s, l2_loss: 0.0943 - round_loss\u001b[A\n",
      "Training:   9%| | 3655/40960 [00:15<02:23, 259.65batches/s, l2_loss: 0.0941 - round_loss\u001b[A\n",
      "Training:   9%| | 3711/40960 [00:15<02:20, 265.11batches/s, l2_loss: 0.0941 - round_loss\u001b[A\n",
      "Training:   9%| | 3711/40960 [00:15<02:20, 265.11batches/s, l2_loss: 0.0942 - round_loss\u001b[A\n",
      "Training:   9%| | 3761/40960 [00:15<02:23, 258.95batches/s, l2_loss: 0.0942 - round_loss\u001b[A\n",
      "Training:   9%| | 3761/40960 [00:15<02:23, 258.95batches/s, l2_loss: 0.0942 - round_loss\u001b[A\n",
      "Training:   9%| | 3816/40960 [00:16<02:21, 263.02batches/s, l2_loss: 0.0942 - round_loss\u001b[A\n",
      "Training:   9%| | 3816/40960 [00:16<02:21, 263.02batches/s, l2_loss: 0.0941 - round_loss\u001b[A\n",
      "Training:   9%| | 3870/40960 [00:16<02:20, 264.75batches/s, l2_loss: 0.0941 - round_loss\u001b[A\n",
      "Training:   9%| | 3870/40960 [00:16<02:20, 264.75batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 3924/40960 [00:16<02:19, 265.71batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 3924/40960 [00:16<02:19, 265.71batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 3981/40960 [00:16<02:16, 270.84batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 3981/40960 [00:16<02:16, 270.84batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 4035/40960 [00:16<02:16, 270.07batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 4035/40960 [00:16<02:16, 270.07batches/s, l2_loss: 0.0937 - round_loss\u001b[A\n",
      "Training:  10%| | 4088/40960 [00:17<02:17, 267.46batches/s, l2_loss: 0.0937 - round_loss\u001b[A\n",
      "Training:  10%| | 4088/40960 [00:17<02:17, 267.46batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 4135/40960 [00:17<02:23, 257.29batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 4135/40960 [00:17<02:23, 257.29batches/s, l2_loss: 0.0940 - round_loss\u001b[A\n",
      "Training:  10%| | 4181/40960 [00:17<02:27, 248.58batches/s, l2_loss: 0.0940 - round_loss\u001b[A\n",
      "Training:  10%| | 4181/40960 [00:17<02:27, 248.58batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 4238/40960 [00:17<02:21, 259.03batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  10%| | 4238/40960 [00:17<02:21, 259.03batches/s, l2_loss: 0.0938 - round_loss\u001b[A\n",
      "Training:  10%| | 4296/40960 [00:17<02:17, 267.58batches/s, l2_loss: 0.0938 - round_loss\u001b[A\n",
      "Training:  10%| | 4296/40960 [00:17<02:17, 267.58batches/s, l2_loss: 0.0937 - round_loss\u001b[A\n",
      "Training:  11%| | 4359/40960 [00:18<02:10, 281.32batches/s, l2_loss: 0.0937 - round_loss\u001b[A\n",
      "Training:  11%| | 4359/40960 [00:18<02:10, 281.32batches/s, l2_loss: 0.0936 - round_loss\u001b[A\n",
      "Training:  11%| | 4421/40960 [00:18<02:06, 288.59batches/s, l2_loss: 0.0936 - round_loss\u001b[A\n",
      "Training:  11%| | 4421/40960 [00:18<02:06, 288.59batches/s, l2_loss: 0.0934 - round_loss\u001b[A\n",
      "Training:  11%| | 4481/40960 [00:18<02:05, 291.81batches/s, l2_loss: 0.0934 - round_loss\u001b[A\n",
      "Training:  11%| | 4481/40960 [00:18<02:05, 291.81batches/s, l2_loss: 0.0935 - round_loss\u001b[A\n",
      "Training:  11%| | 4541/40960 [00:18<02:03, 294.14batches/s, l2_loss: 0.0935 - round_loss\u001b[A\n",
      "Training:  11%| | 4541/40960 [00:18<02:03, 294.14batches/s, l2_loss: 0.0935 - round_loss\u001b[A\n",
      "Training:  11%| | 4591/40960 [00:18<02:10, 278.67batches/s, l2_loss: 0.0935 - round_loss\u001b[A\n",
      "Training:  11%| | 4591/40960 [00:18<02:10, 278.67batches/s, l2_loss: 0.0935 - round_loss\u001b[A\n",
      "Training:  11%| | 4649/40960 [00:19<02:08, 281.49batches/s, l2_loss: 0.0935 - round_loss\u001b[A\n",
      "Training:  11%| | 4649/40960 [00:19<02:08, 281.49batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  11%| | 4710/40960 [00:19<02:05, 288.03batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  11%| | 4710/40960 [00:19<02:05, 288.03batches/s, l2_loss: 0.0934 - round_loss\u001b[A\n",
      "Training:  12%| | 4776/40960 [00:19<02:00, 299.41batches/s, l2_loss: 0.0934 - round_loss\u001b[A\n",
      "Training:  12%| | 4776/40960 [00:19<02:00, 299.41batches/s, l2_loss: 0.0934 - round_loss\u001b[A\n",
      "Training:  12%| | 4839/40960 [00:19<01:58, 303.64batches/s, l2_loss: 0.0934 - round_loss\u001b[A\n",
      "Training:  12%| | 4839/40960 [00:19<01:58, 303.64batches/s, l2_loss: 0.0934 - round_loss\u001b[A\n",
      "Training:  12%| | 4897/40960 [00:19<02:00, 299.02batches/s, l2_loss: 0.0934 - round_loss\u001b[A\n",
      "Training:  12%| | 4897/40960 [00:19<02:00, 299.02batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  12%| | 4957/40960 [00:20<02:00, 297.82batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  12%| | 4957/40960 [00:20<02:00, 297.82batches/s, l2_loss: 0.0932 - round_loss\u001b[A\n",
      "Training:  12%| | 5020/40960 [00:20<01:58, 302.09batches/s, l2_loss: 0.0932 - round_loss\u001b[A\n",
      "Training:  12%| | 5020/40960 [00:20<01:58, 302.09batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  12%| | 5080/40960 [00:20<01:59, 300.49batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  12%| | 5080/40960 [00:20<01:59, 300.49batches/s, l2_loss: 0.0932 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5140/40960 [00:20<01:59, 298.99batches/s, l2_loss: 0.0932 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5140/40960 [00:20<01:59, 298.99batches/s, l2_loss: 0.0931 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5198/40960 [00:20<02:00, 296.20batches/s, l2_loss: 0.0931 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5198/40960 [00:20<02:00, 296.20batches/s, l2_loss: 0.0930 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5258/40960 [00:21<02:00, 296.76batches/s, l2_loss: 0.0930 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5258/40960 [00:21<02:00, 296.76batches/s, l2_loss: 0.0930 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5315/40960 [00:21<02:01, 292.90batches/s, l2_loss: 0.0930 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5315/40960 [00:21<02:01, 292.90batches/s, l2_loss: 0.0929 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5372/40960 [00:21<02:03, 289.27batches/s, l2_loss: 0.0929 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5372/40960 [00:21<02:03, 289.27batches/s, l2_loss: 0.0929 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5428/40960 [00:21<02:04, 284.86batches/s, l2_loss: 0.0929 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5428/40960 [00:21<02:04, 284.86batches/s, l2_loss: 0.0929 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5485/40960 [00:21<02:04, 284.21batches/s, l2_loss: 0.0929 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5485/40960 [00:21<02:04, 284.21batches/s, l2_loss: 0.0928 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|▏| 5539/40960 [00:22<02:07, 278.16batches/s, l2_loss: 0.0928 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5539/40960 [00:22<02:07, 278.16batches/s, l2_loss: 0.0929 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5595/40960 [00:22<02:07, 278.18batches/s, l2_loss: 0.0929 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5595/40960 [00:22<02:07, 278.18batches/s, l2_loss: 0.0928 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5654/40960 [00:22<02:05, 281.37batches/s, l2_loss: 0.0928 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5654/40960 [00:22<02:05, 281.37batches/s, l2_loss: 0.0928 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5709/40960 [00:22<02:06, 278.21batches/s, l2_loss: 0.0928 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5709/40960 [00:22<02:06, 278.21batches/s, l2_loss: 0.0927 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5769/40960 [00:22<02:03, 284.48batches/s, l2_loss: 0.0927 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5769/40960 [00:22<02:03, 284.48batches/s, l2_loss: 0.0926 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5831/40960 [00:23<02:00, 291.66batches/s, l2_loss: 0.0926 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5831/40960 [00:23<02:00, 291.66batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5881/40960 [00:23<02:06, 278.23batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5881/40960 [00:23<02:06, 278.23batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5939/40960 [00:23<02:04, 280.74batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5939/40960 [00:23<02:04, 280.74batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5991/40960 [00:23<02:07, 273.87batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5991/40960 [00:23<02:07, 273.87batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6047/40960 [00:23<02:07, 274.68batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6047/40960 [00:23<02:07, 274.68batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6089/40960 [00:24<02:16, 254.89batches/s, l2_loss: 0.0925 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6089/40960 [00:24<02:16, 254.89batches/s, l2_loss: 0.0924 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6145/40960 [00:24<02:13, 261.30batches/s, l2_loss: 0.0924 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6145/40960 [00:24<02:13, 261.30batches/s, l2_loss: 0.0924 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6204/40960 [00:24<02:08, 270.86batches/s, l2_loss: 0.0924 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6204/40960 [00:24<02:08, 270.86batches/s, l2_loss: 0.0923 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6260/40960 [00:24<02:07, 272.46batches/s, l2_loss: 0.0923 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6260/40960 [00:24<02:07, 272.46batches/s, l2_loss: 0.0924 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6314/40960 [00:24<02:07, 271.30batches/s, l2_loss: 0.0924 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6314/40960 [00:24<02:07, 271.30batches/s, l2_loss: 0.0923 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6375/40960 [00:25<02:03, 280.16batches/s, l2_loss: 0.0923 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6375/40960 [00:25<02:03, 280.16batches/s, l2_loss: 0.0923 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:25<02:07, 270.65batches/s, l2_loss: 0.0923 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6425/40960 [00:25<02:07, 270.65batches/s, l2_loss: 0.0922 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6478/40960 [00:25<02:08, 268.49batches/s, l2_loss: 0.0922 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6478/40960 [00:25<02:08, 268.49batches/s, l2_loss: 0.0922 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6530/40960 [00:25<02:10, 264.43batches/s, l2_loss: 0.0922 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6530/40960 [00:25<02:10, 264.43batches/s, l2_loss: 0.0922 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6588/40960 [00:25<02:06, 271.97batches/s, l2_loss: 0.0922 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6588/40960 [00:26<02:06, 271.97batches/s, l2_loss: 0.0922 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6652/40960 [00:26<02:00, 285.68batches/s, l2_loss: 0.0922 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6652/40960 [00:26<02:00, 285.68batches/s, l2_loss: 0.0921 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6703/40960 [00:26<02:03, 276.39batches/s, l2_loss: 0.0921 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6703/40960 [00:26<02:03, 276.39batches/s, l2_loss: 0.0920 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6754/40960 [00:26<02:07, 268.40batches/s, l2_loss: 0.0920 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6754/40960 [00:26<02:07, 268.40batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6809/40960 [00:26<02:06, 269.65batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6809/40960 [00:26<02:06, 269.65batches/s, l2_loss: 0.0920 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6864/40960 [00:27<02:06, 270.43batches/s, l2_loss: 0.0920 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6864/40960 [00:27<02:06, 270.43batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6920/40960 [00:27<02:04, 272.53batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6920/40960 [00:27<02:04, 272.53batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6976/40960 [00:27<02:03, 274.27batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6976/40960 [00:27<02:03, 274.27batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7037/40960 [00:27<02:00, 282.55batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7037/40960 [00:27<02:00, 282.55batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7092/40960 [00:27<02:01, 279.10batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7092/40960 [00:27<02:01, 279.10batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7144/40960 [00:28<02:04, 272.24batches/s, l2_loss: 0.0919 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7144/40960 [00:28<02:04, 272.24batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7204/40960 [00:28<02:00, 280.17batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7204/40960 [00:28<02:00, 280.17batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7261/40960 [00:28<01:59, 281.01batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7261/40960 [00:28<01:59, 281.01batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7314/40960 [00:28<02:02, 275.70batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7314/40960 [00:28<02:02, 275.70batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7366/40960 [00:28<02:04, 270.02batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7366/40960 [00:28<02:04, 270.02batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7420/40960 [00:29<02:04, 268.61batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7420/40960 [00:29<02:04, 268.61batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7482/40960 [00:29<01:59, 279.77batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7482/40960 [00:29<01:59, 279.77batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7542/40960 [00:29<01:56, 285.79batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7542/40960 [00:29<01:56, 285.79batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7604/40960 [00:29<01:54, 291.80batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7604/40960 [00:29<01:54, 291.80batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7667/40960 [00:29<01:52, 297.04batches/s, l2_loss: 0.0917 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7667/40960 [00:29<01:52, 297.04batches/s, l2_loss: 0.0916 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7727/40960 [00:30<01:51, 297.57batches/s, l2_loss: 0.0916 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7727/40960 [00:30<01:51, 297.57batches/s, l2_loss: 0.0915 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7788/40960 [00:30<01:50, 299.01batches/s, l2_loss: 0.0915 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7788/40960 [00:30<01:50, 299.01batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7850/40960 [00:30<01:49, 302.00batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7850/40960 [00:30<01:49, 302.00batches/s, l2_loss: 0.0915 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7895/40960 [00:30<01:59, 275.60batches/s, l2_loss: 0.0915 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7895/40960 [00:30<01:59, 275.60batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7947/40960 [00:30<02:02, 270.14batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7947/40960 [00:30<02:02, 270.14batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8008/40960 [00:31<01:57, 279.36batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 8008/40960 [00:31<01:57, 279.36batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8063/40960 [00:31<01:58, 276.56batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8063/40960 [00:31<01:58, 276.56batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8123/40960 [00:31<01:55, 283.11batches/s, l2_loss: 0.0914 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8123/40960 [00:31<01:55, 283.11batches/s, l2_loss: 0.0913 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8187/40960 [00:31<01:51, 292.98batches/s, l2_loss: 0.0913 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8187/40960 [00:31<01:51, 292.98batches/s, l2_loss: 0.0913 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8243/40960 [00:31<01:53, 287.82batches/s, l2_loss: 0.0913 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8243/40960 [00:31<01:53, 287.82batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8303/40960 [00:32<01:52, 290.86batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8303/40960 [00:32<01:52, 290.86batches/s, l2_loss: 0.0881 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8356/40960 [00:32<01:55, 282.49batches/s, l2_loss: 0.0881 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8356/40960 [00:32<01:55, 282.49batches/s, l2_loss: 0.0896 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8410/40960 [00:32<01:57, 277.81batches/s, l2_loss: 0.0896 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8410/40960 [00:32<01:57, 277.81batches/s, l2_loss: 0.0865 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8469/40960 [00:32<01:55, 281.63batches/s, l2_loss: 0.0865 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8469/40960 [00:32<01:55, 281.63batches/s, l2_loss: 0.0870 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8521/40960 [00:32<01:57, 274.92batches/s, l2_loss: 0.0870 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8521/40960 [00:32<01:57, 274.92batches/s, l2_loss: 0.0870 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8570/40960 [00:33<02:02, 264.84batches/s, l2_loss: 0.0870 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8570/40960 [00:33<02:02, 264.84batches/s, l2_loss: 0.0858 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8620/40960 [00:33<02:04, 259.68batches/s, l2_loss: 0.0858 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8620/40960 [00:33<02:04, 259.68batches/s, l2_loss: 0.0872 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8667/40960 [00:33<02:08, 252.19batches/s, l2_loss: 0.0872 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8667/40960 [00:33<02:08, 252.19batches/s, l2_loss: 0.0878 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8724/40960 [00:33<02:03, 261.61batches/s, l2_loss: 0.0878 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8724/40960 [00:33<02:03, 261.61batches/s, l2_loss: 0.0874 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8778/40960 [00:33<02:02, 262.78batches/s, l2_loss: 0.0874 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8778/40960 [00:33<02:02, 262.78batches/s, l2_loss: 0.0879 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8835/40960 [00:34<01:59, 268.66batches/s, l2_loss: 0.0879 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8835/40960 [00:34<01:59, 268.66batches/s, l2_loss: 0.0864 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8890/40960 [00:34<01:58, 270.51batches/s, l2_loss: 0.0864 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8890/40960 [00:34<01:58, 270.51batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8943/40960 [00:34<01:59, 268.08batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8943/40960 [00:34<01:59, 268.08batches/s, l2_loss: 0.0866 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8994/40960 [00:34<02:01, 263.07batches/s, l2_loss: 0.0866 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8994/40960 [00:34<02:01, 263.07batches/s, l2_loss: 0.0864 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9046/40960 [00:34<02:02, 260.99batches/s, l2_loss: 0.0864 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9046/40960 [00:34<02:02, 260.99batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9099/40960 [00:35<02:01, 261.80batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9099/40960 [00:35<02:01, 261.80batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9152/40960 [00:35<02:01, 262.29batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9152/40960 [00:35<02:01, 262.29batches/s, l2_loss: 0.0864 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9197/40960 [00:35<02:06, 250.98batches/s, l2_loss: 0.0864 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9197/40960 [00:35<02:06, 250.98batches/s, l2_loss: 0.0867 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9246/40960 [00:35<02:07, 248.22batches/s, l2_loss: 0.0867 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9246/40960 [00:35<02:07, 248.22batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9297/40960 [00:35<02:06, 249.52batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9297/40960 [00:35<02:06, 249.52batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9348/40960 [00:36<02:06, 249.80batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9348/40960 [00:36<02:06, 249.80batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9404/40960 [00:36<02:02, 258.64batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9404/40960 [00:36<02:02, 258.64batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9463/40960 [00:36<01:57, 269.07batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9463/40960 [00:36<01:57, 269.07batches/s, l2_loss: 0.0860 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9520/40960 [00:36<01:54, 273.54batches/s, l2_loss: 0.0860 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9520/40960 [00:36<01:54, 273.54batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9576/40960 [00:36<01:54, 274.64batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9576/40960 [00:36<01:54, 274.64batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9635/40960 [00:37<01:52, 279.56batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9635/40960 [00:37<01:52, 279.56batches/s, l2_loss: 0.0867 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9695/40960 [00:37<01:49, 284.73batches/s, l2_loss: 0.0867 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9695/40960 [00:37<01:49, 284.73batches/s, l2_loss: 0.0867 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9745/40960 [00:37<01:54, 273.47batches/s, l2_loss: 0.0867 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9745/40960 [00:37<01:54, 273.47batches/s, l2_loss: 0.0861 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9798/40960 [00:37<01:55, 269.68batches/s, l2_loss: 0.0861 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9798/40960 [00:37<01:55, 269.68batches/s, l2_loss: 0.0860 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9849/40960 [00:37<01:57, 265.26batches/s, l2_loss: 0.0860 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9849/40960 [00:37<01:57, 265.26batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9906/40960 [00:38<01:54, 270.71batches/s, l2_loss: 0.0863 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9906/40960 [00:38<01:54, 270.71batches/s, l2_loss: 0.0868 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9961/40960 [00:38<01:54, 270.91batches/s, l2_loss: 0.0868 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9961/40960 [00:38<01:54, 270.91batches/s, l2_loss: 0.0864 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10016/40960 [00:38<01:53, 271.51batches/s, l2_loss: 0.0864 - round_los\u001b[A\n",
      "Training:  24%|▏| 10016/40960 [00:38<01:53, 271.51batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  25%|▏| 10076/40960 [00:38<01:50, 278.95batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  25%|▏| 10076/40960 [00:38<01:50, 278.95batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  25%|▏| 10130/40960 [00:38<01:51, 275.86batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  25%|▏| 10130/40960 [00:38<01:51, 275.86batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  25%|▏| 10184/40960 [00:39<01:52, 273.67batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  25%|▏| 10184/40960 [00:39<01:52, 273.67batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  25%|▎| 10241/40960 [00:39<01:50, 276.93batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  25%|▎| 10241/40960 [00:39<01:50, 276.93batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  25%|▎| 10298/40960 [00:39<01:49, 279.09batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  25%|▎| 10298/40960 [00:39<01:49, 279.09batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  25%|▎| 10354/40960 [00:39<01:49, 278.79batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  25%|▎| 10354/40960 [00:39<01:49, 278.79batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  25%|▎| 10415/40960 [00:39<01:46, 285.91batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  25%|▎| 10415/40960 [00:39<01:46, 285.91batches/s, l2_loss: 0.0861 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10470/40960 [00:40<01:48, 281.91batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  26%|▎| 10470/40960 [00:40<01:48, 281.91batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  26%|▎| 10525/40960 [00:40<01:49, 278.02batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  26%|▎| 10525/40960 [00:40<01:49, 278.02batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  26%|▎| 10572/40960 [00:40<01:54, 264.75batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  26%|▎| 10572/40960 [00:40<01:54, 264.75batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  26%|▎| 10621/40960 [00:40<01:57, 257.92batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  26%|▎| 10621/40960 [00:40<01:57, 257.92batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  26%|▎| 10671/40960 [00:40<01:58, 254.86batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  26%|▎| 10671/40960 [00:40<01:58, 254.86batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  26%|▎| 10729/40960 [00:41<01:54, 264.21batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  26%|▎| 10729/40960 [00:41<01:54, 264.21batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  26%|▎| 10777/40960 [00:41<01:57, 256.85batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  26%|▎| 10777/40960 [00:41<01:57, 256.85batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  26%|▎| 10833/40960 [00:41<01:54, 263.54batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  26%|▎| 10833/40960 [00:41<01:54, 263.54batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  27%|▎| 10889/40960 [00:41<01:52, 267.22batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  27%|▎| 10889/40960 [00:41<01:52, 267.22batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  27%|▎| 10951/40960 [00:41<01:47, 279.92batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  27%|▎| 10951/40960 [00:41<01:47, 279.92batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  27%|▎| 11003/40960 [00:42<01:49, 272.46batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  27%|▎| 11003/40960 [00:42<01:49, 272.46batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  27%|▎| 11057/40960 [00:42<01:50, 271.40batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  27%|▎| 11057/40960 [00:42<01:50, 271.40batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  27%|▎| 11117/40960 [00:42<01:47, 278.72batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  27%|▎| 11117/40960 [00:42<01:47, 278.72batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  27%|▎| 11175/40960 [00:42<01:46, 280.79batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  27%|▎| 11175/40960 [00:42<01:46, 280.79batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  27%|▎| 11220/40960 [00:42<01:53, 262.19batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  27%|▎| 11220/40960 [00:42<01:53, 262.19batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  27%|▎| 11254/40960 [00:43<02:07, 233.88batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  27%|▎| 11254/40960 [00:43<02:07, 233.88batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  28%|▎| 11312/40960 [00:43<01:59, 249.14batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  28%|▎| 11312/40960 [00:43<01:59, 249.14batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  28%|▎| 11365/40960 [00:43<01:56, 253.45batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  28%|▎| 11365/40960 [00:43<01:56, 253.45batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  28%|▎| 11415/40960 [00:43<01:57, 251.78batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  28%|▎| 11415/40960 [00:43<01:57, 251.78batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  28%|▎| 11469/40960 [00:43<01:54, 257.17batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  28%|▎| 11469/40960 [00:43<01:54, 257.17batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  28%|▎| 11521/40960 [00:44<01:54, 257.73batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  28%|▎| 11521/40960 [00:44<01:54, 257.73batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  28%|▎| 11574/40960 [00:44<01:53, 259.56batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  28%|▎| 11574/40960 [00:44<01:53, 259.56batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  28%|▎| 11632/40960 [00:44<01:49, 267.49batches/s, l2_loss: 0.0861 - round_los\u001b[A\n",
      "Training:  28%|▎| 11632/40960 [00:44<01:49, 267.49batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  29%|▎| 11691/40960 [00:44<01:46, 275.02batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  29%|▎| 11691/40960 [00:44<01:46, 275.02batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  29%|▎| 11742/40960 [00:44<01:48, 268.14batches/s, l2_loss: 0.0862 - round_los\u001b[A\n",
      "Training:  29%|▎| 11742/40960 [00:44<01:48, 268.14batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  29%|▎| 11800/40960 [00:45<01:46, 273.68batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  29%|▎| 11800/40960 [00:45<01:46, 273.68batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  29%|▎| 11859/40960 [00:45<01:44, 279.61batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  29%|▎| 11859/40960 [00:45<01:44, 279.61batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  29%|▎| 11919/40960 [00:45<01:41, 284.84batches/s, l2_loss: 0.0860 - round_los\u001b[A\n",
      "Training:  29%|▎| 11919/40960 [00:45<01:41, 284.84batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  29%|▎| 11977/40960 [00:45<01:41, 285.15batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  29%|▎| 11977/40960 [00:45<01:41, 285.15batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  29%|▎| 12033/40960 [00:45<01:42, 283.06batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  29%|▎| 12033/40960 [00:45<01:42, 283.06batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  30%|▎| 12092/40960 [00:46<01:40, 286.62batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  30%|▎| 12092/40960 [00:46<01:40, 286.62batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  30%|▎| 12150/40960 [00:46<01:40, 286.78batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  30%|▎| 12150/40960 [00:46<01:40, 286.78batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  30%|▎| 12210/40960 [00:46<01:39, 290.06batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  30%|▎| 12210/40960 [00:46<01:39, 290.06batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  30%|▎| 12270/40960 [00:46<01:37, 292.88batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  30%|▎| 12270/40960 [00:46<01:37, 292.88batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  30%|▎| 12319/40960 [00:46<01:43, 277.57batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  30%|▎| 12319/40960 [00:47<01:43, 277.57batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  30%|▎| 12372/40960 [00:47<01:44, 273.56batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  30%|▎| 12372/40960 [00:47<01:44, 273.56batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  30%|▎| 12423/40960 [00:47<01:46, 267.22batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  30%|▎| 12423/40960 [00:47<01:46, 267.22batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  30%|▎| 12470/40960 [00:47<01:50, 257.02batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  30%|▎| 12470/40960 [00:47<01:50, 257.02batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  31%|▎| 12522/40960 [00:47<01:50, 257.33batches/s, l2_loss: 0.0859 - round_los\u001b[A\n",
      "Training:  31%|▎| 12522/40960 [00:47<01:50, 257.33batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12579/40960 [00:48<01:46, 265.53batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12579/40960 [00:48<01:46, 265.53batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12636/40960 [00:48<01:44, 270.77batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12636/40960 [00:48<01:44, 270.77batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12691/40960 [00:48<01:44, 270.72batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12691/40960 [00:48<01:44, 270.72batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  31%|▎| 12744/40960 [00:48<01:45, 268.05batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  31%|▎| 12744/40960 [00:48<01:45, 268.05batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12798/40960 [00:48<01:44, 268.29batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12798/40960 [00:48<01:44, 268.29batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  31%|▎| 12851/40960 [00:49<01:45, 266.41batches/s, l2_loss: 0.0858 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|▎| 12851/40960 [00:49<01:45, 266.41batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  32%|▎| 12904/40960 [00:49<01:46, 263.98batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  32%|▎| 12904/40960 [00:49<01:46, 263.98batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  32%|▎| 12963/40960 [00:49<01:42, 272.95batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  32%|▎| 12963/40960 [00:49<01:42, 272.95batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  32%|▎| 13023/40960 [00:49<01:39, 279.42batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  32%|▎| 13023/40960 [00:49<01:39, 279.42batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  32%|▎| 13080/40960 [00:49<01:39, 280.41batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  32%|▎| 13080/40960 [00:49<01:39, 280.41batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  32%|▎| 13139/40960 [00:50<01:38, 283.54batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  32%|▎| 13139/40960 [00:50<01:38, 283.54batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  32%|▎| 13199/40960 [00:50<01:36, 287.52batches/s, l2_loss: 0.0858 - round_los\u001b[A\n",
      "Training:  32%|▎| 13199/40960 [00:50<01:36, 287.52batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  32%|▎| 13258/40960 [00:50<01:35, 289.19batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  32%|▎| 13258/40960 [00:50<01:35, 289.19batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13316/40960 [00:50<01:35, 288.28batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13316/40960 [00:50<01:35, 288.28batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13375/40960 [00:50<01:35, 288.74batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13375/40960 [00:50<01:35, 288.74batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  33%|▎| 13431/40960 [00:51<01:36, 285.56batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  33%|▎| 13431/40960 [00:51<01:36, 285.56batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  33%|▎| 13488/40960 [00:51<01:36, 285.13batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  33%|▎| 13488/40960 [00:51<01:36, 285.13batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13548/40960 [00:51<01:34, 289.09batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13548/40960 [00:51<01:34, 289.09batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13604/40960 [00:51<01:35, 285.28batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13604/40960 [00:51<01:35, 285.28batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13657/40960 [00:51<01:37, 278.87batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  33%|▎| 13657/40960 [00:51<01:37, 278.87batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  33%|▎| 13715/40960 [00:52<01:36, 281.26batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  33%|▎| 13715/40960 [00:52<01:36, 281.26batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  34%|▎| 13770/40960 [00:52<01:37, 278.61batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  34%|▎| 13770/40960 [00:52<01:37, 278.61batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  34%|▎| 13826/40960 [00:52<01:37, 278.78batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  34%|▎| 13826/40960 [00:52<01:37, 278.78batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  34%|▎| 13877/40960 [00:52<01:40, 270.42batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  34%|▎| 13877/40960 [00:52<01:40, 270.42batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  34%|▎| 13927/40960 [00:52<01:43, 262.01batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  34%|▎| 13927/40960 [00:52<01:43, 262.01batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  34%|▎| 13984/40960 [00:53<01:40, 268.14batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  34%|▎| 13984/40960 [00:53<01:40, 268.14batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  34%|▎| 14044/40960 [00:53<01:37, 276.96batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  34%|▎| 14044/40960 [00:53<01:37, 276.96batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  34%|▎| 14102/40960 [00:53<01:36, 279.54batches/s, l2_loss: 0.0857 - round_los\u001b[A\n",
      "Training:  34%|▎| 14102/40960 [00:53<01:36, 279.54batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  35%|▎| 14154/40960 [00:53<01:38, 272.74batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  35%|▎| 14154/40960 [00:53<01:38, 272.74batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  35%|▎| 14210/40960 [00:53<01:37, 274.36batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  35%|▎| 14210/40960 [00:53<01:37, 274.36batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  35%|▎| 14264/40960 [00:54<01:37, 272.79batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  35%|▎| 14264/40960 [00:54<01:37, 272.79batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  35%|▎| 14323/40960 [00:54<01:35, 279.37batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  35%|▎| 14323/40960 [00:54<01:35, 279.37batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  35%|▎| 14379/40960 [00:54<01:35, 279.36batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  35%|▎| 14379/40960 [00:54<01:35, 279.36batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  35%|▎| 14437/40960 [00:54<01:34, 281.98batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  35%|▎| 14437/40960 [00:54<01:34, 281.98batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  35%|▎| 14495/40960 [00:54<01:33, 284.08batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  35%|▎| 14495/40960 [00:54<01:33, 284.08batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  36%|▎| 14552/40960 [00:55<01:32, 283.99batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  36%|▎| 14552/40960 [00:55<01:32, 283.99batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  36%|▎| 14600/40960 [00:55<01:37, 269.47batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  36%|▎| 14600/40960 [00:55<01:37, 269.47batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14651/40960 [00:55<01:39, 264.93batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14651/40960 [00:55<01:39, 264.93batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14710/40960 [00:55<01:36, 272.60batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14710/40960 [00:55<01:36, 272.60batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  36%|▎| 14767/40960 [00:55<01:35, 274.58batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  36%|▎| 14767/40960 [00:55<01:35, 274.58batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14826/40960 [00:56<01:33, 279.53batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14826/40960 [00:56<01:33, 279.53batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14883/40960 [00:56<01:33, 280.34batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14883/40960 [00:56<01:33, 280.34batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14932/40960 [00:56<01:36, 269.40batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  36%|▎| 14932/40960 [00:56<01:36, 269.40batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 14982/40960 [00:56<01:38, 263.47batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 14982/40960 [00:56<01:38, 263.47batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 15029/40960 [00:56<01:42, 254.09batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 15029/40960 [00:56<01:42, 254.09batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  37%|▎| 15072/40960 [00:57<01:47, 240.83batches/s, l2_loss: 0.0856 - round_los\u001b[A\n",
      "Training:  37%|▎| 15072/40960 [00:57<01:47, 240.83batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 15120/40960 [00:57<01:47, 240.36batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 15120/40960 [00:57<01:47, 240.36batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  37%|▎| 15171/40960 [00:57<01:45, 243.30batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  37%|▎| 15171/40960 [00:57<01:45, 243.30batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  37%|▎| 15223/40960 [00:57<01:44, 246.82batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  37%|▎| 15223/40960 [00:57<01:44, 246.82batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 15276/40960 [00:57<01:42, 251.76batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 15276/40960 [00:57<01:42, 251.76batches/s, l2_loss: 0.0855 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15325/40960 [00:58<01:42, 249.37batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  37%|▎| 15325/40960 [00:58<01:42, 249.37batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  38%|▍| 15385/40960 [00:58<01:37, 263.29batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  38%|▍| 15385/40960 [00:58<01:37, 263.29batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  38%|▍| 15446/40960 [00:58<01:32, 275.29batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  38%|▍| 15446/40960 [00:58<01:32, 275.29batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  38%|▍| 15508/40960 [00:58<01:29, 285.10batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  38%|▍| 15508/40960 [00:58<01:29, 285.10batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  38%|▍| 15567/40960 [00:58<01:28, 287.11batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  38%|▍| 15567/40960 [00:58<01:28, 287.11batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  38%|▍| 15626/40960 [00:59<01:27, 288.12batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  38%|▍| 15626/40960 [00:59<01:27, 288.12batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  38%|▍| 15684/40960 [00:59<01:27, 288.53batches/s, l2_loss: 0.0855 - round_los\u001b[A\n",
      "Training:  38%|▍| 15684/40960 [00:59<01:27, 288.53batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  38%|▍| 15743/40960 [00:59<01:26, 290.05batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  38%|▍| 15743/40960 [00:59<01:26, 290.05batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  39%|▍| 15801/40960 [00:59<01:26, 289.32batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  39%|▍| 15801/40960 [00:59<01:26, 289.32batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  39%|▍| 15858/40960 [00:59<01:27, 286.36batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  39%|▍| 15858/40960 [00:59<01:27, 286.36batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  39%|▍| 15915/40960 [01:00<01:27, 285.37batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  39%|▍| 15915/40960 [01:00<01:27, 285.37batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  39%|▍| 15974/40960 [01:00<01:26, 288.10batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  39%|▍| 15974/40960 [01:00<01:26, 288.10batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  39%|▍| 16026/40960 [01:00<01:29, 279.39batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  39%|▍| 16026/40960 [01:00<01:29, 279.39batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  39%|▍| 16081/40960 [01:00<01:29, 276.48batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  39%|▍| 16081/40960 [01:00<01:29, 276.48batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  39%|▍| 16135/40960 [01:00<01:30, 274.42batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  39%|▍| 16135/40960 [01:00<01:30, 274.42batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  40%|▍| 16193/40960 [01:01<01:29, 278.04batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  40%|▍| 16193/40960 [01:01<01:29, 278.04batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16248/40960 [01:01<01:29, 276.83batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16248/40960 [01:01<01:29, 276.83batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16300/40960 [01:01<01:30, 271.00batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16300/40960 [01:01<01:30, 271.00batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16349/40960 [01:01<01:33, 262.70batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16349/40960 [01:01<01:33, 262.70batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16402/40960 [01:01<01:33, 262.18batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16402/40960 [01:01<01:33, 262.18batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16457/40960 [01:02<01:32, 264.99batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16457/40960 [01:02<01:32, 264.99batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  40%|▍| 16510/40960 [01:02<01:32, 263.37batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  40%|▍| 16510/40960 [01:02<01:32, 263.37batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16560/40960 [01:02<01:34, 258.56batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  40%|▍| 16560/40960 [01:02<01:34, 258.56batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16612/40960 [01:02<01:34, 258.31batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16612/40960 [01:02<01:34, 258.31batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16665/40960 [01:02<01:33, 259.09batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16665/40960 [01:02<01:33, 259.09batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  41%|▍| 16707/40960 [01:03<01:39, 244.04batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  41%|▍| 16707/40960 [01:03<01:39, 244.04batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  41%|▍| 16761/40960 [01:03<01:36, 251.52batches/s, l2_loss: 0.0854 - round_los\u001b[A\n",
      "Training:  41%|▍| 16761/40960 [01:03<01:36, 251.52batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16816/40960 [01:03<01:33, 258.07batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16816/40960 [01:03<01:33, 258.07batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16876/40960 [01:03<01:29, 269.77batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16876/40960 [01:03<01:29, 269.77batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16931/40960 [01:03<01:28, 271.23batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16931/40960 [01:03<01:28, 271.23batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16987/40960 [01:04<01:27, 273.12batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  41%|▍| 16987/40960 [01:04<01:27, 273.12batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17045/40960 [01:04<01:26, 277.57batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17045/40960 [01:04<01:26, 277.57batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17105/40960 [01:04<01:24, 282.62batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17105/40960 [01:04<01:24, 282.62batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  42%|▍| 17162/40960 [01:04<01:24, 283.30batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  42%|▍| 17162/40960 [01:04<01:24, 283.30batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17221/40960 [01:04<01:22, 286.59batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17221/40960 [01:04<01:22, 286.59batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  42%|▍| 17282/40960 [01:05<01:21, 290.44batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  42%|▍| 17282/40960 [01:05<01:21, 290.44batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17338/40960 [01:05<01:22, 286.91batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17338/40960 [01:05<01:22, 286.91batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17386/40960 [01:05<01:26, 272.29batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  42%|▍| 17386/40960 [01:05<01:26, 272.29batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  43%|▍| 17435/40960 [01:05<01:29, 262.84batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  43%|▍| 17435/40960 [01:05<01:29, 262.84batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17495/40960 [01:05<01:25, 272.88batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17495/40960 [01:05<01:25, 272.88batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17548/40960 [01:06<01:26, 269.81batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17548/40960 [01:06<01:26, 269.81batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  43%|▍| 17592/40960 [01:06<01:31, 254.29batches/s, l2_loss: 0.0853 - round_los\u001b[A\n",
      "Training:  43%|▍| 17592/40960 [01:06<01:31, 254.29batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17644/40960 [01:06<01:31, 255.14batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17644/40960 [01:06<01:31, 255.14batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17703/40960 [01:06<01:27, 266.73batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17703/40960 [01:06<01:27, 266.73batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  43%|▍| 17758/40960 [01:06<01:26, 268.49batches/s, l2_loss: 0.0852 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17758/40960 [01:06<01:26, 268.49batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  43%|▍| 17816/40960 [01:07<01:24, 274.05batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  43%|▍| 17816/40960 [01:07<01:24, 274.05batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 17866/40960 [01:07<01:27, 265.28batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 17866/40960 [01:07<01:27, 265.28batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  44%|▍| 17914/40960 [01:07<01:29, 256.77batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  44%|▍| 17914/40960 [01:07<01:29, 256.77batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 17959/40960 [01:07<01:33, 247.22batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 17959/40960 [01:07<01:33, 247.22batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 18014/40960 [01:08<01:30, 254.57batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 18014/40960 [01:08<01:30, 254.57batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 18066/40960 [01:08<01:29, 254.97batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 18066/40960 [01:08<01:29, 254.97batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 18114/40960 [01:08<01:31, 249.88batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 18114/40960 [01:08<01:31, 249.88batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  44%|▍| 18166/40960 [01:08<01:30, 251.71batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  44%|▍| 18166/40960 [01:08<01:30, 251.71batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 18222/40960 [01:08<01:27, 260.00batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  44%|▍| 18222/40960 [01:08<01:27, 260.00batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  45%|▍| 18279/40960 [01:09<01:25, 266.51batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  45%|▍| 18279/40960 [01:09<01:25, 266.51batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  45%|▍| 18335/40960 [01:09<01:24, 269.24batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  45%|▍| 18335/40960 [01:09<01:24, 269.24batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  45%|▍| 18391/40960 [01:09<01:23, 271.42batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  45%|▍| 18391/40960 [01:09<01:23, 271.42batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  45%|▍| 18451/40960 [01:09<01:20, 279.19batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  45%|▍| 18451/40960 [01:09<01:20, 279.19batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  45%|▍| 18502/40960 [01:09<01:22, 271.50batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  45%|▍| 18502/40960 [01:09<01:22, 271.50batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  45%|▍| 18554/40960 [01:10<01:23, 267.34batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  45%|▍| 18554/40960 [01:10<01:23, 267.34batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  45%|▍| 18608/40960 [01:10<01:23, 267.18batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  45%|▍| 18608/40960 [01:10<01:23, 267.18batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  46%|▍| 18662/40960 [01:10<01:23, 266.89batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  46%|▍| 18662/40960 [01:10<01:23, 266.89batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  46%|▍| 18701/40960 [01:10<01:30, 245.27batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  46%|▍| 18701/40960 [01:10<01:30, 245.27batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  46%|▍| 18756/40960 [01:10<01:27, 252.77batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  46%|▍| 18756/40960 [01:10<01:27, 252.77batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  46%|▍| 18811/40960 [01:11<01:25, 258.73batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  46%|▍| 18811/40960 [01:11<01:25, 258.73batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  46%|▍| 18867/40960 [01:11<01:23, 264.09batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  46%|▍| 18867/40960 [01:11<01:23, 264.09batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  46%|▍| 18924/40960 [01:11<01:21, 270.17batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  46%|▍| 18924/40960 [01:11<01:21, 270.17batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  46%|▍| 18984/40960 [01:11<01:19, 278.06batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  46%|▍| 18984/40960 [01:11<01:19, 278.06batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  46%|▍| 19037/40960 [01:11<01:20, 272.94batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  46%|▍| 19037/40960 [01:11<01:20, 272.94batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19089/40960 [01:12<01:21, 268.80batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19089/40960 [01:12<01:21, 268.80batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19133/40960 [01:12<01:26, 253.27batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19133/40960 [01:12<01:26, 253.27batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19186/40960 [01:12<01:25, 255.99batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19186/40960 [01:12<01:25, 255.99batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19247/40960 [01:12<01:20, 269.51batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19247/40960 [01:12<01:20, 269.51batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19308/40960 [01:12<01:17, 279.24batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19308/40960 [01:12<01:17, 279.24batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19362/40960 [01:13<01:18, 275.99batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19362/40960 [01:13<01:18, 275.99batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  47%|▍| 19413/40960 [01:13<01:20, 267.68batches/s, l2_loss: 0.0852 - round_los\u001b[A\n",
      "Training:  47%|▍| 19413/40960 [01:13<01:20, 267.68batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19455/40960 [01:13<01:26, 250.01batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19455/40960 [01:13<01:26, 250.01batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19506/40960 [01:13<01:25, 250.95batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19506/40960 [01:13<01:25, 250.95batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19554/40960 [01:13<01:26, 246.31batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19554/40960 [01:13<01:26, 246.31batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19609/40960 [01:14<01:24, 254.05batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19609/40960 [01:14<01:24, 254.05batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19665/40960 [01:14<01:21, 261.63batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19665/40960 [01:14<01:21, 261.63batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  48%|▍| 19725/40960 [01:14<01:18, 272.09batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  48%|▍| 19725/40960 [01:14<01:18, 272.09batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19784/40960 [01:14<01:16, 278.55batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  48%|▍| 19784/40960 [01:14<01:16, 278.55batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  48%|▍| 19842/40960 [01:14<01:15, 280.80batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  48%|▍| 19842/40960 [01:14<01:15, 280.80batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 19902/40960 [01:15<01:13, 285.55batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 19902/40960 [01:15<01:13, 285.55batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 19960/40960 [01:15<01:13, 285.67batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 19960/40960 [01:15<01:13, 285.67batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 20008/40960 [01:15<01:17, 271.78batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 20008/40960 [01:15<01:17, 271.78batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 20064/40960 [01:15<01:16, 273.14batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 20064/40960 [01:15<01:16, 273.14batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 20123/40960 [01:15<01:14, 278.66batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  49%|▍| 20123/40960 [01:15<01:14, 278.66batches/s, l2_loss: 0.0850 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|▍| 20181/40960 [01:16<01:13, 281.65batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  49%|▍| 20181/40960 [01:16<01:13, 281.65batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  49%|▍| 20237/40960 [01:16<01:13, 280.31batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  49%|▍| 20237/40960 [01:16<01:13, 280.31batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▍| 20292/40960 [01:16<01:14, 278.17batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▍| 20292/40960 [01:16<01:14, 278.17batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▍| 20349/40960 [01:16<01:13, 278.86batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▍| 20349/40960 [01:16<01:13, 278.86batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▍| 20408/40960 [01:16<01:12, 282.89batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▍| 20408/40960 [01:16<01:12, 282.89batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▍| 20468/40960 [01:17<01:11, 287.82batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▍| 20468/40960 [01:17<01:11, 287.82batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▌| 20525/40960 [01:17<01:11, 285.60batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▌| 20525/40960 [01:17<01:11, 285.60batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▌| 20577/40960 [01:17<01:13, 277.41batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▌| 20577/40960 [01:17<01:13, 277.41batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▌| 20623/40960 [01:17<01:17, 261.97batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▌| 20623/40960 [01:17<01:17, 261.97batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▌| 20665/40960 [01:17<01:23, 244.32batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  50%|▌| 20665/40960 [01:17<01:23, 244.32batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  51%|▌| 20718/40960 [01:18<01:20, 250.18batches/s, l2_loss: 0.0851 - round_los\u001b[A\n",
      "Training:  51%|▌| 20718/40960 [01:18<01:20, 250.18batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 20769/40960 [01:18<01:20, 251.21batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 20769/40960 [01:18<01:20, 251.21batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 20824/40960 [01:18<01:18, 256.58batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 20824/40960 [01:18<01:18, 256.58batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 20885/40960 [01:18<01:14, 270.13batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 20885/40960 [01:18<01:14, 270.13batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 20944/40960 [01:18<01:12, 276.46batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 20944/40960 [01:18<01:12, 276.46batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 21002/40960 [01:19<01:11, 280.28batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 21002/40960 [01:19<01:11, 280.28batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 21056/40960 [01:19<01:11, 276.71batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  51%|▌| 21056/40960 [01:19<01:11, 276.71batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21109/40960 [01:19<01:12, 272.92batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21109/40960 [01:19<01:12, 272.92batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21158/40960 [01:19<01:14, 264.16batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21158/40960 [01:19<01:14, 264.16batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21209/40960 [01:19<01:15, 261.17batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21209/40960 [01:19<01:15, 261.17batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21268/40960 [01:20<01:12, 270.31batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21268/40960 [01:20<01:12, 270.31batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21320/40960 [01:20<01:13, 266.49batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21320/40960 [01:20<01:13, 266.49batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21369/40960 [01:20<01:15, 259.34batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21369/40960 [01:20<01:15, 259.34batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21427/40960 [01:20<01:12, 268.46batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21427/40960 [01:20<01:12, 268.46batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21488/40960 [01:20<01:09, 278.69batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  52%|▌| 21488/40960 [01:20<01:09, 278.69batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  53%|▌| 21543/40960 [01:21<01:10, 277.18batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  53%|▌| 21543/40960 [01:21<01:10, 277.18batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  53%|▌| 21601/40960 [01:21<01:08, 280.61batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  53%|▌| 21601/40960 [01:21<01:08, 280.61batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  53%|▌| 21660/40960 [01:21<01:07, 284.39batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  53%|▌| 21660/40960 [01:21<01:07, 284.39batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  53%|▌| 21714/40960 [01:21<01:08, 279.85batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  53%|▌| 21714/40960 [01:21<01:08, 279.85batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  53%|▌| 21763/40960 [01:21<01:11, 267.55batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  53%|▌| 21763/40960 [01:21<01:11, 267.55batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  53%|▌| 21814/40960 [01:22<01:12, 263.67batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  53%|▌| 21814/40960 [01:22<01:12, 263.67batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  53%|▌| 21872/40960 [01:22<01:10, 271.44batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  53%|▌| 21872/40960 [01:22<01:10, 271.44batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 21933/40960 [01:22<01:07, 281.30batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 21933/40960 [01:22<01:07, 281.30batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 21988/40960 [01:22<01:07, 279.27batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 21988/40960 [01:22<01:07, 279.27batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  54%|▌| 22042/40960 [01:22<01:08, 274.75batches/s, l2_loss: 0.0850 - round_los\u001b[A\n",
      "Training:  54%|▌| 22042/40960 [01:22<01:08, 274.75batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22092/40960 [01:23<01:10, 266.01batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22092/40960 [01:23<01:10, 266.01batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22146/40960 [01:23<01:10, 266.15batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22146/40960 [01:23<01:10, 266.15batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22197/40960 [01:23<01:11, 262.19batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22197/40960 [01:23<01:11, 262.19batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22248/40960 [01:23<01:12, 258.63batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22248/40960 [01:23<01:12, 258.63batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22304/40960 [01:23<01:10, 263.82batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  54%|▌| 22304/40960 [01:23<01:10, 263.82batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22363/40960 [01:24<01:08, 272.65batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22363/40960 [01:24<01:08, 272.65batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22418/40960 [01:24<01:08, 272.14batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22418/40960 [01:24<01:08, 272.14batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22472/40960 [01:24<01:08, 271.00batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22472/40960 [01:24<01:08, 271.00batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22532/40960 [01:24<01:05, 279.34batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22532/40960 [01:24<01:05, 279.34batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22588/40960 [01:24<01:06, 278.09batches/s, l2_loss: 0.0849 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22588/40960 [01:24<01:06, 278.09batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22641/40960 [01:25<01:06, 273.57batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22641/40960 [01:25<01:06, 273.57batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22697/40960 [01:25<01:06, 274.15batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  55%|▌| 22697/40960 [01:25<01:06, 274.15batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22752/40960 [01:25<01:06, 273.24batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22752/40960 [01:25<01:06, 273.24batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22805/40960 [01:25<01:07, 270.31batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22805/40960 [01:25<01:07, 270.31batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22863/40960 [01:25<01:05, 276.08batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22863/40960 [01:25<01:05, 276.08batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22920/40960 [01:26<01:04, 278.31batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22920/40960 [01:26<01:04, 278.31batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22977/40960 [01:26<01:04, 278.53batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 22977/40960 [01:26<01:04, 278.53batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  56%|▌| 23034/40960 [01:26<01:03, 280.41batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  56%|▌| 23034/40960 [01:26<01:03, 280.41batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 23091/40960 [01:26<01:03, 280.80batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  56%|▌| 23091/40960 [01:26<01:03, 280.80batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23146/40960 [01:26<01:03, 278.64batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23146/40960 [01:26<01:03, 278.64batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23201/40960 [01:27<01:03, 277.53batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23201/40960 [01:27<01:03, 277.53batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23252/40960 [01:27<01:05, 269.49batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23252/40960 [01:27<01:05, 269.49batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23311/40960 [01:27<01:03, 276.09batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23311/40960 [01:27<01:03, 276.09batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23356/40960 [01:27<01:07, 260.46batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  57%|▌| 23356/40960 [01:27<01:07, 260.46batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  57%|▌| 23414/40960 [01:27<01:05, 268.10batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  57%|▌| 23414/40960 [01:28<01:05, 268.10batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  57%|▌| 23469/40960 [01:28<01:05, 268.77batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  57%|▌| 23469/40960 [01:28<01:05, 268.77batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  57%|▌| 23527/40960 [01:28<01:03, 274.18batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  57%|▌| 23527/40960 [01:28<01:03, 274.18batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  58%|▌| 23586/40960 [01:28<01:02, 279.14batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  58%|▌| 23586/40960 [01:28<01:02, 279.14batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  58%|▌| 23639/40960 [01:28<01:03, 274.37batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  58%|▌| 23639/40960 [01:28<01:03, 274.37batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  58%|▌| 23697/40960 [01:29<01:01, 278.66batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  58%|▌| 23697/40960 [01:29<01:01, 278.66batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  58%|▌| 23751/40960 [01:29<01:02, 275.94batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  58%|▌| 23751/40960 [01:29<01:02, 275.94batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  58%|▌| 23797/40960 [01:29<01:05, 261.37batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  58%|▌| 23797/40960 [01:29<01:05, 261.37batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  58%|▌| 23853/40960 [01:29<01:04, 265.96batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  58%|▌| 23853/40960 [01:29<01:04, 265.96batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  58%|▌| 23913/40960 [01:29<01:01, 275.25batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  58%|▌| 23913/40960 [01:29<01:01, 275.25batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 23966/40960 [01:30<01:02, 271.68batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 23966/40960 [01:30<01:02, 271.68batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 24022/40960 [01:30<01:02, 273.13batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 24022/40960 [01:30<01:02, 273.13batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  59%|▌| 24083/40960 [01:30<00:59, 281.33batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  59%|▌| 24083/40960 [01:30<00:59, 281.33batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 24141/40960 [01:30<00:59, 283.88batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 24141/40960 [01:30<00:59, 283.88batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  59%|▌| 24194/40960 [01:30<01:00, 277.64batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  59%|▌| 24194/40960 [01:30<01:00, 277.64batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 24248/40960 [01:31<01:00, 274.75batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 24248/40960 [01:31<01:00, 274.75batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  59%|▌| 24294/40960 [01:31<01:03, 261.07batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  59%|▌| 24294/40960 [01:31<01:03, 261.07batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 24345/40960 [01:31<01:04, 258.01batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  59%|▌| 24345/40960 [01:31<01:04, 258.01batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24401/40960 [01:31<01:02, 264.28batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24401/40960 [01:31<01:02, 264.28batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24445/40960 [01:31<01:06, 250.05batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24445/40960 [01:31<01:06, 250.05batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24495/40960 [01:32<01:06, 248.52batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24495/40960 [01:32<01:06, 248.52batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  60%|▌| 24547/40960 [01:32<01:05, 250.88batches/s, l2_loss: 0.0849 - round_los\u001b[A\n",
      "Training:  60%|▌| 24547/40960 [01:32<01:05, 250.88batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24606/40960 [01:32<01:02, 263.77batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24606/40960 [01:32<01:02, 263.77batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24663/40960 [01:32<01:00, 268.91batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24663/40960 [01:32<01:00, 268.91batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24720/40960 [01:32<00:59, 273.33batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24720/40960 [01:32<00:59, 273.33batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24774/40960 [01:33<00:59, 271.68batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  60%|▌| 24774/40960 [01:33<00:59, 271.68batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [01:33<01:00, 268.07batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 24826/40960 [01:33<01:00, 268.07batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 24885/40960 [01:33<00:58, 274.94batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 24885/40960 [01:33<00:58, 274.94batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 24940/40960 [01:33<00:58, 273.85batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 24940/40960 [01:33<00:58, 273.85batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 24994/40960 [01:33<00:58, 271.99batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 24994/40960 [01:33<00:58, 271.99batches/s, l2_loss: 0.0848 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 25049/40960 [01:34<00:58, 271.67batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 25049/40960 [01:34<00:58, 271.67batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  61%|▌| 25104/40960 [01:34<00:58, 272.37batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  61%|▌| 25104/40960 [01:34<00:58, 272.37batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 25161/40960 [01:34<00:57, 275.60batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  61%|▌| 25161/40960 [01:34<00:57, 275.60batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  62%|▌| 25215/40960 [01:34<00:57, 273.61batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  62%|▌| 25215/40960 [01:34<00:57, 273.61batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25260/40960 [01:34<01:00, 257.98batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25260/40960 [01:34<01:00, 257.98batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25303/40960 [01:35<01:04, 242.93batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25303/40960 [01:35<01:04, 242.93batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  62%|▌| 25352/40960 [01:35<01:04, 243.51batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  62%|▌| 25352/40960 [01:35<01:04, 243.51batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25391/40960 [01:35<01:08, 228.57batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25391/40960 [01:35<01:08, 228.57batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25431/40960 [01:35<01:11, 217.45batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25431/40960 [01:35<01:11, 217.45batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25482/40960 [01:35<01:07, 228.40batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25482/40960 [01:35<01:07, 228.40batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25541/40960 [01:36<01:02, 247.73batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25541/40960 [01:36<01:02, 247.73batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25594/40960 [01:36<01:00, 251.95batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25594/40960 [01:36<01:00, 251.95batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25648/40960 [01:36<00:59, 256.72batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25648/40960 [01:36<00:59, 256.72batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25697/40960 [01:36<01:00, 252.45batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25697/40960 [01:36<01:00, 252.45batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25749/40960 [01:36<00:59, 254.47batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25749/40960 [01:36<00:59, 254.47batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25808/40960 [01:37<00:57, 265.28batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25808/40960 [01:37<00:57, 265.28batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  63%|▋| 25868/40960 [01:37<00:54, 275.15batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  63%|▋| 25868/40960 [01:37<00:54, 275.15batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25928/40960 [01:37<00:53, 281.88batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25928/40960 [01:37<00:53, 281.88batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25983/40960 [01:37<00:53, 279.79batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  63%|▋| 25983/40960 [01:37<00:53, 279.79batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26042/40960 [01:37<00:52, 282.89batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26042/40960 [01:37<00:52, 282.89batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26094/40960 [01:38<00:54, 274.77batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26094/40960 [01:38<00:54, 274.77batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  64%|▋| 26146/40960 [01:38<00:54, 269.47batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  64%|▋| 26146/40960 [01:38<00:54, 269.47batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26195/40960 [01:38<00:56, 262.10batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26195/40960 [01:38<00:56, 262.10batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26242/40960 [01:38<00:58, 252.62batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26242/40960 [01:38<00:58, 252.62batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26298/40960 [01:38<00:56, 259.87batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26298/40960 [01:38<00:56, 259.87batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26358/40960 [01:39<00:53, 270.61batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26358/40960 [01:39<00:53, 270.61batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26417/40960 [01:39<00:52, 276.65batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  64%|▋| 26417/40960 [01:39<00:52, 276.65batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26469/40960 [01:39<00:53, 270.70batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26469/40960 [01:39<00:53, 270.70batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26504/40960 [01:39<00:59, 241.96batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26504/40960 [01:39<00:59, 241.96batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26542/40960 [01:39<01:04, 223.53batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26542/40960 [01:39<01:04, 223.53batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26593/40960 [01:40<01:02, 231.42batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26593/40960 [01:40<01:02, 231.42batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26647/40960 [01:40<00:59, 241.69batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26647/40960 [01:40<00:59, 241.69batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26702/40960 [01:40<00:56, 250.68batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26702/40960 [01:40<00:56, 250.68batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  65%|▋| 26757/40960 [01:40<00:55, 257.06batches/s, l2_loss: 0.0848 - round_los\u001b[A\n",
      "Training:  65%|▋| 26757/40960 [01:40<00:55, 257.06batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26815/40960 [01:40<00:53, 266.32batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  65%|▋| 26815/40960 [01:40<00:53, 266.32batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 26871/40960 [01:41<00:52, 268.92batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 26871/40960 [01:41<00:52, 268.92batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 26928/40960 [01:41<00:51, 273.05batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 26928/40960 [01:41<00:51, 273.05batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 26984/40960 [01:41<00:51, 273.75batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 26984/40960 [01:41<00:51, 273.75batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 27036/40960 [01:41<00:51, 268.89batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 27036/40960 [01:41<00:51, 268.89batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 27090/40960 [01:41<00:51, 267.89batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 27090/40960 [01:41<00:51, 267.89batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 27140/40960 [01:42<00:52, 262.37batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 27140/40960 [01:42<00:52, 262.37batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 27199/40960 [01:42<00:50, 271.12batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  66%|▋| 27199/40960 [01:42<00:50, 271.12batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27260/40960 [01:42<00:48, 281.01batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27260/40960 [01:42<00:48, 281.01batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27322/40960 [01:42<00:47, 288.83batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27322/40960 [01:42<00:47, 288.83batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27382/40960 [01:42<00:46, 291.80batches/s, l2_loss: 0.0847 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|▋| 27382/40960 [01:42<00:46, 291.80batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27441/40960 [01:43<00:46, 292.57batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27441/40960 [01:43<00:46, 292.57batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27493/40960 [01:43<00:47, 281.55batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27493/40960 [01:43<00:47, 281.55batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27553/40960 [01:43<00:46, 286.36batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27553/40960 [01:43<00:46, 286.36batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27613/40960 [01:43<00:45, 290.31batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  67%|▋| 27613/40960 [01:43<00:45, 290.31batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27670/40960 [01:43<00:46, 287.72batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27670/40960 [01:43<00:46, 287.72batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27725/40960 [01:44<00:46, 282.61batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27725/40960 [01:44<00:46, 282.61batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27772/40960 [01:44<00:49, 267.19batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27772/40960 [01:44<00:49, 267.19batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27811/40960 [01:44<00:53, 244.67batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27811/40960 [01:44<00:53, 244.67batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27860/40960 [01:44<00:53, 243.34batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27860/40960 [01:44<00:53, 243.34batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27910/40960 [01:44<00:53, 245.31batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27910/40960 [01:44<00:53, 245.31batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27965/40960 [01:45<00:51, 252.79batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 27965/40960 [01:45<00:51, 252.79batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 28026/40960 [01:45<00:48, 267.50batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  68%|▋| 28026/40960 [01:45<00:48, 267.50batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28083/40960 [01:45<00:47, 271.55batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28083/40960 [01:45<00:47, 271.55batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  69%|▋| 28136/40960 [01:45<00:47, 269.07batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  69%|▋| 28136/40960 [01:45<00:47, 269.07batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28175/40960 [01:45<00:52, 244.94batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28175/40960 [01:46<00:52, 244.94batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28232/40960 [01:46<00:49, 256.21batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28232/40960 [01:46<00:49, 256.21batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28284/40960 [01:46<00:49, 255.95batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28284/40960 [01:46<00:49, 255.95batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28332/40960 [01:46<00:50, 250.71batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28332/40960 [01:46<00:50, 250.71batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  69%|▋| 28390/40960 [01:46<00:48, 261.75batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  69%|▋| 28390/40960 [01:46<00:48, 261.75batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28444/40960 [01:47<00:47, 263.01batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  69%|▋| 28444/40960 [01:47<00:47, 263.01batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  70%|▋| 28499/40960 [01:47<00:46, 265.74batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  70%|▋| 28499/40960 [01:47<00:46, 265.74batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  70%|▋| 28555/40960 [01:47<00:46, 269.16batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  70%|▋| 28555/40960 [01:47<00:46, 269.16batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  70%|▋| 28609/40960 [01:47<00:46, 268.00batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  70%|▋| 28609/40960 [01:47<00:46, 268.00batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  70%|▋| 28664/40960 [01:47<00:45, 268.95batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  70%|▋| 28664/40960 [01:47<00:45, 268.95batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  70%|▋| 28714/40960 [01:48<00:46, 263.31batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  70%|▋| 28714/40960 [01:48<00:46, 263.31batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  70%|▋| 28776/40960 [01:48<00:44, 276.67batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  70%|▋| 28776/40960 [01:48<00:44, 276.67batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  70%|▋| 28834/40960 [01:48<00:43, 280.49batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  70%|▋| 28834/40960 [01:48<00:43, 280.49batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  71%|▋| 28885/40960 [01:48<00:44, 270.87batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  71%|▋| 28885/40960 [01:48<00:44, 270.87batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  71%|▋| 28946/40960 [01:48<00:42, 279.87batches/s, l2_loss: 0.0847 - round_los\u001b[A\n",
      "Training:  71%|▋| 28946/40960 [01:48<00:42, 279.87batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29006/40960 [01:49<00:41, 284.71batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29006/40960 [01:49<00:41, 284.71batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29059/40960 [01:49<00:42, 278.17batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29059/40960 [01:49<00:42, 278.17batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29112/40960 [01:49<00:43, 273.47batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29112/40960 [01:49<00:43, 273.47batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29156/40960 [01:49<00:46, 256.09batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29156/40960 [01:49<00:46, 256.09batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29201/40960 [01:49<00:47, 246.83batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29201/40960 [01:49<00:47, 246.83batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29258/40960 [01:50<00:45, 256.89batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  71%|▋| 29258/40960 [01:50<00:45, 256.89batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29317/40960 [01:50<00:43, 267.64batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29317/40960 [01:50<00:43, 267.64batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29372/40960 [01:50<00:42, 269.74batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29372/40960 [01:50<00:42, 269.74batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29424/40960 [01:50<00:43, 265.53batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29424/40960 [01:50<00:43, 265.53batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29482/40960 [01:50<00:42, 272.29batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29482/40960 [01:50<00:42, 272.29batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29541/40960 [01:51<00:41, 277.84batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29541/40960 [01:51<00:41, 277.84batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29599/40960 [01:51<00:40, 280.56batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29599/40960 [01:51<00:40, 280.56batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29651/40960 [01:51<00:41, 272.70batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  72%|▋| 29651/40960 [01:51<00:41, 272.70batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29700/40960 [01:51<00:42, 263.08batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29700/40960 [01:51<00:42, 263.08batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29760/40960 [01:51<00:40, 273.24batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29760/40960 [01:51<00:40, 273.24batches/s, l2_loss: 0.0846 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|▋| 29819/40960 [01:52<00:39, 278.67batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29819/40960 [01:52<00:39, 278.67batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29874/40960 [01:52<00:40, 276.84batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29874/40960 [01:52<00:40, 276.84batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29929/40960 [01:52<00:40, 275.55batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29929/40960 [01:52<00:40, 275.55batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29990/40960 [01:52<00:38, 284.11batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 29990/40960 [01:52<00:38, 284.11batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 30052/40960 [01:52<00:37, 291.30batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  73%|▋| 30052/40960 [01:52<00:37, 291.30batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30107/40960 [01:53<00:38, 285.54batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30107/40960 [01:53<00:38, 285.54batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30164/40960 [01:53<00:38, 283.98batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30164/40960 [01:53<00:38, 283.98batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30214/40960 [01:53<00:39, 273.31batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30214/40960 [01:53<00:39, 273.31batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30265/40960 [01:53<00:40, 266.93batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30265/40960 [01:53<00:40, 266.93batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30321/40960 [01:53<00:39, 270.61batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30321/40960 [01:53<00:39, 270.61batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30374/40960 [01:54<00:39, 267.69batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30374/40960 [01:54<00:39, 267.69batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30428/40960 [01:54<00:39, 267.79batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30428/40960 [01:54<00:39, 267.79batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30473/40960 [01:54<00:41, 252.96batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  74%|▋| 30473/40960 [01:54<00:41, 252.96batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▋| 30521/40960 [01:54<00:42, 248.45batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▋| 30521/40960 [01:54<00:42, 248.45batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▋| 30564/40960 [01:54<00:44, 235.86batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▋| 30564/40960 [01:54<00:44, 235.86batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▋| 30620/40960 [01:55<00:41, 248.87batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▋| 30620/40960 [01:55<00:41, 248.87batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▋| 30670/40960 [01:55<00:41, 248.52batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▋| 30670/40960 [01:55<00:41, 248.52batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▊| 30720/40960 [01:55<00:41, 248.31batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▊| 30720/40960 [01:55<00:41, 248.31batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▊| 30771/40960 [01:55<00:40, 249.52batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▊| 30771/40960 [01:55<00:40, 249.52batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▊| 30829/40960 [01:55<00:38, 261.07batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▊| 30829/40960 [01:55<00:38, 261.07batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▊| 30882/40960 [01:56<00:38, 262.23batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  75%|▊| 30882/40960 [01:56<00:38, 262.23batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 30932/40960 [01:56<00:38, 257.52batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 30932/40960 [01:56<00:38, 257.52batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 30978/40960 [01:56<00:40, 248.78batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 30978/40960 [01:56<00:40, 248.78batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31024/40960 [01:56<00:41, 241.89batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31024/40960 [01:56<00:41, 241.89batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31080/40960 [01:56<00:39, 252.06batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31080/40960 [01:56<00:39, 252.06batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31132/40960 [01:57<00:38, 253.58batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31132/40960 [01:57<00:38, 253.58batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31192/40960 [01:57<00:36, 266.87batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31192/40960 [01:57<00:36, 266.87batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31250/40960 [01:57<00:35, 272.66batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31250/40960 [01:57<00:35, 272.66batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31304/40960 [01:57<00:35, 270.33batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  76%|▊| 31304/40960 [01:57<00:35, 270.33batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31349/40960 [01:57<00:37, 256.10batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31349/40960 [01:57<00:37, 256.10batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31399/40960 [01:58<00:37, 254.12batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31399/40960 [01:58<00:37, 254.12batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31455/40960 [01:58<00:36, 261.66batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31455/40960 [01:58<00:36, 261.66batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31514/40960 [01:58<00:34, 270.43batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31514/40960 [01:58<00:34, 270.43batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31570/40960 [01:58<00:34, 273.16batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31570/40960 [01:58<00:34, 273.16batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31618/40960 [01:58<00:35, 262.46batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31618/40960 [01:58<00:35, 262.46batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31660/40960 [01:59<00:37, 246.29batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31660/40960 [01:59<00:37, 246.29batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31717/40960 [01:59<00:35, 257.00batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  77%|▊| 31717/40960 [01:59<00:35, 257.00batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31773/40960 [01:59<00:34, 263.52batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31773/40960 [01:59<00:34, 263.52batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31829/40960 [01:59<00:34, 267.05batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31829/40960 [01:59<00:34, 267.05batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31886/40960 [01:59<00:33, 272.23batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31886/40960 [01:59<00:33, 272.23batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31939/40960 [02:00<00:33, 269.40batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31939/40960 [02:00<00:33, 269.40batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31993/40960 [02:00<00:33, 269.42batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 31993/40960 [02:00<00:33, 269.42batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 32052/40960 [02:00<00:32, 276.00batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 32052/40960 [02:00<00:32, 276.00batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 32109/40960 [02:00<00:31, 277.42batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  78%|▊| 32109/40960 [02:00<00:31, 277.42batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  79%|▊| 32161/40960 [02:00<00:32, 270.77batches/s, l2_loss: 0.0846 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|▊| 32161/40960 [02:00<00:32, 270.77batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  79%|▊| 32220/40960 [02:01<00:31, 276.95batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  79%|▊| 32220/40960 [02:01<00:31, 276.95batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  79%|▊| 32278/40960 [02:01<00:31, 279.78batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  79%|▊| 32278/40960 [02:01<00:31, 279.78batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  79%|▊| 32336/40960 [02:01<00:30, 281.64batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  79%|▊| 32336/40960 [02:01<00:30, 281.64batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  79%|▊| 32396/40960 [02:01<00:29, 286.56batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  79%|▊| 32396/40960 [02:01<00:29, 286.56batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  79%|▊| 32449/40960 [02:01<00:30, 279.33batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  79%|▊| 32449/40960 [02:01<00:30, 279.33batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  79%|▊| 32501/40960 [02:02<00:30, 272.96batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  79%|▊| 32501/40960 [02:02<00:30, 272.96batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  79%|▊| 32557/40960 [02:02<00:30, 274.78batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  79%|▊| 32557/40960 [02:02<00:30, 274.78batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32617/40960 [02:02<00:29, 280.74batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32617/40960 [02:02<00:29, 280.74batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  80%|▊| 32670/40960 [02:02<00:30, 274.10batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  80%|▊| 32670/40960 [02:02<00:30, 274.10batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32726/40960 [02:02<00:29, 275.55batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32726/40960 [02:02<00:29, 275.55batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  80%|▊| 32767/40960 [02:03<00:32, 253.25batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  80%|▊| 32767/40960 [02:03<00:32, 253.25batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32821/40960 [02:03<00:31, 258.00batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32821/40960 [02:03<00:31, 258.00batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32879/40960 [02:03<00:30, 266.67batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32879/40960 [02:03<00:30, 266.67batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32937/40960 [02:03<00:29, 273.14batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  80%|▊| 32937/40960 [02:03<00:29, 273.14batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 32994/40960 [02:03<00:28, 275.91batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 32994/40960 [02:03<00:28, 275.91batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33048/40960 [02:04<00:29, 272.62batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33048/40960 [02:04<00:29, 272.62batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33107/40960 [02:04<00:28, 278.40batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33107/40960 [02:04<00:28, 278.40batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33167/40960 [02:04<00:27, 283.23batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33167/40960 [02:04<00:27, 283.23batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33221/40960 [02:04<00:27, 278.38batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33221/40960 [02:04<00:27, 278.38batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33274/40960 [02:04<00:28, 274.21batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33274/40960 [02:05<00:28, 274.21batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33324/40960 [02:05<00:28, 265.43batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33324/40960 [02:05<00:28, 265.43batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33372/40960 [02:05<00:29, 257.57batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  81%|▊| 33372/40960 [02:05<00:29, 257.57batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33424/40960 [02:05<00:29, 257.66batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33424/40960 [02:05<00:29, 257.66batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33484/40960 [02:05<00:27, 270.07batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33484/40960 [02:05<00:27, 270.07batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33541/40960 [02:06<00:27, 273.13batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33541/40960 [02:06<00:27, 273.13batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33600/40960 [02:06<00:26, 278.71batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33600/40960 [02:06<00:26, 278.71batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33657/40960 [02:06<00:26, 280.26batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33657/40960 [02:06<00:26, 280.26batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33717/40960 [02:06<00:25, 284.93batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33717/40960 [02:06<00:25, 284.93batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33774/40960 [02:06<00:25, 284.07batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  82%|▊| 33774/40960 [02:06<00:25, 284.07batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 33828/40960 [02:07<00:25, 278.11batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 33828/40960 [02:07<00:25, 278.11batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  83%|▊| 33876/40960 [02:07<00:26, 265.07batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  83%|▊| 33876/40960 [02:07<00:26, 265.07batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  83%|▊| 33932/40960 [02:07<00:26, 268.79batches/s, l2_loss: 0.0846 - round_los\u001b[A\n",
      "Training:  83%|▊| 33932/40960 [02:07<00:26, 268.79batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 33986/40960 [02:07<00:25, 268.83batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 33986/40960 [02:07<00:25, 268.83batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 34043/40960 [02:07<00:25, 271.19batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 34043/40960 [02:07<00:25, 271.19batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 34092/40960 [02:08<00:26, 262.56batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 34092/40960 [02:08<00:26, 262.56batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 34138/40960 [02:08<00:27, 250.65batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 34138/40960 [02:08<00:27, 250.65batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 34190/40960 [02:08<00:26, 253.31batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  83%|▊| 34190/40960 [02:08<00:26, 253.31batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34248/40960 [02:08<00:25, 262.99batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34248/40960 [02:08<00:25, 262.99batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34296/40960 [02:08<00:26, 256.02batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34296/40960 [02:08<00:26, 256.02batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34352/40960 [02:09<00:25, 262.48batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34352/40960 [02:09<00:25, 262.48batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34408/40960 [02:09<00:24, 266.51batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34408/40960 [02:09<00:24, 266.51batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34467/40960 [02:09<00:23, 273.52batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34467/40960 [02:09<00:23, 273.52batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34510/40960 [02:09<00:25, 252.80batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34510/40960 [02:09<00:25, 252.80batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34552/40960 [02:09<00:26, 239.79batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34552/40960 [02:09<00:26, 239.79batches/s, l2_loss: 0.0845 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|▊| 34599/40960 [02:10<00:26, 237.26batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  84%|▊| 34599/40960 [02:10<00:26, 237.26batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34654/40960 [02:10<00:25, 247.71batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34654/40960 [02:10<00:25, 247.71batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34703/40960 [02:10<00:25, 246.29batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34703/40960 [02:10<00:25, 246.29batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34762/40960 [02:10<00:23, 259.28batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34762/40960 [02:10<00:23, 259.28batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34818/40960 [02:10<00:23, 265.02batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34818/40960 [02:10<00:23, 265.02batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34865/40960 [02:11<00:23, 254.42batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34865/40960 [02:11<00:23, 254.42batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34920/40960 [02:11<00:23, 257.70batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34920/40960 [02:11<00:23, 257.70batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34973/40960 [02:11<00:23, 259.52batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  85%|▊| 34973/40960 [02:11<00:23, 259.52batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35026/40960 [02:11<00:22, 259.82batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35026/40960 [02:11<00:22, 259.82batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35075/40960 [02:11<00:23, 253.82batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35075/40960 [02:11<00:23, 253.82batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35125/40960 [02:12<00:23, 252.45batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35125/40960 [02:12<00:23, 252.45batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35185/40960 [02:12<00:21, 265.12batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35185/40960 [02:12<00:21, 265.12batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35241/40960 [02:12<00:21, 269.25batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35241/40960 [02:12<00:21, 269.25batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35296/40960 [02:12<00:21, 269.64batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35296/40960 [02:12<00:21, 269.64batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35356/40960 [02:12<00:20, 277.94batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35356/40960 [02:12<00:20, 277.94batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35408/40960 [02:13<00:20, 270.90batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  86%|▊| 35408/40960 [02:13<00:20, 270.90batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35468/40960 [02:13<00:19, 279.15batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35468/40960 [02:13<00:19, 279.15batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35526/40960 [02:13<00:19, 282.30batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35526/40960 [02:13<00:19, 282.30batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35577/40960 [02:13<00:19, 273.78batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35577/40960 [02:13<00:19, 273.78batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35630/40960 [02:13<00:19, 269.30batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35630/40960 [02:13<00:19, 269.30batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35690/40960 [02:14<00:18, 277.83batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35690/40960 [02:14<00:18, 277.83batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35742/40960 [02:14<00:19, 271.34batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35742/40960 [02:14<00:19, 271.34batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35788/40960 [02:14<00:19, 258.63batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35788/40960 [02:14<00:19, 258.63batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35828/40960 [02:14<00:21, 240.33batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  87%|▊| 35828/40960 [02:14<00:21, 240.33batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 35888/40960 [02:14<00:19, 257.57batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 35888/40960 [02:14<00:19, 257.57batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 35940/40960 [02:15<00:19, 257.01batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 35940/40960 [02:15<00:19, 257.01batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 35990/40960 [02:15<00:19, 254.63batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 35990/40960 [02:15<00:19, 254.63batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 36039/40960 [02:15<00:19, 250.57batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 36039/40960 [02:15<00:19, 250.57batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 36094/40960 [02:15<00:18, 257.80batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 36094/40960 [02:15<00:18, 257.80batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 36149/40960 [02:15<00:18, 262.30batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 36149/40960 [02:15<00:18, 262.30batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 36207/40960 [02:16<00:17, 269.34batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  88%|▉| 36207/40960 [02:16<00:17, 269.34batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36264/40960 [02:16<00:17, 273.40batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36264/40960 [02:16<00:17, 273.40batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36320/40960 [02:16<00:16, 274.05batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36320/40960 [02:16<00:16, 274.05batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36380/40960 [02:16<00:16, 281.68batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36380/40960 [02:16<00:16, 281.68batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36439/40960 [02:16<00:15, 284.26batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36439/40960 [02:16<00:15, 284.26batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36497/40960 [02:17<00:15, 285.97batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36497/40960 [02:17<00:15, 285.97batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36555/40960 [02:17<00:15, 285.93batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36555/40960 [02:17<00:15, 285.93batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36607/40960 [02:17<00:15, 277.31batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36607/40960 [02:17<00:15, 277.31batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36652/40960 [02:17<00:16, 261.39batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  89%|▉| 36652/40960 [02:17<00:16, 261.39batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36711/40960 [02:17<00:15, 271.22batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36711/40960 [02:17<00:15, 271.22batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36771/40960 [02:18<00:15, 278.82batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36771/40960 [02:18<00:15, 278.82batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36829/40960 [02:18<00:14, 281.71batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36829/40960 [02:18<00:14, 281.71batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36890/40960 [02:18<00:14, 288.12batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36890/40960 [02:18<00:14, 288.12batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36952/40960 [02:18<00:13, 293.54batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 36952/40960 [02:18<00:13, 293.54batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  90%|▉| 37012/40960 [02:18<00:13, 295.30batches/s, l2_loss: 0.0845 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 37012/40960 [02:18<00:13, 295.30batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [02:19<00:13, 292.57batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [02:19<00:13, 292.57batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37125/40960 [02:19<00:13, 285.77batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37125/40960 [02:19<00:13, 285.77batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37176/40960 [02:19<00:13, 276.27batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37176/40960 [02:19<00:13, 276.27batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37233/40960 [02:19<00:13, 278.13batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37233/40960 [02:19<00:13, 278.13batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37283/40960 [02:19<00:13, 269.48batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37283/40960 [02:19<00:13, 269.48batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37345/40960 [02:20<00:12, 280.80batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37345/40960 [02:20<00:12, 280.80batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37406/40960 [02:20<00:12, 287.86batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37406/40960 [02:20<00:12, 287.86batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37460/40960 [02:20<00:12, 281.77batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  91%|▉| 37460/40960 [02:20<00:12, 281.77batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37508/40960 [02:20<00:12, 266.43batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37508/40960 [02:20<00:12, 266.43batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37557/40960 [02:20<00:13, 258.42batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37557/40960 [02:20<00:13, 258.42batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37615/40960 [02:21<00:12, 267.31batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37615/40960 [02:21<00:12, 267.31batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37666/40960 [02:21<00:12, 261.80batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37666/40960 [02:21<00:12, 261.80batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37718/40960 [02:21<00:12, 260.73batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37718/40960 [02:21<00:12, 260.73batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37766/40960 [02:21<00:12, 253.81batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  92%|▉| 37766/40960 [02:21<00:12, 253.81batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  92%|▉| 37816/40960 [02:21<00:12, 252.10batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  92%|▉| 37816/40960 [02:22<00:12, 252.10batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  92%|▉| 37866/40960 [02:22<00:12, 250.22batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  92%|▉| 37866/40960 [02:22<00:12, 250.22batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  93%|▉| 37920/40960 [02:22<00:11, 255.42batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  93%|▉| 37920/40960 [02:22<00:11, 255.42batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 37969/40960 [02:22<00:11, 252.20batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 37969/40960 [02:22<00:11, 252.20batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  93%|▉| 38016/40960 [02:22<00:12, 245.07batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  93%|▉| 38016/40960 [02:22<00:12, 245.07batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 38067/40960 [02:23<00:11, 247.52batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 38067/40960 [02:23<00:11, 247.52batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 38122/40960 [02:23<00:11, 255.07batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 38122/40960 [02:23<00:11, 255.07batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  93%|▉| 38175/40960 [02:23<00:10, 257.33batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  93%|▉| 38175/40960 [02:23<00:10, 257.33batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 38225/40960 [02:23<00:10, 254.69batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 38225/40960 [02:23<00:10, 254.69batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 38277/40960 [02:23<00:10, 254.93batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  93%|▉| 38277/40960 [02:23<00:10, 254.93batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38327/40960 [02:24<00:10, 253.40batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38327/40960 [02:24<00:10, 253.40batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38383/40960 [02:24<00:09, 260.04batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38383/40960 [02:24<00:09, 260.04batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  94%|▉| 38434/40960 [02:24<00:09, 256.95batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  94%|▉| 38434/40960 [02:24<00:09, 256.95batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  94%|▉| 38486/40960 [02:24<00:09, 257.02batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  94%|▉| 38486/40960 [02:24<00:09, 257.02batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  94%|▉| 38543/40960 [02:24<00:09, 263.79batches/s, l2_loss: 0.0845 - round_los\u001b[A\n",
      "Training:  94%|▉| 38543/40960 [02:24<00:09, 263.79batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38598/40960 [02:25<00:08, 266.91batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38598/40960 [02:25<00:08, 266.91batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38650/40960 [02:25<00:08, 264.58batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38650/40960 [02:25<00:08, 264.58batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38703/40960 [02:25<00:08, 263.87batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  94%|▉| 38703/40960 [02:25<00:08, 263.87batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38764/40960 [02:25<00:07, 276.02batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38764/40960 [02:25<00:07, 276.02batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38822/40960 [02:25<00:07, 279.13batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38822/40960 [02:25<00:07, 279.13batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38873/40960 [02:26<00:07, 271.06batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38873/40960 [02:26<00:07, 271.06batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38917/40960 [02:26<00:07, 255.80batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38917/40960 [02:26<00:07, 255.80batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38969/40960 [02:26<00:07, 256.04batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 38969/40960 [02:26<00:07, 256.04batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 39022/40960 [02:26<00:07, 258.09batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 39022/40960 [02:26<00:07, 258.09batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 39080/40960 [02:26<00:07, 266.85batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  95%|▉| 39080/40960 [02:26<00:07, 266.85batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39141/40960 [02:27<00:06, 277.20batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39141/40960 [02:27<00:06, 277.20batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39198/40960 [02:27<00:06, 278.36batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39198/40960 [02:27<00:06, 278.36batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39249/40960 [02:27<00:06, 270.44batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39249/40960 [02:27<00:06, 270.44batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39303/40960 [02:27<00:06, 270.25batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39303/40960 [02:27<00:06, 270.25batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39340/40960 [02:27<00:06, 244.36batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39340/40960 [02:27<00:06, 244.36batches/s, l2_loss: 0.0844 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|▉| 39372/40960 [02:28<00:07, 218.29batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39372/40960 [02:28<00:07, 218.29batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39429/40960 [02:28<00:06, 237.56batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39429/40960 [02:28<00:06, 237.56batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39487/40960 [02:28<00:05, 252.85batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  96%|▉| 39487/40960 [02:28<00:05, 252.85batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39543/40960 [02:28<00:05, 260.53batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39543/40960 [02:28<00:05, 260.53batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39599/40960 [02:28<00:05, 265.43batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39599/40960 [02:28<00:05, 265.43batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39659/40960 [02:29<00:04, 274.84batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39659/40960 [02:29<00:04, 274.84batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39717/40960 [02:29<00:04, 278.96batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39717/40960 [02:29<00:04, 278.96batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39772/40960 [02:29<00:04, 276.81batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39772/40960 [02:29<00:04, 276.81batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39829/40960 [02:29<00:04, 278.16batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39829/40960 [02:29<00:04, 278.16batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39887/40960 [02:29<00:03, 280.65batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  97%|▉| 39887/40960 [02:29<00:03, 280.65batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 39944/40960 [02:30<00:03, 280.53batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 39944/40960 [02:30<00:03, 280.53batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40000/40960 [02:30<00:03, 280.25batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40000/40960 [02:30<00:03, 280.25batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40056/40960 [02:30<00:03, 279.52batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40056/40960 [02:30<00:03, 279.52batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [02:30<00:02, 282.63batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [02:30<00:02, 282.63batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40174/40960 [02:30<00:02, 285.82batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40174/40960 [02:30<00:02, 285.82batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40228/40960 [02:31<00:02, 279.14batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40228/40960 [02:31<00:02, 279.14batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40280/40960 [02:31<00:02, 273.11batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40280/40960 [02:31<00:02, 273.11batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40337/40960 [02:31<00:02, 276.51batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  98%|▉| 40337/40960 [02:31<00:02, 276.51batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40397/40960 [02:31<00:01, 282.53batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40397/40960 [02:31<00:01, 282.53batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40452/40960 [02:31<00:01, 279.31batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40452/40960 [02:31<00:01, 279.31batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40502/40960 [02:32<00:01, 270.16batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40502/40960 [02:32<00:01, 270.16batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40555/40960 [02:32<00:01, 268.03batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40555/40960 [02:32<00:01, 268.03batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40613/40960 [02:32<00:01, 273.31batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40613/40960 [02:32<00:01, 273.31batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40671/40960 [02:32<00:01, 277.86batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40671/40960 [02:32<00:01, 277.86batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40707/40960 [02:32<00:01, 246.70batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training:  99%|▉| 40707/40960 [02:32<00:01, 246.70batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training: 100%|▉| 40758/40960 [02:33<00:00, 248.87batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training: 100%|▉| 40758/40960 [02:33<00:00, 248.87batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training: 100%|▉| 40818/40960 [02:33<00:00, 263.03batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training: 100%|▉| 40818/40960 [02:33<00:00, 263.03batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training: 100%|▉| 40874/40960 [02:33<00:00, 267.46batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training: 100%|▉| 40874/40960 [02:33<00:00, 267.46batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training: 100%|▉| 40932/40960 [02:33<00:00, 273.43batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "Training: 100%|▉| 40932/40960 [02:33<00:00, 273.43batches/s, l2_loss: 0.0844 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:23:13.673066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  65%|▋| 17/26 [35:35<19:42, 131.43s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:23:16.814615: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:23:23.235875: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<23:53:08,  2.10s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<23:53:08,  2.10s/batches, l2_loss: 0.4485 - round_loss:\u001b[A\n",
      "Training:   0%| | 56/40960 [00:02<20:27, 33.31batches/s, l2_loss: 0.4485 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 56/40960 [00:02<20:27, 33.31batches/s, l2_loss: 0.6260 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 113/40960 [00:02<09:44, 69.88batches/s, l2_loss: 0.6260 - round_loss: \u001b[A\n",
      "Training:   0%| | 113/40960 [00:02<09:44, 69.88batches/s, l2_loss: 0.5816 - round_loss: \u001b[A\n",
      "Training:   0%| | 158/40960 [00:02<07:04, 96.04batches/s, l2_loss: 0.5816 - round_loss: \u001b[A\n",
      "Training:   0%| | 158/40960 [00:02<07:04, 96.04batches/s, l2_loss: 0.6175 - round_loss: \u001b[A\n",
      "Training:   1%| | 217/40960 [00:02<05:02, 134.88batches/s, l2_loss: 0.6175 - round_loss:\u001b[A\n",
      "Training:   1%| | 217/40960 [00:02<05:02, 134.88batches/s, l2_loss: 0.5973 - round_loss:\u001b[A\n",
      "Training:   1%| | 279/40960 [00:03<03:54, 173.14batches/s, l2_loss: 0.5973 - round_loss:\u001b[A\n",
      "Training:   1%| | 279/40960 [00:03<03:54, 173.14batches/s, l2_loss: 0.6243 - round_loss:\u001b[A\n",
      "Training:   1%| | 341/40960 [00:03<03:18, 205.05batches/s, l2_loss: 0.6243 - round_loss:\u001b[A\n",
      "Training:   1%| | 341/40960 [00:03<03:18, 205.05batches/s, l2_loss: 0.6007 - round_loss:\u001b[A\n",
      "Training:   1%| | 391/40960 [00:03<03:07, 216.35batches/s, l2_loss: 0.6007 - round_loss:\u001b[A\n",
      "Training:   1%| | 391/40960 [00:03<03:07, 216.35batches/s, l2_loss: 0.5854 - round_loss:\u001b[A\n",
      "Training:   1%| | 440/40960 [00:03<03:01, 223.82batches/s, l2_loss: 0.5854 - round_loss:\u001b[A\n",
      "Training:   1%| | 440/40960 [00:03<03:01, 223.82batches/s, l2_loss: 0.5897 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%| | 494/40960 [00:03<02:51, 236.04batches/s, l2_loss: 0.5897 - round_loss:\u001b[A\n",
      "Training:   1%| | 494/40960 [00:03<02:51, 236.04batches/s, l2_loss: 0.5810 - round_loss:\u001b[A\n",
      "Training:   1%| | 551/40960 [00:04<02:42, 248.86batches/s, l2_loss: 0.5810 - round_loss:\u001b[A\n",
      "Training:   1%| | 551/40960 [00:04<02:42, 248.86batches/s, l2_loss: 0.5709 - round_loss:\u001b[A\n",
      "Training:   1%| | 603/40960 [00:04<02:40, 251.04batches/s, l2_loss: 0.5709 - round_loss:\u001b[A\n",
      "Training:   1%| | 603/40960 [00:04<02:40, 251.04batches/s, l2_loss: 0.5741 - round_loss:\u001b[A\n",
      "Training:   2%| | 646/40960 [00:04<02:48, 238.70batches/s, l2_loss: 0.5741 - round_loss:\u001b[A\n",
      "Training:   2%| | 646/40960 [00:04<02:48, 238.70batches/s, l2_loss: 0.5686 - round_loss:\u001b[A\n",
      "Training:   2%| | 698/40960 [00:04<02:45, 243.35batches/s, l2_loss: 0.5686 - round_loss:\u001b[A\n",
      "Training:   2%| | 698/40960 [00:04<02:45, 243.35batches/s, l2_loss: 0.5697 - round_loss:\u001b[A\n",
      "Training:   2%| | 758/40960 [00:04<02:34, 259.73batches/s, l2_loss: 0.5697 - round_loss:\u001b[A\n",
      "Training:   2%| | 758/40960 [00:04<02:34, 259.73batches/s, l2_loss: 0.5665 - round_loss:\u001b[A\n",
      "Training:   2%| | 819/40960 [00:05<02:27, 271.68batches/s, l2_loss: 0.5665 - round_loss:\u001b[A\n",
      "Training:   2%| | 819/40960 [00:05<02:27, 271.68batches/s, l2_loss: 0.5581 - round_loss:\u001b[A\n",
      "Training:   2%| | 875/40960 [00:05<02:26, 273.55batches/s, l2_loss: 0.5581 - round_loss:\u001b[A\n",
      "Training:   2%| | 875/40960 [00:05<02:26, 273.55batches/s, l2_loss: 0.5595 - round_loss:\u001b[A\n",
      "Training:   2%| | 934/40960 [00:05<02:23, 279.44batches/s, l2_loss: 0.5595 - round_loss:\u001b[A\n",
      "Training:   2%| | 934/40960 [00:05<02:23, 279.44batches/s, l2_loss: 0.5530 - round_loss:\u001b[A\n",
      "Training:   2%| | 995/40960 [00:05<02:19, 286.69batches/s, l2_loss: 0.5530 - round_loss:\u001b[A\n",
      "Training:   2%| | 995/40960 [00:05<02:19, 286.69batches/s, l2_loss: 0.5575 - round_loss:\u001b[A\n",
      "Training:   3%| | 1057/40960 [00:05<02:16, 293.21batches/s, l2_loss: 0.5575 - round_loss\u001b[A\n",
      "Training:   3%| | 1057/40960 [00:05<02:16, 293.21batches/s, l2_loss: 0.5543 - round_loss\u001b[A\n",
      "Training:   3%| | 1119/40960 [00:06<02:13, 297.39batches/s, l2_loss: 0.5543 - round_loss\u001b[A\n",
      "Training:   3%| | 1119/40960 [00:06<02:13, 297.39batches/s, l2_loss: 0.5503 - round_loss\u001b[A\n",
      "Training:   3%| | 1179/40960 [00:06<02:13, 297.48batches/s, l2_loss: 0.5503 - round_loss\u001b[A\n",
      "Training:   3%| | 1179/40960 [00:06<02:13, 297.48batches/s, l2_loss: 0.5460 - round_loss\u001b[A\n",
      "Training:   3%| | 1236/40960 [00:06<02:15, 293.74batches/s, l2_loss: 0.5460 - round_loss\u001b[A\n",
      "Training:   3%| | 1236/40960 [00:06<02:15, 293.74batches/s, l2_loss: 0.5437 - round_loss\u001b[A\n",
      "Training:   3%| | 1294/40960 [00:06<02:15, 292.34batches/s, l2_loss: 0.5437 - round_loss\u001b[A\n",
      "Training:   3%| | 1294/40960 [00:06<02:15, 292.34batches/s, l2_loss: 0.5442 - round_loss\u001b[A\n",
      "Training:   3%| | 1355/40960 [00:06<02:14, 295.15batches/s, l2_loss: 0.5442 - round_loss\u001b[A\n",
      "Training:   3%| | 1355/40960 [00:06<02:14, 295.15batches/s, l2_loss: 0.5418 - round_loss\u001b[A\n",
      "Training:   3%| | 1414/40960 [00:07<02:14, 294.32batches/s, l2_loss: 0.5418 - round_loss\u001b[A\n",
      "Training:   3%| | 1414/40960 [00:07<02:14, 294.32batches/s, l2_loss: 0.5432 - round_loss\u001b[A\n",
      "Training:   4%| | 1469/40960 [00:07<02:16, 288.43batches/s, l2_loss: 0.5432 - round_loss\u001b[A\n",
      "Training:   4%| | 1469/40960 [00:07<02:16, 288.43batches/s, l2_loss: 0.5418 - round_loss\u001b[A\n",
      "Training:   4%| | 1531/40960 [00:07<02:14, 294.24batches/s, l2_loss: 0.5418 - round_loss\u001b[A\n",
      "Training:   4%| | 1531/40960 [00:07<02:14, 294.24batches/s, l2_loss: 0.5370 - round_loss\u001b[A\n",
      "Training:   4%| | 1590/40960 [00:07<02:14, 293.08batches/s, l2_loss: 0.5370 - round_loss\u001b[A\n",
      "Training:   4%| | 1590/40960 [00:07<02:14, 293.08batches/s, l2_loss: 0.5334 - round_loss\u001b[A\n",
      "Training:   4%| | 1653/40960 [00:07<02:11, 298.30batches/s, l2_loss: 0.5334 - round_loss\u001b[A\n",
      "Training:   4%| | 1653/40960 [00:07<02:11, 298.30batches/s, l2_loss: 0.5343 - round_loss\u001b[A\n",
      "Training:   4%| | 1717/40960 [00:08<02:08, 304.40batches/s, l2_loss: 0.5343 - round_loss\u001b[A\n",
      "Training:   4%| | 1717/40960 [00:08<02:08, 304.40batches/s, l2_loss: 0.5340 - round_loss\u001b[A\n",
      "Training:   4%| | 1777/40960 [00:08<02:09, 301.73batches/s, l2_loss: 0.5340 - round_loss\u001b[A\n",
      "Training:   4%| | 1777/40960 [00:08<02:09, 301.73batches/s, l2_loss: 0.5312 - round_loss\u001b[A\n",
      "Training:   4%| | 1834/40960 [00:08<02:12, 295.64batches/s, l2_loss: 0.5312 - round_loss\u001b[A\n",
      "Training:   4%| | 1834/40960 [00:08<02:12, 295.64batches/s, l2_loss: 0.5318 - round_loss\u001b[A\n",
      "Training:   5%| | 1892/40960 [00:08<02:12, 293.96batches/s, l2_loss: 0.5318 - round_loss\u001b[A\n",
      "Training:   5%| | 1892/40960 [00:08<02:12, 293.96batches/s, l2_loss: 0.5273 - round_loss\u001b[A\n",
      "Training:   5%| | 1944/40960 [00:08<02:17, 283.77batches/s, l2_loss: 0.5273 - round_loss\u001b[A\n",
      "Training:   5%| | 1944/40960 [00:08<02:17, 283.77batches/s, l2_loss: 0.5271 - round_loss\u001b[A\n",
      "Training:   5%| | 2002/40960 [00:09<02:16, 284.40batches/s, l2_loss: 0.5271 - round_loss\u001b[A\n",
      "Training:   5%| | 2002/40960 [00:09<02:16, 284.40batches/s, l2_loss: 0.5245 - round_loss\u001b[A\n",
      "Training:   5%| | 2060/40960 [00:09<02:16, 284.98batches/s, l2_loss: 0.5245 - round_loss\u001b[A\n",
      "Training:   5%| | 2060/40960 [00:09<02:16, 284.98batches/s, l2_loss: 0.5248 - round_loss\u001b[A\n",
      "Training:   5%| | 2117/40960 [00:09<02:16, 284.55batches/s, l2_loss: 0.5248 - round_loss\u001b[A\n",
      "Training:   5%| | 2117/40960 [00:09<02:16, 284.55batches/s, l2_loss: 0.5212 - round_loss\u001b[A\n",
      "Training:   5%| | 2164/40960 [00:09<02:24, 268.90batches/s, l2_loss: 0.5212 - round_loss\u001b[A\n",
      "Training:   5%| | 2164/40960 [00:09<02:24, 268.90batches/s, l2_loss: 0.5229 - round_loss\u001b[A\n",
      "Training:   5%| | 2214/40960 [00:09<02:27, 262.70batches/s, l2_loss: 0.5229 - round_loss\u001b[A\n",
      "Training:   5%| | 2214/40960 [00:09<02:27, 262.70batches/s, l2_loss: 0.5242 - round_loss\u001b[A\n",
      "Training:   6%| | 2274/40960 [00:10<02:21, 272.81batches/s, l2_loss: 0.5242 - round_loss\u001b[A\n",
      "Training:   6%| | 2274/40960 [00:10<02:21, 272.81batches/s, l2_loss: 0.5225 - round_loss\u001b[A\n",
      "Training:   6%| | 2333/40960 [00:10<02:18, 278.99batches/s, l2_loss: 0.5225 - round_loss\u001b[A\n",
      "Training:   6%| | 2333/40960 [00:10<02:18, 278.99batches/s, l2_loss: 0.5191 - round_loss\u001b[A\n",
      "Training:   6%| | 2395/40960 [00:10<02:14, 287.51batches/s, l2_loss: 0.5191 - round_loss\u001b[A\n",
      "Training:   6%| | 2395/40960 [00:10<02:14, 287.51batches/s, l2_loss: 0.5198 - round_loss\u001b[A\n",
      "Training:   6%| | 2451/40960 [00:10<02:15, 284.58batches/s, l2_loss: 0.5198 - round_loss\u001b[A\n",
      "Training:   6%| | 2451/40960 [00:10<02:15, 284.58batches/s, l2_loss: 0.5179 - round_loss\u001b[A\n",
      "Training:   6%| | 2510/40960 [00:10<02:14, 286.27batches/s, l2_loss: 0.5179 - round_loss\u001b[A\n",
      "Training:   6%| | 2510/40960 [00:10<02:14, 286.27batches/s, l2_loss: 0.5177 - round_loss\u001b[A\n",
      "Training:   6%| | 2565/40960 [00:11<02:16, 281.55batches/s, l2_loss: 0.5177 - round_loss\u001b[A\n",
      "Training:   6%| | 2565/40960 [00:11<02:16, 281.55batches/s, l2_loss: 0.5163 - round_loss\u001b[A\n",
      "Training:   6%| | 2628/40960 [00:11<02:11, 290.57batches/s, l2_loss: 0.5163 - round_loss\u001b[A\n",
      "Training:   6%| | 2628/40960 [00:11<02:11, 290.57batches/s, l2_loss: 0.5167 - round_loss\u001b[A\n",
      "Training:   7%| | 2684/40960 [00:11<02:13, 287.41batches/s, l2_loss: 0.5167 - round_loss\u001b[A\n",
      "Training:   7%| | 2684/40960 [00:11<02:13, 287.41batches/s, l2_loss: 0.5151 - round_loss\u001b[A\n",
      "Training:   7%| | 2735/40960 [00:11<02:17, 277.09batches/s, l2_loss: 0.5151 - round_loss\u001b[A\n",
      "Training:   7%| | 2735/40960 [00:11<02:17, 277.09batches/s, l2_loss: 0.5136 - round_loss\u001b[A\n",
      "Training:   7%| | 2784/40960 [00:11<02:23, 266.61batches/s, l2_loss: 0.5136 - round_loss\u001b[A\n",
      "Training:   7%| | 2784/40960 [00:12<02:23, 266.61batches/s, l2_loss: 0.5128 - round_loss\u001b[A\n",
      "Training:   7%| | 2837/40960 [00:12<02:23, 264.97batches/s, l2_loss: 0.5128 - round_loss\u001b[A\n",
      "Training:   7%| | 2837/40960 [00:12<02:23, 264.97batches/s, l2_loss: 0.5119 - round_loss\u001b[A\n",
      "Training:   7%| | 2893/40960 [00:12<02:21, 268.59batches/s, l2_loss: 0.5119 - round_loss\u001b[A\n",
      "Training:   7%| | 2893/40960 [00:12<02:21, 268.59batches/s, l2_loss: 0.5120 - round_loss\u001b[A\n",
      "Training:   7%| | 2944/40960 [00:12<02:23, 264.51batches/s, l2_loss: 0.5120 - round_loss\u001b[A\n",
      "Training:   7%| | 2944/40960 [00:12<02:23, 264.51batches/s, l2_loss: 0.5112 - round_loss\u001b[A\n",
      "Training:   7%| | 3000/40960 [00:12<02:21, 268.42batches/s, l2_loss: 0.5112 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 3000/40960 [00:12<02:21, 268.42batches/s, l2_loss: 0.5117 - round_loss\u001b[A\n",
      "Training:   7%| | 3054/40960 [00:13<02:21, 268.65batches/s, l2_loss: 0.5117 - round_loss\u001b[A\n",
      "Training:   7%| | 3054/40960 [00:13<02:21, 268.65batches/s, l2_loss: 0.5103 - round_loss\u001b[A\n",
      "Training:   8%| | 3105/40960 [00:13<02:23, 264.11batches/s, l2_loss: 0.5103 - round_loss\u001b[A\n",
      "Training:   8%| | 3105/40960 [00:13<02:23, 264.11batches/s, l2_loss: 0.5091 - round_loss\u001b[A\n",
      "Training:   8%| | 3163/40960 [00:13<02:19, 270.76batches/s, l2_loss: 0.5091 - round_loss\u001b[A\n",
      "Training:   8%| | 3163/40960 [00:13<02:19, 270.76batches/s, l2_loss: 0.5093 - round_loss\u001b[A\n",
      "Training:   8%| | 3207/40960 [00:13<02:29, 252.52batches/s, l2_loss: 0.5093 - round_loss\u001b[A\n",
      "Training:   8%| | 3207/40960 [00:13<02:29, 252.52batches/s, l2_loss: 0.5085 - round_loss\u001b[A\n",
      "Training:   8%| | 3266/40960 [00:13<02:22, 264.87batches/s, l2_loss: 0.5085 - round_loss\u001b[A\n",
      "Training:   8%| | 3266/40960 [00:13<02:22, 264.87batches/s, l2_loss: 0.5076 - round_loss\u001b[A\n",
      "Training:   8%| | 3325/40960 [00:14<02:17, 273.32batches/s, l2_loss: 0.5076 - round_loss\u001b[A\n",
      "Training:   8%| | 3325/40960 [00:14<02:17, 273.32batches/s, l2_loss: 0.5066 - round_loss\u001b[A\n",
      "Training:   8%| | 3376/40960 [00:14<02:20, 267.30batches/s, l2_loss: 0.5066 - round_loss\u001b[A\n",
      "Training:   8%| | 3376/40960 [00:14<02:20, 267.30batches/s, l2_loss: 0.5065 - round_loss\u001b[A\n",
      "Training:   8%| | 3438/40960 [00:14<02:14, 278.82batches/s, l2_loss: 0.5065 - round_loss\u001b[A\n",
      "Training:   8%| | 3438/40960 [00:14<02:14, 278.82batches/s, l2_loss: 0.5054 - round_loss\u001b[A\n",
      "Training:   9%| | 3494/40960 [00:14<02:14, 278.32batches/s, l2_loss: 0.5054 - round_loss\u001b[A\n",
      "Training:   9%| | 3494/40960 [00:14<02:14, 278.32batches/s, l2_loss: 0.5063 - round_loss\u001b[A\n",
      "Training:   9%| | 3543/40960 [00:14<02:20, 266.18batches/s, l2_loss: 0.5063 - round_loss\u001b[A\n",
      "Training:   9%| | 3543/40960 [00:14<02:20, 266.18batches/s, l2_loss: 0.5050 - round_loss\u001b[A\n",
      "Training:   9%| | 3577/40960 [00:15<02:38, 236.00batches/s, l2_loss: 0.5050 - round_loss\u001b[A\n",
      "Training:   9%| | 3577/40960 [00:15<02:38, 236.00batches/s, l2_loss: 0.5040 - round_loss\u001b[A\n",
      "Training:   9%| | 3632/40960 [00:15<02:31, 246.99batches/s, l2_loss: 0.5040 - round_loss\u001b[A\n",
      "Training:   9%| | 3632/40960 [00:15<02:31, 246.99batches/s, l2_loss: 0.5035 - round_loss\u001b[A\n",
      "Training:   9%| | 3696/40960 [00:15<02:18, 268.09batches/s, l2_loss: 0.5035 - round_loss\u001b[A\n",
      "Training:   9%| | 3696/40960 [00:15<02:18, 268.09batches/s, l2_loss: 0.5020 - round_loss\u001b[A\n",
      "Training:   9%| | 3749/40960 [00:15<02:19, 266.57batches/s, l2_loss: 0.5020 - round_loss\u001b[A\n",
      "Training:   9%| | 3749/40960 [00:15<02:19, 266.57batches/s, l2_loss: 0.5026 - round_loss\u001b[A\n",
      "Training:   9%| | 3804/40960 [00:15<02:18, 268.38batches/s, l2_loss: 0.5026 - round_loss\u001b[A\n",
      "Training:   9%| | 3804/40960 [00:15<02:18, 268.38batches/s, l2_loss: 0.5008 - round_loss\u001b[A\n",
      "Training:   9%| | 3854/40960 [00:16<02:21, 262.56batches/s, l2_loss: 0.5008 - round_loss\u001b[A\n",
      "Training:   9%| | 3854/40960 [00:16<02:21, 262.56batches/s, l2_loss: 0.5004 - round_loss\u001b[A\n",
      "Training:  10%| | 3905/40960 [00:16<02:23, 258.87batches/s, l2_loss: 0.5004 - round_loss\u001b[A\n",
      "Training:  10%| | 3905/40960 [00:16<02:23, 258.87batches/s, l2_loss: 0.5010 - round_loss\u001b[A\n",
      "Training:  10%| | 3958/40960 [00:16<02:22, 260.18batches/s, l2_loss: 0.5010 - round_loss\u001b[A\n",
      "Training:  10%| | 3958/40960 [00:16<02:22, 260.18batches/s, l2_loss: 0.5002 - round_loss\u001b[A\n",
      "Training:  10%| | 4007/40960 [00:16<02:26, 252.96batches/s, l2_loss: 0.5002 - round_loss\u001b[A\n",
      "Training:  10%| | 4007/40960 [00:16<02:26, 252.96batches/s, l2_loss: 0.5009 - round_loss\u001b[A\n",
      "Training:  10%| | 4059/40960 [00:16<02:24, 254.88batches/s, l2_loss: 0.5009 - round_loss\u001b[A\n",
      "Training:  10%| | 4059/40960 [00:16<02:24, 254.88batches/s, l2_loss: 0.4995 - round_loss\u001b[A\n",
      "Training:  10%| | 4110/40960 [00:17<02:24, 254.46batches/s, l2_loss: 0.4995 - round_loss\u001b[A\n",
      "Training:  10%| | 4110/40960 [00:17<02:24, 254.46batches/s, l2_loss: 0.4993 - round_loss\u001b[A\n",
      "Training:  10%| | 4166/40960 [00:17<02:20, 261.35batches/s, l2_loss: 0.4993 - round_loss\u001b[A\n",
      "Training:  10%| | 4166/40960 [00:17<02:20, 261.35batches/s, l2_loss: 0.4992 - round_loss\u001b[A\n",
      "Training:  10%| | 4222/40960 [00:17<02:18, 265.97batches/s, l2_loss: 0.4992 - round_loss\u001b[A\n",
      "Training:  10%| | 4222/40960 [00:17<02:18, 265.97batches/s, l2_loss: 0.4975 - round_loss\u001b[A\n",
      "Training:  10%| | 4273/40960 [00:17<02:20, 261.92batches/s, l2_loss: 0.4975 - round_loss\u001b[A\n",
      "Training:  10%| | 4273/40960 [00:17<02:20, 261.92batches/s, l2_loss: 0.4978 - round_loss\u001b[A\n",
      "Training:  11%| | 4331/40960 [00:17<02:15, 269.48batches/s, l2_loss: 0.4978 - round_loss\u001b[A\n",
      "Training:  11%| | 4331/40960 [00:17<02:15, 269.48batches/s, l2_loss: 0.4962 - round_loss\u001b[A\n",
      "Training:  11%| | 4384/40960 [00:18<02:16, 267.36batches/s, l2_loss: 0.4962 - round_loss\u001b[A\n",
      "Training:  11%| | 4384/40960 [00:18<02:16, 267.36batches/s, l2_loss: 0.4959 - round_loss\u001b[A\n",
      "Training:  11%| | 4437/40960 [00:18<02:17, 265.63batches/s, l2_loss: 0.4959 - round_loss\u001b[A\n",
      "Training:  11%| | 4437/40960 [00:18<02:17, 265.63batches/s, l2_loss: 0.4956 - round_loss\u001b[A\n",
      "Training:  11%| | 4485/40960 [00:18<02:22, 255.89batches/s, l2_loss: 0.4956 - round_loss\u001b[A\n",
      "Training:  11%| | 4485/40960 [00:18<02:22, 255.89batches/s, l2_loss: 0.4952 - round_loss\u001b[A\n",
      "Training:  11%| | 4538/40960 [00:18<02:20, 258.57batches/s, l2_loss: 0.4952 - round_loss\u001b[A\n",
      "Training:  11%| | 4538/40960 [00:18<02:20, 258.57batches/s, l2_loss: 0.4954 - round_loss\u001b[A\n",
      "Training:  11%| | 4593/40960 [00:18<02:18, 262.37batches/s, l2_loss: 0.4954 - round_loss\u001b[A\n",
      "Training:  11%| | 4593/40960 [00:18<02:18, 262.37batches/s, l2_loss: 0.4944 - round_loss\u001b[A\n",
      "Training:  11%| | 4649/40960 [00:19<02:15, 267.23batches/s, l2_loss: 0.4944 - round_loss\u001b[A\n",
      "Training:  11%| | 4649/40960 [00:19<02:15, 267.23batches/s, l2_loss: 0.4941 - round_loss\u001b[A\n",
      "Training:  11%| | 4709/40960 [00:19<02:11, 276.33batches/s, l2_loss: 0.4941 - round_loss\u001b[A\n",
      "Training:  11%| | 4709/40960 [00:19<02:11, 276.33batches/s, l2_loss: 0.4934 - round_loss\u001b[A\n",
      "Training:  12%| | 4762/40960 [00:19<02:13, 271.91batches/s, l2_loss: 0.4934 - round_loss\u001b[A\n",
      "Training:  12%| | 4762/40960 [00:19<02:13, 271.91batches/s, l2_loss: 0.4926 - round_loss\u001b[A\n",
      "Training:  12%| | 4804/40960 [00:19<02:23, 252.15batches/s, l2_loss: 0.4926 - round_loss\u001b[A\n",
      "Training:  12%| | 4804/40960 [00:19<02:23, 252.15batches/s, l2_loss: 0.4929 - round_loss\u001b[A\n",
      "Training:  12%| | 4860/40960 [00:19<02:19, 259.29batches/s, l2_loss: 0.4929 - round_loss\u001b[A\n",
      "Training:  12%| | 4860/40960 [00:19<02:19, 259.29batches/s, l2_loss: 0.4924 - round_loss\u001b[A\n",
      "Training:  12%| | 4913/40960 [00:20<02:18, 260.87batches/s, l2_loss: 0.4924 - round_loss\u001b[A\n",
      "Training:  12%| | 4913/40960 [00:20<02:18, 260.87batches/s, l2_loss: 0.4914 - round_loss\u001b[A\n",
      "Training:  12%| | 4963/40960 [00:20<02:20, 256.75batches/s, l2_loss: 0.4914 - round_loss\u001b[A\n",
      "Training:  12%| | 4963/40960 [00:20<02:20, 256.75batches/s, l2_loss: 0.4908 - round_loss\u001b[A\n",
      "Training:  12%| | 5017/40960 [00:20<02:18, 260.18batches/s, l2_loss: 0.4908 - round_loss\u001b[A\n",
      "Training:  12%| | 5017/40960 [00:20<02:18, 260.18batches/s, l2_loss: 0.4912 - round_loss\u001b[A\n",
      "Training:  12%| | 5070/40960 [00:20<02:17, 260.26batches/s, l2_loss: 0.4912 - round_loss\u001b[A\n",
      "Training:  12%| | 5070/40960 [00:20<02:17, 260.26batches/s, l2_loss: 0.4897 - round_loss\u001b[A\n",
      "Training:  12%| | 5119/40960 [00:20<02:20, 255.07batches/s, l2_loss: 0.4897 - round_loss\u001b[A\n",
      "Training:  12%| | 5119/40960 [00:20<02:20, 255.07batches/s, l2_loss: 0.4905 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5174/40960 [00:21<02:17, 260.28batches/s, l2_loss: 0.4905 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5174/40960 [00:21<02:17, 260.28batches/s, l2_loss: 0.4905 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5223/40960 [00:21<02:19, 255.61batches/s, l2_loss: 0.4905 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5223/40960 [00:21<02:19, 255.61batches/s, l2_loss: 0.4900 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5276/40960 [00:21<02:18, 258.12batches/s, l2_loss: 0.4900 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5276/40960 [00:21<02:18, 258.12batches/s, l2_loss: 0.4893 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5324/40960 [00:21<02:21, 252.67batches/s, l2_loss: 0.4893 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5324/40960 [00:21<02:21, 252.67batches/s, l2_loss: 0.4892 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|▏| 5377/40960 [00:21<02:19, 255.40batches/s, l2_loss: 0.4892 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5377/40960 [00:21<02:19, 255.40batches/s, l2_loss: 0.4887 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5438/40960 [00:22<02:11, 269.99batches/s, l2_loss: 0.4887 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5438/40960 [00:22<02:11, 269.99batches/s, l2_loss: 0.4886 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5492/40960 [00:22<02:11, 269.97batches/s, l2_loss: 0.4886 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5492/40960 [00:22<02:11, 269.97batches/s, l2_loss: 0.4880 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5531/40960 [00:22<02:24, 245.57batches/s, l2_loss: 0.4880 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5531/40960 [00:22<02:24, 245.57batches/s, l2_loss: 0.4878 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5582/40960 [00:22<02:22, 247.77batches/s, l2_loss: 0.4878 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5582/40960 [00:22<02:22, 247.77batches/s, l2_loss: 0.4878 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5629/40960 [00:22<02:24, 243.67batches/s, l2_loss: 0.4878 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5629/40960 [00:22<02:24, 243.67batches/s, l2_loss: 0.4871 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5679/40960 [00:23<02:24, 244.48batches/s, l2_loss: 0.4871 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5679/40960 [00:23<02:24, 244.48batches/s, l2_loss: 0.4875 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5735/40960 [00:23<02:20, 250.67batches/s, l2_loss: 0.4875 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5735/40960 [00:23<02:20, 250.67batches/s, l2_loss: 0.4866 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5797/40960 [00:23<02:11, 267.93batches/s, l2_loss: 0.4866 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5797/40960 [00:23<02:11, 267.93batches/s, l2_loss: 0.4858 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5856/40960 [00:23<02:07, 275.18batches/s, l2_loss: 0.4858 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5856/40960 [00:23<02:07, 275.18batches/s, l2_loss: 0.4853 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5919/40960 [00:23<02:02, 286.67batches/s, l2_loss: 0.4853 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5919/40960 [00:23<02:02, 286.67batches/s, l2_loss: 0.4849 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5980/40960 [00:24<02:00, 290.76batches/s, l2_loss: 0.4849 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5980/40960 [00:24<02:00, 290.76batches/s, l2_loss: 0.4854 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6038/40960 [00:24<02:00, 290.02batches/s, l2_loss: 0.4854 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6038/40960 [00:24<02:00, 290.02batches/s, l2_loss: 0.4846 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6102/40960 [00:24<01:56, 298.75batches/s, l2_loss: 0.4846 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6102/40960 [00:24<01:56, 298.75batches/s, l2_loss: 0.4834 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6163/40960 [00:24<01:56, 299.41batches/s, l2_loss: 0.4834 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6163/40960 [00:24<01:56, 299.41batches/s, l2_loss: 0.4841 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6224/40960 [00:24<01:55, 299.55batches/s, l2_loss: 0.4841 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6224/40960 [00:24<01:55, 299.55batches/s, l2_loss: 0.4834 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6286/40960 [00:25<01:54, 302.54batches/s, l2_loss: 0.4834 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6286/40960 [00:25<01:54, 302.54batches/s, l2_loss: 0.4837 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6341/40960 [00:25<01:57, 294.01batches/s, l2_loss: 0.4837 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6341/40960 [00:25<01:57, 294.01batches/s, l2_loss: 0.4832 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6396/40960 [00:25<02:00, 287.93batches/s, l2_loss: 0.4832 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6396/40960 [00:25<02:00, 287.93batches/s, l2_loss: 0.4824 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6456/40960 [00:25<01:58, 291.13batches/s, l2_loss: 0.4824 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6456/40960 [00:25<01:58, 291.13batches/s, l2_loss: 0.4830 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6513/40960 [00:25<01:59, 288.76batches/s, l2_loss: 0.4830 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6513/40960 [00:25<01:59, 288.76batches/s, l2_loss: 0.4822 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6573/40960 [00:26<01:57, 291.78batches/s, l2_loss: 0.4822 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6573/40960 [00:26<01:57, 291.78batches/s, l2_loss: 0.4823 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6634/40960 [00:26<01:56, 294.50batches/s, l2_loss: 0.4823 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6634/40960 [00:26<01:56, 294.50batches/s, l2_loss: 0.4819 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6690/40960 [00:26<01:58, 288.47batches/s, l2_loss: 0.4819 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6690/40960 [00:26<01:58, 288.47batches/s, l2_loss: 0.4813 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6753/40960 [00:26<01:55, 295.20batches/s, l2_loss: 0.4813 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6753/40960 [00:26<01:55, 295.20batches/s, l2_loss: 0.4812 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6802/40960 [00:26<02:02, 279.16batches/s, l2_loss: 0.4812 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6802/40960 [00:26<02:02, 279.16batches/s, l2_loss: 0.4803 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6854/40960 [00:27<02:05, 272.02batches/s, l2_loss: 0.4803 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6854/40960 [00:27<02:05, 272.02batches/s, l2_loss: 0.4803 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6906/40960 [00:27<02:07, 267.21batches/s, l2_loss: 0.4803 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6906/40960 [00:27<02:07, 267.21batches/s, l2_loss: 0.4802 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6968/40960 [00:27<02:01, 279.90batches/s, l2_loss: 0.4802 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6968/40960 [00:27<02:01, 279.90batches/s, l2_loss: 0.4800 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7026/40960 [00:27<02:00, 282.48batches/s, l2_loss: 0.4800 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7026/40960 [00:27<02:00, 282.48batches/s, l2_loss: 0.4797 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7089/40960 [00:27<01:56, 291.00batches/s, l2_loss: 0.4797 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7089/40960 [00:27<01:56, 291.00batches/s, l2_loss: 0.4786 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7154/40960 [00:28<01:52, 300.33batches/s, l2_loss: 0.4786 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7154/40960 [00:28<01:52, 300.33batches/s, l2_loss: 0.4790 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7214/40960 [00:28<01:52, 300.14batches/s, l2_loss: 0.4790 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7214/40960 [00:28<01:52, 300.14batches/s, l2_loss: 0.4791 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7264/40960 [00:28<01:58, 283.97batches/s, l2_loss: 0.4791 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7264/40960 [00:28<01:58, 283.97batches/s, l2_loss: 0.4788 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7322/40960 [00:28<01:57, 285.58batches/s, l2_loss: 0.4788 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7322/40960 [00:28<01:57, 285.58batches/s, l2_loss: 0.4778 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7382/40960 [00:28<01:56, 289.03batches/s, l2_loss: 0.4778 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7382/40960 [00:28<01:56, 289.03batches/s, l2_loss: 0.4775 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7440/40960 [00:29<01:55, 289.26batches/s, l2_loss: 0.4775 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7440/40960 [00:29<01:55, 289.26batches/s, l2_loss: 0.4775 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7502/40960 [00:29<01:53, 294.44batches/s, l2_loss: 0.4775 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7502/40960 [00:29<01:53, 294.44batches/s, l2_loss: 0.4775 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7567/40960 [00:29<01:50, 302.49batches/s, l2_loss: 0.4775 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7567/40960 [00:29<01:50, 302.49batches/s, l2_loss: 0.4773 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7631/40960 [00:29<01:48, 307.27batches/s, l2_loss: 0.4773 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7631/40960 [00:29<01:48, 307.27batches/s, l2_loss: 0.4766 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7691/40960 [00:29<01:49, 303.10batches/s, l2_loss: 0.4766 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7691/40960 [00:29<01:49, 303.10batches/s, l2_loss: 0.4768 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7743/40960 [00:30<01:54, 289.64batches/s, l2_loss: 0.4768 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7743/40960 [00:30<01:54, 289.64batches/s, l2_loss: 0.4768 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7797/40960 [00:30<01:57, 282.87batches/s, l2_loss: 0.4768 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7797/40960 [00:30<01:57, 282.87batches/s, l2_loss: 0.4763 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7846/40960 [00:30<02:02, 269.83batches/s, l2_loss: 0.4763 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7846/40960 [00:30<02:02, 269.83batches/s, l2_loss: 0.4756 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7900/40960 [00:30<02:02, 269.56batches/s, l2_loss: 0.4756 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|▏| 7900/40960 [00:30<02:02, 269.56batches/s, l2_loss: 0.4757 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7964/40960 [00:30<01:56, 284.38batches/s, l2_loss: 0.4757 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7964/40960 [00:30<01:56, 284.38batches/s, l2_loss: 0.4755 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8022/40960 [00:31<01:55, 285.70batches/s, l2_loss: 0.4755 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8022/40960 [00:31<01:55, 285.70batches/s, l2_loss: 0.4748 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8077/40960 [00:31<01:57, 280.82batches/s, l2_loss: 0.4748 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8077/40960 [00:31<01:57, 280.82batches/s, l2_loss: 0.4749 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8130/40960 [00:31<01:58, 276.08batches/s, l2_loss: 0.4749 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8130/40960 [00:31<01:58, 276.08batches/s, l2_loss: 0.4744 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8193/40960 [00:31<01:55, 283.81batches/s, l2_loss: 0.4744 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8193/40960 [00:31<01:55, 283.81batches/s, l2_loss: 0.2684 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8250/40960 [00:32<01:55, 283.71batches/s, l2_loss: 0.2684 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8250/40960 [00:32<01:55, 283.71batches/s, l2_loss: 0.4646 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8304/40960 [00:32<01:57, 279.09batches/s, l2_loss: 0.4646 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8304/40960 [00:32<01:57, 279.09batches/s, l2_loss: 0.4631 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8358/40960 [00:32<01:58, 275.43batches/s, l2_loss: 0.4631 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8358/40960 [00:32<01:58, 275.43batches/s, l2_loss: 0.4660 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8409/40960 [00:32<02:01, 268.70batches/s, l2_loss: 0.4660 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8409/40960 [00:32<02:01, 268.70batches/s, l2_loss: 0.4415 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8463/40960 [00:32<02:01, 268.28batches/s, l2_loss: 0.4415 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8463/40960 [00:32<02:01, 268.28batches/s, l2_loss: 0.4423 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8514/40960 [00:33<02:03, 262.05batches/s, l2_loss: 0.4423 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8514/40960 [00:33<02:03, 262.05batches/s, l2_loss: 0.4414 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8566/40960 [00:33<02:04, 260.23batches/s, l2_loss: 0.4414 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8566/40960 [00:33<02:04, 260.23batches/s, l2_loss: 0.4497 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8620/40960 [00:33<02:02, 263.00batches/s, l2_loss: 0.4497 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8620/40960 [00:33<02:02, 263.00batches/s, l2_loss: 0.4569 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8680/40960 [00:33<01:58, 273.27batches/s, l2_loss: 0.4569 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8680/40960 [00:33<01:58, 273.27batches/s, l2_loss: 0.4487 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8737/40960 [00:33<01:56, 276.44batches/s, l2_loss: 0.4487 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8737/40960 [00:33<01:56, 276.44batches/s, l2_loss: 0.4470 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8781/40960 [00:34<02:04, 258.09batches/s, l2_loss: 0.4470 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8781/40960 [00:34<02:04, 258.09batches/s, l2_loss: 0.4492 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8838/40960 [00:34<02:00, 265.86batches/s, l2_loss: 0.4492 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8838/40960 [00:34<02:00, 265.86batches/s, l2_loss: 0.4516 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8896/40960 [00:34<01:57, 272.38batches/s, l2_loss: 0.4516 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8896/40960 [00:34<01:57, 272.38batches/s, l2_loss: 0.4509 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8952/40960 [00:34<01:56, 274.17batches/s, l2_loss: 0.4509 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8952/40960 [00:34<01:56, 274.17batches/s, l2_loss: 0.4502 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9008/40960 [00:34<01:56, 274.51batches/s, l2_loss: 0.4502 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9008/40960 [00:34<01:56, 274.51batches/s, l2_loss: 0.4497 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9059/40960 [00:35<01:58, 268.68batches/s, l2_loss: 0.4497 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9059/40960 [00:35<01:58, 268.68batches/s, l2_loss: 0.4502 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9117/40960 [00:35<01:56, 274.00batches/s, l2_loss: 0.4502 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9117/40960 [00:35<01:56, 274.00batches/s, l2_loss: 0.4533 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9177/40960 [00:35<01:52, 281.43batches/s, l2_loss: 0.4533 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9177/40960 [00:35<01:52, 281.43batches/s, l2_loss: 0.4510 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9220/40960 [00:35<02:01, 261.58batches/s, l2_loss: 0.4510 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9220/40960 [00:35<02:01, 261.58batches/s, l2_loss: 0.4502 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9277/40960 [00:35<01:58, 267.35batches/s, l2_loss: 0.4502 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9277/40960 [00:35<01:58, 267.35batches/s, l2_loss: 0.4543 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9334/40960 [00:36<01:56, 272.19batches/s, l2_loss: 0.4543 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9334/40960 [00:36<01:56, 272.19batches/s, l2_loss: 0.4512 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9387/40960 [00:36<01:57, 268.87batches/s, l2_loss: 0.4512 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9387/40960 [00:36<01:57, 268.87batches/s, l2_loss: 0.4499 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9443/40960 [00:36<01:56, 271.62batches/s, l2_loss: 0.4499 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9443/40960 [00:36<01:56, 271.62batches/s, l2_loss: 0.4506 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9498/40960 [00:36<01:55, 272.10batches/s, l2_loss: 0.4506 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9498/40960 [00:36<01:55, 272.10batches/s, l2_loss: 0.4497 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9554/40960 [00:36<01:54, 273.32batches/s, l2_loss: 0.4497 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9554/40960 [00:36<01:54, 273.32batches/s, l2_loss: 0.4491 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9615/40960 [00:37<01:51, 281.67batches/s, l2_loss: 0.4491 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9615/40960 [00:37<01:51, 281.67batches/s, l2_loss: 0.4488 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9675/40960 [00:37<01:49, 286.41batches/s, l2_loss: 0.4488 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9675/40960 [00:37<01:49, 286.41batches/s, l2_loss: 0.4492 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9730/40960 [00:37<01:50, 282.23batches/s, l2_loss: 0.4492 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9730/40960 [00:37<01:50, 282.23batches/s, l2_loss: 0.4499 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9782/40960 [00:37<01:53, 274.60batches/s, l2_loss: 0.4499 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9782/40960 [00:37<01:53, 274.60batches/s, l2_loss: 0.4505 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9833/40960 [00:37<01:55, 268.55batches/s, l2_loss: 0.4505 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9833/40960 [00:37<01:55, 268.55batches/s, l2_loss: 0.4515 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9892/40960 [00:38<01:52, 276.15batches/s, l2_loss: 0.4515 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9892/40960 [00:38<01:52, 276.15batches/s, l2_loss: 0.4505 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9941/40960 [00:38<01:56, 265.38batches/s, l2_loss: 0.4505 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9941/40960 [00:38<01:56, 265.38batches/s, l2_loss: 0.4517 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9985/40960 [00:38<02:03, 251.24batches/s, l2_loss: 0.4517 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9985/40960 [00:38<02:03, 251.24batches/s, l2_loss: 0.4499 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10029/40960 [00:38<02:07, 241.88batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  24%|▏| 10029/40960 [00:38<02:07, 241.88batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  25%|▏| 10076/40960 [00:38<02:09, 238.43batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  25%|▏| 10076/40960 [00:38<02:09, 238.43batches/s, l2_loss: 0.4510 - round_los\u001b[A\n",
      "Training:  25%|▏| 10129/40960 [00:39<02:05, 246.26batches/s, l2_loss: 0.4510 - round_los\u001b[A\n",
      "Training:  25%|▏| 10129/40960 [00:39<02:05, 246.26batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  25%|▏| 10170/40960 [00:39<02:13, 231.06batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  25%|▏| 10170/40960 [00:39<02:13, 231.06batches/s, l2_loss: 0.4494 - round_los\u001b[A\n",
      "Training:  25%|▏| 10207/40960 [00:39<02:22, 216.11batches/s, l2_loss: 0.4494 - round_los\u001b[A\n",
      "Training:  25%|▏| 10207/40960 [00:39<02:22, 216.11batches/s, l2_loss: 0.4502 - round_los\u001b[A\n",
      "Training:  25%|▎| 10254/40960 [00:39<02:18, 221.19batches/s, l2_loss: 0.4502 - round_los\u001b[A\n",
      "Training:  25%|▎| 10254/40960 [00:39<02:18, 221.19batches/s, l2_loss: 0.4495 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 10302/40960 [00:39<02:15, 226.12batches/s, l2_loss: 0.4495 - round_los\u001b[A\n",
      "Training:  25%|▎| 10302/40960 [00:39<02:15, 226.12batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  25%|▎| 10356/40960 [00:40<02:08, 238.40batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  25%|▎| 10356/40960 [00:40<02:08, 238.40batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  25%|▎| 10411/40960 [00:40<02:03, 248.29batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  25%|▎| 10411/40960 [00:40<02:03, 248.29batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  26%|▎| 10458/40960 [00:40<02:05, 243.35batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  26%|▎| 10458/40960 [00:40<02:05, 243.35batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  26%|▎| 10511/40960 [00:40<02:01, 249.66batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  26%|▎| 10511/40960 [00:40<02:01, 249.66batches/s, l2_loss: 0.4495 - round_los\u001b[A\n",
      "Training:  26%|▎| 10560/40960 [00:40<02:02, 247.35batches/s, l2_loss: 0.4495 - round_los\u001b[A\n",
      "Training:  26%|▎| 10560/40960 [00:40<02:02, 247.35batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  26%|▎| 10612/40960 [00:41<02:01, 250.10batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  26%|▎| 10612/40960 [00:41<02:01, 250.10batches/s, l2_loss: 0.4501 - round_los\u001b[A\n",
      "Training:  26%|▎| 10661/40960 [00:41<02:02, 248.08batches/s, l2_loss: 0.4501 - round_los\u001b[A\n",
      "Training:  26%|▎| 10661/40960 [00:41<02:02, 248.08batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  26%|▎| 10712/40960 [00:41<02:01, 249.67batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  26%|▎| 10712/40960 [00:41<02:01, 249.67batches/s, l2_loss: 0.4508 - round_los\u001b[A\n",
      "Training:  26%|▎| 10767/40960 [00:41<01:57, 256.08batches/s, l2_loss: 0.4508 - round_los\u001b[A\n",
      "Training:  26%|▎| 10767/40960 [00:41<01:57, 256.08batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  26%|▎| 10819/40960 [00:41<01:57, 255.73batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  26%|▎| 10819/40960 [00:41<01:57, 255.73batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  27%|▎| 10873/40960 [00:42<01:56, 258.60batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  27%|▎| 10873/40960 [00:42<01:56, 258.60batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  27%|▎| 10932/40960 [00:42<01:51, 269.10batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  27%|▎| 10932/40960 [00:42<01:51, 269.10batches/s, l2_loss: 0.4509 - round_los\u001b[A\n",
      "Training:  27%|▎| 10991/40960 [00:42<01:48, 276.75batches/s, l2_loss: 0.4509 - round_los\u001b[A\n",
      "Training:  27%|▎| 10991/40960 [00:42<01:48, 276.75batches/s, l2_loss: 0.4493 - round_los\u001b[A\n",
      "Training:  27%|▎| 11046/40960 [00:42<01:48, 275.29batches/s, l2_loss: 0.4493 - round_los\u001b[A\n",
      "Training:  27%|▎| 11046/40960 [00:42<01:48, 275.29batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  27%|▎| 11104/40960 [00:42<01:47, 278.44batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  27%|▎| 11104/40960 [00:42<01:47, 278.44batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  27%|▎| 11165/40960 [00:43<01:44, 286.23batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  27%|▎| 11165/40960 [00:43<01:44, 286.23batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  27%|▎| 11219/40960 [00:43<01:46, 280.07batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  27%|▎| 11219/40960 [00:43<01:46, 280.07batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  28%|▎| 11272/40960 [00:43<01:48, 273.88batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  28%|▎| 11272/40960 [00:43<01:48, 273.88batches/s, l2_loss: 0.4500 - round_los\u001b[A\n",
      "Training:  28%|▎| 11325/40960 [00:43<01:49, 270.74batches/s, l2_loss: 0.4500 - round_los\u001b[A\n",
      "Training:  28%|▎| 11325/40960 [00:43<01:49, 270.74batches/s, l2_loss: 0.4504 - round_los\u001b[A\n",
      "Training:  28%|▎| 11384/40960 [00:43<01:46, 276.49batches/s, l2_loss: 0.4504 - round_los\u001b[A\n",
      "Training:  28%|▎| 11384/40960 [00:43<01:46, 276.49batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  28%|▎| 11439/40960 [00:44<01:47, 274.72batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  28%|▎| 11439/40960 [00:44<01:47, 274.72batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  28%|▎| 11483/40960 [00:44<01:54, 257.68batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  28%|▎| 11483/40960 [00:44<01:54, 257.68batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  28%|▎| 11519/40960 [00:44<02:05, 234.37batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  28%|▎| 11519/40960 [00:44<02:05, 234.37batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  28%|▎| 11569/40960 [00:44<02:03, 237.98batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  28%|▎| 11569/40960 [00:44<02:03, 237.98batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  28%|▎| 11626/40960 [00:44<01:56, 251.74batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  28%|▎| 11626/40960 [00:44<01:56, 251.74batches/s, l2_loss: 0.4495 - round_los\u001b[A\n",
      "Training:  29%|▎| 11681/40960 [00:45<01:53, 258.11batches/s, l2_loss: 0.4495 - round_los\u001b[A\n",
      "Training:  29%|▎| 11681/40960 [00:45<01:53, 258.11batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  29%|▎| 11741/40960 [00:45<01:48, 269.71batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  29%|▎| 11741/40960 [00:45<01:48, 269.71batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  29%|▎| 11801/40960 [00:45<01:44, 277.91batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  29%|▎| 11801/40960 [00:45<01:44, 277.91batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  29%|▎| 11855/40960 [00:45<01:46, 274.10batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  29%|▎| 11855/40960 [00:45<01:46, 274.10batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  29%|▎| 11904/40960 [00:45<01:49, 265.35batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  29%|▎| 11904/40960 [00:45<01:49, 265.35batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  29%|▎| 11955/40960 [00:46<01:51, 260.96batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  29%|▎| 11955/40960 [00:46<01:51, 260.96batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  29%|▎| 12002/40960 [00:46<01:55, 250.10batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  29%|▎| 12002/40960 [00:46<01:55, 250.10batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  29%|▎| 12050/40960 [00:46<01:57, 245.88batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  29%|▎| 12050/40960 [00:46<01:57, 245.88batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  30%|▎| 12106/40960 [00:46<01:52, 255.47batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  30%|▎| 12106/40960 [00:46<01:52, 255.47batches/s, l2_loss: 0.4493 - round_los\u001b[A\n",
      "Training:  30%|▎| 12165/40960 [00:46<01:47, 267.11batches/s, l2_loss: 0.4493 - round_los\u001b[A\n",
      "Training:  30%|▎| 12165/40960 [00:46<01:47, 267.11batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12220/40960 [00:47<01:46, 268.95batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  30%|▎| 12220/40960 [00:47<01:46, 268.95batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  30%|▎| 12280/40960 [00:47<01:43, 277.15batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  30%|▎| 12280/40960 [00:47<01:43, 277.15batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  30%|▎| 12333/40960 [00:47<01:45, 272.44batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  30%|▎| 12333/40960 [00:47<01:45, 272.44batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  30%|▎| 12390/40960 [00:47<01:43, 275.62batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  30%|▎| 12390/40960 [00:47<01:43, 275.62batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  30%|▎| 12449/40960 [00:47<01:41, 280.22batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  30%|▎| 12449/40960 [00:47<01:41, 280.22batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  31%|▎| 12508/40960 [00:48<01:40, 283.21batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  31%|▎| 12508/40960 [00:48<01:40, 283.21batches/s, l2_loss: 0.4494 - round_los\u001b[A\n",
      "Training:  31%|▎| 12568/40960 [00:48<01:38, 288.20batches/s, l2_loss: 0.4494 - round_los\u001b[A\n",
      "Training:  31%|▎| 12568/40960 [00:48<01:38, 288.20batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  31%|▎| 12624/40960 [00:48<01:39, 285.58batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  31%|▎| 12624/40960 [00:48<01:39, 285.58batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  31%|▎| 12681/40960 [00:48<01:39, 284.09batches/s, l2_loss: 0.4486 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|▎| 12681/40960 [00:48<01:39, 284.09batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  31%|▎| 12735/40960 [00:48<01:40, 279.63batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  31%|▎| 12735/40960 [00:48<01:40, 279.63batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  31%|▎| 12773/40960 [00:49<01:51, 251.79batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  31%|▎| 12773/40960 [00:49<01:51, 251.79batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  31%|▎| 12821/40960 [00:49<01:53, 247.82batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  31%|▎| 12821/40960 [00:49<01:53, 247.82batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  31%|▎| 12872/40960 [00:49<01:52, 249.33batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  31%|▎| 12872/40960 [00:49<01:52, 249.33batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  32%|▎| 12923/40960 [00:49<01:51, 250.46batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  32%|▎| 12923/40960 [00:49<01:51, 250.46batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  32%|▎| 12977/40960 [00:50<01:49, 254.69batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  32%|▎| 12977/40960 [00:50<01:49, 254.69batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  32%|▎| 13022/40960 [00:50<01:53, 245.10batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  32%|▎| 13022/40960 [00:50<01:53, 245.10batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  32%|▎| 13067/40960 [00:50<01:57, 238.36batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  32%|▎| 13067/40960 [00:50<01:57, 238.36batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  32%|▎| 13115/40960 [00:50<01:56, 238.62batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  32%|▎| 13115/40960 [00:50<01:56, 238.62batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  32%|▎| 13162/40960 [00:50<01:57, 235.89batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  32%|▎| 13162/40960 [00:50<01:57, 235.89batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  32%|▎| 13210/40960 [00:51<01:57, 235.96batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  32%|▎| 13210/40960 [00:51<01:57, 235.96batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  32%|▎| 13263/40960 [00:51<01:53, 244.43batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  32%|▎| 13263/40960 [00:51<01:53, 244.43batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  33%|▎| 13319/40960 [00:51<01:48, 253.87batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  33%|▎| 13319/40960 [00:51<01:48, 253.87batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  33%|▎| 13377/40960 [00:51<01:44, 263.92batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  33%|▎| 13377/40960 [00:51<01:44, 263.92batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  33%|▎| 13432/40960 [00:51<01:43, 266.82batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  33%|▎| 13432/40960 [00:51<01:43, 266.82batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  33%|▎| 13487/40960 [00:52<01:42, 268.57batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  33%|▎| 13487/40960 [00:52<01:42, 268.57batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  33%|▎| 13546/40960 [00:52<01:39, 275.47batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  33%|▎| 13546/40960 [00:52<01:39, 275.47batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  33%|▎| 13607/40960 [00:52<01:36, 283.35batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  33%|▎| 13607/40960 [00:52<01:36, 283.35batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  33%|▎| 13666/40960 [00:52<01:35, 286.73batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  33%|▎| 13666/40960 [00:52<01:35, 286.73batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  33%|▎| 13720/40960 [00:52<01:37, 279.35batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  33%|▎| 13720/40960 [00:52<01:37, 279.35batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  34%|▎| 13770/40960 [00:53<01:40, 269.98batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  34%|▎| 13770/40960 [00:53<01:40, 269.98batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  34%|▎| 13815/40960 [00:53<01:46, 256.08batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  34%|▎| 13815/40960 [00:53<01:46, 256.08batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  34%|▎| 13868/40960 [00:53<01:44, 258.34batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  34%|▎| 13868/40960 [00:53<01:44, 258.34batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  34%|▎| 13920/40960 [00:53<01:44, 257.77batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  34%|▎| 13920/40960 [00:53<01:44, 257.77batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  34%|▎| 13978/40960 [00:53<01:41, 265.92batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  34%|▎| 13978/40960 [00:53<01:41, 265.92batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  34%|▎| 14036/40960 [00:54<01:38, 272.64batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  34%|▎| 14036/40960 [00:54<01:38, 272.64batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  34%|▎| 14088/40960 [00:54<01:40, 268.29batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  34%|▎| 14088/40960 [00:54<01:40, 268.29batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  35%|▎| 14146/40960 [00:54<01:37, 274.46batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  35%|▎| 14146/40960 [00:54<01:37, 274.46batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  35%|▎| 14199/40960 [00:54<01:38, 270.47batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  35%|▎| 14199/40960 [00:54<01:38, 270.47batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  35%|▎| 14258/40960 [00:54<01:36, 276.80batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  35%|▎| 14258/40960 [00:54<01:36, 276.80batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  35%|▎| 14317/40960 [00:55<01:34, 281.05batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  35%|▎| 14317/40960 [00:55<01:34, 281.05batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  35%|▎| 14367/40960 [00:55<01:38, 269.61batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  35%|▎| 14367/40960 [00:55<01:38, 269.61batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  35%|▎| 14414/40960 [00:55<01:42, 258.91batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  35%|▎| 14414/40960 [00:55<01:42, 258.91batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  35%|▎| 14472/40960 [00:55<01:39, 267.26batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  35%|▎| 14472/40960 [00:55<01:39, 267.26batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  35%|▎| 14532/40960 [00:55<01:35, 276.14batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  35%|▎| 14532/40960 [00:55<01:35, 276.14batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  36%|▎| 14586/40960 [00:56<01:36, 273.16batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  36%|▎| 14586/40960 [00:56<01:36, 273.16batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  36%|▎| 14622/40960 [00:56<01:48, 243.64batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  36%|▎| 14622/40960 [00:56<01:48, 243.64batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  36%|▎| 14677/40960 [00:56<01:44, 252.53batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  36%|▎| 14677/40960 [00:56<01:44, 252.53batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  36%|▎| 14726/40960 [00:56<01:44, 249.97batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  36%|▎| 14726/40960 [00:56<01:44, 249.97batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  36%|▎| 14778/40960 [00:56<01:43, 252.65batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  36%|▎| 14778/40960 [00:56<01:43, 252.65batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  36%|▎| 14829/40960 [00:57<01:43, 252.39batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  36%|▎| 14829/40960 [00:57<01:43, 252.39batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  36%|▎| 14887/40960 [00:57<01:39, 261.64batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  36%|▎| 14887/40960 [00:57<01:39, 261.64batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  36%|▎| 14929/40960 [00:57<01:46, 245.04batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  36%|▎| 14929/40960 [00:57<01:46, 245.04batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  37%|▎| 14971/40960 [00:57<01:50, 234.18batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  37%|▎| 14971/40960 [00:57<01:50, 234.18batches/s, l2_loss: 0.4477 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15029/40960 [00:57<01:43, 250.65batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  37%|▎| 15029/40960 [00:57<01:43, 250.65batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  37%|▎| 15082/40960 [00:58<01:41, 254.64batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  37%|▎| 15082/40960 [00:58<01:41, 254.64batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  37%|▎| 15131/40960 [00:58<01:43, 250.40batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  37%|▎| 15131/40960 [00:58<01:43, 250.40batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15181/40960 [00:58<01:43, 249.96batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  37%|▎| 15181/40960 [00:58<01:43, 249.96batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  37%|▎| 15236/40960 [00:58<01:40, 256.00batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  37%|▎| 15236/40960 [00:58<01:40, 256.00batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  37%|▎| 15287/40960 [00:58<01:40, 254.53batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  37%|▎| 15287/40960 [00:58<01:40, 254.53batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  37%|▎| 15342/40960 [00:59<01:38, 259.66batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  37%|▎| 15342/40960 [00:59<01:38, 259.66batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  38%|▍| 15393/40960 [00:59<01:39, 257.09batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  38%|▍| 15393/40960 [00:59<01:39, 257.09batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  38%|▍| 15450/40960 [00:59<01:36, 264.84batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  38%|▍| 15450/40960 [00:59<01:36, 264.84batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  38%|▍| 15507/40960 [00:59<01:34, 269.97batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  38%|▍| 15507/40960 [00:59<01:34, 269.97batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  38%|▍| 15566/40960 [00:59<01:32, 275.94batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  38%|▍| 15566/40960 [00:59<01:32, 275.94batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  38%|▍| 15627/40960 [01:00<01:29, 283.33batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  38%|▍| 15627/40960 [01:00<01:29, 283.33batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  38%|▍| 15686/40960 [01:00<01:28, 285.96batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  38%|▍| 15686/40960 [01:00<01:28, 285.96batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  38%|▍| 15741/40960 [01:00<01:29, 281.99batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  38%|▍| 15741/40960 [01:00<01:29, 281.99batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  39%|▍| 15800/40960 [01:00<01:28, 285.47batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  39%|▍| 15800/40960 [01:00<01:28, 285.47batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 15860/40960 [01:00<01:26, 288.94batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 15860/40960 [01:00<01:26, 288.94batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 15920/40960 [01:01<01:25, 292.13batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 15920/40960 [01:01<01:25, 292.13batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 15980/40960 [01:01<01:24, 293.94batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 15980/40960 [01:01<01:24, 293.94batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 16036/40960 [01:01<01:26, 289.44batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 16036/40960 [01:01<01:26, 289.44batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 16085/40960 [01:01<01:30, 275.90batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  39%|▍| 16085/40960 [01:01<01:30, 275.90batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  39%|▍| 16135/40960 [01:01<01:32, 267.95batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  39%|▍| 16135/40960 [01:01<01:32, 267.95batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  40%|▍| 16192/40960 [01:02<01:31, 271.60batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  40%|▍| 16192/40960 [01:02<01:31, 271.60batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  40%|▍| 16245/40960 [01:02<01:32, 268.10batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  40%|▍| 16245/40960 [01:02<01:32, 268.10batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  40%|▍| 16303/40960 [01:02<01:30, 273.73batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  40%|▍| 16303/40960 [01:02<01:30, 273.73batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  40%|▍| 16364/40960 [01:02<01:27, 282.44batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  40%|▍| 16364/40960 [01:02<01:27, 282.44batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  40%|▍| 16420/40960 [01:02<01:27, 281.18batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  40%|▍| 16420/40960 [01:02<01:27, 281.18batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  40%|▍| 16475/40960 [01:03<01:27, 279.02batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  40%|▍| 16475/40960 [01:03<01:27, 279.02batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  40%|▍| 16533/40960 [01:03<01:26, 281.37batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  40%|▍| 16533/40960 [01:03<01:26, 281.37batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  41%|▍| 16591/40960 [01:03<01:26, 282.71batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  41%|▍| 16591/40960 [01:03<01:26, 282.71batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  41%|▍| 16646/40960 [01:03<01:26, 279.75batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  41%|▍| 16646/40960 [01:03<01:26, 279.75batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  41%|▍| 16699/40960 [01:03<01:28, 273.90batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  41%|▍| 16699/40960 [01:03<01:28, 273.90batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  41%|▍| 16749/40960 [01:04<01:30, 266.36batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  41%|▍| 16749/40960 [01:04<01:30, 266.36batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  41%|▍| 16798/40960 [01:04<01:33, 258.56batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  41%|▍| 16798/40960 [01:04<01:33, 258.56batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  41%|▍| 16848/40960 [01:04<01:34, 254.78batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  41%|▍| 16848/40960 [01:04<01:34, 254.78batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  41%|▍| 16903/40960 [01:04<01:32, 260.43batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  41%|▍| 16903/40960 [01:04<01:32, 260.43batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  41%|▍| 16955/40960 [01:04<01:32, 259.85batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  41%|▍| 16955/40960 [01:04<01:32, 259.85batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  42%|▍| 17010/40960 [01:05<01:30, 263.43batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  42%|▍| 17010/40960 [01:05<01:30, 263.43batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  42%|▍| 17067/40960 [01:05<01:28, 269.74batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  42%|▍| 17067/40960 [01:05<01:28, 269.74batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  42%|▍| 17125/40960 [01:05<01:26, 274.54batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  42%|▍| 17125/40960 [01:05<01:26, 274.54batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  42%|▍| 17183/40960 [01:05<01:25, 278.87batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  42%|▍| 17183/40960 [01:05<01:25, 278.87batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  42%|▍| 17229/40960 [01:05<01:30, 263.14batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  42%|▍| 17229/40960 [01:05<01:30, 263.14batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  42%|▍| 17280/40960 [01:06<01:31, 259.47batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  42%|▍| 17280/40960 [01:06<01:31, 259.47batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  42%|▍| 17327/40960 [01:06<01:34, 249.25batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  42%|▍| 17327/40960 [01:06<01:34, 249.25batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  42%|▍| 17380/40960 [01:06<01:33, 253.16batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  42%|▍| 17380/40960 [01:06<01:33, 253.16batches/s, l2_loss: 0.4463 - round_los\u001b[A\n",
      "Training:  43%|▍| 17430/40960 [01:06<01:33, 250.77batches/s, l2_loss: 0.4463 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|▍| 17430/40960 [01:06<01:33, 250.77batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  43%|▍| 17488/40960 [01:06<01:29, 261.28batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  43%|▍| 17488/40960 [01:06<01:29, 261.28batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  43%|▍| 17548/40960 [01:07<01:25, 272.74batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  43%|▍| 17548/40960 [01:07<01:25, 272.74batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  43%|▍| 17607/40960 [01:07<01:23, 278.40batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  43%|▍| 17607/40960 [01:07<01:23, 278.40batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  43%|▍| 17661/40960 [01:07<01:24, 274.52batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  43%|▍| 17661/40960 [01:07<01:24, 274.52batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  43%|▍| 17713/40960 [01:07<01:26, 268.93batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  43%|▍| 17713/40960 [01:07<01:26, 268.93batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  43%|▍| 17768/40960 [01:08<01:26, 269.53batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  43%|▍| 17768/40960 [01:08<01:26, 269.53batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  44%|▍| 17822/40960 [01:08<01:25, 269.45batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  44%|▍| 17822/40960 [01:08<01:25, 269.45batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  44%|▍| 17873/40960 [01:08<01:27, 263.61batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  44%|▍| 17873/40960 [01:08<01:27, 263.61batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  44%|▍| 17926/40960 [01:08<01:27, 263.04batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  44%|▍| 17926/40960 [01:08<01:27, 263.04batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  44%|▍| 17979/40960 [01:08<01:27, 263.56batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  44%|▍| 17979/40960 [01:08<01:27, 263.56batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  44%|▍| 18016/40960 [01:09<01:36, 238.23batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  44%|▍| 18016/40960 [01:09<01:36, 238.23batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  44%|▍| 18069/40960 [01:09<01:33, 245.93batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  44%|▍| 18069/40960 [01:09<01:33, 245.93batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  44%|▍| 18119/40960 [01:09<01:32, 246.82batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  44%|▍| 18119/40960 [01:09<01:32, 246.82batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  44%|▍| 18176/40960 [01:09<01:28, 257.45batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  44%|▍| 18176/40960 [01:09<01:28, 257.45batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  44%|▍| 18227/40960 [01:09<01:28, 256.65batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  44%|▍| 18227/40960 [01:09<01:28, 256.65batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  45%|▍| 18277/40960 [01:10<01:29, 254.18batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  45%|▍| 18277/40960 [01:10<01:29, 254.18batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  45%|▍| 18333/40960 [01:10<01:26, 261.43batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  45%|▍| 18333/40960 [01:10<01:26, 261.43batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  45%|▍| 18386/40960 [01:10<01:26, 262.10batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  45%|▍| 18386/40960 [01:10<01:26, 262.10batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  45%|▍| 18444/40960 [01:10<01:23, 269.53batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  45%|▍| 18444/40960 [01:10<01:23, 269.53batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  45%|▍| 18496/40960 [01:10<01:24, 264.90batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  45%|▍| 18496/40960 [01:10<01:24, 264.90batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  45%|▍| 18535/40960 [01:11<01:32, 241.37batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  45%|▍| 18535/40960 [01:11<01:32, 241.37batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  45%|▍| 18587/40960 [01:11<01:31, 245.68batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  45%|▍| 18587/40960 [01:11<01:31, 245.68batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 18642/40960 [01:11<01:27, 254.07batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 18642/40960 [01:11<01:27, 254.07batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 18685/40960 [01:11<01:32, 240.72batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 18685/40960 [01:11<01:32, 240.72batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 18742/40960 [01:11<01:27, 253.28batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 18742/40960 [01:11<01:27, 253.28batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  46%|▍| 18796/40960 [01:12<01:25, 257.87batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  46%|▍| 18796/40960 [01:12<01:25, 257.87batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  46%|▍| 18843/40960 [01:12<01:28, 248.92batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  46%|▍| 18843/40960 [01:12<01:28, 248.92batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 18895/40960 [01:12<01:27, 251.29batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 18895/40960 [01:12<01:27, 251.29batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  46%|▍| 18952/40960 [01:12<01:24, 261.11batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  46%|▍| 18952/40960 [01:12<01:24, 261.11batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 19001/40960 [01:12<01:25, 255.52batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  46%|▍| 19001/40960 [01:12<01:25, 255.52batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  47%|▍| 19047/40960 [01:13<01:28, 247.59batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  47%|▍| 19047/40960 [01:13<01:28, 247.59batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  47%|▍| 19104/40960 [01:13<01:24, 257.31batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  47%|▍| 19104/40960 [01:13<01:24, 257.31batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  47%|▍| 19158/40960 [01:13<01:23, 260.85batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  47%|▍| 19158/40960 [01:13<01:23, 260.85batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  47%|▍| 19206/40960 [01:13<01:25, 253.94batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  47%|▍| 19206/40960 [01:13<01:25, 253.94batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  47%|▍| 19261/40960 [01:13<01:23, 259.19batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  47%|▍| 19261/40960 [01:13<01:23, 259.19batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  47%|▍| 19317/40960 [01:14<01:21, 264.99batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  47%|▍| 19317/40960 [01:14<01:21, 264.99batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  47%|▍| 19366/40960 [01:14<01:23, 258.44batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  47%|▍| 19366/40960 [01:14<01:23, 258.44batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  47%|▍| 19412/40960 [01:14<01:26, 248.49batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  47%|▍| 19412/40960 [01:14<01:26, 248.49batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  48%|▍| 19467/40960 [01:14<01:23, 256.24batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  48%|▍| 19467/40960 [01:14<01:23, 256.24batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  48%|▍| 19514/40960 [01:14<01:26, 248.48batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  48%|▍| 19514/40960 [01:14<01:26, 248.48batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  48%|▍| 19561/40960 [01:15<01:28, 242.83batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  48%|▍| 19561/40960 [01:15<01:28, 242.83batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  48%|▍| 19614/40960 [01:15<01:26, 248.18batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  48%|▍| 19614/40960 [01:15<01:26, 248.18batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  48%|▍| 19663/40960 [01:15<01:26, 246.64batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  48%|▍| 19663/40960 [01:15<01:26, 246.64batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  48%|▍| 19698/40960 [01:15<01:34, 223.92batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  48%|▍| 19698/40960 [01:15<01:34, 223.92batches/s, l2_loss: 0.4469 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|▍| 19753/40960 [01:15<01:29, 237.80batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  48%|▍| 19753/40960 [01:15<01:29, 237.80batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  48%|▍| 19810/40960 [01:16<01:24, 251.56batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  48%|▍| 19810/40960 [01:16<01:24, 251.56batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  49%|▍| 19868/40960 [01:16<01:20, 262.76batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  49%|▍| 19868/40960 [01:16<01:20, 262.76batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  49%|▍| 19923/40960 [01:16<01:19, 266.26batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  49%|▍| 19923/40960 [01:16<01:19, 266.26batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  49%|▍| 19983/40960 [01:16<01:16, 275.17batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  49%|▍| 19983/40960 [01:16<01:16, 275.17batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  49%|▍| 20036/40960 [01:16<01:17, 271.17batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  49%|▍| 20036/40960 [01:16<01:17, 271.17batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  49%|▍| 20093/40960 [01:17<01:15, 275.25batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  49%|▍| 20093/40960 [01:17<01:15, 275.25batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  49%|▍| 20153/40960 [01:17<01:13, 282.36batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  49%|▍| 20153/40960 [01:17<01:13, 282.36batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  49%|▍| 20213/40960 [01:17<01:12, 286.35batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  49%|▍| 20213/40960 [01:17<01:12, 286.35batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  49%|▍| 20270/40960 [01:17<01:12, 284.38batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  49%|▍| 20270/40960 [01:17<01:12, 284.38batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  50%|▍| 20321/40960 [01:17<01:15, 273.78batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  50%|▍| 20321/40960 [01:17<01:15, 273.78batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  50%|▍| 20370/40960 [01:18<01:18, 263.46batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  50%|▍| 20370/40960 [01:18<01:18, 263.46batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  50%|▍| 20421/40960 [01:18<01:19, 259.84batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  50%|▍| 20421/40960 [01:18<01:19, 259.84batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  50%|▍| 20470/40960 [01:18<01:20, 254.90batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  50%|▍| 20470/40960 [01:18<01:20, 254.90batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  50%|▌| 20512/40960 [01:18<01:24, 241.42batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  50%|▌| 20512/40960 [01:18<01:24, 241.42batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  50%|▌| 20546/40960 [01:18<01:32, 219.97batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  50%|▌| 20546/40960 [01:18<01:32, 219.97batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  50%|▌| 20594/40960 [01:19<01:30, 224.88batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  50%|▌| 20594/40960 [01:19<01:30, 224.88batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  50%|▌| 20650/40960 [01:19<01:24, 240.25batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  50%|▌| 20650/40960 [01:19<01:24, 240.25batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  51%|▌| 20701/40960 [01:19<01:23, 242.93batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  51%|▌| 20701/40960 [01:19<01:23, 242.93batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  51%|▌| 20754/40960 [01:19<01:21, 247.97batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  51%|▌| 20754/40960 [01:19<01:21, 247.97batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  51%|▌| 20800/40960 [01:19<01:23, 240.56batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  51%|▌| 20800/40960 [01:19<01:23, 240.56batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  51%|▌| 20852/40960 [01:20<01:21, 246.19batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  51%|▌| 20852/40960 [01:20<01:21, 246.19batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  51%|▌| 20906/40960 [01:20<01:19, 252.35batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  51%|▌| 20906/40960 [01:20<01:19, 252.35batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  51%|▌| 20961/40960 [01:20<01:17, 257.91batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  51%|▌| 20961/40960 [01:20<01:17, 257.91batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  51%|▌| 21012/40960 [01:20<01:18, 254.78batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  51%|▌| 21012/40960 [01:20<01:18, 254.78batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  51%|▌| 21064/40960 [01:20<01:18, 254.63batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  51%|▌| 21064/40960 [01:20<01:18, 254.63batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  52%|▌| 21118/40960 [01:21<01:16, 257.86batches/s, l2_loss: 0.4467 - round_los\u001b[A\n",
      "Training:  52%|▌| 21118/40960 [01:21<01:16, 257.86batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  52%|▌| 21177/40960 [01:21<01:13, 268.69batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  52%|▌| 21177/40960 [01:21<01:13, 268.69batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  52%|▌| 21225/40960 [01:21<01:16, 258.02batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  52%|▌| 21225/40960 [01:21<01:16, 258.02batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  52%|▌| 21262/40960 [01:21<01:23, 234.55batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  52%|▌| 21262/40960 [01:21<01:23, 234.55batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  52%|▌| 21301/40960 [01:21<01:28, 222.16batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  52%|▌| 21301/40960 [01:21<01:28, 222.16batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  52%|▌| 21358/40960 [01:22<01:21, 240.58batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  52%|▌| 21358/40960 [01:22<01:21, 240.58batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  52%|▌| 21416/40960 [01:22<01:16, 254.84batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  52%|▌| 21416/40960 [01:22<01:16, 254.84batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  52%|▌| 21469/40960 [01:22<01:15, 256.99batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  52%|▌| 21469/40960 [01:22<01:15, 256.99batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  53%|▌| 21525/40960 [01:22<01:13, 263.03batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  53%|▌| 21525/40960 [01:22<01:13, 263.03batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  53%|▌| 21577/40960 [01:22<01:14, 261.92batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  53%|▌| 21577/40960 [01:22<01:14, 261.92batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  53%|▌| 21633/40960 [01:23<01:12, 266.70batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  53%|▌| 21633/40960 [01:23<01:12, 266.70batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  53%|▌| 21684/40960 [01:23<01:13, 262.56batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  53%|▌| 21684/40960 [01:23<01:13, 262.56batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  53%|▌| 21730/40960 [01:23<01:16, 251.73batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  53%|▌| 21730/40960 [01:23<01:16, 251.73batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  53%|▌| 21781/40960 [01:23<01:16, 251.95batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  53%|▌| 21781/40960 [01:23<01:16, 251.95batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  53%|▌| 21833/40960 [01:23<01:15, 253.26batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  53%|▌| 21833/40960 [01:24<01:15, 253.26batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  53%|▌| 21890/40960 [01:24<01:13, 259.66batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  53%|▌| 21890/40960 [01:24<01:13, 259.66batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  54%|▌| 21943/40960 [01:24<01:12, 260.93batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  54%|▌| 21943/40960 [01:24<01:12, 260.93batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  54%|▌| 21979/40960 [01:24<01:20, 235.69batches/s, l2_loss: 0.4468 - round_los\u001b[A\n",
      "Training:  54%|▌| 21979/40960 [01:24<01:20, 235.69batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  54%|▌| 22036/40960 [01:24<01:15, 249.85batches/s, l2_loss: 0.4470 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|▌| 22036/40960 [01:24<01:15, 249.85batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  54%|▌| 22089/40960 [01:25<01:14, 254.14batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  54%|▌| 22089/40960 [01:25<01:14, 254.14batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  54%|▌| 22140/40960 [01:25<01:14, 253.62batches/s, l2_loss: 0.4470 - round_los\u001b[A\n",
      "Training:  54%|▌| 22140/40960 [01:25<01:14, 253.62batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  54%|▌| 22197/40960 [01:25<01:11, 261.83batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  54%|▌| 22197/40960 [01:25<01:11, 261.83batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  54%|▌| 22246/40960 [01:25<01:13, 255.85batches/s, l2_loss: 0.4469 - round_los\u001b[A\n",
      "Training:  54%|▌| 22246/40960 [01:25<01:13, 255.85batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [01:25<01:13, 254.02batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  54%|▌| 22296/40960 [01:25<01:13, 254.02batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  55%|▌| 22349/40960 [01:26<01:12, 256.28batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  55%|▌| 22349/40960 [01:26<01:12, 256.28batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  55%|▌| 22406/40960 [01:26<01:10, 264.15batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  55%|▌| 22406/40960 [01:26<01:10, 264.15batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  55%|▌| 22465/40960 [01:26<01:07, 272.97batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  55%|▌| 22465/40960 [01:26<01:07, 272.97batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  55%|▌| 22524/40960 [01:26<01:06, 278.74batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  55%|▌| 22524/40960 [01:26<01:06, 278.74batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  55%|▌| 22584/40960 [01:26<01:04, 284.81batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  55%|▌| 22584/40960 [01:26<01:04, 284.81batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  55%|▌| 22644/40960 [01:27<01:03, 288.12batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  55%|▌| 22644/40960 [01:27<01:03, 288.12batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  55%|▌| 22704/40960 [01:27<01:02, 290.97batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  55%|▌| 22704/40960 [01:27<01:02, 290.97batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  56%|▌| 22756/40960 [01:27<01:04, 281.49batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  56%|▌| 22756/40960 [01:27<01:04, 281.49batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  56%|▌| 22816/40960 [01:27<01:03, 285.92batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  56%|▌| 22816/40960 [01:27<01:03, 285.92batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  56%|▌| 22873/40960 [01:27<01:03, 284.50batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  56%|▌| 22873/40960 [01:27<01:03, 284.50batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  56%|▌| 22932/40960 [01:28<01:03, 285.89batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  56%|▌| 22932/40960 [01:28<01:03, 285.89batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  56%|▌| 22989/40960 [01:28<01:02, 285.26batches/s, l2_loss: 0.4472 - round_los\u001b[A\n",
      "Training:  56%|▌| 22989/40960 [01:28<01:02, 285.26batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  56%|▌| 23044/40960 [01:28<01:03, 281.78batches/s, l2_loss: 0.4471 - round_los\u001b[A\n",
      "Training:  56%|▌| 23044/40960 [01:28<01:03, 281.78batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  56%|▌| 23103/40960 [01:28<01:02, 284.82batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  56%|▌| 23103/40960 [01:28<01:02, 284.82batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  57%|▌| 23162/40960 [01:28<01:01, 287.76batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  57%|▌| 23162/40960 [01:28<01:01, 287.76batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  57%|▌| 23218/40960 [01:29<01:02, 285.34batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  57%|▌| 23218/40960 [01:29<01:02, 285.34batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  57%|▌| 23263/40960 [01:29<01:06, 265.84batches/s, l2_loss: 0.4473 - round_los\u001b[A\n",
      "Training:  57%|▌| 23263/40960 [01:29<01:06, 265.84batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  57%|▌| 23310/40960 [01:29<01:08, 256.05batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  57%|▌| 23310/40960 [01:29<01:08, 256.05batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  57%|▌| 23353/40960 [01:29<01:12, 243.21batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  57%|▌| 23353/40960 [01:29<01:12, 243.21batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  57%|▌| 23411/40960 [01:29<01:08, 256.17batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  57%|▌| 23411/40960 [01:29<01:08, 256.17batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  57%|▌| 23466/40960 [01:30<01:06, 261.43batches/s, l2_loss: 0.4474 - round_los\u001b[A\n",
      "Training:  57%|▌| 23466/40960 [01:30<01:06, 261.43batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  57%|▌| 23527/40960 [01:30<01:03, 273.80batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  57%|▌| 23527/40960 [01:30<01:03, 273.80batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  58%|▌| 23583/40960 [01:30<01:03, 275.29batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  58%|▌| 23583/40960 [01:30<01:03, 275.29batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  58%|▌| 23640/40960 [01:30<01:02, 277.10batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  58%|▌| 23640/40960 [01:30<01:02, 277.10batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  58%|▌| 23693/40960 [01:30<01:03, 272.32batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  58%|▌| 23693/40960 [01:30<01:03, 272.32batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  58%|▌| 23741/40960 [01:31<01:05, 262.47batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  58%|▌| 23741/40960 [01:31<01:05, 262.47batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  58%|▌| 23794/40960 [01:31<01:05, 262.74batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  58%|▌| 23794/40960 [01:31<01:05, 262.74batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  58%|▌| 23851/40960 [01:31<01:03, 267.79batches/s, l2_loss: 0.4475 - round_los\u001b[A\n",
      "Training:  58%|▌| 23851/40960 [01:31<01:03, 267.79batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  58%|▌| 23908/40960 [01:31<01:02, 271.66batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  58%|▌| 23908/40960 [01:31<01:02, 271.66batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  58%|▌| 23956/40960 [01:31<01:05, 261.19batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  58%|▌| 23956/40960 [01:31<01:05, 261.19batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  59%|▌| 24004/40960 [01:32<01:06, 253.95batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  59%|▌| 24004/40960 [01:32<01:06, 253.95batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  59%|▌| 24054/40960 [01:32<01:07, 251.19batches/s, l2_loss: 0.4476 - round_los\u001b[A\n",
      "Training:  59%|▌| 24054/40960 [01:32<01:07, 251.19batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  59%|▌| 24098/40960 [01:32<01:10, 239.73batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  59%|▌| 24098/40960 [01:32<01:10, 239.73batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24150/40960 [01:32<01:08, 245.12batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24150/40960 [01:32<01:08, 245.12batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  59%|▌| 24203/40960 [01:32<01:06, 250.82batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  59%|▌| 24203/40960 [01:32<01:06, 250.82batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  59%|▌| 24257/40960 [01:33<01:05, 254.98batches/s, l2_loss: 0.4478 - round_los\u001b[A\n",
      "Training:  59%|▌| 24257/40960 [01:33<01:05, 254.98batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24308/40960 [01:33<01:05, 254.67batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  59%|▌| 24308/40960 [01:33<01:05, 254.67batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  59%|▌| 24363/40960 [01:33<01:03, 259.51batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  59%|▌| 24363/40960 [01:33<01:03, 259.51batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  60%|▌| 24410/40960 [01:33<01:06, 250.08batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  60%|▌| 24410/40960 [01:33<01:06, 250.08batches/s, l2_loss: 0.4479 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|▌| 24466/40960 [01:33<01:03, 258.29batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  60%|▌| 24466/40960 [01:33<01:03, 258.29batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  60%|▌| 24524/40960 [01:34<01:01, 266.81batches/s, l2_loss: 0.4477 - round_los\u001b[A\n",
      "Training:  60%|▌| 24524/40960 [01:34<01:01, 266.81batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  60%|▌| 24580/40960 [01:34<01:00, 269.74batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  60%|▌| 24580/40960 [01:34<01:00, 269.74batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  60%|▌| 24634/40960 [01:34<01:00, 269.02batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  60%|▌| 24634/40960 [01:34<01:00, 269.02batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  60%|▌| 24687/40960 [01:34<01:01, 266.20batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  60%|▌| 24687/40960 [01:34<01:01, 266.20batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  60%|▌| 24728/40960 [01:34<01:05, 247.82batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  60%|▌| 24728/40960 [01:34<01:05, 247.82batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  61%|▌| 24781/40960 [01:35<01:04, 251.82batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  61%|▌| 24781/40960 [01:35<01:04, 251.82batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  61%|▌| 24833/40960 [01:35<01:03, 253.14batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  61%|▌| 24833/40960 [01:35<01:03, 253.14batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  61%|▌| 24889/40960 [01:35<01:01, 259.79batches/s, l2_loss: 0.4480 - round_los\u001b[A\n",
      "Training:  61%|▌| 24889/40960 [01:35<01:01, 259.79batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24939/40960 [01:35<01:02, 256.33batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24939/40960 [01:35<01:02, 256.33batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24988/40960 [01:35<01:03, 252.76batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  61%|▌| 24988/40960 [01:35<01:03, 252.76batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  61%|▌| 25048/40960 [01:36<00:59, 266.13batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  61%|▌| 25048/40960 [01:36<00:59, 266.13batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  61%|▌| 25106/40960 [01:36<00:58, 273.17batches/s, l2_loss: 0.4479 - round_los\u001b[A\n",
      "Training:  61%|▌| 25106/40960 [01:36<00:58, 273.17batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25163/40960 [01:36<00:57, 275.74batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  61%|▌| 25163/40960 [01:36<00:57, 275.74batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25213/40960 [01:36<00:58, 266.90batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25213/40960 [01:36<00:58, 266.90batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25268/40960 [01:36<00:58, 267.94batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25268/40960 [01:36<00:58, 267.94batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  62%|▌| 25305/40960 [01:37<01:04, 242.60batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  62%|▌| 25305/40960 [01:37<01:04, 242.60batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25355/40960 [01:37<01:04, 242.76batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25355/40960 [01:37<01:04, 242.76batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  62%|▌| 25392/40960 [01:37<01:09, 223.11batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  62%|▌| 25392/40960 [01:37<01:09, 223.11batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25445/40960 [01:37<01:06, 234.45batches/s, l2_loss: 0.4481 - round_los\u001b[A\n",
      "Training:  62%|▌| 25445/40960 [01:37<01:06, 234.45batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  62%|▌| 25502/40960 [01:37<01:02, 248.78batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  62%|▌| 25502/40960 [01:37<01:02, 248.78batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25561/40960 [01:38<00:58, 261.00batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  62%|▌| 25561/40960 [01:38<00:58, 261.00batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  63%|▋| 25616/40960 [01:38<00:58, 263.63batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  63%|▋| 25616/40960 [01:38<00:58, 263.63batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  63%|▋| 25666/40960 [01:38<00:59, 258.15batches/s, l2_loss: 0.4483 - round_los\u001b[A\n",
      "Training:  63%|▋| 25666/40960 [01:38<00:59, 258.15batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  63%|▋| 25718/40960 [01:38<00:59, 257.75batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  63%|▋| 25718/40960 [01:38<00:59, 257.75batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  63%|▋| 25763/40960 [01:38<01:01, 247.51batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  63%|▋| 25763/40960 [01:38<01:01, 247.51batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  63%|▋| 25810/40960 [01:39<01:02, 241.02batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  63%|▋| 25810/40960 [01:39<01:02, 241.02batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  63%|▋| 25857/40960 [01:39<01:03, 238.01batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  63%|▋| 25857/40960 [01:39<01:03, 238.01batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  63%|▋| 25910/40960 [01:39<01:01, 245.44batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  63%|▋| 25910/40960 [01:39<01:01, 245.44batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25951/40960 [01:39<01:04, 232.32batches/s, l2_loss: 0.4482 - round_los\u001b[A\n",
      "Training:  63%|▋| 25951/40960 [01:39<01:04, 232.32batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  63%|▋| 26007/40960 [01:39<01:00, 246.15batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  63%|▋| 26007/40960 [01:39<01:00, 246.15batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  64%|▋| 26064/40960 [01:40<00:57, 257.06batches/s, l2_loss: 0.4484 - round_los\u001b[A\n",
      "Training:  64%|▋| 26064/40960 [01:40<00:57, 257.06batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  64%|▋| 26112/40960 [01:40<00:59, 251.54batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  64%|▋| 26112/40960 [01:40<00:59, 251.54batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  64%|▋| 26163/40960 [01:40<00:58, 252.48batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  64%|▋| 26163/40960 [01:40<00:58, 252.48batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  64%|▋| 26211/40960 [01:40<00:59, 248.37batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  64%|▋| 26211/40960 [01:40<00:59, 248.37batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  64%|▋| 26263/40960 [01:40<00:58, 251.17batches/s, l2_loss: 0.4486 - round_los\u001b[A\n",
      "Training:  64%|▋| 26263/40960 [01:41<00:58, 251.17batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  64%|▋| 26307/40960 [01:41<01:01, 239.79batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  64%|▋| 26307/40960 [01:41<01:01, 239.79batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  64%|▋| 26359/40960 [01:41<00:59, 244.51batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  64%|▋| 26359/40960 [01:41<00:59, 244.51batches/s, l2_loss: 0.4487 - round_los\u001b[A\n",
      "Training:  64%|▋| 26409/40960 [01:41<00:59, 244.85batches/s, l2_loss: 0.4487 - round_los\u001b[A\n",
      "Training:  64%|▋| 26409/40960 [01:41<00:59, 244.85batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  65%|▋| 26452/40960 [01:41<01:02, 233.57batches/s, l2_loss: 0.4485 - round_los\u001b[A\n",
      "Training:  65%|▋| 26452/40960 [01:41<01:02, 233.57batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  65%|▋| 26497/40960 [01:42<01:02, 230.07batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  65%|▋| 26497/40960 [01:42<01:02, 230.07batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  65%|▋| 26550/40960 [01:42<01:00, 238.77batches/s, l2_loss: 0.4488 - round_los\u001b[A\n",
      "Training:  65%|▋| 26550/40960 [01:42<01:00, 238.77batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  65%|▋| 26585/40960 [01:42<01:06, 217.23batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  65%|▋| 26585/40960 [01:42<01:06, 217.23batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  65%|▋| 26623/40960 [01:42<01:09, 207.19batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  65%|▋| 26623/40960 [01:42<01:09, 207.19batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  65%|▋| 26676/40960 [01:42<01:03, 223.49batches/s, l2_loss: 0.4489 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 26676/40960 [01:42<01:03, 223.49batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  65%|▋| 26725/40960 [01:43<01:01, 229.81batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  65%|▋| 26725/40960 [01:43<01:01, 229.81batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  65%|▋| 26776/40960 [01:43<00:59, 236.82batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  65%|▋| 26776/40960 [01:43<00:59, 236.82batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  65%|▋| 26828/40960 [01:43<00:58, 243.35batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  65%|▋| 26828/40960 [01:43<00:58, 243.35batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  66%|▋| 26883/40960 [01:43<00:55, 251.39batches/s, l2_loss: 0.4489 - round_los\u001b[A\n",
      "Training:  66%|▋| 26883/40960 [01:43<00:55, 251.39batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  66%|▋| 26921/40960 [01:43<01:00, 232.86batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  66%|▋| 26921/40960 [01:43<01:00, 232.86batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  66%|▋| 26965/40960 [01:44<01:01, 228.42batches/s, l2_loss: 0.4491 - round_los\u001b[A\n",
      "Training:  66%|▋| 26965/40960 [01:44<01:01, 228.42batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  66%|▋| 27024/40960 [01:44<00:56, 247.34batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  66%|▋| 27024/40960 [01:44<00:56, 247.34batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  66%|▋| 27075/40960 [01:44<00:55, 249.57batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  66%|▋| 27075/40960 [01:44<00:55, 249.57batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  66%|▋| 27135/40960 [01:44<00:52, 263.79batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  66%|▋| 27135/40960 [01:44<00:52, 263.79batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  66%|▋| 27197/40960 [01:44<00:49, 276.97batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  66%|▋| 27197/40960 [01:44<00:49, 276.97batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  67%|▋| 27257/40960 [01:45<00:48, 283.68batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  67%|▋| 27257/40960 [01:45<00:48, 283.68batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  67%|▋| 27315/40960 [01:45<00:48, 284.18batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  67%|▋| 27315/40960 [01:45<00:48, 284.18batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  67%|▋| 27373/40960 [01:45<00:47, 285.01batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  67%|▋| 27373/40960 [01:45<00:47, 285.01batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  67%|▋| 27428/40960 [01:45<00:48, 280.75batches/s, l2_loss: 0.4490 - round_los\u001b[A\n",
      "Training:  67%|▋| 27428/40960 [01:45<00:48, 280.75batches/s, l2_loss: 0.4493 - round_los\u001b[A\n",
      "Training:  67%|▋| 27483/40960 [01:45<00:48, 279.00batches/s, l2_loss: 0.4493 - round_los\u001b[A\n",
      "Training:  67%|▋| 27483/40960 [01:45<00:48, 279.00batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  67%|▋| 27531/40960 [01:46<00:50, 266.17batches/s, l2_loss: 0.4492 - round_los\u001b[A\n",
      "Training:  67%|▋| 27531/40960 [01:46<00:50, 266.17batches/s, l2_loss: 0.4494 - round_los\u001b[A\n",
      "Training:  67%|▋| 27585/40960 [01:46<00:50, 265.92batches/s, l2_loss: 0.4494 - round_los\u001b[A\n",
      "Training:  67%|▋| 27585/40960 [01:46<00:50, 265.92batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  67%|▋| 27639/40960 [01:46<00:49, 267.11batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  67%|▋| 27639/40960 [01:46<00:49, 267.11batches/s, l2_loss: 0.4495 - round_los\u001b[A\n",
      "Training:  68%|▋| 27699/40960 [01:46<00:48, 276.12batches/s, l2_loss: 0.4495 - round_los\u001b[A\n",
      "Training:  68%|▋| 27699/40960 [01:46<00:48, 276.12batches/s, l2_loss: 0.4496 - round_los\u001b[A\n",
      "Training:  68%|▋| 27752/40960 [01:46<00:48, 271.80batches/s, l2_loss: 0.4496 - round_los\u001b[A\n",
      "Training:  68%|▋| 27752/40960 [01:46<00:48, 271.80batches/s, l2_loss: 0.4496 - round_los\u001b[A\n",
      "Training:  68%|▋| 27801/40960 [01:47<00:50, 262.39batches/s, l2_loss: 0.4496 - round_los\u001b[A\n",
      "Training:  68%|▋| 27801/40960 [01:47<00:50, 262.39batches/s, l2_loss: 0.4496 - round_los\u001b[A\n",
      "Training:  68%|▋| 27836/40960 [01:47<00:55, 236.36batches/s, l2_loss: 0.4496 - round_los\u001b[A\n",
      "Training:  68%|▋| 27836/40960 [01:47<00:55, 236.36batches/s, l2_loss: 0.4496 - round_los\u001b[A\n",
      "Training:  68%|▋| 27890/40960 [01:47<00:53, 245.89batches/s, l2_loss: 0.4496 - round_los\u001b[A\n",
      "Training:  68%|▋| 27890/40960 [01:47<00:53, 245.89batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  68%|▋| 27950/40960 [01:47<00:49, 261.76batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  68%|▋| 27950/40960 [01:47<00:49, 261.76batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  68%|▋| 28006/40960 [01:47<00:48, 266.41batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  68%|▋| 28006/40960 [01:47<00:48, 266.41batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  68%|▋| 28056/40960 [01:48<00:49, 260.00batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  68%|▋| 28056/40960 [01:48<00:49, 260.00batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  69%|▋| 28101/40960 [01:48<00:51, 249.20batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  69%|▋| 28101/40960 [01:48<00:51, 249.20batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  69%|▋| 28146/40960 [01:48<00:53, 241.28batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  69%|▋| 28146/40960 [01:48<00:53, 241.28batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  69%|▋| 28198/40960 [01:48<00:51, 245.48batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  69%|▋| 28198/40960 [01:48<00:51, 245.48batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  69%|▋| 28256/40960 [01:48<00:49, 257.79batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  69%|▋| 28256/40960 [01:48<00:49, 257.79batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  69%|▋| 28312/40960 [01:49<00:47, 264.31batches/s, l2_loss: 0.4499 - round_los\u001b[A\n",
      "Training:  69%|▋| 28312/40960 [01:49<00:47, 264.31batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  69%|▋| 28362/40960 [01:49<00:48, 259.44batches/s, l2_loss: 0.4498 - round_los\u001b[A\n",
      "Training:  69%|▋| 28362/40960 [01:49<00:48, 259.44batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  69%|▋| 28414/40960 [01:49<00:48, 258.85batches/s, l2_loss: 0.4497 - round_los\u001b[A\n",
      "Training:  69%|▋| 28414/40960 [01:49<00:48, 258.85batches/s, l2_loss: 0.4500 - round_los\u001b[A\n",
      "Training:  69%|▋| 28463/40960 [01:49<00:49, 253.50batches/s, l2_loss: 0.4500 - round_los\u001b[A\n",
      "Training:  69%|▋| 28463/40960 [01:49<00:49, 253.50batches/s, l2_loss: 0.4501 - round_los\u001b[A\n",
      "Training:  70%|▋| 28513/40960 [01:49<00:49, 251.21batches/s, l2_loss: 0.4501 - round_los\u001b[A\n",
      "Training:  70%|▋| 28513/40960 [01:49<00:49, 251.21batches/s, l2_loss: 0.4502 - round_los\u001b[A\n",
      "Training:  70%|▋| 28571/40960 [01:50<00:47, 261.18batches/s, l2_loss: 0.4502 - round_los\u001b[A\n",
      "Training:  70%|▋| 28571/40960 [01:50<00:47, 261.18batches/s, l2_loss: 0.4500 - round_los\u001b[A\n",
      "Training:  70%|▋| 28627/40960 [01:50<00:46, 265.51batches/s, l2_loss: 0.4500 - round_los\u001b[A\n",
      "Training:  70%|▋| 28627/40960 [01:50<00:46, 265.51batches/s, l2_loss: 0.4501 - round_los\u001b[A\n",
      "Training:  70%|▋| 28684/40960 [01:50<00:45, 270.91batches/s, l2_loss: 0.4501 - round_los\u001b[A\n",
      "Training:  70%|▋| 28684/40960 [01:50<00:45, 270.91batches/s, l2_loss: 0.4503 - round_los\u001b[A\n",
      "Training:  70%|▋| 28742/40960 [01:50<00:44, 276.56batches/s, l2_loss: 0.4503 - round_los\u001b[A\n",
      "Training:  70%|▋| 28742/40960 [01:50<00:44, 276.56batches/s, l2_loss: 0.4501 - round_los\u001b[A\n",
      "Training:  70%|▋| 28800/40960 [01:50<00:43, 279.83batches/s, l2_loss: 0.4501 - round_los\u001b[A\n",
      "Training:  70%|▋| 28800/40960 [01:50<00:43, 279.83batches/s, l2_loss: 0.4504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28858/40960 [01:51<00:42, 282.21batches/s, l2_loss: 0.4504 - round_los\u001b[A\n",
      "Training:  70%|▋| 28858/40960 [01:51<00:42, 282.21batches/s, l2_loss: 0.4504 - round_los\u001b[A\n",
      "Training:  71%|▋| 28911/40960 [01:51<00:43, 276.66batches/s, l2_loss: 0.4504 - round_los\u001b[A\n",
      "Training:  71%|▋| 28911/40960 [01:51<00:43, 276.66batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  71%|▋| 28970/40960 [01:51<00:42, 280.24batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  71%|▋| 28970/40960 [01:51<00:42, 280.24batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  71%|▋| 29024/40960 [01:51<00:43, 276.12batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  71%|▋| 29024/40960 [01:51<00:43, 276.12batches/s, l2_loss: 0.4505 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|▋| 29085/40960 [01:51<00:41, 283.43batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  71%|▋| 29085/40960 [01:51<00:41, 283.43batches/s, l2_loss: 0.4504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29141/40960 [01:52<00:42, 281.00batches/s, l2_loss: 0.4504 - round_los\u001b[A\n",
      "Training:  71%|▋| 29141/40960 [01:52<00:42, 281.00batches/s, l2_loss: 0.4506 - round_los\u001b[A\n",
      "Training:  71%|▋| 29198/40960 [01:52<00:41, 281.80batches/s, l2_loss: 0.4506 - round_los\u001b[A\n",
      "Training:  71%|▋| 29198/40960 [01:52<00:41, 281.80batches/s, l2_loss: 0.4507 - round_los\u001b[A\n",
      "Training:  71%|▋| 29255/40960 [01:52<00:41, 282.75batches/s, l2_loss: 0.4507 - round_los\u001b[A\n",
      "Training:  71%|▋| 29255/40960 [01:52<00:41, 282.75batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  72%|▋| 29311/40960 [01:52<00:41, 281.74batches/s, l2_loss: 0.4505 - round_los\u001b[A\n",
      "Training:  72%|▋| 29311/40960 [01:52<00:41, 281.74batches/s, l2_loss: 0.4508 - round_los\u001b[A\n",
      "Training:  72%|▋| 29367/40960 [01:52<00:41, 280.95batches/s, l2_loss: 0.4508 - round_los\u001b[A\n",
      "Training:  72%|▋| 29367/40960 [01:52<00:41, 280.95batches/s, l2_loss: 0.4506 - round_los\u001b[A\n",
      "Training:  72%|▋| 29420/40960 [01:53<00:41, 276.08batches/s, l2_loss: 0.4506 - round_los\u001b[A\n",
      "Training:  72%|▋| 29420/40960 [01:53<00:41, 276.08batches/s, l2_loss: 0.4508 - round_los\u001b[A\n",
      "Training:  72%|▋| 29468/40960 [01:53<00:43, 264.57batches/s, l2_loss: 0.4508 - round_los\u001b[A\n",
      "Training:  72%|▋| 29468/40960 [01:53<00:43, 264.57batches/s, l2_loss: 0.4509 - round_los\u001b[A\n",
      "Training:  72%|▋| 29521/40960 [01:53<00:43, 264.16batches/s, l2_loss: 0.4509 - round_los\u001b[A\n",
      "Training:  72%|▋| 29521/40960 [01:53<00:43, 264.16batches/s, l2_loss: 0.4510 - round_los\u001b[A\n",
      "Training:  72%|▋| 29576/40960 [01:53<00:42, 267.39batches/s, l2_loss: 0.4510 - round_los\u001b[A\n",
      "Training:  72%|▋| 29576/40960 [01:53<00:42, 267.39batches/s, l2_loss: 0.4510 - round_los\u001b[A\n",
      "Training:  72%|▋| 29631/40960 [01:53<00:42, 269.42batches/s, l2_loss: 0.4510 - round_los\u001b[A\n",
      "Training:  72%|▋| 29631/40960 [01:53<00:42, 269.42batches/s, l2_loss: 0.4512 - round_los\u001b[A\n",
      "Training:  72%|▋| 29677/40960 [01:54<00:43, 257.40batches/s, l2_loss: 0.4512 - round_los\u001b[A\n",
      "Training:  72%|▋| 29677/40960 [01:54<00:43, 257.40batches/s, l2_loss: 0.4513 - round_los\u001b[A\n",
      "Training:  73%|▋| 29723/40960 [01:54<00:45, 248.21batches/s, l2_loss: 0.4513 - round_los\u001b[A\n",
      "Training:  73%|▋| 29723/40960 [01:54<00:45, 248.21batches/s, l2_loss: 0.4511 - round_los\u001b[A\n",
      "Training:  73%|▋| 29777/40960 [01:54<00:43, 254.69batches/s, l2_loss: 0.4511 - round_los\u001b[A\n",
      "Training:  73%|▋| 29777/40960 [01:54<00:43, 254.69batches/s, l2_loss: 0.4511 - round_los\u001b[A\n",
      "Training:  73%|▋| 29830/40960 [01:54<00:43, 257.72batches/s, l2_loss: 0.4511 - round_los\u001b[A\n",
      "Training:  73%|▋| 29830/40960 [01:54<00:43, 257.72batches/s, l2_loss: 0.4513 - round_los\u001b[A\n",
      "Training:  73%|▋| 29880/40960 [01:54<00:43, 254.50batches/s, l2_loss: 0.4513 - round_los\u001b[A\n",
      "Training:  73%|▋| 29880/40960 [01:54<00:43, 254.50batches/s, l2_loss: 0.4513 - round_los\u001b[A\n",
      "Training:  73%|▋| 29929/40960 [01:55<00:44, 250.23batches/s, l2_loss: 0.4513 - round_los\u001b[A\n",
      "Training:  73%|▋| 29929/40960 [01:55<00:44, 250.23batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  73%|▋| 29985/40960 [01:55<00:42, 259.02batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  73%|▋| 29985/40960 [01:55<00:42, 259.02batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  73%|▋| 30041/40960 [01:55<00:41, 265.07batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  73%|▋| 30041/40960 [01:55<00:41, 265.07batches/s, l2_loss: 0.4516 - round_los\u001b[A\n",
      "Training:  73%|▋| 30094/40960 [01:55<00:41, 263.93batches/s, l2_loss: 0.4516 - round_los\u001b[A\n",
      "Training:  73%|▋| 30094/40960 [01:55<00:41, 263.93batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  74%|▋| 30144/40960 [01:55<00:41, 258.48batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  74%|▋| 30144/40960 [01:55<00:41, 258.48batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  74%|▋| 30198/40960 [01:56<00:41, 260.86batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  74%|▋| 30198/40960 [01:56<00:41, 260.86batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  74%|▋| 30256/40960 [01:56<00:39, 268.85batches/s, l2_loss: 0.4515 - round_los\u001b[A\n",
      "Training:  74%|▋| 30256/40960 [01:56<00:39, 268.85batches/s, l2_loss: 0.4519 - round_los\u001b[A\n",
      "Training:  74%|▋| 30305/40960 [01:56<00:40, 260.27batches/s, l2_loss: 0.4519 - round_los\u001b[A\n",
      "Training:  74%|▋| 30305/40960 [01:56<00:40, 260.27batches/s, l2_loss: 0.4518 - round_los\u001b[A\n",
      "Training:  74%|▋| 30356/40960 [01:56<00:41, 257.33batches/s, l2_loss: 0.4518 - round_los\u001b[A\n",
      "Training:  74%|▋| 30356/40960 [01:56<00:41, 257.33batches/s, l2_loss: 0.4520 - round_los\u001b[A\n",
      "Training:  74%|▋| 30409/40960 [01:56<00:40, 259.47batches/s, l2_loss: 0.4520 - round_los\u001b[A\n",
      "Training:  74%|▋| 30409/40960 [01:56<00:40, 259.47batches/s, l2_loss: 0.4519 - round_los\u001b[A\n",
      "Training:  74%|▋| 30462/40960 [01:57<00:40, 259.63batches/s, l2_loss: 0.4519 - round_los\u001b[A\n",
      "Training:  74%|▋| 30462/40960 [01:57<00:40, 259.63batches/s, l2_loss: 0.4519 - round_los\u001b[A\n",
      "Training:  74%|▋| 30511/40960 [01:57<00:41, 254.56batches/s, l2_loss: 0.4519 - round_los\u001b[A\n",
      "Training:  74%|▋| 30511/40960 [01:57<00:41, 254.56batches/s, l2_loss: 0.4521 - round_los\u001b[A\n",
      "Training:  75%|▋| 30555/40960 [01:57<00:42, 243.91batches/s, l2_loss: 0.4521 - round_los\u001b[A\n",
      "Training:  75%|▋| 30555/40960 [01:57<00:42, 243.91batches/s, l2_loss: 0.4520 - round_los\u001b[A\n",
      "Training:  75%|▋| 30602/40960 [01:57<00:42, 241.21batches/s, l2_loss: 0.4520 - round_los\u001b[A\n",
      "Training:  75%|▋| 30602/40960 [01:57<00:42, 241.21batches/s, l2_loss: 0.4521 - round_los\u001b[A\n",
      "Training:  75%|▋| 30642/40960 [01:57<00:45, 228.81batches/s, l2_loss: 0.4521 - round_los\u001b[A\n",
      "Training:  75%|▋| 30642/40960 [01:57<00:45, 228.81batches/s, l2_loss: 0.4521 - round_los\u001b[A\n",
      "Training:  75%|▋| 30675/40960 [01:58<00:49, 209.36batches/s, l2_loss: 0.4521 - round_los\u001b[A\n",
      "Training:  75%|▋| 30675/40960 [01:58<00:49, 209.36batches/s, l2_loss: 0.4523 - round_los\u001b[A\n",
      "Training:  75%|▊| 30722/40960 [01:58<00:47, 216.57batches/s, l2_loss: 0.4523 - round_los\u001b[A\n",
      "Training:  75%|▊| 30722/40960 [01:58<00:47, 216.57batches/s, l2_loss: 0.4522 - round_los\u001b[A\n",
      "Training:  75%|▊| 30768/40960 [01:58<00:46, 219.31batches/s, l2_loss: 0.4522 - round_los\u001b[A\n",
      "Training:  75%|▊| 30768/40960 [01:58<00:46, 219.31batches/s, l2_loss: 0.4521 - round_los\u001b[A\n",
      "Training:  75%|▊| 30820/40960 [01:58<00:43, 230.70batches/s, l2_loss: 0.4521 - round_los\u001b[A\n",
      "Training:  75%|▊| 30820/40960 [01:58<00:43, 230.70batches/s, l2_loss: 0.4522 - round_los\u001b[A\n",
      "Training:  75%|▊| 30876/40960 [01:58<00:41, 244.83batches/s, l2_loss: 0.4522 - round_los\u001b[A\n",
      "Training:  75%|▊| 30876/40960 [01:58<00:41, 244.83batches/s, l2_loss: 0.4526 - round_los\u001b[A\n",
      "Training:  76%|▊| 30926/40960 [01:59<00:40, 245.74batches/s, l2_loss: 0.4526 - round_los\u001b[A\n",
      "Training:  76%|▊| 30926/40960 [01:59<00:40, 245.74batches/s, l2_loss: 0.4525 - round_los\u001b[A\n",
      "Training:  76%|▊| 30975/40960 [01:59<00:40, 244.97batches/s, l2_loss: 0.4525 - round_los\u001b[A\n",
      "Training:  76%|▊| 30975/40960 [01:59<00:40, 244.97batches/s, l2_loss: 0.4524 - round_los\u001b[A\n",
      "Training:  76%|▊| 31032/40960 [01:59<00:38, 256.81batches/s, l2_loss: 0.4524 - round_los\u001b[A\n",
      "Training:  76%|▊| 31032/40960 [01:59<00:38, 256.81batches/s, l2_loss: 0.4524 - round_los\u001b[A\n",
      "Training:  76%|▊| 31084/40960 [01:59<00:38, 257.16batches/s, l2_loss: 0.4524 - round_los\u001b[A\n",
      "Training:  76%|▊| 31084/40960 [01:59<00:38, 257.16batches/s, l2_loss: 0.4527 - round_los\u001b[A\n",
      "Training:  76%|▊| 31132/40960 [01:59<00:39, 250.69batches/s, l2_loss: 0.4527 - round_los\u001b[A\n",
      "Training:  76%|▊| 31132/40960 [02:00<00:39, 250.69batches/s, l2_loss: 0.4526 - round_los\u001b[A\n",
      "Training:  76%|▊| 31182/40960 [02:00<00:39, 249.19batches/s, l2_loss: 0.4526 - round_los\u001b[A\n",
      "Training:  76%|▊| 31182/40960 [02:00<00:39, 249.19batches/s, l2_loss: 0.4528 - round_los\u001b[A\n",
      "Training:  76%|▊| 31241/40960 [02:00<00:37, 262.60batches/s, l2_loss: 0.4528 - round_los\u001b[A\n",
      "Training:  76%|▊| 31241/40960 [02:00<00:37, 262.60batches/s, l2_loss: 0.4528 - round_los\u001b[A\n",
      "Training:  76%|▊| 31303/40960 [02:00<00:35, 275.53batches/s, l2_loss: 0.4528 - round_los\u001b[A\n",
      "Training:  76%|▊| 31303/40960 [02:00<00:35, 275.53batches/s, l2_loss: 0.4529 - round_los\u001b[A\n",
      "Training:  77%|▊| 31362/40960 [02:00<00:34, 280.66batches/s, l2_loss: 0.4529 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|▊| 31362/40960 [02:00<00:34, 280.66batches/s, l2_loss: 0.4529 - round_los\u001b[A\n",
      "Training:  77%|▊| 31420/40960 [02:01<00:33, 282.43batches/s, l2_loss: 0.4529 - round_los\u001b[A\n",
      "Training:  77%|▊| 31420/40960 [02:01<00:33, 282.43batches/s, l2_loss: 0.4530 - round_los\u001b[A\n",
      "Training:  77%|▊| 31480/40960 [02:01<00:33, 286.20batches/s, l2_loss: 0.4530 - round_los\u001b[A\n",
      "Training:  77%|▊| 31480/40960 [02:01<00:33, 286.20batches/s, l2_loss: 0.4531 - round_los\u001b[A\n",
      "Training:  77%|▊| 31533/40960 [02:01<00:33, 278.22batches/s, l2_loss: 0.4531 - round_los\u001b[A\n",
      "Training:  77%|▊| 31533/40960 [02:01<00:33, 278.22batches/s, l2_loss: 0.4534 - round_los\u001b[A\n",
      "Training:  77%|▊| 31589/40960 [02:01<00:33, 278.60batches/s, l2_loss: 0.4534 - round_los\u001b[A\n",
      "Training:  77%|▊| 31589/40960 [02:01<00:33, 278.60batches/s, l2_loss: 0.4534 - round_los\u001b[A\n",
      "Training:  77%|▊| 31647/40960 [02:01<00:33, 281.22batches/s, l2_loss: 0.4534 - round_los\u001b[A\n",
      "Training:  77%|▊| 31647/40960 [02:01<00:33, 281.22batches/s, l2_loss: 0.4533 - round_los\u001b[A\n",
      "Training:  77%|▊| 31704/40960 [02:02<00:32, 281.88batches/s, l2_loss: 0.4533 - round_los\u001b[A\n",
      "Training:  77%|▊| 31704/40960 [02:02<00:32, 281.88batches/s, l2_loss: 0.4533 - round_los\u001b[A\n",
      "Training:  78%|▊| 31762/40960 [02:02<00:32, 283.61batches/s, l2_loss: 0.4533 - round_los\u001b[A\n",
      "Training:  78%|▊| 31762/40960 [02:02<00:32, 283.61batches/s, l2_loss: 0.4535 - round_los\u001b[A\n",
      "Training:  78%|▊| 31811/40960 [02:02<00:33, 271.46batches/s, l2_loss: 0.4535 - round_los\u001b[A\n",
      "Training:  78%|▊| 31811/40960 [02:02<00:33, 271.46batches/s, l2_loss: 0.4535 - round_los\u001b[A\n",
      "Training:  78%|▊| 31872/40960 [02:02<00:32, 280.12batches/s, l2_loss: 0.4535 - round_los\u001b[A\n",
      "Training:  78%|▊| 31872/40960 [02:02<00:32, 280.12batches/s, l2_loss: 0.4536 - round_los\u001b[A\n",
      "Training:  78%|▊| 31931/40960 [02:02<00:31, 283.24batches/s, l2_loss: 0.4536 - round_los\u001b[A\n",
      "Training:  78%|▊| 31931/40960 [02:02<00:31, 283.24batches/s, l2_loss: 0.4537 - round_los\u001b[A\n",
      "Training:  78%|▊| 31990/40960 [02:03<00:31, 285.94batches/s, l2_loss: 0.4537 - round_los\u001b[A\n",
      "Training:  78%|▊| 31990/40960 [02:03<00:31, 285.94batches/s, l2_loss: 0.4537 - round_los\u001b[A\n",
      "Training:  78%|▊| 32050/40960 [02:03<00:30, 289.27batches/s, l2_loss: 0.4537 - round_los\u001b[A\n",
      "Training:  78%|▊| 32050/40960 [02:03<00:30, 289.27batches/s, l2_loss: 0.4538 - round_los\u001b[A\n",
      "Training:  78%|▊| 32107/40960 [02:03<00:30, 287.27batches/s, l2_loss: 0.4538 - round_los\u001b[A\n",
      "Training:  78%|▊| 32107/40960 [02:03<00:30, 287.27batches/s, l2_loss: 0.4540 - round_los\u001b[A\n",
      "Training:  79%|▊| 32165/40960 [02:03<00:30, 287.80batches/s, l2_loss: 0.4540 - round_los\u001b[A\n",
      "Training:  79%|▊| 32165/40960 [02:03<00:30, 287.80batches/s, l2_loss: 0.4538 - round_los\u001b[A\n",
      "Training:  79%|▊| 32220/40960 [02:03<00:30, 282.86batches/s, l2_loss: 0.4538 - round_los\u001b[A\n",
      "Training:  79%|▊| 32220/40960 [02:03<00:30, 282.86batches/s, l2_loss: 0.4539 - round_los\u001b[A\n",
      "Training:  79%|▊| 32279/40960 [02:04<00:30, 286.25batches/s, l2_loss: 0.4539 - round_los\u001b[A\n",
      "Training:  79%|▊| 32279/40960 [02:04<00:30, 286.25batches/s, l2_loss: 0.4541 - round_los\u001b[A\n",
      "Training:  79%|▊| 32332/40960 [02:04<00:31, 276.97batches/s, l2_loss: 0.4541 - round_los\u001b[A\n",
      "Training:  79%|▊| 32332/40960 [02:04<00:31, 276.97batches/s, l2_loss: 0.4542 - round_los\u001b[A\n",
      "Training:  79%|▊| 32373/40960 [02:04<00:33, 255.30batches/s, l2_loss: 0.4542 - round_los\u001b[A\n",
      "Training:  79%|▊| 32373/40960 [02:04<00:33, 255.30batches/s, l2_loss: 0.4542 - round_los\u001b[A\n",
      "Training:  79%|▊| 32420/40960 [02:04<00:34, 245.88batches/s, l2_loss: 0.4542 - round_los\u001b[A\n",
      "Training:  79%|▊| 32420/40960 [02:04<00:34, 245.88batches/s, l2_loss: 0.4543 - round_los\u001b[A\n",
      "Training:  79%|▊| 32468/40960 [02:04<00:34, 243.19batches/s, l2_loss: 0.4543 - round_los\u001b[A\n",
      "Training:  79%|▊| 32468/40960 [02:04<00:34, 243.19batches/s, l2_loss: 0.4543 - round_los\u001b[A\n",
      "Training:  79%|▊| 32519/40960 [02:05<00:34, 245.46batches/s, l2_loss: 0.4543 - round_los\u001b[A\n",
      "Training:  79%|▊| 32519/40960 [02:05<00:34, 245.46batches/s, l2_loss: 0.4544 - round_los\u001b[A\n",
      "Training:  80%|▊| 32568/40960 [02:05<00:34, 243.49batches/s, l2_loss: 0.4544 - round_los\u001b[A\n",
      "Training:  80%|▊| 32568/40960 [02:05<00:34, 243.49batches/s, l2_loss: 0.4544 - round_los\u001b[A\n",
      "Training:  80%|▊| 32623/40960 [02:05<00:33, 251.46batches/s, l2_loss: 0.4544 - round_los\u001b[A\n",
      "Training:  80%|▊| 32623/40960 [02:05<00:33, 251.46batches/s, l2_loss: 0.4544 - round_los\u001b[A\n",
      "Training:  80%|▊| 32681/40960 [02:05<00:31, 262.03batches/s, l2_loss: 0.4544 - round_los\u001b[A\n",
      "Training:  80%|▊| 32681/40960 [02:05<00:31, 262.03batches/s, l2_loss: 0.4547 - round_los\u001b[A\n",
      "Training:  80%|▊| 32738/40960 [02:05<00:30, 267.35batches/s, l2_loss: 0.4547 - round_los\u001b[A\n",
      "Training:  80%|▊| 32738/40960 [02:05<00:30, 267.35batches/s, l2_loss: 0.4549 - round_los\u001b[A\n",
      "Training:  80%|▊| 32795/40960 [02:06<00:29, 272.53batches/s, l2_loss: 0.4549 - round_los\u001b[A\n",
      "Training:  80%|▊| 32795/40960 [02:06<00:29, 272.53batches/s, l2_loss: 0.4548 - round_los\u001b[A\n",
      "Training:  80%|▊| 32843/40960 [02:06<00:30, 262.80batches/s, l2_loss: 0.4548 - round_los\u001b[A\n",
      "Training:  80%|▊| 32843/40960 [02:06<00:30, 262.80batches/s, l2_loss: 0.4550 - round_los\u001b[A\n",
      "Training:  80%|▊| 32898/40960 [02:06<00:30, 264.59batches/s, l2_loss: 0.4550 - round_los\u001b[A\n",
      "Training:  80%|▊| 32898/40960 [02:06<00:30, 264.59batches/s, l2_loss: 0.4550 - round_los\u001b[A\n",
      "Training:  80%|▊| 32948/40960 [02:06<00:30, 259.97batches/s, l2_loss: 0.4550 - round_los\u001b[A\n",
      "Training:  80%|▊| 32948/40960 [02:06<00:30, 259.97batches/s, l2_loss: 0.4552 - round_los\u001b[A\n",
      "Training:  81%|▊| 32999/40960 [02:06<00:30, 256.95batches/s, l2_loss: 0.4552 - round_los\u001b[A\n",
      "Training:  81%|▊| 32999/40960 [02:06<00:30, 256.95batches/s, l2_loss: 0.4553 - round_los\u001b[A\n",
      "Training:  81%|▊| 33053/40960 [02:07<00:30, 259.71batches/s, l2_loss: 0.4553 - round_los\u001b[A\n",
      "Training:  81%|▊| 33053/40960 [02:07<00:30, 259.71batches/s, l2_loss: 0.4554 - round_los\u001b[A\n",
      "Training:  81%|▊| 33111/40960 [02:07<00:29, 268.41batches/s, l2_loss: 0.4554 - round_los\u001b[A\n",
      "Training:  81%|▊| 33111/40960 [02:07<00:29, 268.41batches/s, l2_loss: 0.4553 - round_los\u001b[A\n",
      "Training:  81%|▊| 33164/40960 [02:07<00:29, 267.16batches/s, l2_loss: 0.4553 - round_los\u001b[A\n",
      "Training:  81%|▊| 33164/40960 [02:07<00:29, 267.16batches/s, l2_loss: 0.4554 - round_los\u001b[A\n",
      "Training:  81%|▊| 33219/40960 [02:07<00:28, 269.19batches/s, l2_loss: 0.4554 - round_los\u001b[A\n",
      "Training:  81%|▊| 33219/40960 [02:07<00:28, 269.19batches/s, l2_loss: 0.4556 - round_los\u001b[A\n",
      "Training:  81%|▊| 33267/40960 [02:07<00:29, 260.10batches/s, l2_loss: 0.4556 - round_los\u001b[A\n",
      "Training:  81%|▊| 33267/40960 [02:07<00:29, 260.10batches/s, l2_loss: 0.4556 - round_los\u001b[A\n",
      "Training:  81%|▊| 33319/40960 [02:08<00:29, 259.63batches/s, l2_loss: 0.4556 - round_los\u001b[A\n",
      "Training:  81%|▊| 33319/40960 [02:08<00:29, 259.63batches/s, l2_loss: 0.4558 - round_los\u001b[A\n",
      "Training:  81%|▊| 33371/40960 [02:08<00:29, 258.74batches/s, l2_loss: 0.4558 - round_los\u001b[A\n",
      "Training:  81%|▊| 33371/40960 [02:08<00:29, 258.74batches/s, l2_loss: 0.4558 - round_los\u001b[A\n",
      "Training:  82%|▊| 33423/40960 [02:08<00:29, 258.60batches/s, l2_loss: 0.4558 - round_los\u001b[A\n",
      "Training:  82%|▊| 33423/40960 [02:08<00:29, 258.60batches/s, l2_loss: 0.4559 - round_los\u001b[A\n",
      "Training:  82%|▊| 33482/40960 [02:08<00:27, 268.34batches/s, l2_loss: 0.4559 - round_los\u001b[A\n",
      "Training:  82%|▊| 33482/40960 [02:08<00:27, 268.34batches/s, l2_loss: 0.4558 - round_los\u001b[A\n",
      "Training:  82%|▊| 33538/40960 [02:08<00:27, 271.72batches/s, l2_loss: 0.4558 - round_los\u001b[A\n",
      "Training:  82%|▊| 33538/40960 [02:08<00:27, 271.72batches/s, l2_loss: 0.4560 - round_los\u001b[A\n",
      "Training:  82%|▊| 33581/40960 [02:09<00:29, 253.95batches/s, l2_loss: 0.4560 - round_los\u001b[A\n",
      "Training:  82%|▊| 33581/40960 [02:09<00:29, 253.95batches/s, l2_loss: 0.4561 - round_los\u001b[A\n",
      "Training:  82%|▊| 33636/40960 [02:09<00:28, 259.53batches/s, l2_loss: 0.4561 - round_los\u001b[A\n",
      "Training:  82%|▊| 33636/40960 [02:09<00:28, 259.53batches/s, l2_loss: 0.4563 - round_los\u001b[A\n",
      "Training:  82%|▊| 33697/40960 [02:09<00:26, 272.32batches/s, l2_loss: 0.4563 - round_los\u001b[A\n",
      "Training:  82%|▊| 33697/40960 [02:09<00:26, 272.32batches/s, l2_loss: 0.4563 - round_los\u001b[A\n",
      "Training:  82%|▊| 33758/40960 [02:09<00:25, 281.10batches/s, l2_loss: 0.4563 - round_los\u001b[A\n",
      "Training:  82%|▊| 33758/40960 [02:09<00:25, 281.10batches/s, l2_loss: 0.4564 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 33819/40960 [02:09<00:24, 288.07batches/s, l2_loss: 0.4564 - round_los\u001b[A\n",
      "Training:  83%|▊| 33819/40960 [02:09<00:24, 288.07batches/s, l2_loss: 0.4564 - round_los\u001b[A\n",
      "Training:  83%|▊| 33871/40960 [02:10<00:25, 279.10batches/s, l2_loss: 0.4564 - round_los\u001b[A\n",
      "Training:  83%|▊| 33871/40960 [02:10<00:25, 279.10batches/s, l2_loss: 0.4567 - round_los\u001b[A\n",
      "Training:  83%|▊| 33919/40960 [02:10<00:26, 265.60batches/s, l2_loss: 0.4567 - round_los\u001b[A\n",
      "Training:  83%|▊| 33919/40960 [02:10<00:26, 265.60batches/s, l2_loss: 0.4567 - round_los\u001b[A\n",
      "Training:  83%|▊| 33976/40960 [02:10<00:25, 270.50batches/s, l2_loss: 0.4567 - round_los\u001b[A\n",
      "Training:  83%|▊| 33976/40960 [02:10<00:25, 270.50batches/s, l2_loss: 0.4568 - round_los\u001b[A\n",
      "Training:  83%|▊| 34028/40960 [02:10<00:26, 264.84batches/s, l2_loss: 0.4568 - round_los\u001b[A\n",
      "Training:  83%|▊| 34028/40960 [02:10<00:26, 264.84batches/s, l2_loss: 0.4568 - round_los\u001b[A\n",
      "Training:  83%|▊| 34076/40960 [02:10<00:26, 257.40batches/s, l2_loss: 0.4568 - round_los\u001b[A\n",
      "Training:  83%|▊| 34076/40960 [02:10<00:26, 257.40batches/s, l2_loss: 0.4570 - round_los\u001b[A\n",
      "Training:  83%|▊| 34127/40960 [02:11<00:26, 256.51batches/s, l2_loss: 0.4570 - round_los\u001b[A\n",
      "Training:  83%|▊| 34127/40960 [02:11<00:26, 256.51batches/s, l2_loss: 0.4571 - round_los\u001b[A\n",
      "Training:  83%|▊| 34175/40960 [02:11<00:27, 250.52batches/s, l2_loss: 0.4571 - round_los\u001b[A\n",
      "Training:  83%|▊| 34175/40960 [02:11<00:27, 250.52batches/s, l2_loss: 0.4571 - round_los\u001b[A\n",
      "Training:  84%|▊| 34211/40960 [02:11<00:29, 229.10batches/s, l2_loss: 0.4571 - round_los\u001b[A\n",
      "Training:  84%|▊| 34211/40960 [02:11<00:29, 229.10batches/s, l2_loss: 0.4573 - round_los\u001b[A\n",
      "Training:  84%|▊| 34259/40960 [02:11<00:28, 231.16batches/s, l2_loss: 0.4573 - round_los\u001b[A\n",
      "Training:  84%|▊| 34259/40960 [02:11<00:28, 231.16batches/s, l2_loss: 0.4572 - round_los\u001b[A\n",
      "Training:  84%|▊| 34313/40960 [02:11<00:27, 241.71batches/s, l2_loss: 0.4572 - round_los\u001b[A\n",
      "Training:  84%|▊| 34313/40960 [02:11<00:27, 241.71batches/s, l2_loss: 0.4573 - round_los\u001b[A\n",
      "Training:  84%|▊| 34364/40960 [02:12<00:26, 244.73batches/s, l2_loss: 0.4573 - round_los\u001b[A\n",
      "Training:  84%|▊| 34364/40960 [02:12<00:26, 244.73batches/s, l2_loss: 0.4574 - round_los\u001b[A\n",
      "Training:  84%|▊| 34411/40960 [02:12<00:27, 240.59batches/s, l2_loss: 0.4574 - round_los\u001b[A\n",
      "Training:  84%|▊| 34411/40960 [02:12<00:27, 240.59batches/s, l2_loss: 0.4576 - round_los\u001b[A\n",
      "Training:  84%|▊| 34464/40960 [02:12<00:26, 246.55batches/s, l2_loss: 0.4576 - round_los\u001b[A\n",
      "Training:  84%|▊| 34464/40960 [02:12<00:26, 246.55batches/s, l2_loss: 0.4576 - round_los\u001b[A\n",
      "Training:  84%|▊| 34509/40960 [02:12<00:26, 239.74batches/s, l2_loss: 0.4576 - round_los\u001b[A\n",
      "Training:  84%|▊| 34509/40960 [02:12<00:26, 239.74batches/s, l2_loss: 0.4578 - round_los\u001b[A\n",
      "Training:  84%|▊| 34554/40960 [02:12<00:27, 235.07batches/s, l2_loss: 0.4578 - round_los\u001b[A\n",
      "Training:  84%|▊| 34554/40960 [02:12<00:27, 235.07batches/s, l2_loss: 0.4578 - round_los\u001b[A\n",
      "Training:  84%|▊| 34607/40960 [02:13<00:26, 243.13batches/s, l2_loss: 0.4578 - round_los\u001b[A\n",
      "Training:  84%|▊| 34607/40960 [02:13<00:26, 243.13batches/s, l2_loss: 0.4579 - round_los\u001b[A\n",
      "Training:  85%|▊| 34661/40960 [02:13<00:25, 250.72batches/s, l2_loss: 0.4579 - round_los\u001b[A\n",
      "Training:  85%|▊| 34661/40960 [02:13<00:25, 250.72batches/s, l2_loss: 0.4580 - round_los\u001b[A\n",
      "Training:  85%|▊| 34715/40960 [02:13<00:24, 254.85batches/s, l2_loss: 0.4580 - round_los\u001b[A\n",
      "Training:  85%|▊| 34715/40960 [02:13<00:24, 254.85batches/s, l2_loss: 0.4581 - round_los\u001b[A\n",
      "Training:  85%|▊| 34766/40960 [02:13<00:24, 254.64batches/s, l2_loss: 0.4581 - round_los\u001b[A\n",
      "Training:  85%|▊| 34766/40960 [02:13<00:24, 254.64batches/s, l2_loss: 0.4582 - round_los\u001b[A\n",
      "Training:  85%|▊| 34814/40960 [02:13<00:24, 249.10batches/s, l2_loss: 0.4582 - round_los\u001b[A\n",
      "Training:  85%|▊| 34814/40960 [02:13<00:24, 249.10batches/s, l2_loss: 0.4583 - round_los\u001b[A\n",
      "Training:  85%|▊| 34863/40960 [02:14<00:24, 247.46batches/s, l2_loss: 0.4583 - round_los\u001b[A\n",
      "Training:  85%|▊| 34863/40960 [02:14<00:24, 247.46batches/s, l2_loss: 0.4584 - round_los\u001b[A\n",
      "Training:  85%|▊| 34918/40960 [02:14<00:23, 254.65batches/s, l2_loss: 0.4584 - round_los\u001b[A\n",
      "Training:  85%|▊| 34918/40960 [02:14<00:23, 254.65batches/s, l2_loss: 0.4586 - round_los\u001b[A\n",
      "Training:  85%|▊| 34972/40960 [02:14<00:23, 259.07batches/s, l2_loss: 0.4586 - round_los\u001b[A\n",
      "Training:  85%|▊| 34972/40960 [02:14<00:23, 259.07batches/s, l2_loss: 0.4588 - round_los\u001b[A\n",
      "Training:  86%|▊| 35025/40960 [02:14<00:22, 259.49batches/s, l2_loss: 0.4588 - round_los\u001b[A\n",
      "Training:  86%|▊| 35025/40960 [02:14<00:22, 259.49batches/s, l2_loss: 0.4588 - round_los\u001b[A\n",
      "Training:  86%|▊| 35081/40960 [02:14<00:22, 264.24batches/s, l2_loss: 0.4588 - round_los\u001b[A\n",
      "Training:  86%|▊| 35081/40960 [02:14<00:22, 264.24batches/s, l2_loss: 0.4588 - round_los\u001b[A\n",
      "Training:  86%|▊| 35142/40960 [02:15<00:21, 275.47batches/s, l2_loss: 0.4588 - round_los\u001b[A\n",
      "Training:  86%|▊| 35142/40960 [02:15<00:21, 275.47batches/s, l2_loss: 0.4589 - round_los\u001b[A\n",
      "Training:  86%|▊| 35202/40960 [02:15<00:20, 281.70batches/s, l2_loss: 0.4589 - round_los\u001b[A\n",
      "Training:  86%|▊| 35202/40960 [02:15<00:20, 281.70batches/s, l2_loss: 0.4592 - round_los\u001b[A\n",
      "Training:  86%|▊| 35260/40960 [02:15<00:20, 283.38batches/s, l2_loss: 0.4592 - round_los\u001b[A\n",
      "Training:  86%|▊| 35260/40960 [02:15<00:20, 283.38batches/s, l2_loss: 0.4593 - round_los\u001b[A\n",
      "Training:  86%|▊| 35318/40960 [02:15<00:19, 284.08batches/s, l2_loss: 0.4593 - round_los\u001b[A\n",
      "Training:  86%|▊| 35318/40960 [02:15<00:19, 284.08batches/s, l2_loss: 0.4594 - round_los\u001b[A\n",
      "Training:  86%|▊| 35375/40960 [02:15<00:19, 283.46batches/s, l2_loss: 0.4594 - round_los\u001b[A\n",
      "Training:  86%|▊| 35375/40960 [02:15<00:19, 283.46batches/s, l2_loss: 0.4595 - round_los\u001b[A\n",
      "Training:  87%|▊| 35431/40960 [02:16<00:19, 280.89batches/s, l2_loss: 0.4595 - round_los\u001b[A\n",
      "Training:  87%|▊| 35431/40960 [02:16<00:19, 280.89batches/s, l2_loss: 0.4595 - round_los\u001b[A\n",
      "Training:  87%|▊| 35490/40960 [02:16<00:19, 284.97batches/s, l2_loss: 0.4595 - round_los\u001b[A\n",
      "Training:  87%|▊| 35490/40960 [02:16<00:19, 284.97batches/s, l2_loss: 0.4598 - round_los\u001b[A\n",
      "Training:  87%|▊| 35549/40960 [02:16<00:18, 286.83batches/s, l2_loss: 0.4598 - round_los\u001b[A\n",
      "Training:  87%|▊| 35549/40960 [02:16<00:18, 286.83batches/s, l2_loss: 0.4599 - round_los\u001b[A\n",
      "Training:  87%|▊| 35606/40960 [02:16<00:18, 285.30batches/s, l2_loss: 0.4599 - round_los\u001b[A\n",
      "Training:  87%|▊| 35606/40960 [02:16<00:18, 285.30batches/s, l2_loss: 0.4601 - round_los\u001b[A\n",
      "Training:  87%|▊| 35666/40960 [02:16<00:18, 288.02batches/s, l2_loss: 0.4601 - round_los\u001b[A\n",
      "Training:  87%|▊| 35666/40960 [02:16<00:18, 288.02batches/s, l2_loss: 0.4602 - round_los\u001b[A\n",
      "Training:  87%|▊| 35711/40960 [02:17<00:19, 267.45batches/s, l2_loss: 0.4602 - round_los\u001b[A\n",
      "Training:  87%|▊| 35711/40960 [02:17<00:19, 267.45batches/s, l2_loss: 0.4602 - round_los\u001b[A\n",
      "Training:  87%|▊| 35762/40960 [02:17<00:19, 263.56batches/s, l2_loss: 0.4602 - round_los\u001b[A\n",
      "Training:  87%|▊| 35762/40960 [02:17<00:19, 263.56batches/s, l2_loss: 0.4602 - round_los\u001b[A\n",
      "Training:  87%|▊| 35808/40960 [02:17<00:20, 252.45batches/s, l2_loss: 0.4602 - round_los\u001b[A\n",
      "Training:  87%|▊| 35808/40960 [02:17<00:20, 252.45batches/s, l2_loss: 0.4604 - round_los\u001b[A\n",
      "Training:  88%|▉| 35868/40960 [02:17<00:19, 266.32batches/s, l2_loss: 0.4604 - round_los\u001b[A\n",
      "Training:  88%|▉| 35868/40960 [02:17<00:19, 266.32batches/s, l2_loss: 0.4605 - round_los\u001b[A\n",
      "Training:  88%|▉| 35925/40960 [02:18<00:18, 271.01batches/s, l2_loss: 0.4605 - round_los\u001b[A\n",
      "Training:  88%|▉| 35925/40960 [02:18<00:18, 271.01batches/s, l2_loss: 0.4607 - round_los\u001b[A\n",
      "Training:  88%|▉| 35978/40960 [02:18<00:18, 268.21batches/s, l2_loss: 0.4607 - round_los\u001b[A\n",
      "Training:  88%|▉| 35978/40960 [02:18<00:18, 268.21batches/s, l2_loss: 0.4607 - round_los\u001b[A\n",
      "Training:  88%|▉| 36037/40960 [02:18<00:17, 275.83batches/s, l2_loss: 0.4607 - round_los\u001b[A\n",
      "Training:  88%|▉| 36037/40960 [02:18<00:17, 275.83batches/s, l2_loss: 0.4608 - round_los\u001b[A\n",
      "Training:  88%|▉| 36096/40960 [02:18<00:17, 281.22batches/s, l2_loss: 0.4608 - round_los\u001b[A\n",
      "Training:  88%|▉| 36096/40960 [02:18<00:17, 281.22batches/s, l2_loss: 0.4611 - round_los\u001b[A\n",
      "Training:  88%|▉| 36150/40960 [02:18<00:17, 277.66batches/s, l2_loss: 0.4611 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|▉| 36150/40960 [02:18<00:17, 277.66batches/s, l2_loss: 0.4612 - round_los\u001b[A\n",
      "Training:  88%|▉| 36212/40960 [02:19<00:16, 286.66batches/s, l2_loss: 0.4612 - round_los\u001b[A\n",
      "Training:  88%|▉| 36212/40960 [02:19<00:16, 286.66batches/s, l2_loss: 0.4614 - round_los\u001b[A\n",
      "Training:  89%|▉| 36272/40960 [02:19<00:16, 290.43batches/s, l2_loss: 0.4614 - round_los\u001b[A\n",
      "Training:  89%|▉| 36272/40960 [02:19<00:16, 290.43batches/s, l2_loss: 0.4614 - round_los\u001b[A\n",
      "Training:  89%|▉| 36327/40960 [02:19<00:16, 284.80batches/s, l2_loss: 0.4614 - round_los\u001b[A\n",
      "Training:  89%|▉| 36327/40960 [02:19<00:16, 284.80batches/s, l2_loss: 0.4615 - round_los\u001b[A\n",
      "Training:  89%|▉| 36380/40960 [02:19<00:16, 278.13batches/s, l2_loss: 0.4615 - round_los\u001b[A\n",
      "Training:  89%|▉| 36380/40960 [02:19<00:16, 278.13batches/s, l2_loss: 0.4618 - round_los\u001b[A\n",
      "Training:  89%|▉| 36441/40960 [02:19<00:15, 285.89batches/s, l2_loss: 0.4618 - round_los\u001b[A\n",
      "Training:  89%|▉| 36441/40960 [02:19<00:15, 285.89batches/s, l2_loss: 0.4619 - round_los\u001b[A\n",
      "Training:  89%|▉| 36502/40960 [02:20<00:15, 291.43batches/s, l2_loss: 0.4619 - round_los\u001b[A\n",
      "Training:  89%|▉| 36502/40960 [02:20<00:15, 291.43batches/s, l2_loss: 0.4619 - round_los\u001b[A\n",
      "Training:  89%|▉| 36561/40960 [02:20<00:15, 292.30batches/s, l2_loss: 0.4619 - round_los\u001b[A\n",
      "Training:  89%|▉| 36561/40960 [02:20<00:15, 292.30batches/s, l2_loss: 0.4621 - round_los\u001b[A\n",
      "Training:  89%|▉| 36622/40960 [02:20<00:14, 295.60batches/s, l2_loss: 0.4621 - round_los\u001b[A\n",
      "Training:  89%|▉| 36622/40960 [02:20<00:14, 295.60batches/s, l2_loss: 0.4623 - round_los\u001b[A\n",
      "Training:  90%|▉| 36681/40960 [02:20<00:14, 294.60batches/s, l2_loss: 0.4623 - round_los\u001b[A\n",
      "Training:  90%|▉| 36681/40960 [02:20<00:14, 294.60batches/s, l2_loss: 0.4626 - round_los\u001b[A\n",
      "Training:  90%|▉| 36743/40960 [02:20<00:14, 297.74batches/s, l2_loss: 0.4626 - round_los\u001b[A\n",
      "Training:  90%|▉| 36743/40960 [02:20<00:14, 297.74batches/s, l2_loss: 0.4627 - round_los\u001b[A\n",
      "Training:  90%|▉| 36795/40960 [02:21<00:14, 285.68batches/s, l2_loss: 0.4627 - round_los\u001b[A\n",
      "Training:  90%|▉| 36795/40960 [02:21<00:14, 285.68batches/s, l2_loss: 0.4629 - round_los\u001b[A\n",
      "Training:  90%|▉| 36845/40960 [02:21<00:15, 273.89batches/s, l2_loss: 0.4629 - round_los\u001b[A\n",
      "Training:  90%|▉| 36845/40960 [02:21<00:15, 273.89batches/s, l2_loss: 0.4629 - round_los\u001b[A\n",
      "Training:  90%|▉| 36902/40960 [02:21<00:14, 276.39batches/s, l2_loss: 0.4629 - round_los\u001b[A\n",
      "Training:  90%|▉| 36902/40960 [02:21<00:14, 276.39batches/s, l2_loss: 0.4630 - round_los\u001b[A\n",
      "Training:  90%|▉| 36960/40960 [02:21<00:14, 279.09batches/s, l2_loss: 0.4630 - round_los\u001b[A\n",
      "Training:  90%|▉| 36960/40960 [02:21<00:14, 279.09batches/s, l2_loss: 0.4630 - round_los\u001b[A\n",
      "Training:  90%|▉| 37020/40960 [02:21<00:13, 284.33batches/s, l2_loss: 0.4630 - round_los\u001b[A\n",
      "Training:  90%|▉| 37020/40960 [02:21<00:13, 284.33batches/s, l2_loss: 0.4632 - round_los\u001b[A\n",
      "Training:  91%|▉| 37076/40960 [02:22<00:13, 282.06batches/s, l2_loss: 0.4632 - round_los\u001b[A\n",
      "Training:  91%|▉| 37076/40960 [02:22<00:13, 282.06batches/s, l2_loss: 0.4635 - round_los\u001b[A\n",
      "Training:  91%|▉| 37131/40960 [02:22<00:13, 279.07batches/s, l2_loss: 0.4635 - round_los\u001b[A\n",
      "Training:  91%|▉| 37131/40960 [02:22<00:13, 279.07batches/s, l2_loss: 0.4635 - round_los\u001b[A\n",
      "Training:  91%|▉| 37186/40960 [02:22<00:13, 276.38batches/s, l2_loss: 0.4635 - round_los\u001b[A\n",
      "Training:  91%|▉| 37186/40960 [02:22<00:13, 276.38batches/s, l2_loss: 0.4637 - round_los\u001b[A\n",
      "Training:  91%|▉| 37231/40960 [02:22<00:14, 258.27batches/s, l2_loss: 0.4637 - round_los\u001b[A\n",
      "Training:  91%|▉| 37231/40960 [02:22<00:14, 258.27batches/s, l2_loss: 0.4637 - round_los\u001b[A\n",
      "Training:  91%|▉| 37284/40960 [02:22<00:14, 258.57batches/s, l2_loss: 0.4637 - round_los\u001b[A\n",
      "Training:  91%|▉| 37284/40960 [02:22<00:14, 258.57batches/s, l2_loss: 0.4640 - round_los\u001b[A\n",
      "Training:  91%|▉| 37331/40960 [02:23<00:14, 250.54batches/s, l2_loss: 0.4640 - round_los\u001b[A\n",
      "Training:  91%|▉| 37331/40960 [02:23<00:14, 250.54batches/s, l2_loss: 0.4640 - round_los\u001b[A\n",
      "Training:  91%|▉| 37386/40960 [02:23<00:13, 256.79batches/s, l2_loss: 0.4640 - round_los\u001b[A\n",
      "Training:  91%|▉| 37386/40960 [02:23<00:13, 256.79batches/s, l2_loss: 0.4642 - round_los\u001b[A\n",
      "Training:  91%|▉| 37438/40960 [02:23<00:13, 256.74batches/s, l2_loss: 0.4642 - round_los\u001b[A\n",
      "Training:  91%|▉| 37438/40960 [02:23<00:13, 256.74batches/s, l2_loss: 0.4644 - round_los\u001b[A\n",
      "Training:  92%|▉| 37492/40960 [02:23<00:13, 260.42batches/s, l2_loss: 0.4644 - round_los\u001b[A\n",
      "Training:  92%|▉| 37492/40960 [02:23<00:13, 260.42batches/s, l2_loss: 0.4645 - round_los\u001b[A\n",
      "Training:  92%|▉| 37545/40960 [02:23<00:13, 260.67batches/s, l2_loss: 0.4645 - round_los\u001b[A\n",
      "Training:  92%|▉| 37545/40960 [02:23<00:13, 260.67batches/s, l2_loss: 0.4647 - round_los\u001b[A\n",
      "Training:  92%|▉| 37595/40960 [02:24<00:13, 256.81batches/s, l2_loss: 0.4647 - round_los\u001b[A\n",
      "Training:  92%|▉| 37595/40960 [02:24<00:13, 256.81batches/s, l2_loss: 0.4648 - round_los\u001b[A\n",
      "Training:  92%|▉| 37648/40960 [02:24<00:12, 258.08batches/s, l2_loss: 0.4648 - round_los\u001b[A\n",
      "Training:  92%|▉| 37648/40960 [02:24<00:12, 258.08batches/s, l2_loss: 0.4649 - round_los\u001b[A\n",
      "Training:  92%|▉| 37697/40960 [02:24<00:12, 253.84batches/s, l2_loss: 0.4649 - round_los\u001b[A\n",
      "Training:  92%|▉| 37697/40960 [02:24<00:12, 253.84batches/s, l2_loss: 0.4650 - round_los\u001b[A\n",
      "Training:  92%|▉| 37744/40960 [02:24<00:13, 246.56batches/s, l2_loss: 0.4650 - round_los\u001b[A\n",
      "Training:  92%|▉| 37744/40960 [02:24<00:13, 246.56batches/s, l2_loss: 0.4652 - round_los\u001b[A\n",
      "Training:  92%|▉| 37793/40960 [02:24<00:12, 244.87batches/s, l2_loss: 0.4652 - round_los\u001b[A\n",
      "Training:  92%|▉| 37793/40960 [02:24<00:12, 244.87batches/s, l2_loss: 0.4652 - round_los\u001b[A\n",
      "Training:  92%|▉| 37847/40960 [02:25<00:12, 251.81batches/s, l2_loss: 0.4652 - round_los\u001b[A\n",
      "Training:  92%|▉| 37847/40960 [02:25<00:12, 251.81batches/s, l2_loss: 0.4654 - round_los\u001b[A\n",
      "Training:  93%|▉| 37906/40960 [02:25<00:11, 264.34batches/s, l2_loss: 0.4654 - round_los\u001b[A\n",
      "Training:  93%|▉| 37906/40960 [02:25<00:11, 264.34batches/s, l2_loss: 0.4657 - round_los\u001b[A\n",
      "Training:  93%|▉| 37949/40960 [02:25<00:12, 247.20batches/s, l2_loss: 0.4657 - round_los\u001b[A\n",
      "Training:  93%|▉| 37949/40960 [02:25<00:12, 247.20batches/s, l2_loss: 0.4659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38005/40960 [02:25<00:11, 256.17batches/s, l2_loss: 0.4659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38005/40960 [02:25<00:11, 256.17batches/s, l2_loss: 0.4659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38060/40960 [02:25<00:11, 260.85batches/s, l2_loss: 0.4659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38060/40960 [02:25<00:11, 260.85batches/s, l2_loss: 0.4660 - round_los\u001b[A\n",
      "Training:  93%|▉| 38096/40960 [02:26<00:12, 236.13batches/s, l2_loss: 0.4660 - round_los\u001b[A\n",
      "Training:  93%|▉| 38096/40960 [02:26<00:12, 236.13batches/s, l2_loss: 0.4661 - round_los\u001b[A\n",
      "Training:  93%|▉| 38148/40960 [02:26<00:11, 242.62batches/s, l2_loss: 0.4661 - round_los\u001b[A\n",
      "Training:  93%|▉| 38148/40960 [02:26<00:11, 242.62batches/s, l2_loss: 0.4663 - round_los\u001b[A\n",
      "Training:  93%|▉| 38206/40960 [02:26<00:10, 256.13batches/s, l2_loss: 0.4663 - round_los\u001b[A\n",
      "Training:  93%|▉| 38206/40960 [02:26<00:10, 256.13batches/s, l2_loss: 0.4666 - round_los\u001b[A\n",
      "Training:  93%|▉| 38259/40960 [02:26<00:10, 258.25batches/s, l2_loss: 0.4666 - round_los\u001b[A\n",
      "Training:  93%|▉| 38259/40960 [02:26<00:10, 258.25batches/s, l2_loss: 0.4666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38302/40960 [02:26<00:10, 244.98batches/s, l2_loss: 0.4666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38302/40960 [02:26<00:10, 244.98batches/s, l2_loss: 0.4666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38355/40960 [02:27<00:10, 250.79batches/s, l2_loss: 0.4666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38355/40960 [02:27<00:10, 250.79batches/s, l2_loss: 0.4668 - round_los\u001b[A\n",
      "Training:  94%|▉| 38393/40960 [02:27<00:11, 232.18batches/s, l2_loss: 0.4668 - round_los\u001b[A\n",
      "Training:  94%|▉| 38393/40960 [02:27<00:11, 232.18batches/s, l2_loss: 0.4670 - round_los\u001b[A\n",
      "Training:  94%|▉| 38435/40960 [02:27<00:11, 225.05batches/s, l2_loss: 0.4670 - round_los\u001b[A\n",
      "Training:  94%|▉| 38435/40960 [02:27<00:11, 225.05batches/s, l2_loss: 0.4670 - round_los\u001b[A\n",
      "Training:  94%|▉| 38475/40960 [02:27<00:11, 217.27batches/s, l2_loss: 0.4670 - round_los\u001b[A\n",
      "Training:  94%|▉| 38475/40960 [02:27<00:11, 217.27batches/s, l2_loss: 0.4672 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|▉| 38528/40960 [02:27<00:10, 231.43batches/s, l2_loss: 0.4672 - round_los\u001b[A\n",
      "Training:  94%|▉| 38528/40960 [02:27<00:10, 231.43batches/s, l2_loss: 0.4673 - round_los\u001b[A\n",
      "Training:  94%|▉| 38582/40960 [02:28<00:09, 242.03batches/s, l2_loss: 0.4673 - round_los\u001b[A\n",
      "Training:  94%|▉| 38582/40960 [02:28<00:09, 242.03batches/s, l2_loss: 0.4674 - round_los\u001b[A\n",
      "Training:  94%|▉| 38638/40960 [02:28<00:09, 253.04batches/s, l2_loss: 0.4674 - round_los\u001b[A\n",
      "Training:  94%|▉| 38638/40960 [02:28<00:09, 253.04batches/s, l2_loss: 0.4677 - round_los\u001b[A\n",
      "Training:  94%|▉| 38696/40960 [02:28<00:08, 263.10batches/s, l2_loss: 0.4677 - round_los\u001b[A\n",
      "Training:  94%|▉| 38696/40960 [02:28<00:08, 263.10batches/s, l2_loss: 0.4679 - round_los\u001b[A\n",
      "Training:  95%|▉| 38748/40960 [02:28<00:08, 261.68batches/s, l2_loss: 0.4679 - round_los\u001b[A\n",
      "Training:  95%|▉| 38748/40960 [02:28<00:08, 261.68batches/s, l2_loss: 0.4679 - round_los\u001b[A\n",
      "Training:  95%|▉| 38796/40960 [02:28<00:08, 253.66batches/s, l2_loss: 0.4679 - round_los\u001b[A\n",
      "Training:  95%|▉| 38796/40960 [02:28<00:08, 253.66batches/s, l2_loss: 0.4681 - round_los\u001b[A\n",
      "Training:  95%|▉| 38849/40960 [02:29<00:08, 256.56batches/s, l2_loss: 0.4681 - round_los\u001b[A\n",
      "Training:  95%|▉| 38849/40960 [02:29<00:08, 256.56batches/s, l2_loss: 0.4682 - round_los\u001b[A\n",
      "Training:  95%|▉| 38904/40960 [02:29<00:07, 261.12batches/s, l2_loss: 0.4682 - round_los\u001b[A\n",
      "Training:  95%|▉| 38904/40960 [02:29<00:07, 261.12batches/s, l2_loss: 0.4684 - round_los\u001b[A\n",
      "Training:  95%|▉| 38961/40960 [02:29<00:07, 266.99batches/s, l2_loss: 0.4684 - round_los\u001b[A\n",
      "Training:  95%|▉| 38961/40960 [02:29<00:07, 266.99batches/s, l2_loss: 0.4688 - round_los\u001b[A\n",
      "Training:  95%|▉| 39019/40960 [02:29<00:07, 273.77batches/s, l2_loss: 0.4688 - round_los\u001b[A\n",
      "Training:  95%|▉| 39019/40960 [02:29<00:07, 273.77batches/s, l2_loss: 0.4688 - round_los\u001b[A\n",
      "Training:  95%|▉| 39077/40960 [02:29<00:06, 278.05batches/s, l2_loss: 0.4688 - round_los\u001b[A\n",
      "Training:  95%|▉| 39077/40960 [02:29<00:06, 278.05batches/s, l2_loss: 0.4690 - round_los\u001b[A\n",
      "Training:  96%|▉| 39136/40960 [02:30<00:06, 282.60batches/s, l2_loss: 0.4690 - round_los\u001b[A\n",
      "Training:  96%|▉| 39136/40960 [02:30<00:06, 282.60batches/s, l2_loss: 0.4692 - round_los\u001b[A\n",
      "Training:  96%|▉| 39193/40960 [02:30<00:06, 282.30batches/s, l2_loss: 0.4692 - round_los\u001b[A\n",
      "Training:  96%|▉| 39193/40960 [02:30<00:06, 282.30batches/s, l2_loss: 0.4693 - round_los\u001b[A\n",
      "Training:  96%|▉| 39246/40960 [02:30<00:06, 275.17batches/s, l2_loss: 0.4693 - round_los\u001b[A\n",
      "Training:  96%|▉| 39246/40960 [02:30<00:06, 275.17batches/s, l2_loss: 0.4695 - round_los\u001b[A\n",
      "Training:  96%|▉| 39294/40960 [02:30<00:06, 263.95batches/s, l2_loss: 0.4695 - round_los\u001b[A\n",
      "Training:  96%|▉| 39294/40960 [02:30<00:06, 263.95batches/s, l2_loss: 0.4696 - round_los\u001b[A\n",
      "Training:  96%|▉| 39350/40960 [02:30<00:06, 268.31batches/s, l2_loss: 0.4696 - round_los\u001b[A\n",
      "Training:  96%|▉| 39350/40960 [02:30<00:06, 268.31batches/s, l2_loss: 0.4696 - round_los\u001b[A\n",
      "Training:  96%|▉| 39403/40960 [02:31<00:05, 266.30batches/s, l2_loss: 0.4696 - round_los\u001b[A\n",
      "Training:  96%|▉| 39403/40960 [02:31<00:05, 266.30batches/s, l2_loss: 0.4698 - round_los\u001b[A\n",
      "Training:  96%|▉| 39458/40960 [02:31<00:05, 268.18batches/s, l2_loss: 0.4698 - round_los\u001b[A\n",
      "Training:  96%|▉| 39458/40960 [02:31<00:05, 268.18batches/s, l2_loss: 0.4701 - round_los\u001b[A\n",
      "Training:  96%|▉| 39515/40960 [02:31<00:05, 271.62batches/s, l2_loss: 0.4701 - round_los\u001b[A\n",
      "Training:  96%|▉| 39515/40960 [02:31<00:05, 271.62batches/s, l2_loss: 0.4703 - round_los\u001b[A\n",
      "Training:  97%|▉| 39573/40960 [02:31<00:05, 275.92batches/s, l2_loss: 0.4703 - round_los\u001b[A\n",
      "Training:  97%|▉| 39573/40960 [02:31<00:05, 275.92batches/s, l2_loss: 0.4703 - round_los\u001b[A\n",
      "Training:  97%|▉| 39629/40960 [02:31<00:04, 276.56batches/s, l2_loss: 0.4703 - round_los\u001b[A\n",
      "Training:  97%|▉| 39629/40960 [02:31<00:04, 276.56batches/s, l2_loss: 0.4704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39687/40960 [02:32<00:04, 279.55batches/s, l2_loss: 0.4704 - round_los\u001b[A\n",
      "Training:  97%|▉| 39687/40960 [02:32<00:04, 279.55batches/s, l2_loss: 0.4707 - round_los\u001b[A\n",
      "Training:  97%|▉| 39742/40960 [02:32<00:04, 277.59batches/s, l2_loss: 0.4707 - round_los\u001b[A\n",
      "Training:  97%|▉| 39742/40960 [02:32<00:04, 277.59batches/s, l2_loss: 0.4708 - round_los\u001b[A\n",
      "Training:  97%|▉| 39794/40960 [02:32<00:04, 271.89batches/s, l2_loss: 0.4708 - round_los\u001b[A\n",
      "Training:  97%|▉| 39794/40960 [02:32<00:04, 271.89batches/s, l2_loss: 0.4710 - round_los\u001b[A\n",
      "Training:  97%|▉| 39850/40960 [02:32<00:04, 273.42batches/s, l2_loss: 0.4710 - round_los\u001b[A\n",
      "Training:  97%|▉| 39850/40960 [02:32<00:04, 273.42batches/s, l2_loss: 0.4713 - round_los\u001b[A\n",
      "Training:  97%|▉| 39909/40960 [02:32<00:03, 278.72batches/s, l2_loss: 0.4713 - round_los\u001b[A\n",
      "Training:  97%|▉| 39909/40960 [02:32<00:03, 278.72batches/s, l2_loss: 0.4714 - round_los\u001b[A\n",
      "Training:  98%|▉| 39968/40960 [02:33<00:03, 282.73batches/s, l2_loss: 0.4714 - round_los\u001b[A\n",
      "Training:  98%|▉| 39968/40960 [02:33<00:03, 282.73batches/s, l2_loss: 0.4715 - round_los\u001b[A\n",
      "Training:  98%|▉| 40027/40960 [02:33<00:03, 285.62batches/s, l2_loss: 0.4715 - round_los\u001b[A\n",
      "Training:  98%|▉| 40027/40960 [02:33<00:03, 285.62batches/s, l2_loss: 0.4717 - round_los\u001b[A\n",
      "Training:  98%|▉| 40087/40960 [02:33<00:03, 289.15batches/s, l2_loss: 0.4717 - round_los\u001b[A\n",
      "Training:  98%|▉| 40087/40960 [02:33<00:03, 289.15batches/s, l2_loss: 0.4719 - round_los\u001b[A\n",
      "Training:  98%|▉| 40147/40960 [02:33<00:02, 291.50batches/s, l2_loss: 0.4719 - round_los\u001b[A\n",
      "Training:  98%|▉| 40147/40960 [02:33<00:02, 291.50batches/s, l2_loss: 0.4722 - round_los\u001b[A\n",
      "Training:  98%|▉| 40207/40960 [02:33<00:02, 293.01batches/s, l2_loss: 0.4722 - round_los\u001b[A\n",
      "Training:  98%|▉| 40207/40960 [02:33<00:02, 293.01batches/s, l2_loss: 0.4722 - round_los\u001b[A\n",
      "Training:  98%|▉| 40266/40960 [02:34<00:02, 292.17batches/s, l2_loss: 0.4722 - round_los\u001b[A\n",
      "Training:  98%|▉| 40266/40960 [02:34<00:02, 292.17batches/s, l2_loss: 0.4723 - round_los\u001b[A\n",
      "Training:  98%|▉| 40325/40960 [02:34<00:02, 292.85batches/s, l2_loss: 0.4723 - round_los\u001b[A\n",
      "Training:  98%|▉| 40325/40960 [02:34<00:02, 292.85batches/s, l2_loss: 0.4725 - round_los\u001b[A\n",
      "Training:  99%|▉| 40379/40960 [02:34<00:02, 285.36batches/s, l2_loss: 0.4725 - round_los\u001b[A\n",
      "Training:  99%|▉| 40379/40960 [02:34<00:02, 285.36batches/s, l2_loss: 0.4727 - round_los\u001b[A\n",
      "Training:  99%|▉| 40428/40960 [02:34<00:01, 272.75batches/s, l2_loss: 0.4727 - round_los\u001b[A\n",
      "Training:  99%|▉| 40428/40960 [02:34<00:01, 272.75batches/s, l2_loss: 0.4728 - round_los\u001b[A\n",
      "Training:  99%|▉| 40477/40960 [02:34<00:01, 262.34batches/s, l2_loss: 0.4728 - round_los\u001b[A\n",
      "Training:  99%|▉| 40477/40960 [02:34<00:01, 262.34batches/s, l2_loss: 0.4729 - round_los\u001b[A\n",
      "Training:  99%|▉| 40529/40960 [02:35<00:01, 260.80batches/s, l2_loss: 0.4729 - round_los\u001b[A\n",
      "Training:  99%|▉| 40529/40960 [02:35<00:01, 260.80batches/s, l2_loss: 0.4732 - round_los\u001b[A\n",
      "Training:  99%|▉| 40575/40960 [02:35<00:01, 250.45batches/s, l2_loss: 0.4732 - round_los\u001b[A\n",
      "Training:  99%|▉| 40575/40960 [02:35<00:01, 250.45batches/s, l2_loss: 0.4733 - round_los\u001b[A\n",
      "Training:  99%|▉| 40629/40960 [02:35<00:01, 255.76batches/s, l2_loss: 0.4733 - round_los\u001b[A\n",
      "Training:  99%|▉| 40629/40960 [02:35<00:01, 255.76batches/s, l2_loss: 0.4733 - round_los\u001b[A\n",
      "Training:  99%|▉| 40685/40960 [02:35<00:01, 261.92batches/s, l2_loss: 0.4733 - round_los\u001b[A\n",
      "Training:  99%|▉| 40685/40960 [02:35<00:01, 261.92batches/s, l2_loss: 0.4736 - round_los\u001b[A\n",
      "Training:  99%|▉| 40736/40960 [02:35<00:00, 259.65batches/s, l2_loss: 0.4736 - round_los\u001b[A\n",
      "Training:  99%|▉| 40736/40960 [02:35<00:00, 259.65batches/s, l2_loss: 0.4739 - round_los\u001b[A\n",
      "Training: 100%|▉| 40793/40960 [02:36<00:00, 267.07batches/s, l2_loss: 0.4739 - round_los\u001b[A\n",
      "Training: 100%|▉| 40793/40960 [02:36<00:00, 267.07batches/s, l2_loss: 0.4739 - round_los\u001b[A\n",
      "Training: 100%|▉| 40852/40960 [02:36<00:00, 273.95batches/s, l2_loss: 0.4739 - round_los\u001b[A\n",
      "Training: 100%|▉| 40852/40960 [02:36<00:00, 273.95batches/s, l2_loss: 0.4739 - round_los\u001b[A\n",
      "Training: 100%|▉| 40889/40960 [02:36<00:00, 245.54batches/s, l2_loss: 0.4739 - round_los\u001b[A\n",
      "Training: 100%|▉| 40889/40960 [02:36<00:00, 245.54batches/s, l2_loss: 0.4741 - round_los\u001b[A\n",
      "Training: 100%|▉| 40925/40960 [02:36<00:00, 223.21batches/s, l2_loss: 0.4741 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|▉| 40925/40960 [02:36<00:00, 223.21batches/s, l2_loss: 0.4742 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:25:58.583653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  69%|▋| 18/26 [38:20<18:52, 141.51s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:26:01.787929: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:26:08.353721: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<24:10:47,  2.13s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<24:10:47,  2.13s/batches, l2_loss: 0.0616 - round_loss:\u001b[A\n",
      "Training:   0%| | 56/40960 [00:02<20:40, 32.96batches/s, l2_loss: 0.0616 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 56/40960 [00:02<20:40, 32.96batches/s, l2_loss: 0.0836 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 107/40960 [00:02<10:29, 64.86batches/s, l2_loss: 0.0836 - round_loss: \u001b[A\n",
      "Training:   0%| | 107/40960 [00:02<10:29, 64.86batches/s, l2_loss: 0.0728 - round_loss: \u001b[A\n",
      "Training:   0%| | 160/40960 [00:02<06:52, 98.96batches/s, l2_loss: 0.0728 - round_loss: \u001b[A\n",
      "Training:   0%| | 160/40960 [00:02<06:52, 98.96batches/s, l2_loss: 0.0749 - round_loss: \u001b[A\n",
      "Training:   1%| | 216/40960 [00:02<05:03, 134.35batches/s, l2_loss: 0.0749 - round_loss:\u001b[A\n",
      "Training:   1%| | 216/40960 [00:02<05:03, 134.35batches/s, l2_loss: 0.0745 - round_loss:\u001b[A\n",
      "Training:   1%| | 274/40960 [00:03<04:02, 167.93batches/s, l2_loss: 0.0745 - round_loss:\u001b[A\n",
      "Training:   1%| | 274/40960 [00:03<04:02, 167.93batches/s, l2_loss: 0.0754 - round_loss:\u001b[A\n",
      "Training:   1%| | 330/40960 [00:03<03:29, 194.19batches/s, l2_loss: 0.0754 - round_loss:\u001b[A\n",
      "Training:   1%| | 330/40960 [00:03<03:29, 194.19batches/s, l2_loss: 0.0763 - round_loss:\u001b[A\n",
      "Training:   1%| | 388/40960 [00:03<03:06, 217.23batches/s, l2_loss: 0.0763 - round_loss:\u001b[A\n",
      "Training:   1%| | 388/40960 [00:03<03:06, 217.23batches/s, l2_loss: 0.0762 - round_loss:\u001b[A\n",
      "Training:   1%| | 442/40960 [00:03<02:55, 230.97batches/s, l2_loss: 0.0762 - round_loss:\u001b[A\n",
      "Training:   1%| | 442/40960 [00:03<02:55, 230.97batches/s, l2_loss: 0.0760 - round_loss:\u001b[A\n",
      "Training:   1%| | 493/40960 [00:03<02:50, 237.47batches/s, l2_loss: 0.0760 - round_loss:\u001b[A\n",
      "Training:   1%| | 493/40960 [00:03<02:50, 237.47batches/s, l2_loss: 0.0758 - round_loss:\u001b[A\n",
      "Training:   1%| | 552/40960 [00:04<02:40, 252.10batches/s, l2_loss: 0.0758 - round_loss:\u001b[A\n",
      "Training:   1%| | 552/40960 [00:04<02:40, 252.10batches/s, l2_loss: 0.0760 - round_loss:\u001b[A\n",
      "Training:   1%| | 603/40960 [00:04<02:40, 251.90batches/s, l2_loss: 0.0760 - round_loss:\u001b[A\n",
      "Training:   1%| | 603/40960 [00:04<02:40, 251.90batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   2%| | 657/40960 [00:04<02:37, 255.90batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   2%| | 657/40960 [00:04<02:37, 255.90batches/s, l2_loss: 0.0765 - round_loss:\u001b[A\n",
      "Training:   2%| | 711/40960 [00:04<02:34, 259.73batches/s, l2_loss: 0.0765 - round_loss:\u001b[A\n",
      "Training:   2%| | 711/40960 [00:04<02:34, 259.73batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   2%| | 763/40960 [00:04<02:35, 258.93batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   2%| | 763/40960 [00:04<02:35, 258.93batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   2%| | 820/40960 [00:05<02:32, 264.08batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   2%| | 820/40960 [00:05<02:32, 264.08batches/s, l2_loss: 0.0761 - round_loss:\u001b[A\n",
      "Training:   2%| | 873/40960 [00:05<02:32, 263.11batches/s, l2_loss: 0.0761 - round_loss:\u001b[A\n",
      "Training:   2%| | 873/40960 [00:05<02:32, 263.11batches/s, l2_loss: 0.0760 - round_loss:\u001b[A\n",
      "Training:   2%| | 924/40960 [00:05<02:34, 259.54batches/s, l2_loss: 0.0760 - round_loss:\u001b[A\n",
      "Training:   2%| | 924/40960 [00:05<02:34, 259.54batches/s, l2_loss: 0.0755 - round_loss:\u001b[A\n",
      "Training:   2%| | 976/40960 [00:05<02:34, 258.62batches/s, l2_loss: 0.0755 - round_loss:\u001b[A\n",
      "Training:   2%| | 976/40960 [00:05<02:34, 258.62batches/s, l2_loss: 0.0758 - round_loss:\u001b[A\n",
      "Training:   3%| | 1030/40960 [00:05<02:32, 261.67batches/s, l2_loss: 0.0758 - round_loss\u001b[A\n",
      "Training:   3%| | 1030/40960 [00:05<02:32, 261.67batches/s, l2_loss: 0.0756 - round_loss\u001b[A\n",
      "Training:   3%| | 1079/40960 [00:06<02:36, 255.52batches/s, l2_loss: 0.0756 - round_loss\u001b[A\n",
      "Training:   3%| | 1079/40960 [00:06<02:36, 255.52batches/s, l2_loss: 0.0757 - round_loss\u001b[A\n",
      "Training:   3%| | 1130/40960 [00:06<02:36, 254.69batches/s, l2_loss: 0.0757 - round_loss\u001b[A\n",
      "Training:   3%| | 1130/40960 [00:06<02:36, 254.69batches/s, l2_loss: 0.0758 - round_loss\u001b[A\n",
      "Training:   3%| | 1192/40960 [00:06<02:26, 270.78batches/s, l2_loss: 0.0758 - round_loss\u001b[A\n",
      "Training:   3%| | 1192/40960 [00:06<02:26, 270.78batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   3%| | 1252/40960 [00:06<02:22, 279.18batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   3%| | 1252/40960 [00:06<02:22, 279.18batches/s, l2_loss: 0.0754 - round_loss\u001b[A\n",
      "Training:   3%| | 1316/40960 [00:06<02:16, 290.43batches/s, l2_loss: 0.0754 - round_loss\u001b[A\n",
      "Training:   3%| | 1316/40960 [00:06<02:16, 290.43batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   3%| | 1377/40960 [00:07<02:14, 294.26batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   3%| | 1377/40960 [00:07<02:14, 294.26batches/s, l2_loss: 0.0756 - round_loss\u001b[A\n",
      "Training:   4%| | 1440/40960 [00:07<02:11, 299.95batches/s, l2_loss: 0.0756 - round_loss\u001b[A\n",
      "Training:   4%| | 1440/40960 [00:07<02:11, 299.95batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:   4%| | 1501/40960 [00:07<02:10, 301.30batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:   4%| | 1501/40960 [00:07<02:10, 301.30batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   4%| | 1557/40960 [00:07<02:13, 294.27batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   4%| | 1557/40960 [00:07<02:13, 294.27batches/s, l2_loss: 0.0754 - round_loss\u001b[A\n",
      "Training:   4%| | 1611/40960 [00:07<02:17, 285.22batches/s, l2_loss: 0.0754 - round_loss\u001b[A\n",
      "Training:   4%| | 1611/40960 [00:07<02:17, 285.22batches/s, l2_loss: 0.0752 - round_loss\u001b[A\n",
      "Training:   4%| | 1669/40960 [00:08<02:17, 285.24batches/s, l2_loss: 0.0752 - round_loss\u001b[A\n",
      "Training:   4%| | 1669/40960 [00:08<02:17, 285.24batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   4%| | 1722/40960 [00:08<02:21, 278.24batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   4%| | 1722/40960 [00:08<02:21, 278.24batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   4%| | 1786/40960 [00:08<02:15, 289.80batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   4%| | 1786/40960 [00:08<02:15, 289.80batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:   5%| | 1848/40960 [00:08<02:12, 295.05batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:   5%| | 1848/40960 [00:08<02:12, 295.05batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:   5%| | 1909/40960 [00:09<02:11, 297.70batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:   5%| | 1909/40960 [00:09<02:11, 297.70batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:   5%| | 1970/40960 [00:09<02:10, 298.20batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:   5%| | 1970/40960 [00:09<02:10, 298.20batches/s, l2_loss: 0.0752 - round_loss\u001b[A\n",
      "Training:   5%| | 2024/40960 [00:09<02:14, 289.79batches/s, l2_loss: 0.0752 - round_loss\u001b[A\n",
      "Training:   5%| | 2024/40960 [00:09<02:14, 289.79batches/s, l2_loss: 0.0748 - round_loss\u001b[A\n",
      "Training:   5%| | 2085/40960 [00:09<02:12, 293.43batches/s, l2_loss: 0.0748 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 2085/40960 [00:09<02:12, 293.43batches/s, l2_loss: 0.0748 - round_loss\u001b[A\n",
      "Training:   5%| | 2143/40960 [00:09<02:12, 292.11batches/s, l2_loss: 0.0748 - round_loss\u001b[A\n",
      "Training:   5%| | 2143/40960 [00:09<02:12, 292.11batches/s, l2_loss: 0.0749 - round_loss\u001b[A\n",
      "Training:   5%| | 2202/40960 [00:10<02:12, 292.97batches/s, l2_loss: 0.0749 - round_loss\u001b[A\n",
      "Training:   5%| | 2202/40960 [00:10<02:12, 292.97batches/s, l2_loss: 0.0748 - round_loss\u001b[A\n",
      "Training:   6%| | 2266/40960 [00:10<02:08, 300.85batches/s, l2_loss: 0.0748 - round_loss\u001b[A\n",
      "Training:   6%| | 2266/40960 [00:10<02:08, 300.85batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:   6%| | 2324/40960 [00:10<02:10, 297.04batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:   6%| | 2324/40960 [00:10<02:10, 297.04batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:   6%| | 2378/40960 [00:10<02:13, 288.55batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:   6%| | 2378/40960 [00:10<02:13, 288.55batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   6%| | 2422/40960 [00:10<02:25, 265.24batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   6%| | 2422/40960 [00:10<02:25, 265.24batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   6%| | 2471/40960 [00:11<02:28, 259.22batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   6%| | 2471/40960 [00:11<02:28, 259.22batches/s, l2_loss: 0.0744 - round_loss\u001b[A\n",
      "Training:   6%| | 2525/40960 [00:11<02:26, 261.86batches/s, l2_loss: 0.0744 - round_loss\u001b[A\n",
      "Training:   6%| | 2525/40960 [00:11<02:26, 261.86batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   6%| | 2578/40960 [00:11<02:26, 262.61batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   6%| | 2578/40960 [00:11<02:26, 262.61batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   6%| | 2634/40960 [00:11<02:23, 267.64batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   6%| | 2634/40960 [00:11<02:23, 267.64batches/s, l2_loss: 0.0744 - round_loss\u001b[A\n",
      "Training:   7%| | 2692/40960 [00:11<02:19, 274.09batches/s, l2_loss: 0.0744 - round_loss\u001b[A\n",
      "Training:   7%| | 2692/40960 [00:11<02:19, 274.09batches/s, l2_loss: 0.0743 - round_loss\u001b[A\n",
      "Training:   7%| | 2752/40960 [00:12<02:16, 280.82batches/s, l2_loss: 0.0743 - round_loss\u001b[A\n",
      "Training:   7%| | 2752/40960 [00:12<02:16, 280.82batches/s, l2_loss: 0.0744 - round_loss\u001b[A\n",
      "Training:   7%| | 2805/40960 [00:12<02:18, 275.06batches/s, l2_loss: 0.0744 - round_loss\u001b[A\n",
      "Training:   7%| | 2805/40960 [00:12<02:18, 275.06batches/s, l2_loss: 0.0743 - round_loss\u001b[A\n",
      "Training:   7%| | 2859/40960 [00:12<02:19, 273.37batches/s, l2_loss: 0.0743 - round_loss\u001b[A\n",
      "Training:   7%| | 2859/40960 [00:12<02:19, 273.37batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   7%| | 2921/40960 [00:12<02:14, 282.85batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   7%| | 2921/40960 [00:12<02:14, 282.85batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   7%| | 2969/40960 [00:12<02:21, 268.40batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   7%| | 2969/40960 [00:12<02:21, 268.40batches/s, l2_loss: 0.0741 - round_loss\u001b[A\n",
      "Training:   7%| | 3029/40960 [00:13<02:16, 277.44batches/s, l2_loss: 0.0741 - round_loss\u001b[A\n",
      "Training:   7%| | 3029/40960 [00:13<02:16, 277.44batches/s, l2_loss: 0.0743 - round_loss\u001b[A\n",
      "Training:   8%| | 3086/40960 [00:13<02:15, 279.30batches/s, l2_loss: 0.0743 - round_loss\u001b[A\n",
      "Training:   8%| | 3086/40960 [00:13<02:15, 279.30batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   8%| | 3146/40960 [00:13<02:12, 284.75batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   8%| | 3146/40960 [00:13<02:12, 284.75batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   8%| | 3195/40960 [00:13<02:18, 272.46batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   8%| | 3195/40960 [00:13<02:18, 272.46batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   8%| | 3254/40960 [00:13<02:15, 278.77batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   8%| | 3254/40960 [00:13<02:15, 278.77batches/s, l2_loss: 0.0738 - round_loss\u001b[A\n",
      "Training:   8%| | 3304/40960 [00:14<02:19, 269.76batches/s, l2_loss: 0.0738 - round_loss\u001b[A\n",
      "Training:   8%| | 3304/40960 [00:14<02:19, 269.76batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   8%| | 3350/40960 [00:14<02:26, 256.93batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   8%| | 3350/40960 [00:14<02:26, 256.93batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   8%| | 3389/40960 [00:14<02:37, 238.25batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   8%| | 3389/40960 [00:14<02:37, 238.25batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:   8%| | 3427/40960 [00:14<02:48, 222.91batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:   8%| | 3427/40960 [00:14<02:48, 222.91batches/s, l2_loss: 0.0738 - round_loss\u001b[A\n",
      "Training:   8%| | 3460/40960 [00:14<03:02, 205.34batches/s, l2_loss: 0.0738 - round_loss\u001b[A\n",
      "Training:   8%| | 3460/40960 [00:14<03:02, 205.34batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   9%| | 3502/40960 [00:15<03:03, 204.67batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   9%| | 3502/40960 [00:15<03:03, 204.67batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   9%| | 3551/40960 [00:15<02:53, 215.75batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   9%| | 3551/40960 [00:15<02:53, 215.75batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   9%| | 3603/40960 [00:15<02:44, 227.69batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   9%| | 3603/40960 [00:15<02:44, 227.69batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   9%| | 3665/40960 [00:15<02:28, 251.47batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   9%| | 3665/40960 [00:15<02:28, 251.47batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:   9%| | 3724/40960 [00:15<02:21, 263.78batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:   9%| | 3724/40960 [00:15<02:21, 263.78batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   9%| | 3775/40960 [00:16<02:22, 260.45batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   9%| | 3775/40960 [00:16<02:22, 260.45batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   9%| | 3832/40960 [00:16<02:19, 266.52batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   9%| | 3832/40960 [00:16<02:19, 266.52batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:  10%| | 3892/40960 [00:16<02:14, 275.33batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:  10%| | 3892/40960 [00:16<02:14, 275.33batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  10%| | 3946/40960 [00:16<02:15, 272.79batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  10%| | 3946/40960 [00:16<02:15, 272.79batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:  10%| | 3996/40960 [00:16<02:19, 264.64batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:  10%| | 3996/40960 [00:16<02:19, 264.64batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:  10%| | 4054/40960 [00:17<02:15, 272.05batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:  10%| | 4054/40960 [00:17<02:15, 272.05batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:  10%| | 4110/40960 [00:17<02:14, 273.33batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:  10%| | 4110/40960 [00:17<02:14, 273.33batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  10%| | 4173/40960 [00:17<02:09, 285.16batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  10%| | 4173/40960 [00:17<02:09, 285.16batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  10%| | 4231/40960 [00:17<02:08, 286.15batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  10%| | 4231/40960 [00:17<02:08, 286.15batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  10%| | 4296/40960 [00:17<02:03, 297.14batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  10%| | 4296/40960 [00:17<02:03, 297.14batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  11%| | 4362/40960 [00:18<01:59, 306.75batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  11%| | 4362/40960 [00:18<01:59, 306.75batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  11%| | 4426/40960 [00:18<01:57, 309.99batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  11%| | 4426/40960 [00:18<01:57, 309.99batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:  11%| | 4479/40960 [00:18<02:03, 296.15batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:  11%| | 4479/40960 [00:18<02:03, 296.15batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%| | 4540/40960 [00:18<02:02, 298.47batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:  11%| | 4540/40960 [00:18<02:02, 298.47batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:  11%| | 4601/40960 [00:18<02:01, 299.78batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:  11%| | 4601/40960 [00:18<02:01, 299.78batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:  11%| | 4656/40960 [00:19<02:04, 291.89batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:  11%| | 4656/40960 [00:19<02:04, 291.89batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  11%| | 4710/40960 [00:19<02:07, 283.78batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  11%| | 4710/40960 [00:19<02:07, 283.78batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  12%| | 4766/40960 [00:19<02:08, 281.37batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  12%| | 4766/40960 [00:19<02:08, 281.37batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 4821/40960 [00:19<02:09, 278.25batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 4821/40960 [00:19<02:09, 278.25batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 4877/40960 [00:19<02:10, 277.24batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 4877/40960 [00:19<02:10, 277.24batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 4928/40960 [00:20<02:13, 270.54batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 4928/40960 [00:20<02:13, 270.54batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 4976/40960 [00:20<02:17, 260.86batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 4976/40960 [00:20<02:17, 260.86batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 5027/40960 [00:20<02:18, 258.83batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  12%| | 5027/40960 [00:20<02:18, 258.83batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  12%| | 5077/40960 [00:20<02:20, 255.08batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  12%| | 5077/40960 [00:20<02:20, 255.08batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5138/40960 [00:20<02:13, 269.08batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5138/40960 [00:20<02:13, 269.08batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5197/40960 [00:21<02:09, 276.66batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5197/40960 [00:21<02:09, 276.66batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5257/40960 [00:21<02:06, 282.02batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5257/40960 [00:21<02:06, 282.02batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5315/40960 [00:21<02:05, 283.95batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5315/40960 [00:21<02:05, 283.95batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5365/40960 [00:21<02:10, 273.22batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5365/40960 [00:21<02:10, 273.22batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5420/40960 [00:21<02:10, 273.12batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5420/40960 [00:21<02:10, 273.12batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5473/40960 [00:22<02:11, 270.48batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5473/40960 [00:22<02:11, 270.48batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5533/40960 [00:22<02:07, 278.11batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5533/40960 [00:22<02:07, 278.11batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5593/40960 [00:22<02:04, 283.55batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5593/40960 [00:22<02:04, 283.55batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5654/40960 [00:22<02:01, 289.57batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5654/40960 [00:22<02:01, 289.57batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5706/40960 [00:22<02:05, 280.03batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5706/40960 [00:22<02:05, 280.03batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5752/40960 [00:23<02:14, 261.97batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5752/40960 [00:23<02:14, 261.97batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5810/40960 [00:23<02:10, 270.01batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5810/40960 [00:23<02:10, 270.01batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5867/40960 [00:23<02:08, 273.99batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5867/40960 [00:23<02:08, 273.99batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5916/40960 [00:23<02:12, 264.95batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5916/40960 [00:23<02:12, 264.95batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5964/40960 [00:23<02:16, 256.22batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5964/40960 [00:23<02:16, 256.22batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6018/40960 [00:24<02:14, 259.46batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6018/40960 [00:24<02:14, 259.46batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6076/40960 [00:24<02:10, 267.12batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6076/40960 [00:24<02:10, 267.12batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6130/40960 [00:24<02:10, 267.64batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6130/40960 [00:24<02:10, 267.64batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6184/40960 [00:24<02:10, 266.67batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6184/40960 [00:24<02:10, 266.67batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6238/40960 [00:24<02:10, 265.92batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6238/40960 [00:24<02:10, 265.92batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6294/40960 [00:25<02:08, 269.47batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6294/40960 [00:25<02:08, 269.47batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6337/40960 [00:25<02:16, 253.09batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6337/40960 [00:25<02:16, 253.09batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6392/40960 [00:25<02:13, 258.87batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6392/40960 [00:25<02:13, 258.87batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6446/40960 [00:25<02:12, 260.67batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6446/40960 [00:25<02:12, 260.67batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6494/40960 [00:25<02:15, 253.87batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6494/40960 [00:25<02:15, 253.87batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6546/40960 [00:26<02:14, 255.08batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6546/40960 [00:26<02:14, 255.08batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6606/40960 [00:26<02:08, 267.77batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6606/40960 [00:26<02:08, 267.77batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6668/40960 [00:26<02:02, 279.67batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6668/40960 [00:26<02:02, 279.67batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6723/40960 [00:26<02:03, 276.73batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6723/40960 [00:26<02:03, 276.73batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6775/40960 [00:26<02:06, 270.20batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6775/40960 [00:26<02:06, 270.20batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6835/40960 [00:27<02:02, 278.69batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6835/40960 [00:27<02:02, 278.69batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6893/40960 [00:27<02:01, 281.46batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6893/40960 [00:27<02:01, 281.46batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6955/40960 [00:27<01:57, 289.56batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|▏| 6955/40960 [00:27<01:57, 289.56batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7015/40960 [00:27<01:56, 292.56batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7015/40960 [00:27<01:56, 292.56batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7076/40960 [00:27<01:54, 295.39batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7076/40960 [00:27<01:54, 295.39batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7140/40960 [00:28<01:52, 301.62batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7140/40960 [00:28<01:52, 301.62batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7194/40960 [00:28<01:55, 292.09batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7194/40960 [00:28<01:55, 292.09batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7258/40960 [00:28<01:52, 299.38batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7258/40960 [00:28<01:52, 299.38batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7323/40960 [00:28<01:49, 305.85batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7323/40960 [00:28<01:49, 305.85batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7378/40960 [00:28<01:53, 295.15batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7378/40960 [00:29<01:53, 295.15batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7436/40960 [00:29<01:54, 291.79batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7436/40960 [00:29<01:54, 291.79batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7484/40960 [00:29<02:01, 275.19batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7484/40960 [00:29<02:01, 275.19batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7544/40960 [00:29<01:58, 281.76batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7544/40960 [00:29<01:58, 281.76batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7606/40960 [00:29<01:55, 288.02batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7606/40960 [00:29<01:55, 288.02batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7663/40960 [00:30<01:56, 285.31batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7663/40960 [00:30<01:56, 285.31batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7715/40960 [00:30<01:59, 277.49batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7715/40960 [00:30<01:59, 277.49batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7766/40960 [00:30<02:03, 269.09batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7766/40960 [00:30<02:03, 269.09batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7830/40960 [00:30<01:57, 282.95batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7830/40960 [00:30<01:57, 282.95batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7889/40960 [00:30<01:56, 285.05batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7889/40960 [00:30<01:56, 285.05batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7943/40960 [00:31<01:58, 278.80batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7943/40960 [00:31<01:58, 278.80batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8004/40960 [00:31<01:55, 285.37batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8004/40960 [00:31<01:55, 285.37batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8061/40960 [00:31<01:55, 285.20batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8061/40960 [00:31<01:55, 285.20batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8123/40960 [00:31<01:52, 291.19batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8123/40960 [00:31<01:52, 291.19batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8185/40960 [00:31<01:50, 296.24batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8185/40960 [00:31<01:50, 296.24batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8243/40960 [00:32<01:51, 292.77batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8243/40960 [00:32<01:51, 292.77batches/s, l2_loss: 0.0700 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8285/40960 [00:32<02:02, 267.69batches/s, l2_loss: 0.0700 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8285/40960 [00:32<02:02, 267.69batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8337/40960 [00:32<02:03, 264.91batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8337/40960 [00:32<02:03, 264.91batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8394/40960 [00:32<02:00, 269.38batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8394/40960 [00:32<02:00, 269.38batches/s, l2_loss: 0.0701 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8451/40960 [00:32<01:59, 272.89batches/s, l2_loss: 0.0701 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8451/40960 [00:32<01:59, 272.89batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8502/40960 [00:33<02:01, 267.32batches/s, l2_loss: 0.0687 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8502/40960 [00:33<02:01, 267.32batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8551/40960 [00:33<02:04, 259.67batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8551/40960 [00:33<02:04, 259.67batches/s, l2_loss: 0.0669 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8605/40960 [00:33<02:03, 262.00batches/s, l2_loss: 0.0669 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8605/40960 [00:33<02:03, 262.00batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8661/40960 [00:33<02:01, 266.67batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8661/40960 [00:33<02:01, 266.67batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8719/40960 [00:33<01:58, 272.71batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8719/40960 [00:33<01:58, 272.71batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8776/40960 [00:34<01:56, 276.06batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8776/40960 [00:34<01:56, 276.06batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8832/40960 [00:34<01:56, 276.50batches/s, l2_loss: 0.0688 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8832/40960 [00:34<01:56, 276.50batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8887/40960 [00:34<01:56, 275.21batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8887/40960 [00:34<01:56, 275.21batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8938/40960 [00:34<01:59, 268.97batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8938/40960 [00:34<01:59, 268.97batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8998/40960 [00:34<01:54, 278.18batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8998/40960 [00:34<01:54, 278.18batches/s, l2_loss: 0.0681 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9055/40960 [00:35<01:54, 279.19batches/s, l2_loss: 0.0681 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9055/40960 [00:35<01:54, 279.19batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9114/40960 [00:35<01:52, 283.05batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9114/40960 [00:35<01:52, 283.05batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9175/40960 [00:35<01:50, 288.63batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9175/40960 [00:35<01:50, 288.63batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9225/40960 [00:35<01:55, 274.07batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9225/40960 [00:35<01:55, 274.07batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9274/40960 [00:35<01:59, 265.15batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9274/40960 [00:35<01:59, 265.15batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9330/40960 [00:36<01:57, 268.29batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9330/40960 [00:36<01:57, 268.29batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9391/40960 [00:36<01:53, 278.38batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9391/40960 [00:36<01:53, 278.38batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9446/40960 [00:36<01:54, 276.25batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9446/40960 [00:36<01:54, 276.25batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|▏| 9499/40960 [00:36<01:55, 272.53batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9499/40960 [00:36<01:55, 272.53batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9556/40960 [00:36<01:54, 275.17batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9556/40960 [00:36<01:54, 275.17batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9614/40960 [00:37<01:52, 279.30batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9614/40960 [00:37<01:52, 279.30batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9673/40960 [00:37<01:50, 283.75batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9673/40960 [00:37<01:50, 283.75batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9724/40960 [00:37<01:54, 272.13batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9724/40960 [00:37<01:54, 272.13batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9769/40960 [00:37<02:01, 257.41batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9769/40960 [00:37<02:01, 257.41batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9817/40960 [00:37<02:03, 251.91batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9817/40960 [00:37<02:03, 251.91batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9873/40960 [00:38<01:59, 260.17batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9873/40960 [00:38<01:59, 260.17batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9932/40960 [00:38<01:54, 270.55batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9932/40960 [00:38<01:54, 270.55batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9985/40960 [00:38<01:55, 268.74batches/s, l2_loss: 0.0686 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9985/40960 [00:38<01:55, 268.74batches/s, l2_loss: 0.0684 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10046/40960 [00:38<01:50, 278.66batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  25%|▏| 10046/40960 [00:38<01:50, 278.66batches/s, l2_loss: 0.0686 - round_los\u001b[A\n",
      "Training:  25%|▏| 10102/40960 [00:38<01:50, 278.47batches/s, l2_loss: 0.0686 - round_los\u001b[A\n",
      "Training:  25%|▏| 10102/40960 [00:38<01:50, 278.47batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  25%|▏| 10160/40960 [00:39<01:49, 281.66batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  25%|▏| 10160/40960 [00:39<01:49, 281.66batches/s, l2_loss: 0.0685 - round_los\u001b[A\n",
      "Training:  25%|▏| 10214/40960 [00:39<01:50, 277.48batches/s, l2_loss: 0.0685 - round_los\u001b[A\n",
      "Training:  25%|▏| 10214/40960 [00:39<01:50, 277.48batches/s, l2_loss: 0.0685 - round_los\u001b[A\n",
      "Training:  25%|▎| 10260/40960 [00:39<01:57, 262.30batches/s, l2_loss: 0.0685 - round_los\u001b[A\n",
      "Training:  25%|▎| 10260/40960 [00:39<01:57, 262.30batches/s, l2_loss: 0.0685 - round_los\u001b[A\n",
      "Training:  25%|▎| 10311/40960 [00:39<01:58, 258.37batches/s, l2_loss: 0.0685 - round_los\u001b[A\n",
      "Training:  25%|▎| 10311/40960 [00:39<01:58, 258.37batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  25%|▎| 10367/40960 [00:39<01:55, 264.17batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  25%|▎| 10367/40960 [00:39<01:55, 264.17batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  25%|▎| 10428/40960 [00:40<01:50, 275.29batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  25%|▎| 10428/40960 [00:40<01:50, 275.29batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  26%|▎| 10479/40960 [00:40<01:53, 268.40batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  26%|▎| 10479/40960 [00:40<01:53, 268.40batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  26%|▎| 10535/40960 [00:40<01:51, 271.69batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  26%|▎| 10535/40960 [00:40<01:51, 271.69batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  26%|▎| 10598/40960 [00:40<01:47, 283.54batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  26%|▎| 10598/40960 [00:40<01:47, 283.54batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  26%|▎| 10656/40960 [00:40<01:46, 285.44batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  26%|▎| 10656/40960 [00:40<01:46, 285.44batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  26%|▎| 10704/40960 [00:41<01:51, 270.52batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  26%|▎| 10704/40960 [00:41<01:51, 270.52batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  26%|▎| 10759/40960 [00:41<01:51, 270.72batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  26%|▎| 10759/40960 [00:41<01:51, 270.72batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  26%|▎| 10813/40960 [00:41<01:52, 268.21batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  26%|▎| 10813/40960 [00:41<01:52, 268.21batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 10861/40960 [00:41<01:56, 259.30batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 10861/40960 [00:41<01:56, 259.30batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 10911/40960 [00:41<01:57, 256.17batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 10911/40960 [00:41<01:57, 256.17batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 10967/40960 [00:42<01:54, 261.94batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 10967/40960 [00:42<01:54, 261.94batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 11016/40960 [00:42<01:57, 255.04batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 11016/40960 [00:42<01:57, 255.04batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 11072/40960 [00:42<01:54, 261.21batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 11072/40960 [00:42<01:54, 261.21batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 11133/40960 [00:42<01:48, 274.05batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 11133/40960 [00:42<01:48, 274.05batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  27%|▎| 11186/40960 [00:42<01:49, 270.81batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  27%|▎| 11186/40960 [00:42<01:49, 270.81batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 11239/40960 [00:43<01:50, 268.25batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  27%|▎| 11239/40960 [00:43<01:50, 268.25batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  28%|▎| 11299/40960 [00:43<01:46, 277.68batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  28%|▎| 11299/40960 [00:43<01:46, 277.68batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  28%|▎| 11354/40960 [00:43<01:47, 275.94batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  28%|▎| 11354/40960 [00:43<01:47, 275.94batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  28%|▎| 11415/40960 [00:43<01:43, 284.10batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  28%|▎| 11415/40960 [00:43<01:43, 284.10batches/s, l2_loss: 0.0686 - round_los\u001b[A\n",
      "Training:  28%|▎| 11472/40960 [00:43<01:44, 282.41batches/s, l2_loss: 0.0686 - round_los\u001b[A\n",
      "Training:  28%|▎| 11472/40960 [00:43<01:44, 282.41batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  28%|▎| 11532/40960 [00:44<01:42, 286.93batches/s, l2_loss: 0.0684 - round_los\u001b[A\n",
      "Training:  28%|▎| 11532/40960 [00:44<01:42, 286.93batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  28%|▎| 11592/40960 [00:44<01:41, 289.77batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  28%|▎| 11592/40960 [00:44<01:41, 289.77batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  28%|▎| 11646/40960 [00:44<01:43, 282.40batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  28%|▎| 11646/40960 [00:44<01:43, 282.40batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  29%|▎| 11701/40960 [00:44<01:44, 279.85batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  29%|▎| 11701/40960 [00:44<01:44, 279.85batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  29%|▎| 11750/40960 [00:44<01:48, 268.67batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  29%|▎| 11750/40960 [00:44<01:48, 268.67batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  29%|▎| 11798/40960 [00:45<01:52, 259.20batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  29%|▎| 11798/40960 [00:45<01:52, 259.20batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  29%|▎| 11846/40960 [00:45<01:55, 252.31batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  29%|▎| 11846/40960 [00:45<01:55, 252.31batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  29%|▎| 11902/40960 [00:45<01:51, 259.66batches/s, l2_loss: 0.0682 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|▎| 11902/40960 [00:45<01:51, 259.66batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  29%|▎| 11960/40960 [00:45<01:48, 268.49batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  29%|▎| 11960/40960 [00:45<01:48, 268.49batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  29%|▎| 12018/40960 [00:45<01:45, 273.91batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  29%|▎| 12018/40960 [00:45<01:45, 273.91batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  29%|▎| 12076/40960 [00:46<01:43, 278.65batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  29%|▎| 12076/40960 [00:46<01:43, 278.65batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  30%|▎| 12135/40960 [00:46<01:41, 283.26batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  30%|▎| 12135/40960 [00:46<01:41, 283.26batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  30%|▎| 12190/40960 [00:46<01:42, 279.99batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  30%|▎| 12190/40960 [00:46<01:42, 279.99batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  30%|▎| 12246/40960 [00:46<01:42, 279.29batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  30%|▎| 12246/40960 [00:46<01:42, 279.29batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  30%|▎| 12297/40960 [00:46<01:45, 271.56batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  30%|▎| 12297/40960 [00:46<01:45, 271.56batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  30%|▎| 12351/40960 [00:47<01:45, 270.48batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  30%|▎| 12351/40960 [00:47<01:45, 270.48batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  30%|▎| 12394/40960 [00:47<01:53, 252.39batches/s, l2_loss: 0.0683 - round_los\u001b[A\n",
      "Training:  30%|▎| 12394/40960 [00:47<01:53, 252.39batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  30%|▎| 12440/40960 [00:47<01:56, 245.11batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  30%|▎| 12440/40960 [00:47<01:56, 245.11batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  31%|▎| 12496/40960 [00:47<01:51, 255.13batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  31%|▎| 12496/40960 [00:47<01:51, 255.13batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  31%|▎| 12556/40960 [00:48<01:45, 268.01batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  31%|▎| 12556/40960 [00:48<01:45, 268.01batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  31%|▎| 12610/40960 [00:48<01:45, 268.57batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  31%|▎| 12610/40960 [00:48<01:45, 268.57batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  31%|▎| 12664/40960 [00:48<01:45, 268.87batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  31%|▎| 12664/40960 [00:48<01:45, 268.87batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  31%|▎| 12723/40960 [00:48<01:42, 275.69batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  31%|▎| 12723/40960 [00:48<01:42, 275.69batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  31%|▎| 12779/40960 [00:48<01:42, 275.65batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  31%|▎| 12779/40960 [00:48<01:42, 275.65batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  31%|▎| 12837/40960 [00:49<01:40, 279.72batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  31%|▎| 12837/40960 [00:49<01:40, 279.72batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  31%|▎| 12893/40960 [00:49<01:40, 278.60batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  31%|▎| 12893/40960 [00:49<01:40, 278.60batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 12951/40960 [00:49<01:39, 281.07batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 12951/40960 [00:49<01:39, 281.07batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 13011/40960 [00:49<01:37, 286.39batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 13011/40960 [00:49<01:37, 286.39batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 13066/40960 [00:49<01:38, 282.07batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 13066/40960 [00:49<01:38, 282.07batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 13117/40960 [00:50<01:41, 273.42batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 13117/40960 [00:50<01:41, 273.42batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  32%|▎| 13163/40960 [00:50<01:47, 259.62batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  32%|▎| 13163/40960 [00:50<01:47, 259.62batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  32%|▎| 13218/40960 [00:50<01:45, 262.59batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  32%|▎| 13218/40960 [00:50<01:45, 262.59batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 13277/40960 [00:50<01:41, 271.41batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  32%|▎| 13277/40960 [00:50<01:41, 271.41batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  33%|▎| 13330/40960 [00:50<01:43, 267.83batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  33%|▎| 13330/40960 [00:50<01:43, 267.83batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13387/40960 [00:51<01:41, 272.55batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13387/40960 [00:51<01:41, 272.55batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  33%|▎| 13446/40960 [00:51<01:39, 277.89batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  33%|▎| 13446/40960 [00:51<01:39, 277.89batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13492/40960 [00:51<01:44, 262.42batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13492/40960 [00:51<01:44, 262.42batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  33%|▎| 13548/40960 [00:51<01:42, 267.00batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  33%|▎| 13548/40960 [00:51<01:42, 267.00batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13605/40960 [00:51<01:41, 269.98batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13605/40960 [00:51<01:41, 269.98batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13646/40960 [00:52<01:50, 247.53batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13646/40960 [00:52<01:50, 247.53batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13702/40960 [00:52<01:46, 255.98batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  33%|▎| 13702/40960 [00:52<01:46, 255.98batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 13759/40960 [00:52<01:42, 264.34batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 13759/40960 [00:52<01:42, 264.34batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  34%|▎| 13811/40960 [00:52<01:43, 261.65batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  34%|▎| 13811/40960 [00:52<01:43, 261.65batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 13854/40960 [00:52<01:50, 246.18batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 13854/40960 [00:52<01:50, 246.18batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 13905/40960 [00:53<01:48, 248.64batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 13905/40960 [00:53<01:48, 248.64batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 13952/40960 [00:53<01:51, 242.69batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 13952/40960 [00:53<01:51, 242.69batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 14004/40960 [00:53<01:49, 246.63batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 14004/40960 [00:53<01:49, 246.63batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  34%|▎| 14058/40960 [00:53<01:46, 252.81batches/s, l2_loss: 0.0682 - round_los\u001b[A\n",
      "Training:  34%|▎| 14058/40960 [00:53<01:46, 252.81batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 14118/40960 [00:53<01:41, 265.60batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  34%|▎| 14118/40960 [00:53<01:41, 265.60batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  35%|▎| 14175/40960 [00:54<01:39, 269.97batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  35%|▎| 14175/40960 [00:54<01:39, 269.97batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  35%|▎| 14234/40960 [00:54<01:36, 276.64batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  35%|▎| 14234/40960 [00:54<01:36, 276.64batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  35%|▎| 14294/40960 [00:54<01:34, 282.38batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  35%|▎| 14294/40960 [00:54<01:34, 282.38batches/s, l2_loss: 0.0681 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14355/40960 [00:54<01:32, 288.81batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  35%|▎| 14355/40960 [00:54<01:32, 288.81batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  35%|▎| 14416/40960 [00:54<01:30, 292.23batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  35%|▎| 14416/40960 [00:54<01:30, 292.23batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  35%|▎| 14472/40960 [00:55<01:32, 287.44batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  35%|▎| 14472/40960 [00:55<01:32, 287.44batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  35%|▎| 14518/40960 [00:55<01:38, 269.26batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  35%|▎| 14518/40960 [00:55<01:38, 269.26batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  36%|▎| 14577/40960 [00:55<01:35, 276.52batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  36%|▎| 14577/40960 [00:55<01:35, 276.52batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14638/40960 [00:55<01:32, 284.63batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14638/40960 [00:55<01:32, 284.63batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  36%|▎| 14688/40960 [00:55<01:36, 272.03batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  36%|▎| 14688/40960 [00:55<01:36, 272.03batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14739/40960 [00:56<01:39, 264.36batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14739/40960 [00:56<01:39, 264.36batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14794/40960 [00:56<01:37, 267.24batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14794/40960 [00:56<01:37, 267.24batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14841/40960 [00:56<01:42, 255.63batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14841/40960 [00:56<01:42, 255.63batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14894/40960 [00:56<01:40, 258.23batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  36%|▎| 14894/40960 [00:56<01:40, 258.23batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  36%|▎| 14940/40960 [00:56<01:45, 247.13batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  36%|▎| 14940/40960 [00:56<01:45, 247.13batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  37%|▎| 14997/40960 [00:57<01:40, 258.22batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  37%|▎| 14997/40960 [00:57<01:40, 258.22batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15046/40960 [00:57<01:41, 254.09batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15046/40960 [00:57<01:41, 254.09batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15106/40960 [00:57<01:36, 266.60batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15106/40960 [00:57<01:36, 266.60batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15165/40960 [00:57<01:34, 274.29batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15165/40960 [00:57<01:34, 274.29batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  37%|▎| 15217/40960 [00:57<01:36, 267.86batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  37%|▎| 15217/40960 [00:57<01:36, 267.86batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15253/40960 [00:58<01:46, 241.30batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15253/40960 [00:58<01:46, 241.30batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15306/40960 [00:58<01:43, 247.38batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  37%|▎| 15306/40960 [00:58<01:43, 247.38batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  37%|▎| 15355/40960 [00:58<01:44, 245.66batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  37%|▎| 15355/40960 [00:58<01:44, 245.66batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15406/40960 [00:58<01:43, 247.66batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15406/40960 [00:58<01:43, 247.66batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15463/40960 [00:58<01:38, 258.27batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15463/40960 [00:58<01:38, 258.27batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15521/40960 [00:59<01:35, 267.02batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15521/40960 [00:59<01:35, 267.02batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  38%|▍| 15580/40960 [00:59<01:32, 275.23batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  38%|▍| 15580/40960 [00:59<01:32, 275.23batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  38%|▍| 15640/40960 [00:59<01:29, 281.36batches/s, l2_loss: 0.0681 - round_los\u001b[A\n",
      "Training:  38%|▍| 15640/40960 [00:59<01:29, 281.36batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15697/40960 [00:59<01:29, 281.17batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15697/40960 [00:59<01:29, 281.17batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15751/40960 [00:59<01:31, 276.49batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  38%|▍| 15751/40960 [00:59<01:31, 276.49batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 15801/40960 [01:00<01:34, 267.57batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 15801/40960 [01:00<01:34, 267.57batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  39%|▍| 15861/40960 [01:00<01:30, 276.48batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  39%|▍| 15861/40960 [01:00<01:30, 276.48batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 15919/40960 [01:00<01:29, 279.94batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 15919/40960 [01:00<01:29, 279.94batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 15974/40960 [01:00<01:30, 275.47batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 15974/40960 [01:00<01:30, 275.47batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 16020/40960 [01:00<01:35, 260.95batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 16020/40960 [01:00<01:35, 260.95batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  39%|▍| 16062/40960 [01:01<01:42, 242.87batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  39%|▍| 16062/40960 [01:01<01:42, 242.87batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 16103/40960 [01:01<01:47, 231.47batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  39%|▍| 16103/40960 [01:01<01:47, 231.47batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  39%|▍| 16160/40960 [01:01<01:40, 246.96batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  39%|▍| 16160/40960 [01:01<01:40, 246.96batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16218/40960 [01:01<01:35, 258.45batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16218/40960 [01:01<01:35, 258.45batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16280/40960 [01:01<01:30, 273.64batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16280/40960 [01:01<01:30, 273.64batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16340/40960 [01:02<01:27, 280.49batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16340/40960 [01:02<01:27, 280.49batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16397/40960 [01:02<01:27, 280.07batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16397/40960 [01:02<01:27, 280.07batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  40%|▍| 16452/40960 [01:02<01:28, 278.31batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  40%|▍| 16452/40960 [01:02<01:28, 278.31batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16512/40960 [01:02<01:26, 283.62batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16512/40960 [01:02<01:26, 283.62batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16572/40960 [01:02<01:24, 288.44batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  40%|▍| 16572/40960 [01:03<01:24, 288.44batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  41%|▍| 16631/40960 [01:03<01:23, 290.37batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  41%|▍| 16631/40960 [01:03<01:23, 290.37batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16690/40960 [01:03<01:23, 290.88batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16690/40960 [01:03<01:23, 290.88batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16744/40960 [01:03<01:25, 283.51batches/s, l2_loss: 0.0679 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|▍| 16744/40960 [01:03<01:25, 283.51batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16787/40960 [01:03<01:32, 261.22batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16787/40960 [01:03<01:32, 261.22batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  41%|▍| 16829/40960 [01:04<01:39, 243.05batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  41%|▍| 16829/40960 [01:04<01:39, 243.05batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16885/40960 [01:04<01:34, 253.60batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16885/40960 [01:04<01:34, 253.60batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16934/40960 [01:04<01:36, 250.08batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  41%|▍| 16934/40960 [01:04<01:36, 250.08batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  41%|▍| 16986/40960 [01:04<01:35, 251.23batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  41%|▍| 16986/40960 [01:04<01:35, 251.23batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  42%|▍| 17036/40960 [01:04<01:35, 250.06batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  42%|▍| 17036/40960 [01:04<01:35, 250.06batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  42%|▍| 17088/40960 [01:05<01:34, 252.99batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  42%|▍| 17088/40960 [01:05<01:34, 252.99batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17137/40960 [01:05<01:35, 249.53batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17137/40960 [01:05<01:35, 249.53batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17188/40960 [01:05<01:34, 251.08batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17188/40960 [01:05<01:34, 251.08batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17234/40960 [01:05<01:37, 244.17batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17234/40960 [01:05<01:37, 244.17batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  42%|▍| 17294/40960 [01:05<01:31, 258.65batches/s, l2_loss: 0.0680 - round_los\u001b[A\n",
      "Training:  42%|▍| 17294/40960 [01:05<01:31, 258.65batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17344/40960 [01:06<01:32, 255.39batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17344/40960 [01:06<01:32, 255.39batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17393/40960 [01:06<01:33, 250.77batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  42%|▍| 17393/40960 [01:06<01:33, 250.77batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17453/40960 [01:06<01:29, 264.11batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17453/40960 [01:06<01:29, 264.11batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17509/40960 [01:06<01:27, 268.47batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17509/40960 [01:06<01:27, 268.47batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17563/40960 [01:06<01:27, 267.65batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17563/40960 [01:06<01:27, 267.65batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17614/40960 [01:07<01:28, 262.87batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17614/40960 [01:07<01:28, 262.87batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17664/40960 [01:07<01:30, 257.34batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17664/40960 [01:07<01:30, 257.34batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17714/40960 [01:07<01:31, 254.74batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17714/40960 [01:07<01:31, 254.74batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17767/40960 [01:07<01:30, 256.56batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  43%|▍| 17767/40960 [01:07<01:30, 256.56batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 17820/40960 [01:07<01:29, 257.53batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 17820/40960 [01:07<01:29, 257.53batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 17868/40960 [01:08<01:31, 251.43batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 17868/40960 [01:08<01:31, 251.43batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 17915/40960 [01:08<01:34, 245.04batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 17915/40960 [01:08<01:34, 245.04batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 17973/40960 [01:08<01:29, 257.84batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 17973/40960 [01:08<01:29, 257.84batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 18030/40960 [01:08<01:26, 265.69batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 18030/40960 [01:08<01:26, 265.69batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 18083/40960 [01:08<01:26, 264.54batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 18083/40960 [01:08<01:26, 264.54batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 18144/40960 [01:09<01:22, 276.46batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 18144/40960 [01:09<01:22, 276.46batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 18204/40960 [01:09<01:20, 281.95batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  44%|▍| 18204/40960 [01:09<01:20, 281.95batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18262/40960 [01:09<01:20, 282.42batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18262/40960 [01:09<01:20, 282.42batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18320/40960 [01:09<01:19, 283.53batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18320/40960 [01:09<01:19, 283.53batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18379/40960 [01:09<01:19, 285.25batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18379/40960 [01:09<01:19, 285.25batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18436/40960 [01:10<01:19, 285.06batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18436/40960 [01:10<01:19, 285.06batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18486/40960 [01:10<01:22, 272.52batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18486/40960 [01:10<01:22, 272.52batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18541/40960 [01:10<01:22, 272.16batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18541/40960 [01:10<01:22, 272.16batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18602/40960 [01:10<01:19, 281.42batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  45%|▍| 18602/40960 [01:10<01:19, 281.42batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  46%|▍| 18662/40960 [01:10<01:17, 286.22batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  46%|▍| 18662/40960 [01:10<01:17, 286.22batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18716/40960 [01:11<01:19, 280.30batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18716/40960 [01:11<01:19, 280.30batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18767/40960 [01:11<01:21, 272.74batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18767/40960 [01:11<01:21, 272.74batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18815/40960 [01:11<01:24, 262.46batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18815/40960 [01:11<01:24, 262.46batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18867/40960 [01:11<01:24, 261.52batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18867/40960 [01:11<01:24, 261.52batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  46%|▍| 18912/40960 [01:11<01:28, 249.58batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  46%|▍| 18912/40960 [01:11<01:28, 249.58batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18969/40960 [01:12<01:24, 259.48batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 18969/40960 [01:12<01:24, 259.48batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 19026/40960 [01:12<01:22, 266.10batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  46%|▍| 19026/40960 [01:12<01:22, 266.10batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  47%|▍| 19083/40960 [01:12<01:20, 270.85batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  47%|▍| 19083/40960 [01:12<01:20, 270.85batches/s, l2_loss: 0.0678 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|▍| 19144/40960 [01:12<01:17, 280.01batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  47%|▍| 19144/40960 [01:12<01:17, 280.01batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  47%|▍| 19201/40960 [01:12<01:17, 280.58batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  47%|▍| 19201/40960 [01:12<01:17, 280.58batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  47%|▍| 19254/40960 [01:13<01:18, 275.28batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  47%|▍| 19254/40960 [01:13<01:18, 275.28batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  47%|▍| 19313/40960 [01:13<01:17, 280.08batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  47%|▍| 19313/40960 [01:13<01:17, 280.08batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  47%|▍| 19368/40960 [01:13<01:17, 278.09batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  47%|▍| 19368/40960 [01:13<01:17, 278.09batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  47%|▍| 19422/40960 [01:13<01:18, 275.52batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  47%|▍| 19422/40960 [01:13<01:18, 275.52batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  48%|▍| 19476/40960 [01:13<01:18, 273.87batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  48%|▍| 19476/40960 [01:13<01:18, 273.87batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19528/40960 [01:14<01:20, 267.52batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19528/40960 [01:14<01:20, 267.52batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  48%|▍| 19584/40960 [01:14<01:19, 269.79batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  48%|▍| 19584/40960 [01:14<01:19, 269.79batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19637/40960 [01:14<01:19, 267.30batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19637/40960 [01:14<01:19, 267.30batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19675/40960 [01:14<01:27, 243.58batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19675/40960 [01:14<01:27, 243.58batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19722/40960 [01:14<01:28, 239.84batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19722/40960 [01:14<01:28, 239.84batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19776/40960 [01:15<01:25, 248.59batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  48%|▍| 19776/40960 [01:15<01:25, 248.59batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  48%|▍| 19830/40960 [01:15<01:23, 253.30batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  48%|▍| 19830/40960 [01:15<01:23, 253.30batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 19881/40960 [01:15<01:23, 252.93batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 19881/40960 [01:15<01:23, 252.93batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 19924/40960 [01:15<01:27, 240.34batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 19924/40960 [01:15<01:27, 240.34batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  49%|▍| 19979/40960 [01:15<01:24, 249.64batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  49%|▍| 19979/40960 [01:15<01:24, 249.64batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 20026/40960 [01:16<01:25, 245.29batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 20026/40960 [01:16<01:25, 245.29batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  49%|▍| 20073/40960 [01:16<01:26, 241.04batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  49%|▍| 20073/40960 [01:16<01:26, 241.04batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 20123/40960 [01:16<01:26, 242.10batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 20123/40960 [01:16<01:26, 242.10batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 20175/40960 [01:16<01:24, 247.09batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 20175/40960 [01:16<01:24, 247.09batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 20230/40960 [01:16<01:21, 255.38batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  49%|▍| 20230/40960 [01:16<01:21, 255.38batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20283/40960 [01:17<01:20, 256.64batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20283/40960 [01:17<01:20, 256.64batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20332/40960 [01:17<01:21, 252.38batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20332/40960 [01:17<01:21, 252.38batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20388/40960 [01:17<01:19, 259.17batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20388/40960 [01:17<01:19, 259.17batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20435/40960 [01:17<01:21, 251.03batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20435/40960 [01:17<01:21, 251.03batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20478/40960 [01:17<01:25, 240.21batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▍| 20478/40960 [01:17<01:25, 240.21batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▌| 20534/40960 [01:18<01:21, 251.21batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▌| 20534/40960 [01:18<01:21, 251.21batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  50%|▌| 20595/40960 [01:18<01:16, 266.09batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  50%|▌| 20595/40960 [01:18<01:16, 266.09batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▌| 20655/40960 [01:18<01:13, 276.06batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  50%|▌| 20655/40960 [01:18<01:13, 276.06batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20715/40960 [01:18<01:11, 282.14batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20715/40960 [01:18<01:11, 282.14batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20777/40960 [01:18<01:09, 289.06batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20777/40960 [01:18<01:09, 289.06batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20827/40960 [01:19<01:12, 277.31batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20827/40960 [01:19<01:12, 277.31batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20883/40960 [01:19<01:12, 277.20batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20883/40960 [01:19<01:12, 277.20batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20934/40960 [01:19<01:14, 269.62batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20934/40960 [01:19<01:14, 269.62batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20988/40960 [01:19<01:14, 269.50batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 20988/40960 [01:19<01:14, 269.50batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 21050/40960 [01:19<01:10, 281.00batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  51%|▌| 21050/40960 [01:20<01:10, 281.00batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21106/40960 [01:20<01:10, 280.45batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21106/40960 [01:20<01:10, 280.45batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21156/40960 [01:20<01:13, 270.27batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21156/40960 [01:20<01:13, 270.27batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21201/40960 [01:20<01:17, 256.10batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21201/40960 [01:20<01:17, 256.10batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21251/40960 [01:20<01:17, 253.57batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21251/40960 [01:20<01:17, 253.57batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21300/40960 [01:21<01:18, 249.11batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21300/40960 [01:21<01:18, 249.11batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21352/40960 [01:21<01:17, 251.93batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21352/40960 [01:21<01:17, 251.93batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21402/40960 [01:21<01:17, 250.79batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21402/40960 [01:21<01:17, 250.79batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  52%|▌| 21460/40960 [01:21<01:14, 261.18batches/s, l2_loss: 0.0678 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21460/40960 [01:21<01:14, 261.18batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21521/40960 [01:21<01:11, 273.67batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21521/40960 [01:21<01:11, 273.67batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21575/40960 [01:22<01:11, 271.56batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21575/40960 [01:22<01:11, 271.56batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21629/40960 [01:22<01:11, 270.39batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21629/40960 [01:22<01:11, 270.39batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21685/40960 [01:22<01:10, 272.63batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21685/40960 [01:22<01:10, 272.63batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21741/40960 [01:22<01:10, 273.48batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21741/40960 [01:22<01:10, 273.48batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21804/40960 [01:22<01:07, 284.88batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21804/40960 [01:22<01:07, 284.88batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21864/40960 [01:23<01:06, 288.52batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  53%|▌| 21864/40960 [01:23<01:06, 288.52batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 21918/40960 [01:23<01:07, 282.91batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 21918/40960 [01:23<01:07, 282.91batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 21963/40960 [01:23<01:11, 264.91batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 21963/40960 [01:23<01:11, 264.91batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22015/40960 [01:23<01:12, 262.67batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22015/40960 [01:23<01:12, 262.67batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22070/40960 [01:23<01:10, 266.33batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22070/40960 [01:23<01:10, 266.33batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22121/40960 [01:24<01:11, 262.30batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22121/40960 [01:24<01:11, 262.30batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22175/40960 [01:24<01:11, 264.04batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22175/40960 [01:24<01:11, 264.04batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22229/40960 [01:24<01:10, 265.67batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22229/40960 [01:24<01:10, 265.67batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22278/40960 [01:24<01:12, 258.96batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  54%|▌| 22278/40960 [01:24<01:12, 258.96batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22327/40960 [01:24<01:13, 253.65batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22327/40960 [01:24<01:13, 253.65batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22380/40960 [01:25<01:12, 255.83batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22380/40960 [01:25<01:12, 255.83batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22436/40960 [01:25<01:10, 262.32batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22436/40960 [01:25<01:10, 262.32batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22486/40960 [01:25<01:11, 258.04batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22486/40960 [01:25<01:11, 258.04batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22547/40960 [01:25<01:07, 271.46batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22547/40960 [01:25<01:07, 271.46batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22601/40960 [01:25<01:08, 269.11batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22601/40960 [01:25<01:08, 269.11batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22659/40960 [01:26<01:06, 274.68batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22659/40960 [01:26<01:06, 274.68batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22721/40960 [01:26<01:04, 284.18batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  55%|▌| 22721/40960 [01:26<01:04, 284.18batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 22780/40960 [01:26<01:03, 286.32batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 22780/40960 [01:26<01:03, 286.32batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 22840/40960 [01:26<01:02, 289.73batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 22840/40960 [01:26<01:02, 289.73batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 22893/40960 [01:26<01:04, 281.34batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 22893/40960 [01:26<01:04, 281.34batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 22947/40960 [01:27<01:05, 276.64batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 22947/40960 [01:27<01:05, 276.64batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  56%|▌| 23002/40960 [01:27<01:05, 275.38batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  56%|▌| 23002/40960 [01:27<01:05, 275.38batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  56%|▌| 23061/40960 [01:27<01:03, 280.74batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  56%|▌| 23061/40960 [01:27<01:03, 280.74batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 23116/40960 [01:27<01:04, 277.97batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  56%|▌| 23116/40960 [01:27<01:04, 277.97batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  57%|▌| 23173/40960 [01:27<01:03, 279.98batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  57%|▌| 23173/40960 [01:27<01:03, 279.98batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  57%|▌| 23221/40960 [01:28<01:06, 266.35batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  57%|▌| 23221/40960 [01:28<01:06, 266.35batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  57%|▌| 23277/40960 [01:28<01:05, 270.37batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  57%|▌| 23277/40960 [01:28<01:05, 270.37batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  57%|▌| 23333/40960 [01:28<01:04, 272.44batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  57%|▌| 23333/40960 [01:28<01:04, 272.44batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  57%|▌| 23393/40960 [01:28<01:02, 280.33batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  57%|▌| 23393/40960 [01:28<01:02, 280.33batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  57%|▌| 23451/40960 [01:28<01:01, 282.99batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  57%|▌| 23451/40960 [01:28<01:01, 282.99batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  57%|▌| 23509/40960 [01:29<01:01, 284.63batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  57%|▌| 23509/40960 [01:29<01:01, 284.63batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23566/40960 [01:29<01:01, 284.00batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23566/40960 [01:29<01:01, 284.00batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23622/40960 [01:29<01:01, 282.14batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23622/40960 [01:29<01:01, 282.14batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23681/40960 [01:29<01:00, 284.23batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23681/40960 [01:29<01:00, 284.23batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23741/40960 [01:29<00:59, 288.01batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23741/40960 [01:29<00:59, 288.01batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23798/40960 [01:30<01:00, 285.90batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23798/40960 [01:30<01:00, 285.90batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23857/40960 [01:30<00:59, 288.11batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23857/40960 [01:30<00:59, 288.11batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23916/40960 [01:30<00:58, 289.70batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  58%|▌| 23916/40960 [01:30<00:58, 289.70batches/s, l2_loss: 0.0677 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|▌| 23978/40960 [01:30<00:57, 294.79batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 23978/40960 [01:30<00:57, 294.79batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24037/40960 [01:30<00:57, 294.09batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24037/40960 [01:30<00:57, 294.09batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24094/40960 [01:31<00:57, 291.22batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24094/40960 [01:31<00:57, 291.22batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24148/40960 [01:31<00:59, 284.39batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24148/40960 [01:31<00:59, 284.39batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24204/40960 [01:31<00:59, 281.98batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24204/40960 [01:31<00:59, 281.98batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  59%|▌| 24261/40960 [01:31<00:59, 281.74batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  59%|▌| 24261/40960 [01:31<00:59, 281.74batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  59%|▌| 24310/40960 [01:31<01:01, 268.89batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  59%|▌| 24310/40960 [01:31<01:01, 268.89batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24366/40960 [01:32<01:01, 271.22batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  59%|▌| 24366/40960 [01:32<01:01, 271.22batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24426/40960 [01:32<00:59, 278.54batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24426/40960 [01:32<00:59, 278.54batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24481/40960 [01:32<00:59, 276.18batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24481/40960 [01:32<00:59, 276.18batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24537/40960 [01:32<00:59, 276.62batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24537/40960 [01:32<00:59, 276.62batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24591/40960 [01:32<00:59, 274.37batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24591/40960 [01:32<00:59, 274.37batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24648/40960 [01:33<00:58, 277.48batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24648/40960 [01:33<00:58, 277.48batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24708/40960 [01:33<00:57, 283.07batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24708/40960 [01:33<00:57, 283.07batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24765/40960 [01:33<00:57, 283.34batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  60%|▌| 24765/40960 [01:33<00:57, 283.34batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 24819/40960 [01:33<00:57, 279.32batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 24819/40960 [01:33<00:57, 279.32batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 24877/40960 [01:33<00:57, 281.49batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 24877/40960 [01:33<00:57, 281.49batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 24936/40960 [01:34<00:56, 284.55batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 24936/40960 [01:34<00:56, 284.55batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 24996/40960 [01:34<00:55, 288.42batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 24996/40960 [01:34<00:55, 288.42batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 25050/40960 [01:34<00:56, 281.56batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 25050/40960 [01:34<00:56, 281.56batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 25107/40960 [01:34<00:56, 281.67batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 25107/40960 [01:34<00:56, 281.67batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 25163/40960 [01:34<00:56, 280.72batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  61%|▌| 25163/40960 [01:34<00:56, 280.72batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25225/40960 [01:35<00:54, 289.36batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25225/40960 [01:35<00:54, 289.36batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25278/40960 [01:35<00:55, 281.37batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25278/40960 [01:35<00:55, 281.37batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25340/40960 [01:35<00:53, 289.26batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25340/40960 [01:35<00:53, 289.26batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25401/40960 [01:35<00:53, 293.31batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25401/40960 [01:35<00:53, 293.31batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25449/40960 [01:35<00:55, 277.37batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25449/40960 [01:35<00:55, 277.37batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25500/40960 [01:36<00:57, 270.01batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25500/40960 [01:36<00:57, 270.01batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25554/40960 [01:36<00:57, 269.64batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25554/40960 [01:36<00:57, 269.64batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25598/40960 [01:36<01:00, 254.13batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  62%|▌| 25598/40960 [01:36<01:00, 254.13batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25634/40960 [01:36<01:06, 228.91batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25634/40960 [01:36<01:06, 228.91batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25687/40960 [01:36<01:03, 238.72batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25687/40960 [01:36<01:03, 238.72batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25740/40960 [01:37<01:01, 246.22batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25740/40960 [01:37<01:01, 246.22batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25794/40960 [01:37<01:00, 252.50batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25794/40960 [01:37<01:00, 252.50batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25845/40960 [01:37<01:00, 251.78batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25845/40960 [01:37<01:00, 251.78batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25905/40960 [01:37<00:56, 265.55batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25905/40960 [01:37<00:56, 265.55batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25964/40960 [01:37<00:54, 273.70batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  63%|▋| 25964/40960 [01:37<00:54, 273.70batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26025/40960 [01:38<00:52, 282.97batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26025/40960 [01:38<00:52, 282.97batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26086/40960 [01:38<00:51, 288.78batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26086/40960 [01:38<00:51, 288.78batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26142/40960 [01:38<00:51, 285.51batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26142/40960 [01:38<00:51, 285.51batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26197/40960 [01:38<00:52, 281.30batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26197/40960 [01:38<00:52, 281.30batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26253/40960 [01:38<00:52, 280.64batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26253/40960 [01:38<00:52, 280.64batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26314/40960 [01:39<00:51, 286.94batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26314/40960 [01:39<00:51, 286.94batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26371/40960 [01:39<00:51, 284.91batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  64%|▋| 26371/40960 [01:39<00:51, 284.91batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26430/40960 [01:39<00:50, 286.54batches/s, l2_loss: 0.0677 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 26430/40960 [01:39<00:50, 286.54batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26490/40960 [01:39<00:49, 289.64batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26490/40960 [01:39<00:49, 289.64batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26547/40960 [01:39<00:50, 286.79batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26547/40960 [01:39<00:50, 286.79batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26604/40960 [01:40<00:50, 286.03batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26604/40960 [01:40<00:50, 286.03batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26662/40960 [01:40<00:49, 286.20batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26662/40960 [01:40<00:49, 286.20batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26722/40960 [01:40<00:49, 289.56batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26722/40960 [01:40<00:49, 289.56batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26780/40960 [01:40<00:49, 288.38batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26780/40960 [01:40<00:49, 288.38batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26827/40960 [01:41<00:52, 269.60batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  65%|▋| 26827/40960 [01:41<00:52, 269.60batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 26866/40960 [01:41<00:57, 247.03batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 26866/40960 [01:41<00:57, 247.03batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 26918/40960 [01:41<00:56, 250.47batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 26918/40960 [01:41<00:56, 250.47batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 26967/40960 [01:41<00:56, 248.00batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 26967/40960 [01:41<00:56, 248.00batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 27027/40960 [01:41<00:53, 262.62batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 27027/40960 [01:41<00:53, 262.62batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 27083/40960 [01:42<00:51, 267.30batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 27083/40960 [01:42<00:51, 267.30batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 27142/40960 [01:42<00:50, 274.88batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 27142/40960 [01:42<00:50, 274.88batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:42<00:49, 278.99batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:42<00:49, 278.99batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27257/40960 [01:42<00:49, 279.35batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27257/40960 [01:42<00:49, 279.35batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27315/40960 [01:42<00:48, 282.09batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27315/40960 [01:42<00:48, 282.09batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27373/40960 [01:43<00:47, 283.98batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27373/40960 [01:43<00:47, 283.98batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27424/40960 [01:43<00:49, 275.15batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27424/40960 [01:43<00:49, 275.15batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27472/40960 [01:43<00:50, 264.56batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27472/40960 [01:43<00:50, 264.56batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27531/40960 [01:43<00:49, 273.39batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27531/40960 [01:43<00:49, 273.39batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27586/40960 [01:43<00:49, 272.21batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27586/40960 [01:43<00:49, 272.21batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27641/40960 [01:44<00:48, 272.09batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  67%|▋| 27641/40960 [01:44<00:48, 272.09batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27699/40960 [01:44<00:48, 276.27batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27699/40960 [01:44<00:48, 276.27batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27750/40960 [01:44<00:49, 269.30batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27750/40960 [01:44<00:49, 269.30batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27807/40960 [01:44<00:48, 272.94batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27807/40960 [01:44<00:48, 272.94batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27844/40960 [01:44<00:53, 246.19batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27844/40960 [01:44<00:53, 246.19batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27875/40960 [01:45<01:00, 216.65batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27875/40960 [01:45<01:00, 216.65batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27919/40960 [01:45<01:00, 215.46batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27919/40960 [01:45<01:00, 215.46batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27974/40960 [01:45<00:55, 232.03batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 27974/40960 [01:45<00:55, 232.03batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 28033/40960 [01:45<00:51, 249.56batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  68%|▋| 28033/40960 [01:45<00:51, 249.56batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28091/40960 [01:45<00:49, 261.24batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28091/40960 [01:45<00:49, 261.24batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28147/40960 [01:46<00:48, 265.01batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28147/40960 [01:46<00:48, 265.01batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28202/40960 [01:46<00:47, 267.69batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28202/40960 [01:46<00:47, 267.69batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  69%|▋| 28254/40960 [01:46<00:47, 264.76batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  69%|▋| 28254/40960 [01:46<00:47, 264.76batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28310/40960 [01:46<00:46, 269.15batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28310/40960 [01:46<00:46, 269.15batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28371/40960 [01:46<00:45, 278.75batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28371/40960 [01:46<00:45, 278.75batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28425/40960 [01:47<00:45, 276.02batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  69%|▋| 28425/40960 [01:47<00:45, 276.02batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  70%|▋| 28486/40960 [01:47<00:43, 283.85batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  70%|▋| 28486/40960 [01:47<00:43, 283.85batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  70%|▋| 28546/40960 [01:47<00:43, 288.61batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  70%|▋| 28546/40960 [01:47<00:43, 288.61batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  70%|▋| 28599/40960 [01:47<00:43, 281.14batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  70%|▋| 28599/40960 [01:47<00:43, 281.14batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  70%|▋| 28659/40960 [01:47<00:42, 286.42batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  70%|▋| 28659/40960 [01:47<00:42, 286.42batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  70%|▋| 28717/40960 [01:48<00:42, 287.00batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  70%|▋| 28717/40960 [01:48<00:42, 287.00batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  70%|▋| 28778/40960 [01:48<00:41, 291.92batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  70%|▋| 28778/40960 [01:48<00:41, 291.92batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  70%|▋| 28832/40960 [01:48<00:42, 283.73batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  70%|▋| 28832/40960 [01:48<00:42, 283.73batches/s, l2_loss: 0.0677 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|▋| 28887/40960 [01:48<00:43, 279.83batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 28887/40960 [01:48<00:43, 279.83batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 28938/40960 [01:48<00:44, 272.29batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 28938/40960 [01:48<00:44, 272.29batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 28989/40960 [01:49<00:44, 267.13batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 28989/40960 [01:49<00:44, 267.13batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 29043/40960 [01:49<00:44, 266.33batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 29043/40960 [01:49<00:44, 266.33batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 29099/40960 [01:49<00:43, 270.05batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 29099/40960 [01:49<00:43, 270.05batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 29156/40960 [01:49<00:43, 273.25batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 29156/40960 [01:49<00:43, 273.25batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 29212/40960 [01:49<00:42, 274.25batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  71%|▋| 29212/40960 [01:49<00:42, 274.25batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  71%|▋| 29270/40960 [01:50<00:41, 278.48batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  71%|▋| 29270/40960 [01:50<00:41, 278.48batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29324/40960 [01:50<00:42, 275.78batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29324/40960 [01:50<00:42, 275.78batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29385/40960 [01:50<00:40, 282.90batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29385/40960 [01:50<00:40, 282.90batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29444/40960 [01:50<00:40, 285.70batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29444/40960 [01:50<00:40, 285.70batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29498/40960 [01:50<00:40, 280.68batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29498/40960 [01:50<00:40, 280.68batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  72%|▋| 29551/40960 [01:51<00:41, 275.50batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  72%|▋| 29551/40960 [01:51<00:41, 275.50batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  72%|▋| 29607/40960 [01:51<00:41, 276.01batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  72%|▋| 29607/40960 [01:51<00:41, 276.01batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29665/40960 [01:51<00:40, 279.98batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  72%|▋| 29665/40960 [01:51<00:40, 279.98batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29716/40960 [01:51<00:41, 272.22batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29716/40960 [01:51<00:41, 272.22batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29766/40960 [01:51<00:42, 264.66batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29766/40960 [01:51<00:42, 264.66batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  73%|▋| 29815/40960 [01:52<00:43, 257.21batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  73%|▋| 29815/40960 [01:52<00:43, 257.21batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29864/40960 [01:52<00:43, 252.62batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29864/40960 [01:52<00:43, 252.62batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29925/40960 [01:52<00:41, 267.68batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29925/40960 [01:52<00:41, 267.68batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29980/40960 [01:52<00:40, 268.86batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 29980/40960 [01:52<00:40, 268.86batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  73%|▋| 30038/40960 [01:52<00:39, 273.59batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  73%|▋| 30038/40960 [01:52<00:39, 273.59batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 30093/40960 [01:53<00:40, 270.68batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  73%|▋| 30093/40960 [01:53<00:40, 270.68batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30150/40960 [01:53<00:39, 273.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30150/40960 [01:53<00:39, 273.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30208/40960 [01:53<00:38, 277.11batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30208/40960 [01:53<00:38, 277.11batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30257/40960 [01:53<00:40, 266.31batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30257/40960 [01:53<00:40, 266.31batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30314/40960 [01:53<00:39, 270.82batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30314/40960 [01:53<00:39, 270.82batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30374/40960 [01:54<00:38, 278.23batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30374/40960 [01:54<00:38, 278.23batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30432/40960 [01:54<00:37, 280.64batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30432/40960 [01:54<00:37, 280.64batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30487/40960 [01:54<00:37, 278.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  74%|▋| 30487/40960 [01:54<00:37, 278.88batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  75%|▋| 30545/40960 [01:54<00:37, 281.31batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  75%|▋| 30545/40960 [01:54<00:37, 281.31batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  75%|▋| 30603/40960 [01:54<00:36, 282.51batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  75%|▋| 30603/40960 [01:54<00:36, 282.51batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▋| 30660/40960 [01:55<00:36, 281.92batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▋| 30660/40960 [01:55<00:36, 281.92batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▋| 30717/40960 [01:55<00:36, 281.17batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▋| 30717/40960 [01:55<00:36, 281.17batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▊| 30778/40960 [01:55<00:35, 287.25batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▊| 30778/40960 [01:55<00:35, 287.25batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▊| 30837/40960 [01:55<00:34, 289.31batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▊| 30837/40960 [01:55<00:34, 289.31batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▊| 30893/40960 [01:55<00:35, 285.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  75%|▊| 30893/40960 [01:55<00:35, 285.49batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  76%|▊| 30949/40960 [01:56<00:35, 283.59batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  76%|▊| 30949/40960 [01:56<00:35, 283.59batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31007/40960 [01:56<00:34, 284.41batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31007/40960 [01:56<00:34, 284.41batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31058/40960 [01:56<00:36, 274.14batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31058/40960 [01:56<00:36, 274.14batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31109/40960 [01:56<00:36, 268.30batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31109/40960 [01:56<00:36, 268.30batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31167/40960 [01:56<00:35, 274.58batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31167/40960 [01:56<00:35, 274.58batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31223/40960 [01:57<00:35, 275.22batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31223/40960 [01:57<00:35, 275.22batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31277/40960 [01:57<00:35, 272.71batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31277/40960 [01:57<00:35, 272.71batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  76%|▊| 31334/40960 [01:57<00:34, 276.36batches/s, l2_loss: 0.0676 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31334/40960 [01:57<00:34, 276.36batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31395/40960 [01:57<00:33, 284.10batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31395/40960 [01:57<00:33, 284.10batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31454/40960 [01:57<00:33, 287.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31454/40960 [01:57<00:33, 287.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31515/40960 [01:58<00:32, 291.97batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31515/40960 [01:58<00:32, 291.97batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31569/40960 [01:58<00:32, 284.83batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31569/40960 [01:58<00:32, 284.83batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31627/40960 [01:58<00:32, 285.05batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31627/40960 [01:58<00:32, 285.05batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31682/40960 [01:58<00:32, 281.69batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31682/40960 [01:58<00:32, 281.69batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31741/40960 [01:58<00:32, 285.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  77%|▊| 31741/40960 [01:58<00:32, 285.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31784/40960 [01:59<00:34, 263.06batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31784/40960 [01:59<00:34, 263.06batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31829/40960 [01:59<00:36, 249.53batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31829/40960 [01:59<00:36, 249.53batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31878/40960 [01:59<00:36, 247.12batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31878/40960 [01:59<00:36, 247.12batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31934/40960 [01:59<00:35, 256.08batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31934/40960 [01:59<00:35, 256.08batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31984/40960 [02:00<00:35, 253.24batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 31984/40960 [02:00<00:35, 253.24batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 32043/40960 [02:00<00:33, 264.43batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 32043/40960 [02:00<00:33, 264.43batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 32103/40960 [02:00<00:32, 274.57batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  78%|▊| 32103/40960 [02:00<00:32, 274.57batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32166/40960 [02:00<00:30, 285.84batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32166/40960 [02:00<00:30, 285.84batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32227/40960 [02:00<00:30, 290.65batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32227/40960 [02:00<00:30, 290.65batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32288/40960 [02:01<00:29, 294.57batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32288/40960 [02:01<00:29, 294.57batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32347/40960 [02:01<00:29, 294.45batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32347/40960 [02:01<00:29, 294.45batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32403/40960 [02:01<00:29, 289.13batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32403/40960 [02:01<00:29, 289.13batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32452/40960 [02:01<00:30, 275.84batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32452/40960 [02:01<00:30, 275.84batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32503/40960 [02:01<00:31, 268.44batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32503/40960 [02:01<00:31, 268.44batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32560/40960 [02:02<00:30, 272.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  79%|▊| 32560/40960 [02:02<00:30, 272.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32610/40960 [02:02<00:31, 265.27batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32610/40960 [02:02<00:31, 265.27batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32671/40960 [02:02<00:29, 276.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32671/40960 [02:02<00:29, 276.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32726/40960 [02:02<00:29, 275.75batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32726/40960 [02:02<00:29, 275.75batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32783/40960 [02:02<00:29, 278.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32783/40960 [02:02<00:29, 278.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32842/40960 [02:03<00:28, 281.74batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32842/40960 [02:03<00:28, 281.74batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32904/40960 [02:03<00:27, 288.95batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32904/40960 [02:03<00:27, 288.95batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32963/40960 [02:03<00:27, 290.29batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  80%|▊| 32963/40960 [02:03<00:27, 290.29batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33022/40960 [02:03<00:27, 290.92batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33022/40960 [02:03<00:27, 290.92batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33080/40960 [02:03<00:27, 289.52batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33080/40960 [02:03<00:27, 289.52batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33137/40960 [02:04<00:27, 288.00batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33137/40960 [02:04<00:27, 288.00batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33196/40960 [02:04<00:26, 290.04batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33196/40960 [02:04<00:26, 290.04batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33256/40960 [02:04<00:26, 291.66batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33256/40960 [02:04<00:26, 291.66batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33310/40960 [02:04<00:26, 283.64batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33310/40960 [02:04<00:26, 283.64batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33355/40960 [02:04<00:28, 265.86batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  81%|▊| 33355/40960 [02:04<00:28, 265.86batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33401/40960 [02:05<00:29, 254.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33401/40960 [02:05<00:29, 254.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33457/40960 [02:05<00:28, 260.66batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33457/40960 [02:05<00:28, 260.66batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33513/40960 [02:05<00:28, 265.70batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33513/40960 [02:05<00:28, 265.70batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33568/40960 [02:05<00:27, 268.30batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33568/40960 [02:05<00:27, 268.30batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33627/40960 [02:05<00:26, 275.05batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33627/40960 [02:05<00:26, 275.05batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33684/40960 [02:06<00:26, 276.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33684/40960 [02:06<00:26, 276.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33738/40960 [02:06<00:26, 274.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33738/40960 [02:06<00:26, 274.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33785/40960 [02:06<00:27, 262.00batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  82%|▊| 33785/40960 [02:06<00:27, 262.00batches/s, l2_loss: 0.0676 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 33823/40960 [02:06<00:29, 240.33batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33823/40960 [02:06<00:29, 240.33batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33863/40960 [02:06<00:31, 226.73batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33863/40960 [02:06<00:31, 226.73batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33903/40960 [02:07<00:32, 217.25batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33903/40960 [02:07<00:32, 217.25batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33952/40960 [02:07<00:31, 224.02batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33952/40960 [02:07<00:31, 224.02batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33996/40960 [02:07<00:31, 222.82batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 33996/40960 [02:07<00:31, 222.82batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 34051/40960 [02:07<00:29, 236.92batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 34051/40960 [02:07<00:29, 236.92batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 34103/40960 [02:07<00:28, 243.73batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 34103/40960 [02:07<00:28, 243.73batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 34156/40960 [02:08<00:27, 249.18batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  83%|▊| 34156/40960 [02:08<00:27, 249.18batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34208/40960 [02:08<00:26, 251.13batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34208/40960 [02:08<00:26, 251.13batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34264/40960 [02:08<00:25, 258.19batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34264/40960 [02:08<00:25, 258.19batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34320/40960 [02:08<00:25, 263.45batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34320/40960 [02:08<00:25, 263.45batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34372/40960 [02:08<00:25, 262.06batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34372/40960 [02:08<00:25, 262.06batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34427/40960 [02:09<00:24, 264.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34427/40960 [02:09<00:24, 264.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34486/40960 [02:09<00:23, 273.56batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34486/40960 [02:09<00:23, 273.56batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34541/40960 [02:09<00:23, 273.77batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34541/40960 [02:09<00:23, 273.77batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34592/40960 [02:09<00:23, 268.15batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  84%|▊| 34592/40960 [02:09<00:23, 268.15batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34637/40960 [02:09<00:24, 253.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34637/40960 [02:09<00:24, 253.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34680/40960 [02:10<00:26, 241.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34680/40960 [02:10<00:26, 241.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34738/40960 [02:10<00:24, 254.93batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34738/40960 [02:10<00:24, 254.93batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34798/40960 [02:10<00:23, 267.28batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34798/40960 [02:10<00:23, 267.28batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34848/40960 [02:10<00:23, 261.23batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34848/40960 [02:10<00:23, 261.23batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34907/40960 [02:10<00:22, 271.18batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34907/40960 [02:10<00:22, 271.18batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34966/40960 [02:11<00:21, 277.39batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  85%|▊| 34966/40960 [02:11<00:21, 277.39batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35024/40960 [02:11<00:21, 279.59batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35024/40960 [02:11<00:21, 279.59batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35072/40960 [02:11<00:22, 267.10batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35072/40960 [02:11<00:22, 267.10batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35125/40960 [02:11<00:21, 265.57batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35125/40960 [02:11<00:21, 265.57batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35174/40960 [02:11<00:22, 259.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35174/40960 [02:11<00:22, 259.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35223/40960 [02:12<00:22, 253.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35223/40960 [02:12<00:22, 253.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35273/40960 [02:12<00:22, 251.56batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35273/40960 [02:12<00:22, 251.56batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35322/40960 [02:12<00:22, 248.96batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35322/40960 [02:12<00:22, 248.96batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35370/40960 [02:12<00:22, 243.62batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35370/40960 [02:12<00:22, 243.62batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35419/40960 [02:12<00:22, 243.57batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  86%|▊| 35419/40960 [02:12<00:22, 243.57batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35471/40960 [02:13<00:22, 248.39batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35471/40960 [02:13<00:22, 248.39batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35522/40960 [02:13<00:21, 250.27batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35522/40960 [02:13<00:21, 250.27batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35568/40960 [02:13<00:22, 242.67batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35568/40960 [02:13<00:22, 242.67batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35619/40960 [02:13<00:21, 245.36batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35619/40960 [02:13<00:21, 245.36batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35675/40960 [02:13<00:20, 254.64batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35675/40960 [02:13<00:20, 254.64batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35725/40960 [02:14<00:20, 252.34batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35725/40960 [02:14<00:20, 252.34batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35780/40960 [02:14<00:20, 257.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35780/40960 [02:14<00:20, 257.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35832/40960 [02:14<00:19, 258.06batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  87%|▊| 35832/40960 [02:14<00:19, 258.06batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 35878/40960 [02:14<00:20, 249.33batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 35878/40960 [02:14<00:20, 249.33batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 35926/40960 [02:14<00:20, 245.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 35926/40960 [02:14<00:20, 245.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 35978/40960 [02:15<00:20, 248.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 35978/40960 [02:15<00:20, 248.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36030/40960 [02:15<00:19, 249.73batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36030/40960 [02:15<00:19, 249.73batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36079/40960 [02:15<00:19, 247.74batches/s, l2_loss: 0.0676 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|▉| 36079/40960 [02:15<00:19, 247.74batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36133/40960 [02:15<00:18, 254.07batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36133/40960 [02:15<00:18, 254.07batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36172/40960 [02:15<00:20, 236.26batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36172/40960 [02:15<00:20, 236.26batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36221/40960 [02:16<00:19, 238.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  88%|▉| 36221/40960 [02:16<00:19, 238.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36274/40960 [02:16<00:19, 245.89batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36274/40960 [02:16<00:19, 245.89batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36327/40960 [02:16<00:18, 251.23batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36327/40960 [02:16<00:18, 251.23batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36375/40960 [02:16<00:18, 247.43batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36375/40960 [02:16<00:18, 247.43batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36425/40960 [02:16<00:18, 246.42batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36425/40960 [02:16<00:18, 246.42batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36473/40960 [02:17<00:18, 244.27batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36473/40960 [02:17<00:18, 244.27batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36534/40960 [02:17<00:16, 262.30batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36534/40960 [02:17<00:16, 262.30batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36590/40960 [02:17<00:16, 266.48batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36590/40960 [02:17<00:16, 266.48batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36644/40960 [02:17<00:16, 266.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  89%|▉| 36644/40960 [02:17<00:16, 266.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36703/40960 [02:17<00:15, 274.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36703/40960 [02:17<00:15, 274.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36763/40960 [02:18<00:14, 280.98batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36763/40960 [02:18<00:14, 280.98batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36815/40960 [02:18<00:15, 274.04batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36815/40960 [02:18<00:15, 274.04batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36874/40960 [02:18<00:14, 280.24batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36874/40960 [02:18<00:14, 280.24batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36928/40960 [02:18<00:14, 275.68batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36928/40960 [02:18<00:14, 275.68batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36986/40960 [02:19<00:14, 279.93batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 36986/40960 [02:19<00:14, 279.93batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 37035/40960 [02:19<00:14, 269.29batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  90%|▉| 37035/40960 [02:19<00:14, 269.29batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37089/40960 [02:19<00:14, 268.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37089/40960 [02:19<00:14, 268.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37135/40960 [02:19<00:14, 256.78batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37135/40960 [02:19<00:14, 256.78batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37181/40960 [02:19<00:15, 247.07batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37181/40960 [02:19<00:15, 247.07batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37238/40960 [02:20<00:14, 257.60batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37238/40960 [02:20<00:14, 257.60batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37299/40960 [02:20<00:13, 271.29batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37299/40960 [02:20<00:13, 271.29batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37352/40960 [02:20<00:13, 267.97batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37352/40960 [02:20<00:13, 267.97batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37412/40960 [02:20<00:12, 277.43batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37412/40960 [02:20<00:12, 277.43batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37462/40960 [02:20<00:13, 268.26batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  91%|▉| 37462/40960 [02:20<00:13, 268.26batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37518/40960 [02:21<00:12, 271.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37518/40960 [02:21<00:12, 271.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37577/40960 [02:21<00:12, 278.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37577/40960 [02:21<00:12, 278.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37630/40960 [02:21<00:12, 274.03batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37630/40960 [02:21<00:12, 274.03batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37684/40960 [02:21<00:12, 269.98batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37684/40960 [02:21<00:12, 269.98batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37745/40960 [02:21<00:11, 279.26batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37745/40960 [02:21<00:11, 279.26batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  92%|▉| 37804/40960 [02:22<00:11, 282.29batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  92%|▉| 37804/40960 [02:22<00:11, 282.29batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37862/40960 [02:22<00:10, 283.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  92%|▉| 37862/40960 [02:22<00:10, 283.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 37919/40960 [02:22<00:10, 283.70batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 37919/40960 [02:22<00:10, 283.70batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 37971/40960 [02:22<00:10, 274.86batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 37971/40960 [02:22<00:10, 274.86batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38023/40960 [02:22<00:10, 270.03batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38023/40960 [02:22<00:10, 270.03batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38077/40960 [02:23<00:10, 269.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38077/40960 [02:23<00:10, 269.49batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38136/40960 [02:23<00:10, 276.01batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38136/40960 [02:23<00:10, 276.01batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38194/40960 [02:23<00:09, 280.11batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38194/40960 [02:23<00:09, 280.11batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38250/40960 [02:23<00:09, 279.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38250/40960 [02:23<00:09, 279.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38290/40960 [02:23<00:10, 254.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  93%|▉| 38290/40960 [02:23<00:10, 254.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38339/40960 [02:24<00:10, 250.65batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38339/40960 [02:24<00:10, 250.65batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38393/40960 [02:24<00:10, 256.40batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38393/40960 [02:24<00:10, 256.40batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38451/40960 [02:24<00:09, 265.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38451/40960 [02:24<00:09, 265.16batches/s, l2_loss: 0.0676 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|▉| 38505/40960 [02:24<00:09, 265.44batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38505/40960 [02:24<00:09, 265.44batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38563/40960 [02:24<00:08, 271.55batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38563/40960 [02:24<00:08, 271.55batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38617/40960 [02:25<00:08, 270.35batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  94%|▉| 38617/40960 [02:25<00:08, 270.35batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  94%|▉| 38674/40960 [02:25<00:08, 273.21batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  94%|▉| 38674/40960 [02:25<00:08, 273.21batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 38730/40960 [02:25<00:08, 274.15batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 38730/40960 [02:25<00:08, 274.15batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 38779/40960 [02:25<00:08, 264.99batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 38779/40960 [02:25<00:08, 264.99batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 38836/40960 [02:25<00:07, 269.81batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 38836/40960 [02:25<00:07, 269.81batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  95%|▉| 38893/40960 [02:26<00:07, 273.59batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  95%|▉| 38893/40960 [02:26<00:07, 273.59batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 38952/40960 [02:26<00:07, 279.40batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 38952/40960 [02:26<00:07, 279.40batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 39012/40960 [02:26<00:06, 285.34batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 39012/40960 [02:26<00:06, 285.34batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 39071/40960 [02:26<00:06, 287.96batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  95%|▉| 39071/40960 [02:26<00:06, 287.96batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39127/40960 [02:26<00:06, 285.21batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39127/40960 [02:26<00:06, 285.21batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39171/40960 [02:27<00:06, 264.31batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39171/40960 [02:27<00:06, 264.31batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39221/40960 [02:27<00:06, 258.75batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39221/40960 [02:27<00:06, 258.75batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39272/40960 [02:27<00:06, 257.35batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39272/40960 [02:27<00:06, 257.35batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39331/40960 [02:27<00:06, 267.79batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39331/40960 [02:27<00:06, 267.79batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39392/40960 [02:27<00:05, 278.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39392/40960 [02:27<00:05, 278.63batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39454/40960 [02:28<00:05, 286.31batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39454/40960 [02:28<00:05, 286.31batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39509/40960 [02:28<00:05, 282.81batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  96%|▉| 39509/40960 [02:28<00:05, 282.81batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39570/40960 [02:28<00:04, 289.36batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39570/40960 [02:28<00:04, 289.36batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39626/40960 [02:28<00:04, 286.10batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39626/40960 [02:28<00:04, 286.10batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39679/40960 [02:28<00:04, 278.13batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39679/40960 [02:28<00:04, 278.13batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39739/40960 [02:29<00:04, 283.29batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39739/40960 [02:29<00:04, 283.29batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  97%|▉| 39798/40960 [02:29<00:04, 285.96batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  97%|▉| 39798/40960 [02:29<00:04, 285.96batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39854/40960 [02:29<00:03, 282.50batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39854/40960 [02:29<00:03, 282.50batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39890/40960 [02:29<00:04, 251.87batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  97%|▉| 39890/40960 [02:29<00:04, 251.87batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 39948/40960 [02:29<00:03, 261.90batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 39948/40960 [02:29<00:03, 261.90batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 39992/40960 [02:30<00:03, 248.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 39992/40960 [02:30<00:03, 248.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40039/40960 [02:30<00:03, 244.26batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40039/40960 [02:30<00:03, 244.26batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40097/40960 [02:30<00:03, 257.10batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40097/40960 [02:30<00:03, 257.10batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40156/40960 [02:30<00:02, 268.36batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40156/40960 [02:30<00:02, 268.36batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40215/40960 [02:30<00:02, 276.17batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40215/40960 [02:30<00:02, 276.17batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40275/40960 [02:31<00:02, 282.59batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40275/40960 [02:31<00:02, 282.59batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40326/40960 [02:31<00:02, 274.18batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  98%|▉| 40326/40960 [02:31<00:02, 274.18batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40379/40960 [02:31<00:02, 270.22batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40379/40960 [02:31<00:02, 270.22batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  99%|▉| 40439/40960 [02:31<00:01, 278.95batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  99%|▉| 40439/40960 [02:31<00:01, 278.95batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40497/40960 [02:31<00:01, 281.27batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40497/40960 [02:31<00:01, 281.27batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40556/40960 [02:32<00:01, 284.22batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40556/40960 [02:32<00:01, 284.22batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40616/40960 [02:32<00:01, 288.83batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40616/40960 [02:32<00:01, 288.83batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  99%|▉| 40675/40960 [02:32<00:00, 289.43batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  99%|▉| 40675/40960 [02:32<00:00, 289.43batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40735/40960 [02:32<00:00, 291.20batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  99%|▉| 40735/40960 [02:32<00:00, 291.20batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training: 100%|▉| 40794/40960 [02:32<00:00, 291.80batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training: 100%|▉| 40794/40960 [02:32<00:00, 291.80batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training: 100%|▉| 40847/40960 [02:33<00:00, 281.76batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training: 100%|▉| 40847/40960 [02:33<00:00, 281.76batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training: 100%|▉| 40897/40960 [02:33<00:00, 271.21batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training: 100%|▉| 40897/40960 [02:33<00:00, 271.21batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training: 100%|▉| 40952/40960 [02:33<00:00, 269.08batches/s, l2_loss: 0.0676 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|▉| 40952/40960 [02:33<00:00, 269.08batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:28:40.311293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  73%|▋| 19/26 [41:02<17:13, 147.60s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:28:43.549124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:28:46.150527: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:00<10:17:27,  1.11batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<10:17:27,  1.11batches/s, l2_loss: 0.0670 - round_loss:\u001b[A\n",
      "Training:   0%| | 97/40960 [00:01<05:52, 116.04batches/s, l2_loss: 0.0670 - round_loss: \u001b[A\n",
      "Training:   0%| | 97/40960 [00:01<05:52, 116.04batches/s, l2_loss: 0.0799 - round_loss: \u001b[A\n",
      "Training:   0%| | 193/40960 [00:01<03:15, 208.46batches/s, l2_loss: 0.0799 - round_loss:\u001b[A\n",
      "Training:   0%| | 193/40960 [00:01<03:15, 208.46batches/s, l2_loss: 0.0795 - round_loss:\u001b[A\n",
      "Training:   1%| | 287/40960 [00:01<02:26, 278.16batches/s, l2_loss: 0.0795 - round_loss:\u001b[A\n",
      "Training:   1%| | 287/40960 [00:01<02:26, 278.16batches/s, l2_loss: 0.0757 - round_loss:\u001b[A\n",
      "Training:   1%| | 382/40960 [00:01<02:02, 331.94batches/s, l2_loss: 0.0757 - round_loss:\u001b[A\n",
      "Training:   1%| | 382/40960 [00:01<02:02, 331.94batches/s, l2_loss: 0.0754 - round_loss:\u001b[A\n",
      "Training:   1%| | 476/40960 [00:01<01:49, 370.40batches/s, l2_loss: 0.0754 - round_loss:\u001b[A\n",
      "Training:   1%| | 476/40960 [00:01<01:49, 370.40batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   1%| | 571/40960 [00:02<01:40, 399.90batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   1%| | 571/40960 [00:02<01:40, 399.90batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   2%| | 666/40960 [00:02<01:35, 421.67batches/s, l2_loss: 0.0759 - round_loss:\u001b[A\n",
      "Training:   2%| | 666/40960 [00:02<01:35, 421.67batches/s, l2_loss: 0.0750 - round_loss:\u001b[A\n",
      "Training:   2%| | 758/40960 [00:02<01:32, 432.67batches/s, l2_loss: 0.0750 - round_loss:\u001b[A\n",
      "Training:   2%| | 758/40960 [00:02<01:32, 432.67batches/s, l2_loss: 0.0742 - round_loss:\u001b[A\n",
      "Training:   2%| | 851/40960 [00:02<01:30, 441.01batches/s, l2_loss: 0.0742 - round_loss:\u001b[A\n",
      "Training:   2%| | 851/40960 [00:02<01:30, 441.01batches/s, l2_loss: 0.0754 - round_loss:\u001b[A\n",
      "Training:   2%| | 945/40960 [00:02<01:29, 448.63batches/s, l2_loss: 0.0754 - round_loss:\u001b[A\n",
      "Training:   2%| | 945/40960 [00:02<01:29, 448.63batches/s, l2_loss: 0.0747 - round_loss:\u001b[A\n",
      "Training:   3%| | 1038/40960 [00:03<01:28, 452.20batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:   3%| | 1038/40960 [00:03<01:28, 452.20batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   3%| | 1131/40960 [00:03<01:27, 454.92batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   3%| | 1131/40960 [00:03<01:27, 454.92batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   3%| | 1225/40960 [00:03<01:26, 459.09batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:   3%| | 1225/40960 [00:03<01:26, 459.09batches/s, l2_loss: 0.0749 - round_loss\u001b[A\n",
      "Training:   3%| | 1319/40960 [00:03<01:25, 462.26batches/s, l2_loss: 0.0749 - round_loss\u001b[A\n",
      "Training:   3%| | 1319/40960 [00:03<01:25, 462.26batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   3%| | 1414/40960 [00:03<01:24, 465.88batches/s, l2_loss: 0.0746 - round_loss\u001b[A\n",
      "Training:   3%| | 1414/40960 [00:03<01:24, 465.88batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:   4%| | 1509/40960 [00:04<01:24, 467.34batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:   4%| | 1509/40960 [00:04<01:24, 467.34batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:   4%| | 1604/40960 [00:04<01:23, 469.43batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:   4%| | 1604/40960 [00:04<01:23, 469.43batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   4%| | 1696/40960 [00:04<01:24, 465.82batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   4%| | 1696/40960 [00:04<01:24, 465.82batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   4%| | 1789/40960 [00:04<01:24, 464.83batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   4%| | 1789/40960 [00:04<01:24, 464.83batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   5%| | 1884/40960 [00:04<01:23, 466.51batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   5%| | 1884/40960 [00:04<01:23, 466.51batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   5%| | 1977/40960 [00:05<01:23, 465.67batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   5%| | 1977/40960 [00:05<01:23, 465.67batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   5%| | 2071/40960 [00:05<01:23, 466.24batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   5%| | 2071/40960 [00:05<01:23, 466.24batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   5%| | 2166/40960 [00:05<01:22, 467.94batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   5%| | 2166/40960 [00:05<01:22, 467.94batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   6%| | 2259/40960 [00:05<01:22, 466.50batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:   6%| | 2259/40960 [00:05<01:22, 466.50batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   6%| | 2349/40960 [00:05<01:23, 460.71batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   6%| | 2349/40960 [00:05<01:23, 460.71batches/s, l2_loss: 0.0741 - round_loss\u001b[A\n",
      "Training:   6%| | 2442/40960 [00:06<01:23, 460.85batches/s, l2_loss: 0.0741 - round_loss\u001b[A\n",
      "Training:   6%| | 2442/40960 [00:06<01:23, 460.85batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   6%| | 2537/40960 [00:06<01:22, 463.53batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:   6%| | 2537/40960 [00:06<01:22, 463.53batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   6%| | 2631/40960 [00:06<01:22, 464.76batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:   6%| | 2631/40960 [00:06<01:22, 464.76batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   7%| | 2727/40960 [00:06<01:21, 468.05batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:   7%| | 2727/40960 [00:06<01:21, 468.05batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   7%| | 2823/40960 [00:06<01:20, 470.86batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   7%| | 2823/40960 [00:06<01:20, 470.86batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   7%| | 2916/40960 [00:07<01:21, 467.90batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:   7%| | 2916/40960 [00:07<01:21, 467.90batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:   7%| | 3012/40960 [00:07<01:20, 470.76batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:   7%| | 3012/40960 [00:07<01:20, 470.76batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   8%| | 3106/40960 [00:07<01:20, 469.32batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   8%| | 3106/40960 [00:07<01:20, 469.32batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   8%| | 3200/40960 [00:07<01:20, 468.73batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:   8%| | 3200/40960 [00:07<01:20, 468.73batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   8%| | 3290/40960 [00:07<01:21, 462.06batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   8%| | 3290/40960 [00:07<01:21, 462.06batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   8%| | 3383/40960 [00:08<01:21, 462.22batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   8%| | 3383/40960 [00:08<01:21, 462.22batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:   8%| | 3474/40960 [00:08<01:21, 459.35batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3474/40960 [00:08<01:21, 459.35batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   9%| | 3568/40960 [00:08<01:21, 461.11batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   9%| | 3568/40960 [00:08<01:21, 461.11batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   9%| | 3661/40960 [00:08<01:20, 461.36batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   9%| | 3661/40960 [00:08<01:20, 461.36batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   9%| | 3756/40960 [00:08<01:20, 464.60batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:   9%| | 3756/40960 [00:08<01:20, 464.60batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   9%| | 3851/40960 [00:09<01:19, 466.49batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:   9%| | 3851/40960 [00:09<01:19, 466.49batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  10%| | 3945/40960 [00:09<01:19, 466.35batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  10%| | 3945/40960 [00:09<01:19, 466.35batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  10%| | 4039/40960 [00:09<01:19, 466.28batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  10%| | 4039/40960 [00:09<01:19, 466.28batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  10%| | 4132/40960 [00:09<01:19, 465.47batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  10%| | 4132/40960 [00:09<01:19, 465.47batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  10%| | 4225/40960 [00:09<01:18, 465.07batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  10%| | 4225/40960 [00:09<01:18, 465.07batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  11%| | 4317/40960 [00:10<01:19, 463.51batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  11%| | 4317/40960 [00:10<01:19, 463.51batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  11%| | 4410/40960 [00:10<01:19, 462.32batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  11%| | 4410/40960 [00:10<01:19, 462.32batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  11%| | 4505/40960 [00:10<01:18, 465.49batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  11%| | 4505/40960 [00:10<01:18, 465.49batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  11%| | 4600/40960 [00:10<01:17, 467.26batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  11%| | 4600/40960 [00:10<01:17, 467.26batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  11%| | 4695/40960 [00:10<01:17, 468.32batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  11%| | 4695/40960 [00:10<01:17, 468.32batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  12%| | 4789/40960 [00:11<01:17, 468.73batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  12%| | 4789/40960 [00:11<01:17, 468.73batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  12%| | 4885/40960 [00:11<01:16, 471.98batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  12%| | 4885/40960 [00:11<01:16, 471.98batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 4978/40960 [00:11<01:16, 469.44batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 4978/40960 [00:11<01:16, 469.44batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 5071/40960 [00:11<01:16, 466.87batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  12%| | 5071/40960 [00:11<01:16, 466.87batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5168/40960 [00:11<01:15, 471.42batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5168/40960 [00:11<01:15, 471.42batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5264/40960 [00:12<01:15, 472.72batches/s, l2_loss: 0.0725 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5264/40960 [00:12<01:15, 472.72batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5360/40960 [00:12<01:15, 474.09batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5360/40960 [00:12<01:15, 474.09batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5454/40960 [00:12<01:15, 472.27batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5454/40960 [00:12<01:15, 472.27batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5549/40960 [00:12<01:14, 472.55batches/s, l2_loss: 0.0723 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5549/40960 [00:12<01:14, 472.55batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5643/40960 [00:12<01:15, 470.86batches/s, l2_loss: 0.0722 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5643/40960 [00:12<01:15, 470.86batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5737/40960 [00:13<01:15, 469.63batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5737/40960 [00:13<01:15, 469.63batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5831/40960 [00:13<01:14, 469.15batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5831/40960 [00:13<01:14, 469.15batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5924/40960 [00:13<01:14, 467.86batches/s, l2_loss: 0.0721 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5924/40960 [00:13<01:14, 467.86batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6020/40960 [00:13<01:14, 470.76batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6020/40960 [00:13<01:14, 470.76batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6112/40960 [00:13<01:14, 466.91batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6112/40960 [00:13<01:14, 466.91batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6207/40960 [00:14<01:14, 467.91batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6207/40960 [00:14<01:14, 467.91batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6302/40960 [00:14<01:13, 468.83batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6302/40960 [00:14<01:13, 468.83batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6396/40960 [00:14<01:13, 468.15batches/s, l2_loss: 0.0720 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6396/40960 [00:14<01:13, 468.15batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6490/40960 [00:14<01:13, 467.92batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6490/40960 [00:14<01:13, 467.92batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6583/40960 [00:14<01:13, 466.45batches/s, l2_loss: 0.0719 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6583/40960 [00:14<01:13, 466.45batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6677/40960 [00:15<01:13, 467.02batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6677/40960 [00:15<01:13, 467.02batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6771/40960 [00:15<01:13, 467.38batches/s, l2_loss: 0.0718 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6771/40960 [00:15<01:13, 467.38batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6865/40960 [00:15<01:13, 467.04batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6865/40960 [00:15<01:13, 467.04batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6959/40960 [00:15<01:12, 467.87batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6959/40960 [00:15<01:12, 467.87batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7054/40960 [00:15<01:12, 468.97batches/s, l2_loss: 0.0717 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7054/40960 [00:15<01:12, 468.97batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7148/40960 [00:16<01:12, 468.12batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7148/40960 [00:16<01:12, 468.12batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7241/40960 [00:16<01:12, 465.87batches/s, l2_loss: 0.0716 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7241/40960 [00:16<01:12, 465.87batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7334/40960 [00:16<01:12, 464.15batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7334/40960 [00:16<01:12, 464.15batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7426/40960 [00:16<01:12, 461.65batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7426/40960 [00:16<01:12, 461.65batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7520/40960 [00:16<01:12, 463.36batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7520/40960 [00:17<01:12, 463.36batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7614/40960 [00:17<01:11, 464.93batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7614/40960 [00:17<01:11, 464.93batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|▏| 7709/40960 [00:17<01:11, 467.33batches/s, l2_loss: 0.0715 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7709/40960 [00:17<01:11, 467.33batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7802/40960 [00:17<01:11, 465.82batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7802/40960 [00:17<01:11, 465.82batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7896/40960 [00:17<01:10, 465.86batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7896/40960 [00:17<01:10, 465.86batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7988/40960 [00:18<01:11, 463.38batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7988/40960 [00:18<01:11, 463.38batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8082/40960 [00:18<01:10, 464.76batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8082/40960 [00:18<01:10, 464.76batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8177/40960 [00:18<01:10, 466.75batches/s, l2_loss: 0.0714 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8177/40960 [00:18<01:10, 466.75batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8259/40960 [00:18<01:12, 449.23batches/s, l2_loss: 0.0713 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8259/40960 [00:18<01:12, 449.23batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8341/40960 [00:18<01:14, 437.31batches/s, l2_loss: 0.0724 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8341/40960 [00:18<01:14, 437.31batches/s, l2_loss: 0.0670 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8425/40960 [00:19<01:15, 431.13batches/s, l2_loss: 0.0670 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8425/40960 [00:19<01:15, 431.13batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8507/40960 [00:19<01:16, 424.20batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8507/40960 [00:19<01:16, 424.20batches/s, l2_loss: 0.0695 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8591/40960 [00:19<01:16, 422.20batches/s, l2_loss: 0.0695 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8591/40960 [00:19<01:16, 422.20batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8676/40960 [00:19<01:16, 421.65batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8676/40960 [00:19<01:16, 421.65batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8755/40960 [00:19<01:17, 413.35batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8755/40960 [00:19<01:17, 413.35batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8839/40960 [00:20<01:17, 415.07batches/s, l2_loss: 0.0689 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8839/40960 [00:20<01:17, 415.07batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8922/40960 [00:20<01:17, 414.98batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8922/40960 [00:20<01:17, 414.98batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9007/40960 [00:20<01:16, 417.95batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9007/40960 [00:20<01:16, 417.95batches/s, l2_loss: 0.0674 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9088/40960 [00:20<01:17, 413.10batches/s, l2_loss: 0.0674 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9088/40960 [00:20<01:17, 413.10batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9172/40960 [00:20<01:16, 413.99batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9172/40960 [00:20<01:16, 413.99batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9259/40960 [00:21<01:15, 419.88batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9259/40960 [00:21<01:15, 419.88batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9345/40960 [00:21<01:14, 422.14batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9345/40960 [00:21<01:14, 422.14batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9429/40960 [00:21<01:15, 420.39batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9429/40960 [00:21<01:15, 420.39batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9512/40960 [00:21<01:15, 417.62batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9512/40960 [00:21<01:15, 417.62batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9596/40960 [00:21<01:15, 417.34batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9596/40960 [00:21<01:15, 417.34batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9680/40960 [00:22<01:14, 417.52batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9680/40960 [00:22<01:14, 417.52batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9764/40960 [00:22<01:14, 418.11batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9764/40960 [00:22<01:14, 418.11batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9847/40960 [00:22<01:14, 415.83batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9847/40960 [00:22<01:14, 415.83batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9932/40960 [00:22<01:14, 418.05batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9932/40960 [00:22<01:14, 418.05batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10014/40960 [00:22<01:14, 414.05batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  24%|▏| 10014/40960 [00:22<01:14, 414.05batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  25%|▏| 10099/40960 [00:23<01:14, 416.45batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  25%|▏| 10099/40960 [00:23<01:14, 416.45batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  25%|▏| 10183/40960 [00:23<01:13, 416.81batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  25%|▏| 10183/40960 [00:23<01:13, 416.81batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  25%|▎| 10268/40960 [00:23<01:13, 418.15batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  25%|▎| 10268/40960 [00:23<01:13, 418.15batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  25%|▎| 10352/40960 [00:23<01:13, 417.52batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  25%|▎| 10352/40960 [00:23<01:13, 417.52batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  25%|▎| 10436/40960 [00:23<01:13, 417.61batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  25%|▎| 10436/40960 [00:23<01:13, 417.61batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  26%|▎| 10521/40960 [00:24<01:12, 419.08batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  26%|▎| 10521/40960 [00:24<01:12, 419.08batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  26%|▎| 10603/40960 [00:24<01:12, 416.09batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  26%|▎| 10603/40960 [00:24<01:12, 416.09batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  26%|▎| 10687/40960 [00:24<01:12, 416.76batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  26%|▎| 10687/40960 [00:24<01:12, 416.76batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  26%|▎| 10772/40960 [00:24<01:12, 418.02batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  26%|▎| 10772/40960 [00:24<01:12, 418.02batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  27%|▎| 10855/40960 [00:24<01:12, 416.32batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  27%|▎| 10855/40960 [00:24<01:12, 416.32batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  27%|▎| 10942/40960 [00:25<01:11, 420.61batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  27%|▎| 10942/40960 [00:25<01:11, 420.61batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  27%|▎| 11028/40960 [00:25<01:10, 422.30batches/s, l2_loss: 0.0679 - round_los\u001b[A\n",
      "Training:  27%|▎| 11028/40960 [00:25<01:10, 422.30batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  27%|▎| 11111/40960 [00:25<01:11, 419.22batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  27%|▎| 11111/40960 [00:25<01:11, 419.22batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  27%|▎| 11196/40960 [00:25<01:10, 420.84batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  27%|▎| 11196/40960 [00:25<01:10, 420.84batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  28%|▎| 11280/40960 [00:25<01:10, 420.38batches/s, l2_loss: 0.0677 - round_los\u001b[A\n",
      "Training:  28%|▎| 11280/40960 [00:25<01:10, 420.38batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  28%|▎| 11366/40960 [00:26<01:09, 422.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  28%|▎| 11366/40960 [00:26<01:09, 422.88batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  28%|▎| 11452/40960 [00:26<01:09, 424.06batches/s, l2_loss: 0.0675 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|▎| 11452/40960 [00:26<01:09, 424.06batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  28%|▎| 11536/40960 [00:26<01:09, 421.67batches/s, l2_loss: 0.0678 - round_los\u001b[A\n",
      "Training:  28%|▎| 11536/40960 [00:26<01:09, 421.67batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  28%|▎| 11621/40960 [00:26<01:09, 422.56batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  28%|▎| 11621/40960 [00:26<01:09, 422.56batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 11704/40960 [00:26<01:09, 419.72batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 11704/40960 [00:26<01:09, 419.72batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  29%|▎| 11790/40960 [00:27<01:09, 422.48batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  29%|▎| 11790/40960 [00:27<01:09, 422.48batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 11873/40960 [00:27<01:09, 419.90batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 11873/40960 [00:27<01:09, 419.90batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  29%|▎| 11958/40960 [00:27<01:08, 420.88batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  29%|▎| 11958/40960 [00:27<01:08, 420.88batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 12043/40960 [00:27<01:08, 421.19batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  29%|▎| 12043/40960 [00:27<01:08, 421.19batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  30%|▎| 12128/40960 [00:27<01:08, 420.71batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  30%|▎| 12128/40960 [00:27<01:08, 420.71batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  30%|▎| 12215/40960 [00:28<01:07, 424.00batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  30%|▎| 12215/40960 [00:28<01:07, 424.00batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  30%|▎| 12300/40960 [00:28<01:07, 423.51batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  30%|▎| 12300/40960 [00:28<01:07, 423.51batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  30%|▎| 12386/40960 [00:28<01:07, 424.06batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  30%|▎| 12386/40960 [00:28<01:07, 424.06batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  30%|▎| 12469/40960 [00:28<01:07, 420.80batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  30%|▎| 12469/40960 [00:28<01:07, 420.80batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  31%|▎| 12552/40960 [00:28<01:07, 418.53batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  31%|▎| 12552/40960 [00:28<01:07, 418.53batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  31%|▎| 12636/40960 [00:29<01:07, 418.12batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  31%|▎| 12636/40960 [00:29<01:07, 418.12batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  31%|▎| 12719/40960 [00:29<01:07, 416.26batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  31%|▎| 12719/40960 [00:29<01:07, 416.26batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  31%|▎| 12800/40960 [00:29<01:08, 412.32batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  31%|▎| 12800/40960 [00:29<01:08, 412.32batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  31%|▎| 12886/40960 [00:29<01:07, 416.75batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  31%|▎| 12886/40960 [00:29<01:07, 416.75batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 12971/40960 [00:29<01:06, 418.69batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 12971/40960 [00:29<01:06, 418.69batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13056/40960 [00:30<01:06, 419.92batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13056/40960 [00:30<01:06, 419.92batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  32%|▎| 13140/40960 [00:30<01:06, 418.79batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  32%|▎| 13140/40960 [00:30<01:06, 418.79batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13224/40960 [00:30<01:06, 417.86batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  32%|▎| 13224/40960 [00:30<01:06, 417.86batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  32%|▎| 13307/40960 [00:30<01:06, 416.77batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  32%|▎| 13307/40960 [00:30<01:06, 416.77batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  33%|▎| 13390/40960 [00:30<01:06, 415.04batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  33%|▎| 13390/40960 [00:30<01:06, 415.04batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  33%|▎| 13476/40960 [00:31<01:05, 418.80batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  33%|▎| 13476/40960 [00:31<01:05, 418.80batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  33%|▎| 13560/40960 [00:31<01:05, 418.86batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  33%|▎| 13560/40960 [00:31<01:05, 418.86batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  33%|▎| 13642/40960 [00:31<01:05, 414.82batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  33%|▎| 13642/40960 [00:31<01:05, 414.82batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  34%|▎| 13724/40960 [00:31<01:06, 411.71batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  34%|▎| 13724/40960 [00:31<01:06, 411.71batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  34%|▎| 13807/40960 [00:31<01:06, 411.40batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  34%|▎| 13807/40960 [00:31<01:06, 411.40batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  34%|▎| 13889/40960 [00:32<01:06, 409.78batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  34%|▎| 13889/40960 [00:32<01:06, 409.78batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  34%|▎| 13968/40960 [00:32<01:06, 404.70batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  34%|▎| 13968/40960 [00:32<01:06, 404.70batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  34%|▎| 14050/40960 [00:32<01:06, 406.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  34%|▎| 14050/40960 [00:32<01:06, 406.07batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  35%|▎| 14135/40960 [00:32<01:05, 411.46batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  35%|▎| 14135/40960 [00:32<01:05, 411.46batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  35%|▎| 14220/40960 [00:32<01:04, 415.23batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  35%|▎| 14220/40960 [00:32<01:04, 415.23batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  35%|▎| 14303/40960 [00:33<01:04, 414.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  35%|▎| 14303/40960 [00:33<01:04, 414.07batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  35%|▎| 14389/40960 [00:33<01:03, 417.48batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  35%|▎| 14389/40960 [00:33<01:03, 417.48batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  35%|▎| 14474/40960 [00:33<01:03, 419.71batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  35%|▎| 14474/40960 [00:33<01:03, 419.71batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  36%|▎| 14559/40960 [00:33<01:02, 420.98batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  36%|▎| 14559/40960 [00:33<01:02, 420.98batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  36%|▎| 14644/40960 [00:33<01:02, 421.28batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  36%|▎| 14644/40960 [00:33<01:02, 421.28batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  36%|▎| 14729/40960 [00:34<01:02, 421.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  36%|▎| 14729/40960 [00:34<01:02, 421.25batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  36%|▎| 14807/40960 [00:34<01:03, 411.37batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  36%|▎| 14807/40960 [00:34<01:03, 411.37batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  36%|▎| 14888/40960 [00:34<01:03, 408.97batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  36%|▎| 14888/40960 [00:34<01:03, 408.97batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  37%|▎| 14975/40960 [00:34<01:02, 416.32batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  37%|▎| 14975/40960 [00:34<01:02, 416.32batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  37%|▎| 15062/40960 [00:34<01:01, 421.14batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  37%|▎| 15062/40960 [00:34<01:01, 421.14batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  37%|▎| 15147/40960 [00:35<01:01, 421.41batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  37%|▎| 15147/40960 [00:35<01:01, 421.41batches/s, l2_loss: 0.0671 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15231/40960 [00:35<01:01, 420.14batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  37%|▎| 15231/40960 [00:35<01:01, 420.14batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  37%|▎| 15319/40960 [00:35<01:00, 426.02batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  37%|▎| 15319/40960 [00:35<01:00, 426.02batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  38%|▍| 15403/40960 [00:35<01:00, 423.12batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  38%|▍| 15403/40960 [00:35<01:00, 423.12batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  38%|▍| 15487/40960 [00:35<01:00, 421.77batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  38%|▍| 15487/40960 [00:35<01:00, 421.77batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  38%|▍| 15570/40960 [00:36<01:00, 418.42batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  38%|▍| 15570/40960 [00:36<01:00, 418.42batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  38%|▍| 15657/40960 [00:36<00:59, 422.88batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  38%|▍| 15657/40960 [00:36<00:59, 422.88batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  38%|▍| 15743/40960 [00:36<00:59, 424.73batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  38%|▍| 15743/40960 [00:36<00:59, 424.73batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  39%|▍| 15825/40960 [00:36<00:59, 420.28batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  39%|▍| 15825/40960 [00:36<00:59, 420.28batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  39%|▍| 15909/40960 [00:36<00:59, 419.44batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  39%|▍| 15909/40960 [00:36<00:59, 419.44batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  39%|▍| 15994/40960 [00:37<00:59, 420.32batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  39%|▍| 15994/40960 [00:37<00:59, 420.32batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  39%|▍| 16079/40960 [00:37<00:59, 420.36batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  39%|▍| 16079/40960 [00:37<00:59, 420.36batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  39%|▍| 16162/40960 [00:37<00:59, 417.98batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  39%|▍| 16162/40960 [00:37<00:59, 417.98batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  40%|▍| 16245/40960 [00:37<00:59, 415.92batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  40%|▍| 16245/40960 [00:37<00:59, 415.92batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  40%|▍| 16329/40960 [00:37<00:59, 415.92batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  40%|▍| 16329/40960 [00:37<00:59, 415.92batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  40%|▍| 16414/40960 [00:38<00:58, 418.22batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  40%|▍| 16414/40960 [00:38<00:58, 418.22batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  40%|▍| 16497/40960 [00:38<00:58, 415.62batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  40%|▍| 16497/40960 [00:38<00:58, 415.62batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  40%|▍| 16574/40960 [00:38<01:00, 404.87batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  40%|▍| 16574/40960 [00:38<01:00, 404.87batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16660/40960 [00:38<00:59, 411.16batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16660/40960 [00:38<00:59, 411.16batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16743/40960 [00:38<00:58, 412.13batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16743/40960 [00:38<00:58, 412.13batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16826/40960 [00:39<00:58, 411.85batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16826/40960 [00:39<00:58, 411.85batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16908/40960 [00:39<00:58, 410.55batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16908/40960 [00:39<00:58, 410.55batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16991/40960 [00:39<00:58, 410.90batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  41%|▍| 16991/40960 [00:39<00:58, 410.90batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  42%|▍| 17076/40960 [00:39<00:57, 414.86batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  42%|▍| 17076/40960 [00:39<00:57, 414.86batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  42%|▍| 17161/40960 [00:39<00:57, 417.26batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  42%|▍| 17161/40960 [00:39<00:57, 417.26batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  42%|▍| 17244/40960 [00:40<00:57, 415.23batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  42%|▍| 17244/40960 [00:40<00:57, 415.23batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  42%|▍| 17328/40960 [00:40<00:56, 415.45batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  42%|▍| 17328/40960 [00:40<00:56, 415.45batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  43%|▍| 17414/40960 [00:40<00:56, 418.69batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  43%|▍| 17414/40960 [00:40<00:56, 418.69batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  43%|▍| 17499/40960 [00:40<00:55, 420.21batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  43%|▍| 17499/40960 [00:40<00:55, 420.21batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  43%|▍| 17583/40960 [00:40<00:55, 419.33batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  43%|▍| 17583/40960 [00:40<00:55, 419.33batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  43%|▍| 17666/40960 [00:41<00:55, 416.87batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  43%|▍| 17666/40960 [00:41<00:55, 416.87batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  43%|▍| 17750/40960 [00:41<00:55, 416.61batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  43%|▍| 17750/40960 [00:41<00:55, 416.61batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 17834/40960 [00:41<00:55, 416.53batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 17834/40960 [00:41<00:55, 416.53batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 17918/40960 [00:41<00:55, 416.92batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 17918/40960 [00:41<00:55, 416.92batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 18004/40960 [00:41<00:54, 419.78batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 18004/40960 [00:41<00:54, 419.78batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 18087/40960 [00:42<00:54, 418.00batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 18087/40960 [00:42<00:54, 418.00batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 18168/40960 [00:42<00:55, 413.82batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  44%|▍| 18168/40960 [00:42<00:55, 413.82batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  45%|▍| 18252/40960 [00:42<00:54, 415.01batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  45%|▍| 18252/40960 [00:42<00:54, 415.01batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  45%|▍| 18335/40960 [00:42<00:54, 414.29batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  45%|▍| 18335/40960 [00:42<00:54, 414.29batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  45%|▍| 18421/40960 [00:42<00:53, 418.27batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  45%|▍| 18421/40960 [00:42<00:53, 418.27batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  45%|▍| 18504/40960 [00:43<00:53, 416.10batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  45%|▍| 18504/40960 [00:43<00:53, 416.10batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  45%|▍| 18590/40960 [00:43<00:53, 418.97batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  45%|▍| 18590/40960 [00:43<00:53, 418.97batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  46%|▍| 18676/40960 [00:43<00:52, 421.40batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  46%|▍| 18676/40960 [00:43<00:52, 421.40batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  46%|▍| 18762/40960 [00:43<00:52, 423.72batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  46%|▍| 18762/40960 [00:43<00:52, 423.72batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  46%|▍| 18847/40960 [00:43<00:52, 422.98batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  46%|▍| 18847/40960 [00:43<00:52, 422.98batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  46%|▍| 18933/40960 [00:44<00:51, 424.57batches/s, l2_loss: 0.0668 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|▍| 18933/40960 [00:44<00:51, 424.57batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  46%|▍| 19017/40960 [00:44<00:51, 423.06batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  46%|▍| 19017/40960 [00:44<00:51, 423.06batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  47%|▍| 19101/40960 [00:44<00:51, 421.00batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  47%|▍| 19101/40960 [00:44<00:51, 421.00batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  47%|▍| 19186/40960 [00:44<00:51, 421.00batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  47%|▍| 19186/40960 [00:44<00:51, 421.00batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  47%|▍| 19271/40960 [00:44<00:51, 421.02batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  47%|▍| 19271/40960 [00:44<00:51, 421.02batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  47%|▍| 19355/40960 [00:45<00:51, 420.69batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  47%|▍| 19355/40960 [00:45<00:51, 420.69batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  47%|▍| 19441/40960 [00:45<00:50, 422.25batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  47%|▍| 19441/40960 [00:45<00:50, 422.25batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  48%|▍| 19527/40960 [00:45<00:50, 424.39batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  48%|▍| 19527/40960 [00:45<00:50, 424.39batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  48%|▍| 19612/40960 [00:45<00:50, 423.16batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  48%|▍| 19612/40960 [00:45<00:50, 423.16batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  48%|▍| 19695/40960 [00:45<00:50, 419.73batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  48%|▍| 19695/40960 [00:45<00:50, 419.73batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  48%|▍| 19780/40960 [00:46<00:50, 421.22batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  48%|▍| 19780/40960 [00:46<00:50, 421.22batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  48%|▍| 19865/40960 [00:46<00:50, 421.20batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  48%|▍| 19865/40960 [00:46<00:50, 421.20batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  49%|▍| 19949/40960 [00:46<00:50, 419.47batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  49%|▍| 19949/40960 [00:46<00:50, 419.47batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  49%|▍| 20036/40960 [00:46<00:49, 422.75batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  49%|▍| 20036/40960 [00:46<00:49, 422.75batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  49%|▍| 20122/40960 [00:46<00:49, 424.75batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  49%|▍| 20122/40960 [00:46<00:49, 424.75batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  49%|▍| 20206/40960 [00:47<00:49, 423.06batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  49%|▍| 20206/40960 [00:47<00:49, 423.06batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  50%|▍| 20285/40960 [00:47<00:49, 413.51batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  50%|▍| 20285/40960 [00:47<00:49, 413.51batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  50%|▍| 20369/40960 [00:47<00:49, 415.15batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  50%|▍| 20369/40960 [00:47<00:49, 415.15batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  50%|▍| 20451/40960 [00:47<00:49, 413.61batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  50%|▍| 20451/40960 [00:47<00:49, 413.61batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  50%|▌| 20533/40960 [00:47<00:49, 411.45batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  50%|▌| 20533/40960 [00:47<00:49, 411.45batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  50%|▌| 20618/40960 [00:48<00:49, 414.24batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  50%|▌| 20618/40960 [00:48<00:49, 414.24batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  51%|▌| 20699/40960 [00:48<00:49, 411.39batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  51%|▌| 20699/40960 [00:48<00:49, 411.39batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  51%|▌| 20781/40960 [00:48<00:49, 410.41batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  51%|▌| 20781/40960 [00:48<00:49, 410.41batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  51%|▌| 20863/40960 [00:48<00:49, 409.32batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  51%|▌| 20863/40960 [00:48<00:49, 409.32batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  51%|▌| 20948/40960 [00:48<00:48, 413.05batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  51%|▌| 20948/40960 [00:49<00:48, 413.05batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  51%|▌| 21032/40960 [00:49<00:48, 414.34batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  51%|▌| 21032/40960 [00:49<00:48, 414.34batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  52%|▌| 21116/40960 [00:49<00:47, 415.44batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  52%|▌| 21116/40960 [00:49<00:47, 415.44batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  52%|▌| 21203/40960 [00:49<00:46, 420.95batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  52%|▌| 21203/40960 [00:49<00:46, 420.95batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  52%|▌| 21287/40960 [00:49<00:46, 419.52batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  52%|▌| 21287/40960 [00:49<00:46, 419.52batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  52%|▌| 21368/40960 [00:50<00:47, 414.67batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  52%|▌| 21368/40960 [00:50<00:47, 414.67batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  52%|▌| 21453/40960 [00:50<00:46, 417.69batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  52%|▌| 21453/40960 [00:50<00:46, 417.69batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21534/40960 [00:50<00:46, 413.53batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21534/40960 [00:50<00:46, 413.53batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21615/40960 [00:50<00:47, 410.80batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21615/40960 [00:50<00:47, 410.80batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21696/40960 [00:50<00:47, 408.64batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21696/40960 [00:50<00:47, 408.64batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21780/40960 [00:51<00:46, 411.25batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21780/40960 [00:51<00:46, 411.25batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21863/40960 [00:51<00:46, 411.12batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  53%|▌| 21863/40960 [00:51<00:46, 411.12batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  54%|▌| 21945/40960 [00:51<00:46, 410.41batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  54%|▌| 21945/40960 [00:51<00:46, 410.41batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  54%|▌| 22026/40960 [00:51<00:46, 408.42batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  54%|▌| 22026/40960 [00:51<00:46, 408.42batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  54%|▌| 22111/40960 [00:51<00:45, 411.79batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  54%|▌| 22111/40960 [00:51<00:45, 411.79batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  54%|▌| 22194/40960 [00:52<00:45, 412.46batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  54%|▌| 22194/40960 [00:52<00:45, 412.46batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  54%|▌| 22280/40960 [00:52<00:44, 416.73batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  54%|▌| 22280/40960 [00:52<00:44, 416.73batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  55%|▌| 22361/40960 [00:52<00:45, 412.19batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  55%|▌| 22361/40960 [00:52<00:45, 412.19batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  55%|▌| 22446/40960 [00:52<00:44, 415.07batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  55%|▌| 22446/40960 [00:52<00:44, 415.07batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  55%|▌| 22527/40960 [00:52<00:44, 411.38batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  55%|▌| 22527/40960 [00:52<00:44, 411.38batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  55%|▌| 22608/40960 [00:53<00:44, 408.56batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  55%|▌| 22608/40960 [00:53<00:44, 408.56batches/s, l2_loss: 0.0665 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22689/40960 [00:53<00:44, 406.20batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [00:53<00:44, 406.20batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 22775/40960 [00:53<00:44, 412.08batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 22775/40960 [00:53<00:44, 412.08batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 22855/40960 [00:53<00:44, 407.64batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 22855/40960 [00:53<00:44, 407.64batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 22939/40960 [00:53<00:44, 408.61batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 22939/40960 [00:53<00:44, 408.61batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 23023/40960 [00:54<00:43, 411.50batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 23023/40960 [00:54<00:43, 411.50batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 23106/40960 [00:54<00:43, 411.70batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  56%|▌| 23106/40960 [00:54<00:43, 411.70batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  57%|▌| 23191/40960 [00:54<00:42, 414.77batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  57%|▌| 23191/40960 [00:54<00:42, 414.77batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  57%|▌| 23275/40960 [00:54<00:42, 414.94batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  57%|▌| 23275/40960 [00:54<00:42, 414.94batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  57%|▌| 23360/40960 [00:54<00:42, 417.09batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  57%|▌| 23360/40960 [00:54<00:42, 417.09batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  57%|▌| 23447/40960 [00:55<00:41, 421.79batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  57%|▌| 23447/40960 [00:55<00:41, 421.79batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  57%|▌| 23533/40960 [00:55<00:41, 424.19batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  57%|▌| 23533/40960 [00:55<00:41, 424.19batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  58%|▌| 23621/40960 [00:55<00:40, 427.43batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  58%|▌| 23621/40960 [00:55<00:40, 427.43batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  58%|▌| 23706/40960 [00:55<00:40, 425.16batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  58%|▌| 23706/40960 [00:55<00:40, 425.16batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  58%|▌| 23790/40960 [00:55<00:40, 423.31batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  58%|▌| 23790/40960 [00:55<00:40, 423.31batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  58%|▌| 23868/40960 [00:56<00:41, 413.05batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  58%|▌| 23868/40960 [00:56<00:41, 413.05batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  58%|▌| 23953/40960 [00:56<00:40, 415.86batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  58%|▌| 23953/40960 [00:56<00:40, 415.86batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24038/40960 [00:56<00:40, 417.18batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24038/40960 [00:56<00:40, 417.18batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24122/40960 [00:56<00:40, 416.66batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24122/40960 [00:56<00:40, 416.66batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24204/40960 [00:56<00:40, 414.54batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24204/40960 [00:56<00:40, 414.54batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24287/40960 [00:57<00:40, 414.20batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24287/40960 [00:57<00:40, 414.20batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24370/40960 [00:57<00:40, 414.07batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  59%|▌| 24370/40960 [00:57<00:40, 414.07batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  60%|▌| 24456/40960 [00:57<00:39, 417.94batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  60%|▌| 24456/40960 [00:57<00:39, 417.94batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  60%|▌| 24540/40960 [00:57<00:39, 418.54batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  60%|▌| 24540/40960 [00:57<00:39, 418.54batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  60%|▌| 24623/40960 [00:57<00:39, 416.82batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  60%|▌| 24623/40960 [00:57<00:39, 416.82batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  60%|▌| 24704/40960 [00:58<00:39, 413.19batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  60%|▌| 24704/40960 [00:58<00:39, 413.19batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 24788/40960 [00:58<00:39, 414.15batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 24788/40960 [00:58<00:39, 414.15batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 24871/40960 [00:58<00:38, 414.07batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 24871/40960 [00:58<00:38, 414.07batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 24956/40960 [00:58<00:38, 416.82batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 24956/40960 [00:58<00:38, 416.82batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 25040/40960 [00:58<00:38, 416.92batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 25040/40960 [00:58<00:38, 416.92batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 25123/40960 [00:59<00:38, 415.88batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  61%|▌| 25123/40960 [00:59<00:38, 415.88batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  62%|▌| 25203/40960 [00:59<00:38, 410.57batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  62%|▌| 25203/40960 [00:59<00:38, 410.57batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  62%|▌| 25286/40960 [00:59<00:38, 411.75batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  62%|▌| 25286/40960 [00:59<00:38, 411.75batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  62%|▌| 25371/40960 [00:59<00:37, 414.99batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  62%|▌| 25371/40960 [00:59<00:37, 414.99batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  62%|▌| 25451/40960 [00:59<00:37, 410.12batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  62%|▌| 25451/40960 [00:59<00:37, 410.12batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  62%|▌| 25536/40960 [01:00<00:37, 414.52batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  62%|▌| 25536/40960 [01:00<00:37, 414.52batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  63%|▋| 25622/40960 [01:00<00:36, 417.68batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  63%|▋| 25622/40960 [01:00<00:36, 417.68batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  63%|▋| 25708/40960 [01:00<00:36, 421.16batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  63%|▋| 25708/40960 [01:00<00:36, 421.16batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  63%|▋| 25792/40960 [01:00<00:36, 420.29batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  63%|▋| 25792/40960 [01:00<00:36, 420.29batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  63%|▋| 25876/40960 [01:00<00:35, 419.05batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  63%|▋| 25876/40960 [01:00<00:35, 419.05batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  63%|▋| 25961/40960 [01:01<00:35, 419.64batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  63%|▋| 25961/40960 [01:01<00:35, 419.64batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26048/40960 [01:01<00:35, 423.75batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26048/40960 [01:01<00:35, 423.75batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26134/40960 [01:01<00:34, 424.78batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26134/40960 [01:01<00:34, 424.78batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26216/40960 [01:01<00:35, 419.62batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26216/40960 [01:01<00:35, 419.62batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26303/40960 [01:01<00:34, 423.04batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26303/40960 [01:01<00:34, 423.04batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  64%|▋| 26387/40960 [01:02<00:34, 421.83batches/s, l2_loss: 0.0663 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|▋| 26387/40960 [01:02<00:34, 421.83batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26473/40960 [01:02<00:34, 424.14batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26473/40960 [01:02<00:34, 424.14batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26555/40960 [01:02<00:34, 418.92batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26555/40960 [01:02<00:34, 418.92batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26637/40960 [01:02<00:34, 416.18batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26637/40960 [01:02<00:34, 416.18batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26719/40960 [01:02<00:34, 413.41batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26719/40960 [01:02<00:34, 413.41batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26802/40960 [01:03<00:34, 412.76batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  65%|▋| 26802/40960 [01:03<00:34, 412.76batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 26888/40960 [01:03<00:33, 417.17batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 26888/40960 [01:03<00:33, 417.17batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 26974/40960 [01:03<00:33, 419.93batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 26974/40960 [01:03<00:33, 419.93batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 27057/40960 [01:03<00:33, 417.98batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 27057/40960 [01:03<00:33, 417.98batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 27140/40960 [01:03<00:33, 416.13batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 27140/40960 [01:03<00:33, 416.13batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 27226/40960 [01:04<00:32, 419.88batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  66%|▋| 27226/40960 [01:04<00:32, 419.88batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  67%|▋| 27312/40960 [01:04<00:32, 422.06batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  67%|▋| 27312/40960 [01:04<00:32, 422.06batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  67%|▋| 27397/40960 [01:04<00:32, 422.68batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  67%|▋| 27397/40960 [01:04<00:32, 422.68batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  67%|▋| 27481/40960 [01:04<00:31, 421.70batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  67%|▋| 27481/40960 [01:04<00:31, 421.70batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  67%|▋| 27565/40960 [01:04<00:31, 419.72batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  67%|▋| 27565/40960 [01:04<00:31, 419.72batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27651/40960 [01:05<00:31, 421.52batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27651/40960 [01:05<00:31, 421.52batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27731/40960 [01:05<00:31, 414.42batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27731/40960 [01:05<00:31, 414.42batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27815/40960 [01:05<00:31, 415.72batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27815/40960 [01:05<00:31, 415.72batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27898/40960 [01:05<00:31, 414.35batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27898/40960 [01:05<00:31, 414.35batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27982/40960 [01:05<00:31, 415.06batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  68%|▋| 27982/40960 [01:05<00:31, 415.06batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28064/40960 [01:06<00:31, 413.50batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28064/40960 [01:06<00:31, 413.50batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28148/40960 [01:06<00:30, 414.95batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28148/40960 [01:06<00:30, 414.95batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28232/40960 [01:06<00:30, 415.05batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28232/40960 [01:06<00:30, 415.05batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28318/40960 [01:06<00:30, 418.52batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28318/40960 [01:06<00:30, 418.52batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28405/40960 [01:06<00:29, 422.02batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  69%|▋| 28405/40960 [01:06<00:29, 422.02batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28492/40960 [01:07<00:29, 425.41batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28492/40960 [01:07<00:29, 425.41batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28576/40960 [01:07<00:29, 423.35batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28576/40960 [01:07<00:29, 423.35batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28659/40960 [01:07<00:29, 420.11batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28659/40960 [01:07<00:29, 420.11batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28738/40960 [01:07<00:29, 411.11batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28738/40960 [01:07<00:29, 411.11batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28821/40960 [01:07<00:29, 411.29batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  70%|▋| 28821/40960 [01:07<00:29, 411.29batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 28907/40960 [01:08<00:28, 415.93batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 28907/40960 [01:08<00:28, 415.93batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 28992/40960 [01:08<00:28, 418.59batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 28992/40960 [01:08<00:28, 418.59batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 29072/40960 [01:08<00:28, 411.31batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 29072/40960 [01:08<00:28, 411.31batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 29156/40960 [01:08<00:28, 412.75batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 29156/40960 [01:08<00:28, 412.75batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 29241/40960 [01:08<00:28, 416.08batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  71%|▋| 29241/40960 [01:08<00:28, 416.08batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  72%|▋| 29324/40960 [01:09<00:28, 414.77batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  72%|▋| 29324/40960 [01:09<00:28, 414.77batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  72%|▋| 29408/40960 [01:09<00:27, 416.20batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  72%|▋| 29408/40960 [01:09<00:27, 416.20batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  72%|▋| 29492/40960 [01:09<00:27, 416.18batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  72%|▋| 29492/40960 [01:09<00:27, 416.18batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  72%|▋| 29576/40960 [01:09<00:27, 416.71batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  72%|▋| 29576/40960 [01:09<00:27, 416.71batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  72%|▋| 29661/40960 [01:09<00:26, 418.84batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  72%|▋| 29661/40960 [01:09<00:26, 418.84batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  73%|▋| 29747/40960 [01:10<00:26, 420.95batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  73%|▋| 29747/40960 [01:10<00:26, 420.95batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  73%|▋| 29830/40960 [01:10<00:26, 418.25batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  73%|▋| 29830/40960 [01:10<00:26, 418.25batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  73%|▋| 29917/40960 [01:10<00:26, 422.81batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  73%|▋| 29917/40960 [01:10<00:26, 422.81batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  73%|▋| 30001/40960 [01:10<00:26, 421.30batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  73%|▋| 30001/40960 [01:10<00:26, 421.30batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  73%|▋| 30085/40960 [01:10<00:25, 420.02batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  73%|▋| 30085/40960 [01:10<00:25, 420.02batches/s, l2_loss: 0.0661 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|▋| 30169/40960 [01:11<00:25, 418.82batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30169/40960 [01:11<00:25, 418.82batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30253/40960 [01:11<00:25, 418.43batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30253/40960 [01:11<00:25, 418.43batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30337/40960 [01:11<00:25, 418.03batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30337/40960 [01:11<00:25, 418.03batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30421/40960 [01:11<00:25, 418.37batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30421/40960 [01:11<00:25, 418.37batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30503/40960 [01:11<00:25, 414.86batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  74%|▋| 30503/40960 [01:11<00:25, 414.86batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▋| 30585/40960 [01:12<00:25, 412.74batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▋| 30585/40960 [01:12<00:25, 412.74batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▋| 30670/40960 [01:12<00:24, 415.78batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▋| 30670/40960 [01:12<00:24, 415.78batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▊| 30754/40960 [01:12<00:24, 415.65batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▊| 30754/40960 [01:12<00:24, 415.65batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▊| 30838/40960 [01:12<00:24, 416.95batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▊| 30838/40960 [01:12<00:24, 416.95batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▊| 30923/40960 [01:12<00:23, 418.55batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  75%|▊| 30923/40960 [01:12<00:23, 418.55batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  76%|▊| 31006/40960 [01:13<00:23, 416.51batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  76%|▊| 31006/40960 [01:13<00:23, 416.51batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  76%|▊| 31088/40960 [01:13<00:23, 414.52batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  76%|▊| 31088/40960 [01:13<00:23, 414.52batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  76%|▊| 31170/40960 [01:13<00:23, 413.07batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  76%|▊| 31170/40960 [01:13<00:23, 413.07batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  76%|▊| 31254/40960 [01:13<00:23, 413.67batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  76%|▊| 31254/40960 [01:13<00:23, 413.67batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31338/40960 [01:13<00:23, 414.74batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31338/40960 [01:13<00:23, 414.74batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31422/40960 [01:14<00:22, 415.79batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31422/40960 [01:14<00:22, 415.79batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31507/40960 [01:14<00:22, 417.92batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31507/40960 [01:14<00:22, 417.92batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31590/40960 [01:14<00:22, 416.89batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31590/40960 [01:14<00:22, 416.89batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31668/40960 [01:14<00:22, 408.28batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  77%|▊| 31668/40960 [01:14<00:22, 408.28batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  78%|▊| 31751/40960 [01:14<00:22, 410.10batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  78%|▊| 31751/40960 [01:14<00:22, 410.10batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  78%|▊| 31836/40960 [01:15<00:22, 413.23batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  78%|▊| 31836/40960 [01:15<00:22, 413.23batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  78%|▊| 31921/40960 [01:15<00:21, 416.61batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  78%|▊| 31921/40960 [01:15<00:21, 416.61batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  78%|▊| 32004/40960 [01:15<00:21, 415.78batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  78%|▊| 32004/40960 [01:15<00:21, 415.78batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  78%|▊| 32090/40960 [01:15<00:21, 419.67batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  78%|▊| 32090/40960 [01:15<00:21, 419.67batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  79%|▊| 32176/40960 [01:15<00:20, 421.86batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  79%|▊| 32176/40960 [01:15<00:20, 421.86batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  79%|▊| 32257/40960 [01:16<00:20, 415.89batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  79%|▊| 32257/40960 [01:16<00:20, 415.89batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  79%|▊| 32343/40960 [01:16<00:20, 419.02batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  79%|▊| 32343/40960 [01:16<00:20, 419.02batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  79%|▊| 32429/40960 [01:16<00:20, 421.81batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  79%|▊| 32429/40960 [01:16<00:20, 421.81batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  79%|▊| 32511/40960 [01:16<00:20, 417.86batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  79%|▊| 32511/40960 [01:16<00:20, 417.86batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  80%|▊| 32593/40960 [01:16<00:20, 415.23batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  80%|▊| 32593/40960 [01:16<00:20, 415.23batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  80%|▊| 32676/40960 [01:17<00:19, 414.81batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  80%|▊| 32676/40960 [01:17<00:19, 414.81batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  80%|▊| 32759/40960 [01:17<00:19, 413.63batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  80%|▊| 32759/40960 [01:17<00:19, 413.63batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  80%|▊| 32838/40960 [01:17<00:19, 407.08batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  80%|▊| 32838/40960 [01:17<00:19, 407.08batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  80%|▊| 32916/40960 [01:17<00:20, 400.55batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  80%|▊| 32916/40960 [01:17<00:20, 400.55batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  81%|▊| 32995/40960 [01:17<00:20, 397.67batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  81%|▊| 32995/40960 [01:17<00:20, 397.67batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  81%|▊| 33079/40960 [01:18<00:19, 403.76batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  81%|▊| 33079/40960 [01:18<00:19, 403.76batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  81%|▊| 33160/40960 [01:18<00:19, 403.72batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  81%|▊| 33160/40960 [01:18<00:19, 403.72batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  81%|▊| 33243/40960 [01:18<00:18, 406.56batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  81%|▊| 33243/40960 [01:18<00:18, 406.56batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  81%|▊| 33327/40960 [01:18<00:18, 409.50batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  81%|▊| 33327/40960 [01:18<00:18, 409.50batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33409/40960 [01:18<00:18, 409.52batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33409/40960 [01:18<00:18, 409.52batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33493/40960 [01:19<00:18, 411.63batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33493/40960 [01:19<00:18, 411.63batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33576/40960 [01:19<00:17, 411.78batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33576/40960 [01:19<00:17, 411.78batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33660/40960 [01:19<00:17, 413.12batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33660/40960 [01:19<00:17, 413.12batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33746/40960 [01:19<00:17, 417.71batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  82%|▊| 33746/40960 [01:19<00:17, 417.71batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 33826/40960 [01:19<00:17, 411.55batches/s, l2_loss: 0.0660 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 33826/40960 [01:19<00:17, 411.55batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 33908/40960 [01:20<00:17, 410.22batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 33908/40960 [01:20<00:17, 410.22batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 33992/40960 [01:20<00:16, 412.37batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 33992/40960 [01:20<00:16, 412.37batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 34075/40960 [01:20<00:16, 411.76batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 34075/40960 [01:20<00:16, 411.76batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 34156/40960 [01:20<00:16, 408.77batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  83%|▊| 34156/40960 [01:20<00:16, 408.77batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34240/40960 [01:20<00:16, 411.23batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34240/40960 [01:20<00:16, 411.23batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34322/40960 [01:21<00:16, 409.38batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34322/40960 [01:21<00:16, 409.38batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34407/40960 [01:21<00:15, 413.53batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34407/40960 [01:21<00:15, 413.53batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34492/40960 [01:21<00:15, 415.75batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34492/40960 [01:21<00:15, 415.75batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34576/40960 [01:21<00:15, 416.15batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  84%|▊| 34576/40960 [01:21<00:15, 416.15batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34660/40960 [01:21<00:15, 416.53batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34660/40960 [01:22<00:15, 416.53batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34743/40960 [01:22<00:14, 415.20batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34743/40960 [01:22<00:14, 415.20batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34829/40960 [01:22<00:14, 419.49batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34829/40960 [01:22<00:14, 419.49batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34910/40960 [01:22<00:14, 413.99batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34910/40960 [01:22<00:14, 413.99batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34993/40960 [01:22<00:14, 414.13batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  85%|▊| 34993/40960 [01:22<00:14, 414.13batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35078/40960 [01:23<00:14, 417.33batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35078/40960 [01:23<00:14, 417.33batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35163/40960 [01:23<00:13, 418.69batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35163/40960 [01:23<00:13, 418.69batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35245/40960 [01:23<00:13, 415.33batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35245/40960 [01:23<00:13, 415.33batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35329/40960 [01:23<00:13, 415.87batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35329/40960 [01:23<00:13, 415.87batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35412/40960 [01:23<00:13, 414.65batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35412/40960 [01:23<00:13, 414.65batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  87%|▊| 35496/40960 [01:24<00:13, 415.18batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  87%|▊| 35496/40960 [01:24<00:13, 415.18batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [01:24<00:12, 417.21batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  87%|▊| 35581/40960 [01:24<00:12, 417.21batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  87%|▊| 35668/40960 [01:24<00:12, 421.31batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  87%|▊| 35668/40960 [01:24<00:12, 421.31batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35752/40960 [01:24<00:12, 420.09batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35752/40960 [01:24<00:12, 420.09batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  87%|▊| 35832/40960 [01:24<00:12, 413.52batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  87%|▊| 35832/40960 [01:24<00:12, 413.52batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  88%|▉| 35913/40960 [01:25<00:12, 410.27batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  88%|▉| 35913/40960 [01:25<00:12, 410.27batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  88%|▉| 35995/40960 [01:25<00:12, 409.08batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  88%|▉| 35995/40960 [01:25<00:12, 409.08batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  88%|▉| 36080/40960 [01:25<00:11, 412.56batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  88%|▉| 36080/40960 [01:25<00:11, 412.56batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  88%|▉| 36161/40960 [01:25<00:11, 409.07batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  88%|▉| 36161/40960 [01:25<00:11, 409.07batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  88%|▉| 36244/40960 [01:25<00:11, 409.40batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  88%|▉| 36244/40960 [01:25<00:11, 409.40batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  89%|▉| 36329/40960 [01:26<00:11, 413.24batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  89%|▉| 36329/40960 [01:26<00:11, 413.24batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  89%|▉| 36412/40960 [01:26<00:10, 413.64batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  89%|▉| 36412/40960 [01:26<00:10, 413.64batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  89%|▉| 36497/40960 [01:26<00:10, 416.04batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  89%|▉| 36497/40960 [01:26<00:10, 416.04batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  89%|▉| 36580/40960 [01:26<00:10, 414.65batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  89%|▉| 36580/40960 [01:26<00:10, 414.65batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36664/40960 [01:26<00:10, 416.08batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36664/40960 [01:26<00:10, 416.08batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36746/40960 [01:27<00:10, 413.94batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36746/40960 [01:27<00:10, 413.94batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36827/40960 [01:27<00:10, 410.12batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36827/40960 [01:27<00:10, 410.12batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36910/40960 [01:27<00:09, 410.53batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36910/40960 [01:27<00:09, 410.53batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36993/40960 [01:27<00:09, 411.73batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  90%|▉| 36993/40960 [01:27<00:09, 411.73batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37075/40960 [01:27<00:09, 410.55batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37075/40960 [01:27<00:09, 410.55batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37158/40960 [01:28<00:09, 411.35batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37158/40960 [01:28<00:09, 411.35batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37240/40960 [01:28<00:09, 410.64batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37240/40960 [01:28<00:09, 410.64batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37324/40960 [01:28<00:08, 413.34batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37324/40960 [01:28<00:08, 413.34batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37411/40960 [01:28<00:08, 418.83batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  91%|▉| 37411/40960 [01:28<00:08, 418.83batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37493/40960 [01:28<00:08, 415.21batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37493/40960 [01:28<00:08, 415.21batches/s, l2_loss: 0.0659 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37572/40960 [01:29<00:08, 408.96batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37572/40960 [01:29<00:08, 408.96batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37654/40960 [01:29<00:08, 407.87batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37654/40960 [01:29<00:08, 407.87batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37733/40960 [01:29<00:08, 402.97batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37733/40960 [01:29<00:08, 402.97batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37813/40960 [01:29<00:07, 401.72batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  92%|▉| 37813/40960 [01:29<00:07, 401.72batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 37897/40960 [01:29<00:07, 406.35batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 37897/40960 [01:29<00:07, 406.35batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 37981/40960 [01:30<00:07, 409.85batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 37981/40960 [01:30<00:07, 409.85batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38061/40960 [01:30<00:07, 405.66batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38061/40960 [01:30<00:07, 405.66batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38147/40960 [01:30<00:06, 412.48batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38147/40960 [01:30<00:06, 412.48batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38232/40960 [01:30<00:06, 415.11batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  93%|▉| 38232/40960 [01:30<00:06, 415.11batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38313/40960 [01:30<00:06, 411.76batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38313/40960 [01:30<00:06, 411.76batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38396/40960 [01:31<00:06, 412.12batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38396/40960 [01:31<00:06, 412.12batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38480/40960 [01:31<00:05, 413.57batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38480/40960 [01:31<00:05, 413.57batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38561/40960 [01:31<00:05, 410.58batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38561/40960 [01:31<00:05, 410.58batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38645/40960 [01:31<00:05, 412.06batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  94%|▉| 38645/40960 [01:31<00:05, 412.06batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 38727/40960 [01:31<00:05, 411.01batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 38727/40960 [01:31<00:05, 411.01batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 38811/40960 [01:32<00:05, 412.72batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 38811/40960 [01:32<00:05, 412.72batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 38893/40960 [01:32<00:05, 411.65batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 38893/40960 [01:32<00:05, 411.65batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 38976/40960 [01:32<00:04, 412.58batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 38976/40960 [01:32<00:04, 412.58batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 39061/40960 [01:32<00:04, 415.79batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  95%|▉| 39061/40960 [01:32<00:04, 415.79batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  96%|▉| 39142/40960 [01:32<00:04, 411.57batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  96%|▉| 39142/40960 [01:32<00:04, 411.57batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  96%|▉| 39225/40960 [01:33<00:04, 411.61batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  96%|▉| 39225/40960 [01:33<00:04, 411.61batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  96%|▉| 39310/40960 [01:33<00:03, 414.41batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  96%|▉| 39310/40960 [01:33<00:03, 414.41batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  96%|▉| 39394/40960 [01:33<00:03, 414.96batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  96%|▉| 39394/40960 [01:33<00:03, 414.96batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  96%|▉| 39478/40960 [01:33<00:03, 415.90batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  96%|▉| 39478/40960 [01:33<00:03, 415.90batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  97%|▉| 39562/40960 [01:33<00:03, 416.83batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  97%|▉| 39562/40960 [01:33<00:03, 416.83batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  97%|▉| 39645/40960 [01:34<00:03, 416.22batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  97%|▉| 39645/40960 [01:34<00:03, 416.22batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  97%|▉| 39726/40960 [01:34<00:02, 412.78batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  97%|▉| 39726/40960 [01:34<00:02, 412.78batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  97%|▉| 39811/40960 [01:34<00:02, 415.35batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  97%|▉| 39811/40960 [01:34<00:02, 415.35batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  97%|▉| 39895/40960 [01:34<00:02, 416.44batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  97%|▉| 39895/40960 [01:34<00:02, 416.44batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  98%|▉| 39981/40960 [01:34<00:02, 419.39batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  98%|▉| 39981/40960 [01:34<00:02, 419.39batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  98%|▉| 40067/40960 [01:35<00:02, 421.40batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  98%|▉| 40067/40960 [01:35<00:02, 421.40batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  98%|▉| 40151/40960 [01:35<00:01, 419.86batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  98%|▉| 40151/40960 [01:35<00:01, 419.86batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  98%|▉| 40236/40960 [01:35<00:01, 421.00batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  98%|▉| 40236/40960 [01:35<00:01, 421.00batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  98%|▉| 40316/40960 [01:35<00:01, 414.48batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  98%|▉| 40316/40960 [01:35<00:01, 414.48batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40394/40960 [01:35<00:01, 406.36batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40394/40960 [01:35<00:01, 406.36batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40478/40960 [01:36<00:01, 410.35batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40478/40960 [01:36<00:01, 410.35batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40563/40960 [01:36<00:00, 414.32batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40563/40960 [01:36<00:00, 414.32batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40646/40960 [01:36<00:00, 414.21batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40646/40960 [01:36<00:00, 414.21batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40732/40960 [01:36<00:00, 418.14batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  99%|▉| 40732/40960 [01:36<00:00, 418.14batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training: 100%|▉| 40813/40960 [01:36<00:00, 413.47batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training: 100%|▉| 40813/40960 [01:36<00:00, 413.47batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training: 100%|▉| 40893/40960 [01:37<00:00, 408.46batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training: 100%|▉| 40893/40960 [01:37<00:00, 408.46batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:30:22.879997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  77%|▊| 20/26 [42:42<13:20, 133.48s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:30:24.121391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:30:27.997705: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<14:34:45,  1.28s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<14:34:45,  1.28s/batches, l2_loss: 0.0814 - round_loss:\u001b[A\n",
      "Training:   0%| | 57/40960 [00:01<13:13, 51.52batches/s, l2_loss: 0.0814 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 57/40960 [00:01<13:13, 51.52batches/s, l2_loss: 0.0900 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 110/40960 [00:01<07:08, 95.24batches/s, l2_loss: 0.0900 - round_loss: \u001b[A\n",
      "Training:   0%| | 110/40960 [00:01<07:08, 95.24batches/s, l2_loss: 0.0947 - round_loss: \u001b[A\n",
      "Training:   0%| | 187/40960 [00:01<04:13, 160.73batches/s, l2_loss: 0.0947 - round_loss:\u001b[A\n",
      "Training:   0%| | 187/40960 [00:01<04:13, 160.73batches/s, l2_loss: 0.0935 - round_loss:\u001b[A\n",
      "Training:   1%| | 265/40960 [00:02<03:08, 216.18batches/s, l2_loss: 0.0935 - round_loss:\u001b[A\n",
      "Training:   1%| | 265/40960 [00:02<03:08, 216.18batches/s, l2_loss: 0.0926 - round_loss:\u001b[A\n",
      "Training:   1%| | 343/40960 [00:02<02:35, 260.60batches/s, l2_loss: 0.0926 - round_loss:\u001b[A\n",
      "Training:   1%| | 343/40960 [00:02<02:35, 260.60batches/s, l2_loss: 0.0916 - round_loss:\u001b[A\n",
      "Training:   1%| | 420/40960 [00:02<02:18, 293.75batches/s, l2_loss: 0.0916 - round_loss:\u001b[A\n",
      "Training:   1%| | 420/40960 [00:02<02:18, 293.75batches/s, l2_loss: 0.0888 - round_loss:\u001b[A\n",
      "Training:   1%| | 501/40960 [00:02<02:04, 324.37batches/s, l2_loss: 0.0888 - round_loss:\u001b[A\n",
      "Training:   1%| | 501/40960 [00:02<02:04, 324.37batches/s, l2_loss: 0.0893 - round_loss:\u001b[A\n",
      "Training:   1%| | 582/40960 [00:02<01:56, 346.92batches/s, l2_loss: 0.0893 - round_loss:\u001b[A\n",
      "Training:   1%| | 582/40960 [00:02<01:56, 346.92batches/s, l2_loss: 0.0892 - round_loss:\u001b[A\n",
      "Training:   2%| | 662/40960 [00:03<01:51, 362.22batches/s, l2_loss: 0.0892 - round_loss:\u001b[A\n",
      "Training:   2%| | 662/40960 [00:03<01:51, 362.22batches/s, l2_loss: 0.0872 - round_loss:\u001b[A\n",
      "Training:   2%| | 739/40960 [00:03<01:49, 368.31batches/s, l2_loss: 0.0872 - round_loss:\u001b[A\n",
      "Training:   2%| | 739/40960 [00:03<01:49, 368.31batches/s, l2_loss: 0.0879 - round_loss:\u001b[A\n",
      "Training:   2%| | 818/40960 [00:03<01:46, 375.80batches/s, l2_loss: 0.0879 - round_loss:\u001b[A\n",
      "Training:   2%| | 818/40960 [00:03<01:46, 375.80batches/s, l2_loss: 0.0866 - round_loss:\u001b[A\n",
      "Training:   2%| | 898/40960 [00:03<01:44, 382.92batches/s, l2_loss: 0.0866 - round_loss:\u001b[A\n",
      "Training:   2%| | 898/40960 [00:03<01:44, 382.92batches/s, l2_loss: 0.0862 - round_loss:\u001b[A\n",
      "Training:   2%| | 979/40960 [00:03<01:42, 389.27batches/s, l2_loss: 0.0862 - round_loss:\u001b[A\n",
      "Training:   2%| | 979/40960 [00:03<01:42, 389.27batches/s, l2_loss: 0.0862 - round_loss:\u001b[A\n",
      "Training:   3%| | 1058/40960 [00:04<01:42, 389.55batches/s, l2_loss: 0.0862 - round_loss\u001b[A\n",
      "Training:   3%| | 1058/40960 [00:04<01:42, 389.55batches/s, l2_loss: 0.0847 - round_loss\u001b[A\n",
      "Training:   3%| | 1135/40960 [00:04<01:42, 387.57batches/s, l2_loss: 0.0847 - round_loss\u001b[A\n",
      "Training:   3%| | 1135/40960 [00:04<01:42, 387.57batches/s, l2_loss: 0.0843 - round_loss\u001b[A\n",
      "Training:   3%| | 1213/40960 [00:04<01:42, 387.03batches/s, l2_loss: 0.0843 - round_loss\u001b[A\n",
      "Training:   3%| | 1213/40960 [00:04<01:42, 387.03batches/s, l2_loss: 0.0840 - round_loss\u001b[A\n",
      "Training:   3%| | 1294/40960 [00:04<01:41, 391.44batches/s, l2_loss: 0.0840 - round_loss\u001b[A\n",
      "Training:   3%| | 1294/40960 [00:04<01:41, 391.44batches/s, l2_loss: 0.0842 - round_loss\u001b[A\n",
      "Training:   3%| | 1374/40960 [00:04<01:40, 392.87batches/s, l2_loss: 0.0842 - round_loss\u001b[A\n",
      "Training:   3%| | 1374/40960 [00:04<01:40, 392.87batches/s, l2_loss: 0.0842 - round_loss\u001b[A\n",
      "Training:   4%| | 1452/40960 [00:05<01:40, 392.00batches/s, l2_loss: 0.0842 - round_loss\u001b[A\n",
      "Training:   4%| | 1452/40960 [00:05<01:40, 392.00batches/s, l2_loss: 0.0841 - round_loss\u001b[A\n",
      "Training:   4%| | 1532/40960 [00:05<01:40, 393.21batches/s, l2_loss: 0.0841 - round_loss\u001b[A\n",
      "Training:   4%| | 1532/40960 [00:05<01:40, 393.21batches/s, l2_loss: 0.0830 - round_loss\u001b[A\n",
      "Training:   4%| | 1610/40960 [00:05<01:40, 391.93batches/s, l2_loss: 0.0830 - round_loss\u001b[A\n",
      "Training:   4%| | 1610/40960 [00:05<01:40, 391.93batches/s, l2_loss: 0.0834 - round_loss\u001b[A\n",
      "Training:   4%| | 1688/40960 [00:05<01:40, 390.29batches/s, l2_loss: 0.0834 - round_loss\u001b[A\n",
      "Training:   4%| | 1688/40960 [00:05<01:40, 390.29batches/s, l2_loss: 0.0826 - round_loss\u001b[A\n",
      "Training:   4%| | 1770/40960 [00:05<01:39, 394.97batches/s, l2_loss: 0.0826 - round_loss\u001b[A\n",
      "Training:   4%| | 1770/40960 [00:05<01:39, 394.97batches/s, l2_loss: 0.0823 - round_loss\u001b[A\n",
      "Training:   5%| | 1851/40960 [00:06<01:38, 397.93batches/s, l2_loss: 0.0823 - round_loss\u001b[A\n",
      "Training:   5%| | 1851/40960 [00:06<01:38, 397.93batches/s, l2_loss: 0.0819 - round_loss\u001b[A\n",
      "Training:   5%| | 1928/40960 [00:06<01:39, 393.19batches/s, l2_loss: 0.0819 - round_loss\u001b[A\n",
      "Training:   5%| | 1928/40960 [00:06<01:39, 393.19batches/s, l2_loss: 0.0817 - round_loss\u001b[A\n",
      "Training:   5%| | 2004/40960 [00:06<01:40, 388.12batches/s, l2_loss: 0.0817 - round_loss\u001b[A\n",
      "Training:   5%| | 2004/40960 [00:06<01:40, 388.12batches/s, l2_loss: 0.0814 - round_loss\u001b[A\n",
      "Training:   5%| | 2080/40960 [00:06<01:40, 385.63batches/s, l2_loss: 0.0814 - round_loss\u001b[A\n",
      "Training:   5%| | 2080/40960 [00:06<01:40, 385.63batches/s, l2_loss: 0.0814 - round_loss\u001b[A\n",
      "Training:   5%| | 2162/40960 [00:06<01:38, 391.99batches/s, l2_loss: 0.0814 - round_loss\u001b[A\n",
      "Training:   5%| | 2162/40960 [00:06<01:38, 391.99batches/s, l2_loss: 0.0811 - round_loss\u001b[A\n",
      "Training:   5%| | 2241/40960 [00:07<01:38, 392.62batches/s, l2_loss: 0.0811 - round_loss\u001b[A\n",
      "Training:   5%| | 2241/40960 [00:07<01:38, 392.62batches/s, l2_loss: 0.0807 - round_loss\u001b[A\n",
      "Training:   6%| | 2322/40960 [00:07<01:37, 395.69batches/s, l2_loss: 0.0807 - round_loss\u001b[A\n",
      "Training:   6%| | 2322/40960 [00:07<01:37, 395.69batches/s, l2_loss: 0.0806 - round_loss\u001b[A\n",
      "Training:   6%| | 2396/40960 [00:07<01:39, 387.94batches/s, l2_loss: 0.0806 - round_loss\u001b[A\n",
      "Training:   6%| | 2396/40960 [00:07<01:39, 387.94batches/s, l2_loss: 0.0807 - round_loss\u001b[A\n",
      "Training:   6%| | 2476/40960 [00:07<01:38, 390.83batches/s, l2_loss: 0.0807 - round_loss\u001b[A\n",
      "Training:   6%| | 2476/40960 [00:07<01:38, 390.83batches/s, l2_loss: 0.0802 - round_loss\u001b[A\n",
      "Training:   6%| | 2551/40960 [00:07<01:39, 385.60batches/s, l2_loss: 0.0802 - round_loss\u001b[A\n",
      "Training:   6%| | 2551/40960 [00:07<01:39, 385.60batches/s, l2_loss: 0.0801 - round_loss\u001b[A\n",
      "Training:   6%| | 2631/40960 [00:08<01:38, 388.62batches/s, l2_loss: 0.0801 - round_loss\u001b[A\n",
      "Training:   6%| | 2631/40960 [00:08<01:38, 388.62batches/s, l2_loss: 0.0796 - round_loss\u001b[A\n",
      "Training:   7%| | 2712/40960 [00:08<01:37, 391.92batches/s, l2_loss: 0.0796 - round_loss\u001b[A\n",
      "Training:   7%| | 2712/40960 [00:08<01:37, 391.92batches/s, l2_loss: 0.0797 - round_loss\u001b[A\n",
      "Training:   7%| | 2790/40960 [00:08<01:37, 390.35batches/s, l2_loss: 0.0797 - round_loss\u001b[A\n",
      "Training:   7%| | 2790/40960 [00:08<01:37, 390.35batches/s, l2_loss: 0.0796 - round_loss\u001b[A\n",
      "Training:   7%| | 2871/40960 [00:08<01:36, 394.22batches/s, l2_loss: 0.0796 - round_loss\u001b[A\n",
      "Training:   7%| | 2871/40960 [00:08<01:36, 394.22batches/s, l2_loss: 0.0793 - round_loss\u001b[A\n",
      "Training:   7%| | 2951/40960 [00:08<01:36, 394.88batches/s, l2_loss: 0.0793 - round_loss\u001b[A\n",
      "Training:   7%| | 2951/40960 [00:08<01:36, 394.88batches/s, l2_loss: 0.0790 - round_loss\u001b[A\n",
      "Training:   7%| | 3029/40960 [00:09<01:36, 392.38batches/s, l2_loss: 0.0790 - round_loss\u001b[A\n",
      "Training:   7%| | 3029/40960 [00:09<01:36, 392.38batches/s, l2_loss: 0.0791 - round_loss\u001b[A\n",
      "Training:   8%| | 3108/40960 [00:09<01:36, 391.86batches/s, l2_loss: 0.0791 - round_loss\u001b[A\n",
      "Training:   8%| | 3108/40960 [00:09<01:36, 391.86batches/s, l2_loss: 0.0790 - round_loss\u001b[A\n",
      "Training:   8%| | 3185/40960 [00:09<01:37, 389.13batches/s, l2_loss: 0.0790 - round_loss\u001b[A\n",
      "Training:   8%| | 3185/40960 [00:09<01:37, 389.13batches/s, l2_loss: 0.0786 - round_loss\u001b[A\n",
      "Training:   8%| | 3266/40960 [00:09<01:35, 393.02batches/s, l2_loss: 0.0786 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%| | 3266/40960 [00:09<01:35, 393.02batches/s, l2_loss: 0.0783 - round_loss\u001b[A\n",
      "Training:   8%| | 3345/40960 [00:09<01:35, 393.07batches/s, l2_loss: 0.0783 - round_loss\u001b[A\n",
      "Training:   8%| | 3345/40960 [00:09<01:35, 393.07batches/s, l2_loss: 0.0783 - round_loss\u001b[A\n",
      "Training:   8%| | 3424/40960 [00:10<01:35, 393.40batches/s, l2_loss: 0.0783 - round_loss\u001b[A\n",
      "Training:   8%| | 3424/40960 [00:10<01:35, 393.40batches/s, l2_loss: 0.0781 - round_loss\u001b[A\n",
      "Training:   9%| | 3505/40960 [00:10<01:34, 395.72batches/s, l2_loss: 0.0781 - round_loss\u001b[A\n",
      "Training:   9%| | 3505/40960 [00:10<01:34, 395.72batches/s, l2_loss: 0.0779 - round_loss\u001b[A\n",
      "Training:   9%| | 3585/40960 [00:10<01:34, 396.72batches/s, l2_loss: 0.0779 - round_loss\u001b[A\n",
      "Training:   9%| | 3585/40960 [00:10<01:34, 396.72batches/s, l2_loss: 0.0778 - round_loss\u001b[A\n",
      "Training:   9%| | 3664/40960 [00:10<01:34, 395.61batches/s, l2_loss: 0.0778 - round_loss\u001b[A\n",
      "Training:   9%| | 3664/40960 [00:10<01:34, 395.61batches/s, l2_loss: 0.0778 - round_loss\u001b[A\n",
      "Training:   9%| | 3744/40960 [00:10<01:34, 395.66batches/s, l2_loss: 0.0778 - round_loss\u001b[A\n",
      "Training:   9%| | 3744/40960 [00:10<01:34, 395.66batches/s, l2_loss: 0.0775 - round_loss\u001b[A\n",
      "Training:   9%| | 3824/40960 [00:11<01:33, 396.79batches/s, l2_loss: 0.0775 - round_loss\u001b[A\n",
      "Training:   9%| | 3824/40960 [00:11<01:33, 396.79batches/s, l2_loss: 0.0774 - round_loss\u001b[A\n",
      "Training:  10%| | 3900/40960 [00:11<01:34, 390.77batches/s, l2_loss: 0.0774 - round_loss\u001b[A\n",
      "Training:  10%| | 3900/40960 [00:11<01:34, 390.77batches/s, l2_loss: 0.0773 - round_loss\u001b[A\n",
      "Training:  10%| | 3981/40960 [00:11<01:33, 393.51batches/s, l2_loss: 0.0773 - round_loss\u001b[A\n",
      "Training:  10%| | 3981/40960 [00:11<01:33, 393.51batches/s, l2_loss: 0.0772 - round_loss\u001b[A\n",
      "Training:  10%| | 4061/40960 [00:11<01:33, 395.41batches/s, l2_loss: 0.0772 - round_loss\u001b[A\n",
      "Training:  10%| | 4061/40960 [00:11<01:33, 395.41batches/s, l2_loss: 0.0771 - round_loss\u001b[A\n",
      "Training:  10%| | 4142/40960 [00:11<01:32, 397.27batches/s, l2_loss: 0.0771 - round_loss\u001b[A\n",
      "Training:  10%| | 4142/40960 [00:11<01:32, 397.27batches/s, l2_loss: 0.0770 - round_loss\u001b[A\n",
      "Training:  10%| | 4222/40960 [00:12<01:32, 397.24batches/s, l2_loss: 0.0770 - round_loss\u001b[A\n",
      "Training:  10%| | 4222/40960 [00:12<01:32, 397.24batches/s, l2_loss: 0.0768 - round_loss\u001b[A\n",
      "Training:  10%| | 4297/40960 [00:12<01:33, 390.13batches/s, l2_loss: 0.0768 - round_loss\u001b[A\n",
      "Training:  10%| | 4297/40960 [00:12<01:33, 390.13batches/s, l2_loss: 0.0767 - round_loss\u001b[A\n",
      "Training:  11%| | 4376/40960 [00:12<01:33, 390.80batches/s, l2_loss: 0.0767 - round_loss\u001b[A\n",
      "Training:  11%| | 4376/40960 [00:12<01:33, 390.80batches/s, l2_loss: 0.0765 - round_loss\u001b[A\n",
      "Training:  11%| | 4455/40960 [00:12<01:33, 391.03batches/s, l2_loss: 0.0765 - round_loss\u001b[A\n",
      "Training:  11%| | 4455/40960 [00:12<01:33, 391.03batches/s, l2_loss: 0.0764 - round_loss\u001b[A\n",
      "Training:  11%| | 4536/40960 [00:12<01:32, 395.02batches/s, l2_loss: 0.0764 - round_loss\u001b[A\n",
      "Training:  11%| | 4536/40960 [00:12<01:32, 395.02batches/s, l2_loss: 0.0765 - round_loss\u001b[A\n",
      "Training:  11%| | 4617/40960 [00:13<01:31, 397.13batches/s, l2_loss: 0.0765 - round_loss\u001b[A\n",
      "Training:  11%| | 4617/40960 [00:13<01:31, 397.13batches/s, l2_loss: 0.0762 - round_loss\u001b[A\n",
      "Training:  11%| | 4696/40960 [00:13<01:31, 395.81batches/s, l2_loss: 0.0762 - round_loss\u001b[A\n",
      "Training:  11%| | 4696/40960 [00:13<01:31, 395.81batches/s, l2_loss: 0.0762 - round_loss\u001b[A\n",
      "Training:  12%| | 4774/40960 [00:13<01:31, 393.64batches/s, l2_loss: 0.0762 - round_loss\u001b[A\n",
      "Training:  12%| | 4774/40960 [00:13<01:31, 393.64batches/s, l2_loss: 0.0760 - round_loss\u001b[A\n",
      "Training:  12%| | 4854/40960 [00:13<01:31, 395.22batches/s, l2_loss: 0.0760 - round_loss\u001b[A\n",
      "Training:  12%| | 4854/40960 [00:13<01:31, 395.22batches/s, l2_loss: 0.0759 - round_loss\u001b[A\n",
      "Training:  12%| | 4931/40960 [00:13<01:31, 391.85batches/s, l2_loss: 0.0759 - round_loss\u001b[A\n",
      "Training:  12%| | 4931/40960 [00:13<01:31, 391.85batches/s, l2_loss: 0.0758 - round_loss\u001b[A\n",
      "Training:  12%| | 5010/40960 [00:14<01:31, 392.35batches/s, l2_loss: 0.0758 - round_loss\u001b[A\n",
      "Training:  12%| | 5010/40960 [00:14<01:31, 392.35batches/s, l2_loss: 0.0757 - round_loss\u001b[A\n",
      "Training:  12%| | 5089/40960 [00:14<01:31, 392.49batches/s, l2_loss: 0.0757 - round_loss\u001b[A\n",
      "Training:  12%| | 5089/40960 [00:14<01:31, 392.49batches/s, l2_loss: 0.0756 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5168/40960 [00:14<01:31, 391.86batches/s, l2_loss: 0.0756 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5168/40960 [00:14<01:31, 391.86batches/s, l2_loss: 0.0755 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5248/40960 [00:14<01:30, 394.09batches/s, l2_loss: 0.0755 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5248/40960 [00:14<01:30, 394.09batches/s, l2_loss: 0.0754 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5328/40960 [00:14<01:30, 394.61batches/s, l2_loss: 0.0754 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5328/40960 [00:14<01:30, 394.61batches/s, l2_loss: 0.0752 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5407/40960 [00:15<01:30, 394.66batches/s, l2_loss: 0.0752 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5407/40960 [00:15<01:30, 394.66batches/s, l2_loss: 0.0753 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5480/40960 [00:15<01:32, 383.88batches/s, l2_loss: 0.0753 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5480/40960 [00:15<01:32, 383.88batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5542/40960 [00:15<01:38, 361.20batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5542/40960 [00:15<01:38, 361.20batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5615/40960 [00:15<01:37, 361.13batches/s, l2_loss: 0.0751 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5615/40960 [00:15<01:37, 361.13batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5675/40960 [00:15<01:42, 342.78batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5675/40960 [00:15<01:42, 342.78batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5735/40960 [00:16<01:48, 324.80batches/s, l2_loss: 0.0750 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5735/40960 [00:16<01:48, 324.80batches/s, l2_loss: 0.0748 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5808/40960 [00:16<01:44, 336.07batches/s, l2_loss: 0.0748 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5808/40960 [00:16<01:44, 336.07batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5885/40960 [00:16<01:40, 350.35batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5885/40960 [00:16<01:40, 350.35batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5961/40960 [00:16<01:37, 357.88batches/s, l2_loss: 0.0747 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5961/40960 [00:16<01:37, 357.88batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6032/40960 [00:16<01:38, 354.55batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6032/40960 [00:17<01:38, 354.55batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6090/40960 [00:17<01:44, 334.63batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6090/40960 [00:17<01:44, 334.63batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6152/40960 [00:17<01:46, 326.72batches/s, l2_loss: 0.0745 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6152/40960 [00:17<01:46, 326.72batches/s, l2_loss: 0.0743 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6216/40960 [00:17<01:47, 322.99batches/s, l2_loss: 0.0743 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6216/40960 [00:17<01:47, 322.99batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6282/40960 [00:17<01:46, 324.95batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6282/40960 [00:17<01:46, 324.95batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6358/40960 [00:18<01:41, 341.16batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6358/40960 [00:18<01:41, 341.16batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6437/40960 [00:18<01:36, 356.82batches/s, l2_loss: 0.0742 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6437/40960 [00:18<01:36, 356.82batches/s, l2_loss: 0.0741 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6517/40960 [00:18<01:33, 369.40batches/s, l2_loss: 0.0741 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6517/40960 [00:18<01:33, 369.40batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6597/40960 [00:18<01:30, 378.49batches/s, l2_loss: 0.0740 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6597/40960 [00:18<01:30, 378.49batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|▏| 6672/40960 [00:18<01:31, 376.52batches/s, l2_loss: 0.0739 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6672/40960 [00:18<01:31, 376.52batches/s, l2_loss: 0.0738 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6752/40960 [00:19<01:29, 382.83batches/s, l2_loss: 0.0738 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6752/40960 [00:19<01:29, 382.83batches/s, l2_loss: 0.0738 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6831/40960 [00:19<01:28, 386.09batches/s, l2_loss: 0.0738 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6831/40960 [00:19<01:28, 386.09batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6909/40960 [00:19<01:28, 386.37batches/s, l2_loss: 0.0737 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6909/40960 [00:19<01:28, 386.37batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6985/40960 [00:19<01:28, 383.59batches/s, l2_loss: 0.0736 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6985/40960 [00:19<01:28, 383.59batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7063/40960 [00:19<01:28, 384.95batches/s, l2_loss: 0.0735 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7063/40960 [00:19<01:28, 384.95batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7144/40960 [00:20<01:26, 390.27batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7144/40960 [00:20<01:26, 390.27batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7223/40960 [00:20<01:26, 391.61batches/s, l2_loss: 0.0734 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7223/40960 [00:20<01:26, 391.61batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7299/40960 [00:20<01:26, 387.85batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7299/40960 [00:20<01:26, 387.85batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7379/40960 [00:20<01:25, 391.24batches/s, l2_loss: 0.0733 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7379/40960 [00:20<01:25, 391.24batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7457/40960 [00:20<01:25, 390.13batches/s, l2_loss: 0.0732 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7457/40960 [00:20<01:25, 390.13batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7538/40960 [00:21<01:24, 394.39batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7538/40960 [00:21<01:24, 394.39batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7619/40960 [00:21<01:24, 396.36batches/s, l2_loss: 0.0731 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7619/40960 [00:21<01:24, 396.36batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7699/40960 [00:21<01:23, 396.18batches/s, l2_loss: 0.0730 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7699/40960 [00:21<01:23, 396.18batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7776/40960 [00:21<01:24, 392.82batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7776/40960 [00:21<01:24, 392.82batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7855/40960 [00:21<01:24, 392.61batches/s, l2_loss: 0.0729 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7855/40960 [00:21<01:24, 392.61batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7933/40960 [00:22<01:24, 391.51batches/s, l2_loss: 0.0728 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7933/40960 [00:22<01:24, 391.51batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8008/40960 [00:22<01:25, 386.01batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8008/40960 [00:22<01:25, 386.01batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8086/40960 [00:22<01:25, 385.91batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8086/40960 [00:22<01:25, 385.91batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8162/40960 [00:22<01:25, 384.14batches/s, l2_loss: 0.0727 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8162/40960 [00:22<01:25, 384.14batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8236/40960 [00:22<01:26, 378.58batches/s, l2_loss: 0.0726 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8236/40960 [00:22<01:26, 378.58batches/s, l2_loss: 0.0634 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8308/40960 [00:23<01:27, 372.17batches/s, l2_loss: 0.0634 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8308/40960 [00:23<01:27, 372.17batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8371/40960 [00:23<01:31, 354.89batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8371/40960 [00:23<01:31, 354.89batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8435/40960 [00:23<01:34, 344.02batches/s, l2_loss: 0.0692 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8435/40960 [00:23<01:34, 344.02batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8500/40960 [00:23<01:36, 337.25batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8500/40960 [00:23<01:36, 337.25batches/s, l2_loss: 0.0672 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8569/40960 [00:23<01:35, 338.87batches/s, l2_loss: 0.0672 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8569/40960 [00:23<01:35, 338.87batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8628/40960 [00:24<01:39, 325.56batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8628/40960 [00:24<01:39, 325.56batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8697/40960 [00:24<01:37, 330.85batches/s, l2_loss: 0.0685 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8697/40960 [00:24<01:37, 330.85batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8769/40960 [00:24<01:35, 338.68batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8769/40960 [00:24<01:35, 338.68batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8843/40960 [00:24<01:32, 347.98batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8843/40960 [00:24<01:32, 347.98batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8917/40960 [00:24<01:30, 354.06batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8917/40960 [00:24<01:30, 354.06batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8991/40960 [00:25<01:29, 357.43batches/s, l2_loss: 0.0683 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8991/40960 [00:25<01:29, 357.43batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9062/40960 [00:25<01:29, 355.45batches/s, l2_loss: 0.0682 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9062/40960 [00:25<01:29, 355.45batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9136/40960 [00:25<01:28, 359.14batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9136/40960 [00:25<01:28, 359.14batches/s, l2_loss: 0.0673 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9209/40960 [00:25<01:28, 359.82batches/s, l2_loss: 0.0673 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9209/40960 [00:25<01:28, 359.82batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9279/40960 [00:25<01:29, 355.33batches/s, l2_loss: 0.0679 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9279/40960 [00:25<01:29, 355.33batches/s, l2_loss: 0.0672 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9351/40960 [00:26<01:28, 355.41batches/s, l2_loss: 0.0672 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9351/40960 [00:26<01:28, 355.41batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9424/40960 [00:26<01:28, 356.98batches/s, l2_loss: 0.0676 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9424/40960 [00:26<01:28, 356.98batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9495/40960 [00:26<01:28, 356.09batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9495/40960 [00:26<01:28, 356.09batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9565/40960 [00:26<01:28, 353.61batches/s, l2_loss: 0.0680 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9565/40960 [00:26<01:28, 353.61batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9638/40960 [00:26<01:27, 356.85batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9638/40960 [00:26<01:27, 356.85batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9708/40960 [00:27<01:28, 353.74batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9708/40960 [00:27<01:28, 353.74batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9778/40960 [00:27<01:28, 352.13batches/s, l2_loss: 0.0677 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9778/40960 [00:27<01:28, 352.13batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9849/40960 [00:27<01:28, 352.38batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9849/40960 [00:27<01:28, 352.38batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9920/40960 [00:27<01:27, 352.93batches/s, l2_loss: 0.0675 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|▏| 9920/40960 [00:27<01:27, 352.93batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9989/40960 [00:27<01:28, 350.22batches/s, l2_loss: 0.0678 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9989/40960 [00:27<01:28, 350.22batches/s, l2_loss: 0.0674 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10062/40960 [00:28<01:27, 354.25batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  25%|▏| 10062/40960 [00:28<01:27, 354.25batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  25%|▏| 10133/40960 [00:28<01:27, 354.03batches/s, l2_loss: 0.0676 - round_los\u001b[A\n",
      "Training:  25%|▏| 10133/40960 [00:28<01:27, 354.03batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  25%|▏| 10206/40960 [00:28<01:26, 355.96batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  25%|▏| 10206/40960 [00:28<01:26, 355.96batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  25%|▎| 10273/40960 [00:28<01:28, 346.79batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  25%|▎| 10273/40960 [00:28<01:28, 346.79batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  25%|▎| 10331/40960 [00:28<01:33, 328.24batches/s, l2_loss: 0.0675 - round_los\u001b[A\n",
      "Training:  25%|▎| 10331/40960 [00:28<01:33, 328.24batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  25%|▎| 10394/40960 [00:29<01:34, 323.42batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  25%|▎| 10394/40960 [00:29<01:34, 323.42batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  26%|▎| 10468/40960 [00:29<01:30, 337.18batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  26%|▎| 10468/40960 [00:29<01:30, 337.18batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  26%|▎| 10533/40960 [00:29<01:31, 332.60batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  26%|▎| 10533/40960 [00:29<01:31, 332.60batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  26%|▎| 10601/40960 [00:29<01:30, 334.73batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  26%|▎| 10601/40960 [00:29<01:30, 334.73batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  26%|▎| 10671/40960 [00:29<01:29, 338.69batches/s, l2_loss: 0.0674 - round_los\u001b[A\n",
      "Training:  26%|▎| 10671/40960 [00:29<01:29, 338.69batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  26%|▎| 10744/40960 [00:30<01:27, 346.34batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  26%|▎| 10744/40960 [00:30<01:27, 346.34batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  26%|▎| 10816/40960 [00:30<01:26, 349.84batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  26%|▎| 10816/40960 [00:30<01:26, 349.84batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  27%|▎| 10890/40960 [00:30<01:24, 354.55batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  27%|▎| 10890/40960 [00:30<01:24, 354.55batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  27%|▎| 10965/40960 [00:30<01:23, 359.40batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  27%|▎| 10965/40960 [00:30<01:23, 359.40batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  27%|▎| 11039/40960 [00:30<01:22, 361.81batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  27%|▎| 11039/40960 [00:30<01:22, 361.81batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  27%|▎| 11113/40960 [00:31<01:22, 363.02batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  27%|▎| 11113/40960 [00:31<01:22, 363.02batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  27%|▎| 11186/40960 [00:31<01:22, 362.79batches/s, l2_loss: 0.0673 - round_los\u001b[A\n",
      "Training:  27%|▎| 11186/40960 [00:31<01:22, 362.79batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  27%|▎| 11259/40960 [00:31<01:21, 363.16batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  27%|▎| 11259/40960 [00:31<01:21, 363.16batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  28%|▎| 11334/40960 [00:31<01:20, 366.53batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  28%|▎| 11334/40960 [00:31<01:20, 366.53batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  28%|▎| 11407/40960 [00:31<01:20, 365.67batches/s, l2_loss: 0.0672 - round_los\u001b[A\n",
      "Training:  28%|▎| 11407/40960 [00:31<01:20, 365.67batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  28%|▎| 11472/40960 [00:32<01:23, 353.29batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  28%|▎| 11472/40960 [00:32<01:23, 353.29batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  28%|▎| 11547/40960 [00:32<01:21, 358.85batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  28%|▎| 11547/40960 [00:32<01:21, 358.85batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  28%|▎| 11622/40960 [00:32<01:20, 362.45batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  28%|▎| 11622/40960 [00:32<01:20, 362.45batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  29%|▎| 11691/40960 [00:32<01:22, 356.47batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  29%|▎| 11691/40960 [00:32<01:22, 356.47batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  29%|▎| 11760/40960 [00:32<01:22, 352.59batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  29%|▎| 11760/40960 [00:32<01:22, 352.59batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  29%|▎| 11832/40960 [00:33<01:22, 353.80batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  29%|▎| 11832/40960 [00:33<01:22, 353.80batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  29%|▎| 11906/40960 [00:33<01:21, 357.96batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  29%|▎| 11906/40960 [00:33<01:21, 357.96batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  29%|▎| 11978/40960 [00:33<01:20, 358.16batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  29%|▎| 11978/40960 [00:33<01:20, 358.16batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  29%|▎| 12051/40960 [00:33<01:20, 359.63batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  29%|▎| 12051/40960 [00:33<01:20, 359.63batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  30%|▎| 12125/40960 [00:33<01:19, 361.45batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  30%|▎| 12125/40960 [00:33<01:19, 361.45batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  30%|▎| 12199/40960 [00:34<01:19, 363.94batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  30%|▎| 12199/40960 [00:34<01:19, 363.94batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  30%|▎| 12273/40960 [00:34<01:18, 364.55batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  30%|▎| 12273/40960 [00:34<01:18, 364.55batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  30%|▎| 12346/40960 [00:34<01:18, 363.42batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  30%|▎| 12346/40960 [00:34<01:18, 363.42batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  30%|▎| 12418/40960 [00:34<01:18, 361.91batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  30%|▎| 12418/40960 [00:34<01:18, 361.91batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  30%|▎| 12488/40960 [00:34<01:19, 358.00batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  30%|▎| 12488/40960 [00:34<01:19, 358.00batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  31%|▎| 12562/40960 [00:35<01:18, 360.27batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  31%|▎| 12562/40960 [00:35<01:18, 360.27batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  31%|▎| 12637/40960 [00:35<01:17, 363.36batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  31%|▎| 12637/40960 [00:35<01:17, 363.36batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  31%|▎| 12712/40960 [00:35<01:17, 366.30batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  31%|▎| 12712/40960 [00:35<01:17, 366.30batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  31%|▎| 12785/40960 [00:35<01:17, 364.65batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  31%|▎| 12785/40960 [00:35<01:17, 364.65batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  31%|▎| 12860/40960 [00:35<01:16, 366.35batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  31%|▎| 12860/40960 [00:35<01:16, 366.35batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  32%|▎| 12931/40960 [00:36<01:17, 361.83batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  32%|▎| 12931/40960 [00:36<01:17, 361.83batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  32%|▎| 12995/40960 [00:36<01:20, 347.97batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  32%|▎| 12995/40960 [00:36<01:20, 347.97batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  32%|▎| 13055/40960 [00:36<01:23, 333.41batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  32%|▎| 13055/40960 [00:36<01:23, 333.41batches/s, l2_loss: 0.0666 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 13124/40960 [00:36<01:22, 335.91batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  32%|▎| 13124/40960 [00:36<01:22, 335.91batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  32%|▎| 13198/40960 [00:36<01:20, 345.88batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  32%|▎| 13198/40960 [00:36<01:20, 345.88batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  32%|▎| 13264/40960 [00:37<01:21, 341.14batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  32%|▎| 13264/40960 [00:37<01:21, 341.14batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  33%|▎| 13336/40960 [00:37<01:19, 346.59batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  33%|▎| 13336/40960 [00:37<01:19, 346.59batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  33%|▎| 13410/40960 [00:37<01:18, 352.64batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  33%|▎| 13410/40960 [00:37<01:18, 352.64batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  33%|▎| 13470/40960 [00:37<01:21, 335.37batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  33%|▎| 13470/40960 [00:37<01:21, 335.37batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  33%|▎| 13533/40960 [00:37<01:23, 329.03batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  33%|▎| 13533/40960 [00:37<01:23, 329.03batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  33%|▎| 13604/40960 [00:38<01:21, 335.71batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  33%|▎| 13604/40960 [00:38<01:21, 335.71batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  33%|▎| 13673/40960 [00:38<01:20, 337.63batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  33%|▎| 13673/40960 [00:38<01:20, 337.63batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  34%|▎| 13743/40960 [00:38<01:19, 340.31batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  34%|▎| 13743/40960 [00:38<01:19, 340.31batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  34%|▎| 13809/40960 [00:38<01:20, 337.23batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  34%|▎| 13809/40960 [00:38<01:20, 337.23batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  34%|▎| 13881/40960 [00:38<01:18, 342.96batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  34%|▎| 13881/40960 [00:38<01:18, 342.96batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  34%|▎| 13955/40960 [00:39<01:17, 350.18batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  34%|▎| 13955/40960 [00:39<01:17, 350.18batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  34%|▎| 14019/40960 [00:39<01:19, 340.76batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  34%|▎| 14019/40960 [00:39<01:19, 340.76batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  34%|▎| 14086/40960 [00:39<01:19, 338.70batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  34%|▎| 14086/40960 [00:39<01:19, 338.70batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  35%|▎| 14148/40960 [00:39<01:21, 330.01batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  35%|▎| 14148/40960 [00:39<01:21, 330.01batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  35%|▎| 14223/40960 [00:39<01:18, 342.24batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  35%|▎| 14223/40960 [00:39<01:18, 342.24batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  35%|▎| 14293/40960 [00:40<01:17, 343.88batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  35%|▎| 14293/40960 [00:40<01:17, 343.88batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  35%|▎| 14365/40960 [00:40<01:16, 347.47batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  35%|▎| 14365/40960 [00:40<01:16, 347.47batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  35%|▎| 14434/40960 [00:40<01:16, 345.45batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  35%|▎| 14434/40960 [00:40<01:16, 345.45batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  35%|▎| 14502/40960 [00:40<01:17, 342.87batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  35%|▎| 14502/40960 [00:40<01:17, 342.87batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  36%|▎| 14555/40960 [00:40<01:22, 319.61batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  36%|▎| 14555/40960 [00:40<01:22, 319.61batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  36%|▎| 14598/40960 [00:41<01:32, 285.74batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  36%|▎| 14598/40960 [00:41<01:32, 285.74batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  36%|▎| 14660/40960 [00:41<01:30, 291.51batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  36%|▎| 14660/40960 [00:41<01:30, 291.51batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  36%|▎| 14733/40960 [00:41<01:23, 312.71batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  36%|▎| 14733/40960 [00:41<01:23, 312.71batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  36%|▎| 14803/40960 [00:41<01:21, 322.70batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  36%|▎| 14803/40960 [00:41<01:21, 322.70batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  36%|▎| 14877/40960 [00:41<01:17, 335.96batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  36%|▎| 14877/40960 [00:41<01:17, 335.96batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  36%|▎| 14950/40960 [00:42<01:15, 343.48batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  36%|▎| 14950/40960 [00:42<01:15, 343.48batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  37%|▎| 15021/40960 [00:42<01:14, 346.26batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  37%|▎| 15021/40960 [00:42<01:14, 346.26batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  37%|▎| 15092/40960 [00:42<01:14, 348.56batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  37%|▎| 15092/40960 [00:42<01:14, 348.56batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  37%|▎| 15164/40960 [00:42<01:13, 351.59batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  37%|▎| 15164/40960 [00:42<01:13, 351.59batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  37%|▎| 15235/40960 [00:42<01:13, 352.34batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  37%|▎| 15235/40960 [00:42<01:13, 352.34batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  37%|▎| 15308/40960 [00:43<01:12, 355.17batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  37%|▎| 15308/40960 [00:43<01:12, 355.17batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  38%|▍| 15381/40960 [00:43<01:11, 358.10batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  38%|▍| 15381/40960 [00:43<01:11, 358.10batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  38%|▍| 15447/40960 [00:43<01:12, 349.52batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  38%|▍| 15447/40960 [00:43<01:12, 349.52batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  38%|▍| 15515/40960 [00:43<01:13, 346.27batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  38%|▍| 15515/40960 [00:43<01:13, 346.27batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  38%|▍| 15587/40960 [00:43<01:12, 349.04batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  38%|▍| 15587/40960 [00:43<01:12, 349.04batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  38%|▍| 15657/40960 [00:44<01:12, 349.23batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  38%|▍| 15657/40960 [00:44<01:12, 349.23batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  38%|▍| 15728/40960 [00:44<01:12, 350.20batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  38%|▍| 15728/40960 [00:44<01:12, 350.20batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  39%|▍| 15801/40960 [00:44<01:11, 353.95batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  39%|▍| 15801/40960 [00:44<01:11, 353.95batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  39%|▍| 15875/40960 [00:44<01:10, 358.12batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  39%|▍| 15875/40960 [00:44<01:10, 358.12batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  39%|▍| 15947/40960 [00:44<01:09, 357.60batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  39%|▍| 15947/40960 [00:44<01:09, 357.60batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  39%|▍| 16019/40960 [00:45<01:09, 357.29batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  39%|▍| 16019/40960 [00:45<01:09, 357.29batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  39%|▍| 16095/40960 [00:45<01:08, 363.60batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  39%|▍| 16095/40960 [00:45<01:08, 363.60batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  39%|▍| 16169/40960 [00:45<01:07, 364.96batches/s, l2_loss: 0.0660 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|▍| 16169/40960 [00:45<01:07, 364.96batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  40%|▍| 16243/40960 [00:45<01:07, 365.48batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  40%|▍| 16243/40960 [00:45<01:07, 365.48batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  40%|▍| 16315/40960 [00:45<01:07, 363.60batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  40%|▍| 16315/40960 [00:46<01:07, 363.60batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  40%|▍| 16388/40960 [00:46<01:07, 363.44batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  40%|▍| 16388/40960 [00:46<01:07, 363.44batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  40%|▍| 16460/40960 [00:46<01:07, 362.13batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  40%|▍| 16460/40960 [00:46<01:07, 362.13batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  40%|▍| 16533/40960 [00:46<01:07, 362.21batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  40%|▍| 16533/40960 [00:46<01:07, 362.21batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  41%|▍| 16607/40960 [00:46<01:07, 363.27batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  41%|▍| 16607/40960 [00:46<01:07, 363.27batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16676/40960 [00:47<01:08, 356.90batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16676/40960 [00:47<01:08, 356.90batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16750/40960 [00:47<01:07, 360.58batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16750/40960 [00:47<01:07, 360.58batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16825/40960 [00:47<01:06, 364.68batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16825/40960 [00:47<01:06, 364.68batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16899/40960 [00:47<01:05, 365.48batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16899/40960 [00:47<01:05, 365.48batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16972/40960 [00:47<01:05, 365.05batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  41%|▍| 16972/40960 [00:47<01:05, 365.05batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  42%|▍| 17044/40960 [00:48<01:05, 362.89batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  42%|▍| 17044/40960 [00:48<01:05, 362.89batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  42%|▍| 17117/40960 [00:48<01:05, 362.40batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  42%|▍| 17117/40960 [00:48<01:05, 362.40batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  42%|▍| 17188/40960 [00:48<01:06, 359.05batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  42%|▍| 17188/40960 [00:48<01:06, 359.05batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  42%|▍| 17257/40960 [00:48<01:07, 353.40batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  42%|▍| 17257/40960 [00:48<01:07, 353.40batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  42%|▍| 17327/40960 [00:48<01:07, 351.87batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  42%|▍| 17327/40960 [00:48<01:07, 351.87batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  42%|▍| 17400/40960 [00:49<01:06, 354.98batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  42%|▍| 17400/40960 [00:49<01:06, 354.98batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17471/40960 [00:49<01:06, 353.80batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17471/40960 [00:49<01:06, 353.80batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17541/40960 [00:49<01:06, 352.48batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17541/40960 [00:49<01:06, 352.48batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17611/40960 [00:49<01:06, 350.97batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17611/40960 [00:49<01:06, 350.97batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17681/40960 [00:49<01:06, 349.35batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17681/40960 [00:49<01:06, 349.35batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17753/40960 [00:50<01:05, 352.37batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17753/40960 [00:50<01:05, 352.37batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17816/40960 [00:50<01:08, 339.84batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  43%|▍| 17816/40960 [00:50<01:08, 339.84batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  44%|▍| 17886/40960 [00:50<01:07, 342.40batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  44%|▍| 17886/40960 [00:50<01:07, 342.40batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  44%|▍| 17961/40960 [00:50<01:05, 351.27batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  44%|▍| 17961/40960 [00:50<01:05, 351.27batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  44%|▍| 18036/40960 [00:50<01:04, 357.80batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  44%|▍| 18036/40960 [00:50<01:04, 357.80batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  44%|▍| 18108/40960 [00:51<01:03, 357.92batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  44%|▍| 18108/40960 [00:51<01:03, 357.92batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  44%|▍| 18178/40960 [00:51<01:04, 354.98batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  44%|▍| 18178/40960 [00:51<01:04, 354.98batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18248/40960 [00:51<01:04, 352.43batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18248/40960 [00:51<01:04, 352.43batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  45%|▍| 18319/40960 [00:51<01:04, 352.93batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  45%|▍| 18319/40960 [00:51<01:04, 352.93batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18394/40960 [00:51<01:02, 358.67batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18394/40960 [00:51<01:02, 358.67batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18468/40960 [00:52<01:02, 361.43batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18468/40960 [00:52<01:02, 361.43batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18542/40960 [00:52<01:01, 363.84batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18542/40960 [00:52<01:01, 363.84batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18617/40960 [00:52<01:01, 366.07batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  45%|▍| 18617/40960 [00:52<01:01, 366.07batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  46%|▍| 18692/40960 [00:52<01:00, 368.31batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  46%|▍| 18692/40960 [00:52<01:00, 368.31batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  46%|▍| 18764/40960 [00:52<01:00, 364.79batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  46%|▍| 18764/40960 [00:52<01:00, 364.79batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  46%|▍| 18837/40960 [00:53<01:00, 363.67batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  46%|▍| 18837/40960 [00:53<01:00, 363.67batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  46%|▍| 18910/40960 [00:53<01:00, 362.92batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  46%|▍| 18910/40960 [00:53<01:00, 362.92batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  46%|▍| 18983/40960 [00:53<01:00, 363.13batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  46%|▍| 18983/40960 [00:53<01:00, 363.13batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  47%|▍| 19057/40960 [00:53<01:00, 364.10batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  47%|▍| 19057/40960 [00:53<01:00, 364.10batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19128/40960 [00:53<01:00, 360.60batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19128/40960 [00:53<01:00, 360.60batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19172/40960 [00:54<01:08, 318.28batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19172/40960 [00:54<01:08, 318.28batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19238/40960 [00:54<01:07, 321.38batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19238/40960 [00:54<01:07, 321.38batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19308/40960 [00:54<01:05, 328.88batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19308/40960 [00:54<01:05, 328.88batches/s, l2_loss: 0.0656 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|▍| 19381/40960 [00:54<01:03, 338.53batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  47%|▍| 19381/40960 [00:54<01:03, 338.53batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  47%|▍| 19447/40960 [00:54<01:04, 335.06batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  47%|▍| 19447/40960 [00:54<01:04, 335.06batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  48%|▍| 19522/40960 [00:55<01:02, 345.67batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  48%|▍| 19522/40960 [00:55<01:02, 345.67batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  48%|▍| 19591/40960 [00:55<01:01, 344.73batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  48%|▍| 19591/40960 [00:55<01:01, 344.73batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  48%|▍| 19660/40960 [00:55<01:02, 343.46batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  48%|▍| 19660/40960 [00:55<01:02, 343.46batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  48%|▍| 19729/40960 [00:55<01:01, 343.52batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  48%|▍| 19729/40960 [00:55<01:01, 343.52batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  48%|▍| 19800/40960 [00:55<01:01, 346.00batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  48%|▍| 19800/40960 [00:55<01:01, 346.00batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  49%|▍| 19871/40960 [00:56<01:00, 347.72batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  49%|▍| 19871/40960 [00:56<01:00, 347.72batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  49%|▍| 19945/40960 [00:56<00:59, 354.13batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  49%|▍| 19945/40960 [00:56<00:59, 354.13batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  49%|▍| 20018/40960 [00:56<00:58, 356.42batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  49%|▍| 20018/40960 [00:56<00:58, 356.42batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  49%|▍| 20089/40960 [00:56<00:58, 354.09batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  49%|▍| 20089/40960 [00:56<00:58, 354.09batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  49%|▍| 20164/40960 [00:56<00:57, 359.50batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  49%|▍| 20164/40960 [00:56<00:57, 359.50batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  49%|▍| 20238/40960 [00:57<00:57, 361.93batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  49%|▍| 20238/40960 [00:57<00:57, 361.93batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▍| 20313/40960 [00:57<00:56, 364.21batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▍| 20313/40960 [00:57<00:56, 364.21batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▍| 20388/40960 [00:57<00:56, 366.03batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▍| 20388/40960 [00:57<00:56, 366.03batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▍| 20456/40960 [00:57<00:57, 358.02batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▍| 20456/40960 [00:57<00:57, 358.02batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  50%|▌| 20516/40960 [00:57<01:00, 340.50batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  50%|▌| 20516/40960 [00:57<01:00, 340.50batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▌| 20584/40960 [00:58<01:00, 338.74batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▌| 20584/40960 [00:58<01:00, 338.74batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▌| 20653/40960 [00:58<00:59, 339.37batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  50%|▌| 20653/40960 [00:58<00:59, 339.37batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  51%|▌| 20718/40960 [00:58<01:00, 334.81batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  51%|▌| 20718/40960 [00:58<01:00, 334.81batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  51%|▌| 20781/40960 [00:58<01:01, 327.37batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  51%|▌| 20781/40960 [00:58<01:01, 327.37batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  51%|▌| 20847/40960 [00:58<01:01, 326.92batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  51%|▌| 20847/40960 [00:58<01:01, 326.92batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  51%|▌| 20918/40960 [00:59<00:59, 334.78batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  51%|▌| 20918/40960 [00:59<00:59, 334.78batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  51%|▌| 20990/40960 [00:59<00:58, 341.10batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  51%|▌| 20990/40960 [00:59<00:58, 341.10batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  51%|▌| 21063/40960 [00:59<00:57, 347.13batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  51%|▌| 21063/40960 [00:59<00:57, 347.13batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21131/40960 [00:59<00:57, 344.58batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21131/40960 [00:59<00:57, 344.58batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21195/40960 [00:59<00:58, 335.46batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21195/40960 [00:59<00:58, 335.46batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  52%|▌| 21257/40960 [01:00<01:00, 326.75batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  52%|▌| 21257/40960 [01:00<01:00, 326.75batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21308/40960 [01:00<01:04, 304.88batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21308/40960 [01:00<01:04, 304.88batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21378/40960 [01:00<01:01, 317.31batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21378/40960 [01:00<01:01, 317.31batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21438/40960 [01:00<01:02, 311.59batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21438/40960 [01:00<01:02, 311.59batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21502/40960 [01:00<01:01, 313.93batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  52%|▌| 21502/40960 [01:00<01:01, 313.93batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21574/40960 [01:01<00:59, 326.83batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21574/40960 [01:01<00:59, 326.83batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21641/40960 [01:01<00:58, 327.98batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21641/40960 [01:01<00:58, 327.98batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21713/40960 [01:01<00:57, 336.81batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21713/40960 [01:01<00:57, 336.81batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21777/40960 [01:01<00:58, 328.47batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21777/40960 [01:01<00:58, 328.47batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21835/40960 [01:01<01:00, 315.99batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21835/40960 [01:01<01:00, 315.99batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21901/40960 [01:02<00:59, 319.90batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  53%|▌| 21901/40960 [01:02<00:59, 319.90batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  54%|▌| 21970/40960 [01:02<00:58, 326.72batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  54%|▌| 21970/40960 [01:02<00:58, 326.72batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  54%|▌| 22040/40960 [01:02<00:56, 333.21batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  54%|▌| 22040/40960 [01:02<00:56, 333.21batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  54%|▌| 22089/40960 [01:02<01:01, 304.99batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  54%|▌| 22089/40960 [01:02<01:01, 304.99batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  54%|▌| 22154/40960 [01:02<01:00, 309.69batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  54%|▌| 22154/40960 [01:02<01:00, 309.69batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  54%|▌| 22219/40960 [01:03<00:59, 313.30batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  54%|▌| 22219/40960 [01:03<00:59, 313.30batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  54%|▌| 22292/40960 [01:03<00:56, 327.89batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  54%|▌| 22292/40960 [01:03<00:56, 327.89batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  55%|▌| 22359/40960 [01:03<00:56, 329.91batches/s, l2_loss: 0.0653 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22359/40960 [01:03<00:56, 329.91batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  55%|▌| 22417/40960 [01:03<00:58, 317.44batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  55%|▌| 22417/40960 [01:03<00:58, 317.44batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  55%|▌| 22459/40960 [01:03<01:04, 284.91batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  55%|▌| 22459/40960 [01:03<01:04, 284.91batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  55%|▌| 22516/40960 [01:04<01:05, 282.26batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  55%|▌| 22516/40960 [01:04<01:05, 282.26batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  55%|▌| 22584/40960 [01:04<01:01, 298.46batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  55%|▌| 22584/40960 [01:04<01:01, 298.46batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  55%|▌| 22658/40960 [01:04<00:57, 319.19batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  55%|▌| 22658/40960 [01:04<00:57, 319.19batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  55%|▌| 22727/40960 [01:04<00:55, 325.63batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  55%|▌| 22727/40960 [01:04<00:55, 325.63batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 22798/40960 [01:04<00:54, 333.43batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 22798/40960 [01:04<00:54, 333.43batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 22866/40960 [01:05<00:54, 334.00batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 22866/40960 [01:05<00:54, 334.00batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 22935/40960 [01:05<00:53, 337.03batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 22935/40960 [01:05<00:53, 337.03batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 23006/40960 [01:05<00:52, 341.12batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 23006/40960 [01:05<00:52, 341.12batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 23079/40960 [01:05<00:51, 347.12batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  56%|▌| 23079/40960 [01:05<00:51, 347.12batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23153/40960 [01:05<00:50, 352.72batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23153/40960 [01:05<00:50, 352.72batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23226/40960 [01:06<00:49, 355.28batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23226/40960 [01:06<00:49, 355.28batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23300/40960 [01:06<00:49, 359.27batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23300/40960 [01:06<00:49, 359.27batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23373/40960 [01:06<00:48, 360.20batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23373/40960 [01:06<00:48, 360.20batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23446/40960 [01:06<00:48, 360.97batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23446/40960 [01:06<00:48, 360.97batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23520/40960 [01:06<00:48, 363.03batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  57%|▌| 23520/40960 [01:06<00:48, 363.03batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23593/40960 [01:07<00:47, 362.15batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23593/40960 [01:07<00:47, 362.15batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23662/40960 [01:07<00:48, 355.75batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23662/40960 [01:07<00:48, 355.75batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23736/40960 [01:07<00:48, 357.51batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23736/40960 [01:07<00:48, 357.51batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  58%|▌| 23810/40960 [01:07<00:47, 360.68batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  58%|▌| 23810/40960 [01:07<00:47, 360.68batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23883/40960 [01:07<00:47, 360.62batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23883/40960 [01:07<00:47, 360.62batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23958/40960 [01:08<00:46, 364.23batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  58%|▌| 23958/40960 [01:08<00:46, 364.23batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  59%|▌| 24031/40960 [01:08<00:46, 363.25batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  59%|▌| 24031/40960 [01:08<00:46, 363.25batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  59%|▌| 24100/40960 [01:08<00:47, 357.03batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  59%|▌| 24100/40960 [01:08<00:47, 357.03batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  59%|▌| 24175/40960 [01:08<00:46, 360.99batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  59%|▌| 24175/40960 [01:08<00:46, 360.99batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  59%|▌| 24249/40960 [01:08<00:45, 363.40batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  59%|▌| 24249/40960 [01:09<00:45, 363.40batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  59%|▌| 24318/40960 [01:09<00:46, 356.73batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  59%|▌| 24318/40960 [01:09<00:46, 356.73batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  60%|▌| 24387/40960 [01:09<00:47, 352.60batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  60%|▌| 24387/40960 [01:09<00:47, 352.60batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  60%|▌| 24446/40960 [01:09<00:49, 333.75batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  60%|▌| 24446/40960 [01:09<00:49, 333.75batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  60%|▌| 24509/40960 [01:09<00:50, 326.80batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  60%|▌| 24509/40960 [01:09<00:50, 326.80batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  60%|▌| 24569/40960 [01:10<00:51, 317.33batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  60%|▌| 24569/40960 [01:10<00:51, 317.33batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  60%|▌| 24639/40960 [01:10<00:50, 326.04batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  60%|▌| 24639/40960 [01:10<00:50, 326.04batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  60%|▌| 24712/40960 [01:10<00:48, 336.43batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  60%|▌| 24712/40960 [01:10<00:48, 336.43batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  61%|▌| 24781/40960 [01:10<00:47, 337.10batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  61%|▌| 24781/40960 [01:10<00:47, 337.10batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  61%|▌| 24851/40960 [01:10<00:47, 340.34batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  61%|▌| 24851/40960 [01:10<00:47, 340.34batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  61%|▌| 24919/40960 [01:11<00:47, 339.52batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  61%|▌| 24919/40960 [01:11<00:47, 339.52batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  61%|▌| 24992/40960 [01:11<00:46, 347.11batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  61%|▌| 24992/40960 [01:11<00:46, 347.11batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  61%|▌| 25066/40960 [01:11<00:45, 352.33batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  61%|▌| 25066/40960 [01:11<00:45, 352.33batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  61%|▌| 25141/40960 [01:11<00:44, 358.18batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  61%|▌| 25141/40960 [01:11<00:44, 358.18batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  62%|▌| 25213/40960 [01:11<00:44, 357.72batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  62%|▌| 25213/40960 [01:11<00:44, 357.72batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25284/40960 [01:12<00:43, 356.59batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25284/40960 [01:12<00:43, 356.59batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25357/40960 [01:12<00:43, 357.89batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25357/40960 [01:12<00:43, 357.89batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25429/40960 [01:12<00:43, 357.34batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25429/40960 [01:12<00:43, 357.34batches/s, l2_loss: 0.0652 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|▌| 25502/40960 [01:12<00:43, 358.59batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25502/40960 [01:12<00:43, 358.59batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25560/40960 [01:12<00:45, 336.73batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  62%|▌| 25560/40960 [01:12<00:45, 336.73batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25631/40960 [01:13<00:44, 340.90batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25631/40960 [01:13<00:44, 340.90batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25704/40960 [01:13<00:43, 347.67batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25704/40960 [01:13<00:43, 347.67batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25774/40960 [01:13<00:43, 347.39batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25774/40960 [01:13<00:43, 347.39batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25847/40960 [01:13<00:42, 352.10batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25847/40960 [01:13<00:42, 352.10batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25920/40960 [01:13<00:42, 355.91batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25920/40960 [01:13<00:42, 355.91batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25993/40960 [01:14<00:41, 357.04batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  63%|▋| 25993/40960 [01:14<00:41, 357.04batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26069/40960 [01:14<00:41, 362.77batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26069/40960 [01:14<00:41, 362.77batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26138/40960 [01:14<00:41, 357.47batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26138/40960 [01:14<00:41, 357.47batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26210/40960 [01:14<00:41, 357.98batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26210/40960 [01:14<00:41, 357.98batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26282/40960 [01:14<00:40, 358.58batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26282/40960 [01:14<00:40, 358.58batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26355/40960 [01:15<00:40, 359.75batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  64%|▋| 26355/40960 [01:15<00:40, 359.75batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26428/40960 [01:15<00:40, 360.66batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26428/40960 [01:15<00:40, 360.66batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26498/40960 [01:15<00:40, 355.81batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26498/40960 [01:15<00:40, 355.81batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26564/40960 [01:15<00:41, 346.81batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26564/40960 [01:15<00:41, 346.81batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26636/40960 [01:15<00:40, 350.74batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26636/40960 [01:15<00:40, 350.74batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26708/40960 [01:16<00:40, 352.86batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26708/40960 [01:16<00:40, 352.86batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26778/40960 [01:16<00:40, 351.51batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  65%|▋| 26778/40960 [01:16<00:40, 351.51batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 26852/40960 [01:16<00:39, 356.51batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 26852/40960 [01:16<00:39, 356.51batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 26924/40960 [01:16<00:39, 357.53batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 26924/40960 [01:16<00:39, 357.53batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 26994/40960 [01:16<00:39, 355.21batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 26994/40960 [01:16<00:39, 355.21batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 27065/40960 [01:17<00:39, 353.80batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 27065/40960 [01:17<00:39, 353.80batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 27137/40960 [01:17<00:38, 355.27batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 27137/40960 [01:17<00:38, 355.27batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:17<00:40, 342.91batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:17<00:40, 342.91batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27265/40960 [01:17<00:40, 336.05batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27265/40960 [01:17<00:40, 336.05batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27333/40960 [01:17<00:40, 337.06batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27333/40960 [01:17<00:40, 337.06batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27404/40960 [01:18<00:39, 341.94batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27404/40960 [01:18<00:39, 341.94batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27470/40960 [01:18<00:39, 338.26batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27470/40960 [01:18<00:39, 338.26batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27545/40960 [01:18<00:38, 348.24batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27545/40960 [01:18<00:38, 348.24batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27594/40960 [01:18<00:42, 317.32batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  67%|▋| 27594/40960 [01:18<00:42, 317.32batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27655/40960 [01:18<00:42, 312.36batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27655/40960 [01:18<00:42, 312.36batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27722/40960 [01:19<00:41, 318.38batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27722/40960 [01:19<00:41, 318.38batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27782/40960 [01:19<00:42, 312.06batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27782/40960 [01:19<00:42, 312.06batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27850/40960 [01:19<00:41, 319.42batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27850/40960 [01:19<00:41, 319.42batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27922/40960 [01:19<00:39, 331.29batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  68%|▋| 27922/40960 [01:19<00:39, 331.29batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  68%|▋| 27995/40960 [01:19<00:38, 340.91batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  68%|▋| 27995/40960 [01:19<00:38, 340.91batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28060/40960 [01:20<00:38, 336.08batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28060/40960 [01:20<00:38, 336.08batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28129/40960 [01:20<00:37, 337.72batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28129/40960 [01:20<00:37, 337.72batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28189/40960 [01:20<00:39, 325.67batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28189/40960 [01:20<00:39, 325.67batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28247/40960 [01:20<00:40, 314.72batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28247/40960 [01:20<00:40, 314.72batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28323/40960 [01:20<00:37, 333.90batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28323/40960 [01:20<00:37, 333.90batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28398/40960 [01:21<00:36, 345.32batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  69%|▋| 28398/40960 [01:21<00:36, 345.32batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28471/40960 [01:21<00:35, 349.92batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28471/40960 [01:21<00:35, 349.92batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28537/40960 [01:21<00:36, 340.83batches/s, l2_loss: 0.0652 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28537/40960 [01:21<00:36, 340.83batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28606/40960 [01:21<00:36, 341.64batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28606/40960 [01:21<00:36, 341.64batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28673/40960 [01:21<00:36, 339.58batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28673/40960 [01:21<00:36, 339.58batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28746/40960 [01:22<00:35, 346.46batches/s, l2_loss: 0.0652 - round_los\u001b[A\n",
      "Training:  70%|▋| 28746/40960 [01:22<00:35, 346.46batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  70%|▋| 28820/40960 [01:22<00:34, 352.95batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  70%|▋| 28820/40960 [01:22<00:34, 352.95batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 28877/40960 [01:22<00:36, 332.58batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 28877/40960 [01:22<00:36, 332.58batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 28948/40960 [01:22<00:35, 338.08batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 28948/40960 [01:22<00:35, 338.08batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 29020/40960 [01:22<00:34, 344.50batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 29020/40960 [01:22<00:34, 344.50batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 29093/40960 [01:23<00:33, 350.46batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 29093/40960 [01:23<00:33, 350.46batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 29163/40960 [01:23<00:33, 349.28batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 29163/40960 [01:23<00:33, 349.28batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 29234/40960 [01:23<00:33, 349.25batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  71%|▋| 29234/40960 [01:23<00:33, 349.25batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29303/40960 [01:23<00:33, 346.71batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29303/40960 [01:23<00:33, 346.71batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29377/40960 [01:23<00:32, 352.88batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29377/40960 [01:23<00:32, 352.88batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29453/40960 [01:24<00:31, 359.76batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29453/40960 [01:24<00:31, 359.76batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29525/40960 [01:24<00:31, 359.48batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29525/40960 [01:24<00:31, 359.48batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29590/40960 [01:24<00:32, 347.80batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29590/40960 [01:24<00:32, 347.80batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29657/40960 [01:24<00:32, 343.71batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  72%|▋| 29657/40960 [01:24<00:32, 343.71batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 29732/40960 [01:24<00:31, 352.16batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 29732/40960 [01:24<00:31, 352.16batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 29806/40960 [01:25<00:31, 356.96batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 29806/40960 [01:25<00:31, 356.96batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 29875/40960 [01:25<00:31, 352.42batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 29875/40960 [01:25<00:31, 352.42batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 29948/40960 [01:25<00:30, 355.67batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 29948/40960 [01:25<00:30, 355.67batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 30019/40960 [01:25<00:30, 354.07batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 30019/40960 [01:25<00:30, 354.07batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 30088/40960 [01:25<00:30, 350.88batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  73%|▋| 30088/40960 [01:25<00:30, 350.88batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30160/40960 [01:26<00:30, 353.33batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30160/40960 [01:26<00:30, 353.33batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30235/40960 [01:26<00:29, 358.60batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30235/40960 [01:26<00:29, 358.60batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30307/40960 [01:26<00:29, 358.41batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30307/40960 [01:26<00:29, 358.41batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30378/40960 [01:26<00:29, 357.23batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30378/40960 [01:26<00:29, 357.23batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30453/40960 [01:26<00:29, 362.08batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30453/40960 [01:26<00:29, 362.08batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  75%|▋| 30527/40960 [01:27<00:28, 363.21batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  75%|▋| 30527/40960 [01:27<00:28, 363.21batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  75%|▋| 30590/40960 [01:27<00:29, 346.71batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  75%|▋| 30590/40960 [01:27<00:29, 346.71batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  75%|▋| 30648/40960 [01:27<00:31, 328.32batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  75%|▋| 30648/40960 [01:27<00:31, 328.32batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  75%|▊| 30721/40960 [01:27<00:30, 338.64batches/s, l2_loss: 0.0653 - round_los\u001b[A\n",
      "Training:  75%|▊| 30721/40960 [01:27<00:30, 338.64batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  75%|▊| 30796/40960 [01:27<00:29, 349.03batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  75%|▊| 30796/40960 [01:27<00:29, 349.03batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  75%|▊| 30870/40960 [01:28<00:28, 353.98batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  75%|▊| 30870/40960 [01:28<00:28, 353.98batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 30946/40960 [01:28<00:27, 360.37batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 30946/40960 [01:28<00:27, 360.37batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31020/40960 [01:28<00:27, 363.02batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31020/40960 [01:28<00:27, 363.02batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31091/40960 [01:28<00:27, 359.02batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31091/40960 [01:28<00:27, 359.02batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31162/40960 [01:28<00:27, 356.85batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31162/40960 [01:28<00:27, 356.85batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31234/40960 [01:29<00:27, 356.47batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31234/40960 [01:29<00:27, 356.47batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31307/40960 [01:29<00:27, 356.89batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  76%|▊| 31307/40960 [01:29<00:27, 356.89batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31366/40960 [01:29<00:28, 336.74batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31366/40960 [01:29<00:28, 336.74batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31426/40960 [01:29<00:29, 325.07batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31426/40960 [01:29<00:29, 325.07batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31498/40960 [01:29<00:28, 334.48batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31498/40960 [01:29<00:28, 334.48batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31570/40960 [01:30<00:27, 340.96batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31570/40960 [01:30<00:27, 340.96batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31642/40960 [01:30<00:26, 346.05batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31642/40960 [01:30<00:26, 346.05batches/s, l2_loss: 0.0654 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|▊| 31714/40960 [01:30<00:26, 349.60batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  77%|▊| 31714/40960 [01:30<00:26, 349.60batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 31784/40960 [01:30<00:26, 348.84batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 31784/40960 [01:30<00:26, 348.84batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  78%|▊| 31854/40960 [01:30<00:26, 348.32batches/s, l2_loss: 0.0654 - round_los\u001b[A\n",
      "Training:  78%|▊| 31854/40960 [01:30<00:26, 348.32batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 31927/40960 [01:31<00:25, 352.22batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 31927/40960 [01:31<00:25, 352.22batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 31997/40960 [01:31<00:25, 351.03batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 31997/40960 [01:31<00:25, 351.03batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 32067/40960 [01:31<00:25, 350.66batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 32067/40960 [01:31<00:25, 350.66batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 32141/40960 [01:31<00:24, 356.24batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  78%|▊| 32141/40960 [01:31<00:24, 356.24batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32209/40960 [01:31<00:24, 350.90batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32209/40960 [01:31<00:24, 350.90batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32275/40960 [01:32<00:25, 344.14batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32275/40960 [01:32<00:25, 344.14batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32348/40960 [01:32<00:24, 349.09batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32348/40960 [01:32<00:24, 349.09batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32420/40960 [01:32<00:24, 350.99batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32420/40960 [01:32<00:24, 350.99batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32489/40960 [01:32<00:24, 348.56batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  79%|▊| 32489/40960 [01:32<00:24, 348.56batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  80%|▊| 32564/40960 [01:32<00:23, 355.38batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  80%|▊| 32564/40960 [01:32<00:23, 355.38batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  80%|▊| 32634/40960 [01:33<00:23, 353.31batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  80%|▊| 32634/40960 [01:33<00:23, 353.31batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  80%|▊| 32704/40960 [01:33<00:23, 351.75batches/s, l2_loss: 0.0655 - round_los\u001b[A\n",
      "Training:  80%|▊| 32704/40960 [01:33<00:23, 351.75batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  80%|▊| 32775/40960 [01:33<00:23, 352.12batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  80%|▊| 32775/40960 [01:33<00:23, 352.12batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  80%|▊| 32848/40960 [01:33<00:22, 355.53batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  80%|▊| 32848/40960 [01:33<00:22, 355.53batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  80%|▊| 32916/40960 [01:34<00:23, 347.88batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  80%|▊| 32916/40960 [01:34<00:23, 347.88batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 32973/40960 [01:34<00:24, 328.56batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 32973/40960 [01:34<00:24, 328.56batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33014/40960 [01:34<00:27, 288.81batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33014/40960 [01:34<00:27, 288.81batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33059/40960 [01:34<00:29, 268.15batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33059/40960 [01:34<00:29, 268.15batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33124/40960 [01:34<00:27, 284.12batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33124/40960 [01:34<00:27, 284.12batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33199/40960 [01:35<00:24, 310.61batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33199/40960 [01:35<00:24, 310.61batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33265/40960 [01:35<00:24, 315.55batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33265/40960 [01:35<00:24, 315.55batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33328/40960 [01:35<00:24, 314.86batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  81%|▊| 33328/40960 [01:35<00:24, 314.86batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  82%|▊| 33392/40960 [01:35<00:24, 315.07batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  82%|▊| 33392/40960 [01:35<00:24, 315.07batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  82%|▊| 33466/40960 [01:35<00:22, 330.28batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  82%|▊| 33466/40960 [01:35<00:22, 330.28batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  82%|▊| 33539/40960 [01:36<00:21, 339.37batches/s, l2_loss: 0.0656 - round_los\u001b[A\n",
      "Training:  82%|▊| 33539/40960 [01:36<00:21, 339.37batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  82%|▊| 33611/40960 [01:36<00:21, 344.18batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  82%|▊| 33611/40960 [01:36<00:21, 344.18batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  82%|▊| 33683/40960 [01:36<00:20, 348.59batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  82%|▊| 33683/40960 [01:36<00:20, 348.59batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  82%|▊| 33755/40960 [01:36<00:20, 351.52batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  82%|▊| 33755/40960 [01:36<00:20, 351.52batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 33828/40960 [01:36<00:20, 354.44batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 33828/40960 [01:36<00:20, 354.44batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 33904/40960 [01:37<00:19, 360.89batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 33904/40960 [01:37<00:19, 360.89batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 33975/40960 [01:37<00:19, 358.96batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 33975/40960 [01:37<00:19, 358.96batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 34044/40960 [01:37<00:19, 354.52batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 34044/40960 [01:37<00:19, 354.52batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 34118/40960 [01:37<00:19, 357.73batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 34118/40960 [01:37<00:19, 357.73batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 34193/40960 [01:37<00:18, 361.75batches/s, l2_loss: 0.0657 - round_los\u001b[A\n",
      "Training:  83%|▊| 34193/40960 [01:37<00:18, 361.75batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34266/40960 [01:38<00:18, 362.05batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34266/40960 [01:38<00:18, 362.05batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34341/40960 [01:38<00:18, 365.12batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34341/40960 [01:38<00:18, 365.12batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34413/40960 [01:38<00:18, 361.85batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34413/40960 [01:38<00:18, 361.85batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34485/40960 [01:38<00:17, 360.12batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34485/40960 [01:38<00:17, 360.12batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34559/40960 [01:38<00:17, 361.37batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34559/40960 [01:38<00:17, 361.37batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34607/40960 [01:39<00:19, 322.95batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  84%|▊| 34607/40960 [01:39<00:19, 322.95batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  85%|▊| 34664/40960 [01:39<00:20, 311.10batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  85%|▊| 34664/40960 [01:39<00:20, 311.10batches/s, l2_loss: 0.0658 - round_los\u001b[A\n",
      "Training:  85%|▊| 34720/40960 [01:39<00:20, 300.26batches/s, l2_loss: 0.0658 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34720/40960 [01:39<00:20, 300.26batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  85%|▊| 34780/40960 [01:39<00:20, 298.45batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  85%|▊| 34780/40960 [01:39<00:20, 298.45batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  85%|▊| 34828/40960 [01:39<00:21, 280.65batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  85%|▊| 34828/40960 [01:39<00:21, 280.65batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  85%|▊| 34894/40960 [01:40<00:20, 294.74batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  85%|▊| 34894/40960 [01:40<00:20, 294.74batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  85%|▊| 34956/40960 [01:40<00:20, 299.22batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  85%|▊| 34956/40960 [01:40<00:20, 299.22batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35028/40960 [01:40<00:18, 315.91batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35028/40960 [01:40<00:18, 315.91batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35095/40960 [01:40<00:18, 321.48batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35095/40960 [01:40<00:18, 321.48batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35149/40960 [01:40<00:19, 303.56batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35149/40960 [01:40<00:19, 303.56batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35198/40960 [01:41<00:20, 284.05batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35198/40960 [01:41<00:20, 284.05batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35258/40960 [01:41<00:19, 288.59batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35258/40960 [01:41<00:19, 288.59batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35315/40960 [01:41<00:19, 286.31batches/s, l2_loss: 0.0659 - round_los\u001b[A\n",
      "Training:  86%|▊| 35315/40960 [01:41<00:19, 286.31batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35376/40960 [01:41<00:19, 290.78batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  86%|▊| 35376/40960 [01:41<00:19, 290.78batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35440/40960 [01:41<00:18, 298.68batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35440/40960 [01:41<00:18, 298.68batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35481/40960 [01:42<00:20, 269.27batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35481/40960 [01:42<00:20, 269.27batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35532/40960 [01:42<00:20, 263.82batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35532/40960 [01:42<00:20, 263.82batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35586/40960 [01:42<00:20, 264.90batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35586/40960 [01:42<00:20, 264.90batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35644/40960 [01:42<00:19, 271.78batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35644/40960 [01:42<00:19, 271.78batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35718/40960 [01:42<00:17, 299.81batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35718/40960 [01:42<00:17, 299.81batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35789/40960 [01:43<00:16, 315.58batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  87%|▊| 35789/40960 [01:43<00:16, 315.58batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  88%|▉| 35863/40960 [01:43<00:15, 330.60batches/s, l2_loss: 0.0660 - round_los\u001b[A\n",
      "Training:  88%|▉| 35863/40960 [01:43<00:15, 330.60batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 35930/40960 [01:43<00:15, 330.98batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 35930/40960 [01:43<00:15, 330.98batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 36004/40960 [01:43<00:14, 342.18batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 36004/40960 [01:43<00:14, 342.18batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 36076/40960 [01:43<00:14, 346.65batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 36076/40960 [01:43<00:14, 346.65batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 36145/40960 [01:44<00:13, 345.97batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 36145/40960 [01:44<00:13, 345.97batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 36216/40960 [01:44<00:13, 347.59batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  88%|▉| 36216/40960 [01:44<00:13, 347.59batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  89%|▉| 36286/40960 [01:44<00:13, 347.67batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  89%|▉| 36286/40960 [01:44<00:13, 347.67batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  89%|▉| 36352/40960 [01:44<00:13, 342.03batches/s, l2_loss: 0.0661 - round_los\u001b[A\n",
      "Training:  89%|▉| 36352/40960 [01:44<00:13, 342.03batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  89%|▉| 36425/40960 [01:44<00:13, 348.08batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  89%|▉| 36425/40960 [01:44<00:13, 348.08batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  89%|▉| 36493/40960 [01:45<00:12, 344.72batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  89%|▉| 36493/40960 [01:45<00:12, 344.72batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  89%|▉| 36552/40960 [01:45<00:13, 329.78batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  89%|▉| 36552/40960 [01:45<00:13, 329.78batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  89%|▉| 36617/40960 [01:45<00:13, 326.96batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  89%|▉| 36617/40960 [01:45<00:13, 326.96batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  90%|▉| 36682/40960 [01:45<00:13, 326.30batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  90%|▉| 36682/40960 [01:45<00:13, 326.30batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  90%|▉| 36752/40960 [01:45<00:12, 332.58batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  90%|▉| 36752/40960 [01:45<00:12, 332.58batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  90%|▉| 36823/40960 [01:46<00:12, 338.65batches/s, l2_loss: 0.0662 - round_los\u001b[A\n",
      "Training:  90%|▉| 36823/40960 [01:46<00:12, 338.65batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  90%|▉| 36893/40960 [01:46<00:11, 341.88batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  90%|▉| 36893/40960 [01:46<00:11, 341.88batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  90%|▉| 36963/40960 [01:46<00:11, 344.06batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  90%|▉| 36963/40960 [01:46<00:11, 344.06batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  90%|▉| 37032/40960 [01:46<00:11, 342.50batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  90%|▉| 37032/40960 [01:46<00:11, 342.50batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  91%|▉| 37099/40960 [01:46<00:11, 340.07batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  91%|▉| 37099/40960 [01:46<00:11, 340.07batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  91%|▉| 37170/40960 [01:47<00:11, 344.41batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  91%|▉| 37170/40960 [01:47<00:11, 344.41batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  91%|▉| 37243/40960 [01:47<00:10, 350.51batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  91%|▉| 37243/40960 [01:47<00:10, 350.51batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  91%|▉| 37309/40960 [01:47<00:10, 344.02batches/s, l2_loss: 0.0663 - round_los\u001b[A\n",
      "Training:  91%|▉| 37309/40960 [01:47<00:10, 344.02batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  91%|▉| 37357/40960 [01:47<00:11, 310.42batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  91%|▉| 37357/40960 [01:47<00:11, 310.42batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  91%|▉| 37398/40960 [01:47<00:12, 277.61batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  91%|▉| 37398/40960 [01:47<00:12, 277.61batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  91%|▉| 37455/40960 [01:48<00:12, 279.67batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  91%|▉| 37455/40960 [01:48<00:12, 279.67batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  92%|▉| 37520/40960 [01:48<00:11, 292.51batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  92%|▉| 37520/40960 [01:48<00:11, 292.51batches/s, l2_loss: 0.0664 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37593/40960 [01:48<00:10, 313.88batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  92%|▉| 37593/40960 [01:48<00:10, 313.88batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  92%|▉| 37666/40960 [01:48<00:10, 329.05batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  92%|▉| 37666/40960 [01:48<00:10, 329.05batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  92%|▉| 37738/40960 [01:48<00:09, 337.78batches/s, l2_loss: 0.0664 - round_los\u001b[A\n",
      "Training:  92%|▉| 37738/40960 [01:48<00:09, 337.78batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  92%|▉| 37807/40960 [01:49<00:09, 339.71batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  92%|▉| 37807/40960 [01:49<00:09, 339.71batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  92%|▉| 37880/40960 [01:49<00:08, 346.63batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  92%|▉| 37880/40960 [01:49<00:08, 346.63batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  93%|▉| 37953/40960 [01:49<00:08, 351.91batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  93%|▉| 37953/40960 [01:49<00:08, 351.91batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  93%|▉| 38021/40960 [01:49<00:08, 347.31batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  93%|▉| 38021/40960 [01:49<00:08, 347.31batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  93%|▉| 38088/40960 [01:49<00:08, 343.15batches/s, l2_loss: 0.0665 - round_los\u001b[A\n",
      "Training:  93%|▉| 38088/40960 [01:49<00:08, 343.15batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  93%|▉| 38157/40960 [01:50<00:08, 342.53batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  93%|▉| 38157/40960 [01:50<00:08, 342.53batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  93%|▉| 38225/40960 [01:50<00:08, 340.45batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  93%|▉| 38225/40960 [01:50<00:08, 340.45batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  93%|▉| 38290/40960 [01:50<00:07, 335.52batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  93%|▉| 38290/40960 [01:50<00:07, 335.52batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38354/40960 [01:50<00:07, 330.22batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38354/40960 [01:50<00:07, 330.22batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [01:50<00:07, 336.06batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38424/40960 [01:50<00:07, 336.06batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38493/40960 [01:51<00:07, 338.57batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38493/40960 [01:51<00:07, 338.57batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38564/40960 [01:51<00:07, 341.96batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38564/40960 [01:51<00:07, 341.96batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38634/40960 [01:51<00:06, 343.94batches/s, l2_loss: 0.0666 - round_los\u001b[A\n",
      "Training:  94%|▉| 38634/40960 [01:51<00:06, 343.94batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  94%|▉| 38696/40960 [01:51<00:06, 333.40batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  94%|▉| 38696/40960 [01:51<00:06, 333.40batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 38758/40960 [01:51<00:06, 325.70batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 38758/40960 [01:51<00:06, 325.70batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 38827/40960 [01:52<00:06, 330.52batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 38827/40960 [01:52<00:06, 330.52batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 38899/40960 [01:52<00:06, 339.32batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 38899/40960 [01:52<00:06, 339.32batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 38971/40960 [01:52<00:05, 344.91batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 38971/40960 [01:52<00:05, 344.91batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 39045/40960 [01:52<00:05, 351.60batches/s, l2_loss: 0.0667 - round_los\u001b[A\n",
      "Training:  95%|▉| 39045/40960 [01:52<00:05, 351.60batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39119/40960 [01:52<00:05, 356.71batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39119/40960 [01:52<00:05, 356.71batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39191/40960 [01:53<00:04, 356.90batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39191/40960 [01:53<00:04, 356.90batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39253/40960 [01:53<00:04, 342.06batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39253/40960 [01:53<00:04, 342.06batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39320/40960 [01:53<00:04, 338.79batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39320/40960 [01:53<00:04, 338.79batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39378/40960 [01:53<00:04, 323.66batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39378/40960 [01:53<00:04, 323.66batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39445/40960 [01:53<00:04, 326.26batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39445/40960 [01:53<00:04, 326.26batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39515/40960 [01:54<00:04, 332.38batches/s, l2_loss: 0.0668 - round_los\u001b[A\n",
      "Training:  96%|▉| 39515/40960 [01:54<00:04, 332.38batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39585/40960 [01:54<00:04, 337.37batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39585/40960 [01:54<00:04, 337.37batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39652/40960 [01:54<00:03, 335.67batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39652/40960 [01:54<00:03, 335.67batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39722/40960 [01:54<00:03, 339.30batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39722/40960 [01:54<00:03, 339.30batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39785/40960 [01:54<00:03, 331.51batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39785/40960 [01:54<00:03, 331.51batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39855/40960 [01:55<00:03, 337.01batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39855/40960 [01:55<00:03, 337.01batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39928/40960 [01:55<00:02, 344.63batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  97%|▉| 39928/40960 [01:55<00:02, 344.63batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  98%|▉| 39998/40960 [01:55<00:02, 345.70batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  98%|▉| 39998/40960 [01:55<00:02, 345.70batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  98%|▉| 40066/40960 [01:55<00:02, 342.93batches/s, l2_loss: 0.0669 - round_los\u001b[A\n",
      "Training:  98%|▉| 40066/40960 [01:55<00:02, 342.93batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  98%|▉| 40134/40960 [01:55<00:02, 341.91batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  98%|▉| 40134/40960 [01:55<00:02, 341.91batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  98%|▉| 40195/40960 [01:56<00:02, 330.25batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  98%|▉| 40195/40960 [01:56<00:02, 330.25batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  98%|▉| 40263/40960 [01:56<00:02, 332.93batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  98%|▉| 40263/40960 [01:56<00:02, 332.93batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  98%|▉| 40337/40960 [01:56<00:01, 343.66batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  98%|▉| 40337/40960 [01:56<00:01, 343.66batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  99%|▉| 40410/40960 [01:56<00:01, 349.25batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  99%|▉| 40410/40960 [01:56<00:01, 349.25batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  99%|▉| 40484/40960 [01:56<00:01, 354.16batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  99%|▉| 40484/40960 [01:56<00:01, 354.16batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  99%|▉| 40556/40960 [01:57<00:01, 354.84batches/s, l2_loss: 0.0670 - round_los\u001b[A\n",
      "Training:  99%|▉| 40556/40960 [01:57<00:01, 354.84batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  99%|▉| 40631/40960 [01:57<00:00, 359.56batches/s, l2_loss: 0.0671 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|▉| 40631/40960 [01:57<00:00, 359.56batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  99%|▉| 40699/40960 [01:57<00:00, 352.61batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training:  99%|▉| 40699/40960 [01:57<00:00, 352.61batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training: 100%|▉| 40770/40960 [01:57<00:00, 351.63batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training: 100%|▉| 40770/40960 [01:57<00:00, 351.63batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training: 100%|▉| 40842/40960 [01:58<00:00, 353.20batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training: 100%|▉| 40842/40960 [01:58<00:00, 353.20batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training: 100%|▉| 40914/40960 [01:58<00:00, 353.54batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "Training: 100%|▉| 40914/40960 [01:58<00:00, 353.54batches/s, l2_loss: 0.0671 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:32:25.457132: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  81%|▊| 21/26 [44:46<10:51, 130.40s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:32:27.339334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:32:29.842816: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                                | 1/40960 [00:00<9:41:52,  1.17batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<9:41:52,  1.17batches/s, l2_loss: 0.0116 - round_loss: \u001b[A\n",
      "Training:   0%| | 96/40960 [00:01<05:40, 120.00batches/s, l2_loss: 0.0116 - round_loss: \u001b[A\n",
      "Training:   0%| | 96/40960 [00:01<05:40, 120.00batches/s, l2_loss: 0.0204 - round_loss: \u001b[A\n",
      "Training:   0%| | 189/40960 [00:01<03:13, 210.92batches/s, l2_loss: 0.0204 - round_loss:\u001b[A\n",
      "Training:   0%| | 189/40960 [00:01<03:13, 210.92batches/s, l2_loss: 0.0197 - round_loss:\u001b[A\n",
      "Training:   1%| | 282/40960 [00:01<02:25, 280.42batches/s, l2_loss: 0.0197 - round_loss:\u001b[A\n",
      "Training:   1%| | 282/40960 [00:01<02:25, 280.42batches/s, l2_loss: 0.0204 - round_loss:\u001b[A\n",
      "Training:   1%| | 374/40960 [00:01<02:02, 330.62batches/s, l2_loss: 0.0204 - round_loss:\u001b[A\n",
      "Training:   1%| | 374/40960 [00:01<02:02, 330.62batches/s, l2_loss: 0.0205 - round_loss:\u001b[A\n",
      "Training:   1%| | 467/40960 [00:01<01:49, 368.13batches/s, l2_loss: 0.0205 - round_loss:\u001b[A\n",
      "Training:   1%| | 467/40960 [00:01<01:49, 368.13batches/s, l2_loss: 0.0207 - round_loss:\u001b[A\n",
      "Training:   1%| | 562/40960 [00:02<01:41, 398.33batches/s, l2_loss: 0.0207 - round_loss:\u001b[A\n",
      "Training:   1%| | 562/40960 [00:02<01:41, 398.33batches/s, l2_loss: 0.0210 - round_loss:\u001b[A\n",
      "Training:   2%| | 655/40960 [00:02<01:36, 416.60batches/s, l2_loss: 0.0210 - round_loss:\u001b[A\n",
      "Training:   2%| | 655/40960 [00:02<01:36, 416.60batches/s, l2_loss: 0.0204 - round_loss:\u001b[A\n",
      "Training:   2%| | 746/40960 [00:02<01:34, 426.69batches/s, l2_loss: 0.0204 - round_loss:\u001b[A\n",
      "Training:   2%| | 746/40960 [00:02<01:34, 426.69batches/s, l2_loss: 0.0200 - round_loss:\u001b[A\n",
      "Training:   2%| | 836/40960 [00:02<01:32, 432.64batches/s, l2_loss: 0.0200 - round_loss:\u001b[A\n",
      "Training:   2%| | 836/40960 [00:02<01:32, 432.64batches/s, l2_loss: 0.0203 - round_loss:\u001b[A\n",
      "Training:   2%| | 929/40960 [00:02<01:30, 441.43batches/s, l2_loss: 0.0203 - round_loss:\u001b[A\n",
      "Training:   2%| | 929/40960 [00:02<01:30, 441.43batches/s, l2_loss: 0.0202 - round_loss:\u001b[A\n",
      "Training:   2%| | 1021/40960 [00:03<01:29, 445.82batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   2%| | 1021/40960 [00:03<01:29, 445.82batches/s, l2_loss: 0.0204 - round_loss\u001b[A\n",
      "Training:   3%| | 1113/40960 [00:03<01:28, 449.97batches/s, l2_loss: 0.0204 - round_loss\u001b[A\n",
      "Training:   3%| | 1113/40960 [00:03<01:28, 449.97batches/s, l2_loss: 0.0204 - round_loss\u001b[A\n",
      "Training:   3%| | 1206/40960 [00:03<01:27, 454.42batches/s, l2_loss: 0.0204 - round_loss\u001b[A\n",
      "Training:   3%| | 1206/40960 [00:03<01:27, 454.42batches/s, l2_loss: 0.0204 - round_loss\u001b[A\n",
      "Training:   3%| | 1301/40960 [00:03<01:26, 460.05batches/s, l2_loss: 0.0204 - round_loss\u001b[A\n",
      "Training:   3%| | 1301/40960 [00:03<01:26, 460.05batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   3%| | 1393/40960 [00:03<01:26, 459.77batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   3%| | 1393/40960 [00:03<01:26, 459.77batches/s, l2_loss: 0.0203 - round_loss\u001b[A\n",
      "Training:   4%| | 1487/40960 [00:04<01:25, 461.78batches/s, l2_loss: 0.0203 - round_loss\u001b[A\n",
      "Training:   4%| | 1487/40960 [00:04<01:25, 461.78batches/s, l2_loss: 0.0203 - round_loss\u001b[A\n",
      "Training:   4%| | 1582/40960 [00:04<01:24, 465.23batches/s, l2_loss: 0.0203 - round_loss\u001b[A\n",
      "Training:   4%| | 1582/40960 [00:04<01:24, 465.23batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   4%| | 1671/40960 [00:04<01:25, 458.94batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   4%| | 1671/40960 [00:04<01:25, 458.94batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   4%| | 1760/40960 [00:04<01:26, 453.86batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   4%| | 1760/40960 [00:04<01:26, 453.86batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   5%| | 1852/40960 [00:04<01:25, 455.70batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   5%| | 1852/40960 [00:04<01:25, 455.70batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   5%| | 1946/40960 [00:05<01:24, 459.02batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   5%| | 1946/40960 [00:05<01:24, 459.02batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   5%| | 2037/40960 [00:05<01:25, 456.66batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   5%| | 2037/40960 [00:05<01:25, 456.66batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   5%| | 2130/40960 [00:05<01:24, 458.70batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   5%| | 2130/40960 [00:05<01:24, 458.70batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   5%| | 2224/40960 [00:05<01:23, 461.82batches/s, l2_loss: 0.0202 - round_loss\u001b[A\n",
      "Training:   5%| | 2224/40960 [00:05<01:23, 461.82batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   6%| | 2318/40960 [00:05<01:23, 462.88batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   6%| | 2318/40960 [00:05<01:23, 462.88batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   6%| | 2410/40960 [00:06<01:23, 461.83batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   6%| | 2410/40960 [00:06<01:23, 461.83batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   6%| | 2502/40960 [00:06<01:23, 460.21batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   6%| | 2502/40960 [00:06<01:23, 460.21batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   6%| | 2594/40960 [00:06<01:23, 459.46batches/s, l2_loss: 0.0201 - round_loss\u001b[A\n",
      "Training:   6%| | 2594/40960 [00:06<01:23, 459.46batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 2684/40960 [00:06<01:23, 456.27batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 2684/40960 [00:06<01:23, 456.27batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 2777/40960 [00:06<01:23, 457.92batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 2777/40960 [00:06<01:23, 457.92batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 2870/40960 [00:07<01:22, 459.93batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 2870/40960 [00:07<01:22, 459.93batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 2964/40960 [00:07<01:22, 461.67batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 2964/40960 [00:07<01:22, 461.67batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   7%| | 3058/40960 [00:07<01:21, 462.94batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 3058/40960 [00:07<01:21, 462.94batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   8%| | 3151/40960 [00:07<01:21, 463.10batches/s, l2_loss: 0.0200 - round_loss\u001b[A\n",
      "Training:   8%| | 3151/40960 [00:07<01:21, 463.10batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   8%| | 3243/40960 [00:07<01:21, 461.43batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   8%| | 3243/40960 [00:07<01:21, 461.43batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   8%| | 3334/40960 [00:08<01:22, 458.46batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   8%| | 3334/40960 [00:08<01:22, 458.46batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   8%| | 3427/40960 [00:08<01:21, 459.87batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   8%| | 3427/40960 [00:08<01:21, 459.87batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   9%| | 3518/40960 [00:08<01:21, 457.50batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   9%| | 3518/40960 [00:08<01:21, 457.50batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   9%| | 3610/40960 [00:08<01:21, 457.25batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   9%| | 3610/40960 [00:08<01:21, 457.25batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   9%| | 3702/40960 [00:08<01:21, 458.01batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   9%| | 3702/40960 [00:08<01:21, 458.01batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   9%| | 3796/40960 [00:09<01:20, 460.93batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:   9%| | 3796/40960 [00:09<01:20, 460.93batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   9%| | 3887/40960 [00:09<01:20, 458.72batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:   9%| | 3887/40960 [00:09<01:20, 458.72batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:  10%| | 3981/40960 [00:09<01:20, 460.98batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:  10%| | 3981/40960 [00:09<01:20, 460.98batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:  10%| | 4075/40960 [00:09<01:19, 463.64batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:  10%| | 4075/40960 [00:09<01:19, 463.64batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:  10%| | 4165/40960 [00:09<01:20, 458.50batches/s, l2_loss: 0.0199 - round_loss\u001b[A\n",
      "Training:  10%| | 4165/40960 [00:09<01:20, 458.50batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  10%| | 4255/40960 [00:10<01:20, 455.74batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  10%| | 4255/40960 [00:10<01:20, 455.74batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:  11%| | 4345/40960 [00:10<01:20, 453.64batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:  11%| | 4345/40960 [00:10<01:20, 453.64batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:  11%| | 4437/40960 [00:10<01:20, 455.09batches/s, l2_loss: 0.0198 - round_loss\u001b[A\n",
      "Training:  11%| | 4437/40960 [00:10<01:20, 455.09batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  11%| | 4528/40960 [00:10<01:20, 455.02batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  11%| | 4528/40960 [00:10<01:20, 455.02batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  11%| | 4620/40960 [00:10<01:19, 456.35batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  11%| | 4620/40960 [00:10<01:19, 456.35batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 4714/40960 [00:11<01:18, 459.39batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 4714/40960 [00:11<01:18, 459.39batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 4807/40960 [00:11<01:18, 460.93batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 4807/40960 [00:11<01:18, 460.93batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 4899/40960 [00:11<01:18, 459.68batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 4899/40960 [00:11<01:18, 459.68batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 4989/40960 [00:11<01:18, 455.90batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 4989/40960 [00:11<01:18, 455.90batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 5083/40960 [00:11<01:18, 459.80batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  12%| | 5083/40960 [00:11<01:18, 459.80batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5176/40960 [00:12<01:17, 461.28batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5176/40960 [00:12<01:17, 461.28batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5269/40960 [00:12<01:17, 462.28batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5269/40960 [00:12<01:17, 462.28batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5360/40960 [00:12<01:17, 458.88batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5360/40960 [00:12<01:17, 458.88batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5452/40960 [00:12<01:17, 458.71batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5452/40960 [00:12<01:17, 458.71batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5547/40960 [00:12<01:16, 462.33batches/s, l2_loss: 0.0197 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5547/40960 [00:12<01:16, 462.33batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5640/40960 [00:13<01:16, 462.35batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5640/40960 [00:13<01:16, 462.35batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5729/40960 [00:13<01:17, 457.04batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5729/40960 [00:13<01:17, 457.04batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5819/40960 [00:13<01:17, 454.55batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5819/40960 [00:13<01:17, 454.55batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5914/40960 [00:13<01:16, 460.32batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5914/40960 [00:13<01:16, 460.32batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6007/40960 [00:13<01:15, 461.22batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6007/40960 [00:13<01:15, 461.22batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6101/40960 [00:14<01:15, 463.03batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6101/40960 [00:14<01:15, 463.03batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6194/40960 [00:14<01:15, 463.44batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6194/40960 [00:14<01:15, 463.44batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6284/40960 [00:14<01:15, 459.35batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6284/40960 [00:14<01:15, 459.35batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6377/40960 [00:14<01:15, 460.35batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6377/40960 [00:14<01:15, 460.35batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6470/40960 [00:14<01:14, 461.22batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6470/40960 [00:14<01:14, 461.22batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6565/40960 [00:15<01:14, 464.15batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6565/40960 [00:15<01:14, 464.15batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6657/40960 [00:15<01:14, 462.31batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6657/40960 [00:15<01:14, 462.31batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6751/40960 [00:15<01:13, 463.41batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6751/40960 [00:15<01:13, 463.41batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6844/40960 [00:15<01:13, 463.31batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6844/40960 [00:15<01:13, 463.31batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6937/40960 [00:15<01:13, 462.80batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6937/40960 [00:15<01:13, 462.80batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7029/40960 [00:16<01:13, 460.89batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7029/40960 [00:16<01:13, 460.89batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7121/40960 [00:16<01:13, 459.27batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7121/40960 [00:16<01:13, 459.27batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|▏| 7214/40960 [00:16<01:13, 460.21batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7214/40960 [00:16<01:13, 460.21batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7307/40960 [00:16<01:12, 461.38batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7307/40960 [00:16<01:12, 461.38batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7398/40960 [00:16<01:13, 458.29batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7398/40960 [00:16<01:13, 458.29batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7489/40960 [00:17<01:13, 457.12batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7489/40960 [00:17<01:13, 457.12batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7580/40960 [00:17<01:13, 455.06batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7580/40960 [00:17<01:13, 455.06batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7667/40960 [00:17<01:14, 448.26batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7667/40960 [00:17<01:14, 448.26batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7760/40960 [00:17<01:13, 452.03batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7760/40960 [00:17<01:13, 452.03batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7852/40960 [00:17<01:13, 453.50batches/s, l2_loss: 0.0195 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7852/40960 [00:17<01:13, 453.50batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7946/40960 [00:18<01:12, 457.14batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7946/40960 [00:18<01:12, 457.14batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8039/40960 [00:18<01:11, 459.20batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8039/40960 [00:18<01:11, 459.20batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8133/40960 [00:18<01:11, 461.07batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8133/40960 [00:18<01:11, 461.07batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8221/40960 [00:18<01:12, 454.49batches/s, l2_loss: 0.0194 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8221/40960 [00:18<01:12, 454.49batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8307/40960 [00:18<01:13, 446.26batches/s, l2_loss: 0.0196 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8307/40960 [00:18<01:13, 446.26batches/s, l2_loss: 0.0193 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8389/40960 [00:19<01:14, 435.03batches/s, l2_loss: 0.0193 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8389/40960 [00:19<01:14, 435.03batches/s, l2_loss: 0.0184 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8474/40960 [00:19<01:15, 430.77batches/s, l2_loss: 0.0184 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8474/40960 [00:19<01:15, 430.77batches/s, l2_loss: 0.0183 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8558/40960 [00:19<01:15, 426.45batches/s, l2_loss: 0.0183 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8558/40960 [00:19<01:15, 426.45batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8644/40960 [00:19<01:15, 426.18batches/s, l2_loss: 0.0188 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8644/40960 [00:19<01:15, 426.18batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8726/40960 [00:19<01:16, 419.97batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8726/40960 [00:19<01:16, 419.97batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8810/40960 [00:20<01:16, 418.76batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8810/40960 [00:20<01:16, 418.76batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8890/40960 [00:20<01:17, 412.68batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8890/40960 [00:20<01:17, 412.68batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8971/40960 [00:20<01:17, 410.32batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8971/40960 [00:20<01:17, 410.32batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9052/40960 [00:20<01:18, 408.73batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9052/40960 [00:20<01:18, 408.73batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9134/40960 [00:20<01:17, 408.74batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9134/40960 [00:20<01:17, 408.74batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9216/40960 [00:21<01:17, 408.77batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9216/40960 [00:21<01:17, 408.77batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9298/40960 [00:21<01:17, 408.74batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9298/40960 [00:21<01:17, 408.74batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9382/40960 [00:21<01:16, 411.30batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9382/40960 [00:21<01:16, 411.30batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9465/40960 [00:21<01:16, 412.38batches/s, l2_loss: 0.0185 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9465/40960 [00:21<01:16, 412.38batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9550/40960 [00:21<01:15, 416.00batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9550/40960 [00:21<01:15, 416.00batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9631/40960 [00:22<01:15, 412.48batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9631/40960 [00:22<01:15, 412.48batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9716/40960 [00:22<01:15, 415.80batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9716/40960 [00:22<01:15, 415.80batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9800/40960 [00:22<01:14, 416.48batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9800/40960 [00:22<01:14, 416.48batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9883/40960 [00:22<01:14, 415.10batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9883/40960 [00:22<01:14, 415.10batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9967/40960 [00:22<01:14, 415.67batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9967/40960 [00:22<01:14, 415.67batches/s, l2_loss: 0.0186 - round_loss\u001b[A\n",
      "Training:  25%|▏| 10053/40960 [00:23<01:13, 419.67batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▏| 10053/40960 [00:23<01:13, 419.67batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▏| 10136/40960 [00:23<01:13, 416.83batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▏| 10136/40960 [00:23<01:13, 416.83batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▏| 10213/40960 [00:23<01:15, 406.95batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▏| 10213/40960 [00:23<01:15, 406.95batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▎| 10297/40960 [00:23<01:14, 409.97batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▎| 10297/40960 [00:23<01:14, 409.97batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▎| 10381/40960 [00:23<01:14, 411.56batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  25%|▎| 10381/40960 [00:23<01:14, 411.56batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10463/40960 [00:24<01:14, 410.32batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10463/40960 [00:24<01:14, 410.32batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10546/40960 [00:24<01:14, 410.90batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10546/40960 [00:24<01:14, 410.90batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10632/40960 [00:24<01:12, 415.51batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10632/40960 [00:24<01:12, 415.51batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10715/40960 [00:24<01:12, 414.36batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10715/40960 [00:24<01:12, 414.36batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10800/40960 [00:24<01:12, 416.47batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  26%|▎| 10800/40960 [00:24<01:12, 416.47batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 10884/40960 [00:25<01:12, 417.08batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 10884/40960 [00:25<01:12, 417.08batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 10968/40960 [00:25<01:11, 417.15batches/s, l2_loss: 0.0186 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|▎| 10968/40960 [00:25<01:11, 417.15batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11051/40960 [00:25<01:11, 415.99batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11051/40960 [00:25<01:11, 415.99batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11136/40960 [00:25<01:11, 417.96batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11136/40960 [00:25<01:11, 417.96batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11220/40960 [00:25<01:11, 418.09batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  27%|▎| 11220/40960 [00:25<01:11, 418.09batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11302/40960 [00:26<01:11, 414.41batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11302/40960 [00:26<01:11, 414.41batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11382/40960 [00:26<01:12, 409.09batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11382/40960 [00:26<01:12, 409.09batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11468/40960 [00:26<01:11, 414.62batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11468/40960 [00:26<01:11, 414.62batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11549/40960 [00:26<01:11, 411.02batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11549/40960 [00:26<01:11, 411.02batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11633/40960 [00:26<01:10, 413.14batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  28%|▎| 11633/40960 [00:26<01:10, 413.14batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 11716/40960 [00:27<01:10, 413.18batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 11716/40960 [00:27<01:10, 413.18batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 11802/40960 [00:27<01:09, 418.08batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 11802/40960 [00:27<01:09, 418.08batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 11888/40960 [00:27<01:09, 420.90batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 11888/40960 [00:27<01:09, 420.90batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 11972/40960 [00:27<01:09, 419.62batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  29%|▎| 11972/40960 [00:27<01:09, 419.62batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  29%|▎| 12052/40960 [00:27<01:09, 412.98batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  29%|▎| 12052/40960 [00:27<01:09, 412.98batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  30%|▎| 12135/40960 [00:28<01:09, 413.54batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  30%|▎| 12135/40960 [00:28<01:09, 413.54batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  30%|▎| 12220/40960 [00:28<01:09, 415.66batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  30%|▎| 12220/40960 [00:28<01:09, 415.66batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  30%|▎| 12301/40960 [00:28<01:09, 412.03batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  30%|▎| 12301/40960 [00:28<01:09, 412.03batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  30%|▎| 12379/40960 [00:28<01:10, 405.06batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  30%|▎| 12379/40960 [00:28<01:10, 405.06batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  30%|▎| 12466/40960 [00:28<01:08, 413.04batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  30%|▎| 12466/40960 [00:29<01:08, 413.04batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  31%|▎| 12548/40960 [00:29<01:09, 410.83batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  31%|▎| 12548/40960 [00:29<01:09, 410.83batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12632/40960 [00:29<01:08, 412.28batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12632/40960 [00:29<01:08, 412.28batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12714/40960 [00:29<01:08, 410.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12714/40960 [00:29<01:08, 410.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12798/40960 [00:29<01:08, 412.46batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12798/40960 [00:29<01:08, 412.46batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12881/40960 [00:30<01:07, 413.02batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  31%|▎| 12881/40960 [00:30<01:07, 413.02batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  32%|▎| 12966/40960 [00:30<01:07, 415.53batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  32%|▎| 12966/40960 [00:30<01:07, 415.53batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  32%|▎| 13046/40960 [00:30<01:08, 410.21batches/s, l2_loss: 0.0186 - round_los\u001b[A\n",
      "Training:  32%|▎| 13046/40960 [00:30<01:08, 410.21batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13130/40960 [00:30<01:07, 413.11batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13130/40960 [00:30<01:07, 413.11batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13211/40960 [00:30<01:07, 410.60batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13211/40960 [00:30<01:07, 410.60batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13294/40960 [00:31<01:07, 411.72batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  32%|▎| 13294/40960 [00:31<01:07, 411.72batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13373/40960 [00:31<01:08, 405.10batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13373/40960 [00:31<01:08, 405.10batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13453/40960 [00:31<01:08, 402.72batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13453/40960 [00:31<01:08, 402.72batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13535/40960 [00:31<01:07, 403.81batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13535/40960 [00:31<01:07, 403.81batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13618/40960 [00:31<01:07, 406.56batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13618/40960 [00:31<01:07, 406.56batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13703/40960 [00:32<01:06, 411.61batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  33%|▎| 13703/40960 [00:32<01:06, 411.61batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 13789/40960 [00:32<01:05, 416.34batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 13789/40960 [00:32<01:05, 416.34batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 13871/40960 [00:32<01:05, 414.19batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 13871/40960 [00:32<01:05, 414.19batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 13954/40960 [00:32<01:05, 413.96batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 13954/40960 [00:32<01:05, 413.96batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 14035/40960 [00:32<01:05, 410.70batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 14035/40960 [00:32<01:05, 410.70batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 14116/40960 [00:33<01:05, 408.05batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  34%|▎| 14116/40960 [00:33<01:05, 408.05batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14196/40960 [00:33<01:05, 405.52batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14196/40960 [00:33<01:05, 405.52batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14277/40960 [00:33<01:05, 404.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14277/40960 [00:33<01:05, 404.69batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14359/40960 [00:33<01:05, 404.84batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14359/40960 [00:33<01:05, 404.84batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14439/40960 [00:33<01:05, 403.18batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14439/40960 [00:33<01:05, 403.18batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14523/40960 [00:34<01:05, 406.63batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  35%|▎| 14523/40960 [00:34<01:05, 406.63batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14607/40960 [00:34<01:04, 409.86batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14607/40960 [00:34<01:04, 409.86batches/s, l2_loss: 0.0185 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|▎| 14691/40960 [00:34<01:03, 411.66batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14691/40960 [00:34<01:03, 411.66batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14770/40960 [00:34<01:04, 405.92batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14770/40960 [00:34<01:04, 405.92batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14851/40960 [00:34<01:04, 405.01batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14851/40960 [00:34<01:04, 405.01batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14931/40960 [00:35<01:04, 402.20batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  36%|▎| 14931/40960 [00:35<01:04, 402.20batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15013/40960 [00:35<01:04, 404.16batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15013/40960 [00:35<01:04, 404.16batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15094/40960 [00:35<01:04, 403.50batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15094/40960 [00:35<01:04, 403.50batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15176/40960 [00:35<01:03, 405.31batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15176/40960 [00:35<01:03, 405.31batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15256/40960 [00:35<01:03, 403.50batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15256/40960 [00:35<01:03, 403.50batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15340/40960 [00:36<01:02, 407.86batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  37%|▎| 15340/40960 [00:36<01:02, 407.86batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15425/40960 [00:36<01:01, 412.96batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15425/40960 [00:36<01:01, 412.96batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15508/40960 [00:36<01:01, 412.08batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15508/40960 [00:36<01:01, 412.08batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15588/40960 [00:36<01:02, 407.39batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15588/40960 [00:36<01:02, 407.39batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15674/40960 [00:36<01:01, 413.03batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15674/40960 [00:36<01:01, 413.03batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15758/40960 [00:37<01:00, 414.06batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  38%|▍| 15758/40960 [00:37<01:00, 414.06batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  39%|▍| 15842/40960 [00:37<01:00, 414.50batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  39%|▍| 15842/40960 [00:37<01:00, 414.50batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 15928/40960 [00:37<00:59, 418.12batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 15928/40960 [00:37<00:59, 418.12batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  39%|▍| 16011/40960 [00:37<00:59, 415.98batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  39%|▍| 16011/40960 [00:37<00:59, 415.98batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 16095/40960 [00:37<00:59, 415.96batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 16095/40960 [00:37<00:59, 415.96batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 16178/40960 [00:38<00:59, 415.15batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  39%|▍| 16178/40960 [00:38<00:59, 415.15batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  40%|▍| 16261/40960 [00:38<00:59, 414.77batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  40%|▍| 16261/40960 [00:38<00:59, 414.77batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16342/40960 [00:38<00:59, 411.19batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16342/40960 [00:38<00:59, 411.19batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16423/40960 [00:38<01:00, 408.41batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16423/40960 [00:38<01:00, 408.41batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16506/40960 [00:38<00:59, 410.29batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  40%|▍| 16506/40960 [00:38<00:59, 410.29batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16589/40960 [00:39<00:59, 411.62batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16589/40960 [00:39<00:59, 411.62batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  41%|▍| 16673/40960 [00:39<00:58, 413.45batches/s, l2_loss: 0.0185 - round_los\u001b[A\n",
      "Training:  41%|▍| 16673/40960 [00:39<00:58, 413.45batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16754/40960 [00:39<00:59, 409.60batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16754/40960 [00:39<00:59, 409.60batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16835/40960 [00:39<00:59, 407.66batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16835/40960 [00:39<00:59, 407.66batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16918/40960 [00:39<00:58, 408.91batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  41%|▍| 16918/40960 [00:39<00:58, 408.91batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17003/40960 [00:40<00:58, 412.93batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17003/40960 [00:40<00:58, 412.93batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17088/40960 [00:40<00:57, 416.34batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17088/40960 [00:40<00:57, 416.34batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17171/40960 [00:40<00:57, 414.66batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17171/40960 [00:40<00:57, 414.66batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17252/40960 [00:40<00:57, 411.42batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17252/40960 [00:40<00:57, 411.42batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17334/40960 [00:40<00:57, 410.38batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  42%|▍| 17334/40960 [00:40<00:57, 410.38batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17411/40960 [00:41<00:58, 402.70batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17411/40960 [00:41<00:58, 402.70batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17495/40960 [00:41<00:57, 406.83batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17495/40960 [00:41<00:57, 406.83batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17577/40960 [00:41<00:57, 406.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17577/40960 [00:41<00:57, 406.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17662/40960 [00:41<00:56, 411.41batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17662/40960 [00:41<00:56, 411.41batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17745/40960 [00:41<00:56, 410.79batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  43%|▍| 17745/40960 [00:41<00:56, 410.79batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17827/40960 [00:42<00:56, 409.58batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17827/40960 [00:42<00:56, 409.58batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17911/40960 [00:42<00:55, 412.62batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17911/40960 [00:42<00:55, 412.62batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17993/40960 [00:42<00:55, 410.62batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 17993/40960 [00:42<00:55, 410.62batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18074/40960 [00:42<00:56, 408.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18074/40960 [00:42<00:56, 408.46batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18157/40960 [00:42<00:55, 409.29batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  44%|▍| 18157/40960 [00:42<00:55, 409.29batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18240/40960 [00:43<00:55, 410.00batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18240/40960 [00:43<00:55, 410.00batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18324/40960 [00:43<00:54, 412.21batches/s, l2_loss: 0.0184 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 18324/40960 [00:43<00:54, 412.21batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18409/40960 [00:43<00:54, 415.67batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18409/40960 [00:43<00:54, 415.67batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18496/40960 [00:43<00:53, 420.43batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18496/40960 [00:43<00:53, 420.43batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18581/40960 [00:43<00:53, 421.59batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  45%|▍| 18581/40960 [00:43<00:53, 421.59batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18665/40960 [00:44<00:52, 420.80batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18665/40960 [00:44<00:52, 420.80batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18748/40960 [00:44<00:53, 417.87batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18748/40960 [00:44<00:53, 417.87batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18828/40960 [00:44<00:53, 412.34batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18828/40960 [00:44<00:53, 412.34batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18909/40960 [00:44<00:53, 409.78batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18909/40960 [00:44<00:53, 409.78batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18994/40960 [00:44<00:53, 414.04batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  46%|▍| 18994/40960 [00:44<00:53, 414.04batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19077/40960 [00:45<00:52, 413.39batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19077/40960 [00:45<00:52, 413.39batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19162/40960 [00:45<00:52, 416.61batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19162/40960 [00:45<00:52, 416.61batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19248/40960 [00:45<00:51, 419.49batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19248/40960 [00:45<00:51, 419.49batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19332/40960 [00:45<00:51, 419.55batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19332/40960 [00:45<00:51, 419.55batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19415/40960 [00:45<00:51, 416.85batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  47%|▍| 19415/40960 [00:45<00:51, 416.85batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19499/40960 [00:46<00:51, 417.00batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19499/40960 [00:46<00:51, 417.00batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19584/40960 [00:46<00:51, 418.08batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19584/40960 [00:46<00:51, 418.08batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19668/40960 [00:46<00:50, 418.11batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19668/40960 [00:46<00:50, 418.11batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19752/40960 [00:46<00:50, 417.28batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19752/40960 [00:46<00:50, 417.28batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19835/40960 [00:46<00:50, 416.05batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  48%|▍| 19835/40960 [00:46<00:50, 416.05batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 19918/40960 [00:47<00:50, 414.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 19918/40960 [00:47<00:50, 414.44batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20003/40960 [00:47<00:50, 417.12batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20003/40960 [00:47<00:50, 417.12batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20086/40960 [00:47<00:50, 415.02batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20086/40960 [00:47<00:50, 415.02batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20171/40960 [00:47<00:49, 417.18batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  49%|▍| 20171/40960 [00:47<00:49, 417.18batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  49%|▍| 20254/40960 [00:47<00:49, 415.92batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  49%|▍| 20254/40960 [00:47<00:49, 415.92batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▍| 20336/40960 [00:48<00:49, 414.04batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▍| 20336/40960 [00:48<00:49, 414.04batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  50%|▍| 20414/40960 [00:48<00:50, 406.76batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  50%|▍| 20414/40960 [00:48<00:50, 406.76batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▌| 20495/40960 [00:48<00:50, 405.09batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▌| 20495/40960 [00:48<00:50, 405.09batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  50%|▌| 20576/40960 [00:48<00:50, 403.77batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  50%|▌| 20576/40960 [00:48<00:50, 403.77batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▌| 20658/40960 [00:48<00:50, 404.32batches/s, l2_loss: 0.0184 - round_los\u001b[A\n",
      "Training:  50%|▌| 20658/40960 [00:48<00:50, 404.32batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 20742/40960 [00:49<00:49, 408.72batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 20742/40960 [00:49<00:49, 408.72batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 20825/40960 [00:49<00:49, 409.33batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 20825/40960 [00:49<00:49, 409.33batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 20911/40960 [00:49<00:48, 415.02batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 20911/40960 [00:49<00:48, 415.02batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 20995/40960 [00:49<00:48, 415.33batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 20995/40960 [00:49<00:48, 415.33batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 21078/40960 [00:49<00:47, 414.57batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  51%|▌| 21078/40960 [00:49<00:47, 414.57batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21156/40960 [00:50<00:48, 406.40batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21156/40960 [00:50<00:48, 406.40batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21240/40960 [00:50<00:48, 409.31batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21240/40960 [00:50<00:48, 409.31batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21323/40960 [00:50<00:47, 409.59batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21323/40960 [00:50<00:47, 409.59batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21408/40960 [00:50<00:47, 413.13batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21408/40960 [00:50<00:47, 413.13batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21493/40960 [00:50<00:46, 416.38batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  52%|▌| 21493/40960 [00:50<00:46, 416.38batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  53%|▌| 21579/40960 [00:51<00:46, 420.34batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  53%|▌| 21579/40960 [00:51<00:46, 420.34batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  53%|▌| 21664/40960 [00:51<00:45, 421.30batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  53%|▌| 21664/40960 [00:51<00:45, 421.30batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  53%|▌| 21745/40960 [00:51<00:46, 415.67batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  53%|▌| 21745/40960 [00:51<00:46, 415.67batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  53%|▌| 21831/40960 [00:51<00:45, 418.67batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  53%|▌| 21831/40960 [00:51<00:45, 418.67batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 21917/40960 [00:51<00:45, 421.20batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 21917/40960 [00:51<00:45, 421.20batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 22002/40960 [00:52<00:44, 422.26batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 22002/40960 [00:52<00:44, 422.26batches/s, l2_loss: 0.0183 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|▌| 22084/40960 [00:52<00:45, 417.85batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 22084/40960 [00:52<00:45, 417.85batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 22164/40960 [00:52<00:45, 412.32batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 22164/40960 [00:52<00:45, 412.32batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 22246/40960 [00:52<00:45, 410.20batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  54%|▌| 22246/40960 [00:52<00:45, 410.20batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22329/40960 [00:52<00:45, 410.29batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22329/40960 [00:52<00:45, 410.29batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22414/40960 [00:53<00:44, 414.23batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22414/40960 [00:53<00:44, 414.23batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22499/40960 [00:53<00:44, 416.79batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22499/40960 [00:53<00:44, 416.79batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22583/40960 [00:53<00:44, 417.19batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22583/40960 [00:53<00:44, 417.19batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22670/40960 [00:53<00:43, 421.14batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  55%|▌| 22670/40960 [00:53<00:43, 421.14batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 22755/40960 [00:53<00:43, 420.67batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 22755/40960 [00:53<00:43, 420.67batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 22840/40960 [00:54<00:43, 421.14batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 22840/40960 [00:54<00:43, 421.14batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 22926/40960 [00:54<00:42, 423.09batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 22926/40960 [00:54<00:42, 423.09batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 23011/40960 [00:54<00:42, 422.27batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 23011/40960 [00:54<00:42, 422.27batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 23095/40960 [00:54<00:42, 420.18batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  56%|▌| 23095/40960 [00:54<00:42, 420.18batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23178/40960 [00:54<00:42, 417.49batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23178/40960 [00:54<00:42, 417.49batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23257/40960 [00:55<00:43, 410.03batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23257/40960 [00:55<00:43, 410.03batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23342/40960 [00:55<00:42, 413.49batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23342/40960 [00:55<00:42, 413.49batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23427/40960 [00:55<00:42, 416.48batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23427/40960 [00:55<00:42, 416.48batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23511/40960 [00:55<00:41, 417.48batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  57%|▌| 23511/40960 [00:55<00:41, 417.48batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23596/40960 [00:55<00:41, 418.36batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23596/40960 [00:55<00:41, 418.36batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23681/40960 [00:56<00:41, 419.16batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23681/40960 [00:56<00:41, 419.16batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23765/40960 [00:56<00:41, 418.38batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23765/40960 [00:56<00:41, 418.38batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23849/40960 [00:56<00:40, 418.22batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23849/40960 [00:56<00:40, 418.22batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23935/40960 [00:56<00:40, 421.04batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  58%|▌| 23935/40960 [00:56<00:40, 421.04batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24021/40960 [00:56<00:40, 422.75batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24021/40960 [00:56<00:40, 422.75batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24105/40960 [00:57<00:39, 421.74batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24105/40960 [00:57<00:39, 421.74batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24189/40960 [00:57<00:39, 421.02batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24189/40960 [00:57<00:39, 421.02batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24271/40960 [00:57<00:40, 416.95batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24271/40960 [00:57<00:40, 416.95batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24357/40960 [00:57<00:39, 419.86batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  59%|▌| 24357/40960 [00:57<00:39, 419.86batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24443/40960 [00:57<00:39, 421.92batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24443/40960 [00:57<00:39, 421.92batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24525/40960 [00:58<00:39, 417.08batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24525/40960 [00:58<00:39, 417.08batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24609/40960 [00:58<00:39, 417.42batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24609/40960 [00:58<00:39, 417.42batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24693/40960 [00:58<00:38, 417.37batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24693/40960 [00:58<00:38, 417.37batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24778/40960 [00:58<00:38, 419.01batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  60%|▌| 24778/40960 [00:58<00:38, 419.01batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 24862/40960 [00:58<00:38, 418.95batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 24862/40960 [00:58<00:38, 418.95batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 24944/40960 [00:59<00:38, 415.11batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 24944/40960 [00:59<00:38, 415.11batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 25022/40960 [00:59<00:39, 406.59batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 25022/40960 [00:59<00:39, 406.59batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 25108/40960 [00:59<00:38, 412.67batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 25108/40960 [00:59<00:38, 412.67batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 25190/40960 [00:59<00:38, 411.66batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  61%|▌| 25190/40960 [00:59<00:38, 411.66batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  62%|▌| 25273/40960 [00:59<00:38, 412.27batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  62%|▌| 25273/40960 [00:59<00:38, 412.27batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  62%|▌| 25355/40960 [01:00<00:37, 410.68batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  62%|▌| 25355/40960 [01:00<00:37, 410.68batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  62%|▌| 25439/40960 [01:00<00:37, 412.77batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  62%|▌| 25439/40960 [01:00<00:37, 412.77batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  62%|▌| 25522/40960 [01:00<00:37, 412.66batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  62%|▌| 25522/40960 [01:00<00:37, 412.66batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  63%|▋| 25605/40960 [01:00<00:37, 413.18batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  63%|▋| 25605/40960 [01:00<00:37, 413.18batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  63%|▋| 25687/40960 [01:00<00:37, 411.80batches/s, l2_loss: 0.0183 - round_los\u001b[A\n",
      "Training:  63%|▋| 25687/40960 [01:01<00:37, 411.80batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  63%|▋| 25770/40960 [01:01<00:36, 411.41batches/s, l2_loss: 0.0182 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|▋| 25770/40960 [01:01<00:36, 411.41batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  63%|▋| 25855/40960 [01:01<00:36, 414.35batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  63%|▋| 25855/40960 [01:01<00:36, 414.35batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  63%|▋| 25939/40960 [01:01<00:36, 415.68batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  63%|▋| 25939/40960 [01:01<00:36, 415.68batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26022/40960 [01:01<00:35, 415.33batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26022/40960 [01:01<00:35, 415.33batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26108/40960 [01:02<00:35, 419.40batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26108/40960 [01:02<00:35, 419.40batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26192/40960 [01:02<00:35, 419.09batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26192/40960 [01:02<00:35, 419.09batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26276/40960 [01:02<00:35, 418.34batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26276/40960 [01:02<00:35, 418.34batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26362/40960 [01:02<00:34, 420.76batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  64%|▋| 26362/40960 [01:02<00:34, 420.76batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26447/40960 [01:02<00:34, 421.20batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26447/40960 [01:02<00:34, 421.20batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26532/40960 [01:03<00:34, 421.18batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26532/40960 [01:03<00:34, 421.18batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26619/40960 [01:03<00:33, 423.91batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26619/40960 [01:03<00:33, 423.91batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26702/40960 [01:03<00:33, 421.15batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26702/40960 [01:03<00:33, 421.15batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26785/40960 [01:03<00:33, 418.80batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  65%|▋| 26785/40960 [01:03<00:33, 418.80batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 26869/40960 [01:03<00:33, 418.25batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 26869/40960 [01:03<00:33, 418.25batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 26953/40960 [01:04<00:33, 418.71batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 26953/40960 [01:04<00:33, 418.71batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 27035/40960 [01:04<00:33, 415.93batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 27035/40960 [01:04<00:33, 415.93batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 27118/40960 [01:04<00:33, 415.50batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 27118/40960 [01:04<00:33, 415.50batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 27197/40960 [01:04<00:33, 409.19batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  66%|▋| 27197/40960 [01:04<00:33, 409.19batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27276/40960 [01:04<00:33, 404.54batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27276/40960 [01:04<00:33, 404.54batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27360/40960 [01:05<00:33, 409.06batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27360/40960 [01:05<00:33, 409.06batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27442/40960 [01:05<00:33, 408.17batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27442/40960 [01:05<00:33, 408.17batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27527/40960 [01:05<00:32, 412.93batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27527/40960 [01:05<00:32, 412.93batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27612/40960 [01:05<00:32, 415.50batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  67%|▋| 27612/40960 [01:05<00:32, 415.50batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 27694/40960 [01:05<00:32, 412.48batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 27694/40960 [01:05<00:32, 412.48batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 27774/40960 [01:06<00:32, 408.55batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 27774/40960 [01:06<00:32, 408.55batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 27854/40960 [01:06<00:32, 405.39batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 27854/40960 [01:06<00:32, 405.39batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 27938/40960 [01:06<00:31, 409.28batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 27938/40960 [01:06<00:31, 409.28batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 28021/40960 [01:06<00:31, 410.31batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  68%|▋| 28021/40960 [01:06<00:31, 410.31batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28102/40960 [01:06<00:31, 407.79batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28102/40960 [01:06<00:31, 407.79batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28182/40960 [01:07<00:31, 405.01batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28182/40960 [01:07<00:31, 405.01batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28264/40960 [01:07<00:31, 405.15batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28264/40960 [01:07<00:31, 405.15batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28347/40960 [01:07<00:30, 407.39batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28347/40960 [01:07<00:30, 407.39batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28429/40960 [01:07<00:30, 407.23batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  69%|▋| 28429/40960 [01:07<00:30, 407.23batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28513/40960 [01:07<00:30, 410.13batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28513/40960 [01:07<00:30, 410.13batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28597/40960 [01:08<00:29, 412.50batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28597/40960 [01:08<00:29, 412.50batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28680/40960 [01:08<00:29, 412.59batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28680/40960 [01:08<00:29, 412.59batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28765/40960 [01:08<00:29, 415.50batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28765/40960 [01:08<00:29, 415.50batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28850/40960 [01:08<00:28, 417.77batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  70%|▋| 28850/40960 [01:08<00:28, 417.77batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 28936/40960 [01:08<00:28, 419.95batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 28936/40960 [01:08<00:28, 419.95batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 29020/40960 [01:09<00:28, 419.16batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 29020/40960 [01:09<00:28, 419.16batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 29103/40960 [01:09<00:28, 416.83batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 29103/40960 [01:09<00:28, 416.83batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 29186/40960 [01:09<00:28, 415.98batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 29186/40960 [01:09<00:28, 415.98batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 29269/40960 [01:09<00:28, 414.49batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  71%|▋| 29269/40960 [01:09<00:28, 414.49batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29352/40960 [01:09<00:28, 413.41batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29352/40960 [01:09<00:28, 413.41batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29434/40960 [01:10<00:27, 412.32batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29434/40960 [01:10<00:27, 412.32batches/s, l2_loss: 0.0182 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|▋| 29517/40960 [01:10<00:27, 411.99batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29517/40960 [01:10<00:27, 411.99batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29599/40960 [01:10<00:27, 410.34batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29599/40960 [01:10<00:27, 410.34batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29680/40960 [01:10<00:27, 408.44batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  72%|▋| 29680/40960 [01:10<00:27, 408.44batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 29765/40960 [01:10<00:27, 412.65batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 29765/40960 [01:10<00:27, 412.65batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 29849/40960 [01:11<00:26, 414.70batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 29849/40960 [01:11<00:26, 414.70batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 29934/40960 [01:11<00:26, 416.38batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 29934/40960 [01:11<00:26, 416.38batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 30017/40960 [01:11<00:26, 415.70batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 30017/40960 [01:11<00:26, 415.70batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 30101/40960 [01:11<00:26, 416.72batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  73%|▋| 30101/40960 [01:11<00:26, 416.72batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  74%|▋| 30185/40960 [01:11<00:25, 416.52batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  74%|▋| 30185/40960 [01:11<00:25, 416.52batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  74%|▋| 30268/40960 [01:12<00:25, 414.69batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  74%|▋| 30268/40960 [01:12<00:25, 414.69batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  74%|▋| 30351/40960 [01:12<00:25, 413.29batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  74%|▋| 30351/40960 [01:12<00:25, 413.29batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  74%|▋| 30437/40960 [01:12<00:25, 417.35batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  74%|▋| 30437/40960 [01:12<00:25, 417.35batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▋| 30521/40960 [01:12<00:25, 417.54batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▋| 30521/40960 [01:12<00:25, 417.54batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▋| 30602/40960 [01:12<00:25, 412.80batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▋| 30602/40960 [01:12<00:25, 412.80batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▋| 30688/40960 [01:13<00:24, 416.91batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▋| 30688/40960 [01:13<00:24, 416.91batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▊| 30770/40960 [01:13<00:24, 414.30batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▊| 30770/40960 [01:13<00:24, 414.30batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▊| 30854/40960 [01:13<00:24, 414.64batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  75%|▊| 30854/40960 [01:13<00:24, 414.64batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 30938/40960 [01:13<00:24, 415.23batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 30938/40960 [01:13<00:24, 415.23batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31022/40960 [01:13<00:23, 416.44batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31022/40960 [01:13<00:23, 416.44batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31103/40960 [01:14<00:23, 412.77batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31103/40960 [01:14<00:23, 412.77batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31172/40960 [01:14<00:25, 390.58batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31172/40960 [01:14<00:25, 390.58batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31230/40960 [01:14<00:26, 360.43batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31230/40960 [01:14<00:26, 360.43batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31299/40960 [01:14<00:27, 354.77batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  76%|▊| 31299/40960 [01:14<00:27, 354.77batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31382/40960 [01:14<00:25, 372.57batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31382/40960 [01:14<00:25, 372.57batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31466/40960 [01:15<00:24, 385.55batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31466/40960 [01:15<00:24, 385.55batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31550/40960 [01:15<00:23, 395.08batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31550/40960 [01:15<00:23, 395.08batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31635/40960 [01:15<00:23, 403.87batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31635/40960 [01:15<00:23, 403.87batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31717/40960 [01:15<00:22, 405.64batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  77%|▊| 31717/40960 [01:15<00:22, 405.64batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 31801/40960 [01:15<00:22, 408.96batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 31801/40960 [01:15<00:22, 408.96batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 31885/40960 [01:16<00:22, 411.39batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 31885/40960 [01:16<00:22, 411.39batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 31970/40960 [01:16<00:21, 414.82batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 31970/40960 [01:16<00:21, 414.82batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 32051/40960 [01:16<00:21, 410.47batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 32051/40960 [01:16<00:21, 410.47batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 32135/40960 [01:16<00:21, 413.23batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  78%|▊| 32135/40960 [01:16<00:21, 413.23batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  79%|▊| 32217/40960 [01:16<00:21, 411.26batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  79%|▊| 32217/40960 [01:16<00:21, 411.26batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  79%|▊| 32302/40960 [01:17<00:20, 414.20batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  79%|▊| 32302/40960 [01:17<00:20, 414.20batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  79%|▊| 32386/40960 [01:17<00:20, 414.91batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  79%|▊| 32386/40960 [01:17<00:20, 414.91batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  79%|▊| 32471/40960 [01:17<00:20, 417.37batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  79%|▊| 32471/40960 [01:17<00:20, 417.37batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  79%|▊| 32555/40960 [01:17<00:20, 417.08batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  79%|▊| 32555/40960 [01:17<00:20, 417.08batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  80%|▊| 32637/40960 [01:17<00:20, 414.50batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  80%|▊| 32637/40960 [01:17<00:20, 414.50batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  80%|▊| 32721/40960 [01:18<00:19, 415.82batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  80%|▊| 32721/40960 [01:18<00:19, 415.82batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  80%|▊| 32804/40960 [01:18<00:19, 414.35batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  80%|▊| 32804/40960 [01:18<00:19, 414.35batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  80%|▊| 32888/40960 [01:18<00:19, 414.73batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  80%|▊| 32888/40960 [01:18<00:19, 414.73batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  80%|▊| 32969/40960 [01:18<00:19, 410.66batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  80%|▊| 32969/40960 [01:18<00:19, 410.66batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  81%|▊| 33050/40960 [01:18<00:19, 407.65batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  81%|▊| 33050/40960 [01:18<00:19, 407.65batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  81%|▊| 33133/40960 [01:19<00:19, 409.08batches/s, l2_loss: 0.0181 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|▊| 33133/40960 [01:19<00:19, 409.08batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  81%|▊| 33215/40960 [01:19<00:18, 408.58batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  81%|▊| 33215/40960 [01:19<00:18, 408.58batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  81%|▊| 33300/40960 [01:19<00:18, 412.28batches/s, l2_loss: 0.0182 - round_los\u001b[A\n",
      "Training:  81%|▊| 33300/40960 [01:19<00:18, 412.28batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  81%|▊| 33380/40960 [01:19<00:18, 407.88batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  81%|▊| 33380/40960 [01:19<00:18, 407.88batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33464/40960 [01:19<00:18, 410.17batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33464/40960 [01:19<00:18, 410.17batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33544/40960 [01:20<00:18, 406.73batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33544/40960 [01:20<00:18, 406.73batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33625/40960 [01:20<00:18, 405.62batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33625/40960 [01:20<00:18, 405.62batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33706/40960 [01:20<00:17, 404.71batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33706/40960 [01:20<00:17, 404.71batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33789/40960 [01:20<00:17, 406.64batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  82%|▊| 33789/40960 [01:20<00:17, 406.64batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  83%|▊| 33867/40960 [01:20<00:17, 401.24batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  83%|▊| 33867/40960 [01:20<00:17, 401.24batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  83%|▊| 33952/40960 [01:21<00:17, 406.93batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  83%|▊| 33952/40960 [01:21<00:17, 406.93batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  83%|▊| 34036/40960 [01:21<00:16, 410.75batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  83%|▊| 34036/40960 [01:21<00:16, 410.75batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  83%|▊| 34120/40960 [01:21<00:16, 413.48batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  83%|▊| 34120/40960 [01:21<00:16, 413.48batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34206/40960 [01:21<00:16, 418.06batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34206/40960 [01:21<00:16, 418.06batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34292/40960 [01:21<00:15, 420.81batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34292/40960 [01:21<00:15, 420.81batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34377/40960 [01:22<00:15, 421.44batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34377/40960 [01:22<00:15, 421.44batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34462/40960 [01:22<00:15, 421.74batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34462/40960 [01:22<00:15, 421.74batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34543/40960 [01:22<00:15, 415.60batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  84%|▊| 34543/40960 [01:22<00:15, 415.60batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34628/40960 [01:22<00:15, 418.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34628/40960 [01:22<00:15, 418.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34713/40960 [01:22<00:14, 419.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34713/40960 [01:22<00:14, 419.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34799/40960 [01:23<00:14, 421.83batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34799/40960 [01:23<00:14, 421.83batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34885/40960 [01:23<00:14, 422.88batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34885/40960 [01:23<00:14, 422.88batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34967/40960 [01:23<00:14, 418.88batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  85%|▊| 34967/40960 [01:23<00:14, 418.88batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35050/40960 [01:23<00:14, 416.16batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35050/40960 [01:23<00:14, 416.16batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35129/40960 [01:23<00:14, 409.34batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35129/40960 [01:23<00:14, 409.34batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35213/40960 [01:24<00:13, 411.91batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35213/40960 [01:24<00:13, 411.91batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35296/40960 [01:24<00:13, 411.79batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35296/40960 [01:24<00:13, 411.79batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35381/40960 [01:24<00:13, 415.34batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  86%|▊| 35381/40960 [01:24<00:13, 415.34batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35465/40960 [01:24<00:13, 416.22batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35465/40960 [01:24<00:13, 416.22batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35550/40960 [01:24<00:12, 417.44batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35550/40960 [01:24<00:12, 417.44batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35631/40960 [01:25<00:12, 413.19batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35631/40960 [01:25<00:12, 413.19batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35716/40960 [01:25<00:12, 415.81batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35716/40960 [01:25<00:12, 415.81batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35800/40960 [01:25<00:12, 415.74batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  87%|▊| 35800/40960 [01:25<00:12, 415.74batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 35884/40960 [01:25<00:12, 416.96batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 35884/40960 [01:25<00:12, 416.96batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 35967/40960 [01:25<00:12, 416.06batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 35967/40960 [01:25<00:12, 416.06batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 36048/40960 [01:26<00:11, 411.81batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 36048/40960 [01:26<00:11, 411.81batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 36131/40960 [01:26<00:11, 412.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 36131/40960 [01:26<00:11, 412.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 36214/40960 [01:26<00:11, 412.53batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  88%|▉| 36214/40960 [01:26<00:11, 412.53batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36298/40960 [01:26<00:11, 413.68batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36298/40960 [01:26<00:11, 413.68batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36383/40960 [01:26<00:10, 416.23batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36383/40960 [01:26<00:10, 416.23batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36467/40960 [01:27<00:10, 417.16batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36467/40960 [01:27<00:10, 417.16batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36553/40960 [01:27<00:10, 419.87batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36553/40960 [01:27<00:10, 419.87batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36636/40960 [01:27<00:10, 417.74batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  89%|▉| 36636/40960 [01:27<00:10, 417.74batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 36721/40960 [01:27<00:10, 419.61batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 36721/40960 [01:27<00:10, 419.61batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 36808/40960 [01:27<00:09, 422.88batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 36808/40960 [01:27<00:09, 422.88batches/s, l2_loss: 0.0181 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 36891/40960 [01:28<00:09, 419.45batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 36891/40960 [01:28<00:09, 419.45batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 36975/40960 [01:28<00:09, 418.58batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 36975/40960 [01:28<00:09, 418.58batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 37060/40960 [01:28<00:09, 419.36batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  90%|▉| 37060/40960 [01:28<00:09, 419.36batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  91%|▉| 37145/40960 [01:28<00:09, 420.85batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  91%|▉| 37145/40960 [01:28<00:09, 420.85batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  91%|▉| 37229/40960 [01:28<00:08, 420.31batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  91%|▉| 37229/40960 [01:28<00:08, 420.31batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  91%|▉| 37314/40960 [01:29<00:08, 420.35batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  91%|▉| 37314/40960 [01:29<00:08, 420.35batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  91%|▉| 37398/40960 [01:29<00:08, 419.85batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  91%|▉| 37398/40960 [01:29<00:08, 419.85batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37482/40960 [01:29<00:08, 418.26batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37482/40960 [01:29<00:08, 418.26batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37563/40960 [01:29<00:08, 414.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37563/40960 [01:29<00:08, 414.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37647/40960 [01:29<00:07, 414.94batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37647/40960 [01:29<00:07, 414.94batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37729/40960 [01:30<00:07, 412.96batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37729/40960 [01:30<00:07, 412.96batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37813/40960 [01:30<00:07, 413.77batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  92%|▉| 37813/40960 [01:30<00:07, 413.77batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 37895/40960 [01:30<00:07, 411.82batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 37895/40960 [01:30<00:07, 411.82batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 37978/40960 [01:30<00:07, 411.72batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 37978/40960 [01:30<00:07, 411.72batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 38062/40960 [01:30<00:07, 413.52batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 38062/40960 [01:30<00:07, 413.52batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 38146/40960 [01:31<00:06, 415.01batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 38146/40960 [01:31<00:06, 415.01batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 38231/40960 [01:31<00:06, 417.64batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  93%|▉| 38231/40960 [01:31<00:06, 417.64batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38314/40960 [01:31<00:06, 416.65batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38314/40960 [01:31<00:06, 416.65batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38398/40960 [01:31<00:06, 416.99batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38398/40960 [01:31<00:06, 416.99batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38480/40960 [01:31<00:05, 414.55batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38480/40960 [01:31<00:05, 414.55batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38563/40960 [01:32<00:05, 414.39batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38563/40960 [01:32<00:05, 414.39batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38646/40960 [01:32<00:05, 413.56batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  94%|▉| 38646/40960 [01:32<00:05, 413.56batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 38728/40960 [01:32<00:05, 411.29batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 38728/40960 [01:32<00:05, 411.29batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 38812/40960 [01:32<00:05, 413.63batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 38812/40960 [01:32<00:05, 413.63batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 38897/40960 [01:32<00:04, 416.97batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 38897/40960 [01:32<00:04, 416.97batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 38983/40960 [01:33<00:04, 420.73batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 38983/40960 [01:33<00:04, 420.73batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 39070/40960 [01:33<00:04, 423.63batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  95%|▉| 39070/40960 [01:33<00:04, 423.63batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39155/40960 [01:33<00:04, 422.85batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39155/40960 [01:33<00:04, 422.85batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39241/40960 [01:33<00:04, 423.69batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39241/40960 [01:33<00:04, 423.69batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39324/40960 [01:34<00:03, 420.28batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39324/40960 [01:34<00:03, 420.28batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39404/40960 [01:34<00:03, 413.11batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39404/40960 [01:34<00:03, 413.11batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39488/40960 [01:34<00:03, 414.37batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  96%|▉| 39488/40960 [01:34<00:03, 414.37batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39571/40960 [01:34<00:03, 413.04batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39571/40960 [01:34<00:03, 413.04batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39652/40960 [01:34<00:03, 410.39batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39652/40960 [01:34<00:03, 410.39batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39734/40960 [01:35<00:02, 410.06batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39734/40960 [01:35<00:02, 410.06batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39818/40960 [01:35<00:02, 412.83batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39818/40960 [01:35<00:02, 412.83batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39902/40960 [01:35<00:02, 414.37batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  97%|▉| 39902/40960 [01:35<00:02, 414.37batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 39989/40960 [01:35<00:02, 419.72batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 39989/40960 [01:35<00:02, 419.72batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40075/40960 [01:35<00:02, 422.16batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40075/40960 [01:35<00:02, 422.16batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40158/40960 [01:36<00:01, 419.45batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40158/40960 [01:36<00:01, 419.45batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40240/40960 [01:36<00:01, 416.08batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40240/40960 [01:36<00:01, 416.08batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40322/40960 [01:36<00:01, 413.39batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  98%|▉| 40322/40960 [01:36<00:01, 413.39batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40408/40960 [01:36<00:01, 417.76batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40408/40960 [01:36<00:01, 417.76batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40494/40960 [01:36<00:01, 421.12batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40494/40960 [01:36<00:01, 421.12batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40578/40960 [01:37<00:00, 420.16batches/s, l2_loss: 0.0181 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|▉| 40578/40960 [01:37<00:00, 420.16batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40661/40960 [01:37<00:00, 417.97batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40661/40960 [01:37<00:00, 417.97batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40742/40960 [01:37<00:00, 413.32batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training:  99%|▉| 40742/40960 [01:37<00:00, 413.32batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training: 100%|▉| 40825/40960 [01:37<00:00, 412.86batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training: 100%|▉| 40825/40960 [01:37<00:00, 412.86batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training: 100%|▉| 40909/40960 [01:37<00:00, 414.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "Training: 100%|▉| 40909/40960 [01:37<00:00, 414.03batches/s, l2_loss: 0.0181 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:34:07.264685: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  85%|▊| 22/26 [46:27<08:06, 121.63s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:34:08.530588: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:34:13.677689: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<19:02:11,  1.67s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<19:02:11,  1.67s/batches, l2_loss: 0.0524 - round_loss:\u001b[A\n",
      "Training:   0%| | 58/40960 [00:01<16:12, 42.05batches/s, l2_loss: 0.0524 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 58/40960 [00:01<16:12, 42.05batches/s, l2_loss: 0.0666 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 122/40960 [00:02<07:34, 89.87batches/s, l2_loss: 0.0666 - round_loss: \u001b[A\n",
      "Training:   0%| | 122/40960 [00:02<07:34, 89.87batches/s, l2_loss: 0.0665 - round_loss: \u001b[A\n",
      "Training:   0%| | 177/40960 [00:02<05:22, 126.37batches/s, l2_loss: 0.0665 - round_loss:\u001b[A\n",
      "Training:   0%| | 177/40960 [00:02<05:22, 126.37batches/s, l2_loss: 0.0621 - round_loss:\u001b[A\n",
      "Training:   1%| | 234/40960 [00:02<04:13, 160.70batches/s, l2_loss: 0.0621 - round_loss:\u001b[A\n",
      "Training:   1%| | 234/40960 [00:02<04:13, 160.70batches/s, l2_loss: 0.0657 - round_loss:\u001b[A\n",
      "Training:   1%| | 284/40960 [00:02<03:44, 181.53batches/s, l2_loss: 0.0657 - round_loss:\u001b[A\n",
      "Training:   1%| | 284/40960 [00:02<03:44, 181.53batches/s, l2_loss: 0.0626 - round_loss:\u001b[A\n",
      "Training:   1%| | 345/40960 [00:02<03:11, 212.50batches/s, l2_loss: 0.0626 - round_loss:\u001b[A\n",
      "Training:   1%| | 345/40960 [00:02<03:11, 212.50batches/s, l2_loss: 0.0627 - round_loss:\u001b[A\n",
      "Training:   1%| | 403/40960 [00:03<02:54, 232.97batches/s, l2_loss: 0.0627 - round_loss:\u001b[A\n",
      "Training:   1%| | 403/40960 [00:03<02:54, 232.97batches/s, l2_loss: 0.0622 - round_loss:\u001b[A\n",
      "Training:   1%| | 461/40960 [00:03<02:43, 248.13batches/s, l2_loss: 0.0622 - round_loss:\u001b[A\n",
      "Training:   1%| | 461/40960 [00:03<02:43, 248.13batches/s, l2_loss: 0.0615 - round_loss:\u001b[A\n",
      "Training:   1%| | 517/40960 [00:03<02:37, 256.36batches/s, l2_loss: 0.0615 - round_loss:\u001b[A\n",
      "Training:   1%| | 517/40960 [00:03<02:37, 256.36batches/s, l2_loss: 0.0619 - round_loss:\u001b[A\n",
      "Training:   1%| | 573/40960 [00:03<02:34, 261.96batches/s, l2_loss: 0.0619 - round_loss:\u001b[A\n",
      "Training:   1%| | 573/40960 [00:03<02:34, 261.96batches/s, l2_loss: 0.0624 - round_loss:\u001b[A\n",
      "Training:   2%| | 626/40960 [00:03<02:34, 261.83batches/s, l2_loss: 0.0624 - round_loss:\u001b[A\n",
      "Training:   2%| | 626/40960 [00:03<02:34, 261.83batches/s, l2_loss: 0.0614 - round_loss:\u001b[A\n",
      "Training:   2%| | 680/40960 [00:04<02:32, 263.70batches/s, l2_loss: 0.0614 - round_loss:\u001b[A\n",
      "Training:   2%| | 680/40960 [00:04<02:32, 263.70batches/s, l2_loss: 0.0615 - round_loss:\u001b[A\n",
      "Training:   2%| | 741/40960 [00:04<02:25, 275.54batches/s, l2_loss: 0.0615 - round_loss:\u001b[A\n",
      "Training:   2%| | 741/40960 [00:04<02:25, 275.54batches/s, l2_loss: 0.0605 - round_loss:\u001b[A\n",
      "Training:   2%| | 809/40960 [00:04<02:16, 294.34batches/s, l2_loss: 0.0605 - round_loss:\u001b[A\n",
      "Training:   2%| | 809/40960 [00:04<02:16, 294.34batches/s, l2_loss: 0.0602 - round_loss:\u001b[A\n",
      "Training:   2%| | 876/40960 [00:04<02:11, 305.72batches/s, l2_loss: 0.0602 - round_loss:\u001b[A\n",
      "Training:   2%| | 876/40960 [00:04<02:11, 305.72batches/s, l2_loss: 0.0601 - round_loss:\u001b[A\n",
      "Training:   2%| | 947/40960 [00:04<02:05, 319.88batches/s, l2_loss: 0.0601 - round_loss:\u001b[A\n",
      "Training:   2%| | 947/40960 [00:04<02:05, 319.88batches/s, l2_loss: 0.0595 - round_loss:\u001b[A\n",
      "Training:   2%| | 1016/40960 [00:05<02:02, 326.46batches/s, l2_loss: 0.0595 - round_loss\u001b[A\n",
      "Training:   2%| | 1016/40960 [00:05<02:02, 326.46batches/s, l2_loss: 0.0595 - round_loss\u001b[A\n",
      "Training:   3%| | 1085/40960 [00:05<02:00, 331.52batches/s, l2_loss: 0.0595 - round_loss\u001b[A\n",
      "Training:   3%| | 1085/40960 [00:05<02:00, 331.52batches/s, l2_loss: 0.0589 - round_loss\u001b[A\n",
      "Training:   3%| | 1156/40960 [00:05<01:57, 337.64batches/s, l2_loss: 0.0589 - round_loss\u001b[A\n",
      "Training:   3%| | 1156/40960 [00:05<01:57, 337.64batches/s, l2_loss: 0.0588 - round_loss\u001b[A\n",
      "Training:   3%| | 1227/40960 [00:05<01:56, 341.92batches/s, l2_loss: 0.0588 - round_loss\u001b[A\n",
      "Training:   3%| | 1227/40960 [00:05<01:56, 341.92batches/s, l2_loss: 0.0582 - round_loss\u001b[A\n",
      "Training:   3%| | 1298/40960 [00:05<01:55, 344.84batches/s, l2_loss: 0.0582 - round_loss\u001b[A\n",
      "Training:   3%| | 1298/40960 [00:05<01:55, 344.84batches/s, l2_loss: 0.0581 - round_loss\u001b[A\n",
      "Training:   3%| | 1368/40960 [00:06<01:54, 345.28batches/s, l2_loss: 0.0581 - round_loss\u001b[A\n",
      "Training:   3%| | 1368/40960 [00:06<01:54, 345.28batches/s, l2_loss: 0.0582 - round_loss\u001b[A\n",
      "Training:   4%| | 1437/40960 [00:06<01:54, 344.74batches/s, l2_loss: 0.0582 - round_loss\u001b[A\n",
      "Training:   4%| | 1437/40960 [00:06<01:54, 344.74batches/s, l2_loss: 0.0577 - round_loss\u001b[A\n",
      "Training:   4%| | 1506/40960 [00:06<01:54, 344.03batches/s, l2_loss: 0.0577 - round_loss\u001b[A\n",
      "Training:   4%| | 1506/40960 [00:06<01:54, 344.03batches/s, l2_loss: 0.0574 - round_loss\u001b[A\n",
      "Training:   4%| | 1573/40960 [00:06<01:55, 339.92batches/s, l2_loss: 0.0574 - round_loss\u001b[A\n",
      "Training:   4%| | 1573/40960 [00:06<01:55, 339.92batches/s, l2_loss: 0.0576 - round_loss\u001b[A\n",
      "Training:   4%| | 1637/40960 [00:06<01:58, 332.74batches/s, l2_loss: 0.0576 - round_loss\u001b[A\n",
      "Training:   4%| | 1637/40960 [00:06<01:58, 332.74batches/s, l2_loss: 0.0572 - round_loss\u001b[A\n",
      "Training:   4%| | 1695/40960 [00:07<02:03, 319.06batches/s, l2_loss: 0.0572 - round_loss\u001b[A\n",
      "Training:   4%| | 1695/40960 [00:07<02:03, 319.06batches/s, l2_loss: 0.0567 - round_loss\u001b[A\n",
      "Training:   4%| | 1756/40960 [00:07<02:04, 314.53batches/s, l2_loss: 0.0567 - round_loss\u001b[A\n",
      "Training:   4%| | 1756/40960 [00:07<02:04, 314.53batches/s, l2_loss: 0.0564 - round_loss\u001b[A\n",
      "Training:   4%| | 1810/40960 [00:07<02:10, 300.38batches/s, l2_loss: 0.0564 - round_loss\u001b[A\n",
      "Training:   4%| | 1810/40960 [00:07<02:10, 300.38batches/s, l2_loss: 0.0568 - round_loss\u001b[A\n",
      "Training:   5%| | 1875/40960 [00:07<02:07, 307.58batches/s, l2_loss: 0.0568 - round_loss\u001b[A\n",
      "Training:   5%| | 1875/40960 [00:07<02:07, 307.58batches/s, l2_loss: 0.0565 - round_loss\u001b[A\n",
      "Training:   5%| | 1938/40960 [00:07<02:06, 308.74batches/s, l2_loss: 0.0565 - round_loss\u001b[A\n",
      "Training:   5%| | 1938/40960 [00:07<02:06, 308.74batches/s, l2_loss: 0.0566 - round_loss\u001b[A\n",
      "Training:   5%| | 1998/40960 [00:08<02:07, 305.09batches/s, l2_loss: 0.0566 - round_loss\u001b[A\n",
      "Training:   5%| | 1998/40960 [00:08<02:07, 305.09batches/s, l2_loss: 0.0564 - round_loss\u001b[A\n",
      "Training:   5%| | 2067/40960 [00:08<02:02, 316.68batches/s, l2_loss: 0.0564 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%| | 2067/40960 [00:08<02:02, 316.68batches/s, l2_loss: 0.0560 - round_loss\u001b[A\n",
      "Training:   5%| | 2128/40960 [00:08<02:04, 311.64batches/s, l2_loss: 0.0560 - round_loss\u001b[A\n",
      "Training:   5%| | 2128/40960 [00:08<02:04, 311.64batches/s, l2_loss: 0.0559 - round_loss\u001b[A\n",
      "Training:   5%| | 2195/40960 [00:08<02:01, 317.96batches/s, l2_loss: 0.0559 - round_loss\u001b[A\n",
      "Training:   5%| | 2195/40960 [00:08<02:01, 317.96batches/s, l2_loss: 0.0557 - round_loss\u001b[A\n",
      "Training:   6%| | 2264/40960 [00:08<01:59, 325.10batches/s, l2_loss: 0.0557 - round_loss\u001b[A\n",
      "Training:   6%| | 2264/40960 [00:08<01:59, 325.10batches/s, l2_loss: 0.0555 - round_loss\u001b[A\n",
      "Training:   6%| | 2334/40960 [00:09<01:56, 332.02batches/s, l2_loss: 0.0555 - round_loss\u001b[A\n",
      "Training:   6%| | 2334/40960 [00:09<01:56, 332.02batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:   6%| | 2402/40960 [00:09<01:55, 334.20batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:   6%| | 2402/40960 [00:09<01:55, 334.20batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:   6%| | 2470/40960 [00:09<01:54, 335.42batches/s, l2_loss: 0.0554 - round_loss\u001b[A\n",
      "Training:   6%| | 2470/40960 [00:09<01:54, 335.42batches/s, l2_loss: 0.0552 - round_loss\u001b[A\n",
      "Training:   6%| | 2541/40960 [00:09<01:52, 340.50batches/s, l2_loss: 0.0552 - round_loss\u001b[A\n",
      "Training:   6%| | 2541/40960 [00:09<01:52, 340.50batches/s, l2_loss: 0.0548 - round_loss\u001b[A\n",
      "Training:   6%| | 2608/40960 [00:09<01:53, 338.76batches/s, l2_loss: 0.0548 - round_loss\u001b[A\n",
      "Training:   6%| | 2608/40960 [00:09<01:53, 338.76batches/s, l2_loss: 0.0550 - round_loss\u001b[A\n",
      "Training:   7%| | 2679/40960 [00:10<01:51, 343.32batches/s, l2_loss: 0.0550 - round_loss\u001b[A\n",
      "Training:   7%| | 2679/40960 [00:10<01:51, 343.32batches/s, l2_loss: 0.0547 - round_loss\u001b[A\n",
      "Training:   7%| | 2748/40960 [00:10<01:51, 342.89batches/s, l2_loss: 0.0547 - round_loss\u001b[A\n",
      "Training:   7%| | 2748/40960 [00:10<01:51, 342.89batches/s, l2_loss: 0.0544 - round_loss\u001b[A\n",
      "Training:   7%| | 2807/40960 [00:10<01:56, 327.26batches/s, l2_loss: 0.0544 - round_loss\u001b[A\n",
      "Training:   7%| | 2807/40960 [00:10<01:56, 327.26batches/s, l2_loss: 0.0545 - round_loss\u001b[A\n",
      "Training:   7%| | 2873/40960 [00:10<01:56, 327.62batches/s, l2_loss: 0.0545 - round_loss\u001b[A\n",
      "Training:   7%| | 2873/40960 [00:10<01:56, 327.62batches/s, l2_loss: 0.0544 - round_loss\u001b[A\n",
      "Training:   7%| | 2939/40960 [00:10<01:55, 327.92batches/s, l2_loss: 0.0544 - round_loss\u001b[A\n",
      "Training:   7%| | 2939/40960 [00:10<01:55, 327.92batches/s, l2_loss: 0.0542 - round_loss\u001b[A\n",
      "Training:   7%| | 3005/40960 [00:11<01:55, 327.88batches/s, l2_loss: 0.0542 - round_loss\u001b[A\n",
      "Training:   7%| | 3005/40960 [00:11<01:55, 327.88batches/s, l2_loss: 0.0540 - round_loss\u001b[A\n",
      "Training:   7%| | 3063/40960 [00:11<01:59, 316.28batches/s, l2_loss: 0.0540 - round_loss\u001b[A\n",
      "Training:   7%| | 3063/40960 [00:11<01:59, 316.28batches/s, l2_loss: 0.0540 - round_loss\u001b[A\n",
      "Training:   8%| | 3121/40960 [00:11<02:02, 308.32batches/s, l2_loss: 0.0540 - round_loss\u001b[A\n",
      "Training:   8%| | 3121/40960 [00:11<02:02, 308.32batches/s, l2_loss: 0.0540 - round_loss\u001b[A\n",
      "Training:   8%| | 3189/40960 [00:11<01:59, 316.29batches/s, l2_loss: 0.0540 - round_loss\u001b[A\n",
      "Training:   8%| | 3189/40960 [00:11<01:59, 316.29batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   8%| | 3256/40960 [00:11<01:58, 319.36batches/s, l2_loss: 0.0538 - round_loss\u001b[A\n",
      "Training:   8%| | 3256/40960 [00:11<01:58, 319.36batches/s, l2_loss: 0.0536 - round_loss\u001b[A\n",
      "Training:   8%| | 3324/40960 [00:12<01:55, 325.10batches/s, l2_loss: 0.0536 - round_loss\u001b[A\n",
      "Training:   8%| | 3324/40960 [00:12<01:55, 325.10batches/s, l2_loss: 0.0536 - round_loss\u001b[A\n",
      "Training:   8%| | 3391/40960 [00:12<01:54, 327.19batches/s, l2_loss: 0.0536 - round_loss\u001b[A\n",
      "Training:   8%| | 3391/40960 [00:12<01:54, 327.19batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   8%| | 3458/40960 [00:12<01:54, 328.66batches/s, l2_loss: 0.0535 - round_loss\u001b[A\n",
      "Training:   8%| | 3458/40960 [00:12<01:54, 328.66batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   9%| | 3525/40960 [00:12<01:53, 330.51batches/s, l2_loss: 0.0533 - round_loss\u001b[A\n",
      "Training:   9%| | 3525/40960 [00:12<01:53, 330.51batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3595/40960 [00:12<01:51, 336.11batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3595/40960 [00:12<01:51, 336.11batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3662/40960 [00:13<01:51, 334.92batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3662/40960 [00:13<01:51, 334.92batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3734/40960 [00:13<01:48, 341.79batches/s, l2_loss: 0.0531 - round_loss\u001b[A\n",
      "Training:   9%| | 3734/40960 [00:13<01:48, 341.79batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   9%| | 3803/40960 [00:13<01:48, 341.70batches/s, l2_loss: 0.0530 - round_loss\u001b[A\n",
      "Training:   9%| | 3803/40960 [00:13<01:48, 341.70batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   9%| | 3873/40960 [00:13<01:47, 343.77batches/s, l2_loss: 0.0529 - round_loss\u001b[A\n",
      "Training:   9%| | 3873/40960 [00:13<01:47, 343.77batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  10%| | 3940/40960 [00:13<01:48, 340.38batches/s, l2_loss: 0.0528 - round_loss\u001b[A\n",
      "Training:  10%| | 3940/40960 [00:13<01:48, 340.38batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  10%| | 4006/40960 [00:14<01:49, 337.19batches/s, l2_loss: 0.0527 - round_loss\u001b[A\n",
      "Training:  10%| | 4006/40960 [00:14<01:49, 337.19batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  10%| | 4070/40960 [00:14<01:51, 331.24batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  10%| | 4070/40960 [00:14<01:51, 331.24batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  10%| | 4136/40960 [00:14<01:51, 330.60batches/s, l2_loss: 0.0525 - round_loss\u001b[A\n",
      "Training:  10%| | 4136/40960 [00:14<01:51, 330.60batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  10%| | 4203/40960 [00:14<01:51, 330.97batches/s, l2_loss: 0.0524 - round_loss\u001b[A\n",
      "Training:  10%| | 4203/40960 [00:14<01:51, 330.97batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  10%| | 4272/40960 [00:14<01:49, 333.97batches/s, l2_loss: 0.0523 - round_loss\u001b[A\n",
      "Training:  10%| | 4272/40960 [00:14<01:49, 333.97batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  11%| | 4342/40960 [00:15<01:48, 337.62batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  11%| | 4342/40960 [00:15<01:48, 337.62batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  11%| | 4410/40960 [00:15<01:48, 337.48batches/s, l2_loss: 0.0522 - round_loss\u001b[A\n",
      "Training:  11%| | 4410/40960 [00:15<01:48, 337.48batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  11%| | 4469/40960 [00:15<01:52, 323.25batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  11%| | 4469/40960 [00:15<01:52, 323.25batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  11%| | 4528/40960 [00:15<01:56, 313.45batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  11%| | 4528/40960 [00:15<01:56, 313.45batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  11%| | 4594/40960 [00:15<01:54, 317.70batches/s, l2_loss: 0.0520 - round_loss\u001b[A\n",
      "Training:  11%| | 4594/40960 [00:15<01:54, 317.70batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  11%| | 4657/40960 [00:16<01:55, 315.06batches/s, l2_loss: 0.0519 - round_loss\u001b[A\n",
      "Training:  11%| | 4657/40960 [00:16<01:55, 315.06batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  12%| | 4716/40960 [00:16<01:57, 309.09batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  12%| | 4716/40960 [00:16<01:57, 309.09batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  12%| | 4783/40960 [00:16<01:54, 316.19batches/s, l2_loss: 0.0517 - round_loss\u001b[A\n",
      "Training:  12%| | 4783/40960 [00:16<01:54, 316.19batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  12%| | 4844/40960 [00:16<01:55, 312.69batches/s, l2_loss: 0.0516 - round_loss\u001b[A\n",
      "Training:  12%| | 4844/40960 [00:16<01:55, 312.69batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  12%| | 4912/40960 [00:16<01:52, 320.72batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  12%| | 4912/40960 [00:16<01:52, 320.72batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  12%| | 4972/40960 [00:17<01:55, 312.63batches/s, l2_loss: 0.0515 - round_loss\u001b[A\n",
      "Training:  12%| | 4972/40960 [00:17<01:55, 312.63batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%| | 5041/40960 [00:17<01:51, 322.24batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  12%| | 5041/40960 [00:17<01:51, 322.24batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  12%| | 5109/40960 [00:17<01:49, 327.39batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  12%| | 5109/40960 [00:17<01:49, 327.39batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5180/40960 [00:17<01:46, 334.84batches/s, l2_loss: 0.0513 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5180/40960 [00:17<01:46, 334.84batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5249/40960 [00:17<01:45, 337.69batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5249/40960 [00:18<01:45, 337.69batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5319/40960 [00:18<01:44, 340.79batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5319/40960 [00:18<01:44, 340.79batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5391/40960 [00:18<01:42, 345.47batches/s, l2_loss: 0.0511 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5391/40960 [00:18<01:42, 345.47batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5464/40960 [00:18<01:41, 350.05batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5464/40960 [00:18<01:41, 350.05batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5535/40960 [00:18<01:40, 350.76batches/s, l2_loss: 0.0509 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5535/40960 [00:18<01:40, 350.76batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5606/40960 [00:19<01:40, 351.09batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5606/40960 [00:19<01:40, 351.09batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5674/40960 [00:19<01:41, 347.11batches/s, l2_loss: 0.0508 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5674/40960 [00:19<01:41, 347.11batches/s, l2_loss: 0.0507 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5746/40960 [00:19<01:40, 349.53batches/s, l2_loss: 0.0507 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5746/40960 [00:19<01:40, 349.53batches/s, l2_loss: 0.0506 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5813/40960 [00:19<01:42, 344.27batches/s, l2_loss: 0.0506 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5813/40960 [00:19<01:42, 344.27batches/s, l2_loss: 0.0506 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5875/40960 [00:19<01:45, 332.57batches/s, l2_loss: 0.0506 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5875/40960 [00:19<01:45, 332.57batches/s, l2_loss: 0.0505 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5945/40960 [00:20<01:43, 337.22batches/s, l2_loss: 0.0505 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5945/40960 [00:20<01:43, 337.22batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6011/40960 [00:20<01:44, 333.70batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6011/40960 [00:20<01:44, 333.70batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6082/40960 [00:20<01:42, 339.41batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6082/40960 [00:20<01:42, 339.41batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6145/40960 [00:20<01:45, 330.92batches/s, l2_loss: 0.0504 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6145/40960 [00:20<01:45, 330.92batches/s, l2_loss: 0.0503 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6213/40960 [00:20<01:44, 333.34batches/s, l2_loss: 0.0503 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6213/40960 [00:20<01:44, 333.34batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6280/40960 [00:21<01:44, 333.43batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6280/40960 [00:21<01:44, 333.43batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6346/40960 [00:21<01:44, 331.33batches/s, l2_loss: 0.0502 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6346/40960 [00:21<01:44, 331.33batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6416/40960 [00:21<01:42, 336.56batches/s, l2_loss: 0.0501 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6416/40960 [00:21<01:42, 336.56batches/s, l2_loss: 0.0500 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6485/40960 [00:21<01:41, 339.04batches/s, l2_loss: 0.0500 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6485/40960 [00:21<01:41, 339.04batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6551/40960 [00:21<01:42, 335.61batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6551/40960 [00:21<01:42, 335.61batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6619/40960 [00:22<01:42, 335.33batches/s, l2_loss: 0.0499 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6619/40960 [00:22<01:42, 335.33batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6687/40960 [00:22<01:41, 336.44batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6687/40960 [00:22<01:41, 336.44batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6748/40960 [00:22<01:44, 326.73batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6748/40960 [00:22<01:44, 326.73batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6819/40960 [00:22<01:41, 335.08batches/s, l2_loss: 0.0498 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6819/40960 [00:22<01:41, 335.08batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6885/40960 [00:22<01:42, 333.14batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6885/40960 [00:22<01:42, 333.14batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6947/40960 [00:23<01:44, 325.60batches/s, l2_loss: 0.0497 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6947/40960 [00:23<01:44, 325.60batches/s, l2_loss: 0.0496 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7012/40960 [00:23<01:44, 324.39batches/s, l2_loss: 0.0496 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7012/40960 [00:23<01:44, 324.39batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7082/40960 [00:23<01:42, 331.48batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7082/40960 [00:23<01:42, 331.48batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7149/40960 [00:23<01:41, 331.73batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7149/40960 [00:23<01:41, 331.73batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7207/40960 [00:23<01:46, 318.20batches/s, l2_loss: 0.0495 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7207/40960 [00:23<01:46, 318.20batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7265/40960 [00:24<01:49, 307.39batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7265/40960 [00:24<01:49, 307.39batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7330/40960 [00:24<01:47, 312.06batches/s, l2_loss: 0.0494 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7330/40960 [00:24<01:47, 312.06batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7397/40960 [00:24<01:45, 318.75batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7397/40960 [00:24<01:45, 318.75batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7460/40960 [00:24<01:45, 316.84batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7460/40960 [00:24<01:45, 316.84batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7522/40960 [00:24<01:46, 314.29batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7522/40960 [00:24<01:46, 314.29batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7593/40960 [00:25<01:42, 324.99batches/s, l2_loss: 0.0493 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7593/40960 [00:25<01:42, 324.99batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7660/40960 [00:25<01:41, 327.91batches/s, l2_loss: 0.0492 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7660/40960 [00:25<01:41, 327.91batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7729/40960 [00:25<01:40, 331.75batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7729/40960 [00:25<01:40, 331.75batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7796/40960 [00:25<01:39, 331.67batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7796/40960 [00:25<01:39, 331.67batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7862/40960 [00:25<01:40, 330.01batches/s, l2_loss: 0.0491 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7862/40960 [00:25<01:40, 330.01batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7924/40960 [00:26<01:42, 322.61batches/s, l2_loss: 0.0490 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7924/40960 [00:26<01:42, 322.61batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7983/40960 [00:26<01:45, 313.05batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|▏| 7983/40960 [00:26<01:45, 313.05batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8049/40960 [00:26<01:43, 317.78batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8049/40960 [00:26<01:43, 317.78batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8100/40960 [00:26<01:50, 298.70batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8100/40960 [00:26<01:50, 298.70batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8155/40960 [00:26<01:52, 291.12batches/s, l2_loss: 0.0489 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8155/40960 [00:26<01:52, 291.12batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8209/40960 [00:27<01:55, 284.00batches/s, l2_loss: 0.0488 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8209/40960 [00:27<01:55, 284.00batches/s, l2_loss: 0.0335 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8264/40960 [00:27<01:56, 280.89batches/s, l2_loss: 0.0335 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8264/40960 [00:27<01:56, 280.89batches/s, l2_loss: 0.0383 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8319/40960 [00:27<01:57, 278.37batches/s, l2_loss: 0.0383 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8319/40960 [00:27<01:57, 278.37batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8380/40960 [00:27<01:53, 285.87batches/s, l2_loss: 0.0438 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8380/40960 [00:27<01:53, 285.87batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8442/40960 [00:27<01:51, 292.90batches/s, l2_loss: 0.0413 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8442/40960 [00:27<01:51, 292.90batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8497/40960 [00:28<01:53, 286.30batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8497/40960 [00:28<01:53, 286.30batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8551/40960 [00:28<01:55, 281.23batches/s, l2_loss: 0.0439 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8551/40960 [00:28<01:55, 281.23batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8608/40960 [00:28<01:54, 281.45batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8608/40960 [00:28<01:54, 281.45batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8671/40960 [00:28<01:51, 290.50batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8671/40960 [00:28<01:51, 290.50batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8719/40960 [00:28<01:57, 274.42batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8719/40960 [00:28<01:57, 274.42batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8765/40960 [00:29<02:04, 258.36batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8765/40960 [00:29<02:04, 258.36batches/s, l2_loss: 0.0453 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8812/40960 [00:29<02:09, 248.55batches/s, l2_loss: 0.0453 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8812/40960 [00:29<02:09, 248.55batches/s, l2_loss: 0.0448 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8876/40960 [00:29<01:59, 269.43batches/s, l2_loss: 0.0448 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8876/40960 [00:29<01:59, 269.43batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8935/40960 [00:29<01:55, 276.94batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8935/40960 [00:29<01:55, 276.94batches/s, l2_loss: 0.0446 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8990/40960 [00:29<01:55, 275.66batches/s, l2_loss: 0.0446 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8990/40960 [00:29<01:55, 275.66batches/s, l2_loss: 0.0448 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9053/40960 [00:30<01:51, 286.74batches/s, l2_loss: 0.0448 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9053/40960 [00:30<01:51, 286.74batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9117/40960 [00:30<01:47, 296.24batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9117/40960 [00:30<01:47, 296.24batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9178/40960 [00:30<01:46, 298.48batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9178/40960 [00:30<01:46, 298.48batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9234/40960 [00:30<01:48, 291.33batches/s, l2_loss: 0.0451 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9234/40960 [00:30<01:48, 291.33batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9285/40960 [00:30<01:53, 279.67batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9285/40960 [00:30<01:53, 279.67batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9349/40960 [00:31<01:48, 290.63batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9349/40960 [00:31<01:48, 290.63batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9417/40960 [00:31<01:43, 304.62batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9417/40960 [00:31<01:43, 304.62batches/s, l2_loss: 0.0449 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9482/40960 [00:31<01:41, 310.48batches/s, l2_loss: 0.0449 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9482/40960 [00:31<01:41, 310.48batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9542/40960 [00:31<01:42, 307.22batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9542/40960 [00:31<01:42, 307.22batches/s, l2_loss: 0.0446 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9609/40960 [00:31<01:39, 314.73batches/s, l2_loss: 0.0446 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9609/40960 [00:31<01:39, 314.73batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9674/40960 [00:32<01:38, 317.24batches/s, l2_loss: 0.0447 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9674/40960 [00:32<01:38, 317.24batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9740/40960 [00:32<01:37, 319.80batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9740/40960 [00:32<01:37, 319.80batches/s, l2_loss: 0.0446 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9805/40960 [00:32<01:37, 320.97batches/s, l2_loss: 0.0446 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9805/40960 [00:32<01:37, 320.97batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9870/40960 [00:32<01:36, 320.93batches/s, l2_loss: 0.0445 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9870/40960 [00:32<01:36, 320.93batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9919/40960 [00:32<01:44, 298.03batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9919/40960 [00:32<01:44, 298.03batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9964/40960 [00:33<01:53, 273.53batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9964/40960 [00:33<01:53, 273.53batches/s, l2_loss: 0.0444 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10004/40960 [00:33<02:03, 250.57batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  24%|▏| 10004/40960 [00:33<02:03, 250.57batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  25%|▏| 10068/40960 [00:33<01:54, 270.55batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  25%|▏| 10068/40960 [00:33<01:54, 270.55batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  25%|▏| 10121/40960 [00:33<01:55, 268.11batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  25%|▏| 10121/40960 [00:33<01:55, 268.11batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  25%|▏| 10187/40960 [00:33<01:47, 285.37batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  25%|▏| 10187/40960 [00:33<01:47, 285.37batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  25%|▎| 10253/40960 [00:34<01:43, 297.54batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  25%|▎| 10253/40960 [00:34<01:43, 297.54batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  25%|▎| 10318/40960 [00:34<01:40, 304.66batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  25%|▎| 10318/40960 [00:34<01:40, 304.66batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  25%|▎| 10384/40960 [00:34<01:38, 310.95batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  25%|▎| 10384/40960 [00:34<01:38, 310.95batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  26%|▎| 10448/40960 [00:34<01:37, 311.79batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  26%|▎| 10448/40960 [00:34<01:37, 311.79batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  26%|▎| 10513/40960 [00:34<01:36, 314.76batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  26%|▎| 10513/40960 [00:34<01:36, 314.76batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  26%|▎| 10572/40960 [00:35<01:38, 307.96batches/s, l2_loss: 0.0444 - round_los\u001b[A\n",
      "Training:  26%|▎| 10572/40960 [00:35<01:38, 307.96batches/s, l2_loss: 0.0443 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10632/40960 [00:35<01:39, 305.31batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  26%|▎| 10632/40960 [00:35<01:39, 305.31batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  26%|▎| 10698/40960 [00:35<01:36, 312.32batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  26%|▎| 10698/40960 [00:35<01:36, 312.32batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  26%|▎| 10757/40960 [00:35<01:39, 304.98batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  26%|▎| 10757/40960 [00:35<01:39, 304.98batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  26%|▎| 10815/40960 [00:35<01:40, 300.01batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  26%|▎| 10815/40960 [00:35<01:40, 300.01batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 10869/40960 [00:36<01:43, 291.00batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 10869/40960 [00:36<01:43, 291.00batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  27%|▎| 10933/40960 [00:36<01:40, 298.60batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  27%|▎| 10933/40960 [00:36<01:40, 298.60batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 10991/40960 [00:36<01:42, 292.94batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 10991/40960 [00:36<01:42, 292.94batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  27%|▎| 11054/40960 [00:36<01:40, 298.39batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  27%|▎| 11054/40960 [00:36<01:40, 298.39batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  27%|▎| 11095/40960 [00:36<01:51, 268.39batches/s, l2_loss: 0.0443 - round_los\u001b[A\n",
      "Training:  27%|▎| 11095/40960 [00:36<01:51, 268.39batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 11133/40960 [00:37<02:02, 243.12batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 11133/40960 [00:37<02:02, 243.12batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 11180/40960 [00:37<02:04, 239.69batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 11180/40960 [00:37<02:04, 239.69batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 11238/40960 [00:37<01:56, 254.53batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  27%|▎| 11238/40960 [00:37<01:56, 254.53batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  28%|▎| 11293/40960 [00:37<01:54, 259.28batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  28%|▎| 11293/40960 [00:37<01:54, 259.28batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11338/40960 [00:38<02:00, 246.50batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11338/40960 [00:38<02:00, 246.50batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11397/40960 [00:38<01:53, 260.61batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11397/40960 [00:38<01:53, 260.61batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11459/40960 [00:38<01:47, 274.94batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11459/40960 [00:38<01:47, 274.94batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11515/40960 [00:38<01:47, 274.81batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11515/40960 [00:38<01:47, 274.81batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  28%|▎| 11576/40960 [00:38<01:43, 283.26batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  28%|▎| 11576/40960 [00:38<01:43, 283.26batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11640/40960 [00:39<01:40, 292.96batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  28%|▎| 11640/40960 [00:39<01:40, 292.96batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11699/40960 [00:39<01:39, 292.88batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11699/40960 [00:39<01:39, 292.88batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11764/40960 [00:39<01:36, 302.13batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11764/40960 [00:39<01:36, 302.13batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11828/40960 [00:39<01:34, 306.86batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11828/40960 [00:39<01:34, 306.86batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11893/40960 [00:39<01:33, 310.95batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11893/40960 [00:39<01:33, 310.95batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  29%|▎| 11946/40960 [00:40<01:38, 295.12batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  29%|▎| 11946/40960 [00:40<01:38, 295.12batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11994/40960 [00:40<01:44, 278.14batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  29%|▎| 11994/40960 [00:40<01:44, 278.14batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  29%|▎| 12037/40960 [00:40<01:51, 258.98batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  29%|▎| 12037/40960 [00:40<01:51, 258.98batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12097/40960 [00:40<01:46, 270.63batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12097/40960 [00:40<01:46, 270.63batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  30%|▎| 12154/40960 [00:40<01:45, 273.60batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  30%|▎| 12154/40960 [00:40<01:45, 273.60batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12218/40960 [00:41<01:40, 286.91batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12218/40960 [00:41<01:40, 286.91batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12284/40960 [00:41<01:35, 298.72batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12284/40960 [00:41<01:35, 298.72batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12345/40960 [00:41<01:35, 300.38batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12345/40960 [00:41<01:35, 300.38batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  30%|▎| 12409/40960 [00:41<01:33, 304.86batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  30%|▎| 12409/40960 [00:41<01:33, 304.86batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12465/40960 [00:41<01:36, 296.42batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  30%|▎| 12465/40960 [00:41<01:36, 296.42batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12526/40960 [00:42<01:35, 298.43batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12526/40960 [00:42<01:35, 298.43batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12585/40960 [00:42<01:35, 296.16batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12585/40960 [00:42<01:35, 296.16batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12646/40960 [00:42<01:35, 297.76batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12646/40960 [00:42<01:35, 297.76batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12712/40960 [00:42<01:31, 307.09batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12712/40960 [00:42<01:31, 307.09batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12777/40960 [00:42<01:30, 311.77batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12777/40960 [00:42<01:30, 311.77batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12842/40960 [00:43<01:29, 315.17batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  31%|▎| 12842/40960 [00:43<01:29, 315.17batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  32%|▎| 12905/40960 [00:43<01:29, 314.37batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  32%|▎| 12905/40960 [00:43<01:29, 314.37batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 12968/40960 [00:43<01:29, 313.28batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 12968/40960 [00:43<01:29, 313.28batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 13032/40960 [00:43<01:28, 315.02batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 13032/40960 [00:43<01:28, 315.02batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  32%|▎| 13097/40960 [00:43<01:27, 316.64batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  32%|▎| 13097/40960 [00:43<01:27, 316.64batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 13160/40960 [00:44<01:28, 314.71batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 13160/40960 [00:44<01:28, 314.71batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 13218/40960 [00:44<01:30, 306.17batches/s, l2_loss: 0.0438 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 13218/40960 [00:44<01:30, 306.17batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 13285/40960 [00:44<01:28, 313.58batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  32%|▎| 13285/40960 [00:44<01:28, 313.58batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13348/40960 [00:44<01:28, 312.59batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13348/40960 [00:44<01:28, 312.59batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13406/40960 [00:44<01:30, 305.84batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13406/40960 [00:44<01:30, 305.84batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13464/40960 [00:45<01:31, 301.08batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13464/40960 [00:45<01:31, 301.08batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13526/40960 [00:45<01:30, 303.03batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13526/40960 [00:45<01:30, 303.03batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13591/40960 [00:45<01:28, 309.23batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13591/40960 [00:45<01:28, 309.23batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13654/40960 [00:45<01:28, 309.83batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  33%|▎| 13654/40960 [00:45<01:28, 309.83batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  33%|▎| 13711/40960 [00:45<01:30, 301.58batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  33%|▎| 13711/40960 [00:45<01:30, 301.58batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13762/40960 [00:46<01:34, 287.47batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13762/40960 [00:46<01:34, 287.47batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13816/40960 [00:46<01:36, 281.70batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13816/40960 [00:46<01:36, 281.70batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13873/40960 [00:46<01:35, 282.40batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13873/40960 [00:46<01:35, 282.40batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13934/40960 [00:46<01:33, 287.71batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13934/40960 [00:46<01:33, 287.71batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13988/40960 [00:46<01:35, 281.65batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 13988/40960 [00:46<01:35, 281.65batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 14043/40960 [00:47<01:36, 278.25batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 14043/40960 [00:47<01:36, 278.25batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 14105/40960 [00:47<01:33, 287.01batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  34%|▎| 14105/40960 [00:47<01:33, 287.01batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  35%|▎| 14168/40960 [00:47<01:30, 295.30batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  35%|▎| 14168/40960 [00:47<01:30, 295.30batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14228/40960 [00:47<01:30, 296.35batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14228/40960 [00:47<01:30, 296.35batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14290/40960 [00:47<01:28, 299.69batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14290/40960 [00:47<01:28, 299.69batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14348/40960 [00:48<01:29, 296.43batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14348/40960 [00:48<01:29, 296.43batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14398/40960 [00:48<01:34, 281.19batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14398/40960 [00:48<01:34, 281.19batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14454/40960 [00:48<01:34, 280.24batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14454/40960 [00:48<01:34, 280.24batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14510/40960 [00:48<01:35, 277.10batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  35%|▎| 14510/40960 [00:48<01:35, 277.10batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14564/40960 [00:48<01:36, 274.24batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14564/40960 [00:48<01:36, 274.24batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14625/40960 [00:49<01:32, 283.37batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14625/40960 [00:49<01:32, 283.37batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14691/40960 [00:49<01:28, 296.63batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14691/40960 [00:49<01:28, 296.63batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14758/40960 [00:49<01:25, 306.95batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14758/40960 [00:49<01:25, 306.95batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14822/40960 [00:49<01:24, 309.60batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14822/40960 [00:49<01:24, 309.60batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  36%|▎| 14882/40960 [00:49<01:25, 305.97batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  36%|▎| 14882/40960 [00:49<01:25, 305.97batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14942/40960 [00:50<01:25, 303.41batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  36%|▎| 14942/40960 [00:50<01:25, 303.41batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  37%|▎| 15000/40960 [00:50<01:26, 298.48batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  37%|▎| 15000/40960 [00:50<01:26, 298.48batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  37%|▎| 15067/40960 [00:50<01:24, 307.89batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  37%|▎| 15067/40960 [00:50<01:24, 307.89batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  37%|▎| 15131/40960 [00:50<01:22, 311.28batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  37%|▎| 15131/40960 [00:50<01:22, 311.28batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  37%|▎| 15185/40960 [00:50<01:26, 298.95batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  37%|▎| 15185/40960 [00:50<01:26, 298.95batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  37%|▎| 15222/40960 [00:51<01:37, 263.59batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  37%|▎| 15222/40960 [00:51<01:37, 263.59batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  37%|▎| 15271/40960 [00:51<01:39, 256.96batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  37%|▎| 15271/40960 [00:51<01:39, 256.96batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  37%|▎| 15329/40960 [00:51<01:36, 266.76batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  37%|▎| 15329/40960 [00:51<01:36, 266.76batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15395/40960 [00:51<01:29, 284.65batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15395/40960 [00:51<01:29, 284.65batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15453/40960 [00:51<01:29, 285.19batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15453/40960 [00:51<01:29, 285.19batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15519/40960 [00:52<01:25, 297.38batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15519/40960 [00:52<01:25, 297.38batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15584/40960 [00:52<01:23, 304.66batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15584/40960 [00:52<01:23, 304.66batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15649/40960 [00:52<01:21, 310.04batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15649/40960 [00:52<01:21, 310.04batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15714/40960 [00:52<01:20, 314.16batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  38%|▍| 15714/40960 [00:52<01:20, 314.16batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 15772/40960 [00:52<01:22, 306.44batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 15772/40960 [00:52<01:22, 306.44batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 15832/40960 [00:53<01:22, 303.57batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 15832/40960 [00:53<01:22, 303.57batches/s, l2_loss: 0.0435 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|▍| 15888/40960 [00:53<01:24, 296.35batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 15888/40960 [00:53<01:24, 296.35batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  39%|▍| 15947/40960 [00:53<01:24, 295.72batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  39%|▍| 15947/40960 [00:53<01:24, 295.72batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  39%|▍| 16006/40960 [00:53<01:24, 294.41batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  39%|▍| 16006/40960 [00:53<01:24, 294.41batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 16062/40960 [00:53<01:26, 288.24batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 16062/40960 [00:53<01:26, 288.24batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 16118/40960 [00:54<01:27, 284.31batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 16118/40960 [00:54<01:27, 284.31batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 16165/40960 [00:54<01:32, 266.89batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  39%|▍| 16165/40960 [00:54<01:32, 266.89batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  40%|▍| 16225/40960 [00:54<01:29, 276.70batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  40%|▍| 16225/40960 [00:54<01:29, 276.70batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16285/40960 [00:54<01:27, 281.35batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16285/40960 [00:54<01:27, 281.35batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  40%|▍| 16345/40960 [00:54<01:25, 286.62batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  40%|▍| 16345/40960 [00:54<01:25, 286.62batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16396/40960 [00:55<01:28, 276.51batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16396/40960 [00:55<01:28, 276.51batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16460/40960 [00:55<01:24, 288.44batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16460/40960 [00:55<01:24, 288.44batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16521/40960 [00:55<01:23, 293.11batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16521/40960 [00:55<01:23, 293.11batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16572/40960 [00:55<01:26, 281.64batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  40%|▍| 16572/40960 [00:55<01:26, 281.64batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  41%|▍| 16629/40960 [00:55<01:26, 281.30batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  41%|▍| 16629/40960 [00:55<01:26, 281.30batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  41%|▍| 16684/40960 [00:56<01:27, 278.06batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  41%|▍| 16684/40960 [00:56<01:27, 278.06batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  41%|▍| 16732/40960 [00:56<01:31, 265.08batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  41%|▍| 16732/40960 [00:56<01:31, 265.08batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  41%|▍| 16785/40960 [00:56<01:31, 263.65batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  41%|▍| 16785/40960 [00:56<01:31, 263.65batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  41%|▍| 16845/40960 [00:56<01:28, 273.34batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  41%|▍| 16845/40960 [00:56<01:28, 273.34batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  41%|▍| 16906/40960 [00:56<01:25, 282.03batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  41%|▍| 16906/40960 [00:56<01:25, 282.03batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  41%|▍| 16961/40960 [00:57<01:25, 279.75batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  41%|▍| 16961/40960 [00:57<01:25, 279.75batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17015/40960 [00:57<01:26, 276.09batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17015/40960 [00:57<01:26, 276.09batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17075/40960 [00:57<01:24, 282.75batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17075/40960 [00:57<01:24, 282.75batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17137/40960 [00:57<01:22, 289.96batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17137/40960 [00:57<01:22, 289.96batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17194/40960 [00:58<01:22, 287.40batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17194/40960 [00:58<01:22, 287.40batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17258/40960 [00:58<01:20, 296.23batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17258/40960 [00:58<01:20, 296.23batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17296/40960 [00:58<01:29, 264.26batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17296/40960 [00:58<01:29, 264.26batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17352/40960 [00:58<01:28, 267.87batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  42%|▍| 17352/40960 [00:58<01:28, 267.87batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17415/40960 [00:58<01:23, 281.31batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17415/40960 [00:58<01:23, 281.31batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17467/40960 [00:59<01:25, 274.73batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17467/40960 [00:59<01:25, 274.73batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17529/40960 [00:59<01:22, 284.57batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17529/40960 [00:59<01:22, 284.57batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17592/40960 [00:59<01:20, 292.00batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17592/40960 [00:59<01:20, 292.00batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17650/40960 [00:59<01:20, 290.24batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17650/40960 [00:59<01:20, 290.24batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  43%|▍| 17711/40960 [00:59<01:19, 293.58batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  43%|▍| 17711/40960 [00:59<01:19, 293.58batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17774/40960 [01:00<01:17, 299.80batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  43%|▍| 17774/40960 [01:00<01:17, 299.80batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  44%|▍| 17839/40960 [01:00<01:15, 306.43batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  44%|▍| 17839/40960 [01:00<01:15, 306.43batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  44%|▍| 17897/40960 [01:00<01:16, 300.69batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  44%|▍| 17897/40960 [01:00<01:16, 300.69batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  44%|▍| 17942/40960 [01:00<01:23, 274.82batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  44%|▍| 17942/40960 [01:00<01:23, 274.82batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  44%|▍| 17999/40960 [01:00<01:22, 277.47batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  44%|▍| 17999/40960 [01:00<01:22, 277.47batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  44%|▍| 18057/40960 [01:01<01:21, 280.24batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  44%|▍| 18057/40960 [01:01<01:21, 280.24batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  44%|▍| 18123/40960 [01:01<01:17, 294.13batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  44%|▍| 18123/40960 [01:01<01:17, 294.13batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  44%|▍| 18177/40960 [01:01<01:19, 285.83batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  44%|▍| 18177/40960 [01:01<01:19, 285.83batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  44%|▍| 18225/40960 [01:01<01:24, 270.57batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  44%|▍| 18225/40960 [01:01<01:24, 270.57batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  45%|▍| 18274/40960 [01:01<01:26, 261.17batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  45%|▍| 18274/40960 [01:01<01:26, 261.17batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  45%|▍| 18334/40960 [01:02<01:23, 271.79batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  45%|▍| 18334/40960 [01:02<01:23, 271.79batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18387/40960 [01:02<01:24, 268.20batches/s, l2_loss: 0.0432 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|▍| 18387/40960 [01:02<01:24, 268.20batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18442/40960 [01:02<01:23, 269.03batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18442/40960 [01:02<01:23, 269.03batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18502/40960 [01:02<01:20, 277.50batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18502/40960 [01:02<01:20, 277.50batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18566/40960 [01:02<01:17, 288.91batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18566/40960 [01:02<01:17, 288.91batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18630/40960 [01:03<01:15, 296.94batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  45%|▍| 18630/40960 [01:03<01:15, 296.94batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18693/40960 [01:03<01:13, 302.15batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18693/40960 [01:03<01:13, 302.15batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18759/40960 [01:03<01:11, 309.36batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18759/40960 [01:03<01:11, 309.36batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18825/40960 [01:03<01:10, 314.32batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18825/40960 [01:03<01:10, 314.32batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18882/40960 [01:03<01:12, 305.54batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18882/40960 [01:03<01:12, 305.54batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18942/40960 [01:04<01:12, 303.54batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 18942/40960 [01:04<01:12, 303.54batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 19002/40960 [01:04<01:12, 301.76batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  46%|▍| 19002/40960 [01:04<01:12, 301.76batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19069/40960 [01:04<01:10, 310.53batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19069/40960 [01:04<01:10, 310.53batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19134/40960 [01:04<01:09, 314.57batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19134/40960 [01:04<01:09, 314.57batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19198/40960 [01:04<01:08, 315.90batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19198/40960 [01:04<01:08, 315.90batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19264/40960 [01:05<01:08, 318.90batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19264/40960 [01:05<01:08, 318.90batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19329/40960 [01:05<01:07, 320.17batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19329/40960 [01:05<01:07, 320.17batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19396/40960 [01:05<01:06, 324.57batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19396/40960 [01:05<01:06, 324.57batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19450/40960 [01:05<01:09, 307.77batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  47%|▍| 19450/40960 [01:05<01:09, 307.77batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  48%|▍| 19512/40960 [01:05<01:09, 307.44batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  48%|▍| 19512/40960 [01:05<01:09, 307.44batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  48%|▍| 19576/40960 [01:06<01:08, 310.52batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  48%|▍| 19576/40960 [01:06<01:08, 310.52batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  48%|▍| 19641/40960 [01:06<01:07, 313.63batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  48%|▍| 19641/40960 [01:06<01:07, 313.63batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  48%|▍| 19704/40960 [01:06<01:07, 313.16batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  48%|▍| 19704/40960 [01:06<01:07, 313.16batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  48%|▍| 19770/40960 [01:06<01:06, 317.07batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  48%|▍| 19770/40960 [01:06<01:06, 317.07batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  48%|▍| 19830/40960 [01:06<01:07, 311.17batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  48%|▍| 19830/40960 [01:06<01:07, 311.17batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 19876/40960 [01:07<01:13, 285.79batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 19876/40960 [01:07<01:13, 285.79batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 19924/40960 [01:07<01:17, 270.77batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 19924/40960 [01:07<01:17, 270.77batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 19988/40960 [01:07<01:13, 284.46batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 19988/40960 [01:07<01:13, 284.46batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 20054/40960 [01:07<01:10, 297.17batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 20054/40960 [01:07<01:10, 297.17batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 20104/40960 [01:07<01:14, 281.52batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 20104/40960 [01:07<01:14, 281.52batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 20165/40960 [01:08<01:12, 288.25batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 20165/40960 [01:08<01:12, 288.25batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 20210/40960 [01:08<01:17, 269.06batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  49%|▍| 20210/40960 [01:08<01:17, 269.06batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▍| 20276/40960 [01:08<01:12, 285.95batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▍| 20276/40960 [01:08<01:12, 285.95batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▍| 20342/40960 [01:08<01:09, 297.20batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▍| 20342/40960 [01:08<01:09, 297.20batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▍| 20403/40960 [01:08<01:08, 299.28batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▍| 20403/40960 [01:08<01:08, 299.28batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▍| 20469/40960 [01:09<01:06, 308.28batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▍| 20469/40960 [01:09<01:06, 308.28batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▌| 20536/40960 [01:09<01:04, 315.71batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▌| 20536/40960 [01:09<01:04, 315.71batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▌| 20600/40960 [01:09<01:04, 315.78batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▌| 20600/40960 [01:09<01:04, 315.78batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▌| 20664/40960 [01:09<01:04, 316.42batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  50%|▌| 20664/40960 [01:09<01:04, 316.42batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  51%|▌| 20729/40960 [01:09<01:03, 318.17batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  51%|▌| 20729/40960 [01:09<01:03, 318.17batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  51%|▌| 20793/40960 [01:10<01:03, 318.59batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  51%|▌| 20793/40960 [01:10<01:03, 318.59batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  51%|▌| 20856/40960 [01:10<01:03, 316.48batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  51%|▌| 20856/40960 [01:10<01:03, 316.48batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  51%|▌| 20921/40960 [01:10<01:03, 317.70batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  51%|▌| 20921/40960 [01:10<01:03, 317.70batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  51%|▌| 20986/40960 [01:10<01:02, 319.48batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  51%|▌| 20986/40960 [01:10<01:02, 319.48batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  51%|▌| 21048/40960 [01:10<01:02, 316.41batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  51%|▌| 21048/40960 [01:10<01:02, 316.41batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  52%|▌| 21113/40960 [01:11<01:02, 318.12batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  52%|▌| 21113/40960 [01:11<01:02, 318.12batches/s, l2_loss: 0.0430 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|▌| 21177/40960 [01:11<01:02, 317.30batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21177/40960 [01:11<01:02, 317.30batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21240/40960 [01:11<01:02, 315.29batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21240/40960 [01:11<01:02, 315.29batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21300/40960 [01:11<01:04, 304.81batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21300/40960 [01:11<01:04, 304.81batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  52%|▌| 21367/40960 [01:11<01:02, 312.69batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  52%|▌| 21367/40960 [01:11<01:02, 312.69batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21418/40960 [01:12<01:06, 293.62batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21418/40960 [01:12<01:06, 293.62batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21468/40960 [01:12<01:09, 279.59batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  52%|▌| 21468/40960 [01:12<01:09, 279.59batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21524/40960 [01:12<01:09, 277.92batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21524/40960 [01:12<01:09, 277.92batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21583/40960 [01:12<01:08, 282.11batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21583/40960 [01:12<01:08, 282.11batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21641/40960 [01:12<01:08, 283.45batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21641/40960 [01:12<01:08, 283.45batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21706/40960 [01:13<01:05, 294.74batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21706/40960 [01:13<01:05, 294.74batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21770/40960 [01:13<01:03, 302.03batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21770/40960 [01:13<01:03, 302.03batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21833/40960 [01:13<01:02, 305.27batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21833/40960 [01:13<01:02, 305.27batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21894/40960 [01:13<01:02, 304.72batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  53%|▌| 21894/40960 [01:13<01:02, 304.72batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 21950/40960 [01:13<01:04, 296.46batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 21950/40960 [01:13<01:04, 296.46batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22006/40960 [01:14<01:05, 290.48batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22006/40960 [01:14<01:05, 290.48batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22067/40960 [01:14<01:04, 294.77batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22067/40960 [01:14<01:04, 294.77batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22130/40960 [01:14<01:02, 300.79batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22130/40960 [01:14<01:02, 300.79batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22195/40960 [01:14<01:00, 307.88batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22195/40960 [01:14<01:00, 307.88batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22260/40960 [01:14<01:00, 311.65batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  54%|▌| 22260/40960 [01:14<01:00, 311.65batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22327/40960 [01:15<00:58, 317.72batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22327/40960 [01:15<00:58, 317.72batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22395/40960 [01:15<00:57, 323.81batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22395/40960 [01:15<00:57, 323.81batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22459/40960 [01:15<00:57, 322.43batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22459/40960 [01:15<00:57, 322.43batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22527/40960 [01:15<00:56, 327.43batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22527/40960 [01:15<00:56, 327.43batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22590/40960 [01:15<00:56, 323.52batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22590/40960 [01:15<00:56, 323.52batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22657/40960 [01:16<00:56, 325.79batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22657/40960 [01:16<00:56, 325.79batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22722/40960 [01:16<00:56, 325.40batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  55%|▌| 22722/40960 [01:16<00:56, 325.40batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 22787/40960 [01:16<00:56, 324.14batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 22787/40960 [01:16<00:56, 324.14batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 22850/40960 [01:16<00:56, 320.15batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 22850/40960 [01:16<00:56, 320.15batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 22914/40960 [01:16<00:56, 319.71batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 22914/40960 [01:17<00:56, 319.71batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 22976/40960 [01:17<00:56, 315.77batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 22976/40960 [01:17<00:56, 315.77batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 23042/40960 [01:17<00:56, 319.86batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 23042/40960 [01:17<00:56, 319.86batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 23107/40960 [01:17<00:55, 321.32batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  56%|▌| 23107/40960 [01:17<00:55, 321.32batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23171/40960 [01:17<00:55, 320.84batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23171/40960 [01:17<00:55, 320.84batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23233/40960 [01:18<00:56, 316.16batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23233/40960 [01:18<00:56, 316.16batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23297/40960 [01:18<00:55, 316.40batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23297/40960 [01:18<00:55, 316.40batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23356/40960 [01:18<00:56, 309.43batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23356/40960 [01:18<00:56, 309.43batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  57%|▌| 23421/40960 [01:18<00:55, 313.71batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  57%|▌| 23421/40960 [01:18<00:55, 313.71batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23488/40960 [01:18<00:54, 319.61batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  57%|▌| 23488/40960 [01:18<00:54, 319.61batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23554/40960 [01:19<00:53, 322.47batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23554/40960 [01:19<00:53, 322.47batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23621/40960 [01:19<00:53, 325.52batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23621/40960 [01:19<00:53, 325.52batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23682/40960 [01:19<00:54, 319.14batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23682/40960 [01:19<00:54, 319.14batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23748/40960 [01:19<00:53, 321.26batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23748/40960 [01:19<00:53, 321.26batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23811/40960 [01:19<00:53, 318.99batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23811/40960 [01:19<00:53, 318.99batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23874/40960 [01:20<00:53, 316.41batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23874/40960 [01:20<00:53, 316.41batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  58%|▌| 23939/40960 [01:20<00:53, 317.90batches/s, l2_loss: 0.0430 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|▌| 23939/40960 [01:20<00:53, 317.90batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 23999/40960 [01:20<00:54, 312.57batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 23999/40960 [01:20<00:54, 312.57batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  59%|▌| 24057/40960 [01:20<00:55, 305.32batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  59%|▌| 24057/40960 [01:20<00:55, 305.32batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24119/40960 [01:20<00:55, 305.63batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24119/40960 [01:20<00:55, 305.63batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24179/40960 [01:21<00:55, 303.38batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24179/40960 [01:21<00:55, 303.38batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24242/40960 [01:21<00:54, 305.73batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24242/40960 [01:21<00:54, 305.73batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24308/40960 [01:21<00:53, 312.57batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24308/40960 [01:21<00:53, 312.57batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24371/40960 [01:21<00:52, 313.00batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  59%|▌| 24371/40960 [01:21<00:52, 313.00batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24423/40960 [01:21<00:55, 296.60batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24423/40960 [01:21<00:55, 296.60batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24485/40960 [01:22<00:54, 299.85batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24485/40960 [01:22<00:54, 299.85batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24546/40960 [01:22<00:54, 300.69batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24546/40960 [01:22<00:54, 300.69batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  60%|▌| 24610/40960 [01:22<00:53, 305.17batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  60%|▌| 24610/40960 [01:22<00:53, 305.17batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24671/40960 [01:22<00:53, 303.11batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24671/40960 [01:22<00:53, 303.11batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24737/40960 [01:22<00:52, 310.30batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  60%|▌| 24737/40960 [01:22<00:52, 310.30batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 24798/40960 [01:23<00:52, 308.66batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 24798/40960 [01:23<00:52, 308.66batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  61%|▌| 24852/40960 [01:23<00:54, 296.88batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  61%|▌| 24852/40960 [01:23<00:54, 296.88batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 24912/40960 [01:23<00:54, 297.02batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 24912/40960 [01:23<00:54, 297.02batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 24969/40960 [01:23<00:54, 292.28batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 24969/40960 [01:23<00:54, 292.28batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 25031/40960 [01:23<00:53, 296.62batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 25031/40960 [01:23<00:53, 296.62batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  61%|▌| 25096/40960 [01:24<00:52, 301.87batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  61%|▌| 25096/40960 [01:24<00:52, 301.87batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 25142/40960 [01:24<00:56, 279.07batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 25142/40960 [01:24<00:56, 279.07batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 25187/40960 [01:24<01:00, 262.10batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  61%|▌| 25187/40960 [01:24<01:00, 262.10batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25242/40960 [01:24<00:59, 264.65batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25242/40960 [01:24<00:59, 264.65batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25301/40960 [01:24<00:57, 273.03batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25301/40960 [01:24<00:57, 273.03batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25356/40960 [01:25<00:57, 273.54batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25356/40960 [01:25<00:57, 273.54batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25410/40960 [01:25<00:57, 269.45batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25410/40960 [01:25<00:57, 269.45batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25462/40960 [01:25<00:58, 266.29batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25462/40960 [01:25<00:58, 266.29batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25495/40960 [01:25<01:05, 235.07batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25495/40960 [01:25<01:05, 235.07batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25553/40960 [01:25<01:01, 250.11batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  62%|▌| 25553/40960 [01:25<01:01, 250.11batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25609/40960 [01:26<00:59, 258.89batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25609/40960 [01:26<00:59, 258.89batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25667/40960 [01:26<00:57, 266.58batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25667/40960 [01:26<00:57, 266.58batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25721/40960 [01:26<00:57, 267.19batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25721/40960 [01:26<00:57, 267.19batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25785/40960 [01:26<00:53, 282.44batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25785/40960 [01:26<00:53, 282.44batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25838/40960 [01:26<00:54, 276.78batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25838/40960 [01:26<00:54, 276.78batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25899/40960 [01:27<00:52, 285.13batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25899/40960 [01:27<00:52, 285.13batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25966/40960 [01:27<00:50, 298.98batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  63%|▋| 25966/40960 [01:27<00:50, 298.98batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26032/40960 [01:27<00:48, 308.09batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26032/40960 [01:27<00:48, 308.09batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26088/40960 [01:27<00:49, 298.71batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26088/40960 [01:27<00:49, 298.71batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26148/40960 [01:27<00:49, 298.42batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26148/40960 [01:27<00:49, 298.42batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26204/40960 [01:28<00:50, 292.62batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26204/40960 [01:28<00:50, 292.62batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26267/40960 [01:28<00:49, 299.08batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26267/40960 [01:28<00:49, 299.08batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26332/40960 [01:28<00:47, 306.52batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26332/40960 [01:28<00:47, 306.52batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26395/40960 [01:28<00:47, 308.79batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  64%|▋| 26395/40960 [01:28<00:47, 308.79batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26459/40960 [01:28<00:46, 311.59batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26459/40960 [01:28<00:46, 311.59batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26520/40960 [01:29<00:47, 306.69batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26520/40960 [01:29<00:47, 306.69batches/s, l2_loss: 0.0429 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 26575/40960 [01:29<00:48, 295.39batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26575/40960 [01:29<00:48, 295.39batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26641/40960 [01:29<00:46, 304.73batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26641/40960 [01:29<00:46, 304.73batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26709/40960 [01:29<00:45, 314.63batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26709/40960 [01:29<00:45, 314.63batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26775/40960 [01:29<00:44, 318.79batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  65%|▋| 26775/40960 [01:29<00:44, 318.79batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 26833/40960 [01:30<00:45, 309.12batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 26833/40960 [01:30<00:45, 309.12batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 26896/40960 [01:30<00:45, 309.73batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 26896/40960 [01:30<00:45, 309.73batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 26960/40960 [01:30<00:44, 312.77batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 26960/40960 [01:30<00:44, 312.77batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  66%|▋| 27023/40960 [01:30<00:44, 312.34batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  66%|▋| 27023/40960 [01:30<00:44, 312.34batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 27081/40960 [01:30<00:45, 305.54batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 27081/40960 [01:30<00:45, 305.54batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 27139/40960 [01:31<00:46, 300.05batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 27139/40960 [01:31<00:46, 300.05batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:31<00:45, 300.67batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:31<00:45, 300.67batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27266/40960 [01:31<00:44, 308.92batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27266/40960 [01:31<00:44, 308.92batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27328/40960 [01:31<00:44, 309.22batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27328/40960 [01:31<00:44, 309.22batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27386/40960 [01:31<00:44, 302.44batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27386/40960 [01:31<00:44, 302.44batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27448/40960 [01:32<00:44, 303.21batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27448/40960 [01:32<00:44, 303.21batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27503/40960 [01:32<00:45, 293.23batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27503/40960 [01:32<00:45, 293.23batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27562/40960 [01:32<00:45, 292.08batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27562/40960 [01:32<00:45, 292.08batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27627/40960 [01:32<00:44, 300.67batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  67%|▋| 27627/40960 [01:32<00:44, 300.67batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 27692/40960 [01:32<00:43, 306.70batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 27692/40960 [01:32<00:43, 306.70batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 27757/40960 [01:33<00:42, 311.21batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 27757/40960 [01:33<00:42, 311.21batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 27818/40960 [01:33<00:42, 307.90batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 27818/40960 [01:33<00:42, 307.90batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  68%|▋| 27882/40960 [01:33<00:41, 311.47batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  68%|▋| 27882/40960 [01:33<00:41, 311.47batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  68%|▋| 27916/40960 [01:33<00:48, 269.09batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  68%|▋| 27916/40960 [01:33<00:48, 269.09batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 27977/40960 [01:33<00:46, 278.84batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 27977/40960 [01:33<00:46, 278.84batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 28034/40960 [01:34<00:46, 279.83batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  68%|▋| 28034/40960 [01:34<00:46, 279.83batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28087/40960 [01:34<00:46, 275.33batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28087/40960 [01:34<00:46, 275.33batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28150/40960 [01:34<00:44, 286.96batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28150/40960 [01:34<00:44, 286.96batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28214/40960 [01:34<00:43, 296.05batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28214/40960 [01:34<00:43, 296.05batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28276/40960 [01:34<00:42, 300.07batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28276/40960 [01:34<00:42, 300.07batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28333/40960 [01:35<00:42, 295.29batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  69%|▋| 28333/40960 [01:35<00:42, 295.29batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  69%|▋| 28393/40960 [01:35<00:42, 296.69batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  69%|▋| 28393/40960 [01:35<00:42, 296.69batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  69%|▋| 28456/40960 [01:35<00:41, 302.07batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  69%|▋| 28456/40960 [01:35<00:41, 302.07batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  70%|▋| 28520/40960 [01:35<00:40, 307.28batches/s, l2_loss: 0.0429 - round_los\u001b[A\n",
      "Training:  70%|▋| 28520/40960 [01:35<00:40, 307.28batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28584/40960 [01:35<00:39, 310.87batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28584/40960 [01:35<00:39, 310.87batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28646/40960 [01:36<00:39, 309.83batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28646/40960 [01:36<00:39, 309.83batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28703/40960 [01:36<00:40, 302.35batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28703/40960 [01:36<00:40, 302.35batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28754/40960 [01:36<00:42, 286.78batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28754/40960 [01:36<00:42, 286.78batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28814/40960 [01:36<00:41, 290.46batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28814/40960 [01:36<00:41, 290.46batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28870/40960 [01:36<00:42, 286.29batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  70%|▋| 28870/40960 [01:36<00:42, 286.29batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 28930/40960 [01:37<00:41, 289.97batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 28930/40960 [01:37<00:41, 289.97batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 28995/40960 [01:37<00:39, 299.96batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 28995/40960 [01:37<00:39, 299.96batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 29055/40960 [01:37<00:39, 298.26batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 29055/40960 [01:37<00:39, 298.26batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 29116/40960 [01:37<00:39, 298.53batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 29116/40960 [01:37<00:39, 298.53batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 29178/40960 [01:37<00:39, 301.86batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 29178/40960 [01:37<00:39, 301.86batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  71%|▋| 29240/40960 [01:38<00:38, 303.80batches/s, l2_loss: 0.0430 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|▋| 29240/40960 [01:38<00:38, 303.80batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29301/40960 [01:38<00:38, 302.94batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29301/40960 [01:38<00:38, 302.94batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29366/40960 [01:38<00:37, 308.69batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29366/40960 [01:38<00:37, 308.69batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29432/40960 [01:38<00:36, 313.99batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29432/40960 [01:38<00:36, 313.99batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29497/40960 [01:38<00:36, 315.89batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29497/40960 [01:38<00:36, 315.89batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29561/40960 [01:39<00:36, 315.87batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29561/40960 [01:39<00:36, 315.87batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29625/40960 [01:39<00:35, 316.09batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29625/40960 [01:39<00:35, 316.09batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29691/40960 [01:39<00:35, 319.49batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  72%|▋| 29691/40960 [01:39<00:35, 319.49batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29757/40960 [01:39<00:34, 322.49batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29757/40960 [01:39<00:34, 322.49batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29818/40960 [01:39<00:35, 315.92batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29818/40960 [01:40<00:35, 315.92batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29875/40960 [01:40<00:36, 305.36batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29875/40960 [01:40<00:36, 305.36batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29933/40960 [01:40<00:36, 299.76batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29933/40960 [01:40<00:36, 299.76batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29983/40960 [01:40<00:38, 283.90batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 29983/40960 [01:40<00:38, 283.90batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 30019/40960 [01:40<00:43, 252.56batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 30019/40960 [01:40<00:43, 252.56batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 30074/40960 [01:41<00:42, 258.58batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  73%|▋| 30074/40960 [01:41<00:42, 258.58batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  74%|▋| 30140/40960 [01:41<00:38, 279.81batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  74%|▋| 30140/40960 [01:41<00:38, 279.81batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  74%|▋| 30205/40960 [01:41<00:36, 293.11batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  74%|▋| 30205/40960 [01:41<00:36, 293.11batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  74%|▋| 30271/40960 [01:41<00:35, 303.85batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  74%|▋| 30271/40960 [01:41<00:35, 303.85batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  74%|▋| 30337/40960 [01:41<00:34, 311.19batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  74%|▋| 30337/40960 [01:41<00:34, 311.19batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  74%|▋| 30402/40960 [01:42<00:33, 315.13batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  74%|▋| 30402/40960 [01:42<00:33, 315.13batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  74%|▋| 30467/40960 [01:42<00:33, 317.65batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  74%|▋| 30467/40960 [01:42<00:33, 317.65batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  75%|▋| 30534/40960 [01:42<00:32, 322.35batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  75%|▋| 30534/40960 [01:42<00:32, 322.35batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  75%|▋| 30598/40960 [01:42<00:32, 320.77batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  75%|▋| 30598/40960 [01:42<00:32, 320.77batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  75%|▋| 30662/40960 [01:42<00:32, 319.22batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  75%|▋| 30662/40960 [01:42<00:32, 319.22batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  75%|▊| 30728/40960 [01:43<00:31, 321.36batches/s, l2_loss: 0.0430 - round_los\u001b[A\n",
      "Training:  75%|▊| 30728/40960 [01:43<00:31, 321.36batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  75%|▊| 30791/40960 [01:43<00:31, 319.05batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  75%|▊| 30791/40960 [01:43<00:31, 319.05batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  75%|▊| 30855/40960 [01:43<00:31, 318.44batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  75%|▊| 30855/40960 [01:43<00:31, 318.44batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  75%|▊| 30913/40960 [01:43<00:32, 309.70batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  75%|▊| 30913/40960 [01:43<00:32, 309.70batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 30971/40960 [01:43<00:33, 302.61batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 30971/40960 [01:43<00:33, 302.61batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31031/40960 [01:44<00:32, 301.45batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31031/40960 [01:44<00:32, 301.45batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31096/40960 [01:44<00:32, 307.47batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31096/40960 [01:44<00:32, 307.47batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31160/40960 [01:44<00:31, 309.66batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31160/40960 [01:44<00:31, 309.66batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31226/40960 [01:44<00:30, 315.25batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31226/40960 [01:44<00:30, 315.25batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31292/40960 [01:44<00:30, 318.43batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  76%|▊| 31292/40960 [01:44<00:30, 318.43batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31353/40960 [01:45<00:30, 314.02batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31353/40960 [01:45<00:30, 314.02batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31410/40960 [01:45<00:31, 304.97batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31410/40960 [01:45<00:31, 304.97batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31475/40960 [01:45<00:30, 310.48batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31475/40960 [01:45<00:30, 310.48batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31530/40960 [01:45<00:31, 299.42batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31530/40960 [01:45<00:31, 299.42batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31593/40960 [01:45<00:30, 303.45batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31593/40960 [01:45<00:30, 303.45batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31655/40960 [01:46<00:30, 305.16batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31655/40960 [01:46<00:30, 305.16batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31715/40960 [01:46<00:30, 302.54batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  77%|▊| 31715/40960 [01:46<00:30, 302.54batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  78%|▊| 31777/40960 [01:46<00:30, 303.48batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  78%|▊| 31777/40960 [01:46<00:30, 303.48batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  78%|▊| 31843/40960 [01:46<00:29, 311.03batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  78%|▊| 31843/40960 [01:46<00:29, 311.03batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  78%|▊| 31907/40960 [01:46<00:28, 313.01batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  78%|▊| 31907/40960 [01:46<00:28, 313.01batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  78%|▊| 31964/40960 [01:47<00:29, 303.45batches/s, l2_loss: 0.0431 - round_los\u001b[A\n",
      "Training:  78%|▊| 31964/40960 [01:47<00:29, 303.45batches/s, l2_loss: 0.0432 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|▊| 32022/40960 [01:47<00:30, 296.54batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  78%|▊| 32022/40960 [01:47<00:30, 296.54batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  78%|▊| 32084/40960 [01:47<00:29, 299.35batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  78%|▊| 32084/40960 [01:47<00:29, 299.35batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  78%|▊| 32151/40960 [01:47<00:28, 309.68batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  78%|▊| 32151/40960 [01:47<00:28, 309.68batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32215/40960 [01:47<00:28, 312.19batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32215/40960 [01:47<00:28, 312.19batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32275/40960 [01:48<00:28, 308.45batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32275/40960 [01:48<00:28, 308.45batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32340/40960 [01:48<00:27, 312.43batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32340/40960 [01:48<00:27, 312.43batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32394/40960 [01:48<00:28, 298.89batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32394/40960 [01:48<00:28, 298.89batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32458/40960 [01:48<00:27, 304.81batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32458/40960 [01:48<00:27, 304.81batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32524/40960 [01:48<00:27, 311.29batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  79%|▊| 32524/40960 [01:48<00:27, 311.29batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32584/40960 [01:49<00:27, 306.58batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32584/40960 [01:49<00:27, 306.58batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32652/40960 [01:49<00:26, 315.23batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32652/40960 [01:49<00:26, 315.23batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32720/40960 [01:49<00:25, 322.08batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32720/40960 [01:49<00:25, 322.08batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32777/40960 [01:49<00:26, 309.61batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32777/40960 [01:49<00:26, 309.61batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32832/40960 [01:49<00:27, 298.70batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32832/40960 [01:49<00:27, 298.70batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32896/40960 [01:50<00:26, 305.01batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32896/40960 [01:50<00:26, 305.01batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32946/40960 [01:50<00:27, 288.24batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  80%|▊| 32946/40960 [01:50<00:27, 288.24batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  81%|▊| 33007/40960 [01:50<00:27, 292.10batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  81%|▊| 33007/40960 [01:50<00:27, 292.10batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  81%|▊| 33068/40960 [01:50<00:26, 294.79batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  81%|▊| 33068/40960 [01:50<00:26, 294.79batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  81%|▊| 33132/40960 [01:50<00:25, 301.76batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  81%|▊| 33132/40960 [01:50<00:25, 301.76batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  81%|▊| 33184/40960 [01:51<00:27, 286.70batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  81%|▊| 33184/40960 [01:51<00:27, 286.70batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  81%|▊| 33249/40960 [01:51<00:25, 297.42batches/s, l2_loss: 0.0432 - round_los\u001b[A\n",
      "Training:  81%|▊| 33249/40960 [01:51<00:25, 297.42batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  81%|▊| 33317/40960 [01:51<00:24, 309.82batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  81%|▊| 33317/40960 [01:51<00:24, 309.82batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  81%|▊| 33382/40960 [01:51<00:24, 312.62batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  81%|▊| 33382/40960 [01:51<00:24, 312.62batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33446/40960 [01:51<00:23, 313.97batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33446/40960 [01:51<00:23, 313.97batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33499/40960 [01:52<00:24, 298.73batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33499/40960 [01:52<00:24, 298.73batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33565/40960 [01:52<00:24, 306.67batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33565/40960 [01:52<00:24, 306.67batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33630/40960 [01:52<00:23, 311.12batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33630/40960 [01:52<00:23, 311.12batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33689/40960 [01:52<00:23, 305.14batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33689/40960 [01:52<00:23, 305.14batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33748/40960 [01:52<00:23, 301.95batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  82%|▊| 33748/40960 [01:52<00:23, 301.95batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 33800/40960 [01:53<00:24, 286.88batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 33800/40960 [01:53<00:24, 286.88batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 33856/40960 [01:53<00:25, 283.72batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 33856/40960 [01:53<00:25, 283.72batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 33914/40960 [01:53<00:24, 285.33batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 33914/40960 [01:53<00:24, 285.33batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 33973/40960 [01:53<00:24, 288.08batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 33973/40960 [01:53<00:24, 288.08batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 34036/40960 [01:53<00:23, 295.69batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 34036/40960 [01:53<00:23, 295.69batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 34103/40960 [01:54<00:22, 307.06batches/s, l2_loss: 0.0433 - round_los\u001b[A\n",
      "Training:  83%|▊| 34103/40960 [01:54<00:22, 307.06batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  83%|▊| 34171/40960 [01:54<00:21, 315.99batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  83%|▊| 34171/40960 [01:54<00:21, 315.99batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34234/40960 [01:54<00:21, 314.18batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34234/40960 [01:54<00:21, 314.18batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34297/40960 [01:54<00:21, 313.12batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34297/40960 [01:54<00:21, 313.12batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34362/40960 [01:54<00:20, 316.07batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34362/40960 [01:54<00:20, 316.07batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34426/40960 [01:55<00:20, 316.11batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34426/40960 [01:55<00:20, 316.11batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34490/40960 [01:55<00:20, 316.42batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34490/40960 [01:55<00:20, 316.42batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34556/40960 [01:55<00:20, 319.71batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  84%|▊| 34556/40960 [01:55<00:20, 319.71batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34620/40960 [01:55<00:19, 318.83batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34620/40960 [01:55<00:19, 318.83batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34684/40960 [01:55<00:19, 317.85batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34684/40960 [01:55<00:19, 317.85batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34751/40960 [01:56<00:19, 322.93batches/s, l2_loss: 0.0434 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34751/40960 [01:56<00:19, 322.93batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34808/40960 [01:56<00:19, 311.07batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34808/40960 [01:56<00:19, 311.07batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34875/40960 [01:56<00:19, 317.55batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34875/40960 [01:56<00:19, 317.55batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34928/40960 [01:56<00:20, 301.44batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34928/40960 [01:56<00:20, 301.44batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34991/40960 [01:56<00:19, 304.25batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  85%|▊| 34991/40960 [01:56<00:19, 304.25batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  86%|▊| 35056/40960 [01:57<00:19, 310.41batches/s, l2_loss: 0.0434 - round_los\u001b[A\n",
      "Training:  86%|▊| 35056/40960 [01:57<00:19, 310.41batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35119/40960 [01:57<00:18, 310.82batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35119/40960 [01:57<00:18, 310.82batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35180/40960 [01:57<00:18, 307.94batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35180/40960 [01:57<00:18, 307.94batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35246/40960 [01:57<00:18, 314.28batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35246/40960 [01:57<00:18, 314.28batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35307/40960 [01:57<00:18, 311.46batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35307/40960 [01:57<00:18, 311.46batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35365/40960 [01:58<00:18, 303.79batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  86%|▊| 35365/40960 [01:58<00:18, 303.79batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35431/40960 [01:58<00:17, 310.70batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35431/40960 [01:58<00:17, 310.70batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35498/40960 [01:58<00:17, 316.74batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35498/40960 [01:58<00:17, 316.74batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35561/40960 [01:58<00:17, 316.18batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35561/40960 [01:58<00:17, 316.18batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35628/40960 [01:58<00:16, 320.67batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35628/40960 [01:58<00:16, 320.67batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35689/40960 [01:59<00:16, 315.87batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35689/40960 [01:59<00:16, 315.87batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35749/40960 [01:59<00:16, 311.03batches/s, l2_loss: 0.0435 - round_los\u001b[A\n",
      "Training:  87%|▊| 35749/40960 [01:59<00:16, 311.03batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  87%|▊| 35809/40960 [01:59<00:16, 307.45batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  87%|▊| 35809/40960 [01:59<00:16, 307.45batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 35873/40960 [01:59<00:16, 310.35batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 35873/40960 [01:59<00:16, 310.35batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 35933/40960 [01:59<00:16, 306.54batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 35933/40960 [01:59<00:16, 306.54batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 35991/40960 [02:00<00:16, 300.91batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 35991/40960 [02:00<00:16, 300.91batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 36054/40960 [02:00<00:16, 304.59batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 36054/40960 [02:00<00:16, 304.59batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 36118/40960 [02:00<00:15, 309.08batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 36118/40960 [02:00<00:15, 309.08batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 36177/40960 [02:00<00:15, 304.49batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 36177/40960 [02:00<00:15, 304.49batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 36243/40960 [02:00<00:15, 311.12batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  88%|▉| 36243/40960 [02:00<00:15, 311.12batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  89%|▉| 36309/40960 [02:01<00:14, 315.73batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  89%|▉| 36309/40960 [02:01<00:14, 315.73batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  89%|▉| 36376/40960 [02:01<00:14, 320.66batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  89%|▉| 36376/40960 [02:01<00:14, 320.66batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  89%|▉| 36443/40960 [02:01<00:13, 324.19batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  89%|▉| 36443/40960 [02:01<00:13, 324.19batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  89%|▉| 36508/40960 [02:01<00:13, 324.40batches/s, l2_loss: 0.0436 - round_los\u001b[A\n",
      "Training:  89%|▉| 36508/40960 [02:01<00:13, 324.40batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  89%|▉| 36572/40960 [02:01<00:13, 322.33batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  89%|▉| 36572/40960 [02:01<00:13, 322.33batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  89%|▉| 36625/40960 [02:02<00:14, 303.63batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  89%|▉| 36625/40960 [02:02<00:14, 303.63batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36682/40960 [02:02<00:14, 296.88batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36682/40960 [02:02<00:14, 296.88batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36738/40960 [02:02<00:14, 290.15batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36738/40960 [02:02<00:14, 290.15batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36797/40960 [02:02<00:14, 290.48batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36797/40960 [02:02<00:14, 290.48batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36860/40960 [02:02<00:13, 297.27batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36860/40960 [02:02<00:13, 297.27batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36922/40960 [02:03<00:13, 301.06batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36922/40960 [02:03<00:13, 301.06batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36984/40960 [02:03<00:13, 303.56batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 36984/40960 [02:03<00:13, 303.56batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 37047/40960 [02:03<00:12, 304.97batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  90%|▉| 37047/40960 [02:03<00:12, 304.97batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37106/40960 [02:03<00:12, 301.24batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37106/40960 [02:03<00:12, 301.24batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37168/40960 [02:04<00:12, 302.78batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37168/40960 [02:04<00:12, 302.78batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37232/40960 [02:04<00:12, 306.38batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37232/40960 [02:04<00:12, 306.38batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37293/40960 [02:04<00:12, 304.98batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37293/40960 [02:04<00:12, 304.98batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37357/40960 [02:04<00:11, 308.86batches/s, l2_loss: 0.0437 - round_los\u001b[A\n",
      "Training:  91%|▉| 37357/40960 [02:04<00:11, 308.86batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  91%|▉| 37423/40960 [02:04<00:11, 314.15batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  91%|▉| 37423/40960 [02:04<00:11, 314.15batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37489/40960 [02:05<00:10, 318.03batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37489/40960 [02:05<00:10, 318.03batches/s, l2_loss: 0.0438 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37555/40960 [02:05<00:10, 321.14batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37555/40960 [02:05<00:10, 321.14batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37621/40960 [02:05<00:10, 323.00batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37621/40960 [02:05<00:10, 323.00batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37686/40960 [02:05<00:10, 323.16batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37686/40960 [02:05<00:10, 323.16batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37750/40960 [02:05<00:09, 321.61batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37750/40960 [02:05<00:09, 321.61batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37812/40960 [02:06<00:09, 317.85batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37812/40960 [02:06<00:09, 317.85batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37874/40960 [02:06<00:09, 314.32batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  92%|▉| 37874/40960 [02:06<00:09, 314.32batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  93%|▉| 37941/40960 [02:06<00:09, 319.65batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  93%|▉| 37941/40960 [02:06<00:09, 319.65batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  93%|▉| 38004/40960 [02:06<00:09, 318.06batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  93%|▉| 38004/40960 [02:06<00:09, 318.06batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  93%|▉| 38066/40960 [02:06<00:09, 314.93batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  93%|▉| 38066/40960 [02:06<00:09, 314.93batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  93%|▉| 38127/40960 [02:07<00:09, 311.71batches/s, l2_loss: 0.0438 - round_los\u001b[A\n",
      "Training:  93%|▉| 38127/40960 [02:07<00:09, 311.71batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  93%|▉| 38186/40960 [02:07<00:09, 304.47batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  93%|▉| 38186/40960 [02:07<00:09, 304.47batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  93%|▉| 38236/40960 [02:07<00:09, 287.50batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  93%|▉| 38236/40960 [02:07<00:09, 287.50batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  93%|▉| 38289/40960 [02:07<00:09, 280.55batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  93%|▉| 38289/40960 [02:07<00:09, 280.55batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38348/40960 [02:07<00:09, 284.48batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38348/40960 [02:07<00:09, 284.48batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38413/40960 [02:08<00:08, 295.85batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38413/40960 [02:08<00:08, 295.85batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38472/40960 [02:08<00:08, 294.49batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38472/40960 [02:08<00:08, 294.49batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38530/40960 [02:08<00:08, 292.97batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38530/40960 [02:08<00:08, 292.97batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38591/40960 [02:08<00:08, 296.12batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38591/40960 [02:08<00:08, 296.12batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38652/40960 [02:08<00:07, 298.50batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  94%|▉| 38652/40960 [02:08<00:07, 298.50batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  95%|▉| 38711/40960 [02:09<00:07, 296.36batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  95%|▉| 38711/40960 [02:09<00:07, 296.36batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  95%|▉| 38772/40960 [02:09<00:07, 298.18batches/s, l2_loss: 0.0439 - round_los\u001b[A\n",
      "Training:  95%|▉| 38772/40960 [02:09<00:07, 298.18batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 38834/40960 [02:09<00:07, 301.69batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 38834/40960 [02:09<00:07, 301.69batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 38897/40960 [02:09<00:06, 304.90batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 38897/40960 [02:09<00:06, 304.90batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 38958/40960 [02:09<00:06, 303.59batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 38958/40960 [02:09<00:06, 303.59batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 39019/40960 [02:10<00:06, 303.32batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 39019/40960 [02:10<00:06, 303.32batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 39082/40960 [02:10<00:06, 306.19batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  95%|▉| 39082/40960 [02:10<00:06, 306.19batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39144/40960 [02:10<00:05, 306.48batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39144/40960 [02:10<00:05, 306.48batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39204/40960 [02:10<00:05, 304.33batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39204/40960 [02:10<00:05, 304.33batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39265/40960 [02:10<00:05, 303.66batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39265/40960 [02:10<00:05, 303.66batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39323/40960 [02:11<00:05, 299.21batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39323/40960 [02:11<00:05, 299.21batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39386/40960 [02:11<00:05, 303.88batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39386/40960 [02:11<00:05, 303.88batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39449/40960 [02:11<00:04, 307.03batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39449/40960 [02:11<00:04, 307.03batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39510/40960 [02:11<00:04, 305.07batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  96%|▉| 39510/40960 [02:11<00:04, 305.07batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  97%|▉| 39573/40960 [02:11<00:04, 306.68batches/s, l2_loss: 0.0440 - round_los\u001b[A\n",
      "Training:  97%|▉| 39573/40960 [02:11<00:04, 306.68batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39632/40960 [02:12<00:04, 302.03batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39632/40960 [02:12<00:04, 302.03batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39691/40960 [02:12<00:04, 299.18batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39691/40960 [02:12<00:04, 299.18batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39753/40960 [02:12<00:04, 301.20batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39753/40960 [02:12<00:04, 301.20batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39812/40960 [02:12<00:03, 298.94batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39812/40960 [02:12<00:03, 298.94batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39871/40960 [02:12<00:03, 296.78batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39871/40960 [02:12<00:03, 296.78batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39934/40960 [02:13<00:03, 301.37batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  97%|▉| 39934/40960 [02:13<00:03, 301.37batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 39996/40960 [02:13<00:03, 302.91batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 39996/40960 [02:13<00:03, 302.91batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40056/40960 [02:13<00:03, 301.10batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40056/40960 [02:13<00:03, 301.10batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [02:13<00:02, 298.81batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40115/40960 [02:13<00:02, 298.81batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40173/40960 [02:13<00:02, 295.71batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40173/40960 [02:13<00:02, 295.71batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40233/40960 [02:14<00:02, 296.38batches/s, l2_loss: 0.0441 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40233/40960 [02:14<00:02, 296.38batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40294/40960 [02:14<00:02, 298.29batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  98%|▉| 40294/40960 [02:14<00:02, 298.29batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40352/40960 [02:14<00:02, 294.75batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40352/40960 [02:14<00:02, 294.75batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40415/40960 [02:14<00:01, 299.52batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40415/40960 [02:14<00:01, 299.52batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  99%|▉| 40477/40960 [02:14<00:01, 301.85batches/s, l2_loss: 0.0441 - round_los\u001b[A\n",
      "Training:  99%|▉| 40477/40960 [02:14<00:01, 301.85batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40540/40960 [02:15<00:01, 304.59batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40540/40960 [02:15<00:01, 304.59batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40602/40960 [02:15<00:01, 305.40batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40602/40960 [02:15<00:01, 305.40batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40665/40960 [02:15<00:00, 307.40batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40665/40960 [02:15<00:00, 307.40batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40728/40960 [02:15<00:00, 308.58batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training:  99%|▉| 40728/40960 [02:15<00:00, 308.58batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training: 100%|▉| 40790/40960 [02:15<00:00, 307.45batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training: 100%|▉| 40790/40960 [02:15<00:00, 307.45batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training: 100%|▉| 40853/40960 [02:16<00:00, 308.38batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training: 100%|▉| 40853/40960 [02:16<00:00, 308.38batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training: 100%|▉| 40914/40960 [02:16<00:00, 306.12batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "Training: 100%|▉| 40914/40960 [02:16<00:00, 306.12batches/s, l2_loss: 0.0442 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:36:28.942730: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  88%|▉| 23/26 [48:50<06:24, 128.03s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:36:31.475433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A\n",
      "Training:   0%|                                | 1/40960 [00:00<9:02:36,  1.26batches/s]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:00<9:02:36,  1.26batches/s, l2_loss: 0.0139 - round_loss: \u001b[A2025-06-09 15:36:33.952373: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%| | 94/40960 [00:00<05:30, 123.66batches/s, l2_loss: 0.0139 - round_loss: \u001b[A\n",
      "Training:   0%| | 94/40960 [00:01<05:30, 123.66batches/s, l2_loss: 0.0234 - round_loss: \u001b[A\n",
      "Training:   0%| | 187/40960 [00:01<03:08, 216.57batches/s, l2_loss: 0.0234 - round_loss:\u001b[A\n",
      "Training:   0%| | 187/40960 [00:01<03:08, 216.57batches/s, l2_loss: 0.0241 - round_loss:\u001b[A\n",
      "Training:   1%| | 281/40960 [00:01<02:21, 287.36batches/s, l2_loss: 0.0241 - round_loss:\u001b[A\n",
      "Training:   1%| | 281/40960 [00:01<02:21, 287.36batches/s, l2_loss: 0.0242 - round_loss:\u001b[A\n",
      "Training:   1%| | 375/40960 [00:01<01:59, 339.19batches/s, l2_loss: 0.0242 - round_loss:\u001b[A\n",
      "Training:   1%| | 375/40960 [00:01<01:59, 339.19batches/s, l2_loss: 0.0245 - round_loss:\u001b[A\n",
      "Training:   1%| | 468/40960 [00:01<01:48, 374.59batches/s, l2_loss: 0.0245 - round_loss:\u001b[A\n",
      "Training:   1%| | 468/40960 [00:01<01:48, 374.59batches/s, l2_loss: 0.0243 - round_loss:\u001b[A\n",
      "Training:   1%| | 560/40960 [00:02<01:41, 398.37batches/s, l2_loss: 0.0243 - round_loss:\u001b[A\n",
      "Training:   1%| | 560/40960 [00:02<01:41, 398.37batches/s, l2_loss: 0.0244 - round_loss:\u001b[A\n",
      "Training:   2%| | 654/40960 [00:02<01:36, 419.10batches/s, l2_loss: 0.0244 - round_loss:\u001b[A\n",
      "Training:   2%| | 654/40960 [00:02<01:36, 419.10batches/s, l2_loss: 0.0248 - round_loss:\u001b[A\n",
      "Training:   2%| | 745/40960 [00:02<01:33, 428.87batches/s, l2_loss: 0.0248 - round_loss:\u001b[A\n",
      "Training:   2%| | 745/40960 [00:02<01:33, 428.87batches/s, l2_loss: 0.0245 - round_loss:\u001b[A\n",
      "Training:   2%| | 836/40960 [00:02<01:31, 436.41batches/s, l2_loss: 0.0245 - round_loss:\u001b[A\n",
      "Training:   2%| | 836/40960 [00:02<01:31, 436.41batches/s, l2_loss: 0.0242 - round_loss:\u001b[A\n",
      "Training:   2%| | 931/40960 [00:02<01:29, 447.51batches/s, l2_loss: 0.0242 - round_loss:\u001b[A\n",
      "Training:   2%| | 931/40960 [00:02<01:29, 447.51batches/s, l2_loss: 0.0243 - round_loss:\u001b[A\n",
      "Training:   3%| | 1027/40960 [00:03<01:27, 456.10batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   3%| | 1027/40960 [00:03<01:27, 456.10batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   3%| | 1122/40960 [00:03<01:26, 460.97batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   3%| | 1122/40960 [00:03<01:26, 460.97batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   3%| | 1218/40960 [00:03<01:25, 465.76batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   3%| | 1218/40960 [00:03<01:25, 465.76batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   3%| | 1314/40960 [00:03<01:24, 469.14batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   3%| | 1314/40960 [00:03<01:24, 469.14batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   3%| | 1408/40960 [00:03<01:24, 468.20batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   3%| | 1408/40960 [00:03<01:24, 468.20batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   4%| | 1499/40960 [00:04<01:25, 464.04batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   4%| | 1499/40960 [00:04<01:25, 464.04batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   4%| | 1594/40960 [00:04<01:24, 466.45batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   4%| | 1594/40960 [00:04<01:24, 466.45batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   4%| | 1685/40960 [00:04<01:24, 462.98batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   4%| | 1685/40960 [00:04<01:24, 462.98batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   4%| | 1776/40960 [00:04<01:25, 459.69batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   4%| | 1776/40960 [00:04<01:25, 459.69batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   5%| | 1868/40960 [00:04<01:25, 458.62batches/s, l2_loss: 0.0243 - round_loss\u001b[A\n",
      "Training:   5%| | 1868/40960 [00:04<01:25, 458.62batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   5%| | 1961/40960 [00:05<01:24, 459.18batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   5%| | 1961/40960 [00:05<01:24, 459.18batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   5%| | 2053/40960 [00:05<01:24, 459.28batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   5%| | 2053/40960 [00:05<01:24, 459.28batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   5%| | 2145/40960 [00:05<01:24, 459.49batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   5%| | 2145/40960 [00:05<01:24, 459.49batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   5%| | 2238/40960 [00:05<01:23, 460.99batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   5%| | 2238/40960 [00:05<01:23, 460.99batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   6%| | 2332/40960 [00:05<01:23, 463.23batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   6%| | 2332/40960 [00:05<01:23, 463.23batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   6%| | 2428/40960 [00:06<01:22, 466.91batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%| | 2428/40960 [00:06<01:22, 466.91batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   6%| | 2521/40960 [00:06<01:22, 465.53batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   6%| | 2521/40960 [00:06<01:22, 465.53batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   6%| | 2615/40960 [00:06<01:22, 465.91batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   6%| | 2615/40960 [00:06<01:22, 465.91batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   7%| | 2707/40960 [00:06<01:22, 464.01batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   7%| | 2707/40960 [00:06<01:22, 464.01batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   7%| | 2801/40960 [00:06<01:22, 464.42batches/s, l2_loss: 0.0242 - round_loss\u001b[A\n",
      "Training:   7%| | 2801/40960 [00:06<01:22, 464.42batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   7%| | 2895/40960 [00:07<01:21, 465.00batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   7%| | 2895/40960 [00:07<01:21, 465.00batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   7%| | 2990/40960 [00:07<01:21, 467.49batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   7%| | 2990/40960 [00:07<01:21, 467.49batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3084/40960 [00:07<01:21, 467.34batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3084/40960 [00:07<01:21, 467.34batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3175/40960 [00:07<01:21, 463.61batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3175/40960 [00:07<01:21, 463.61batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3269/40960 [00:07<01:21, 464.86batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3269/40960 [00:07<01:21, 464.86batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3360/40960 [00:08<01:21, 460.99batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3360/40960 [00:08<01:21, 460.99batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3455/40960 [00:08<01:20, 463.82batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   8%| | 3455/40960 [00:08<01:20, 463.82batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   9%| | 3548/40960 [00:08<01:20, 462.86batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   9%| | 3548/40960 [00:08<01:20, 462.86batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   9%| | 3643/40960 [00:08<01:20, 465.55batches/s, l2_loss: 0.0241 - round_loss\u001b[A\n",
      "Training:   9%| | 3643/40960 [00:08<01:20, 465.55batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:   9%| | 3737/40960 [00:08<01:19, 466.65batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:   9%| | 3737/40960 [00:08<01:19, 466.65batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:   9%| | 3830/40960 [00:09<01:19, 465.29batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:   9%| | 3830/40960 [00:09<01:19, 465.29batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 3923/40960 [00:09<01:19, 464.52batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 3923/40960 [00:09<01:19, 464.52batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 4016/40960 [00:09<01:19, 463.58batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 4016/40960 [00:09<01:19, 463.58batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 4108/40960 [00:09<01:19, 461.59batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 4108/40960 [00:09<01:19, 461.59batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 4201/40960 [00:09<01:19, 462.19batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 4201/40960 [00:09<01:19, 462.19batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 4295/40960 [00:10<01:19, 463.76batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  10%| | 4295/40960 [00:10<01:19, 463.76batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  11%| | 4389/40960 [00:10<01:18, 464.54batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  11%| | 4389/40960 [00:10<01:18, 464.54batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  11%| | 4483/40960 [00:10<01:18, 465.24batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  11%| | 4483/40960 [00:10<01:18, 465.24batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  11%| | 4576/40960 [00:10<01:18, 465.06batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  11%| | 4576/40960 [00:10<01:18, 465.06batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  11%| | 4670/40960 [00:10<01:17, 466.29batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  11%| | 4670/40960 [00:10<01:17, 466.29batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  12%| | 4764/40960 [00:11<01:17, 466.25batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  12%| | 4764/40960 [00:11<01:17, 466.25batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  12%| | 4855/40960 [00:11<01:18, 462.68batches/s, l2_loss: 0.0240 - round_loss\u001b[A\n",
      "Training:  12%| | 4855/40960 [00:11<01:18, 462.68batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  12%| | 4947/40960 [00:11<01:18, 461.69batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  12%| | 4947/40960 [00:11<01:18, 461.69batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  12%| | 5041/40960 [00:11<01:17, 463.34batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  12%| | 5041/40960 [00:11<01:17, 463.34batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5135/40960 [00:11<01:17, 464.29batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5135/40960 [00:11<01:17, 464.29batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5228/40960 [00:12<01:17, 464.02batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5228/40960 [00:12<01:17, 464.02batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5320/40960 [00:12<01:17, 461.95batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5320/40960 [00:12<01:17, 461.95batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5414/40960 [00:12<01:16, 463.89batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5414/40960 [00:12<01:16, 463.89batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5507/40960 [00:12<01:16, 462.78batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5507/40960 [00:12<01:16, 462.78batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5595/40960 [00:12<01:17, 454.98batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5595/40960 [00:12<01:17, 454.98batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5687/40960 [00:13<01:17, 455.60batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5687/40960 [00:13<01:17, 455.60batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5779/40960 [00:13<01:17, 456.27batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5779/40960 [00:13<01:17, 456.27batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5873/40960 [00:13<01:16, 459.40batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5873/40960 [00:13<01:16, 459.40batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5967/40960 [00:13<01:15, 461.25batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5967/40960 [00:13<01:15, 461.25batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6059/40960 [00:13<01:15, 460.12batches/s, l2_loss: 0.0239 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6059/40960 [00:13<01:15, 460.12batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6153/40960 [00:14<01:15, 462.71batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6153/40960 [00:14<01:15, 462.71batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6246/40960 [00:14<01:15, 462.42batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6246/40960 [00:14<01:15, 462.42batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6340/40960 [00:14<01:14, 464.11batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6340/40960 [00:14<01:14, 464.11batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6435/40960 [00:14<01:14, 466.01batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6435/40960 [00:14<01:14, 466.01batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6530/40960 [00:14<01:13, 468.11batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6530/40960 [00:14<01:13, 468.11batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|▏| 6624/40960 [00:15<01:13, 467.53batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6624/40960 [00:15<01:13, 467.53batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6712/40960 [00:15<01:14, 458.32batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6712/40960 [00:15<01:14, 458.32batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6806/40960 [00:15<01:14, 460.92batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6806/40960 [00:15<01:14, 460.92batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6901/40960 [00:15<01:13, 464.61batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6901/40960 [00:15<01:13, 464.61batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6996/40960 [00:15<01:12, 466.53batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6996/40960 [00:15<01:12, 466.53batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7089/40960 [00:16<01:12, 465.99batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7089/40960 [00:16<01:12, 465.99batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7181/40960 [00:16<01:12, 463.44batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7181/40960 [00:16<01:12, 463.44batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7277/40960 [00:16<01:12, 467.48batches/s, l2_loss: 0.0238 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7277/40960 [00:16<01:12, 467.48batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7369/40960 [00:16<01:12, 464.92batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7369/40960 [00:16<01:12, 464.92batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7459/40960 [00:16<01:12, 460.24batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7459/40960 [00:16<01:12, 460.24batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7553/40960 [00:17<01:12, 462.59batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7553/40960 [00:17<01:12, 462.59batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7645/40960 [00:17<01:12, 460.48batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7645/40960 [00:17<01:12, 460.48batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7741/40960 [00:17<01:11, 465.21batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7741/40960 [00:17<01:11, 465.21batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7835/40960 [00:17<01:11, 466.46batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7835/40960 [00:17<01:11, 466.46batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7929/40960 [00:17<01:10, 466.93batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7929/40960 [00:17<01:10, 466.93batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8023/40960 [00:18<01:10, 467.77batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8023/40960 [00:18<01:10, 467.77batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8115/40960 [00:18<01:10, 465.39batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8115/40960 [00:18<01:10, 465.39batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8205/40960 [00:18<01:11, 459.89batches/s, l2_loss: 0.0237 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8205/40960 [00:18<01:11, 459.89batches/s, l2_loss: 0.0249 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8287/40960 [00:18<01:13, 444.39batches/s, l2_loss: 0.0249 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8287/40960 [00:18<01:13, 444.39batches/s, l2_loss: 0.0246 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8370/40960 [00:18<01:14, 435.42batches/s, l2_loss: 0.0246 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8370/40960 [00:18<01:14, 435.42batches/s, l2_loss: 0.0221 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8454/40960 [00:19<01:15, 429.70batches/s, l2_loss: 0.0221 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8454/40960 [00:19<01:15, 429.70batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8540/40960 [00:19<01:15, 429.02batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8540/40960 [00:19<01:15, 429.02batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8623/40960 [00:19<01:16, 424.49batches/s, l2_loss: 0.0234 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8623/40960 [00:19<01:16, 424.49batches/s, l2_loss: 0.0232 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8707/40960 [00:19<01:16, 421.74batches/s, l2_loss: 0.0232 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8707/40960 [00:19<01:16, 421.74batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8789/40960 [00:19<01:16, 417.84batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8789/40960 [00:19<01:16, 417.84batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8876/40960 [00:20<01:15, 422.31batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8876/40960 [00:20<01:15, 422.31batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8960/40960 [00:20<01:15, 421.39batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8960/40960 [00:20<01:15, 421.39batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9041/40960 [00:20<01:16, 415.00batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9041/40960 [00:20<01:16, 415.00batches/s, l2_loss: 0.0231 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9123/40960 [00:20<01:17, 413.08batches/s, l2_loss: 0.0231 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9123/40960 [00:20<01:17, 413.08batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9205/40960 [00:20<01:17, 412.03batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9205/40960 [00:20<01:17, 412.03batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9289/40960 [00:21<01:16, 413.73batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9289/40960 [00:21<01:16, 413.73batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9371/40960 [00:21<01:16, 411.71batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9371/40960 [00:21<01:16, 411.71batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9455/40960 [00:21<01:16, 413.27batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9455/40960 [00:21<01:16, 413.27batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9538/40960 [00:21<01:16, 413.35batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9538/40960 [00:21<01:16, 413.35batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9619/40960 [00:21<01:16, 409.53batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9619/40960 [00:21<01:16, 409.53batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9699/40960 [00:22<01:17, 405.70batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9699/40960 [00:22<01:17, 405.70batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9779/40960 [00:22<01:17, 403.75batches/s, l2_loss: 0.0229 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9779/40960 [00:22<01:17, 403.75batches/s, l2_loss: 0.0228 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9858/40960 [00:22<01:17, 400.30batches/s, l2_loss: 0.0228 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9858/40960 [00:22<01:17, 400.30batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9940/40960 [00:22<01:17, 402.44batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9940/40960 [00:22<01:17, 402.44batches/s, l2_loss: 0.0230 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10024/40960 [00:22<01:15, 407.30batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  24%|▏| 10024/40960 [00:22<01:15, 407.30batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  25%|▏| 10105/40960 [00:23<01:15, 406.60batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  25%|▏| 10105/40960 [00:23<01:15, 406.60batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  25%|▏| 10187/40960 [00:23<01:15, 406.84batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  25%|▏| 10187/40960 [00:23<01:15, 406.84batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  25%|▎| 10272/40960 [00:23<01:14, 411.53batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  25%|▎| 10272/40960 [00:23<01:14, 411.53batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  25%|▎| 10356/40960 [00:23<01:14, 413.12batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  25%|▎| 10356/40960 [00:23<01:14, 413.12batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  25%|▎| 10439/40960 [00:23<01:13, 412.77batches/s, l2_loss: 0.0230 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|▎| 10439/40960 [00:23<01:13, 412.77batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  26%|▎| 10522/40960 [00:24<01:13, 412.48batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  26%|▎| 10522/40960 [00:24<01:13, 412.48batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  26%|▎| 10603/40960 [00:24<01:14, 408.99batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  26%|▎| 10603/40960 [00:24<01:14, 408.99batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  26%|▎| 10685/40960 [00:24<01:14, 408.70batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  26%|▎| 10685/40960 [00:24<01:14, 408.70batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  26%|▎| 10769/40960 [00:24<01:13, 410.97batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  26%|▎| 10769/40960 [00:24<01:13, 410.97batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 10855/40960 [00:24<01:12, 416.55batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 10855/40960 [00:24<01:12, 416.55batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  27%|▎| 10938/40960 [00:25<01:12, 415.52batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  27%|▎| 10938/40960 [00:25<01:12, 415.52batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 11016/40960 [00:25<01:13, 407.61batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 11016/40960 [00:25<01:13, 407.61batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 11097/40960 [00:25<01:13, 405.96batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 11097/40960 [00:25<01:13, 405.96batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 11180/40960 [00:25<01:13, 407.48batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 11180/40960 [00:25<01:13, 407.48batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 11263/40960 [00:25<01:12, 408.29batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  27%|▎| 11263/40960 [00:25<01:12, 408.29batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  28%|▎| 11341/40960 [00:26<01:13, 401.59batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  28%|▎| 11341/40960 [00:26<01:13, 401.59batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  28%|▎| 11423/40960 [00:26<01:13, 403.02batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  28%|▎| 11423/40960 [00:26<01:13, 403.02batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  28%|▎| 11507/40960 [00:26<01:12, 407.67batches/s, l2_loss: 0.0230 - round_los\u001b[A\n",
      "Training:  28%|▎| 11507/40960 [00:26<01:12, 407.67batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  28%|▎| 11588/40960 [00:26<01:12, 406.30batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  28%|▎| 11588/40960 [00:26<01:12, 406.30batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  28%|▎| 11667/40960 [00:26<01:12, 402.37batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  28%|▎| 11667/40960 [00:26<01:12, 402.37batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 11749/40960 [00:27<01:12, 404.31batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 11749/40960 [00:27<01:12, 404.31batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 11833/40960 [00:27<01:11, 407.38batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 11833/40960 [00:27<01:11, 407.38batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 11919/40960 [00:27<01:10, 413.73batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 11919/40960 [00:27<01:10, 413.73batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 11999/40960 [00:27<01:10, 409.41batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 11999/40960 [00:27<01:10, 409.41batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 12082/40960 [00:27<01:10, 410.46batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  29%|▎| 12082/40960 [00:27<01:10, 410.46batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  30%|▎| 12165/40960 [00:28<01:10, 411.05batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  30%|▎| 12165/40960 [00:28<01:10, 411.05batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  30%|▎| 12251/40960 [00:28<01:08, 416.30batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  30%|▎| 12251/40960 [00:28<01:08, 416.30batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  30%|▎| 12331/40960 [00:28<01:09, 409.86batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  30%|▎| 12331/40960 [00:28<01:09, 409.86batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  30%|▎| 12415/40960 [00:28<01:09, 412.77batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  30%|▎| 12415/40960 [00:28<01:09, 412.77batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12498/40960 [00:28<01:08, 412.50batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12498/40960 [00:28<01:08, 412.50batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12585/40960 [00:29<01:07, 418.45batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12585/40960 [00:29<01:07, 418.45batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12667/40960 [00:29<01:08, 414.90batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12667/40960 [00:29<01:08, 414.90batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12753/40960 [00:29<01:07, 418.70batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12753/40960 [00:29<01:07, 418.70batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12838/40960 [00:29<01:07, 419.62batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  31%|▎| 12838/40960 [00:29<01:07, 419.62batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  32%|▎| 12923/40960 [00:29<01:06, 421.05batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  32%|▎| 12923/40960 [00:29<01:06, 421.05batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  32%|▎| 13008/40960 [00:30<01:06, 422.21batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  32%|▎| 13008/40960 [00:30<01:06, 422.21batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  32%|▎| 13093/40960 [00:30<01:05, 422.64batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  32%|▎| 13093/40960 [00:30<01:05, 422.64batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  32%|▎| 13176/40960 [00:30<01:06, 420.08batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  32%|▎| 13176/40960 [00:30<01:06, 420.08batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  32%|▎| 13261/40960 [00:30<01:05, 421.07batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  32%|▎| 13261/40960 [00:30<01:05, 421.07batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  33%|▎| 13347/40960 [00:30<01:05, 422.98batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  33%|▎| 13347/40960 [00:30<01:05, 422.98batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  33%|▎| 13430/40960 [00:31<01:05, 419.39batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  33%|▎| 13430/40960 [00:31<01:05, 419.39batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  33%|▎| 13515/40960 [00:31<01:05, 419.72batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  33%|▎| 13515/40960 [00:31<01:05, 419.72batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  33%|▎| 13600/40960 [00:31<01:05, 420.34batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  33%|▎| 13600/40960 [00:31<01:05, 420.34batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  33%|▎| 13682/40960 [00:31<01:05, 416.83batches/s, l2_loss: 0.0229 - round_los\u001b[A\n",
      "Training:  33%|▎| 13682/40960 [00:31<01:05, 416.83batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 13767/40960 [00:31<01:04, 418.99batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 13767/40960 [00:31<01:04, 418.99batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 13853/40960 [00:32<01:04, 421.84batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 13853/40960 [00:32<01:04, 421.84batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 13938/40960 [00:32<01:03, 422.62batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 13938/40960 [00:32<01:03, 422.62batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 14021/40960 [00:32<01:04, 420.24batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 14021/40960 [00:32<01:04, 420.24batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 14102/40960 [00:32<01:04, 414.77batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  34%|▎| 14102/40960 [00:32<01:04, 414.77batches/s, l2_loss: 0.0228 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14186/40960 [00:32<01:04, 416.02batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14186/40960 [00:32<01:04, 416.02batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14271/40960 [00:33<01:03, 418.71batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14271/40960 [00:33<01:03, 418.71batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14353/40960 [00:33<01:04, 414.69batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14353/40960 [00:33<01:04, 414.69batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14436/40960 [00:33<01:04, 413.78batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14436/40960 [00:33<01:04, 413.78batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14518/40960 [00:33<01:04, 412.08batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  35%|▎| 14518/40960 [00:33<01:04, 412.08batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14602/40960 [00:33<01:03, 414.22batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14602/40960 [00:33<01:03, 414.22batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14684/40960 [00:34<01:03, 412.76batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14684/40960 [00:34<01:03, 412.76batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14768/40960 [00:34<01:03, 414.06batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14768/40960 [00:34<01:03, 414.06batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14850/40960 [00:34<01:03, 412.72batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14850/40960 [00:34<01:03, 412.72batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14932/40960 [00:34<01:03, 411.83batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  36%|▎| 14932/40960 [00:34<01:03, 411.83batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15016/40960 [00:34<01:02, 413.81batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15016/40960 [00:34<01:02, 413.81batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15100/40960 [00:35<01:02, 414.69batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15100/40960 [00:35<01:02, 414.69batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15184/40960 [00:35<01:01, 415.92batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15184/40960 [00:35<01:01, 415.92batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15269/40960 [00:35<01:01, 417.64batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15269/40960 [00:35<01:01, 417.64batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15355/40960 [00:35<01:00, 420.12batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  37%|▎| 15355/40960 [00:35<01:00, 420.12batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  38%|▍| 15438/40960 [00:35<01:00, 418.47batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  38%|▍| 15438/40960 [00:35<01:00, 418.47batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  38%|▍| 15524/40960 [00:36<01:00, 421.72batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  38%|▍| 15524/40960 [00:36<01:00, 421.72batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  38%|▍| 15606/40960 [00:36<01:00, 417.75batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  38%|▍| 15606/40960 [00:36<01:00, 417.75batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  38%|▍| 15687/40960 [00:36<01:01, 412.82batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  38%|▍| 15687/40960 [00:36<01:01, 412.82batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 15771/40960 [00:36<01:00, 414.97batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 15771/40960 [00:36<01:00, 414.97batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 15851/40960 [00:36<01:01, 408.64batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 15851/40960 [00:36<01:01, 408.64batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 15934/40960 [00:37<01:01, 409.15batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 15934/40960 [00:37<01:01, 409.15batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 16014/40960 [00:37<01:01, 406.33batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 16014/40960 [00:37<01:01, 406.33batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 16098/40960 [00:37<01:00, 410.29batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  39%|▍| 16098/40960 [00:37<01:00, 410.29batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  40%|▍| 16180/40960 [00:37<01:00, 409.74batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  40%|▍| 16180/40960 [00:37<01:00, 409.74batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  40%|▍| 16265/40960 [00:37<00:59, 413.66batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  40%|▍| 16265/40960 [00:37<00:59, 413.66batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  40%|▍| 16350/40960 [00:38<00:59, 416.24batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  40%|▍| 16350/40960 [00:38<00:59, 416.24batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  40%|▍| 16433/40960 [00:38<00:58, 415.75batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  40%|▍| 16433/40960 [00:38<00:58, 415.75batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  40%|▍| 16519/40960 [00:38<00:58, 419.10batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  40%|▍| 16519/40960 [00:38<00:58, 419.10batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  41%|▍| 16603/40960 [00:38<00:58, 418.75batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  41%|▍| 16603/40960 [00:38<00:58, 418.75batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  41%|▍| 16687/40960 [00:39<00:58, 418.07batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  41%|▍| 16687/40960 [00:39<00:58, 418.07batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  41%|▍| 16773/40960 [00:39<00:57, 420.34batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  41%|▍| 16773/40960 [00:39<00:57, 420.34batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  41%|▍| 16856/40960 [00:39<00:57, 418.14batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  41%|▍| 16856/40960 [00:39<00:57, 418.14batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  41%|▍| 16941/40960 [00:39<00:57, 418.85batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  41%|▍| 16941/40960 [00:39<00:57, 418.85batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  42%|▍| 17025/40960 [00:39<00:57, 418.65batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  42%|▍| 17025/40960 [00:39<00:57, 418.65batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  42%|▍| 17109/40960 [00:40<00:56, 418.89batches/s, l2_loss: 0.0228 - round_los\u001b[A\n",
      "Training:  42%|▍| 17109/40960 [00:40<00:56, 418.89batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  42%|▍| 17193/40960 [00:40<00:56, 419.21batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  42%|▍| 17193/40960 [00:40<00:56, 419.21batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  42%|▍| 17276/40960 [00:40<00:56, 416.85batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  42%|▍| 17276/40960 [00:40<00:56, 416.85batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  42%|▍| 17358/40960 [00:40<00:57, 413.99batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  42%|▍| 17358/40960 [00:40<00:57, 413.99batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17443/40960 [00:40<00:56, 415.69batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17443/40960 [00:40<00:56, 415.69batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17526/40960 [00:41<00:56, 415.28batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17526/40960 [00:41<00:56, 415.28batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17607/40960 [00:41<00:56, 412.05batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17607/40960 [00:41<00:56, 412.05batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17690/40960 [00:41<00:56, 412.49batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17690/40960 [00:41<00:56, 412.49batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17774/40960 [00:41<00:56, 413.88batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  43%|▍| 17774/40960 [00:41<00:56, 413.88batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 17857/40960 [00:41<00:55, 413.27batches/s, l2_loss: 0.0227 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 17857/40960 [00:41<00:55, 413.27batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 17939/40960 [00:42<00:55, 411.12batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 17939/40960 [00:42<00:55, 411.12batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 18018/40960 [00:42<00:56, 404.90batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 18018/40960 [00:42<00:56, 404.90batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 18100/40960 [00:42<00:56, 406.08batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 18100/40960 [00:42<00:56, 406.08batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 18182/40960 [00:42<00:55, 407.13batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  44%|▍| 18182/40960 [00:42<00:55, 407.13batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18265/40960 [00:42<00:55, 408.88batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18265/40960 [00:42<00:55, 408.88batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18347/40960 [00:43<00:55, 409.12batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18347/40960 [00:43<00:55, 409.12batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18432/40960 [00:43<00:54, 412.54batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18432/40960 [00:43<00:54, 412.54batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18516/40960 [00:43<00:54, 413.41batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18516/40960 [00:43<00:54, 413.41batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18598/40960 [00:43<00:54, 411.84batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  45%|▍| 18598/40960 [00:43<00:54, 411.84batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 18684/40960 [00:43<00:53, 416.47batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 18684/40960 [00:43<00:53, 416.47batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 18769/40960 [00:44<00:53, 417.68batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 18769/40960 [00:44<00:53, 417.68batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 18855/40960 [00:44<00:52, 420.12batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 18855/40960 [00:44<00:52, 420.12batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 18941/40960 [00:44<00:52, 422.99batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 18941/40960 [00:44<00:52, 422.99batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 19024/40960 [00:44<00:52, 420.11batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  46%|▍| 19024/40960 [00:44<00:52, 420.11batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19109/40960 [00:44<00:51, 421.17batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19109/40960 [00:44<00:51, 421.17batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19187/40960 [00:45<00:53, 410.54batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19187/40960 [00:45<00:53, 410.54batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19270/40960 [00:45<00:52, 411.42batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19270/40960 [00:45<00:52, 411.42batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19352/40960 [00:45<00:52, 410.91batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19352/40960 [00:45<00:52, 410.91batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19432/40960 [00:45<00:52, 406.82batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  47%|▍| 19432/40960 [00:45<00:52, 406.82batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19513/40960 [00:45<00:52, 406.11batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19513/40960 [00:45<00:52, 406.11batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19597/40960 [00:46<00:52, 409.41batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19597/40960 [00:46<00:52, 409.41batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19679/40960 [00:46<00:52, 408.98batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19679/40960 [00:46<00:52, 408.98batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19760/40960 [00:46<00:52, 406.71batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19760/40960 [00:46<00:52, 406.71batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19843/40960 [00:46<00:51, 408.46batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  48%|▍| 19843/40960 [00:46<00:51, 408.46batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 19930/40960 [00:46<00:50, 415.14batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 19930/40960 [00:46<00:50, 415.14batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 20017/40960 [00:47<00:49, 419.92batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 20017/40960 [00:47<00:49, 419.92batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 20102/40960 [00:47<00:49, 421.08batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 20102/40960 [00:47<00:49, 421.08batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 20184/40960 [00:47<00:49, 416.62batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 20184/40960 [00:47<00:49, 416.62batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 20266/40960 [00:47<00:49, 414.36batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  49%|▍| 20266/40960 [00:47<00:49, 414.36batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▍| 20350/40960 [00:47<00:49, 414.99batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▍| 20350/40960 [00:47<00:49, 414.99batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▍| 20431/40960 [00:48<00:49, 411.37batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▍| 20431/40960 [00:48<00:49, 411.37batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▌| 20513/40960 [00:48<00:49, 409.77batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▌| 20513/40960 [00:48<00:49, 409.77batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▌| 20595/40960 [00:48<00:49, 409.60batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▌| 20595/40960 [00:48<00:49, 409.60batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▌| 20678/40960 [00:48<00:49, 410.42batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  50%|▌| 20678/40960 [00:48<00:49, 410.42batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  51%|▌| 20763/40960 [00:48<00:48, 414.23batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  51%|▌| 20763/40960 [00:48<00:48, 414.23batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  51%|▌| 20847/40960 [00:49<00:48, 415.02batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  51%|▌| 20847/40960 [00:49<00:48, 415.02batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  51%|▌| 20931/40960 [00:49<00:48, 415.59batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  51%|▌| 20931/40960 [00:49<00:48, 415.59batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  51%|▌| 21015/40960 [00:49<00:47, 415.89batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  51%|▌| 21015/40960 [00:49<00:47, 415.89batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  52%|▌| 21096/40960 [00:49<00:48, 411.79batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  52%|▌| 21096/40960 [00:49<00:48, 411.79batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  52%|▌| 21178/40960 [00:49<00:48, 410.87batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  52%|▌| 21178/40960 [00:49<00:48, 410.87batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  52%|▌| 21262/40960 [00:50<00:47, 413.13batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  52%|▌| 21262/40960 [00:50<00:47, 413.13batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  52%|▌| 21345/40960 [00:50<00:47, 413.68batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  52%|▌| 21345/40960 [00:50<00:47, 413.68batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  52%|▌| 21427/40960 [00:50<00:47, 412.28batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  52%|▌| 21427/40960 [00:50<00:47, 412.28batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  53%|▌| 21511/40960 [00:50<00:46, 414.00batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  53%|▌| 21511/40960 [00:50<00:46, 414.00batches/s, l2_loss: 0.0226 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|▌| 21596/40960 [00:50<00:46, 416.93batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  53%|▌| 21596/40960 [00:50<00:46, 416.93batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  53%|▌| 21682/40960 [00:51<00:45, 420.69batches/s, l2_loss: 0.0227 - round_los\u001b[A\n",
      "Training:  53%|▌| 21682/40960 [00:51<00:45, 420.69batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  53%|▌| 21767/40960 [00:51<00:45, 421.93batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  53%|▌| 21767/40960 [00:51<00:45, 421.93batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  53%|▌| 21852/40960 [00:51<00:45, 421.69batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  53%|▌| 21852/40960 [00:51<00:45, 421.69batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 21936/40960 [00:51<00:45, 419.99batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 21936/40960 [00:51<00:45, 419.99batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 22021/40960 [00:51<00:45, 420.56batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 22021/40960 [00:51<00:45, 420.56batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 22106/40960 [00:52<00:44, 420.50batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 22106/40960 [00:52<00:44, 420.50batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 22189/40960 [00:52<00:44, 418.36batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 22189/40960 [00:52<00:44, 418.36batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 22273/40960 [00:52<00:44, 417.45batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  54%|▌| 22273/40960 [00:52<00:44, 417.45batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22357/40960 [00:52<00:44, 417.71batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22357/40960 [00:52<00:44, 417.71batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22441/40960 [00:52<00:44, 417.75batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22441/40960 [00:52<00:44, 417.75batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22527/40960 [00:53<00:43, 420.94batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22527/40960 [00:53<00:43, 420.94batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22612/40960 [00:53<00:43, 421.49batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22612/40960 [00:53<00:43, 421.49batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22698/40960 [00:53<00:43, 422.56batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  55%|▌| 22698/40960 [00:53<00:43, 422.56batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 22784/40960 [00:53<00:42, 423.36batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 22784/40960 [00:53<00:42, 423.36batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 22868/40960 [00:53<00:42, 421.27batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 22868/40960 [00:53<00:42, 421.27batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 22952/40960 [00:54<00:42, 420.12batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 22952/40960 [00:54<00:42, 420.12batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 23036/40960 [00:54<00:42, 419.65batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 23036/40960 [00:54<00:42, 419.65batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 23120/40960 [00:54<00:42, 418.82batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  56%|▌| 23120/40960 [00:54<00:42, 418.82batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23196/40960 [00:54<00:43, 406.56batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23196/40960 [00:54<00:43, 406.56batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23280/40960 [00:54<00:43, 410.14batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23280/40960 [00:54<00:43, 410.14batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23365/40960 [00:55<00:42, 413.44batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23365/40960 [00:55<00:42, 413.44batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23453/40960 [00:55<00:41, 420.32batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23453/40960 [00:55<00:41, 420.32batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23537/40960 [00:55<00:41, 419.93batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  57%|▌| 23537/40960 [00:55<00:41, 419.93batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23623/40960 [00:55<00:41, 422.34batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23623/40960 [00:55<00:41, 422.34batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23710/40960 [00:55<00:40, 425.79batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23710/40960 [00:55<00:40, 425.79batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23795/40960 [00:56<00:40, 424.32batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23795/40960 [00:56<00:40, 424.32batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23875/40960 [00:56<00:41, 416.24batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23875/40960 [00:56<00:41, 416.24batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23957/40960 [00:56<00:41, 413.12batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  58%|▌| 23957/40960 [00:56<00:41, 413.12batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  59%|▌| 24042/40960 [00:56<00:40, 415.82batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  59%|▌| 24042/40960 [00:56<00:40, 415.82batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  59%|▌| 24129/40960 [00:56<00:40, 420.01batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  59%|▌| 24129/40960 [00:56<00:40, 420.01batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  59%|▌| 24213/40960 [00:57<00:39, 420.00batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  59%|▌| 24213/40960 [00:57<00:39, 420.00batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  59%|▌| 24297/40960 [00:57<00:39, 418.63batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  59%|▌| 24297/40960 [00:57<00:39, 418.63batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24376/40960 [00:57<00:40, 411.55batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24376/40960 [00:57<00:40, 411.55batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24460/40960 [00:57<00:39, 413.92batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24460/40960 [00:57<00:39, 413.92batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24541/40960 [00:57<00:40, 409.94batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24541/40960 [00:57<00:40, 409.94batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24623/40960 [00:58<00:39, 408.72batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24623/40960 [00:58<00:39, 408.72batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24706/40960 [00:58<00:39, 410.30batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  60%|▌| 24706/40960 [00:58<00:39, 410.30batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 24791/40960 [00:58<00:39, 413.62batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 24791/40960 [00:58<00:39, 413.62batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 24876/40960 [00:58<00:38, 415.81batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 24876/40960 [00:58<00:38, 415.81batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 24962/40960 [00:58<00:38, 419.35batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 24962/40960 [00:58<00:38, 419.35batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 25047/40960 [00:59<00:37, 420.53batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 25047/40960 [00:59<00:37, 420.53batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 25133/40960 [00:59<00:37, 421.98batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  61%|▌| 25133/40960 [00:59<00:37, 421.98batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25219/40960 [00:59<00:37, 423.27batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25219/40960 [00:59<00:37, 423.27batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25303/40960 [00:59<00:37, 420.73batches/s, l2_loss: 0.0226 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|▌| 25303/40960 [00:59<00:37, 420.73batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25384/40960 [00:59<00:37, 414.89batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25384/40960 [00:59<00:37, 414.89batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25464/40960 [01:00<00:37, 409.11batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25464/40960 [01:00<00:37, 409.11batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25547/40960 [01:00<00:37, 410.84batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  62%|▌| 25547/40960 [01:00<00:37, 410.84batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25631/40960 [01:00<00:37, 412.39batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25631/40960 [01:00<00:37, 412.39batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25713/40960 [01:00<00:37, 411.47batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25713/40960 [01:00<00:37, 411.47batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25797/40960 [01:00<00:36, 413.57batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25797/40960 [01:00<00:36, 413.57batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25881/40960 [01:01<00:36, 415.31batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25881/40960 [01:01<00:36, 415.31batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25966/40960 [01:01<00:35, 416.96batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  63%|▋| 25966/40960 [01:01<00:35, 416.96batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26051/40960 [01:01<00:35, 419.01batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26051/40960 [01:01<00:35, 419.01batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26132/40960 [01:01<00:35, 414.01batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26132/40960 [01:01<00:35, 414.01batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26215/40960 [01:01<00:35, 411.35batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26215/40960 [01:01<00:35, 411.35batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26295/40960 [01:02<00:35, 407.75batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26295/40960 [01:02<00:35, 407.75batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26378/40960 [01:02<00:35, 409.06batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  64%|▋| 26378/40960 [01:02<00:35, 409.06batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  65%|▋| 26459/40960 [01:02<00:35, 407.44batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  65%|▋| 26459/40960 [01:02<00:35, 407.44batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  65%|▋| 26543/40960 [01:02<00:35, 410.22batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  65%|▋| 26543/40960 [01:02<00:35, 410.22batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  65%|▋| 26623/40960 [01:02<00:35, 406.17batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  65%|▋| 26623/40960 [01:02<00:35, 406.17batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  65%|▋| 26706/40960 [01:03<00:34, 408.81batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  65%|▋| 26706/40960 [01:03<00:34, 408.81batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  65%|▋| 26792/40960 [01:03<00:34, 414.20batches/s, l2_loss: 0.0226 - round_los\u001b[A\n",
      "Training:  65%|▋| 26792/40960 [01:03<00:34, 414.20batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 26875/40960 [01:03<00:34, 413.51batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 26875/40960 [01:03<00:34, 413.51batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 26955/40960 [01:03<00:34, 408.79batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 26955/40960 [01:03<00:34, 408.79batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 27036/40960 [01:03<00:34, 407.04batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 27036/40960 [01:03<00:34, 407.04batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 27121/40960 [01:04<00:33, 411.38batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 27121/40960 [01:04<00:33, 411.38batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 27204/40960 [01:04<00:33, 411.54batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  66%|▋| 27204/40960 [01:04<00:33, 411.54batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27288/40960 [01:04<00:33, 413.88batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27288/40960 [01:04<00:33, 413.88batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27373/40960 [01:04<00:32, 416.74batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27373/40960 [01:04<00:32, 416.74batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27453/40960 [01:04<00:32, 410.29batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27453/40960 [01:04<00:32, 410.29batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27532/40960 [01:05<00:33, 404.78batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27532/40960 [01:05<00:33, 404.78batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27616/40960 [01:05<00:32, 408.60batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  67%|▋| 27616/40960 [01:05<00:32, 408.60batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 27701/40960 [01:05<00:32, 413.19batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 27701/40960 [01:05<00:32, 413.19batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 27787/40960 [01:05<00:31, 417.54batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 27787/40960 [01:05<00:31, 417.54batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 27868/40960 [01:05<00:31, 413.57batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 27868/40960 [01:05<00:31, 413.57batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 27953/40960 [01:06<00:31, 416.04batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 27953/40960 [01:06<00:31, 416.04batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 28037/40960 [01:06<00:30, 417.02batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  68%|▋| 28037/40960 [01:06<00:30, 417.02batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28122/40960 [01:06<00:30, 417.98batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28122/40960 [01:06<00:30, 417.98batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28204/40960 [01:06<00:30, 415.50batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28204/40960 [01:06<00:30, 415.50batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28290/40960 [01:06<00:30, 419.13batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28290/40960 [01:06<00:30, 419.13batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28374/40960 [01:07<00:30, 418.83batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28374/40960 [01:07<00:30, 418.83batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28458/40960 [01:07<00:29, 418.75batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  69%|▋| 28458/40960 [01:07<00:29, 418.75batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  70%|▋| 28543/40960 [01:07<00:29, 420.52batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  70%|▋| 28543/40960 [01:07<00:29, 420.52batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  70%|▋| 28629/40960 [01:07<00:29, 422.59batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  70%|▋| 28629/40960 [01:07<00:29, 422.59batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  70%|▋| 28715/40960 [01:07<00:28, 423.85batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  70%|▋| 28715/40960 [01:07<00:28, 423.85batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  70%|▋| 28799/40960 [01:08<00:28, 422.34batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  70%|▋| 28799/40960 [01:08<00:28, 422.34batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 28882/40960 [01:08<00:28, 419.72batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 28882/40960 [01:08<00:28, 419.72batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 28969/40960 [01:08<00:28, 423.49batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 28969/40960 [01:08<00:28, 423.49batches/s, l2_loss: 0.0225 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|▋| 29056/40960 [01:08<00:27, 425.60batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 29056/40960 [01:08<00:27, 425.60batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 29141/40960 [01:08<00:27, 423.96batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 29141/40960 [01:08<00:27, 423.96batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 29226/40960 [01:09<00:27, 423.29batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  71%|▋| 29226/40960 [01:09<00:27, 423.29batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29307/40960 [01:09<00:27, 417.80batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29307/40960 [01:09<00:27, 417.80batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29391/40960 [01:09<00:27, 417.08batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29391/40960 [01:09<00:27, 417.08batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29477/40960 [01:09<00:27, 419.62batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29477/40960 [01:09<00:27, 419.62batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29560/40960 [01:09<00:27, 418.00batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29560/40960 [01:09<00:27, 418.00batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29646/40960 [01:10<00:26, 420.96batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  72%|▋| 29646/40960 [01:10<00:26, 420.96batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 29733/40960 [01:10<00:26, 423.81batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 29733/40960 [01:10<00:26, 423.81batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 29815/40960 [01:10<00:26, 418.92batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 29815/40960 [01:10<00:26, 418.92batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 29900/40960 [01:10<00:26, 420.11batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 29900/40960 [01:10<00:26, 420.11batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 29985/40960 [01:10<00:26, 420.86batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 29985/40960 [01:11<00:26, 420.86batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 30069/40960 [01:11<00:25, 419.77batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  73%|▋| 30069/40960 [01:11<00:25, 419.77batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30153/40960 [01:11<00:25, 419.65batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30153/40960 [01:11<00:25, 419.65batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30239/40960 [01:11<00:25, 422.60batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30239/40960 [01:11<00:25, 422.60batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30321/40960 [01:11<00:25, 418.09batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30321/40960 [01:11<00:25, 418.09batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30408/40960 [01:12<00:24, 422.58batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30408/40960 [01:12<00:24, 422.58batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30492/40960 [01:12<00:24, 420.47batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  74%|▋| 30492/40960 [01:12<00:24, 420.47batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▋| 30576/40960 [01:12<00:24, 420.19batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▋| 30576/40960 [01:12<00:24, 420.19batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▋| 30663/40960 [01:12<00:24, 423.37batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▋| 30663/40960 [01:12<00:24, 423.37batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▊| 30748/40960 [01:12<00:24, 423.08batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▊| 30748/40960 [01:12<00:24, 423.08batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▊| 30832/40960 [01:13<00:24, 421.82batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▊| 30832/40960 [01:13<00:24, 421.82batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▊| 30916/40960 [01:13<00:23, 421.08batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  75%|▊| 30916/40960 [01:13<00:23, 421.08batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 30999/40960 [01:13<00:23, 418.53batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 30999/40960 [01:13<00:23, 418.53batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 31082/40960 [01:13<00:23, 417.34batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 31082/40960 [01:13<00:23, 417.34batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 31165/40960 [01:13<00:23, 416.15batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 31165/40960 [01:13<00:23, 416.15batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 31250/40960 [01:14<00:23, 417.95batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 31250/40960 [01:14<00:23, 417.95batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 31334/40960 [01:14<00:23, 418.39batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  76%|▊| 31334/40960 [01:14<00:23, 418.39batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  77%|▊| 31418/40960 [01:14<00:22, 418.75batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  77%|▊| 31418/40960 [01:14<00:22, 418.75batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  77%|▊| 31500/40960 [01:14<00:22, 414.79batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  77%|▊| 31500/40960 [01:14<00:22, 414.79batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  77%|▊| 31580/40960 [01:14<00:22, 410.20batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  77%|▊| 31580/40960 [01:14<00:22, 410.20batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  77%|▊| 31665/40960 [01:15<00:22, 413.41batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  77%|▊| 31665/40960 [01:15<00:22, 413.41batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 31745/40960 [01:15<00:22, 409.18batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 31745/40960 [01:15<00:22, 409.18batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 31830/40960 [01:15<00:22, 412.62batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 31830/40960 [01:15<00:22, 412.62batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 31906/40960 [01:15<00:22, 402.82batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 31906/40960 [01:15<00:22, 402.82batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 31986/40960 [01:15<00:22, 400.64batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 31986/40960 [01:15<00:22, 400.64batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 32068/40960 [01:16<00:22, 402.41batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 32068/40960 [01:16<00:22, 402.41batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 32151/40960 [01:16<00:21, 405.29batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  78%|▊| 32151/40960 [01:16<00:21, 405.29batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32230/40960 [01:16<00:21, 401.90batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32230/40960 [01:16<00:21, 401.90batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32311/40960 [01:16<00:21, 402.50batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32311/40960 [01:16<00:21, 402.50batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32391/40960 [01:16<00:21, 401.72batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32391/40960 [01:16<00:21, 401.72batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32475/40960 [01:17<00:20, 406.90batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32475/40960 [01:17<00:20, 406.90batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32560/40960 [01:17<00:20, 411.58batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  79%|▊| 32560/40960 [01:17<00:20, 411.58batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  80%|▊| 32643/40960 [01:17<00:20, 411.70batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  80%|▊| 32643/40960 [01:17<00:20, 411.70batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  80%|▊| 32727/40960 [01:17<00:19, 413.23batches/s, l2_loss: 0.0225 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32727/40960 [01:17<00:19, 413.23batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  80%|▊| 32809/40960 [01:17<00:19, 411.24batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  80%|▊| 32809/40960 [01:17<00:19, 411.24batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  80%|▊| 32892/40960 [01:18<00:19, 411.03batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  80%|▊| 32892/40960 [01:18<00:19, 411.03batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 32973/40960 [01:18<00:19, 408.71batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 32973/40960 [01:18<00:19, 408.71batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 33054/40960 [01:18<00:19, 407.15batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 33054/40960 [01:18<00:19, 407.15batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 33140/40960 [01:18<00:18, 413.73batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 33140/40960 [01:18<00:18, 413.73batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 33224/40960 [01:18<00:18, 414.78batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 33224/40960 [01:18<00:18, 414.78batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 33308/40960 [01:19<00:18, 415.52batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  81%|▊| 33308/40960 [01:19<00:18, 415.52batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  82%|▊| 33393/40960 [01:19<00:18, 417.54batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  82%|▊| 33393/40960 [01:19<00:18, 417.54batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  82%|▊| 33475/40960 [01:19<00:18, 415.14batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  82%|▊| 33475/40960 [01:19<00:18, 415.14batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  82%|▊| 33559/40960 [01:19<00:17, 415.41batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  82%|▊| 33559/40960 [01:19<00:17, 415.41batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  82%|▊| 33641/40960 [01:19<00:17, 413.65batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  82%|▊| 33641/40960 [01:19<00:17, 413.65batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  82%|▊| 33726/40960 [01:20<00:17, 416.77batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  82%|▊| 33726/40960 [01:20<00:17, 416.77batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  83%|▊| 33806/40960 [01:20<00:17, 411.08batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  83%|▊| 33806/40960 [01:20<00:17, 411.08batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  83%|▊| 33888/40960 [01:20<00:17, 410.66batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  83%|▊| 33888/40960 [01:20<00:17, 410.66batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  83%|▊| 33965/40960 [01:20<00:17, 401.77batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  83%|▊| 33965/40960 [01:20<00:17, 401.77batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  83%|▊| 34049/40960 [01:20<00:17, 405.87batches/s, l2_loss: 0.0225 - round_los\u001b[A\n",
      "Training:  83%|▊| 34049/40960 [01:20<00:17, 405.87batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  83%|▊| 34130/40960 [01:21<00:16, 404.36batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  83%|▊| 34130/40960 [01:21<00:16, 404.36batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34210/40960 [01:21<00:16, 402.06batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34210/40960 [01:21<00:16, 402.06batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34292/40960 [01:21<00:16, 403.73batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34292/40960 [01:21<00:16, 403.73batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34373/40960 [01:21<00:16, 403.21batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34373/40960 [01:21<00:16, 403.21batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34454/40960 [01:21<00:16, 402.68batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34454/40960 [01:21<00:16, 402.68batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34532/40960 [01:22<00:16, 398.52batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  84%|▊| 34532/40960 [01:22<00:16, 398.52batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34613/40960 [01:22<00:15, 400.36batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34613/40960 [01:22<00:15, 400.36batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [01:22<00:15, 398.89batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [01:22<00:15, 398.89batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34776/40960 [01:22<00:15, 403.37batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34776/40960 [01:22<00:15, 403.37batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34857/40960 [01:22<00:15, 402.71batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34857/40960 [01:22<00:15, 402.71batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34940/40960 [01:23<00:14, 406.17batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 34940/40960 [01:23<00:14, 406.17batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 35019/40960 [01:23<00:14, 401.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  85%|▊| 35019/40960 [01:23<00:14, 401.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  86%|▊| 35103/40960 [01:23<00:14, 406.71batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  86%|▊| 35103/40960 [01:23<00:14, 406.71batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  86%|▊| 35183/40960 [01:23<00:14, 404.65batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  86%|▊| 35183/40960 [01:23<00:14, 404.65batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  86%|▊| 35267/40960 [01:23<00:13, 408.68batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  86%|▊| 35267/40960 [01:23<00:13, 408.68batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  86%|▊| 35352/40960 [01:24<00:13, 412.90batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  86%|▊| 35352/40960 [01:24<00:13, 412.90batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35436/40960 [01:24<00:13, 414.34batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35436/40960 [01:24<00:13, 414.34batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35522/40960 [01:24<00:12, 418.85batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35522/40960 [01:24<00:12, 418.85batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35605/40960 [01:24<00:12, 416.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35605/40960 [01:24<00:12, 416.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35688/40960 [01:24<00:12, 415.03batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35688/40960 [01:24<00:12, 415.03batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35772/40960 [01:25<00:12, 415.89batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  87%|▊| 35772/40960 [01:25<00:12, 415.89batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 35857/40960 [01:25<00:12, 417.90batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 35857/40960 [01:25<00:12, 417.90batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 35942/40960 [01:25<00:11, 419.49batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 35942/40960 [01:25<00:11, 419.49batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 36028/40960 [01:25<00:11, 421.45batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 36028/40960 [01:25<00:11, 421.45batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 36110/40960 [01:25<00:11, 417.66batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 36110/40960 [01:25<00:11, 417.66batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 36196/40960 [01:26<00:11, 420.33batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  88%|▉| 36196/40960 [01:26<00:11, 420.33batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36280/40960 [01:26<00:11, 418.96batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36280/40960 [01:26<00:11, 418.96batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36366/40960 [01:26<00:10, 421.98batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36366/40960 [01:26<00:10, 421.98batches/s, l2_loss: 0.0224 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36451/40960 [01:26<00:10, 422.74batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36451/40960 [01:26<00:10, 422.74batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36537/40960 [01:26<00:10, 423.88batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36537/40960 [01:26<00:10, 423.88batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36622/40960 [01:27<00:10, 422.92batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  89%|▉| 36622/40960 [01:27<00:10, 422.92batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 36707/40960 [01:27<00:10, 422.66batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 36707/40960 [01:27<00:10, 422.66batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 36792/40960 [01:27<00:09, 422.31batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 36792/40960 [01:27<00:09, 422.31batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 36875/40960 [01:27<00:09, 418.85batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 36875/40960 [01:27<00:09, 418.85batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 36962/40960 [01:27<00:09, 422.46batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 36962/40960 [01:27<00:09, 422.46batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 37049/40960 [01:28<00:09, 425.56batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  90%|▉| 37049/40960 [01:28<00:09, 425.56batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37133/40960 [01:28<00:09, 423.71batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37133/40960 [01:28<00:09, 423.71batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37218/40960 [01:28<00:08, 423.76batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37218/40960 [01:28<00:08, 423.76batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37303/40960 [01:28<00:08, 422.61batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37303/40960 [01:28<00:08, 422.61batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37385/40960 [01:28<00:08, 417.83batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37385/40960 [01:28<00:08, 417.83batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37466/40960 [01:29<00:08, 413.85batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  91%|▉| 37466/40960 [01:29<00:08, 413.85batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37551/40960 [01:29<00:08, 416.58batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37551/40960 [01:29<00:08, 416.58batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37635/40960 [01:29<00:07, 417.03batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37635/40960 [01:29<00:07, 417.03batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37717/40960 [01:29<00:07, 414.07batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37717/40960 [01:29<00:07, 414.07batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37798/40960 [01:29<00:07, 410.84batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37798/40960 [01:29<00:07, 410.84batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37882/40960 [01:30<00:07, 413.22batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  92%|▉| 37882/40960 [01:30<00:07, 413.22batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  93%|▉| 37964/40960 [01:30<00:07, 412.10batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  93%|▉| 37964/40960 [01:30<00:07, 412.10batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  93%|▉| 38048/40960 [01:30<00:07, 413.59batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  93%|▉| 38048/40960 [01:30<00:07, 413.59batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  93%|▉| 38135/40960 [01:30<00:06, 418.81batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  93%|▉| 38135/40960 [01:30<00:06, 418.81batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  93%|▉| 38216/40960 [01:30<00:06, 414.32batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  93%|▉| 38216/40960 [01:30<00:06, 414.32batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38302/40960 [01:31<00:06, 418.13batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38302/40960 [01:31<00:06, 418.13batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38384/40960 [01:31<00:06, 415.31batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38384/40960 [01:31<00:06, 415.31batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38465/40960 [01:31<00:06, 411.17batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38465/40960 [01:31<00:06, 411.17batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38548/40960 [01:31<00:05, 412.02batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38548/40960 [01:31<00:05, 412.02batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38633/40960 [01:31<00:05, 415.89batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  94%|▉| 38633/40960 [01:31<00:05, 415.89batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 38718/40960 [01:32<00:05, 417.69batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 38718/40960 [01:32<00:05, 417.69batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 38803/40960 [01:32<00:05, 418.56batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 38803/40960 [01:32<00:05, 418.56batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 38884/40960 [01:32<00:05, 412.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 38884/40960 [01:32<00:05, 412.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 38969/40960 [01:32<00:04, 415.67batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 38969/40960 [01:32<00:04, 415.67batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 39053/40960 [01:32<00:04, 416.03batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  95%|▉| 39053/40960 [01:32<00:04, 416.03batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39136/40960 [01:33<00:04, 415.34batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39136/40960 [01:33<00:04, 415.34batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39216/40960 [01:33<00:04, 409.88batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39216/40960 [01:33<00:04, 409.88batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39302/40960 [01:33<00:03, 414.64batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39302/40960 [01:33<00:03, 414.64batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39380/40960 [01:33<00:03, 406.34batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39380/40960 [01:33<00:03, 406.34batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39461/40960 [01:33<00:03, 405.22batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  96%|▉| 39461/40960 [01:33<00:03, 405.22batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39541/40960 [01:34<00:03, 403.32batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39541/40960 [01:34<00:03, 403.32batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39623/40960 [01:34<00:03, 404.26batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39623/40960 [01:34<00:03, 404.26batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39708/40960 [01:34<00:03, 410.25batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39708/40960 [01:34<00:03, 410.25batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39791/40960 [01:34<00:02, 410.64batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39791/40960 [01:34<00:02, 410.64batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39875/40960 [01:34<00:02, 413.22batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  97%|▉| 39875/40960 [01:34<00:02, 413.22batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 39959/40960 [01:35<00:02, 415.24batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 39959/40960 [01:35<00:02, 415.24batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 40044/40960 [01:35<00:02, 416.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 40044/40960 [01:35<00:02, 416.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 40128/40960 [01:35<00:01, 417.05batches/s, l2_loss: 0.0224 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40128/40960 [01:35<00:01, 417.05batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 40208/40960 [01:35<00:01, 411.52batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 40208/40960 [01:35<00:01, 411.52batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 40291/40960 [01:35<00:01, 412.20batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  98%|▉| 40291/40960 [01:35<00:01, 412.20batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40376/40960 [01:36<00:01, 415.30batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40376/40960 [01:36<00:01, 415.30batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40459/40960 [01:36<00:01, 414.77batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40459/40960 [01:36<00:01, 414.77batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40544/40960 [01:36<00:00, 416.52batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40544/40960 [01:36<00:00, 416.52batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40631/40960 [01:36<00:00, 420.64batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40631/40960 [01:36<00:00, 420.64batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40715/40960 [01:36<00:00, 419.62batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training:  99%|▉| 40715/40960 [01:36<00:00, 419.62batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training: 100%|▉| 40798/40960 [01:37<00:00, 416.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training: 100%|▉| 40798/40960 [01:37<00:00, 416.97batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training: 100%|▉| 40880/40960 [01:37<00:00, 414.39batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "Training: 100%|▉| 40880/40960 [01:37<00:00, 414.39batches/s, l2_loss: 0.0224 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:38:10.978125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  92%|▉| 24/26 [50:31<03:59, 119.85s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:38:12.304218: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 15:38:13.624654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-06-09 15:38:22.864934: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:03<38:54:51,  3.42s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:03<38:54:51,  3.42s/batches, l2_loss: 0.0502 - round_loss:\u001b[A\n",
      "Training:   0%| | 43/40960 [00:03<41:26, 16.45batches/s, l2_loss: 0.0502 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 43/40960 [00:03<41:26, 16.45batches/s, l2_loss: 0.0939 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 93/40960 [00:03<17:12, 39.59batches/s, l2_loss: 0.0939 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 93/40960 [00:03<17:12, 39.59batches/s, l2_loss: 0.0874 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 143/40960 [00:04<10:21, 65.64batches/s, l2_loss: 0.0874 - round_loss: \u001b[A\n",
      "Training:   0%| | 143/40960 [00:04<10:21, 65.64batches/s, l2_loss: 0.0991 - round_loss: \u001b[A\n",
      "Training:   0%| | 188/40960 [00:04<07:35, 89.58batches/s, l2_loss: 0.0991 - round_loss: \u001b[A\n",
      "Training:   0%| | 188/40960 [00:04<07:35, 89.58batches/s, l2_loss: 0.0909 - round_loss: \u001b[A\n",
      "Training:   1%| | 224/40960 [00:04<06:27, 105.23batches/s, l2_loss: 0.0909 - round_loss:\u001b[A\n",
      "Training:   1%| | 224/40960 [00:04<06:27, 105.23batches/s, l2_loss: 0.0975 - round_loss:\u001b[A\n",
      "Training:   1%| | 270/40960 [00:04<05:12, 130.15batches/s, l2_loss: 0.0975 - round_loss:\u001b[A\n",
      "Training:   1%| | 270/40960 [00:04<05:12, 130.15batches/s, l2_loss: 0.1034 - round_loss:\u001b[A\n",
      "Training:   1%| | 317/40960 [00:04<04:25, 153.00batches/s, l2_loss: 0.1034 - round_loss:\u001b[A\n",
      "Training:   1%| | 317/40960 [00:04<04:25, 153.00batches/s, l2_loss: 0.0972 - round_loss:\u001b[A\n",
      "Training:   1%| | 368/40960 [00:05<03:49, 176.93batches/s, l2_loss: 0.0972 - round_loss:\u001b[A\n",
      "Training:   1%| | 368/40960 [00:05<03:49, 176.93batches/s, l2_loss: 0.0968 - round_loss:\u001b[A\n",
      "Training:   1%| | 415/40960 [00:05<03:31, 191.35batches/s, l2_loss: 0.0968 - round_loss:\u001b[A\n",
      "Training:   1%| | 415/40960 [00:05<03:31, 191.35batches/s, l2_loss: 0.1020 - round_loss:\u001b[A\n",
      "Training:   1%| | 464/40960 [00:05<03:18, 204.41batches/s, l2_loss: 0.1020 - round_loss:\u001b[A\n",
      "Training:   1%| | 464/40960 [00:05<03:18, 204.41batches/s, l2_loss: 0.1049 - round_loss:\u001b[A\n",
      "Training:   1%| | 511/40960 [00:05<03:10, 212.44batches/s, l2_loss: 0.1049 - round_loss:\u001b[A\n",
      "Training:   1%| | 511/40960 [00:05<03:10, 212.44batches/s, l2_loss: 0.1021 - round_loss:\u001b[A\n",
      "Training:   1%| | 559/40960 [00:05<03:04, 219.27batches/s, l2_loss: 0.1021 - round_loss:\u001b[A\n",
      "Training:   1%| | 559/40960 [00:05<03:04, 219.27batches/s, l2_loss: 0.1034 - round_loss:\u001b[A\n",
      "Training:   1%| | 606/40960 [00:06<03:00, 223.29batches/s, l2_loss: 0.1034 - round_loss:\u001b[A\n",
      "Training:   1%| | 606/40960 [00:06<03:00, 223.29batches/s, l2_loss: 0.1020 - round_loss:\u001b[A\n",
      "Training:   2%| | 647/40960 [00:06<03:05, 216.81batches/s, l2_loss: 0.1020 - round_loss:\u001b[A\n",
      "Training:   2%| | 647/40960 [00:06<03:05, 216.81batches/s, l2_loss: 0.1014 - round_loss:\u001b[A\n",
      "Training:   2%| | 696/40960 [00:06<02:59, 224.56batches/s, l2_loss: 0.1014 - round_loss:\u001b[A\n",
      "Training:   2%| | 696/40960 [00:06<02:59, 224.56batches/s, l2_loss: 0.1033 - round_loss:\u001b[A\n",
      "Training:   2%| | 732/40960 [00:06<03:10, 210.77batches/s, l2_loss: 0.1033 - round_loss:\u001b[A\n",
      "Training:   2%| | 732/40960 [00:06<03:10, 210.77batches/s, l2_loss: 0.1014 - round_loss:\u001b[A\n",
      "Training:   2%| | 766/40960 [00:06<03:23, 197.62batches/s, l2_loss: 0.1014 - round_loss:\u001b[A\n",
      "Training:   2%| | 766/40960 [00:06<03:23, 197.62batches/s, l2_loss: 0.1019 - round_loss:\u001b[A\n",
      "Training:   2%| | 808/40960 [00:07<03:20, 200.11batches/s, l2_loss: 0.1019 - round_loss:\u001b[A\n",
      "Training:   2%| | 808/40960 [00:07<03:20, 200.11batches/s, l2_loss: 0.1053 - round_loss:\u001b[A\n",
      "Training:   2%| | 854/40960 [00:07<03:12, 208.00batches/s, l2_loss: 0.1053 - round_loss:\u001b[A\n",
      "Training:   2%| | 854/40960 [00:07<03:12, 208.00batches/s, l2_loss: 0.1038 - round_loss:\u001b[A\n",
      "Training:   2%| | 891/40960 [00:07<03:19, 200.85batches/s, l2_loss: 0.1038 - round_loss:\u001b[A\n",
      "Training:   2%| | 891/40960 [00:07<03:19, 200.85batches/s, l2_loss: 0.1020 - round_loss:\u001b[A\n",
      "Training:   2%| | 932/40960 [00:07<03:18, 201.42batches/s, l2_loss: 0.1020 - round_loss:\u001b[A\n",
      "Training:   2%| | 932/40960 [00:07<03:18, 201.42batches/s, l2_loss: 0.1017 - round_loss:\u001b[A\n",
      "Training:   2%| | 975/40960 [00:07<03:15, 204.52batches/s, l2_loss: 0.1017 - round_loss:\u001b[A\n",
      "Training:   2%| | 975/40960 [00:07<03:15, 204.52batches/s, l2_loss: 0.1011 - round_loss:\u001b[A\n",
      "Training:   2%| | 1015/40960 [00:08<03:18, 201.65batches/s, l2_loss: 0.1011 - round_loss\u001b[A\n",
      "Training:   2%| | 1015/40960 [00:08<03:18, 201.65batches/s, l2_loss: 0.1020 - round_loss\u001b[A\n",
      "Training:   3%| | 1054/40960 [00:08<03:20, 199.21batches/s, l2_loss: 0.1020 - round_loss\u001b[A\n",
      "Training:   3%| | 1054/40960 [00:08<03:20, 199.21batches/s, l2_loss: 0.1043 - round_loss\u001b[A\n",
      "Training:   3%| | 1092/40960 [00:08<03:23, 195.68batches/s, l2_loss: 0.1043 - round_loss\u001b[A\n",
      "Training:   3%| | 1092/40960 [00:08<03:23, 195.68batches/s, l2_loss: 0.1028 - round_loss\u001b[A\n",
      "Training:   3%| | 1130/40960 [00:08<03:25, 193.56batches/s, l2_loss: 0.1028 - round_loss\u001b[A\n",
      "Training:   3%| | 1130/40960 [00:08<03:25, 193.56batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   3%| | 1169/40960 [00:08<03:26, 192.83batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%| | 1169/40960 [00:08<03:26, 192.83batches/s, l2_loss: 0.1009 - round_loss\u001b[A\n",
      "Training:   3%| | 1207/40960 [00:09<03:28, 190.91batches/s, l2_loss: 0.1009 - round_loss\u001b[A\n",
      "Training:   3%| | 1207/40960 [00:09<03:28, 190.91batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:   3%| | 1244/40960 [00:09<03:30, 188.46batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:   3%| | 1244/40960 [00:09<03:30, 188.46batches/s, l2_loss: 0.1019 - round_loss\u001b[A\n",
      "Training:   3%| | 1288/40960 [00:09<03:21, 196.63batches/s, l2_loss: 0.1019 - round_loss\u001b[A\n",
      "Training:   3%| | 1288/40960 [00:09<03:21, 196.63batches/s, l2_loss: 0.1033 - round_loss\u001b[A\n",
      "Training:   3%| | 1334/40960 [00:09<03:12, 206.15batches/s, l2_loss: 0.1033 - round_loss\u001b[A\n",
      "Training:   3%| | 1334/40960 [00:09<03:12, 206.15batches/s, l2_loss: 0.1017 - round_loss\u001b[A\n",
      "Training:   3%| | 1373/40960 [00:09<03:16, 201.01batches/s, l2_loss: 0.1017 - round_loss\u001b[A\n",
      "Training:   3%| | 1373/40960 [00:09<03:16, 201.01batches/s, l2_loss: 0.1021 - round_loss\u001b[A\n",
      "Training:   3%| | 1407/40960 [00:10<03:26, 191.17batches/s, l2_loss: 0.1021 - round_loss\u001b[A\n",
      "Training:   3%| | 1407/40960 [00:10<03:26, 191.17batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   4%| | 1444/40960 [00:10<03:29, 188.96batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   4%| | 1444/40960 [00:10<03:29, 188.96batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:   4%| | 1483/40960 [00:10<03:27, 190.31batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:   4%| | 1483/40960 [00:10<03:27, 190.31batches/s, l2_loss: 0.1012 - round_loss\u001b[A\n",
      "Training:   4%| | 1529/40960 [00:10<03:16, 200.86batches/s, l2_loss: 0.1012 - round_loss\u001b[A\n",
      "Training:   4%| | 1529/40960 [00:10<03:16, 200.86batches/s, l2_loss: 0.1015 - round_loss\u001b[A\n",
      "Training:   4%| | 1581/40960 [00:10<03:01, 217.10batches/s, l2_loss: 0.1015 - round_loss\u001b[A\n",
      "Training:   4%| | 1581/40960 [00:10<03:01, 217.10batches/s, l2_loss: 0.1007 - round_loss\u001b[A\n",
      "Training:   4%| | 1629/40960 [00:11<02:56, 223.05batches/s, l2_loss: 0.1007 - round_loss\u001b[A\n",
      "Training:   4%| | 1629/40960 [00:11<02:56, 223.05batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   4%| | 1673/40960 [00:11<02:57, 221.02batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   4%| | 1673/40960 [00:11<02:57, 221.02batches/s, l2_loss: 0.1010 - round_loss\u001b[A\n",
      "Training:   4%| | 1721/40960 [00:11<02:53, 226.44batches/s, l2_loss: 0.1010 - round_loss\u001b[A\n",
      "Training:   4%| | 1721/40960 [00:11<02:53, 226.44batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   4%| | 1768/40960 [00:11<02:51, 228.88batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   4%| | 1768/40960 [00:11<02:51, 228.88batches/s, l2_loss: 0.1016 - round_loss\u001b[A\n",
      "Training:   4%| | 1816/40960 [00:11<02:48, 231.65batches/s, l2_loss: 0.1016 - round_loss\u001b[A\n",
      "Training:   4%| | 1816/40960 [00:11<02:48, 231.65batches/s, l2_loss: 0.1006 - round_loss\u001b[A\n",
      "Training:   5%| | 1865/40960 [00:12<02:46, 235.18batches/s, l2_loss: 0.1006 - round_loss\u001b[A\n",
      "Training:   5%| | 1865/40960 [00:12<02:46, 235.18batches/s, l2_loss: 0.1008 - round_loss\u001b[A\n",
      "Training:   5%| | 1912/40960 [00:12<02:46, 234.22batches/s, l2_loss: 0.1008 - round_loss\u001b[A\n",
      "Training:   5%| | 1912/40960 [00:12<02:46, 234.22batches/s, l2_loss: 0.1012 - round_loss\u001b[A\n",
      "Training:   5%| | 1953/40960 [00:12<02:54, 223.39batches/s, l2_loss: 0.1012 - round_loss\u001b[A\n",
      "Training:   5%| | 1953/40960 [00:12<02:54, 223.39batches/s, l2_loss: 0.1017 - round_loss\u001b[A\n",
      "Training:   5%| | 1989/40960 [00:12<03:05, 209.62batches/s, l2_loss: 0.1017 - round_loss\u001b[A\n",
      "Training:   5%| | 1989/40960 [00:12<03:05, 209.62batches/s, l2_loss: 0.1023 - round_loss\u001b[A\n",
      "Training:   5%| | 2032/40960 [00:12<03:05, 210.25batches/s, l2_loss: 0.1023 - round_loss\u001b[A\n",
      "Training:   5%| | 2032/40960 [00:12<03:05, 210.25batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   5%| | 2065/40960 [00:13<03:19, 194.90batches/s, l2_loss: 0.1014 - round_loss\u001b[A\n",
      "Training:   5%| | 2065/40960 [00:13<03:19, 194.90batches/s, l2_loss: 0.1006 - round_loss\u001b[A\n",
      "Training:   5%| | 2099/40960 [00:13<03:27, 187.11batches/s, l2_loss: 0.1006 - round_loss\u001b[A\n",
      "Training:   5%| | 2099/40960 [00:13<03:27, 187.11batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   5%| | 2137/40960 [00:13<03:27, 187.35batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   5%| | 2137/40960 [00:13<03:27, 187.35batches/s, l2_loss: 0.1016 - round_loss\u001b[A\n",
      "Training:   5%| | 2182/40960 [00:13<03:16, 197.68batches/s, l2_loss: 0.1016 - round_loss\u001b[A\n",
      "Training:   5%| | 2182/40960 [00:13<03:16, 197.68batches/s, l2_loss: 0.1008 - round_loss\u001b[A\n",
      "Training:   5%| | 2232/40960 [00:13<03:01, 212.81batches/s, l2_loss: 0.1008 - round_loss\u001b[A\n",
      "Training:   5%| | 2232/40960 [00:13<03:01, 212.81batches/s, l2_loss: 0.1016 - round_loss\u001b[A\n",
      "Training:   6%| | 2279/40960 [00:14<02:56, 219.35batches/s, l2_loss: 0.1016 - round_loss\u001b[A\n",
      "Training:   6%| | 2279/40960 [00:14<02:56, 219.35batches/s, l2_loss: 0.1012 - round_loss\u001b[A\n",
      "Training:   6%| | 2324/40960 [00:14<02:55, 220.13batches/s, l2_loss: 0.1012 - round_loss\u001b[A\n",
      "Training:   6%| | 2324/40960 [00:14<02:55, 220.13batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:   6%| | 2371/40960 [00:14<02:52, 223.65batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:   6%| | 2371/40960 [00:14<02:52, 223.65batches/s, l2_loss: 0.1004 - round_loss\u001b[A\n",
      "Training:   6%| | 2418/40960 [00:14<02:50, 226.32batches/s, l2_loss: 0.1004 - round_loss\u001b[A\n",
      "Training:   6%| | 2418/40960 [00:14<02:50, 226.32batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   6%| | 2465/40960 [00:14<02:48, 228.82batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   6%| | 2465/40960 [00:14<02:48, 228.82batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:   6%| | 2511/40960 [00:15<02:49, 227.46batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:   6%| | 2511/40960 [00:15<02:49, 227.46batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:   6%| | 2553/40960 [00:15<02:53, 221.34batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:   6%| | 2553/40960 [00:15<02:53, 221.34batches/s, l2_loss: 0.1002 - round_loss\u001b[A\n",
      "Training:   6%| | 2590/40960 [00:15<03:02, 210.13batches/s, l2_loss: 0.1002 - round_loss\u001b[A\n",
      "Training:   6%| | 2590/40960 [00:15<03:02, 210.13batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   6%| | 2633/40960 [00:15<03:01, 210.88batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   6%| | 2633/40960 [00:15<03:01, 210.88batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:   7%| | 2672/40960 [00:15<03:06, 204.83batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:   7%| | 2672/40960 [00:15<03:06, 204.83batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:   7%| | 2716/40960 [00:16<03:03, 208.86batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:   7%| | 2716/40960 [00:16<03:03, 208.86batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:   7%| | 2758/40960 [00:16<03:03, 208.56batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:   7%| | 2758/40960 [00:16<03:03, 208.56batches/s, l2_loss: 0.1009 - round_loss\u001b[A\n",
      "Training:   7%| | 2794/40960 [00:16<03:12, 198.50batches/s, l2_loss: 0.1009 - round_loss\u001b[A\n",
      "Training:   7%| | 2794/40960 [00:16<03:12, 198.50batches/s, l2_loss: 0.1008 - round_loss\u001b[A\n",
      "Training:   7%| | 2828/40960 [00:16<03:20, 189.77batches/s, l2_loss: 0.1008 - round_loss\u001b[A\n",
      "Training:   7%| | 2828/40960 [00:16<03:20, 189.77batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:   7%| | 2859/40960 [00:16<03:33, 178.81batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:   7%| | 2859/40960 [00:17<03:33, 178.81batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:   7%| | 2886/40960 [00:17<03:52, 163.93batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:   7%| | 2886/40960 [00:17<03:52, 163.93batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   7%| | 2927/40960 [00:17<03:36, 175.80batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   7%| | 2927/40960 [00:17<03:36, 175.80batches/s, l2_loss: 0.1006 - round_loss\u001b[A\n",
      "Training:   7%| | 2969/40960 [00:17<03:25, 185.10batches/s, l2_loss: 0.1006 - round_loss\u001b[A\n",
      "Training:   7%| | 2969/40960 [00:17<03:25, 185.10batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:   7%| | 3010/40960 [00:17<03:19, 189.90batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:   7%| | 3010/40960 [00:17<03:19, 189.90batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 3055/40960 [00:18<03:10, 199.28batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   7%| | 3055/40960 [00:18<03:10, 199.28batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:   8%| | 3098/40960 [00:18<03:06, 202.65batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:   8%| | 3098/40960 [00:18<03:06, 202.65batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   8%| | 3143/40960 [00:18<03:01, 207.92batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   8%| | 3143/40960 [00:18<03:01, 207.92batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:   8%| | 3189/40960 [00:18<02:56, 214.22batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:   8%| | 3189/40960 [00:18<02:56, 214.22batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:   8%| | 3241/40960 [00:18<02:46, 226.96batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:   8%| | 3241/40960 [00:18<02:46, 226.96batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   8%| | 3289/40960 [00:19<02:43, 230.64batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   8%| | 3289/40960 [00:19<02:43, 230.64batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:   8%| | 3334/40960 [00:19<02:45, 227.79batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:   8%| | 3334/40960 [00:19<02:45, 227.79batches/s, l2_loss: 0.1002 - round_loss\u001b[A\n",
      "Training:   8%| | 3374/40960 [00:19<02:51, 219.03batches/s, l2_loss: 0.1002 - round_loss\u001b[A\n",
      "Training:   8%| | 3374/40960 [00:19<02:51, 219.03batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   8%| | 3413/40960 [00:19<02:58, 210.93batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   8%| | 3413/40960 [00:19<02:58, 210.93batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:   8%| | 3452/40960 [00:19<03:02, 205.50batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:   8%| | 3452/40960 [00:19<03:02, 205.50batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   9%| | 3490/40960 [00:20<03:07, 200.09batches/s, l2_loss: 0.1001 - round_loss\u001b[A\n",
      "Training:   9%| | 3490/40960 [00:20<03:07, 200.09batches/s, l2_loss: 0.1007 - round_loss\u001b[A\n",
      "Training:   9%| | 3536/40960 [00:20<02:59, 208.04batches/s, l2_loss: 0.1007 - round_loss\u001b[A\n",
      "Training:   9%| | 3536/40960 [00:20<02:59, 208.04batches/s, l2_loss: 0.1002 - round_loss\u001b[A\n",
      "Training:   9%| | 3583/40960 [00:20<02:53, 215.58batches/s, l2_loss: 0.1002 - round_loss\u001b[A\n",
      "Training:   9%| | 3583/40960 [00:20<02:53, 215.58batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   9%| | 3624/40960 [00:20<02:56, 211.15batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   9%| | 3624/40960 [00:20<02:56, 211.15batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:   9%| | 3668/40960 [00:20<02:55, 212.30batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:   9%| | 3668/40960 [00:20<02:55, 212.30batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:   9%| | 3711/40960 [00:21<02:54, 212.88batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:   9%| | 3711/40960 [00:21<02:54, 212.88batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   9%| | 3751/40960 [00:21<02:59, 207.87batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:   9%| | 3751/40960 [00:21<02:59, 207.87batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:   9%| | 3793/40960 [00:21<02:58, 207.78batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:   9%| | 3793/40960 [00:21<02:58, 207.78batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:   9%| | 3828/40960 [00:21<03:07, 198.03batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:   9%| | 3828/40960 [00:21<03:07, 198.03batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:   9%| | 3860/40960 [00:21<03:19, 186.32batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:   9%| | 3860/40960 [00:21<03:19, 186.32batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:  10%| | 3904/40960 [00:22<03:09, 195.63batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:  10%| | 3904/40960 [00:22<03:09, 195.63batches/s, l2_loss: 0.1002 - round_loss\u001b[A\n",
      "Training:  10%| | 3951/40960 [00:22<02:58, 206.85batches/s, l2_loss: 0.1002 - round_loss\u001b[A\n",
      "Training:  10%| | 3951/40960 [00:22<02:58, 206.85batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:  10%| | 3997/40960 [00:22<02:53, 212.90batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:  10%| | 3997/40960 [00:22<02:53, 212.90batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:  10%| | 4039/40960 [00:22<02:54, 211.25batches/s, l2_loss: 0.1005 - round_loss\u001b[A\n",
      "Training:  10%| | 4039/40960 [00:22<02:54, 211.25batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:  10%| | 4085/40960 [00:22<02:50, 215.70batches/s, l2_loss: 0.1003 - round_loss\u001b[A\n",
      "Training:  10%| | 4085/40960 [00:22<02:50, 215.70batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:  10%| | 4133/40960 [00:23<02:45, 222.18batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:  10%| | 4133/40960 [00:23<02:45, 222.18batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:  10%| | 4172/40960 [00:23<02:52, 213.34batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:  10%| | 4172/40960 [00:23<02:52, 213.34batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:  10%| | 4208/40960 [00:23<03:01, 202.84batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:  10%| | 4208/40960 [00:23<03:01, 202.84batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:  10%| | 4251/40960 [00:23<02:58, 205.19batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:  10%| | 4251/40960 [00:23<02:58, 205.19batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  10%| | 4299/40960 [00:23<02:50, 215.10batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  10%| | 4299/40960 [00:23<02:50, 215.10batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:  11%| | 4341/40960 [00:24<02:52, 212.79batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:  11%| | 4341/40960 [00:24<02:52, 212.79batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:  11%| | 4387/40960 [00:24<02:48, 216.97batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:  11%| | 4387/40960 [00:24<02:48, 216.97batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:  11%| | 4431/40960 [00:24<02:48, 216.73batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:  11%| | 4431/40960 [00:24<02:48, 216.73batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:  11%| | 4476/40960 [00:24<02:47, 217.62batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:  11%| | 4476/40960 [00:24<02:47, 217.62batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:  11%| | 4511/40960 [00:24<02:58, 204.15batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:  11%| | 4511/40960 [00:24<02:58, 204.15batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:  11%| | 4549/40960 [00:25<03:04, 197.18batches/s, l2_loss: 0.0998 - round_loss\u001b[A\n",
      "Training:  11%| | 4549/40960 [00:25<03:04, 197.18batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:  11%| | 4587/40960 [00:25<03:08, 193.26batches/s, l2_loss: 0.1000 - round_loss\u001b[A\n",
      "Training:  11%| | 4587/40960 [00:25<03:08, 193.26batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:  11%| | 4623/40960 [00:25<03:12, 188.99batches/s, l2_loss: 0.0997 - round_loss\u001b[A\n",
      "Training:  11%| | 4623/40960 [00:25<03:12, 188.99batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  11%| | 4659/40960 [00:25<03:16, 184.75batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  11%| | 4659/40960 [00:25<03:16, 184.75batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  11%| | 4699/40960 [00:25<03:12, 188.65batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  11%| | 4699/40960 [00:25<03:12, 188.65batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  12%| | 4738/40960 [00:26<03:11, 189.45batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  12%| | 4738/40960 [00:26<03:11, 189.45batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:  12%| | 4780/40960 [00:26<03:05, 195.38batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:  12%| | 4780/40960 [00:26<03:05, 195.38batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:  12%| | 4824/40960 [00:26<02:58, 202.06batches/s, l2_loss: 0.0999 - round_loss\u001b[A\n",
      "Training:  12%| | 4824/40960 [00:26<02:58, 202.06batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:  12%| | 4862/40960 [00:26<03:03, 196.98batches/s, l2_loss: 0.0995 - round_loss\u001b[A\n",
      "Training:  12%| | 4862/40960 [00:26<03:03, 196.98batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  12%| | 4904/40960 [00:26<02:59, 200.39batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%| | 4904/40960 [00:26<02:59, 200.39batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  12%| | 4951/40960 [00:27<02:51, 210.31batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  12%| | 4951/40960 [00:27<02:51, 210.31batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  12%| | 4999/40960 [00:27<02:44, 218.95batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  12%| | 4999/40960 [00:27<02:44, 218.95batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  12%| | 5045/40960 [00:27<02:41, 221.72batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  12%| | 5045/40960 [00:27<02:41, 221.72batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  12%| | 5091/40960 [00:27<02:40, 224.16batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  12%| | 5091/40960 [00:27<02:40, 224.16batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5137/40960 [00:27<02:38, 225.62batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5137/40960 [00:27<02:38, 225.62batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5186/40960 [00:28<02:35, 230.16batches/s, l2_loss: 0.0996 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5186/40960 [00:28<02:35, 230.16batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5228/40960 [00:28<02:40, 222.75batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5228/40960 [00:28<02:40, 222.75batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5270/40960 [00:28<02:43, 218.40batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5270/40960 [00:28<02:43, 218.40batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5316/40960 [00:28<02:41, 221.05batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5316/40960 [00:28<02:41, 221.05batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5365/40960 [00:28<02:36, 227.29batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5365/40960 [00:28<02:36, 227.29batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5414/40960 [00:29<02:33, 232.00batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5414/40960 [00:29<02:33, 232.00batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5457/40960 [00:29<02:37, 225.37batches/s, l2_loss: 0.0994 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5457/40960 [00:29<02:37, 225.37batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5500/40960 [00:29<02:40, 221.17batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5500/40960 [00:29<02:40, 221.17batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5540/40960 [00:29<02:45, 214.61batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5540/40960 [00:29<02:45, 214.61batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5585/40960 [00:29<02:42, 217.10batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5585/40960 [00:29<02:42, 217.10batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5623/40960 [00:30<02:50, 207.69batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5623/40960 [00:30<02:50, 207.69batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5668/40960 [00:30<02:47, 211.15batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5668/40960 [00:30<02:47, 211.15batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5716/40960 [00:30<02:41, 218.55batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5716/40960 [00:30<02:41, 218.55batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5760/40960 [00:30<02:41, 218.33batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5760/40960 [00:30<02:41, 218.33batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5810/40960 [00:30<02:34, 227.18batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5810/40960 [00:30<02:34, 227.18batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5849/40960 [00:31<02:42, 216.05batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5849/40960 [00:31<02:42, 216.05batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5898/40960 [00:31<02:36, 224.04batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5898/40960 [00:31<02:36, 224.04batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5936/40960 [00:31<02:43, 213.86batches/s, l2_loss: 0.0988 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5936/40960 [00:31<02:43, 213.86batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5974/40960 [00:31<02:50, 205.13batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  15%|▏| 5974/40960 [00:31<02:50, 205.13batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6021/40960 [00:32<02:44, 212.85batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6021/40960 [00:32<02:44, 212.85batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6066/40960 [00:32<02:42, 215.26batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6066/40960 [00:32<02:42, 215.26batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6095/40960 [00:32<03:00, 192.98batches/s, l2_loss: 0.0990 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6095/40960 [00:32<03:00, 192.98batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6133/40960 [00:32<03:01, 191.42batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6133/40960 [00:32<03:01, 191.42batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6169/40960 [00:32<03:05, 187.64batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6169/40960 [00:32<03:05, 187.64batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6214/40960 [00:33<02:55, 197.56batches/s, l2_loss: 0.0992 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6214/40960 [00:33<02:55, 197.56batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6256/40960 [00:33<02:53, 200.39batches/s, l2_loss: 0.0991 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6256/40960 [00:33<02:53, 200.39batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6296/40960 [00:33<02:53, 199.77batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6296/40960 [00:33<02:53, 199.77batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6335/40960 [00:33<02:54, 197.93batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6335/40960 [00:33<02:54, 197.93batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6379/40960 [00:33<02:50, 203.34batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6379/40960 [00:33<02:50, 203.34batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6424/40960 [00:34<02:45, 208.79batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6424/40960 [00:34<02:45, 208.79batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6473/40960 [00:34<02:37, 219.28batches/s, l2_loss: 0.0993 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6473/40960 [00:34<02:37, 219.28batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6522/40960 [00:34<02:32, 226.20batches/s, l2_loss: 0.0989 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6522/40960 [00:34<02:32, 226.20batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6570/40960 [00:34<02:29, 229.44batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6570/40960 [00:34<02:29, 229.44batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6622/40960 [00:34<02:24, 237.26batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6622/40960 [00:34<02:24, 237.26batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6665/40960 [00:35<02:29, 228.94batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6665/40960 [00:35<02:29, 228.94batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6712/40960 [00:35<02:30, 227.86batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6712/40960 [00:35<02:30, 227.86batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6750/40960 [00:35<02:38, 216.24batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6750/40960 [00:35<02:38, 216.24batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6789/40960 [00:35<02:42, 209.82batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6789/40960 [00:35<02:42, 209.82batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6829/40960 [00:35<02:45, 205.64batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6829/40960 [00:35<02:45, 205.64batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|▏| 6875/40960 [00:36<02:40, 212.35batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6875/40960 [00:36<02:40, 212.35batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6920/40960 [00:36<02:37, 215.56batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6920/40960 [00:36<02:37, 215.56batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6954/40960 [00:36<02:49, 200.60batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6954/40960 [00:36<02:49, 200.60batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6994/40960 [00:36<02:49, 200.34batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6994/40960 [00:36<02:49, 200.34batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7033/40960 [00:36<02:52, 197.11batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7033/40960 [00:36<02:52, 197.11batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7069/40960 [00:37<02:57, 190.72batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7069/40960 [00:37<02:57, 190.72batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7104/40960 [00:37<03:04, 183.75batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7104/40960 [00:37<03:04, 183.75batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7140/40960 [00:37<03:05, 181.97batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7140/40960 [00:37<03:05, 181.97batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7188/40960 [00:37<02:50, 197.90batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7188/40960 [00:37<02:50, 197.90batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7219/40960 [00:37<03:03, 183.70batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7219/40960 [00:37<03:03, 183.70batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7264/40960 [00:38<02:53, 194.60batches/s, l2_loss: 0.0986 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7264/40960 [00:38<02:53, 194.60batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7313/40960 [00:38<02:40, 209.25batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7313/40960 [00:38<02:40, 209.25batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7357/40960 [00:38<02:38, 212.23batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7357/40960 [00:38<02:38, 212.23batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7400/40960 [00:38<02:37, 212.80batches/s, l2_loss: 0.0983 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7400/40960 [00:38<02:37, 212.80batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7445/40960 [00:38<02:35, 215.74batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7445/40960 [00:38<02:35, 215.74batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7490/40960 [00:39<02:33, 217.61batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7490/40960 [00:39<02:33, 217.61batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7523/40960 [00:39<02:47, 199.19batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7523/40960 [00:39<02:47, 199.19batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7557/40960 [00:39<02:55, 190.55batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7557/40960 [00:39<02:55, 190.55batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7600/40960 [00:39<02:48, 197.50batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7600/40960 [00:39<02:48, 197.50batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7649/40960 [00:39<02:38, 210.64batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7649/40960 [00:39<02:38, 210.64batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7695/40960 [00:40<02:34, 215.83batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7695/40960 [00:40<02:34, 215.83batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7733/40960 [00:40<02:40, 207.65batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7733/40960 [00:40<02:40, 207.65batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7768/40960 [00:40<02:48, 196.43batches/s, l2_loss: 0.0985 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7768/40960 [00:40<02:48, 196.43batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7800/40960 [00:40<02:58, 185.57batches/s, l2_loss: 0.0984 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7800/40960 [00:40<02:58, 185.57batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7841/40960 [00:40<02:54, 189.88batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7841/40960 [00:40<02:54, 189.88batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7886/40960 [00:41<02:46, 199.14batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7886/40960 [00:41<02:46, 199.14batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7921/40960 [00:41<02:52, 191.29batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7921/40960 [00:41<02:52, 191.29batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7961/40960 [00:41<02:51, 192.92batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7961/40960 [00:41<02:51, 192.92batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7996/40960 [00:41<02:56, 186.93batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  20%|▏| 7996/40960 [00:41<02:56, 186.93batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8041/40960 [00:41<02:46, 197.26batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8041/40960 [00:41<02:46, 197.26batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8082/40960 [00:42<02:44, 199.54batches/s, l2_loss: 0.0982 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8082/40960 [00:42<02:44, 199.54batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8129/40960 [00:42<02:36, 209.84batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8129/40960 [00:42<02:36, 209.84batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8175/40960 [00:42<02:32, 215.47batches/s, l2_loss: 0.0980 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8175/40960 [00:42<02:32, 215.47batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8221/40960 [00:42<02:29, 219.31batches/s, l2_loss: 0.0981 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8221/40960 [00:42<02:29, 219.31batches/s, l2_loss: 0.0652 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8270/40960 [00:42<02:24, 226.74batches/s, l2_loss: 0.0652 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8270/40960 [00:42<02:24, 226.74batches/s, l2_loss: 0.0915 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8318/40960 [00:43<02:22, 228.90batches/s, l2_loss: 0.0915 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8318/40960 [00:43<02:22, 228.90batches/s, l2_loss: 0.0944 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8363/40960 [00:43<02:23, 227.64batches/s, l2_loss: 0.0944 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8363/40960 [00:43<02:23, 227.64batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8405/40960 [00:43<02:26, 221.97batches/s, l2_loss: 0.0987 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8405/40960 [00:43<02:26, 221.97batches/s, l2_loss: 0.0915 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8453/40960 [00:43<02:23, 226.20batches/s, l2_loss: 0.0915 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8453/40960 [00:43<02:23, 226.20batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8499/40960 [00:43<02:23, 226.94batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8499/40960 [00:43<02:23, 226.94batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8542/40960 [00:44<02:25, 222.88batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8542/40960 [00:44<02:25, 222.88batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8584/40960 [00:44<02:28, 218.67batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8584/40960 [00:44<02:28, 218.67batches/s, l2_loss: 0.0943 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8627/40960 [00:44<02:29, 216.91batches/s, l2_loss: 0.0943 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8627/40960 [00:44<02:29, 216.91batches/s, l2_loss: 0.0960 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8670/40960 [00:44<02:29, 215.78batches/s, l2_loss: 0.0960 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8670/40960 [00:44<02:29, 215.78batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8714/40960 [00:44<02:29, 215.27batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|▏| 8714/40960 [00:44<02:29, 215.27batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8753/40960 [00:45<02:35, 207.37batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8753/40960 [00:45<02:35, 207.37batches/s, l2_loss: 0.0971 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8791/40960 [00:45<02:39, 201.51batches/s, l2_loss: 0.0971 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8791/40960 [00:45<02:39, 201.51batches/s, l2_loss: 0.0970 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8832/40960 [00:45<02:38, 202.26batches/s, l2_loss: 0.0970 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8832/40960 [00:45<02:38, 202.26batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8871/40960 [00:45<02:42, 197.50batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8871/40960 [00:45<02:42, 197.50batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8910/40960 [00:46<02:43, 196.10batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8910/40960 [00:46<02:43, 196.10batches/s, l2_loss: 0.0936 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8954/40960 [00:46<02:38, 202.51batches/s, l2_loss: 0.0936 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8954/40960 [00:46<02:38, 202.51batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8997/40960 [00:46<02:35, 205.45batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8997/40960 [00:46<02:35, 205.45batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9039/40960 [00:46<02:34, 206.35batches/s, l2_loss: 0.0933 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9039/40960 [00:46<02:34, 206.35batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9079/40960 [00:46<02:36, 204.29batches/s, l2_loss: 0.0918 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9079/40960 [00:46<02:36, 204.29batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9120/40960 [00:47<02:36, 203.74batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9120/40960 [00:47<02:36, 203.74batches/s, l2_loss: 0.0961 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9163/40960 [00:47<02:34, 206.19batches/s, l2_loss: 0.0961 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9163/40960 [00:47<02:34, 206.19batches/s, l2_loss: 0.0970 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9211/40960 [00:47<02:26, 216.09batches/s, l2_loss: 0.0970 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9211/40960 [00:47<02:26, 216.09batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9257/40960 [00:47<02:24, 219.90batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9257/40960 [00:47<02:24, 219.90batches/s, l2_loss: 0.0964 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9305/40960 [00:47<02:20, 224.68batches/s, l2_loss: 0.0964 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9305/40960 [00:47<02:20, 224.68batches/s, l2_loss: 0.0961 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9355/40960 [00:48<02:16, 230.81batches/s, l2_loss: 0.0961 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9355/40960 [00:48<02:16, 230.81batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9393/40960 [00:48<02:25, 217.36batches/s, l2_loss: 0.0946 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9393/40960 [00:48<02:25, 217.36batches/s, l2_loss: 0.0936 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9434/40960 [00:48<02:28, 212.55batches/s, l2_loss: 0.0936 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9434/40960 [00:48<02:28, 212.55batches/s, l2_loss: 0.0926 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9480/40960 [00:48<02:25, 217.09batches/s, l2_loss: 0.0926 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9480/40960 [00:48<02:25, 217.09batches/s, l2_loss: 0.0947 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9519/40960 [00:48<02:30, 209.17batches/s, l2_loss: 0.0947 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9519/40960 [00:48<02:30, 209.17batches/s, l2_loss: 0.0958 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9562/40960 [00:49<02:29, 209.64batches/s, l2_loss: 0.0958 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9562/40960 [00:49<02:29, 209.64batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9606/40960 [00:49<02:28, 211.04batches/s, l2_loss: 0.0953 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9606/40960 [00:49<02:28, 211.04batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9643/40960 [00:49<02:34, 202.64batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9643/40960 [00:49<02:34, 202.64batches/s, l2_loss: 0.0954 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9678/40960 [00:49<02:41, 193.46batches/s, l2_loss: 0.0954 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9678/40960 [00:49<02:41, 193.46batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9721/40960 [00:49<02:37, 198.66batches/s, l2_loss: 0.0945 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9721/40960 [00:49<02:37, 198.66batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9769/40960 [00:50<02:28, 210.07batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9769/40960 [00:50<02:28, 210.07batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9809/40960 [00:50<02:30, 206.43batches/s, l2_loss: 0.0939 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9809/40960 [00:50<02:30, 206.43batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9851/40960 [00:50<02:30, 206.73batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9851/40960 [00:50<02:30, 206.73batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9897/40960 [00:50<02:25, 213.22batches/s, l2_loss: 0.0950 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9897/40960 [00:50<02:25, 213.22batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9939/40960 [00:50<02:26, 212.04batches/s, l2_loss: 0.0959 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9939/40960 [00:50<02:26, 212.04batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9987/40960 [00:51<02:21, 219.40batches/s, l2_loss: 0.0951 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9987/40960 [00:51<02:21, 219.40batches/s, l2_loss: 0.0948 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10028/40960 [00:51<02:24, 214.49batches/s, l2_loss: 0.0948 - round_los\u001b[A\n",
      "Training:  24%|▏| 10028/40960 [00:51<02:24, 214.49batches/s, l2_loss: 0.0959 - round_los\u001b[A\n",
      "Training:  25%|▏| 10069/40960 [00:51<02:26, 210.89batches/s, l2_loss: 0.0959 - round_los\u001b[A\n",
      "Training:  25%|▏| 10069/40960 [00:51<02:26, 210.89batches/s, l2_loss: 0.0950 - round_los\u001b[A\n",
      "Training:  25%|▏| 10114/40960 [00:51<02:24, 214.03batches/s, l2_loss: 0.0950 - round_los\u001b[A\n",
      "Training:  25%|▏| 10114/40960 [00:51<02:24, 214.03batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  25%|▏| 10159/40960 [00:51<02:22, 215.83batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  25%|▏| 10159/40960 [00:51<02:22, 215.83batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  25%|▏| 10203/40960 [00:52<02:21, 216.66batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  25%|▏| 10203/40960 [00:52<02:21, 216.66batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  25%|▎| 10246/40960 [00:52<02:22, 215.62batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  25%|▎| 10246/40960 [00:52<02:22, 215.62batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  25%|▎| 10293/40960 [00:52<02:18, 221.12batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  25%|▎| 10293/40960 [00:52<02:18, 221.12batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  25%|▎| 10337/40960 [00:52<02:18, 220.57batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  25%|▎| 10337/40960 [00:52<02:18, 220.57batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  25%|▎| 10380/40960 [00:52<02:20, 218.10batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  25%|▎| 10380/40960 [00:52<02:20, 218.10batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  25%|▎| 10425/40960 [00:53<02:18, 219.84batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  25%|▎| 10425/40960 [00:53<02:18, 219.84batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  26%|▎| 10472/40960 [00:53<02:16, 223.77batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  26%|▎| 10472/40960 [00:53<02:16, 223.77batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  26%|▎| 10518/40960 [00:53<02:15, 225.19batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  26%|▎| 10518/40960 [00:53<02:15, 225.19batches/s, l2_loss: 0.0948 - round_los\u001b[A\n",
      "Training:  26%|▎| 10566/40960 [00:53<02:12, 229.44batches/s, l2_loss: 0.0948 - round_los\u001b[A\n",
      "Training:  26%|▎| 10566/40960 [00:53<02:12, 229.44batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  26%|▎| 10612/40960 [00:53<02:12, 229.51batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  26%|▎| 10612/40960 [00:53<02:12, 229.51batches/s, l2_loss: 0.0947 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|▎| 10655/40960 [00:54<02:15, 224.39batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  26%|▎| 10655/40960 [00:54<02:15, 224.39batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  26%|▎| 10702/40960 [00:54<02:13, 226.62batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  26%|▎| 10702/40960 [00:54<02:13, 226.62batches/s, l2_loss: 0.0954 - round_los\u001b[A\n",
      "Training:  26%|▎| 10745/40960 [00:54<02:16, 222.11batches/s, l2_loss: 0.0954 - round_los\u001b[A\n",
      "Training:  26%|▎| 10745/40960 [00:54<02:16, 222.11batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  26%|▎| 10789/40960 [00:54<02:17, 219.84batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  26%|▎| 10789/40960 [00:54<02:17, 219.84batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  26%|▎| 10836/40960 [00:54<02:15, 222.83batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  26%|▎| 10836/40960 [00:54<02:15, 222.83batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  27%|▎| 10880/40960 [00:55<02:16, 220.62batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  27%|▎| 10880/40960 [00:55<02:16, 220.62batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  27%|▎| 10919/40960 [00:55<02:21, 212.50batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  27%|▎| 10919/40960 [00:55<02:21, 212.50batches/s, l2_loss: 0.0948 - round_los\u001b[A\n",
      "Training:  27%|▎| 10965/40960 [00:55<02:18, 216.23batches/s, l2_loss: 0.0948 - round_los\u001b[A\n",
      "Training:  27%|▎| 10965/40960 [00:55<02:18, 216.23batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  27%|▎| 11006/40960 [00:55<02:20, 212.70batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  27%|▎| 11006/40960 [00:55<02:20, 212.70batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  27%|▎| 11051/40960 [00:55<02:18, 215.25batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  27%|▎| 11051/40960 [00:55<02:18, 215.25batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  27%|▎| 11096/40960 [00:56<02:17, 217.53batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  27%|▎| 11096/40960 [00:56<02:17, 217.53batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  27%|▎| 11144/40960 [00:56<02:13, 224.01batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  27%|▎| 11144/40960 [00:56<02:13, 224.01batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  27%|▎| 11184/40960 [00:56<02:17, 215.98batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  27%|▎| 11184/40960 [00:56<02:17, 215.98batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  27%|▎| 11229/40960 [00:56<02:16, 217.97batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  27%|▎| 11229/40960 [00:56<02:16, 217.97batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  28%|▎| 11267/40960 [00:56<02:22, 208.59batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  28%|▎| 11267/40960 [00:56<02:22, 208.59batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  28%|▎| 11312/40960 [00:57<02:18, 213.46batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  28%|▎| 11312/40960 [00:57<02:18, 213.46batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  28%|▎| 11351/40960 [00:57<02:22, 207.83batches/s, l2_loss: 0.0951 - round_los\u001b[A\n",
      "Training:  28%|▎| 11351/40960 [00:57<02:22, 207.83batches/s, l2_loss: 0.0950 - round_los\u001b[A\n",
      "Training:  28%|▎| 11391/40960 [00:57<02:24, 204.97batches/s, l2_loss: 0.0950 - round_los\u001b[A\n",
      "Training:  28%|▎| 11391/40960 [00:57<02:24, 204.97batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  28%|▎| 11420/40960 [00:57<02:39, 184.88batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  28%|▎| 11420/40960 [00:57<02:39, 184.88batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  28%|▎| 11454/40960 [00:57<02:45, 178.32batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  28%|▎| 11454/40960 [00:57<02:45, 178.32batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  28%|▎| 11480/40960 [00:58<03:00, 163.01batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  28%|▎| 11480/40960 [00:58<03:00, 163.01batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  28%|▎| 11519/40960 [00:58<02:50, 172.29batches/s, l2_loss: 0.0949 - round_los\u001b[A\n",
      "Training:  28%|▎| 11519/40960 [00:58<02:50, 172.29batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  28%|▎| 11553/40960 [00:58<02:51, 171.51batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  28%|▎| 11553/40960 [00:58<02:51, 171.51batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  28%|▎| 11598/40960 [00:58<02:36, 187.10batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  28%|▎| 11598/40960 [00:58<02:36, 187.10batches/s, l2_loss: 0.0950 - round_los\u001b[A\n",
      "Training:  28%|▎| 11648/40960 [00:58<02:22, 205.32batches/s, l2_loss: 0.0950 - round_los\u001b[A\n",
      "Training:  28%|▎| 11648/40960 [00:58<02:22, 205.32batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  29%|▎| 11696/40960 [00:59<02:15, 215.56batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  29%|▎| 11696/40960 [00:59<02:15, 215.56batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  29%|▎| 11740/40960 [00:59<02:15, 215.84batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  29%|▎| 11740/40960 [00:59<02:15, 215.84batches/s, l2_loss: 0.0948 - round_los\u001b[A\n",
      "Training:  29%|▎| 11783/40960 [00:59<02:15, 215.36batches/s, l2_loss: 0.0948 - round_los\u001b[A\n",
      "Training:  29%|▎| 11783/40960 [00:59<02:15, 215.36batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  29%|▎| 11826/40960 [00:59<02:15, 215.21batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  29%|▎| 11826/40960 [00:59<02:15, 215.21batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  29%|▎| 11867/40960 [00:59<02:17, 211.58batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  29%|▎| 11867/40960 [00:59<02:17, 211.58batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  29%|▎| 11910/40960 [01:00<02:16, 212.49batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  29%|▎| 11910/40960 [01:00<02:16, 212.49batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  29%|▎| 11944/40960 [01:00<02:25, 199.22batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  29%|▎| 11944/40960 [01:00<02:25, 199.22batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  29%|▎| 11984/40960 [01:00<02:26, 198.34batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  29%|▎| 11984/40960 [01:00<02:26, 198.34batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  29%|▎| 12019/40960 [01:00<02:31, 191.23batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  29%|▎| 12019/40960 [01:00<02:31, 191.23batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  29%|▎| 12057/40960 [01:00<02:32, 190.09batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  29%|▎| 12057/40960 [01:00<02:32, 190.09batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  30%|▎| 12102/40960 [01:01<02:24, 200.32batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  30%|▎| 12102/40960 [01:01<02:24, 200.32batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  30%|▎| 12145/40960 [01:01<02:21, 203.66batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  30%|▎| 12145/40960 [01:01<02:21, 203.66batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  30%|▎| 12190/40960 [01:01<02:18, 208.12batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  30%|▎| 12190/40960 [01:01<02:18, 208.12batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  30%|▎| 12234/40960 [01:01<02:16, 210.72batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  30%|▎| 12234/40960 [01:01<02:16, 210.72batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  30%|▎| 12271/40960 [01:02<02:22, 201.25batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  30%|▎| 12271/40960 [01:02<02:22, 201.25batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  30%|▎| 12311/40960 [01:02<02:24, 198.66batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  30%|▎| 12311/40960 [01:02<02:24, 198.66batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  30%|▎| 12350/40960 [01:02<02:26, 195.27batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  30%|▎| 12350/40960 [01:02<02:26, 195.27batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  30%|▎| 12390/40960 [01:02<02:25, 196.57batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  30%|▎| 12390/40960 [01:02<02:25, 196.57batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  30%|▎| 12434/40960 [01:02<02:20, 203.45batches/s, l2_loss: 0.0945 - round_los\u001b[A\n",
      "Training:  30%|▎| 12434/40960 [01:02<02:20, 203.45batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  30%|▎| 12475/40960 [01:03<02:20, 202.62batches/s, l2_loss: 0.0942 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 12475/40960 [01:03<02:20, 202.62batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  31%|▎| 12513/40960 [01:03<02:23, 198.06batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  31%|▎| 12513/40960 [01:03<02:23, 198.06batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  31%|▎| 12555/40960 [01:03<02:21, 201.13batches/s, l2_loss: 0.0946 - round_los\u001b[A\n",
      "Training:  31%|▎| 12555/40960 [01:03<02:21, 201.13batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  31%|▎| 12602/40960 [01:03<02:14, 210.75batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  31%|▎| 12602/40960 [01:03<02:14, 210.75batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  31%|▎| 12649/40960 [01:03<02:10, 217.02batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  31%|▎| 12649/40960 [01:03<02:10, 217.02batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  31%|▎| 12692/40960 [01:04<02:11, 215.66batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  31%|▎| 12692/40960 [01:04<02:11, 215.66batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  31%|▎| 12737/40960 [01:04<02:09, 217.15batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  31%|▎| 12737/40960 [01:04<02:09, 217.15batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  31%|▎| 12785/40960 [01:04<02:06, 222.76batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  31%|▎| 12785/40960 [01:04<02:06, 222.76batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  31%|▎| 12829/40960 [01:04<02:07, 221.17batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  31%|▎| 12829/40960 [01:04<02:07, 221.17batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  31%|▎| 12865/40960 [01:04<02:14, 208.51batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  31%|▎| 12865/40960 [01:04<02:14, 208.51batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  31%|▎| 12902/40960 [01:05<02:19, 201.38batches/s, l2_loss: 0.0947 - round_los\u001b[A\n",
      "Training:  31%|▎| 12902/40960 [01:05<02:19, 201.38batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  32%|▎| 12940/40960 [01:05<02:23, 195.59batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  32%|▎| 12940/40960 [01:05<02:23, 195.59batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  32%|▎| 12976/40960 [01:05<02:26, 190.81batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  32%|▎| 12976/40960 [01:05<02:26, 190.81batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  32%|▎| 13009/40960 [01:05<02:34, 181.47batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  32%|▎| 13009/40960 [01:05<02:34, 181.47batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  32%|▎| 13050/40960 [01:05<02:28, 187.79batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  32%|▎| 13050/40960 [01:05<02:28, 187.79batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  32%|▎| 13098/40960 [01:06<02:17, 203.05batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  32%|▎| 13098/40960 [01:06<02:17, 203.05batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  32%|▎| 13146/40960 [01:06<02:10, 213.68batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  32%|▎| 13146/40960 [01:06<02:10, 213.68batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  32%|▎| 13189/40960 [01:06<02:10, 212.81batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  32%|▎| 13189/40960 [01:06<02:10, 212.81batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  32%|▎| 13230/40960 [01:06<02:12, 210.05batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  32%|▎| 13230/40960 [01:06<02:12, 210.05batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  32%|▎| 13279/40960 [01:06<02:05, 220.38batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  32%|▎| 13279/40960 [01:06<02:05, 220.38batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  33%|▎| 13324/40960 [01:07<02:05, 220.56batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  33%|▎| 13324/40960 [01:07<02:05, 220.56batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  33%|▎| 13366/40960 [01:07<02:07, 217.23batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  33%|▎| 13366/40960 [01:07<02:07, 217.23batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  33%|▎| 13409/40960 [01:07<02:07, 215.76batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  33%|▎| 13409/40960 [01:07<02:07, 215.76batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  33%|▎| 13452/40960 [01:07<02:08, 214.40batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  33%|▎| 13452/40960 [01:07<02:08, 214.40batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  33%|▎| 13492/40960 [01:07<02:11, 209.08batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  33%|▎| 13492/40960 [01:07<02:11, 209.08batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  33%|▎| 13530/40960 [01:08<02:15, 202.47batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  33%|▎| 13530/40960 [01:08<02:15, 202.47batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  33%|▎| 13570/40960 [01:08<02:16, 200.14batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  33%|▎| 13570/40960 [01:08<02:16, 200.14batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  33%|▎| 13608/40960 [01:08<02:19, 196.03batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  33%|▎| 13608/40960 [01:08<02:19, 196.03batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  33%|▎| 13652/40960 [01:08<02:14, 202.82batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  33%|▎| 13652/40960 [01:08<02:14, 202.82batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  33%|▎| 13696/40960 [01:08<02:11, 206.86batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  33%|▎| 13696/40960 [01:08<02:11, 206.86batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  34%|▎| 13736/40960 [01:09<02:13, 204.30batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  34%|▎| 13736/40960 [01:09<02:13, 204.30batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  34%|▎| 13782/40960 [01:09<02:08, 211.33batches/s, l2_loss: 0.0944 - round_los\u001b[A\n",
      "Training:  34%|▎| 13782/40960 [01:09<02:08, 211.33batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  34%|▎| 13827/40960 [01:09<02:06, 213.97batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  34%|▎| 13827/40960 [01:09<02:06, 213.97batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  34%|▎| 13871/40960 [01:09<02:05, 215.56batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  34%|▎| 13871/40960 [01:09<02:05, 215.56batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  34%|▎| 13917/40960 [01:09<02:03, 219.82batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  34%|▎| 13917/40960 [01:09<02:03, 219.82batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  34%|▎| 13959/40960 [01:10<02:04, 216.79batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  34%|▎| 13959/40960 [01:10<02:04, 216.79batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  34%|▎| 14000/40960 [01:10<02:06, 212.81batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  34%|▎| 14000/40960 [01:10<02:06, 212.81batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  34%|▎| 14039/40960 [01:10<02:09, 207.25batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  34%|▎| 14039/40960 [01:10<02:09, 207.25batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  34%|▎| 14086/40960 [01:10<02:05, 214.55batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  34%|▎| 14086/40960 [01:10<02:05, 214.55batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  34%|▎| 14130/40960 [01:10<02:04, 215.31batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  34%|▎| 14130/40960 [01:10<02:04, 215.31batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  35%|▎| 14176/40960 [01:11<02:02, 218.57batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  35%|▎| 14176/40960 [01:11<02:02, 218.57batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  35%|▎| 14219/40960 [01:11<02:02, 217.44batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  35%|▎| 14219/40960 [01:11<02:02, 217.44batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  35%|▎| 14263/40960 [01:11<02:02, 217.23batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  35%|▎| 14263/40960 [01:11<02:02, 217.23batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  35%|▎| 14306/40960 [01:11<02:04, 214.93batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  35%|▎| 14306/40960 [01:11<02:04, 214.93batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  35%|▎| 14348/40960 [01:11<02:04, 213.11batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  35%|▎| 14348/40960 [01:11<02:04, 213.11batches/s, l2_loss: 0.0941 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|▎| 14386/40960 [01:12<02:09, 205.61batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  35%|▎| 14386/40960 [01:12<02:09, 205.61batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  35%|▎| 14428/40960 [01:12<02:08, 205.98batches/s, l2_loss: 0.0943 - round_los\u001b[A\n",
      "Training:  35%|▎| 14428/40960 [01:12<02:08, 205.98batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  35%|▎| 14469/40960 [01:12<02:08, 205.66batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  35%|▎| 14469/40960 [01:12<02:08, 205.66batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  35%|▎| 14513/40960 [01:12<02:06, 209.24batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  35%|▎| 14513/40960 [01:12<02:06, 209.24batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  36%|▎| 14561/40960 [01:12<02:01, 217.31batches/s, l2_loss: 0.0942 - round_los\u001b[A\n",
      "Training:  36%|▎| 14561/40960 [01:12<02:01, 217.31batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  36%|▎| 14599/40960 [01:13<02:06, 207.57batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  36%|▎| 14599/40960 [01:13<02:06, 207.57batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  36%|▎| 14643/40960 [01:13<02:05, 210.28batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  36%|▎| 14643/40960 [01:13<02:05, 210.28batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  36%|▎| 14678/40960 [01:13<02:12, 198.83batches/s, l2_loss: 0.0940 - round_los\u001b[A\n",
      "Training:  36%|▎| 14678/40960 [01:13<02:12, 198.83batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  36%|▎| 14720/40960 [01:13<02:10, 201.27batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  36%|▎| 14720/40960 [01:13<02:10, 201.27batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  36%|▎| 14760/40960 [01:13<02:10, 200.44batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  36%|▎| 14760/40960 [01:13<02:10, 200.44batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  36%|▎| 14795/40960 [01:14<02:17, 190.29batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  36%|▎| 14795/40960 [01:14<02:17, 190.29batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  36%|▎| 14823/40960 [01:14<02:30, 174.03batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  36%|▎| 14823/40960 [01:14<02:30, 174.03batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  36%|▎| 14862/40960 [01:14<02:25, 179.38batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  36%|▎| 14862/40960 [01:14<02:25, 179.38batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  36%|▎| 14907/40960 [01:14<02:15, 191.71batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  36%|▎| 14907/40960 [01:14<02:15, 191.71batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  37%|▎| 14953/40960 [01:14<02:08, 202.86batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  37%|▎| 14953/40960 [01:14<02:08, 202.86batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  37%|▎| 14998/40960 [01:15<02:03, 209.39batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  37%|▎| 14998/40960 [01:15<02:03, 209.39batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  37%|▎| 15040/40960 [01:15<02:04, 208.59batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  37%|▎| 15040/40960 [01:15<02:04, 208.59batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  37%|▎| 15079/40960 [01:15<02:06, 204.17batches/s, l2_loss: 0.0941 - round_los\u001b[A\n",
      "Training:  37%|▎| 15079/40960 [01:15<02:06, 204.17batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  37%|▎| 15124/40960 [01:15<02:03, 208.99batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  37%|▎| 15124/40960 [01:15<02:03, 208.99batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  37%|▎| 15165/40960 [01:15<02:04, 206.56batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  37%|▎| 15165/40960 [01:16<02:04, 206.56batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  37%|▎| 15203/40960 [01:16<02:07, 201.34batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  37%|▎| 15203/40960 [01:16<02:07, 201.34batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  37%|▎| 15241/40960 [01:16<02:10, 196.84batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  37%|▎| 15241/40960 [01:16<02:10, 196.84batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  37%|▎| 15276/40960 [01:16<02:15, 189.33batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  37%|▎| 15276/40960 [01:16<02:15, 189.33batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  37%|▎| 15320/40960 [01:16<02:09, 197.80batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  37%|▎| 15320/40960 [01:16<02:09, 197.80batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  38%|▍| 15360/40960 [01:17<02:09, 197.74batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  38%|▍| 15360/40960 [01:17<02:09, 197.74batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  38%|▍| 15401/40960 [01:17<02:08, 198.91batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  38%|▍| 15401/40960 [01:17<02:08, 198.91batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  38%|▍| 15448/40960 [01:17<02:02, 209.03batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  38%|▍| 15448/40960 [01:17<02:02, 209.03batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  38%|▍| 15495/40960 [01:17<01:57, 216.11batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  38%|▍| 15495/40960 [01:17<01:57, 216.11batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  38%|▍| 15536/40960 [01:17<01:59, 211.94batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  38%|▍| 15536/40960 [01:17<01:59, 211.94batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  38%|▍| 15580/40960 [01:18<01:58, 213.44batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  38%|▍| 15580/40960 [01:18<01:58, 213.44batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  38%|▍| 15617/40960 [01:18<02:04, 203.57batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  38%|▍| 15617/40960 [01:18<02:04, 203.57batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  38%|▍| 15656/40960 [01:18<02:06, 200.70batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  38%|▍| 15656/40960 [01:18<02:06, 200.70batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  38%|▍| 15692/40960 [01:18<02:10, 193.43batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  38%|▍| 15692/40960 [01:18<02:10, 193.43batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  38%|▍| 15722/40960 [01:18<02:21, 178.29batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  38%|▍| 15722/40960 [01:18<02:21, 178.29batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  38%|▍| 15762/40960 [01:19<02:16, 184.07batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  38%|▍| 15762/40960 [01:19<02:16, 184.07batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  39%|▍| 15805/40960 [01:19<02:10, 192.90batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  39%|▍| 15805/40960 [01:19<02:10, 192.90batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  39%|▍| 15847/40960 [01:19<02:07, 197.57batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  39%|▍| 15847/40960 [01:19<02:07, 197.57batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  39%|▍| 15891/40960 [01:19<02:03, 202.84batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  39%|▍| 15891/40960 [01:19<02:03, 202.84batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  39%|▍| 15933/40960 [01:19<02:02, 204.58batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  39%|▍| 15933/40960 [01:19<02:02, 204.58batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  39%|▍| 15979/40960 [01:20<01:58, 211.49batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  39%|▍| 15979/40960 [01:20<01:58, 211.49batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  39%|▍| 16024/40960 [01:20<01:56, 213.91batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  39%|▍| 16024/40960 [01:20<01:56, 213.91batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  39%|▍| 16070/40960 [01:20<01:54, 217.68batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  39%|▍| 16070/40960 [01:20<01:54, 217.68batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  39%|▍| 16113/40960 [01:20<01:54, 216.73batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  39%|▍| 16113/40960 [01:20<01:54, 216.73batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  39%|▍| 16162/40960 [01:20<01:50, 224.29batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  39%|▍| 16162/40960 [01:20<01:50, 224.29batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  40%|▍| 16208/40960 [01:21<01:50, 224.55batches/s, l2_loss: 0.0935 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|▍| 16208/40960 [01:21<01:50, 224.55batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  40%|▍| 16246/40960 [01:21<01:55, 214.05batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  40%|▍| 16246/40960 [01:21<01:55, 214.05batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  40%|▍| 16282/40960 [01:21<02:01, 202.79batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  40%|▍| 16282/40960 [01:21<02:01, 202.79batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  40%|▍| 16320/40960 [01:21<02:04, 198.40batches/s, l2_loss: 0.0939 - round_los\u001b[A\n",
      "Training:  40%|▍| 16320/40960 [01:21<02:04, 198.40batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  40%|▍| 16368/40960 [01:21<01:57, 209.62batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  40%|▍| 16368/40960 [01:21<01:57, 209.62batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  40%|▍| 16414/40960 [01:22<01:54, 214.26batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  40%|▍| 16414/40960 [01:22<01:54, 214.26batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  40%|▍| 16457/40960 [01:22<01:54, 214.01batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  40%|▍| 16457/40960 [01:22<01:54, 214.01batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  40%|▍| 16497/40960 [01:22<01:57, 208.89batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  40%|▍| 16497/40960 [01:22<01:57, 208.89batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  40%|▍| 16540/40960 [01:22<01:56, 209.70batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  40%|▍| 16540/40960 [01:22<01:56, 209.70batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  40%|▍| 16583/40960 [01:22<01:55, 210.58batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  40%|▍| 16583/40960 [01:22<01:55, 210.58batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  41%|▍| 16621/40960 [01:23<01:59, 203.44batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  41%|▍| 16621/40960 [01:23<01:59, 203.44batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  41%|▍| 16664/40960 [01:23<01:57, 206.65batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  41%|▍| 16664/40960 [01:23<01:57, 206.65batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  41%|▍| 16707/40960 [01:23<01:56, 208.23batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  41%|▍| 16707/40960 [01:23<01:56, 208.23batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  41%|▍| 16749/40960 [01:23<01:56, 207.23batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  41%|▍| 16749/40960 [01:23<01:56, 207.23batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  41%|▍| 16791/40960 [01:23<01:56, 206.80batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  41%|▍| 16791/40960 [01:23<01:56, 206.80batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  41%|▍| 16834/40960 [01:24<01:55, 208.94batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  41%|▍| 16834/40960 [01:24<01:55, 208.94batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  41%|▍| 16874/40960 [01:24<01:57, 205.61batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  41%|▍| 16874/40960 [01:24<01:57, 205.61batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  41%|▍| 16917/40960 [01:24<01:56, 207.10batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  41%|▍| 16917/40960 [01:24<01:56, 207.10batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  41%|▍| 16964/40960 [01:24<01:51, 215.20batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  41%|▍| 16964/40960 [01:24<01:51, 215.20batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  42%|▍| 17005/40960 [01:24<01:53, 211.08batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  42%|▍| 17005/40960 [01:24<01:53, 211.08batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  42%|▍| 17048/40960 [01:25<01:53, 210.84batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  42%|▍| 17048/40960 [01:25<01:53, 210.84batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  42%|▍| 17093/40960 [01:25<01:51, 214.26batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  42%|▍| 17093/40960 [01:25<01:51, 214.26batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  42%|▍| 17136/40960 [01:25<01:51, 213.73batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  42%|▍| 17136/40960 [01:25<01:51, 213.73batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  42%|▍| 17173/40960 [01:25<01:57, 202.75batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  42%|▍| 17173/40960 [01:25<01:57, 202.75batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  42%|▍| 17207/40960 [01:25<02:03, 192.68batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  42%|▍| 17207/40960 [01:25<02:03, 192.68batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  42%|▍| 17247/40960 [01:26<02:02, 194.24batches/s, l2_loss: 0.0938 - round_los\u001b[A\n",
      "Training:  42%|▍| 17247/40960 [01:26<02:02, 194.24batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  42%|▍| 17289/40960 [01:26<01:59, 198.18batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  42%|▍| 17289/40960 [01:26<01:59, 198.18batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  42%|▍| 17333/40960 [01:26<01:55, 203.79batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  42%|▍| 17333/40960 [01:26<01:55, 203.79batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  42%|▍| 17375/40960 [01:26<01:55, 204.57batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  42%|▍| 17375/40960 [01:26<01:55, 204.57batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  43%|▍| 17421/40960 [01:26<01:51, 211.00batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  43%|▍| 17421/40960 [01:26<01:51, 211.00batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  43%|▍| 17469/40960 [01:27<01:46, 219.55batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  43%|▍| 17469/40960 [01:27<01:46, 219.55batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  43%|▍| 17510/40960 [01:27<01:49, 215.05batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  43%|▍| 17510/40960 [01:27<01:49, 215.05batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  43%|▍| 17546/40960 [01:27<01:54, 204.44batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  43%|▍| 17546/40960 [01:27<01:54, 204.44batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  43%|▍| 17591/40960 [01:27<01:51, 210.47batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  43%|▍| 17591/40960 [01:27<01:51, 210.47batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  43%|▍| 17630/40960 [01:27<01:54, 203.01batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  43%|▍| 17630/40960 [01:27<01:54, 203.01batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  43%|▍| 17670/40960 [01:28<01:55, 201.44batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  43%|▍| 17670/40960 [01:28<01:55, 201.44batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  43%|▍| 17715/40960 [01:28<01:52, 207.30batches/s, l2_loss: 0.0937 - round_los\u001b[A\n",
      "Training:  43%|▍| 17715/40960 [01:28<01:52, 207.30batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  43%|▍| 17755/40960 [01:28<01:53, 204.51batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  43%|▍| 17755/40960 [01:28<01:53, 204.51batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  43%|▍| 17799/40960 [01:28<01:51, 207.87batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  43%|▍| 17799/40960 [01:28<01:51, 207.87batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  44%|▍| 17843/40960 [01:28<01:49, 210.44batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  44%|▍| 17843/40960 [01:28<01:49, 210.44batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 17888/40960 [01:29<01:48, 213.54batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 17888/40960 [01:29<01:48, 213.54batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 17936/40960 [01:29<01:44, 221.36batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 17936/40960 [01:29<01:44, 221.36batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  44%|▍| 17982/40960 [01:29<01:42, 223.54batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  44%|▍| 17982/40960 [01:29<01:42, 223.54batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  44%|▍| 18028/40960 [01:29<01:42, 224.13batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  44%|▍| 18028/40960 [01:29<01:42, 224.13batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 18074/40960 [01:29<01:41, 225.48batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 18074/40960 [01:29<01:41, 225.48batches/s, l2_loss: 0.0935 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|▍| 18118/40960 [01:30<01:42, 223.36batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 18118/40960 [01:30<01:42, 223.36batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 18162/40960 [01:30<01:43, 221.29batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  44%|▍| 18162/40960 [01:30<01:43, 221.29batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  44%|▍| 18212/40960 [01:30<01:39, 228.63batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  44%|▍| 18212/40960 [01:30<01:39, 228.63batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  45%|▍| 18256/40960 [01:30<01:40, 225.59batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  45%|▍| 18256/40960 [01:30<01:40, 225.59batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  45%|▍| 18300/40960 [01:31<01:41, 222.61batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  45%|▍| 18300/40960 [01:31<01:41, 222.61batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  45%|▍| 18345/40960 [01:31<01:41, 222.43batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  45%|▍| 18345/40960 [01:31<01:41, 222.43batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  45%|▍| 18391/40960 [01:31<01:41, 223.25batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  45%|▍| 18391/40960 [01:31<01:41, 223.25batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  45%|▍| 18439/40960 [01:31<01:39, 227.13batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  45%|▍| 18439/40960 [01:31<01:39, 227.13batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  45%|▍| 18486/40960 [01:31<01:38, 228.16batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  45%|▍| 18486/40960 [01:31<01:38, 228.16batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  45%|▍| 18532/40960 [01:32<01:38, 228.57batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  45%|▍| 18532/40960 [01:32<01:38, 228.57batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  45%|▍| 18582/40960 [01:32<01:35, 233.81batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  45%|▍| 18582/40960 [01:32<01:35, 233.81batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  45%|▍| 18629/40960 [01:32<01:35, 233.17batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  45%|▍| 18629/40960 [01:32<01:35, 233.17batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  46%|▍| 18672/40960 [01:32<01:37, 227.57batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  46%|▍| 18672/40960 [01:32<01:37, 227.57batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  46%|▍| 18717/40960 [01:32<01:38, 225.75batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  46%|▍| 18717/40960 [01:32<01:38, 225.75batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  46%|▍| 18760/40960 [01:33<01:39, 222.12batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  46%|▍| 18760/40960 [01:33<01:39, 222.12batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  46%|▍| 18799/40960 [01:33<01:44, 213.04batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  46%|▍| 18799/40960 [01:33<01:44, 213.04batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  46%|▍| 18843/40960 [01:33<01:44, 212.44batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  46%|▍| 18843/40960 [01:33<01:44, 212.44batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  46%|▍| 18887/40960 [01:33<01:43, 213.64batches/s, l2_loss: 0.0936 - round_los\u001b[A\n",
      "Training:  46%|▍| 18887/40960 [01:33<01:43, 213.64batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  46%|▍| 18931/40960 [01:33<01:42, 215.17batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  46%|▍| 18931/40960 [01:33<01:42, 215.17batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  46%|▍| 18971/40960 [01:34<01:44, 209.92batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  46%|▍| 18971/40960 [01:34<01:44, 209.92batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  46%|▍| 19006/40960 [01:34<01:50, 198.62batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  46%|▍| 19006/40960 [01:34<01:50, 198.62batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  47%|▍| 19048/40960 [01:34<01:48, 201.95batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  47%|▍| 19048/40960 [01:34<01:48, 201.95batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  47%|▍| 19095/40960 [01:34<01:44, 209.99batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  47%|▍| 19095/40960 [01:34<01:44, 209.99batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19130/40960 [01:34<01:50, 198.42batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19130/40960 [01:34<01:50, 198.42batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19178/40960 [01:35<01:43, 209.58batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19178/40960 [01:35<01:43, 209.58batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  47%|▍| 19220/40960 [01:35<01:43, 209.56batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  47%|▍| 19220/40960 [01:35<01:43, 209.56batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19260/40960 [01:35<01:45, 205.10batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19260/40960 [01:35<01:45, 205.10batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  47%|▍| 19307/40960 [01:35<01:41, 212.39batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  47%|▍| 19307/40960 [01:35<01:41, 212.39batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19344/40960 [01:35<01:45, 204.25batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19344/40960 [01:35<01:45, 204.25batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19381/40960 [01:36<01:49, 197.92batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  47%|▍| 19381/40960 [01:36<01:49, 197.92batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  47%|▍| 19416/40960 [01:36<01:53, 189.30batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  47%|▍| 19416/40960 [01:36<01:53, 189.30batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  47%|▍| 19455/40960 [01:36<01:53, 190.12batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  47%|▍| 19455/40960 [01:36<01:53, 190.12batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  48%|▍| 19493/40960 [01:36<01:53, 189.81batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  48%|▍| 19493/40960 [01:36<01:53, 189.81batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  48%|▍| 19536/40960 [01:36<01:49, 196.18batches/s, l2_loss: 0.0935 - round_los\u001b[A\n",
      "Training:  48%|▍| 19536/40960 [01:36<01:49, 196.18batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  48%|▍| 19576/40960 [01:37<01:48, 197.17batches/s, l2_loss: 0.0934 - round_los\u001b[A\n",
      "Training:  48%|▍| 19576/40960 [01:37<01:48, 197.17batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  48%|▍| 19617/40960 [01:37<01:47, 198.17batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  48%|▍| 19617/40960 [01:37<01:47, 198.17batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  48%|▍| 19654/40960 [01:37<01:49, 194.15batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  48%|▍| 19654/40960 [01:37<01:49, 194.15batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  48%|▍| 19688/40960 [01:37<01:53, 186.90batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  48%|▍| 19688/40960 [01:37<01:53, 186.90batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  48%|▍| 19722/40960 [01:37<01:57, 180.45batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  48%|▍| 19722/40960 [01:37<01:57, 180.45batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  48%|▍| 19762/40960 [01:38<01:53, 186.13batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  48%|▍| 19762/40960 [01:38<01:53, 186.13batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  48%|▍| 19802/40960 [01:38<01:52, 188.78batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  48%|▍| 19802/40960 [01:38<01:52, 188.78batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  48%|▍| 19834/40960 [01:38<01:57, 179.87batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  48%|▍| 19834/40960 [01:38<01:57, 179.87batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 19871/40960 [01:38<01:57, 180.23batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 19871/40960 [01:38<01:57, 180.23batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 19915/40960 [01:38<01:49, 191.48batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 19915/40960 [01:38<01:49, 191.48batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 19958/40960 [01:39<01:46, 197.86batches/s, l2_loss: 0.0932 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|▍| 19958/40960 [01:39<01:46, 197.86batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20001/40960 [01:39<01:44, 201.37batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20001/40960 [01:39<01:44, 201.37batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 20043/40960 [01:39<01:42, 203.46batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 20043/40960 [01:39<01:42, 203.46batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 20079/40960 [01:39<01:46, 195.42batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  49%|▍| 20079/40960 [01:39<01:46, 195.42batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20125/40960 [01:39<01:41, 204.66batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20125/40960 [01:39<01:41, 204.66batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20174/40960 [01:40<01:36, 215.49batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20174/40960 [01:40<01:36, 215.49batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20219/40960 [01:40<01:35, 217.24batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20219/40960 [01:40<01:35, 217.24batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20263/40960 [01:40<01:35, 216.78batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  49%|▍| 20263/40960 [01:40<01:35, 216.78batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  50%|▍| 20305/40960 [01:40<01:36, 213.80batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  50%|▍| 20305/40960 [01:40<01:36, 213.80batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▍| 20345/40960 [01:40<01:38, 208.47batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▍| 20345/40960 [01:40<01:38, 208.47batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▍| 20388/40960 [01:41<01:37, 210.28batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▍| 20388/40960 [01:41<01:37, 210.28batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  50%|▍| 20433/40960 [01:41<01:35, 213.93batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  50%|▍| 20433/40960 [01:41<01:35, 213.93batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  50%|▍| 20478/40960 [01:41<01:34, 215.96batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  50%|▍| 20478/40960 [01:41<01:34, 215.96batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▌| 20519/40960 [01:41<01:36, 211.31batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▌| 20519/40960 [01:41<01:36, 211.31batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▌| 20559/40960 [01:41<01:38, 206.29batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▌| 20559/40960 [01:41<01:38, 206.29batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▌| 20600/40960 [01:42<01:39, 205.27batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▌| 20600/40960 [01:42<01:39, 205.27batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▌| 20643/40960 [01:42<01:37, 207.42batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  50%|▌| 20643/40960 [01:42<01:37, 207.42batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  51%|▌| 20685/40960 [01:42<01:38, 205.16batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  51%|▌| 20685/40960 [01:42<01:38, 205.16batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  51%|▌| 20725/40960 [01:42<01:39, 202.55batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  51%|▌| 20725/40960 [01:42<01:39, 202.55batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 20770/40960 [01:42<01:36, 208.61batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 20770/40960 [01:42<01:36, 208.61batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  51%|▌| 20817/40960 [01:43<01:33, 215.38batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  51%|▌| 20817/40960 [01:43<01:33, 215.38batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  51%|▌| 20860/40960 [01:43<01:34, 213.70batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  51%|▌| 20860/40960 [01:43<01:34, 213.70batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 20903/40960 [01:43<01:34, 213.14batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 20903/40960 [01:43<01:34, 213.14batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 20950/40960 [01:43<01:31, 219.51batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 20950/40960 [01:43<01:31, 219.51batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 20999/40960 [01:43<01:28, 226.05batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 20999/40960 [01:44<01:28, 226.05batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  51%|▌| 21042/40960 [01:44<01:29, 221.84batches/s, l2_loss: 0.0933 - round_los\u001b[A\n",
      "Training:  51%|▌| 21042/40960 [01:44<01:29, 221.84batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 21085/40960 [01:44<01:30, 218.79batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  51%|▌| 21085/40960 [01:44<01:30, 218.79batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  52%|▌| 21119/40960 [01:44<01:37, 203.45batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  52%|▌| 21119/40960 [01:44<01:37, 203.45batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  52%|▌| 21161/40960 [01:44<01:36, 205.35batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  52%|▌| 21161/40960 [01:44<01:36, 205.35batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  52%|▌| 21202/40960 [01:45<01:36, 204.28batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  52%|▌| 21202/40960 [01:45<01:36, 204.28batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  52%|▌| 21243/40960 [01:45<01:36, 203.78batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  52%|▌| 21243/40960 [01:45<01:36, 203.78batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  52%|▌| 21285/40960 [01:45<01:35, 205.23batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  52%|▌| 21285/40960 [01:45<01:35, 205.23batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  52%|▌| 21329/40960 [01:45<01:33, 208.96batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  52%|▌| 21329/40960 [01:45<01:33, 208.96batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  52%|▌| 21375/40960 [01:45<01:31, 214.36batches/s, l2_loss: 0.0932 - round_los\u001b[A\n",
      "Training:  52%|▌| 21375/40960 [01:45<01:31, 214.36batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  52%|▌| 21425/40960 [01:46<01:27, 223.79batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  52%|▌| 21425/40960 [01:46<01:27, 223.79batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  52%|▌| 21472/40960 [01:46<01:26, 226.02batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  52%|▌| 21472/40960 [01:46<01:26, 226.02batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  53%|▌| 21513/40960 [01:46<01:28, 218.56batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  53%|▌| 21513/40960 [01:46<01:28, 218.56batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21556/40960 [01:46<01:29, 216.56batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21556/40960 [01:46<01:29, 216.56batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21598/40960 [01:46<01:30, 214.40batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21598/40960 [01:46<01:30, 214.40batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21643/40960 [01:47<01:29, 215.92batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21643/40960 [01:47<01:29, 215.92batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21687/40960 [01:47<01:29, 216.55batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21687/40960 [01:47<01:29, 216.55batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21731/40960 [01:47<01:28, 217.52batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21731/40960 [01:47<01:28, 217.52batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  53%|▌| 21770/40960 [01:47<01:32, 208.34batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  53%|▌| 21770/40960 [01:47<01:32, 208.34batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21810/40960 [01:47<01:33, 204.74batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21810/40960 [01:47<01:33, 204.74batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  53%|▌| 21848/40960 [01:48<01:36, 198.86batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  53%|▌| 21848/40960 [01:48<01:36, 198.86batches/s, l2_loss: 0.0931 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|▌| 21885/40960 [01:48<01:38, 193.41batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  53%|▌| 21885/40960 [01:48<01:38, 193.41batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  54%|▌| 21931/40960 [01:48<01:33, 203.70batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  54%|▌| 21931/40960 [01:48<01:33, 203.70batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  54%|▌| 21974/40960 [01:48<01:31, 207.01batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  54%|▌| 21974/40960 [01:48<01:31, 207.01batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  54%|▌| 22018/40960 [01:48<01:30, 209.84batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  54%|▌| 22018/40960 [01:48<01:30, 209.84batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  54%|▌| 22060/40960 [01:49<01:30, 208.78batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  54%|▌| 22060/40960 [01:49<01:30, 208.78batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  54%|▌| 22102/40960 [01:49<01:30, 209.06batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  54%|▌| 22102/40960 [01:49<01:30, 209.06batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  54%|▌| 22145/40960 [01:49<01:29, 209.85batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  54%|▌| 22145/40960 [01:49<01:29, 209.85batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  54%|▌| 22192/40960 [01:49<01:26, 216.95batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  54%|▌| 22192/40960 [01:49<01:26, 216.95batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  54%|▌| 22239/40960 [01:49<01:24, 221.97batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  54%|▌| 22239/40960 [01:49<01:24, 221.97batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  54%|▌| 22282/40960 [01:50<01:25, 219.14batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  54%|▌| 22282/40960 [01:50<01:25, 219.14batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22327/40960 [01:50<01:24, 220.49batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22327/40960 [01:50<01:24, 220.49batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22376/40960 [01:50<01:22, 226.57batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22376/40960 [01:50<01:22, 226.57batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  55%|▌| 22419/40960 [01:50<01:23, 221.89batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  55%|▌| 22419/40960 [01:50<01:23, 221.89batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22453/40960 [01:50<01:29, 205.78batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22453/40960 [01:50<01:29, 205.78batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22481/40960 [01:51<01:39, 186.08batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22481/40960 [01:51<01:39, 186.08batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  55%|▌| 22514/40960 [01:51<01:42, 179.19batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  55%|▌| 22514/40960 [01:51<01:42, 179.19batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22557/40960 [01:51<01:37, 188.29batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22557/40960 [01:51<01:37, 188.29batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22599/40960 [01:51<01:34, 193.76batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22599/40960 [01:51<01:34, 193.76batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  55%|▌| 22643/40960 [01:51<01:31, 200.31batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  55%|▌| 22643/40960 [01:51<01:31, 200.31batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [01:52<01:27, 208.81batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  55%|▌| 22689/40960 [01:52<01:27, 208.81batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  56%|▌| 22736/40960 [01:52<01:24, 216.44batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  56%|▌| 22736/40960 [01:52<01:24, 216.44batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 22778/40960 [01:52<01:25, 212.96batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 22778/40960 [01:52<01:25, 212.96batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 22821/40960 [01:52<01:25, 212.36batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 22821/40960 [01:52<01:25, 212.36batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  56%|▌| 22864/40960 [01:52<01:25, 212.29batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  56%|▌| 22864/40960 [01:52<01:25, 212.29batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 22890/40960 [01:53<01:36, 186.41batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 22890/40960 [01:53<01:36, 186.41batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 22934/40960 [01:53<01:32, 195.25batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 22934/40960 [01:53<01:32, 195.25batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  56%|▌| 22976/40960 [01:53<01:30, 197.98batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  56%|▌| 22976/40960 [01:53<01:30, 197.98batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  56%|▌| 23022/40960 [01:53<01:26, 206.98batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  56%|▌| 23022/40960 [01:53<01:26, 206.98batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 23061/40960 [01:53<01:28, 203.36batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 23061/40960 [01:53<01:28, 203.36batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 23102/40960 [01:54<01:28, 202.86batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  56%|▌| 23102/40960 [01:54<01:28, 202.86batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23147/40960 [01:54<01:25, 209.00batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23147/40960 [01:54<01:25, 209.00batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23189/40960 [01:54<01:25, 208.89batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23189/40960 [01:54<01:25, 208.89batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  57%|▌| 23230/40960 [01:54<01:25, 206.89batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  57%|▌| 23230/40960 [01:54<01:25, 206.89batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23266/40960 [01:54<01:29, 198.10batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23266/40960 [01:54<01:29, 198.10batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  57%|▌| 23305/40960 [01:55<01:30, 195.51batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  57%|▌| 23305/40960 [01:55<01:30, 195.51batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23351/40960 [01:55<01:25, 205.10batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23351/40960 [01:55<01:25, 205.10batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23388/40960 [01:55<01:28, 198.58batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23388/40960 [01:55<01:28, 198.58batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  57%|▌| 23430/40960 [01:55<01:26, 201.60batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  57%|▌| 23430/40960 [01:55<01:26, 201.60batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23472/40960 [01:55<01:25, 203.80batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  57%|▌| 23472/40960 [01:55<01:25, 203.80batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  57%|▌| 23514/40960 [01:56<01:24, 205.41batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  57%|▌| 23514/40960 [01:56<01:24, 205.41batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23561/40960 [01:56<01:21, 213.15batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23561/40960 [01:56<01:21, 213.15batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23605/40960 [01:56<01:20, 215.18batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23605/40960 [01:56<01:20, 215.18batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23649/40960 [01:56<01:20, 216.35batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23649/40960 [01:56<01:20, 216.35batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  58%|▌| 23693/40960 [01:56<01:19, 216.76batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  58%|▌| 23693/40960 [01:56<01:19, 216.76batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23740/40960 [01:57<01:17, 222.08batches/s, l2_loss: 0.0930 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|▌| 23740/40960 [01:57<01:17, 222.08batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  58%|▌| 23777/40960 [01:57<01:22, 207.70batches/s, l2_loss: 0.0931 - round_los\u001b[A\n",
      "Training:  58%|▌| 23777/40960 [01:57<01:22, 207.70batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23819/40960 [01:57<01:22, 207.61batches/s, l2_loss: 0.0930 - round_los\u001b[A\n",
      "Training:  58%|▌| 23819/40960 [01:57<01:22, 207.61batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  58%|▌| 23856/40960 [01:57<01:25, 199.67batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  58%|▌| 23856/40960 [01:57<01:25, 199.67batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  58%|▌| 23901/40960 [01:57<01:22, 205.68batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  58%|▌| 23901/40960 [01:57<01:22, 205.68batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  58%|▌| 23936/40960 [01:58<01:27, 195.27batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  58%|▌| 23936/40960 [01:58<01:27, 195.27batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 23980/40960 [01:58<01:24, 201.86batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 23980/40960 [01:58<01:24, 201.86batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  59%|▌| 24024/40960 [01:58<01:22, 206.45batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  59%|▌| 24024/40960 [01:58<01:22, 206.45batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24068/40960 [01:58<01:20, 210.20batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24068/40960 [01:58<01:20, 210.20batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24112/40960 [01:59<01:19, 211.98batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24112/40960 [01:59<01:19, 211.98batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  59%|▌| 24155/40960 [01:59<01:18, 212.79batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  59%|▌| 24155/40960 [01:59<01:18, 212.79batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24193/40960 [01:59<01:21, 205.65batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24193/40960 [01:59<01:21, 205.65batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24237/40960 [01:59<01:19, 209.73batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24237/40960 [01:59<01:19, 209.73batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24275/40960 [01:59<01:22, 202.42batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  59%|▌| 24275/40960 [01:59<01:22, 202.42batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  59%|▌| 24317/40960 [02:00<01:21, 203.48batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  59%|▌| 24317/40960 [02:00<01:21, 203.48batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  59%|▌| 24362/40960 [02:00<01:19, 208.71batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  59%|▌| 24362/40960 [02:00<01:19, 208.71batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24401/40960 [02:00<01:21, 202.13batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24401/40960 [02:00<01:21, 202.13batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24441/40960 [02:00<01:22, 201.11batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24441/40960 [02:00<01:22, 201.11batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24480/40960 [02:00<01:22, 198.98batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24480/40960 [02:00<01:22, 198.98batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24517/40960 [02:01<01:24, 194.49batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24517/40960 [02:01<01:24, 194.49batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24553/40960 [02:01<01:26, 189.40batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24553/40960 [02:01<01:26, 189.40batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24591/40960 [02:01<01:26, 188.64batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24591/40960 [02:01<01:26, 188.64batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24628/40960 [02:01<01:27, 186.86batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24628/40960 [02:01<01:27, 186.86batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24665/40960 [02:01<01:27, 186.03batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24665/40960 [02:01<01:27, 186.03batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24708/40960 [02:02<01:24, 193.21batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  60%|▌| 24708/40960 [02:02<01:24, 193.21batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24755/40960 [02:02<01:18, 205.37batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  60%|▌| 24755/40960 [02:02<01:18, 205.37batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  61%|▌| 24804/40960 [02:02<01:14, 216.46batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  61%|▌| 24804/40960 [02:02<01:14, 216.46batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 24852/40960 [02:02<01:12, 222.93batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 24852/40960 [02:02<01:12, 222.93batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 24898/40960 [02:02<01:11, 224.48batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 24898/40960 [02:02<01:11, 224.48batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  61%|▌| 24941/40960 [02:03<01:12, 220.91batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  61%|▌| 24941/40960 [02:03<01:12, 220.91batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 24983/40960 [02:03<01:14, 215.79batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 24983/40960 [02:03<01:14, 215.79batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 25026/40960 [02:03<01:14, 215.02batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 25026/40960 [02:03<01:14, 215.02batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 25073/40960 [02:03<01:12, 219.43batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 25073/40960 [02:03<01:12, 219.43batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 25118/40960 [02:03<01:11, 220.16batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  61%|▌| 25118/40960 [02:03<01:11, 220.16batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  61%|▌| 25163/40960 [02:04<01:11, 221.06batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  61%|▌| 25163/40960 [02:04<01:11, 221.06batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  62%|▌| 25208/40960 [02:04<01:11, 221.78batches/s, l2_loss: 0.0929 - round_los\u001b[A\n",
      "Training:  62%|▌| 25208/40960 [02:04<01:11, 221.78batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25254/40960 [02:04<01:10, 223.51batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25254/40960 [02:04<01:10, 223.51batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25295/40960 [02:04<01:12, 217.37batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25295/40960 [02:04<01:12, 217.37batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25337/40960 [02:04<01:12, 214.96batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25337/40960 [02:04<01:12, 214.96batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25375/40960 [02:05<01:15, 206.58batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25375/40960 [02:05<01:15, 206.58batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25416/40960 [02:05<01:15, 205.49batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25416/40960 [02:05<01:15, 205.49batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  62%|▌| 25460/40960 [02:05<01:13, 209.52batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  62%|▌| 25460/40960 [02:05<01:13, 209.52batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  62%|▌| 25502/40960 [02:05<01:13, 209.35batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  62%|▌| 25502/40960 [02:05<01:13, 209.35batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  62%|▌| 25543/40960 [02:05<01:14, 207.33batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  62%|▌| 25543/40960 [02:05<01:14, 207.33batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25577/40960 [02:06<01:18, 195.20batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  62%|▌| 25577/40960 [02:06<01:18, 195.20batches/s, l2_loss: 0.0928 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|▋| 25614/40960 [02:06<01:20, 191.37batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  63%|▋| 25614/40960 [02:06<01:20, 191.37batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25653/40960 [02:06<01:20, 191.11batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25653/40960 [02:06<01:20, 191.11batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  63%|▋| 25694/40960 [02:06<01:18, 195.04batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  63%|▋| 25694/40960 [02:06<01:18, 195.04batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25733/40960 [02:06<01:18, 193.56batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25733/40960 [02:06<01:18, 193.56batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25772/40960 [02:07<01:18, 193.89batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25772/40960 [02:07<01:18, 193.89batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25806/40960 [02:07<01:21, 185.22batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25806/40960 [02:07<01:21, 185.22batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  63%|▋| 25842/40960 [02:07<01:22, 182.73batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  63%|▋| 25842/40960 [02:07<01:22, 182.73batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25886/40960 [02:07<01:18, 192.88batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25886/40960 [02:07<01:18, 192.88batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  63%|▋| 25929/40960 [02:07<01:15, 198.40batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  63%|▋| 25929/40960 [02:07<01:15, 198.40batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25967/40960 [02:08<01:17, 194.64batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 25967/40960 [02:08<01:17, 194.64batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 26006/40960 [02:08<01:16, 194.48batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  63%|▋| 26006/40960 [02:08<01:16, 194.48batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26048/40960 [02:08<01:15, 198.55batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26048/40960 [02:08<01:15, 198.55batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  64%|▋| 26089/40960 [02:08<01:14, 199.23batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  64%|▋| 26089/40960 [02:08<01:14, 199.23batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26131/40960 [02:08<01:13, 202.38batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26131/40960 [02:08<01:13, 202.38batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26172/40960 [02:09<01:12, 202.69batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26172/40960 [02:09<01:12, 202.69batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26215/40960 [02:09<01:12, 202.57batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26215/40960 [02:09<01:12, 202.57batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26253/40960 [02:09<01:14, 198.54batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26253/40960 [02:09<01:14, 198.54batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  64%|▋| 26289/40960 [02:09<01:16, 191.44batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  64%|▋| 26289/40960 [02:09<01:16, 191.44batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  64%|▋| 26335/40960 [02:09<01:12, 201.44batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  64%|▋| 26335/40960 [02:09<01:12, 201.44batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  64%|▋| 26372/40960 [02:10<01:14, 195.03batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  64%|▋| 26372/40960 [02:10<01:14, 195.03batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26417/40960 [02:10<01:11, 202.33batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  64%|▋| 26417/40960 [02:10<01:11, 202.33batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  65%|▋| 26461/40960 [02:10<01:10, 204.27batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  65%|▋| 26461/40960 [02:10<01:10, 204.27batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26495/40960 [02:10<01:15, 192.57batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26495/40960 [02:10<01:15, 192.57batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26539/40960 [02:10<01:11, 200.32batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26539/40960 [02:10<01:11, 200.32batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  65%|▋| 26574/40960 [02:11<01:14, 192.34batches/s, l2_loss: 0.0928 - round_los\u001b[A\n",
      "Training:  65%|▋| 26574/40960 [02:11<01:14, 192.34batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26617/40960 [02:11<01:12, 198.46batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26617/40960 [02:11<01:12, 198.46batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26659/40960 [02:11<01:11, 201.10batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26659/40960 [02:11<01:11, 201.10batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  65%|▋| 26705/40960 [02:11<01:08, 208.35batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  65%|▋| 26705/40960 [02:11<01:08, 208.35batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26751/40960 [02:11<01:06, 214.18batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  65%|▋| 26751/40960 [02:12<01:06, 214.18batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  65%|▋| 26797/40960 [02:12<01:05, 217.59batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  65%|▋| 26797/40960 [02:12<01:05, 217.59batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 26841/40960 [02:12<01:04, 218.23batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 26841/40960 [02:12<01:04, 218.23batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  66%|▋| 26881/40960 [02:12<01:06, 211.22batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  66%|▋| 26881/40960 [02:12<01:06, 211.22batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 26925/40960 [02:12<01:05, 212.92batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 26925/40960 [02:12<01:05, 212.92batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 26963/40960 [02:13<01:08, 203.55batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 26963/40960 [02:13<01:08, 203.55batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  66%|▋| 26998/40960 [02:13<01:11, 194.59batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  66%|▋| 26998/40960 [02:13<01:11, 194.59batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 27041/40960 [02:13<01:09, 199.44batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 27041/40960 [02:13<01:09, 199.44batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 27081/40960 [02:13<01:09, 199.40batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 27081/40960 [02:13<01:09, 199.40batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  66%|▋| 27120/40960 [02:13<01:10, 197.05batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  66%|▋| 27120/40960 [02:13<01:10, 197.05batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 27162/40960 [02:14<01:09, 199.93batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 27162/40960 [02:14<01:09, 199.93batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 27203/40960 [02:14<01:08, 201.15batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  66%|▋| 27203/40960 [02:14<01:08, 201.15batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  67%|▋| 27244/40960 [02:14<01:07, 202.06batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  67%|▋| 27244/40960 [02:14<01:07, 202.06batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27290/40960 [02:14<01:05, 209.34batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27290/40960 [02:14<01:05, 209.34batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27336/40960 [02:14<01:03, 214.99batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27336/40960 [02:14<01:03, 214.99batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27384/40960 [02:15<01:01, 221.84batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27384/40960 [02:15<01:01, 221.84batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27433/40960 [02:15<00:59, 227.12batches/s, l2_loss: 0.0926 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|▋| 27433/40960 [02:15<00:59, 227.12batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  67%|▋| 27468/40960 [02:15<01:04, 210.06batches/s, l2_loss: 0.0927 - round_los\u001b[A\n",
      "Training:  67%|▋| 27468/40960 [02:15<01:04, 210.06batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27509/40960 [02:15<01:04, 208.33batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27509/40960 [02:15<01:04, 208.33batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  67%|▋| 27557/40960 [02:15<01:01, 216.30batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  67%|▋| 27557/40960 [02:15<01:01, 216.30batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27595/40960 [02:16<01:04, 207.90batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27595/40960 [02:16<01:04, 207.90batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27632/40960 [02:16<01:06, 201.01batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  67%|▋| 27632/40960 [02:16<01:06, 201.01batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27667/40960 [02:16<01:09, 191.71batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27667/40960 [02:16<01:09, 191.71batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27714/40960 [02:16<01:05, 203.71batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27714/40960 [02:16<01:05, 203.71batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  68%|▋| 27761/40960 [02:16<01:02, 212.15batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  68%|▋| 27761/40960 [02:16<01:02, 212.15batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  68%|▋| 27810/40960 [02:17<00:59, 220.83batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  68%|▋| 27810/40960 [02:17<00:59, 220.83batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27851/40960 [02:17<01:00, 215.71batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27851/40960 [02:17<01:00, 215.71batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27899/40960 [02:17<00:58, 222.42batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27899/40960 [02:17<00:58, 222.42batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  68%|▋| 27939/40960 [02:17<01:00, 215.44batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  68%|▋| 27939/40960 [02:17<01:00, 215.44batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27978/40960 [02:17<01:02, 208.32batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 27978/40960 [02:17<01:02, 208.32batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 28027/40960 [02:18<00:59, 218.70batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  68%|▋| 28027/40960 [02:18<00:59, 218.70batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  69%|▋| 28074/40960 [02:18<00:58, 221.92batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  69%|▋| 28074/40960 [02:18<00:58, 221.92batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  69%|▋| 28117/40960 [02:18<00:58, 218.53batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  69%|▋| 28117/40960 [02:18<00:58, 218.53batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  69%|▋| 28162/40960 [02:18<00:58, 219.92batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  69%|▋| 28162/40960 [02:18<00:58, 219.92batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28213/40960 [02:18<00:55, 229.10batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28213/40960 [02:18<00:55, 229.10batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28253/40960 [02:19<00:58, 218.97batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28253/40960 [02:19<00:58, 218.97batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28299/40960 [02:19<00:57, 220.31batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28299/40960 [02:19<00:57, 220.31batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28334/40960 [02:19<01:01, 205.66batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28334/40960 [02:19<01:01, 205.66batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28372/40960 [02:19<01:02, 199.86batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28372/40960 [02:19<01:02, 199.86batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  69%|▋| 28407/40960 [02:19<01:05, 190.52batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  69%|▋| 28407/40960 [02:19<01:05, 190.52batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28449/40960 [02:20<01:03, 195.86batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  69%|▋| 28449/40960 [02:20<01:03, 195.86batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28489/40960 [02:20<01:03, 196.13batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28489/40960 [02:20<01:03, 196.13batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28530/40960 [02:20<01:02, 198.38batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28530/40960 [02:20<01:02, 198.38batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28576/40960 [02:20<01:00, 206.31batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28576/40960 [02:20<01:00, 206.31batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28624/40960 [02:20<00:57, 215.71batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28624/40960 [02:20<00:57, 215.71batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  70%|▋| 28666/40960 [02:21<00:57, 213.57batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  70%|▋| 28666/40960 [02:21<00:57, 213.57batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28713/40960 [02:21<00:55, 219.19batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28713/40960 [02:21<00:55, 219.19batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  70%|▋| 28754/40960 [02:21<00:56, 214.67batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  70%|▋| 28754/40960 [02:21<00:56, 214.67batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28792/40960 [02:21<00:58, 207.03batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28792/40960 [02:21<00:58, 207.03batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28840/40960 [02:21<00:56, 215.72batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  70%|▋| 28840/40960 [02:21<00:56, 215.72batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  71%|▋| 28888/40960 [02:22<00:54, 222.21batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  71%|▋| 28888/40960 [02:22<00:54, 222.21batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  71%|▋| 28936/40960 [02:22<00:53, 226.67batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  71%|▋| 28936/40960 [02:22<00:53, 226.67batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  71%|▋| 28982/40960 [02:22<00:52, 226.29batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  71%|▋| 28982/40960 [02:22<00:52, 226.29batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  71%|▋| 29030/40960 [02:22<00:52, 229.16batches/s, l2_loss: 0.0926 - round_los\u001b[A\n",
      "Training:  71%|▋| 29030/40960 [02:22<00:52, 229.16batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  71%|▋| 29078/40960 [02:22<00:51, 231.53batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  71%|▋| 29078/40960 [02:22<00:51, 231.53batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  71%|▋| 29124/40960 [02:23<00:51, 229.81batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  71%|▋| 29124/40960 [02:23<00:51, 229.81batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  71%|▋| 29164/40960 [02:23<00:53, 220.20batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  71%|▋| 29164/40960 [02:23<00:53, 220.20batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  71%|▋| 29209/40960 [02:23<00:53, 220.19batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  71%|▋| 29209/40960 [02:23<00:53, 220.19batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  71%|▋| 29248/40960 [02:23<00:55, 212.49batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  71%|▋| 29248/40960 [02:23<00:55, 212.49batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29296/40960 [02:23<00:52, 220.22batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29296/40960 [02:23<00:52, 220.22batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29344/40960 [02:24<00:51, 224.91batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29344/40960 [02:24<00:51, 224.91batches/s, l2_loss: 0.0925 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|▋| 29388/40960 [02:24<00:52, 221.84batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  72%|▋| 29388/40960 [02:24<00:52, 221.84batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29430/40960 [02:24<00:52, 217.67batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29430/40960 [02:24<00:52, 217.67batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29475/40960 [02:24<00:52, 218.67batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29475/40960 [02:24<00:52, 218.67batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29516/40960 [02:24<00:53, 213.39batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29516/40960 [02:24<00:53, 213.39batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  72%|▋| 29554/40960 [02:25<00:55, 205.36batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  72%|▋| 29554/40960 [02:25<00:55, 205.36batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29599/40960 [02:25<00:54, 209.76batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29599/40960 [02:25<00:54, 209.76batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29644/40960 [02:25<00:53, 212.99batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  72%|▋| 29644/40960 [02:25<00:53, 212.99batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  72%|▋| 29687/40960 [02:25<00:53, 212.13batches/s, l2_loss: 0.0925 - round_los\u001b[A\n",
      "Training:  72%|▋| 29687/40960 [02:25<00:53, 212.13batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29728/40960 [02:26<00:53, 208.21batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29728/40960 [02:26<00:53, 208.21batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29772/40960 [02:26<00:53, 210.76batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29772/40960 [02:26<00:53, 210.76batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29819/40960 [02:26<00:51, 217.31batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29819/40960 [02:26<00:51, 217.31batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29863/40960 [02:26<00:51, 216.24batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29863/40960 [02:26<00:51, 216.24batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29908/40960 [02:26<00:50, 218.01batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29908/40960 [02:26<00:50, 218.01batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29954/40960 [02:27<00:49, 220.66batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 29954/40960 [02:27<00:49, 220.66batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 30000/40960 [02:27<00:49, 222.85batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 30000/40960 [02:27<00:49, 222.85batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  73%|▋| 30046/40960 [02:27<00:48, 224.84batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  73%|▋| 30046/40960 [02:27<00:48, 224.84batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 30093/40960 [02:27<00:47, 227.84batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  73%|▋| 30093/40960 [02:27<00:47, 227.84batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  74%|▋| 30130/40960 [02:27<00:50, 214.73batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  74%|▋| 30130/40960 [02:27<00:50, 214.73batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30171/40960 [02:28<00:51, 210.27batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30171/40960 [02:28<00:51, 210.27batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30215/40960 [02:28<00:50, 213.02batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30215/40960 [02:28<00:50, 213.02batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  74%|▋| 30256/40960 [02:28<00:51, 209.54batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  74%|▋| 30256/40960 [02:28<00:51, 209.54batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30296/40960 [02:28<00:51, 205.90batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30296/40960 [02:28<00:51, 205.90batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30332/40960 [02:28<00:54, 196.79batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30332/40960 [02:28<00:54, 196.79batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30367/40960 [02:29<00:55, 189.39batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30367/40960 [02:29<00:55, 189.39batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30414/40960 [02:29<00:52, 202.52batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30414/40960 [02:29<00:52, 202.52batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  74%|▋| 30456/40960 [02:29<00:51, 203.82batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  74%|▋| 30456/40960 [02:29<00:51, 203.82batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30499/40960 [02:29<00:51, 204.66batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  74%|▋| 30499/40960 [02:29<00:51, 204.66batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  75%|▋| 30544/40960 [02:29<00:49, 209.52batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  75%|▋| 30544/40960 [02:29<00:49, 209.52batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▋| 30587/40960 [02:30<00:49, 210.81batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▋| 30587/40960 [02:30<00:49, 210.81batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▋| 30630/40960 [02:30<00:48, 211.91batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▋| 30630/40960 [02:30<00:48, 211.91batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▋| 30666/40960 [02:30<00:51, 201.83batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▋| 30666/40960 [02:30<00:51, 201.83batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  75%|▋| 30700/40960 [02:30<00:53, 190.97batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  75%|▋| 30700/40960 [02:30<00:53, 190.97batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30743/40960 [02:30<00:51, 197.59batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30743/40960 [02:30<00:51, 197.59batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30786/40960 [02:31<00:50, 202.17batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30786/40960 [02:31<00:50, 202.17batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30830/40960 [02:31<00:49, 206.32batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30830/40960 [02:31<00:49, 206.32batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30876/40960 [02:31<00:47, 212.05batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30876/40960 [02:31<00:47, 212.05batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30923/40960 [02:31<00:45, 218.33batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  75%|▊| 30923/40960 [02:31<00:45, 218.33batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 30967/40960 [02:31<00:45, 218.73batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 30967/40960 [02:31<00:45, 218.73batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31014/40960 [02:32<00:44, 221.95batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31014/40960 [02:32<00:44, 221.95batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  76%|▊| 31059/40960 [02:32<00:44, 222.13batches/s, l2_loss: 0.0924 - round_los\u001b[A\n",
      "Training:  76%|▊| 31059/40960 [02:32<00:44, 222.13batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31104/40960 [02:32<00:44, 222.78batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31104/40960 [02:32<00:44, 222.78batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31140/40960 [02:32<00:47, 208.83batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31140/40960 [02:32<00:47, 208.83batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  76%|▊| 31182/40960 [02:32<00:47, 208.03batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  76%|▊| 31182/40960 [02:32<00:47, 208.03batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31224/40960 [02:33<00:46, 207.37batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31224/40960 [02:33<00:46, 207.37batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31257/40960 [02:33<00:50, 192.89batches/s, l2_loss: 0.0923 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|▊| 31257/40960 [02:33<00:50, 192.89batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31295/40960 [02:33<00:51, 189.44batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  76%|▊| 31295/40960 [02:33<00:51, 189.44batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31338/40960 [02:33<00:49, 195.62batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31338/40960 [02:33<00:49, 195.62batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31378/40960 [02:33<00:48, 195.71batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31378/40960 [02:33<00:48, 195.71batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31406/40960 [02:34<00:53, 177.58batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31406/40960 [02:34<00:53, 177.58batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31443/40960 [02:34<00:53, 179.17batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31443/40960 [02:34<00:53, 179.17batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31487/40960 [02:34<00:49, 189.95batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31487/40960 [02:34<00:49, 189.95batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31525/40960 [02:34<00:49, 189.96batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31525/40960 [02:34<00:49, 189.96batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31565/40960 [02:34<00:48, 191.76batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31565/40960 [02:34<00:48, 191.76batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31608/40960 [02:35<00:47, 197.30batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  77%|▊| 31608/40960 [02:35<00:47, 197.30batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  77%|▊| 31649/40960 [02:35<00:47, 197.33batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  77%|▊| 31649/40960 [02:35<00:47, 197.33batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  77%|▊| 31686/40960 [02:35<00:48, 192.65batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  77%|▊| 31686/40960 [02:35<00:48, 192.65batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  77%|▊| 31716/40960 [02:35<00:51, 177.89batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  77%|▊| 31716/40960 [02:35<00:51, 177.89batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31757/40960 [02:35<00:49, 184.53batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31757/40960 [02:35<00:49, 184.53batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31796/40960 [02:36<00:49, 186.45batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31796/40960 [02:36<00:49, 186.45batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31838/40960 [02:36<00:47, 192.41batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31838/40960 [02:36<00:47, 192.41batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31881/40960 [02:36<00:45, 198.04batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31881/40960 [02:36<00:45, 198.04batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31923/40960 [02:36<00:45, 200.31batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31923/40960 [02:36<00:45, 200.31batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31964/40960 [02:36<00:44, 200.85batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 31964/40960 [02:37<00:44, 200.85batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 32008/40960 [02:37<00:43, 205.99batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 32008/40960 [02:37<00:43, 205.99batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 32051/40960 [02:37<00:42, 208.35batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 32051/40960 [02:37<00:42, 208.35batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  78%|▊| 32096/40960 [02:37<00:41, 213.18batches/s, l2_loss: 0.0923 - round_los\u001b[A\n",
      "Training:  78%|▊| 32096/40960 [02:37<00:41, 213.18batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 32142/40960 [02:37<00:40, 217.83batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  78%|▊| 32142/40960 [02:37<00:40, 217.83batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32182/40960 [02:38<00:41, 211.60batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32182/40960 [02:38<00:41, 211.60batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  79%|▊| 32217/40960 [02:38<00:43, 200.40batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  79%|▊| 32217/40960 [02:38<00:43, 200.40batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  79%|▊| 32252/40960 [02:38<00:45, 192.23batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  79%|▊| 32252/40960 [02:38<00:45, 192.23batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32294/40960 [02:38<00:44, 196.40batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32294/40960 [02:38<00:44, 196.40batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  79%|▊| 32332/40960 [02:38<00:44, 194.33batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  79%|▊| 32332/40960 [02:38<00:44, 194.33batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32372/40960 [02:39<00:44, 194.46batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32372/40960 [02:39<00:44, 194.46batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32411/40960 [02:39<00:44, 193.90batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32411/40960 [02:39<00:44, 193.90batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32451/40960 [02:39<00:43, 194.13batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32451/40960 [02:39<00:43, 194.13batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32488/40960 [02:39<00:44, 190.38batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32488/40960 [02:39<00:44, 190.38batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32532/40960 [02:39<00:42, 198.40batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  79%|▊| 32532/40960 [02:39<00:42, 198.40batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32578/40960 [02:40<00:40, 207.25batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32578/40960 [02:40<00:40, 207.25batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32623/40960 [02:40<00:39, 212.07batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32623/40960 [02:40<00:39, 212.07batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  80%|▊| 32663/40960 [02:40<00:39, 208.35batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  80%|▊| 32663/40960 [02:40<00:39, 208.35batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  80%|▊| 32710/40960 [02:40<00:38, 216.20batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  80%|▊| 32710/40960 [02:40<00:38, 216.20batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32757/40960 [02:40<00:37, 221.08batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32757/40960 [02:40<00:37, 221.08batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  80%|▊| 32798/40960 [02:41<00:37, 216.24batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  80%|▊| 32798/40960 [02:41<00:37, 216.24batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32844/40960 [02:41<00:37, 219.11batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32844/40960 [02:41<00:37, 219.11batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32887/40960 [02:41<00:37, 217.50batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32887/40960 [02:41<00:37, 217.50batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32928/40960 [02:41<00:37, 213.75batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32928/40960 [02:41<00:37, 213.75batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32971/40960 [02:41<00:37, 213.26batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  80%|▊| 32971/40960 [02:41<00:37, 213.26batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  81%|▊| 33010/40960 [02:42<00:38, 206.62batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  81%|▊| 33010/40960 [02:42<00:38, 206.62batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  81%|▊| 33051/40960 [02:42<00:38, 204.96batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  81%|▊| 33051/40960 [02:42<00:38, 204.96batches/s, l2_loss: 0.0921 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|▊| 33091/40960 [02:42<00:38, 202.34batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33091/40960 [02:42<00:38, 202.34batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  81%|▊| 33131/40960 [02:42<00:38, 201.51batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  81%|▊| 33131/40960 [02:42<00:38, 201.51batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  81%|▊| 33174/40960 [02:42<00:38, 204.79batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  81%|▊| 33174/40960 [02:42<00:38, 204.79batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33211/40960 [02:43<00:39, 197.26batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33211/40960 [02:43<00:39, 197.26batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33254/40960 [02:43<00:38, 199.70batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33254/40960 [02:43<00:38, 199.70batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33297/40960 [02:43<00:37, 204.16batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33297/40960 [02:43<00:37, 204.16batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33339/40960 [02:43<00:37, 205.22batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33339/40960 [02:43<00:37, 205.22batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33377/40960 [02:43<00:37, 200.35batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  81%|▊| 33377/40960 [02:43<00:37, 200.35batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33417/40960 [02:44<00:37, 199.02batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33417/40960 [02:44<00:37, 199.02batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33454/40960 [02:44<00:38, 194.52batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33454/40960 [02:44<00:38, 194.52batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33493/40960 [02:44<00:38, 194.45batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33493/40960 [02:44<00:38, 194.45batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33528/40960 [02:44<00:39, 187.13batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33528/40960 [02:44<00:39, 187.13batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33565/40960 [02:44<00:39, 185.90batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33565/40960 [02:44<00:39, 185.90batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33604/40960 [02:45<00:39, 187.86batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33604/40960 [02:45<00:39, 187.86batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  82%|▊| 33647/40960 [02:45<00:37, 194.83batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  82%|▊| 33647/40960 [02:45<00:37, 194.83batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33679/40960 [02:45<00:40, 182.01batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33679/40960 [02:45<00:40, 182.01batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33717/40960 [02:45<00:39, 183.61batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33717/40960 [02:45<00:39, 183.61batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33752/40960 [02:45<00:39, 180.83batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33752/40960 [02:45<00:39, 180.83batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33790/40960 [02:46<00:39, 183.39batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  82%|▊| 33790/40960 [02:46<00:39, 183.39batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 33826/40960 [02:46<00:39, 182.09batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 33826/40960 [02:46<00:39, 182.09batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  83%|▊| 33858/40960 [02:46<00:40, 174.71batches/s, l2_loss: 0.0922 - round_los\u001b[A\n",
      "Training:  83%|▊| 33858/40960 [02:46<00:40, 174.71batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 33892/40960 [02:46<00:40, 173.05batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 33892/40960 [02:46<00:40, 173.05batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 33930/40960 [02:46<00:39, 177.86batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 33930/40960 [02:46<00:39, 177.86batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 33969/40960 [02:47<00:38, 182.28batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 33969/40960 [02:47<00:38, 182.28batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34011/40960 [02:47<00:36, 189.93batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34011/40960 [02:47<00:36, 189.93batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34058/40960 [02:47<00:33, 203.24batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34058/40960 [02:47<00:33, 203.24batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34101/40960 [02:47<00:33, 206.05batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34101/40960 [02:47<00:33, 206.05batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34150/40960 [02:47<00:31, 217.12batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34150/40960 [02:47<00:31, 217.12batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34200/40960 [02:48<00:29, 225.91batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  83%|▊| 34200/40960 [02:48<00:29, 225.91batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  84%|▊| 34246/40960 [02:48<00:29, 226.20batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  84%|▊| 34246/40960 [02:48<00:29, 226.20batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  84%|▊| 34289/40960 [02:48<00:30, 221.62batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  84%|▊| 34289/40960 [02:48<00:30, 221.62batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  84%|▊| 34330/40960 [02:48<00:30, 215.19batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  84%|▊| 34330/40960 [02:48<00:30, 215.19batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34367/40960 [02:48<00:31, 206.15batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34367/40960 [02:48<00:31, 206.15batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  84%|▊| 34407/40960 [02:49<00:32, 203.26batches/s, l2_loss: 0.0921 - round_los\u001b[A\n",
      "Training:  84%|▊| 34407/40960 [02:49<00:32, 203.26batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34450/40960 [02:49<00:31, 206.43batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34450/40960 [02:49<00:31, 206.43batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34497/40960 [02:49<00:30, 214.00batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34497/40960 [02:49<00:30, 214.00batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34544/40960 [02:49<00:29, 219.89batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34544/40960 [02:49<00:29, 219.89batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34586/40960 [02:49<00:29, 215.22batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  84%|▊| 34586/40960 [02:49<00:29, 215.22batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34621/40960 [02:50<00:31, 202.83batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34621/40960 [02:50<00:31, 202.83batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34660/40960 [02:50<00:31, 199.02batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34660/40960 [02:50<00:31, 199.02batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [02:50<00:33, 188.08batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [02:50<00:33, 188.08batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34718/40960 [02:50<00:37, 167.56batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34718/40960 [02:50<00:37, 167.56batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34765/40960 [02:50<00:33, 187.08batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34765/40960 [02:50<00:33, 187.08batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34808/40960 [02:51<00:31, 194.98batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34808/40960 [02:51<00:31, 194.98batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34849/40960 [02:51<00:30, 197.51batches/s, l2_loss: 0.0920 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|▊| 34849/40960 [02:51<00:30, 197.51batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34888/40960 [02:51<00:31, 195.30batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34888/40960 [02:51<00:31, 195.30batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34927/40960 [02:51<00:30, 194.78batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 34927/40960 [02:51<00:30, 194.78batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  85%|▊| 34964/40960 [02:51<00:31, 191.68batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  85%|▊| 34964/40960 [02:51<00:31, 191.68batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 35011/40960 [02:52<00:29, 203.40batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  85%|▊| 35011/40960 [02:52<00:29, 203.40batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35059/40960 [02:52<00:27, 213.15batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35059/40960 [02:52<00:27, 213.15batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35101/40960 [02:52<00:27, 212.08batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35101/40960 [02:52<00:27, 212.08batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35148/40960 [02:52<00:26, 217.61batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35148/40960 [02:52<00:26, 217.61batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35194/40960 [02:52<00:26, 219.54batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35194/40960 [02:53<00:26, 219.54batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35227/40960 [02:53<00:28, 200.25batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35227/40960 [02:53<00:28, 200.25batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35264/40960 [02:53<00:29, 194.42batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35264/40960 [02:53<00:29, 194.42batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  86%|▊| 35299/40960 [02:53<00:30, 188.15batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  86%|▊| 35299/40960 [02:53<00:30, 188.15batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35336/40960 [02:53<00:30, 186.08batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35336/40960 [02:53<00:30, 186.08batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35377/40960 [02:54<00:29, 190.30batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35377/40960 [02:54<00:29, 190.30batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35415/40960 [02:54<00:29, 189.35batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  86%|▊| 35415/40960 [02:54<00:29, 189.35batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  87%|▊| 35453/40960 [02:54<00:29, 188.37batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  87%|▊| 35453/40960 [02:54<00:29, 188.37batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35490/40960 [02:54<00:29, 187.11batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35490/40960 [02:54<00:29, 187.11batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35523/40960 [02:54<00:30, 180.29batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35523/40960 [02:54<00:30, 180.29batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  87%|▊| 35563/40960 [02:55<00:29, 186.01batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  87%|▊| 35563/40960 [02:55<00:29, 186.01batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35600/40960 [02:55<00:28, 185.43batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35600/40960 [02:55<00:28, 185.43batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35638/40960 [02:55<00:28, 185.97batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35638/40960 [02:55<00:28, 185.97batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  87%|▊| 35680/40960 [02:55<00:27, 192.17batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  87%|▊| 35680/40960 [02:55<00:27, 192.17batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  87%|▊| 35723/40960 [02:55<00:26, 197.65batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  87%|▊| 35723/40960 [02:55<00:26, 197.65batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35771/40960 [02:56<00:24, 209.12batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35771/40960 [02:56<00:24, 209.12batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35815/40960 [02:56<00:24, 211.84batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  87%|▊| 35815/40960 [02:56<00:24, 211.84batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  88%|▉| 35862/40960 [02:56<00:23, 218.40batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  88%|▉| 35862/40960 [02:56<00:23, 218.40batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 35909/40960 [02:56<00:22, 222.61batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 35909/40960 [02:56<00:22, 222.61batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  88%|▉| 35951/40960 [02:56<00:23, 217.63batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  88%|▉| 35951/40960 [02:56<00:23, 217.63batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 35996/40960 [02:57<00:22, 219.79batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 35996/40960 [02:57<00:22, 219.79batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36042/40960 [02:57<00:22, 222.56batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36042/40960 [02:57<00:22, 222.56batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36083/40960 [02:57<00:22, 216.50batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36083/40960 [02:57<00:22, 216.50batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36117/40960 [02:57<00:24, 201.17batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36117/40960 [02:57<00:24, 201.17batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36161/40960 [02:57<00:23, 205.55batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36161/40960 [02:57<00:23, 205.55batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36202/40960 [02:58<00:23, 204.60batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  88%|▉| 36202/40960 [02:58<00:23, 204.60batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  88%|▉| 36245/40960 [02:58<00:22, 205.59batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  88%|▉| 36245/40960 [02:58<00:22, 205.59batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  89%|▉| 36286/40960 [02:58<00:22, 204.75batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  89%|▉| 36286/40960 [02:58<00:22, 204.75batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  89%|▉| 36332/40960 [02:58<00:21, 211.90batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  89%|▉| 36332/40960 [02:58<00:21, 211.90batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  89%|▉| 36375/40960 [02:58<00:21, 212.62batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  89%|▉| 36375/40960 [02:58<00:21, 212.62batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36414/40960 [02:59<00:21, 207.04batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36414/40960 [02:59<00:21, 207.04batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36460/40960 [02:59<00:21, 212.97batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36460/40960 [02:59<00:21, 212.97batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  89%|▉| 36507/40960 [02:59<00:20, 218.95batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  89%|▉| 36507/40960 [02:59<00:20, 218.95batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36551/40960 [02:59<00:20, 218.73batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36551/40960 [02:59<00:20, 218.73batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36598/40960 [02:59<00:19, 223.56batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36598/40960 [02:59<00:19, 223.56batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36643/40960 [03:00<00:19, 223.20batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  89%|▉| 36643/40960 [03:00<00:19, 223.20batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36687/40960 [03:00<00:19, 222.03batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36687/40960 [03:00<00:19, 222.03batches/s, l2_loss: 0.0918 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|▉| 36726/40960 [03:00<00:19, 212.03batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  90%|▉| 36726/40960 [03:00<00:19, 212.03batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36769/40960 [03:00<00:19, 212.76batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36769/40960 [03:00<00:19, 212.76batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36807/40960 [03:00<00:20, 205.47batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36807/40960 [03:00<00:20, 205.47batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36845/40960 [03:01<00:20, 199.17batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36845/40960 [03:01<00:20, 199.17batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36889/40960 [03:01<00:19, 204.40batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36889/40960 [03:01<00:19, 204.40batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36932/40960 [03:01<00:19, 206.32batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 36932/40960 [03:01<00:19, 206.32batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  90%|▉| 36971/40960 [03:01<00:19, 202.69batches/s, l2_loss: 0.0920 - round_los\u001b[A\n",
      "Training:  90%|▉| 36971/40960 [03:01<00:19, 202.69batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 37016/40960 [03:01<00:18, 209.13batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 37016/40960 [03:01<00:18, 209.13batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 37060/40960 [03:02<00:18, 210.72batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  90%|▉| 37060/40960 [03:02<00:18, 210.72batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37097/40960 [03:02<00:19, 201.94batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37097/40960 [03:02<00:19, 201.94batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37141/40960 [03:02<00:18, 206.37batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37141/40960 [03:02<00:18, 206.37batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37187/40960 [03:02<00:17, 212.87batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37187/40960 [03:02<00:17, 212.87batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37233/40960 [03:02<00:17, 217.04batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37233/40960 [03:02<00:17, 217.04batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37273/40960 [03:03<00:17, 210.52batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37273/40960 [03:03<00:17, 210.52batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37309/40960 [03:03<00:18, 200.15batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37309/40960 [03:03<00:18, 200.15batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37355/40960 [03:03<00:17, 208.12batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37355/40960 [03:03<00:17, 208.12batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37398/40960 [03:03<00:16, 210.06batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37398/40960 [03:03<00:16, 210.06batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37438/40960 [03:03<00:17, 206.85batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37438/40960 [03:03<00:17, 206.85batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37478/40960 [03:04<00:17, 204.29batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  91%|▉| 37478/40960 [03:04<00:17, 204.29batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37519/40960 [03:04<00:16, 203.30batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37519/40960 [03:04<00:16, 203.30batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37565/40960 [03:04<00:16, 210.08batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37565/40960 [03:04<00:16, 210.08batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37608/40960 [03:04<00:15, 211.49batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37608/40960 [03:04<00:15, 211.49batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37649/40960 [03:04<00:15, 208.86batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37649/40960 [03:04<00:15, 208.86batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37689/40960 [03:05<00:15, 205.58batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37689/40960 [03:05<00:15, 205.58batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37731/40960 [03:05<00:15, 206.81batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37731/40960 [03:05<00:15, 206.81batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37776/40960 [03:05<00:15, 210.64batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37776/40960 [03:05<00:15, 210.64batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37821/40960 [03:05<00:14, 214.23batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37821/40960 [03:05<00:14, 214.23batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37866/40960 [03:05<00:14, 216.40batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  92%|▉| 37866/40960 [03:05<00:14, 216.40batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 37906/40960 [03:06<00:14, 211.38batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 37906/40960 [03:06<00:14, 211.38batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  93%|▉| 37950/40960 [03:06<00:14, 213.67batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  93%|▉| 37950/40960 [03:06<00:14, 213.67batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  93%|▉| 37994/40960 [03:06<00:13, 215.22batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  93%|▉| 37994/40960 [03:06<00:13, 215.22batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38038/40960 [03:06<00:13, 215.40batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38038/40960 [03:06<00:13, 215.40batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  93%|▉| 38083/40960 [03:06<00:13, 217.68batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  93%|▉| 38083/40960 [03:06<00:13, 217.68batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38117/40960 [03:07<00:14, 201.59batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38117/40960 [03:07<00:14, 201.59batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38159/40960 [03:07<00:13, 203.78batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38159/40960 [03:07<00:13, 203.78batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  93%|▉| 38202/40960 [03:07<00:13, 205.36batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  93%|▉| 38202/40960 [03:07<00:13, 205.36batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38234/40960 [03:07<00:14, 191.01batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38234/40960 [03:07<00:14, 191.01batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38276/40960 [03:08<00:13, 195.27batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  93%|▉| 38276/40960 [03:08<00:13, 195.27batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38319/40960 [03:08<00:13, 200.09batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38319/40960 [03:08<00:13, 200.09batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  94%|▉| 38360/40960 [03:08<00:12, 201.47batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  94%|▉| 38360/40960 [03:08<00:12, 201.47batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  94%|▉| 38404/40960 [03:08<00:12, 206.92batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  94%|▉| 38404/40960 [03:08<00:12, 206.92batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38451/40960 [03:08<00:11, 214.69batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38451/40960 [03:08<00:11, 214.69batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38493/40960 [03:09<00:11, 212.14batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38493/40960 [03:09<00:11, 212.14batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38537/40960 [03:09<00:11, 214.12batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38537/40960 [03:09<00:11, 214.12batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38580/40960 [03:09<00:11, 213.89batches/s, l2_loss: 0.0918 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|▉| 38580/40960 [03:09<00:11, 213.89batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38628/40960 [03:09<00:10, 221.11batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38628/40960 [03:09<00:10, 221.11batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38665/40960 [03:09<00:10, 209.77batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  94%|▉| 38665/40960 [03:09<00:10, 209.77batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38708/40960 [03:10<00:10, 210.74batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38708/40960 [03:10<00:10, 210.74batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38751/40960 [03:10<00:10, 211.38batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38751/40960 [03:10<00:10, 211.38batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38792/40960 [03:10<00:10, 209.20batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38792/40960 [03:10<00:10, 209.20batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  95%|▉| 38838/40960 [03:10<00:09, 215.32batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  95%|▉| 38838/40960 [03:10<00:09, 215.32batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  95%|▉| 38879/40960 [03:10<00:09, 211.12batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  95%|▉| 38879/40960 [03:10<00:09, 211.12batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38916/40960 [03:11<00:10, 203.12batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38916/40960 [03:11<00:10, 203.12batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  95%|▉| 38951/40960 [03:11<00:10, 194.65batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  95%|▉| 38951/40960 [03:11<00:10, 194.65batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38987/40960 [03:11<00:10, 188.92batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 38987/40960 [03:11<00:10, 188.92batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 39034/40960 [03:11<00:09, 202.00batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 39034/40960 [03:11<00:09, 202.00batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 39076/40960 [03:11<00:09, 202.95batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 39076/40960 [03:11<00:09, 202.95batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 39111/40960 [03:12<00:09, 194.49batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  95%|▉| 39111/40960 [03:12<00:09, 194.49batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39148/40960 [03:12<00:09, 191.44batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39148/40960 [03:12<00:09, 191.44batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39192/40960 [03:12<00:08, 199.24batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39192/40960 [03:12<00:08, 199.24batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  96%|▉| 39238/40960 [03:12<00:08, 207.11batches/s, l2_loss: 0.0919 - round_los\u001b[A\n",
      "Training:  96%|▉| 39238/40960 [03:12<00:08, 207.11batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39282/40960 [03:12<00:07, 210.60batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39282/40960 [03:12<00:07, 210.60batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39319/40960 [03:13<00:08, 202.34batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39319/40960 [03:13<00:08, 202.34batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39360/40960 [03:13<00:07, 202.83batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39360/40960 [03:13<00:07, 202.83batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39400/40960 [03:13<00:07, 201.16batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39400/40960 [03:13<00:07, 201.16batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  96%|▉| 39435/40960 [03:13<00:07, 192.90batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  96%|▉| 39435/40960 [03:13<00:07, 192.90batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39472/40960 [03:13<00:07, 189.33batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39472/40960 [03:13<00:07, 189.33batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39516/40960 [03:14<00:07, 197.45batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  96%|▉| 39516/40960 [03:14<00:07, 197.45batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39553/40960 [03:14<00:07, 190.78batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39553/40960 [03:14<00:07, 190.78batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39593/40960 [03:14<00:07, 192.06batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39593/40960 [03:14<00:07, 192.06batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39632/40960 [03:14<00:06, 191.53batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39632/40960 [03:14<00:06, 191.53batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39675/40960 [03:14<00:06, 196.95batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39675/40960 [03:14<00:06, 196.95batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39721/40960 [03:15<00:06, 206.34batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39721/40960 [03:15<00:06, 206.34batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  97%|▉| 39766/40960 [03:15<00:05, 211.54batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  97%|▉| 39766/40960 [03:15<00:05, 211.54batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  97%|▉| 39796/40960 [03:15<00:06, 192.34batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  97%|▉| 39796/40960 [03:15<00:06, 192.34batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  97%|▉| 39843/40960 [03:15<00:05, 204.88batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  97%|▉| 39843/40960 [03:15<00:05, 204.88batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39888/40960 [03:15<00:05, 210.09batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39888/40960 [03:15<00:05, 210.09batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39935/40960 [03:16<00:04, 217.27batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  97%|▉| 39935/40960 [03:16<00:04, 217.27batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 39976/40960 [03:16<00:04, 211.81batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 39976/40960 [03:16<00:04, 211.81batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40011/40960 [03:16<00:04, 200.03batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40011/40960 [03:16<00:04, 200.03batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40053/40960 [03:16<00:04, 202.41batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40053/40960 [03:16<00:04, 202.41batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40097/40960 [03:16<00:04, 206.23batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40097/40960 [03:16<00:04, 206.23batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  98%|▉| 40141/40960 [03:17<00:03, 209.56batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  98%|▉| 40141/40960 [03:17<00:03, 209.56batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  98%|▉| 40185/40960 [03:17<00:03, 211.19batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  98%|▉| 40185/40960 [03:17<00:03, 211.19batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40230/40960 [03:17<00:03, 214.53batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40230/40960 [03:17<00:03, 214.53batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  98%|▉| 40273/40960 [03:17<00:03, 213.51batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  98%|▉| 40273/40960 [03:17<00:03, 213.51batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40317/40960 [03:17<00:02, 215.11batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  98%|▉| 40317/40960 [03:17<00:02, 215.11batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40358/40960 [03:18<00:02, 211.16batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40358/40960 [03:18<00:02, 211.16batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40403/40960 [03:18<00:02, 214.49batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40403/40960 [03:18<00:02, 214.49batches/s, l2_loss: 0.0918 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|▉| 40448/40960 [03:18<00:02, 216.41batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40448/40960 [03:18<00:02, 216.41batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40493/40960 [03:18<00:02, 218.30batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40493/40960 [03:18<00:02, 218.30batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40538/40960 [03:18<00:01, 219.02batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40538/40960 [03:18<00:01, 219.02batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40581/40960 [03:19<00:01, 217.07batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40581/40960 [03:19<00:01, 217.07batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40622/40960 [03:19<00:01, 213.13batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40622/40960 [03:19<00:01, 213.13batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40665/40960 [03:19<00:01, 212.81batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40665/40960 [03:19<00:01, 212.81batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40708/40960 [03:19<00:01, 211.88batches/s, l2_loss: 0.0918 - round_los\u001b[A\n",
      "Training:  99%|▉| 40708/40960 [03:19<00:01, 211.88batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40748/40960 [03:19<00:01, 207.50batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training:  99%|▉| 40748/40960 [03:19<00:01, 207.50batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training: 100%|▉| 40792/40960 [03:20<00:00, 209.74batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training: 100%|▉| 40792/40960 [03:20<00:00, 209.74batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training: 100%|▉| 40835/40960 [03:20<00:00, 210.96batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training: 100%|▉| 40835/40960 [03:20<00:00, 210.96batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training: 100%|▉| 40880/40960 [03:20<00:00, 214.01batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training: 100%|▉| 40880/40960 [03:20<00:00, 214.01batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training: 100%|▉| 40921/40960 [03:20<00:00, 211.18batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "Training: 100%|▉| 40921/40960 [03:20<00:00, 211.18batches/s, l2_loss: 0.0917 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-06-09 15:41:41.043934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  96%|▉| 25/26 [54:04<02:27, 147.94s/blocks, Layers=['model_ResBaGAN_discrimina2025-06-09 15:41:45.748517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 15:41:54.834487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround: 100%|█| 26/26 [54:20<00:00, 125.42s/blocks, Layers=['model_ResBaGAN_discrimina\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Adaround is done (completion time is 00:54:22.27)\n",
      "[info] Quantization-Aware Fine-Tuning skipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 15:42:08.536269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:08.546427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:08.546680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:08.549295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:08.549601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:08.549861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:10.725133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:10.725391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:10.725604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:10.725763: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-09 15:42:10.726015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-09 15:42:11.417680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:11.419359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:11.419584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:11.421596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:11.421799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:11.421996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:12.754043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:12.754301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:12.754498: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-09 15:42:12.754658: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-09 15:42:12.754682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Starting Layer Noise Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Quant Analysis:  50%|████████████            | 1/2 [00:00<00:00,  2.25iterations/s]2025-06-09 15:42:17.043631: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 15:42:17.078851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-09 15:42:59.912511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "Full Quant Analysis: 100%|████████████████████████| 2/2 [00:45<00:00, 22.50s/iterations]\n",
      "2025-06-09 15:43:01.528813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-06-09 15:43:01.552643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Layer Noise Analysis is done (completion time is 00:00:46.21)\n",
      "[info] Output layers signal-to-noise ratio (SNR): measures the quantization noise (higher is better)\n",
      "[info] \tmodel_ResBaGAN_discriminator/output_layer2 SNR:\t31.68 dB\n",
      "[info] \tmodel_ResBaGAN_discriminator/output_layer1 SNR:\t28.12 dB\n",
      "[info] Model Optimization is done\n"
     ]
    }
   ],
   "source": [
    "# Cuantizar el modelo con el dataset de calibración\n",
    "\n",
    "# For calling Optimize, use the short version: runner.optimize(calib_dataset)\n",
    "# A more general approach is being used here that works also with multiple input nodes.\n",
    "# The calibration dataset could also be a dictionary with the format:\n",
    "# {input_layer_name_1_from_hn: layer_1_calib_dataset, input_layer_name_2_from_hn: layer_2_calib_dataset}\n",
    "hn_layers = runner.get_hn_dict()[\"layers\"]\n",
    "print(\"Input layers are: \")\n",
    "print([layer for layer in hn_layers if hn_layers[layer][\"type\"] == \"input_layer\"])  # See available input layer names\n",
    "calib_dataset_dict = {\"model_ResBaGAN_discriminator/input_layer1\": calib_dataset}  # In our case there is only one input layer\n",
    "\n",
    "optimization_level = 4\n",
    "compression_level = 3\n",
    "# Mapeamos las proporciones de pesos de 4 bits según el nivel de compresión\n",
    "compression_ratios = {\n",
    "    0: 0.0,\n",
    "    1: 0.2,\n",
    "    2: 0.4,\n",
    "    3: 0.6,\n",
    "    4: 0.8,\n",
    "    5: 1.0\n",
    "}\n",
    "auto_4bit_ratio = compression_ratios.get(compression_level, 0.0)\n",
    "\n",
    "alls_lines = [\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # Batch size is 8 by default; 2 was used for stability on PCs with low amount of RAM / VRAM\n",
    "    f\"model_optimization_flavor(optimization_level={optimization_level}, compression_level={compression_level}, batch_size=8)\\n\",\n",
    "    # The following line is needed because this is a really small model, and the compression_level is always reverted back to 0.'\n",
    "    # To force using compression_level with small models, the following line should be used (compression level=4 equals to 80% 4-bit):\n",
    "    f\"model_optimization_config(compression_params, auto_4bit_weights_ratio={auto_4bit_ratio})\\n\",\n",
    "    # The application of the compression could be seen by the [info] messages: \"Assigning 4bit weight to layer ..\"\n",
    "]\n",
    "\n",
    "runner.load_model_script(\"\".join(alls_lines))\n",
    "\n",
    "runner.optimize(calib_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb54f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:44:24.242692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:24.246501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:24.246726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:24.248904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:24.249135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:24.249331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:25.640758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:25.641012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:25.641223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-08 19:44:25.641375: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-06-08 19:44:25.641400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-06-08 19:44:25.785304: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:27.713293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-08 19:44:42.804050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2025-06-08 19:44:43.622835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Inference: 104entries [00:16,  6.37entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.2400 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:44.147325: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:44.270540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 547.25entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.3600 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:44.602740: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:44.726498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 562.86entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.3400 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:45.037570: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:45.162839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 597.57entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.4600 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:45.471736: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:45.592760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 591.36entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.1800 ; Coincidencias: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:45.904919: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:46.026655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 587.82entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.4000 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:46.348612: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:46.476751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 595.94entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.3000 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:46.807744: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:46.937103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 554.29entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.4100 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:47.260073: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:47.382029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 553.90entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.3500 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:47.703355: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:47.829395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 550.67entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.2700 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:48.182734: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:48.320700: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 538.26entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.3300 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:48.671458: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:48.799018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 562.57entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.3200 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:49.121846: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:49.244814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 609.69entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.5400 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:49.552483: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:49.680103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 636.86entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.4800 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:49.982825: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:50.104075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 580.02entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.3600 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:50.411126: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:50.532788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 600.64entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.2900 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:50.853360: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:50.994767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 554.32entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.2100 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:51.313970: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:51.456760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 565.04entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.2600 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:51.792741: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:51.930116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 492.40entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.2600 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:52.262334: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:52.388205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 530.82entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.5500 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:52.727105: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:52.849861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 422.68entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.3300 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:44:53.233553: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:53.360343: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 551.97entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.2700 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:53.713153: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:53.838261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 542.15entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.5600 ; Coincidencias: 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:54.165783: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:54.292173: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 588.74entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.4500 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:54.602763: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:54.732871: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 565.91entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.3800 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:55.047912: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:55.175645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 565.91entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.3500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:55.514369: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:55.643244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 581.98entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.2200 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:55.973550: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:56.096682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 598.21entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.3400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:56.402299: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:56.524003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 358.45entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:44:56.937152: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:57.081771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 395.81entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.1700 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:44:57.480414: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:57.601932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 514.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.2800 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:44:57.939598: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:58.060950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 592.92entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.4100 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:58.374011: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:58.503711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 561.00entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.3000 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:58.837846: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:58.965106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 564.59entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:59.293121: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:59.421408: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 582.79entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.2800 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:44:59.745390: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:44:59.882812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 528.40entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.3600 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:00.210644: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:00.331777: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 571.69entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.4000 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:00.634405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:00.758034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 501.91entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.2700 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:01.107142: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:01.229032: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 450.79entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.3100 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:01.593136: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:01.715310: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 497.53entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.2500 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:02.069665: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:02.191601: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 585.48entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.3100 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:02.500561: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:02.630728: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 562.92entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.2500 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:02.968995: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:03.098154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 546.35entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.3300 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:03.443057: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:03.572107: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 593.89entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.6100 ; Coincidencias: 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:03.879698: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:04.012842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 568.74entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:04.363215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:04.491453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 567.89entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.3200 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:04.835100: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:04.963073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 564.52entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.6000 ; Coincidencias: 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:05.298099: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:05.428357: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 546.37entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.2300 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:05.753697: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:05.882048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 597.45entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:06.198914: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:06.327330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 595.04entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.3900 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:06.655077: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:06.782849: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 577.11entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.3700 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:07.113277: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:07.252759: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 516.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.2500 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:45:07.597867: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:07.725338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 566.14entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.4400 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:08.052095: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:08.180337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 571.54entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.3900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:08.526957: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:08.655650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 607.06entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.3800 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:08.974653: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:09.102827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 588.52entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.3300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:09.417299: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:09.548198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 596.04entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.4600 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:09.858938: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:09.984338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 574.66entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.3300 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:10.302930: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:10.428199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 583.59entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.3400 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:10.739776: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:10.868043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 536.77entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.4500 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:11.197428: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:11.326430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 595.55entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.3600 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:11.652848: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:11.778305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 588.81entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.3300 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:12.091578: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:12.212212: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 409.13entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.3700 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:12.593503: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:12.713777: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 585.53entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.4300 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:13.031088: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:13.167647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 565.51entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.4400 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:13.491220: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:13.615401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 399.55entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.4100 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:45:14.032686: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:14.155565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 532.00entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.2800 ; Coincidencias: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:14.509632: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:14.632831: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 552.15entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.3500 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:14.949115: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:15.071204: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 607.07entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.3900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:15.378779: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:15.501274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 498.72entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.2800 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:15.845787: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:15.968580: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 479.18entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.4800 ; Coincidencias: 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:16.318435: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:16.439605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 616.32entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:16.758085: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:16.880562: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 441.65entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.2700 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:17.256901: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:17.378120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 618.85entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.2100 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:17.684770: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:17.805468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 475.74entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.3500 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:18.163222: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:18.294921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 613.77entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.1600 ; Coincidencias: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:18.613622: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:18.752847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 563.37entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.4000 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:19.084708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:19.210391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 551.88entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.2400 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:19.549141: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:19.677106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 592.98entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.4100 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:19.991438: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:20.113334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 518.99entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.2400 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:45:20.446850: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:20.569174: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 397.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.2800 ; Coincidencias: 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:45:20.968156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:21.101403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 580.63entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.5400 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:21.412250: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:21.535812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 580.42entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.3500 ; Coincidencias: 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:21.847139: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:21.969294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 587.75entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.4900 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:22.301847: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:22.443935: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 582.28entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.5100 ; Coincidencias: 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:22.765465: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:22.889114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 610.24entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.3600 ; Coincidencias: 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:23.201100: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:23.329027: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 586.37entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.2400 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:23.645661: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:23.768607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 617.72entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.3000 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:24.075187: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:24.197112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 508.34entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.2900 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:45:24.563397: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:24.694636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 592.02entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.2400 ; Coincidencias: 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:25.007311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:25.129665: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 530.58entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.4000 ; Coincidencias: 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:25.460514: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:25.587708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 592.23entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.4800 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:25.919817: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:26.060071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 514.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.3800 ; Coincidencias: 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:45:26.413005: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:26.538282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 561.42entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.4400 ; Coincidencias: 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:26.861256: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:26.981816: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 513.88entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.2800 ; Coincidencias: 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:45:27.323009: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:27.442728: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 404.56entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.3100 ; Coincidencias: 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 19:45:27.860222: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:27.990008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 575.85entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.4300 ; Coincidencias: 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:28.324725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:28.454766: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 563.54entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.3200 ; Coincidencias: 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:28.778447: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:28.901151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 496.97entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.3800 ; Coincidencias: 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-06-08 19:45:29.250404: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-06-08 19:45:29.377251: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 560.53entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.2800 ; Coincidencias: 83/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.348400\n",
      "Precisión global: 81.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR cuantizado\n",
    "\n",
    "# Modo evaluación\n",
    "dataset.to_test()\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    (inputs, labels, targets_pixel_level) = next(data_iter)\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    outputs_discriminator = outputs[0]\n",
    "    outputs_discriminator[:, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "    preds_onnx=np.argmax(outputs_discriminator, axis=1)\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_QUANTIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)[0]\n",
    "        native_res[:, 0, 0, dataset.classes_count] = -math.inf # Se deshabilita la clase fake para test\n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61eebb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Saved HAR to: /home/pablo/Documentos/Enxeñaría Informática/Cuarto/2º Cuatrimestre/Traballo Fin de Grao/hyper-rpi/results/models/model_ResBaGAN_discriminator_quantized_model_o4_c3.har\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo cuantizado\n",
    "# Let's save the runner's state to a Quantized HAR\n",
    "quantized_model_har_path = f\"{model_name}_quantized_model_o{optimization_level}_c{compression_level}.har\"\n",
    "runner.save_har(quantized_model_har_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24260b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b9b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dcee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hailo_gpu_env] *",
   "language": "python",
   "name": "conda-env-hailo_gpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
