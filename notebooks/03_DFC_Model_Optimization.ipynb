{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b76dd13",
   "metadata": {},
   "source": [
    "# Fase 03: Optimización del modelo en HAR (Hailo Archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f181ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:58:19.462737: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-20 18:58:20.055727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/pablo/anaconda3/envs/hailo_gpu_env/lib/python3.8/site-packages/nvidia/dali/backend.py:77: Warning: DALI 1.49 is the last release to support Python 3.8 Please update your environment to use Python 3.9, or newer.\n",
      "  deprecation_warning(\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from matplotlib import patches\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.python.eager.context import eager_mode\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from itertools import islice\n",
    "\n",
    "# Funciones y parámetros de la CNN base\n",
    "import sys\n",
    "sys.path.append('../src/models/')\n",
    "from cnn21_pix import *\n",
    "\n",
    "# import the hailo sdk client relevant classes\n",
    "from hailo_sdk_client import ClientRunner, InferenceContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d16a4d",
   "metadata": {},
   "source": [
    "## 1. Optimización detallada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f860d1c",
   "metadata": {},
   "source": [
    "### 1.1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a555f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros\n",
    "\n",
    "DATASET='../data/imagenes_rios/oitaven_river.raw'\n",
    "GT='../data/imagenes_rios/oitaven_river.pgm'\n",
    "\n",
    "# Queremos usar todos los datos para la inferencia\n",
    "SAMPLES=[0,0]\n",
    "PAD=1\n",
    "AUM=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0231fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Read dataset: ../data/imagenes_rios/oitaven_river.raw\n",
      "  B: 5 H: 6722 V: 6689\n",
      "  Read: 224817290\n",
      "* Read GT: ../data/imagenes_rios/oitaven_river.pgm\n",
      "  H: 6722 V: 6689 depth: 10\n",
      "  Read: 44963458\n",
      "* Select training samples\n",
      "  nclasses: 10\n",
      "  Class  # :   total | train |   val |    test\n",
      "  Class  1 :  309248 |     0 |     0 |  309248\n",
      "  Class  2 :  113324 |     0 |     0 |  113324\n",
      "  Class  3 :   79152 |     0 |     0 |   79152\n",
      "  Class  4 :   43861 |     0 |     0 |   43861\n",
      "  Class  5 :  128022 |     0 |     0 |  128022\n",
      "  Class  6 :   78785 |     0 |     0 |   78785\n",
      "  Class  7 : 2428482 |     0 |     0 | 2428482\n",
      "  Class  8 : 1829360 |     0 |     0 | 1829360\n",
      "  Class  9 :  193884 |     0 |     0 |  193884\n",
      "  Class 10 :  863061 |     0 |     0 |  863061\n",
      "  - test dataset: 6067179\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "\n",
    "(datos,H,V,B)=read_raw(DATASET)\n",
    "(truth,H1,V1)=read_pgm(GT)\n",
    "\n",
    "# Durante la ejecucion de la red vamos a coger patches de tamano cuadrado\n",
    "sizex=32; sizey=32 \n",
    "\n",
    "# Hacemos padding en el dataset para poder aprovechar hasta el borde\n",
    "if(PAD):\n",
    "    datos=torch.FloatTensor(np.pad(datos,((sizey//2,sizey//2),(sizex//2,sizex//2),(0,0)),'symmetric'))\n",
    "    H=H+2*(sizex//2); V=V+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(-1,H1))\n",
    "    truth=np.pad(truth,((sizey//2,sizey//2),(sizex//2,sizex//2)),'constant')\n",
    "    H1=H1+2*(sizex//2); V1=V1+2*(sizey//2)\n",
    "    truth=np.reshape(truth,(H1*V1))\n",
    "    \n",
    "# Necesitamos los datos en band-vector para hacer convoluciones\n",
    "datos=np.transpose(datos,(2,0,1))\n",
    "\n",
    "# Seleccionar conjunto de test (en este caso es una predicción)\n",
    "(train,val,test,nclases,nclases_no_vacias)=select_training_samples(truth,H,V,sizex,sizey,SAMPLES)\n",
    "dataset_test=HyperDataset(datos,truth,test,H,V,sizex,sizey)\n",
    "print('  - test dataset:',len(dataset_test))\n",
    "\n",
    "# Dataloader\n",
    "batch_size=100 # defecto 100\n",
    "# Indicamos shuffle = True porque no se evalúa todo el dataset\n",
    "test_loader=DataLoader(dataset_test,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf81525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo convertido a ONNX\n",
    "\n",
    "ort_session = ort.InferenceSession(\"../results/model_cnn21.onnx\")\n",
    "\n",
    "# Cargar el modelo en HAR\n",
    "\n",
    "model_name = \"../results/model_cnn21\"\n",
    "hailo_model_har_name = f\"{model_name}_hailo_model.har\"\n",
    "assert os.path.isfile(hailo_model_har_name), \"Please provide valid path for HAR file\"\n",
    "runner = ClientRunner(har=hailo_model_har_name, hw_arch=\"hailo8l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0ecb0",
   "metadata": {},
   "source": [
    "### 1.2 Evaluar el modelo en har sin optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07a259b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 13:48:41.842469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:41.848134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:41.848337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:41.855864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:41.856080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:41.856270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:43.913769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:43.914331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:43.914528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-19 13:48:43.914882: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-19 13:48:43.914907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 13:48:44.045210: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-19 13:48:44.344213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-19 13:48:48.440281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2025-05-19 13:48:49.472938: W tensorflow/core/kernels/gpu_utils.cc:70] Failed to check cudnn convolutions for out-of-bounds reads and writes with an error message: 'Failed to load in-memory CUBIN: CUDA_ERROR_INVALID_IMAGE: device kernel image is invalid'; skipping this check. This only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2025-05-19 13:48:49.543973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Inference: 8entries [00:05,  1.51entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error medio entre PyTorch y ONNX: 4.57763690064894e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Comprobacion rapida de la diferencia de precisión\n",
    "\n",
    "# Crear tensor de entrada de prueba\n",
    "input_tensor = torch.randn(1, B, sizex, sizey).to(\"cpu\")\n",
    "input_np = input_tensor.cpu().numpy()\n",
    "\n",
    "# Realizar la inferencia en ONNX\n",
    "output_onnx = ort_session.run(None, {'input': input_np})[0]\n",
    "\n",
    "# print(output_onnx)\n",
    "\n",
    "# Realizar la inferencia en HAR\n",
    "with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "    input_har = np.transpose(input_np, (0, 2, 3, 1))\n",
    "\n",
    "    # Realizar la inferencia en el modelo .har\n",
    "    output_har = runner.infer(ctx, input_har)\n",
    "\n",
    "    # print(output_har) \n",
    "\n",
    "# Comparar las diferencias\n",
    "error = np.abs(output_onnx - output_har).mean()\n",
    "print(f'Error medio entre PyTorch y ONNX: {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062ef5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# El bucle de inferencia tiene un memory leak que proviene del SDK de hailo con el emulador NATIVE\\n# Se realiza la evaluacion, por tanto, con un unico batch\\n\\n# Inferencia\\n\\noutput=np.zeros(H*V,dtype=np.uint8)\\n\\n# Medir el tiempo de ejecución\\nstart_time = time.time()\\n\\n# Realizar la predicción\\nwith runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\\n    total=0\\n    for (inputs, labels) in test_loader:\\n        # Convertir inputs a un formato adecuado para Hailo (numpy array)\\n        # Cambiamos de (batch_size, B, sizex, sizey) a (batch_size, sizey, sizex, B)\\n        inputs_np = np.transpose(inputs.numpy(), (0, 3, 2, 1))\\n\\n        # Realizar la inferencia en el modelo .har\\n        native_res = runner.infer(ctx, inputs_np)\\n        \\n        predicted=np.argmax(native_res, axis=-1)\\n        predicted=predicted.squeeze()\\n        \\n        # Asignar las predicciones al array de salida\\n        for i in range(len(predicted)):\\n            output[test[total+i]]=np.uint8(predicted[i]+1)\\n        total+=labels.size(0)\\n\\n        # Mostrar el progreso\\n        if(total%100000==0): print(\\'  Test:\\',total,\\'/\\',len(dataset_test))\\n        \\nend_time = time.time()\\n\\nprint(\"Prediction time: {:.4f} seconds\".format(end_time - start_time))\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# El bucle de inferencia tiene un memory leak que proviene del SDK de hailo con el emulador NATIVE\n",
    "# Se realiza la evaluacion, por tanto, con un unico batch\n",
    "\n",
    "# Inferencia\n",
    "\n",
    "output=np.zeros(H*V,dtype=np.uint8)\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "start_time = time.time()\n",
    "\n",
    "# Realizar la predicción\n",
    "with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "    total=0\n",
    "    for (inputs, labels) in test_loader:\n",
    "        # Convertir inputs a un formato adecuado para Hailo (numpy array)\n",
    "        # Cambiamos de (batch_size, B, sizex, sizey) a (batch_size, sizey, sizex, B)\n",
    "        inputs_np = np.transpose(inputs.numpy(), (0, 3, 2, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_np)\n",
    "        \n",
    "        predicted=np.argmax(native_res, axis=-1)\n",
    "        predicted=predicted.squeeze()\n",
    "        \n",
    "        # Asignar las predicciones al array de salida\n",
    "        for i in range(len(predicted)):\n",
    "            output[test[total+i]]=np.uint8(predicted[i]+1)\n",
    "        total+=labels.size(0)\n",
    "\n",
    "        # Mostrar el progreso\n",
    "        if(total%100000==0): print('  Test:',total,'/',len(dataset_test))\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Prediction time: {:.4f} seconds\".format(end_time - start_time))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16be5c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:18.366492: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1540.91entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:18.861796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2050.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:19.306366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2172.28entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:19.734777: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2241.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:20.203461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1961.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:20.673310: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2009.24entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:21.163250: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1806.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:21.663459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2201.73entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:22.102058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1877.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:22.561687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2217.56entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:22.994986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2291.49entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:23.456894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2162.48entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:23.890403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2111.41entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:24.332829: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2233.19entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:24.778659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1976.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:25.254084: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2203.49entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:25.708939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1890.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:26.179791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2216.58entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:26.607181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2243.34entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:27.035761: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2292.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:27.489646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1954.69entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:27.953259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2003.75entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:28.443660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2210.76entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:28.875408: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2075.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:29.315626: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2244.97entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:29.749180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2305.14entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:30.238549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1671.07entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:30.743543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2315.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:31.181710: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2227.34entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:31.613873: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2026.49entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:32.080162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2193.24entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:32.516141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2316.50entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:32.944831: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2197.83entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:33.373717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2284.44entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:33.805940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2290.42entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:34.235893: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2315.73entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:34.663412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2274.63entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:35.092585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2301.22entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:35.536605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2244.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:35.966072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2321.83entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:36.406332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2218.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:36.836325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2288.75entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:37.265514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2248.67entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:37.699519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2293.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:38.131782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2230.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:38.560814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2312.80entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:38.991739: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2141.91entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:39.425870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2320.73entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:39.854514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2333.02entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:40.285083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2335.05entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:40.715281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2347.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:41.145344: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2319.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:41.581078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2205.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:42.015150: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2242.51entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:42.447066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2285.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:42.885433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2302.45entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:43.317114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2249.46entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:43.751581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2273.25entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:44.181786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2340.19entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:44.613749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2322.95entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:45.043628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2246.18entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:45.478113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2307.54entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:45.907438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2253.24entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:46.342339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2313.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:46.776971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2238.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:47.207403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2237.41entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:47.638476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2112.69entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:48.187161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2321.69entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:48.679650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1919.79entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:49.163059: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2151.31entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:49.608113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2210.69entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:50.087832: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1818.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:50.591050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1971.84entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:51.098107: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2081.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:51.583801: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2055.13entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:52.046583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2334.82entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:52.521833: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1859.97entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:53.056134: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2231.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:53.492865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2140.99entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:53.968379: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1808.77entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:54.436656: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2118.36entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:54.879919: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2064.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:55.355578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2206.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:55.842361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1787.63entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:56.342973: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2148.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:56.814901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2142.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:57.338515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1875.07entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:57.838386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2214.93entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:58.307210: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2166.80entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:58.757876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1856.49entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:59.236307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2190.36entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:17:59.678417: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2315.74entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:00.125669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1940.77entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:00.594445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2058.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:01.132237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2218.05entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:01.578406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2331.64entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:02.024708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2312.74entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:02.459459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2298.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:02.892880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2248.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:03.326304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2316.19entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.0000 ; Coincidencias: 100/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.000000\n",
      "Precisión global: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR sin optimizacion\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    preds_onnx=np.argmax(outputs[0], axis=1) # outputs[0] contiene las predicciones\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_NATIVE) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)\n",
    "        \n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e9139",
   "metadata": {},
   "source": [
    "### 1.3 Aplicar modificaciones de optimización al modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ac30ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warning] Model script is empty\n",
      "[info] Loading model script commands to model_cnn21 from string\n",
      "[warning] Model script is empty\n",
      "[warning] DEPRECATION WARNING: Optimizing in full precision will require calibration data in the near future, to allow more accurate optimization algorithms which require inference on actual data.\n"
     ]
    }
   ],
   "source": [
    "# Crear un model script para el proceso de optimización\n",
    "\n",
    "model_script_lines = [\n",
    "    # Add normalization layer with mean [123.675, 116.28, 103.53] and std [58.395, 57.12, 57.375])\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # For multiple input nodes:\n",
    "    # {normalization_layer_name_1} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_1_from_hn})\\n',\n",
    "    # {normalization_layer_name_2} = normalization([list of means per channel], [list of stds per channel], {input_layer_name_2_from_hn})\\n',\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Load the model script to ClientRunner so it will be considered on optimization\n",
    "runner.load_model_script(\"\".join(model_script_lines))\n",
    "runner.optimize_full_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d6a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:34.587670: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 270.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:35.459731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2039.36entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:35.912833: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2168.35entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:36.365088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2165.57entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:36.802975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2174.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:37.243461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2245.65entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:37.695271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1980.23entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:38.151572: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2230.52entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:38.591923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2269.59entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:39.032660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2268.61entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:39.472558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2349.18entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:39.909241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2254.37entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:40.349809: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2261.74entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:40.787277: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2295.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:41.224550: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1964.22entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:41.705385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2283.30entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:42.140544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2335.07entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:42.598742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1994.53entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:43.052765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2263.77entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:43.491624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2250.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:43.928872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2124.78entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:44.368313: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2271.06entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:44.805607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2290.59entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:45.243353: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2292.64entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:45.686045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2275.13entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:46.124538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2293.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:46.560900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2342.12entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:46.997987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2276.11entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:47.438230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2306.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:47.874872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2337.04entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:48.316970: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2276.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:48.758858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2260.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:49.198476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2243.72entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:49.638326: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2246.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:50.076297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2313.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:50.517986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2187.03entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:50.961263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2272.33entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:51.403436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2268.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:51.845548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2245.02entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:52.282388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2318.56entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:52.719217: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2274.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:53.159181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2281.34entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:53.605375: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2276.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:54.042229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2254.16entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:54.482080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2296.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:54.919954: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2278.19entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:55.360000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2285.80entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:55.796826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2307.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:56.233291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2291.96entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:56.670775: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2285.99entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:57.111442: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2349.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:57.551663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2319.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:57.996878: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2271.12entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:58.436304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2309.69entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:58.882503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2204.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:59.327569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2233.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:18:59.772227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2288.61entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:00.211824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2260.69entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:00.660303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2108.33entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:01.132782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2200.91entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:01.590216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1818.27entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:02.082526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2256.76entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:02.535993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2269.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:03.044643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1936.86entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:03.533016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2263.77entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:03.976569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2341.90entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:04.429609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1938.16entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:04.959226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1763.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:05.480113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2215.97entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:05.935805: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1807.11entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:06.408642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2163.95entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:06.872309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2326.52entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:07.322363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2249.61entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:07.765387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2211.73entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:08.218511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2128.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:08.666460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2196.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:09.105944: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2222.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:09.560294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2296.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:10.006582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2189.17entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:10.450101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2191.03entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:10.934458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1807.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:11.396396: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2307.85entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:11.874021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2321.95entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:12.313575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2297.34entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:12.793039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2182.63entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:13.267066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2233.33entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:13.709271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2233.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:14.164820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2100.05entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:14.631566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2271.76entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:15.079717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2315.63entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:15.531373: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2038.26entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:16.000124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2242.32entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:16.475317: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2239.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:16.941787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2227.49entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:17.406436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2300.89entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:17.856653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1927.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:18.356201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2285.40entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:18.807067: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2297.67entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:19.253537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2241.04entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 0entries [00:00, ?entries/s]2025-04-18 03:19:19.710452: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2302.29entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.0000 ; Coincidencias: 100/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.000000\n",
      "Precisión global: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR con optimizacion\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    preds_onnx=np.argmax(outputs[0], axis=1) # outputs[0] contiene las predicciones\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_FP_OPTIMIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)\n",
    "        \n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce0f2c",
   "metadata": {},
   "source": [
    "### 1.4 Cuantizar el modelo y evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8005d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataset de calibración\n",
    "# The original images are being used, just as the input to the SDK_FP_OPTIMIZED emulator\n",
    "total_images = 1050\n",
    "\n",
    "calib_dataset = np.zeros((total_images, sizex, sizey, B), dtype = np.float32)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Seleccionamos batches del dataloader para guardarlos en el dataset\n",
    "for inputs, _ in test_loader:\n",
    "    for img in inputs:\n",
    "        if count >= total_images:\n",
    "            break\n",
    "            \n",
    "        # Los inputs son de la forma (batch_size, B, sizex, sizey)\n",
    "        img_np = img.numpy()\n",
    "        # Trasponemos los inputs a formato (batch_size, sizex, sizey, B)\n",
    "        img_har = np.transpose(img_np, (1, 2, 0))\n",
    "\n",
    "        calib_dataset[count] = img_har\n",
    "        count += 1\n",
    "        \n",
    "    if count >= total_images:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4166000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layers are: \n",
      "['model_cnn21/input_layer1']\n",
      "[info] Loading model script commands to model_cnn21 from string\n",
      "[info] Starting Model Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:59:10.734463: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:10.736107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:10.736314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:10.737440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:10.737635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:10.737820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.291338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.291593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.291783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.291925: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 18:59:12.291951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-05-20 18:59:12.497105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.499625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.499847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.501349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.501562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:12.501783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:13.977214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:13.977465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:13.977659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:13.977806: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 18:59:13.977867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warning] Reducing compression ratio to 0 because the number of parameters in the network is not large enough (0M and need at least 20M). Can be enforced using model_optimization_config(compression_params, auto_4bit_weights_ratio=1.000)\n",
      "[info] Model received quantization params from the hn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:59:14.395871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:14.397583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:14.397792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:14.399085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:14.399292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:14.399474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:15.855354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:15.855624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:15.855846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:15.856005: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 18:59:15.856032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-05-20 18:59:16.050165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:16.051734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:16.051939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:16.053068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:16.053278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:16.053466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:17.613398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:17.613724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:17.613929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:17.614082: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 18:59:17.614120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] MatmulDecompose skipped\n",
      "[info] Starting Mixed Precision\n",
      "[info] Assigning 4bit weights to layer model_cnn21/conv2 with 12.80k parameters\n",
      "[info] Ratio of weights in 4bit is 0.38\n",
      "[info] Model Optimization Algorithm Mixed Precision is done (completion time is 00:00:00.02)\n",
      "[info] LayerNorm Decomposition skipped\n",
      "[info] Starting Statistics Collector\n",
      "[info] Using dataset with 64 entries for calibration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration:   0%|                                          | 0/64 [00:00<?, ?entries/s]2025-05-20 18:59:19.048487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:19.068064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:22.134650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "Calibration: 100%|█████████████████████████████████| 64/64 [00:04<00:00, 13.83entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Statistics Collector is done (completion time is 00:00:04.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:59:23.402878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-05-20 18:59:23.416215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:23.425725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:23.432021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:23.438068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:23.444136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:23.450388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:23.457049: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Starting Fix zp_comp Encoding\n",
      "[info] Model Optimization Algorithm Fix zp_comp Encoding is done (completion time is 00:00:00.00)\n",
      "[info] Matmul Equalization skipped\n",
      "[info] Starting MatmulDecomposeFix\n",
      "[info] Model Optimization Algorithm MatmulDecomposeFix is done (completion time is 00:00:00.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:59:24.839678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:24.843957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:24.844207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:24.846021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:24.846229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:24.846450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:26.912447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:26.912734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:26.912960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:26.913127: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 18:59:26.913155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-05-20 18:59:27.297657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:27.299243: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:27.299495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:27.300751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:27.300971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:27.301233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:28.808916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:28.809170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:28.809382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 18:59:28.809532: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 18:59:28.809556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Finetune encoding skipped\n",
      "[info] Bias Correction skipped\n",
      "[warning] Dataset is larger than dataset_size in Adaround. Increasing the algorithm dataset size might improve the results\n",
      "[info] Starting Adaround\n",
      "[info] The algorithm Adaround will use up to 0.17 GB of storage space\n",
      "[info] Using dataset with 1024 entries for Adaround\n",
      "[info] Using dataset with 64 entries for bias correction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:59:30.093573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:30.093750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:30.641988: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:30.642171: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:   0%|        | 0/3 [00:00<?, ?blocks/s, Layers=['model_cnn21/conv1_output_0']]2025-05-20 18:59:31.201081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 18:59:33.341351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-05-20 18:59:37.958014: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-05-20 18:59:38.027106: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x5567e69b6ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-20 18:59:38.027129: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-05-20 18:59:38.059801: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-20 18:59:38.294152: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:02<34:00:27,  2.99s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:02<34:00:27,  2.99s/batches, l2_loss: 0.0042 - round_loss:\u001b[A\n",
      "Training:   0%| | 97/40960 [00:03<16:09, 42.16batches/s, l2_loss: 0.0042 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 97/40960 [00:03<16:09, 42.16batches/s, l2_loss: 0.0033 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 193/40960 [00:03<07:30, 90.57batches/s, l2_loss: 0.0033 - round_loss: \u001b[A\n",
      "Training:   0%| | 193/40960 [00:03<07:30, 90.57batches/s, l2_loss: 0.0032 - round_loss: \u001b[A\n",
      "Training:   1%| | 288/40960 [00:03<04:44, 142.95batches/s, l2_loss: 0.0032 - round_loss:\u001b[A\n",
      "Training:   1%| | 288/40960 [00:03<04:44, 142.95batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   1%| | 385/40960 [00:03<03:24, 198.68batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   1%| | 385/40960 [00:03<03:24, 198.68batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   1%| | 480/40960 [00:03<02:41, 250.59batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   1%| | 480/40960 [00:03<02:41, 250.59batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   1%| | 577/40960 [00:04<02:14, 299.93batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   1%| | 577/40960 [00:04<02:14, 299.93batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   2%| | 673/40960 [00:04<01:57, 341.46batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   2%| | 673/40960 [00:04<01:57, 341.46batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   2%| | 770/40960 [00:04<01:46, 376.56batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   2%| | 770/40960 [00:04<01:46, 376.56batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   2%| | 867/40960 [00:04<01:39, 404.55batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   2%| | 867/40960 [00:04<01:39, 404.55batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   2%| | 965/40960 [00:05<01:33, 427.14batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   2%| | 965/40960 [00:05<01:33, 427.14batches/s, l2_loss: 0.0031 - round_loss:\u001b[A\n",
      "Training:   3%| | 1063/40960 [00:05<01:29, 444.70batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   3%| | 1063/40960 [00:05<01:29, 444.70batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   3%| | 1161/40960 [00:05<01:27, 456.78batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   3%| | 1161/40960 [00:05<01:27, 456.78batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   3%| | 1258/40960 [00:05<01:25, 464.95batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   3%| | 1258/40960 [00:05<01:25, 464.95batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   3%| | 1355/40960 [00:05<01:24, 470.59batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   3%| | 1355/40960 [00:05<01:24, 470.59batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1450/40960 [00:06<01:23, 471.67batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1450/40960 [00:06<01:23, 471.67batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1547/40960 [00:06<01:23, 474.46batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1547/40960 [00:06<01:23, 474.46batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1642/40960 [00:06<01:22, 473.99batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1642/40960 [00:06<01:22, 473.99batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1738/40960 [00:06<01:22, 475.25batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1738/40960 [00:06<01:22, 475.25batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1839/40960 [00:06<01:21, 482.80batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   4%| | 1839/40960 [00:06<01:21, 482.80batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   5%| | 1937/40960 [00:07<01:20, 484.92batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   5%| | 1937/40960 [00:07<01:20, 484.92batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   5%| | 2036/40960 [00:07<01:19, 487.67batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   5%| | 2036/40960 [00:07<01:19, 487.67batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   5%| | 2135/40960 [00:07<01:19, 489.26batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   5%| | 2135/40960 [00:07<01:19, 489.26batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   5%| | 2233/40960 [00:07<01:19, 488.32batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   5%| | 2233/40960 [00:07<01:19, 488.32batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   6%| | 2330/40960 [00:07<01:19, 487.21batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   6%| | 2330/40960 [00:07<01:19, 487.21batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   6%| | 2430/40960 [00:08<01:18, 490.49batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   6%| | 2430/40960 [00:08<01:18, 490.49batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   6%| | 2525/40960 [00:08<01:19, 485.51batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   6%| | 2525/40960 [00:08<01:19, 485.51batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   6%| | 2624/40960 [00:08<01:18, 487.14batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   6%| | 2624/40960 [00:08<01:18, 487.14batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   7%| | 2721/40960 [00:08<01:18, 485.15batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%| | 2721/40960 [00:08<01:18, 485.15batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   7%| | 2820/40960 [00:08<01:18, 487.65batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   7%| | 2820/40960 [00:08<01:18, 487.65batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   7%| | 2916/40960 [00:09<01:18, 484.90batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   7%| | 2916/40960 [00:09<01:18, 484.90batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   7%| | 3014/40960 [00:09<01:18, 486.15batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   7%| | 3014/40960 [00:09<01:18, 486.15batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   8%| | 3113/40960 [00:09<01:17, 487.95batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:   8%| | 3113/40960 [00:09<01:17, 487.95batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   8%| | 3210/40960 [00:09<01:17, 486.27batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   8%| | 3210/40960 [00:09<01:17, 486.27batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   8%| | 3305/40960 [00:09<01:18, 481.67batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   8%| | 3305/40960 [00:09<01:18, 481.67batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   8%| | 3404/40960 [00:10<01:17, 484.56batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   8%| | 3404/40960 [00:10<01:17, 484.56batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   9%| | 3503/40960 [00:10<01:16, 487.45batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   9%| | 3503/40960 [00:10<01:16, 487.45batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   9%| | 3602/40960 [00:10<01:16, 488.46batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   9%| | 3602/40960 [00:10<01:16, 488.46batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   9%| | 3700/40960 [00:10<01:16, 487.85batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   9%| | 3700/40960 [00:10<01:16, 487.85batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   9%| | 3798/40960 [00:10<01:16, 487.77batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:   9%| | 3798/40960 [00:10<01:16, 487.77batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 3897/40960 [00:11<01:15, 488.66batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 3897/40960 [00:11<01:15, 488.66batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 3994/40960 [00:11<01:15, 487.37batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 3994/40960 [00:11<01:15, 487.37batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 4092/40960 [00:11<01:15, 487.44batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 4092/40960 [00:11<01:15, 487.44batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 4188/40960 [00:11<01:15, 484.65batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 4188/40960 [00:11<01:15, 484.65batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 4284/40960 [00:11<01:16, 481.99batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  10%| | 4284/40960 [00:11<01:16, 481.99batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  11%| | 4384/40960 [00:12<01:15, 486.30batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  11%| | 4384/40960 [00:12<01:15, 486.30batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  11%| | 4481/40960 [00:12<01:15, 485.69batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  11%| | 4481/40960 [00:12<01:15, 485.69batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  11%| | 4580/40960 [00:12<01:14, 488.12batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  11%| | 4580/40960 [00:12<01:14, 488.12batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  11%| | 4677/40960 [00:12<01:14, 486.00batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  11%| | 4677/40960 [00:12<01:14, 486.00batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  12%| | 4773/40960 [00:12<01:14, 483.94batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  12%| | 4773/40960 [00:12<01:14, 483.94batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  12%| | 4870/40960 [00:13<01:14, 483.92batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  12%| | 4870/40960 [00:13<01:14, 483.92batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  12%| | 4967/40960 [00:13<01:14, 483.20batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  12%| | 4967/40960 [00:13<01:14, 483.20batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  12%| | 5063/40960 [00:13<01:14, 481.92batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  12%| | 5063/40960 [00:13<01:14, 481.92batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5159/40960 [00:13<01:14, 480.94batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5159/40960 [00:13<01:14, 480.94batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5254/40960 [00:13<01:14, 477.70batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5254/40960 [00:13<01:14, 477.70batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5352/40960 [00:14<01:14, 480.20batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5352/40960 [00:14<01:14, 480.20batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5450/40960 [00:14<01:13, 481.69batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5450/40960 [00:14<01:13, 481.69batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5546/40960 [00:14<01:13, 480.55batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5546/40960 [00:14<01:13, 480.55batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5643/40960 [00:14<01:13, 481.58batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5643/40960 [00:14<01:13, 481.58batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5740/40960 [00:14<01:13, 481.65batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5740/40960 [00:14<01:13, 481.65batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5839/40960 [00:15<01:12, 485.04batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5839/40960 [00:15<01:12, 485.04batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5933/40960 [00:15<01:12, 480.50batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5933/40960 [00:15<01:12, 480.50batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6028/40960 [00:15<01:13, 478.43batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6028/40960 [00:15<01:13, 478.43batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6124/40960 [00:15<01:12, 477.95batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6124/40960 [00:15<01:12, 477.95batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6220/40960 [00:15<01:12, 478.23batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6220/40960 [00:15<01:12, 478.23batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6318/40960 [00:16<01:11, 481.23batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6318/40960 [00:16<01:11, 481.23batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6418/40960 [00:16<01:11, 486.36batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6418/40960 [00:16<01:11, 486.36batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6517/40960 [00:16<01:10, 487.82batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6517/40960 [00:16<01:10, 487.82batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6613/40960 [00:16<01:10, 485.48batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6613/40960 [00:16<01:10, 485.48batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6710/40960 [00:16<01:10, 485.19batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6710/40960 [00:16<01:10, 485.19batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6808/40960 [00:17<01:10, 485.53batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6808/40960 [00:17<01:10, 485.53batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6904/40960 [00:17<01:10, 482.67batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6904/40960 [00:17<01:10, 482.67batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6999/40960 [00:17<01:10, 479.46batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6999/40960 [00:17<01:10, 479.46batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|▏| 7095/40960 [00:17<01:10, 478.25batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7095/40960 [00:17<01:10, 478.25batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7191/40960 [00:17<01:10, 478.21batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7191/40960 [00:17<01:10, 478.21batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7287/40960 [00:18<01:10, 478.68batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7287/40960 [00:18<01:10, 478.68batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7383/40960 [00:18<01:10, 478.70batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7383/40960 [00:18<01:10, 478.70batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7482/40960 [00:18<01:09, 482.21batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7482/40960 [00:18<01:09, 482.21batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7580/40960 [00:18<01:09, 483.13batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7580/40960 [00:18<01:09, 483.13batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7678/40960 [00:18<01:08, 484.25batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7678/40960 [00:18<01:08, 484.25batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7777/40960 [00:19<01:08, 486.99batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7777/40960 [00:19<01:08, 486.99batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7875/40960 [00:19<01:07, 487.08batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7875/40960 [00:19<01:07, 487.08batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7971/40960 [00:19<01:08, 484.55batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7971/40960 [00:19<01:08, 484.55batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8068/40960 [00:19<01:08, 483.36batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8068/40960 [00:19<01:08, 483.36batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8166/40960 [00:19<01:07, 484.68batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8166/40960 [00:19<01:07, 484.68batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8249/40960 [00:20<01:10, 463.57batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8249/40960 [00:20<01:10, 463.57batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8337/40960 [00:20<01:11, 455.71batches/s, l2_loss: 0.0030 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8337/40960 [00:20<01:11, 455.71batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8425/40960 [00:20<01:12, 449.51batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8425/40960 [00:20<01:12, 449.51batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8513/40960 [00:20<01:12, 445.92batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8513/40960 [00:20<01:12, 445.92batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8601/40960 [00:20<01:13, 442.99batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8601/40960 [00:20<01:13, 442.99batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8690/40960 [00:21<01:12, 442.29batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8690/40960 [00:21<01:12, 442.29batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8780/40960 [00:21<01:12, 443.25batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8780/40960 [00:21<01:12, 443.25batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8867/40960 [00:21<01:13, 439.63batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8867/40960 [00:21<01:13, 439.63batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8957/40960 [00:21<01:12, 441.86batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8957/40960 [00:21<01:12, 441.86batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9043/40960 [00:21<01:12, 437.68batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9043/40960 [00:21<01:12, 437.68batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9130/40960 [00:22<01:12, 436.88batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9130/40960 [00:22<01:12, 436.88batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9217/40960 [00:22<01:12, 436.30batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9217/40960 [00:22<01:12, 436.30batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9306/40960 [00:22<01:12, 438.64batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9306/40960 [00:22<01:12, 438.64batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9393/40960 [00:22<01:12, 436.17batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9393/40960 [00:22<01:12, 436.17batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9480/40960 [00:22<01:12, 435.66batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9480/40960 [00:22<01:12, 435.66batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9568/40960 [00:23<01:12, 435.86batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9568/40960 [00:23<01:12, 435.86batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9657/40960 [00:23<01:11, 437.70batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9657/40960 [00:23<01:11, 437.70batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9747/40960 [00:23<01:10, 440.35batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9747/40960 [00:23<01:10, 440.35batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9835/40960 [00:23<01:10, 439.17batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9835/40960 [00:23<01:10, 439.17batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9923/40960 [00:23<01:10, 438.00batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9923/40960 [00:23<01:10, 438.00batches/s, l2_loss: 0.0031 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10011/40960 [00:24<01:10, 437.55batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  24%|▏| 10011/40960 [00:24<01:10, 437.55batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  25%|▏| 10100/40960 [00:24<01:10, 439.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  25%|▏| 10100/40960 [00:24<01:10, 439.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  25%|▏| 10190/40960 [00:24<01:09, 442.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  25%|▏| 10190/40960 [00:24<01:09, 442.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  25%|▎| 10276/40960 [00:24<01:10, 438.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  25%|▎| 10276/40960 [00:24<01:10, 438.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  25%|▎| 10365/40960 [00:24<01:09, 439.71batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  25%|▎| 10365/40960 [00:24<01:09, 439.71batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10452/40960 [00:25<01:09, 437.89batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10452/40960 [00:25<01:09, 437.89batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10540/40960 [00:25<01:09, 437.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10540/40960 [00:25<01:09, 437.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10628/40960 [00:25<01:09, 437.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10628/40960 [00:25<01:09, 437.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10715/40960 [00:25<01:09, 435.63batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10715/40960 [00:25<01:09, 435.63batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10802/40960 [00:25<01:09, 435.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  26%|▎| 10802/40960 [00:25<01:09, 435.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 10891/40960 [00:26<01:08, 437.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 10891/40960 [00:26<01:08, 437.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 10977/40960 [00:26<01:09, 433.53batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 10977/40960 [00:26<01:09, 433.53batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 11064/40960 [00:26<01:09, 433.09batches/s, l2_loss: 0.0031 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|▎| 11064/40960 [00:26<01:09, 433.09batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 11151/40960 [00:26<01:08, 433.08batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 11151/40960 [00:26<01:08, 433.08batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 11240/40960 [00:26<01:08, 436.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  27%|▎| 11240/40960 [00:26<01:08, 436.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11328/40960 [00:27<01:07, 437.47batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11328/40960 [00:27<01:07, 437.47batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11415/40960 [00:27<01:07, 436.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11415/40960 [00:27<01:07, 436.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11499/40960 [00:27<01:08, 430.28batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11499/40960 [00:27<01:08, 430.28batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11583/40960 [00:27<01:08, 426.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11583/40960 [00:27<01:08, 426.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11672/40960 [00:27<01:07, 430.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  28%|▎| 11672/40960 [00:27<01:07, 430.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  29%|▎| 11760/40960 [00:28<01:07, 433.45batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  29%|▎| 11760/40960 [00:28<01:07, 433.45batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  29%|▎| 11849/40960 [00:28<01:06, 436.45batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  29%|▎| 11849/40960 [00:28<01:06, 436.45batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  29%|▎| 11938/40960 [00:28<01:06, 438.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  29%|▎| 11938/40960 [00:28<01:06, 438.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  29%|▎| 12027/40960 [00:28<01:05, 439.15batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  29%|▎| 12027/40960 [00:28<01:05, 439.15batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12115/40960 [00:28<01:05, 439.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12115/40960 [00:28<01:05, 439.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12204/40960 [00:29<01:05, 439.86batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12204/40960 [00:29<01:05, 439.86batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12290/40960 [00:29<01:05, 436.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12290/40960 [00:29<01:05, 436.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12377/40960 [00:29<01:05, 436.09batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12377/40960 [00:29<01:05, 436.09batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12465/40960 [00:29<01:05, 436.34batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  30%|▎| 12465/40960 [00:29<01:05, 436.34batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  31%|▎| 12552/40960 [00:29<01:05, 435.90batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  31%|▎| 12552/40960 [00:29<01:05, 435.90batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  31%|▎| 12640/40960 [00:30<01:04, 435.86batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  31%|▎| 12640/40960 [00:30<01:04, 435.86batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  31%|▎| 12730/40960 [00:30<01:04, 439.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  31%|▎| 12730/40960 [00:30<01:04, 439.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  31%|▎| 12818/40960 [00:30<01:04, 439.08batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  31%|▎| 12818/40960 [00:30<01:04, 439.08batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 12908/40960 [00:30<01:03, 441.57batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 12908/40960 [00:30<01:03, 441.57batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 12997/40960 [00:30<01:03, 441.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 12997/40960 [00:30<01:03, 441.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 13087/40960 [00:31<01:02, 442.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 13087/40960 [00:31<01:02, 442.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 13173/40960 [00:31<01:03, 438.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 13173/40960 [00:31<01:03, 438.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 13257/40960 [00:31<01:04, 432.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  32%|▎| 13257/40960 [00:31<01:04, 432.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13343/40960 [00:31<01:04, 430.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13343/40960 [00:31<01:04, 430.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13430/40960 [00:31<01:03, 432.05batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13430/40960 [00:31<01:03, 432.05batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13520/40960 [00:32<01:02, 437.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13520/40960 [00:32<01:02, 437.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13609/40960 [00:32<01:02, 439.18batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13609/40960 [00:32<01:02, 439.18batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13697/40960 [00:32<01:02, 439.40batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  33%|▎| 13697/40960 [00:32<01:02, 439.40batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  34%|▎| 13786/40960 [00:32<01:01, 440.37batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  34%|▎| 13786/40960 [00:32<01:01, 440.37batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  34%|▎| 13877/40960 [00:32<01:01, 443.41batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  34%|▎| 13877/40960 [00:32<01:01, 443.41batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  34%|▎| 13965/40960 [00:33<01:01, 440.89batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  34%|▎| 13965/40960 [00:33<01:01, 440.89batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  34%|▎| 14052/40960 [00:33<01:01, 438.47batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  34%|▎| 14052/40960 [00:33<01:01, 438.47batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14141/40960 [00:33<01:00, 440.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14141/40960 [00:33<01:00, 440.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14230/40960 [00:33<01:00, 440.93batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14230/40960 [00:33<01:00, 440.93batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14320/40960 [00:33<01:00, 442.68batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14320/40960 [00:33<01:00, 442.68batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14409/40960 [00:34<01:00, 442.04batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14409/40960 [00:34<01:00, 442.04batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14499/40960 [00:34<00:59, 443.55batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  35%|▎| 14499/40960 [00:34<00:59, 443.55batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14589/40960 [00:34<00:59, 444.49batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14589/40960 [00:34<00:59, 444.49batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14676/40960 [00:34<00:59, 441.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14676/40960 [00:34<00:59, 441.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14764/40960 [00:34<00:59, 439.87batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14764/40960 [00:34<00:59, 439.87batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14854/40960 [00:35<00:59, 442.36batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14854/40960 [00:35<00:59, 442.36batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14942/40960 [00:35<00:58, 441.50batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  36%|▎| 14942/40960 [00:35<00:58, 441.50batches/s, l2_loss: 0.0031 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|▎| 15029/40960 [00:35<00:59, 438.93batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  37%|▎| 15029/40960 [00:35<00:59, 438.93batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  37%|▎| 15117/40960 [00:35<00:58, 438.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  37%|▎| 15117/40960 [00:35<00:58, 438.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  37%|▎| 15206/40960 [00:35<00:58, 440.20batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  37%|▎| 15206/40960 [00:35<00:58, 440.20batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  37%|▎| 15293/40960 [00:36<00:58, 438.39batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  37%|▎| 15293/40960 [00:36<00:58, 438.39batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15381/40960 [00:36<00:58, 438.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15381/40960 [00:36<00:58, 438.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15456/40960 [00:36<01:00, 419.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15456/40960 [00:36<01:00, 419.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15530/40960 [00:36<01:03, 403.22batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15530/40960 [00:36<01:03, 403.22batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15604/40960 [00:36<01:04, 392.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15604/40960 [00:36<01:04, 392.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15677/40960 [00:37<01:06, 382.83batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15677/40960 [00:37<01:06, 382.83batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15752/40960 [00:37<01:06, 379.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  38%|▍| 15752/40960 [00:37<01:06, 379.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 15829/40960 [00:37<01:06, 380.33batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 15829/40960 [00:37<01:06, 380.33batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 15910/40960 [00:37<01:04, 386.37batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 15910/40960 [00:37<01:04, 386.37batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 15992/40960 [00:37<01:03, 393.26batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 15992/40960 [00:37<01:03, 393.26batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 16081/40960 [00:38<01:01, 407.67batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 16081/40960 [00:38<01:01, 407.67batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 16166/40960 [00:38<01:00, 412.83batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  39%|▍| 16166/40960 [00:38<01:00, 412.83batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16247/40960 [00:38<01:00, 409.45batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16247/40960 [00:38<01:00, 409.45batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16325/40960 [00:38<01:01, 402.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16325/40960 [00:38<01:01, 402.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16404/40960 [00:38<01:01, 399.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16404/40960 [00:38<01:01, 399.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16494/40960 [00:39<00:59, 414.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16494/40960 [00:39<00:59, 414.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16582/40960 [00:39<00:57, 422.09batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  40%|▍| 16582/40960 [00:39<00:57, 422.09batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  41%|▍| 16668/40960 [00:39<00:57, 423.44batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  41%|▍| 16668/40960 [00:39<00:57, 423.44batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  41%|▍| 16758/40960 [00:39<00:56, 430.18batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  41%|▍| 16758/40960 [00:39<00:56, 430.18batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  41%|▍| 16844/40960 [00:39<00:56, 429.02batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  41%|▍| 16844/40960 [00:39<00:56, 429.02batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  41%|▍| 16923/40960 [00:40<00:57, 417.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  41%|▍| 16923/40960 [00:40<00:57, 417.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17002/40960 [00:40<00:58, 409.75batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17002/40960 [00:40<00:58, 409.75batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17088/40960 [00:40<00:57, 414.98batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17088/40960 [00:40<00:57, 414.98batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17175/40960 [00:40<00:56, 420.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17175/40960 [00:40<00:56, 420.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17263/40960 [00:40<00:55, 425.84batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17263/40960 [00:40<00:55, 425.84batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17350/40960 [00:41<00:55, 427.50batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  42%|▍| 17350/40960 [00:41<00:55, 427.50batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17437/40960 [00:41<00:54, 428.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17437/40960 [00:41<00:54, 428.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17526/40960 [00:41<00:54, 432.76batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17526/40960 [00:41<00:54, 432.76batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17613/40960 [00:41<00:54, 432.20batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17613/40960 [00:41<00:54, 432.20batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17702/40960 [00:42<00:53, 435.19batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17702/40960 [00:42<00:53, 435.19batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17791/40960 [00:42<00:52, 437.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  43%|▍| 17791/40960 [00:42<00:52, 437.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 17878/40960 [00:42<00:52, 436.42batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 17878/40960 [00:42<00:52, 436.42batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 17965/40960 [00:42<00:52, 435.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 17965/40960 [00:42<00:52, 435.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 18052/40960 [00:42<00:52, 434.04batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 18052/40960 [00:42<00:52, 434.04batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 18139/40960 [00:43<00:52, 434.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 18139/40960 [00:43<00:52, 434.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 18226/40960 [00:43<00:52, 434.16batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  44%|▍| 18226/40960 [00:43<00:52, 434.16batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  45%|▍| 18315/40960 [00:43<00:51, 436.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  45%|▍| 18315/40960 [00:43<00:51, 436.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  45%|▍| 18402/40960 [00:43<00:51, 436.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  45%|▍| 18402/40960 [00:43<00:51, 436.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  45%|▍| 18491/40960 [00:43<00:51, 437.60batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  45%|▍| 18491/40960 [00:43<00:51, 437.60batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  45%|▍| 18576/40960 [00:44<00:51, 433.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  45%|▍| 18576/40960 [00:44<00:51, 433.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 18663/40960 [00:44<00:51, 432.99batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 18663/40960 [00:44<00:51, 432.99batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 18751/40960 [00:44<00:51, 434.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|▍| 18751/40960 [00:44<00:51, 434.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 18840/40960 [00:44<00:50, 436.11batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 18840/40960 [00:44<00:50, 436.11batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 18929/40960 [00:44<00:50, 437.52batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 18929/40960 [00:44<00:50, 437.52batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 19019/40960 [00:45<00:49, 441.11batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  46%|▍| 19019/40960 [00:45<00:49, 441.11batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  47%|▍| 19106/40960 [00:45<00:49, 438.89batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  47%|▍| 19106/40960 [00:45<00:49, 438.89batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  47%|▍| 19195/40960 [00:45<00:49, 440.66batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  47%|▍| 19195/40960 [00:45<00:49, 440.66batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  47%|▍| 19284/40960 [00:45<00:49, 441.58batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  47%|▍| 19284/40960 [00:45<00:49, 441.58batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  47%|▍| 19374/40960 [00:45<00:48, 443.09batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  47%|▍| 19374/40960 [00:45<00:48, 443.09batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19463/40960 [00:46<00:48, 442.45batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19463/40960 [00:46<00:48, 442.45batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19551/40960 [00:46<00:48, 440.84batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19551/40960 [00:46<00:48, 440.84batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19640/40960 [00:46<00:48, 441.47batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19640/40960 [00:46<00:48, 441.47batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19727/40960 [00:46<00:48, 438.85batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19727/40960 [00:46<00:48, 438.85batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19816/40960 [00:46<00:48, 439.32batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  48%|▍| 19816/40960 [00:46<00:48, 439.32batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 19904/40960 [00:47<00:48, 438.50batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 19904/40960 [00:47<00:48, 438.50batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 19992/40960 [00:47<00:47, 437.80batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 19992/40960 [00:47<00:47, 437.80batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 20080/40960 [00:47<00:47, 438.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 20080/40960 [00:47<00:47, 438.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 20169/40960 [00:47<00:47, 439.58batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 20169/40960 [00:47<00:47, 439.58batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 20256/40960 [00:47<00:47, 438.07batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  49%|▍| 20256/40960 [00:47<00:47, 438.07batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  50%|▍| 20343/40960 [00:48<00:47, 436.48batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  50%|▍| 20343/40960 [00:48<00:47, 436.48batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  50%|▍| 20432/40960 [00:48<00:46, 438.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  50%|▍| 20432/40960 [00:48<00:46, 438.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  50%|▌| 20519/40960 [00:48<00:46, 437.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  50%|▌| 20519/40960 [00:48<00:46, 437.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  50%|▌| 20608/40960 [00:48<00:46, 438.34batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  50%|▌| 20608/40960 [00:48<00:46, 438.34batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 20695/40960 [00:48<00:46, 437.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 20695/40960 [00:48<00:46, 437.24batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 20783/40960 [00:49<00:46, 436.66batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 20783/40960 [00:49<00:46, 436.66batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 20872/40960 [00:49<00:45, 438.32batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 20872/40960 [00:49<00:45, 438.32batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 20962/40960 [00:49<00:45, 440.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 20962/40960 [00:49<00:45, 440.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 21049/40960 [00:49<00:45, 438.78batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  51%|▌| 21049/40960 [00:49<00:45, 438.78batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21136/40960 [00:49<00:45, 437.46batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21136/40960 [00:49<00:45, 437.46batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21224/40960 [00:50<00:45, 437.55batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21224/40960 [00:50<00:45, 437.55batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21309/40960 [00:50<00:45, 433.71batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21309/40960 [00:50<00:45, 433.71batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21399/40960 [00:50<00:44, 438.01batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21399/40960 [00:50<00:44, 438.01batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21487/40960 [00:50<00:44, 437.63batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  52%|▌| 21487/40960 [00:50<00:44, 437.63batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  53%|▌| 21575/40960 [00:50<00:44, 437.20batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  53%|▌| 21575/40960 [00:50<00:44, 437.20batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  53%|▌| 21662/40960 [00:51<00:44, 435.58batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  53%|▌| 21662/40960 [00:51<00:44, 435.58batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  53%|▌| 21751/40960 [00:51<00:43, 437.33batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  53%|▌| 21751/40960 [00:51<00:43, 437.33batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  53%|▌| 21838/40960 [00:51<00:43, 435.28batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  53%|▌| 21838/40960 [00:51<00:43, 435.28batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 21929/40960 [00:51<00:43, 440.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 21929/40960 [00:51<00:43, 440.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 22017/40960 [00:51<00:43, 439.32batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 22017/40960 [00:51<00:43, 439.32batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 22104/40960 [00:52<00:43, 437.27batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 22104/40960 [00:52<00:43, 437.27batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 22192/40960 [00:52<00:42, 436.94batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 22192/40960 [00:52<00:42, 436.94batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 22281/40960 [00:52<00:42, 439.16batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  54%|▌| 22281/40960 [00:52<00:42, 439.16batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22368/40960 [00:52<00:42, 437.69batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22368/40960 [00:52<00:42, 437.69batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22455/40960 [00:52<00:42, 436.46batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22455/40960 [00:52<00:42, 436.46batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22544/40960 [00:53<00:42, 438.36batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22544/40960 [00:53<00:42, 438.36batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22633/40960 [00:53<00:41, 440.18batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22633/40960 [00:53<00:41, 440.18batches/s, l2_loss: 0.0031 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|▌| 22721/40960 [00:53<00:41, 438.74batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  55%|▌| 22721/40960 [00:53<00:41, 438.74batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 22810/40960 [00:53<00:41, 440.44batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 22810/40960 [00:53<00:41, 440.44batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 22894/40960 [00:53<00:41, 433.36batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 22894/40960 [00:53<00:41, 433.36batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 22981/40960 [00:54<00:41, 433.31batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 22981/40960 [00:54<00:41, 433.31batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 23060/40960 [00:54<00:42, 420.98batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 23060/40960 [00:54<00:42, 420.98batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 23135/40960 [00:54<00:43, 406.68batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  56%|▌| 23135/40960 [00:54<00:43, 406.68batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  57%|▌| 23216/40960 [00:54<00:43, 405.49batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  57%|▌| 23216/40960 [00:54<00:43, 405.49batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  57%|▌| 23303/40960 [00:54<00:42, 414.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  57%|▌| 23303/40960 [00:54<00:42, 414.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  57%|▌| 23389/40960 [00:55<00:42, 417.61batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  57%|▌| 23389/40960 [00:55<00:42, 417.61batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  57%|▌| 23472/40960 [00:55<00:41, 416.43batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  57%|▌| 23472/40960 [00:55<00:41, 416.43batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23558/40960 [00:55<00:41, 420.48batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23558/40960 [00:55<00:41, 420.48batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23645/40960 [00:55<00:40, 424.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23645/40960 [00:55<00:40, 424.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23733/40960 [00:55<00:40, 428.23batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23733/40960 [00:55<00:40, 428.23batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23819/40960 [00:56<00:40, 427.96batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23819/40960 [00:56<00:40, 427.96batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23905/40960 [00:56<00:39, 427.88batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  58%|▌| 23905/40960 [00:56<00:39, 427.88batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 23993/40960 [00:56<00:39, 431.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 23993/40960 [00:56<00:39, 431.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 24078/40960 [00:56<00:39, 428.44batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 24078/40960 [00:56<00:39, 428.44batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 24165/40960 [00:56<00:39, 429.23batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 24165/40960 [00:56<00:39, 429.23batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 24250/40960 [00:57<00:39, 427.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 24250/40960 [00:57<00:39, 427.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 24334/40960 [00:57<00:39, 424.34batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  59%|▌| 24334/40960 [00:57<00:39, 424.34batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24421/40960 [00:57<00:38, 427.04batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24421/40960 [00:57<00:38, 427.04batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24508/40960 [00:57<00:38, 428.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24508/40960 [00:57<00:38, 428.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24595/40960 [00:57<00:38, 428.96batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24595/40960 [00:57<00:38, 428.96batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24679/40960 [00:58<00:38, 425.42batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24679/40960 [00:58<00:38, 425.42batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24767/40960 [00:58<00:37, 428.51batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  60%|▌| 24767/40960 [00:58<00:37, 428.51batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  61%|▌| 24854/40960 [00:58<00:37, 428.64batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  61%|▌| 24854/40960 [00:58<00:37, 428.64batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  61%|▌| 24944/40960 [00:58<00:36, 433.79batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  61%|▌| 24944/40960 [00:58<00:36, 433.79batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  61%|▌| 25033/40960 [00:58<00:36, 436.49batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  61%|▌| 25033/40960 [00:58<00:36, 436.49batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  61%|▌| 25120/40960 [00:59<00:36, 435.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  61%|▌| 25120/40960 [00:59<00:36, 435.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25202/40960 [00:59<00:36, 426.94batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25202/40960 [00:59<00:36, 426.94batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25289/40960 [00:59<00:36, 428.71batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25289/40960 [00:59<00:36, 428.71batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25375/40960 [00:59<00:36, 427.83batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25375/40960 [00:59<00:36, 427.83batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25459/40960 [00:59<00:36, 424.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25459/40960 [00:59<00:36, 424.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25545/40960 [01:00<00:36, 425.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  62%|▌| 25545/40960 [01:00<00:36, 425.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25630/40960 [01:00<00:36, 425.28batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25630/40960 [01:00<00:36, 425.28batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25716/40960 [01:00<00:35, 425.55batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25716/40960 [01:00<00:35, 425.55batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25803/40960 [01:00<00:35, 427.43batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25803/40960 [01:00<00:35, 427.43batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25891/40960 [01:00<00:35, 430.01batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25891/40960 [01:00<00:35, 430.01batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25980/40960 [01:01<00:34, 433.72batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  63%|▋| 25980/40960 [01:01<00:34, 433.72batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26059/40960 [01:01<00:35, 421.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26059/40960 [01:01<00:35, 421.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26145/40960 [01:01<00:34, 423.29batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26145/40960 [01:01<00:34, 423.29batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26233/40960 [01:01<00:34, 427.01batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26233/40960 [01:01<00:34, 427.01batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26320/40960 [01:01<00:34, 428.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26320/40960 [01:01<00:34, 428.56batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26407/40960 [01:02<00:33, 429.53batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  64%|▋| 26407/40960 [01:02<00:33, 429.53batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  65%|▋| 26496/40960 [01:02<00:33, 433.33batches/s, l2_loss: 0.0031 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|▋| 26496/40960 [01:02<00:33, 433.33batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  65%|▋| 26583/40960 [01:02<00:33, 433.17batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  65%|▋| 26583/40960 [01:02<00:33, 433.17batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  65%|▋| 26668/40960 [01:02<00:33, 430.20batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  65%|▋| 26668/40960 [01:02<00:33, 430.20batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  65%|▋| 26752/40960 [01:02<00:33, 426.65batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  65%|▋| 26752/40960 [01:02<00:33, 426.65batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 26837/40960 [01:03<00:33, 425.97batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 26837/40960 [01:03<00:33, 425.97batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 26923/40960 [01:03<00:32, 426.84batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 26923/40960 [01:03<00:32, 426.84batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 27011/40960 [01:03<00:32, 430.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 27011/40960 [01:03<00:32, 430.54batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 27096/40960 [01:03<00:32, 427.36batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 27096/40960 [01:03<00:32, 427.36batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 27183/40960 [01:03<00:32, 429.02batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  66%|▋| 27183/40960 [01:03<00:32, 429.02batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27270/40960 [01:04<00:31, 429.91batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27270/40960 [01:04<00:31, 429.91batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27356/40960 [01:04<00:31, 428.73batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27356/40960 [01:04<00:31, 428.73batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27432/40960 [01:04<00:32, 413.95batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27432/40960 [01:04<00:32, 413.95batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27513/40960 [01:04<00:32, 410.88batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27513/40960 [01:04<00:32, 410.88batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27600/40960 [01:04<00:32, 417.39batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  67%|▋| 27600/40960 [01:04<00:32, 417.39batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 27680/40960 [01:05<00:32, 411.70batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 27680/40960 [01:05<00:32, 411.70batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 27768/40960 [01:05<00:31, 419.39batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 27768/40960 [01:05<00:31, 419.39batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 27852/40960 [01:05<00:31, 418.53batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 27852/40960 [01:05<00:31, 418.53batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 27934/40960 [01:05<00:31, 414.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 27934/40960 [01:05<00:31, 414.92batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 28021/40960 [01:05<00:30, 419.66batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  68%|▋| 28021/40960 [01:05<00:30, 419.66batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28102/40960 [01:06<00:30, 415.12batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28102/40960 [01:06<00:30, 415.12batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28177/40960 [01:06<00:31, 402.37batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28177/40960 [01:06<00:31, 402.37batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28253/40960 [01:06<00:32, 394.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28253/40960 [01:06<00:32, 394.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28336/40960 [01:06<00:31, 400.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28336/40960 [01:06<00:31, 400.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28422/40960 [01:06<00:30, 408.46batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  69%|▋| 28422/40960 [01:06<00:30, 408.46batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28507/40960 [01:07<00:30, 412.34batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28507/40960 [01:07<00:30, 412.34batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28593/40960 [01:07<00:29, 417.28batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28593/40960 [01:07<00:29, 417.28batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28680/40960 [01:07<00:29, 421.87batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28680/40960 [01:07<00:29, 421.87batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28768/40960 [01:07<00:28, 426.96batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28768/40960 [01:07<00:28, 426.96batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28855/40960 [01:07<00:28, 428.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  70%|▋| 28855/40960 [01:07<00:28, 428.81batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  71%|▋| 28943/40960 [01:08<00:27, 431.86batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  71%|▋| 28943/40960 [01:08<00:27, 431.86batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  71%|▋| 29025/40960 [01:08<00:28, 424.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  71%|▋| 29025/40960 [01:08<00:28, 424.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  71%|▋| 29112/40960 [01:08<00:27, 426.67batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  71%|▋| 29112/40960 [01:08<00:27, 426.67batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  71%|▋| 29202/40960 [01:08<00:27, 432.66batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  71%|▋| 29202/40960 [01:08<00:27, 432.66batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29288/40960 [01:08<00:27, 431.04batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29288/40960 [01:08<00:27, 431.04batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29369/40960 [01:09<00:27, 422.73batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29369/40960 [01:09<00:27, 422.73batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29454/40960 [01:09<00:27, 423.35batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29454/40960 [01:09<00:27, 423.35batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29536/40960 [01:09<00:27, 418.11batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29536/40960 [01:09<00:27, 418.11batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29622/40960 [01:09<00:26, 421.11batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  72%|▋| 29622/40960 [01:09<00:26, 421.11batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 29710/40960 [01:09<00:26, 425.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 29710/40960 [01:09<00:26, 425.59batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 29793/40960 [01:10<00:26, 421.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 29793/40960 [01:10<00:26, 421.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 29871/40960 [01:10<00:26, 411.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 29871/40960 [01:10<00:26, 411.10batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 29961/40960 [01:10<00:26, 421.40batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 29961/40960 [01:10<00:26, 421.40batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 30041/40960 [01:10<00:26, 413.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  73%|▋| 30041/40960 [01:10<00:26, 413.21batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30114/40960 [01:10<00:27, 397.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30114/40960 [01:10<00:27, 397.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30190/40960 [01:11<00:27, 392.29batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30190/40960 [01:11<00:27, 392.29batches/s, l2_loss: 0.0031 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|▋| 30271/40960 [01:11<00:27, 395.51batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30271/40960 [01:11<00:27, 395.51batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30355/40960 [01:11<00:26, 402.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30355/40960 [01:11<00:26, 402.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30444/40960 [01:11<00:25, 414.83batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  74%|▋| 30444/40960 [01:11<00:25, 414.83batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▋| 30535/40960 [01:11<00:24, 425.38batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▋| 30535/40960 [01:11<00:24, 425.38batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▋| 30627/40960 [01:12<00:23, 435.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▋| 30627/40960 [01:12<00:23, 435.00batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▋| 30714/40960 [01:12<00:23, 433.96batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▋| 30714/40960 [01:12<00:23, 433.96batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▊| 30796/40960 [01:12<00:23, 425.15batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▊| 30796/40960 [01:12<00:23, 425.15batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▊| 30884/40960 [01:12<00:23, 429.06batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  75%|▊| 30884/40960 [01:12<00:23, 429.06batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 30970/40960 [01:12<00:23, 429.29batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 30970/40960 [01:12<00:23, 429.29batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 31059/40960 [01:13<00:22, 433.77batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 31059/40960 [01:13<00:22, 433.77batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 31146/40960 [01:13<00:22, 433.80batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 31146/40960 [01:13<00:22, 433.80batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 31234/40960 [01:13<00:22, 435.16batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 31234/40960 [01:13<00:22, 435.16batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 31322/40960 [01:13<00:22, 436.53batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  76%|▊| 31322/40960 [01:13<00:22, 436.53batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  77%|▊| 31411/40960 [01:13<00:21, 437.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  77%|▊| 31411/40960 [01:13<00:21, 437.62batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  77%|▊| 31499/40960 [01:14<00:21, 437.50batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  77%|▊| 31499/40960 [01:14<00:21, 437.50batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  77%|▊| 31588/40960 [01:14<00:21, 438.86batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  77%|▊| 31588/40960 [01:14<00:21, 438.86batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  77%|▊| 31675/40960 [01:14<00:21, 436.98batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  77%|▊| 31675/40960 [01:14<00:21, 436.98batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 31762/40960 [01:14<00:21, 435.74batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 31762/40960 [01:14<00:21, 435.74batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 31847/40960 [01:14<00:21, 431.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 31847/40960 [01:14<00:21, 431.30batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 31933/40960 [01:15<00:20, 430.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 31933/40960 [01:15<00:20, 430.13batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 32018/40960 [01:15<00:20, 428.58batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 32018/40960 [01:15<00:20, 428.58batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 32107/40960 [01:15<00:20, 432.12batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  78%|▊| 32107/40960 [01:15<00:20, 432.12batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  79%|▊| 32192/40960 [01:15<00:20, 428.65batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  79%|▊| 32192/40960 [01:15<00:20, 428.65batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  79%|▊| 32275/40960 [01:15<00:20, 423.99batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  79%|▊| 32275/40960 [01:16<00:20, 423.99batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  79%|▊| 32362/40960 [01:16<00:20, 426.14batches/s, l2_loss: 0.0031 - round_los\u001b[A\n",
      "Training:  79%|▊| 32362/40960 [01:16<00:20, 426.14batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  79%|▊| 32448/40960 [01:16<00:19, 425.94batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  79%|▊| 32448/40960 [01:16<00:19, 425.94batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  79%|▊| 32536/40960 [01:16<00:19, 429.97batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  79%|▊| 32536/40960 [01:16<00:19, 429.97batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32621/40960 [01:16<00:19, 427.14batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32621/40960 [01:16<00:19, 427.14batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32707/40960 [01:17<00:19, 426.70batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32707/40960 [01:17<00:19, 426.70batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32793/40960 [01:17<00:19, 427.62batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32793/40960 [01:17<00:19, 427.62batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32882/40960 [01:17<00:18, 431.63batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32882/40960 [01:17<00:18, 431.63batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32971/40960 [01:17<00:18, 434.88batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  80%|▊| 32971/40960 [01:17<00:18, 434.88batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  81%|▊| 33060/40960 [01:17<00:18, 436.76batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  81%|▊| 33060/40960 [01:17<00:18, 436.76batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  81%|▊| 33145/40960 [01:18<00:18, 431.97batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  81%|▊| 33145/40960 [01:18<00:18, 431.97batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  81%|▊| 33235/40960 [01:18<00:17, 436.02batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  81%|▊| 33235/40960 [01:18<00:17, 436.02batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  81%|▊| 33322/40960 [01:18<00:17, 435.61batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  81%|▊| 33322/40960 [01:18<00:17, 435.61batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33410/40960 [01:18<00:17, 435.87batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33410/40960 [01:18<00:17, 435.87batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33499/40960 [01:18<00:17, 437.69batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33499/40960 [01:18<00:17, 437.69batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33585/40960 [01:19<00:16, 434.53batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33585/40960 [01:19<00:16, 434.53batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33674/40960 [01:19<00:16, 437.07batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33674/40960 [01:19<00:16, 437.07batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33760/40960 [01:19<00:16, 433.65batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  82%|▊| 33760/40960 [01:19<00:16, 433.65batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 33841/40960 [01:19<00:16, 423.42batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 33841/40960 [01:19<00:16, 423.42batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 33926/40960 [01:19<00:16, 423.10batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 33926/40960 [01:19<00:16, 423.10batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 34014/40960 [01:20<00:16, 427.02batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 34014/40960 [01:20<00:16, 427.02batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 34103/40960 [01:20<00:15, 431.28batches/s, l2_loss: 0.0032 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 34103/40960 [01:20<00:15, 431.28batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 34190/40960 [01:20<00:15, 432.08batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  83%|▊| 34190/40960 [01:20<00:15, 432.08batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34275/40960 [01:20<00:15, 428.81batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34275/40960 [01:20<00:15, 428.81batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34350/40960 [01:20<00:16, 411.28batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34350/40960 [01:20<00:16, 411.28batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34431/40960 [01:21<00:15, 408.26batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34431/40960 [01:21<00:15, 408.26batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34518/40960 [01:21<00:15, 415.31batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34518/40960 [01:21<00:15, 415.31batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34603/40960 [01:21<00:15, 417.57batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  84%|▊| 34603/40960 [01:21<00:15, 417.57batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [01:21<00:14, 426.43batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [01:21<00:14, 426.43batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34771/40960 [01:21<00:14, 414.86batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34771/40960 [01:21<00:14, 414.86batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34853/40960 [01:22<00:14, 412.47batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34853/40960 [01:22<00:14, 412.47batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34928/40960 [01:22<00:15, 400.87batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34928/40960 [01:22<00:15, 400.87batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34986/40960 [01:22<00:16, 365.66batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  85%|▊| 34986/40960 [01:22<00:16, 365.66batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35041/40960 [01:22<00:17, 338.52batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35041/40960 [01:22<00:17, 338.52batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35108/40960 [01:22<00:17, 336.97batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35108/40960 [01:22<00:17, 336.97batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35186/40960 [01:23<00:16, 352.03batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35186/40960 [01:23<00:16, 352.03batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35254/40960 [01:23<00:16, 348.18batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35254/40960 [01:23<00:16, 348.18batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35325/40960 [01:23<00:16, 349.21batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35325/40960 [01:23<00:16, 349.21batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35390/40960 [01:23<00:16, 341.26batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  86%|▊| 35390/40960 [01:23<00:16, 341.26batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35468/40960 [01:23<00:15, 354.99batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35468/40960 [01:23<00:15, 354.99batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35545/40960 [01:24<00:14, 363.33batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35545/40960 [01:24<00:14, 363.33batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35627/40960 [01:24<00:14, 377.11batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35627/40960 [01:24<00:14, 377.11batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35706/40960 [01:24<00:13, 381.19batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35706/40960 [01:24<00:13, 381.19batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35790/40960 [01:24<00:13, 392.38batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  87%|▊| 35790/40960 [01:24<00:13, 392.38batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 35868/40960 [01:24<00:13, 391.09batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 35868/40960 [01:24<00:13, 391.09batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 35946/40960 [01:25<00:12, 390.70batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 35946/40960 [01:25<00:12, 390.70batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 36034/40960 [01:25<00:12, 404.42batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 36034/40960 [01:25<00:12, 404.42batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 36118/40960 [01:25<00:11, 408.82batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 36118/40960 [01:25<00:11, 408.82batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 36199/40960 [01:25<00:11, 406.34batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  88%|▉| 36199/40960 [01:25<00:11, 406.34batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36288/40960 [01:25<00:11, 416.73batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36288/40960 [01:25<00:11, 416.73batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36374/40960 [01:26<00:10, 420.41batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36374/40960 [01:26<00:10, 420.41batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36462/40960 [01:26<00:10, 425.11batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36462/40960 [01:26<00:10, 425.11batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36550/40960 [01:26<00:10, 428.47batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36550/40960 [01:26<00:10, 428.47batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36640/40960 [01:26<00:09, 433.25batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  89%|▉| 36640/40960 [01:26<00:09, 433.25batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  90%|▉| 36722/40960 [01:26<00:09, 425.75batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  90%|▉| 36722/40960 [01:26<00:09, 425.75batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  90%|▉| 36805/40960 [01:27<00:09, 421.42batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  90%|▉| 36805/40960 [01:27<00:09, 421.42batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  90%|▉| 36892/40960 [01:27<00:09, 424.32batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  90%|▉| 36892/40960 [01:27<00:09, 424.32batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  90%|▉| 36982/40960 [01:27<00:09, 431.72batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  90%|▉| 36982/40960 [01:27<00:09, 431.72batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [01:27<00:08, 433.40batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37070/40960 [01:27<00:08, 433.40batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37159/40960 [01:27<00:08, 436.54batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37159/40960 [01:27<00:08, 436.54batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37248/40960 [01:28<00:08, 438.36batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37248/40960 [01:28<00:08, 438.36batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37336/40960 [01:28<00:08, 438.44batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37336/40960 [01:28<00:08, 438.44batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37424/40960 [01:28<00:08, 437.22batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  91%|▉| 37424/40960 [01:28<00:08, 437.22batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37513/40960 [01:28<00:07, 438.66batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37513/40960 [01:28<00:07, 438.66batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37602/40960 [01:28<00:07, 439.12batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37602/40960 [01:28<00:07, 439.12batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37688/40960 [01:29<00:07, 435.81batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37688/40960 [01:29<00:07, 435.81batches/s, l2_loss: 0.0032 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37778/40960 [01:29<00:07, 439.37batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37778/40960 [01:29<00:07, 439.37batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37863/40960 [01:29<00:07, 434.82batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  92%|▉| 37863/40960 [01:29<00:07, 434.82batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  93%|▉| 37949/40960 [01:29<00:06, 433.27batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  93%|▉| 37949/40960 [01:29<00:06, 433.27batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  93%|▉| 38039/40960 [01:29<00:06, 437.58batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  93%|▉| 38039/40960 [01:29<00:06, 437.58batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  93%|▉| 38128/40960 [01:30<00:06, 438.58batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  93%|▉| 38128/40960 [01:30<00:06, 438.58batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  93%|▉| 38215/40960 [01:30<00:06, 436.15batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  93%|▉| 38215/40960 [01:30<00:06, 436.15batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38304/40960 [01:30<00:06, 438.61batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38304/40960 [01:30<00:06, 438.61batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38393/40960 [01:30<00:05, 439.32batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38393/40960 [01:30<00:05, 439.32batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38481/40960 [01:30<00:05, 437.91batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38481/40960 [01:30<00:05, 437.91batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38567/40960 [01:31<00:05, 434.62batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38567/40960 [01:31<00:05, 434.62batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38656/40960 [01:31<00:05, 436.51batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  94%|▉| 38656/40960 [01:31<00:05, 436.51batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 38746/40960 [01:31<00:05, 440.11batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 38746/40960 [01:31<00:05, 440.11batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 38835/40960 [01:31<00:04, 441.37batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 38835/40960 [01:31<00:04, 441.37batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 38924/40960 [01:31<00:04, 441.31batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 38924/40960 [01:31<00:04, 441.31batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 39012/40960 [01:32<00:04, 439.40batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 39012/40960 [01:32<00:04, 439.40batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 39097/40960 [01:32<00:04, 434.16batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  95%|▉| 39097/40960 [01:32<00:04, 434.16batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  96%|▉| 39184/40960 [01:32<00:04, 432.40batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  96%|▉| 39184/40960 [01:32<00:04, 432.40batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  96%|▉| 39273/40960 [01:32<00:03, 435.84batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  96%|▉| 39273/40960 [01:32<00:03, 435.84batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  96%|▉| 39356/40960 [01:32<00:03, 428.70batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  96%|▉| 39356/40960 [01:32<00:03, 428.70batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  96%|▉| 39445/40960 [01:33<00:03, 432.63batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  96%|▉| 39445/40960 [01:33<00:03, 432.63batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39532/40960 [01:33<00:03, 433.05batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39532/40960 [01:33<00:03, 433.05batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39620/40960 [01:33<00:03, 434.32batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39620/40960 [01:33<00:03, 434.32batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39709/40960 [01:33<00:02, 436.49batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39709/40960 [01:33<00:02, 436.49batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39799/40960 [01:33<00:02, 439.91batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39799/40960 [01:33<00:02, 439.91batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39886/40960 [01:34<00:02, 437.15batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  97%|▉| 39886/40960 [01:34<00:02, 437.15batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 39976/40960 [01:34<00:02, 440.69batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 39976/40960 [01:34<00:02, 440.69batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 40067/40960 [01:34<00:02, 443.61batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 40067/40960 [01:34<00:02, 443.61batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 40156/40960 [01:34<00:01, 443.59batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 40156/40960 [01:34<00:01, 443.59batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 40246/40960 [01:34<00:01, 444.10batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 40246/40960 [01:34<00:01, 444.10batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 40335/40960 [01:35<00:01, 443.68batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  98%|▉| 40335/40960 [01:35<00:01, 443.68batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  99%|▉| 40423/40960 [01:35<00:01, 441.58batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  99%|▉| 40423/40960 [01:35<00:01, 441.58batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  99%|▉| 40509/40960 [01:35<00:01, 437.88batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  99%|▉| 40509/40960 [01:35<00:01, 437.88batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  99%|▉| 40593/40960 [01:35<00:00, 431.85batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  99%|▉| 40593/40960 [01:35<00:00, 431.85batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  99%|▉| 40683/40960 [01:35<00:00, 435.96batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training:  99%|▉| 40683/40960 [01:35<00:00, 435.96batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training: 100%|▉| 40769/40960 [01:36<00:00, 433.88batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training: 100%|▉| 40769/40960 [01:36<00:00, 433.88batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training: 100%|▉| 40856/40960 [01:36<00:00, 433.05batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training: 100%|▉| 40856/40960 [01:36<00:00, 433.05batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training: 100%|▉| 40944/40960 [01:36<00:00, 435.00batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "Training: 100%|▉| 40944/40960 [01:36<00:00, 435.00batches/s, l2_loss: 0.0032 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-05-20 19:01:12.531619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  33%|▎| 1/3 [01:43<03:26, 103.00s/blocks, Layers=['model_cnn21/conv2_output_0'2025-05-20 19:01:14.205962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-05-20 19:01:17.355342: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<11:48:03,  1.04s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<11:48:03,  1.04s/batches, l2_loss: 0.0473 - round_loss:\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%| | 93/40960 [00:01<06:48, 99.95batches/s, l2_loss: 0.0473 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 93/40960 [00:01<06:48, 99.95batches/s, l2_loss: 0.0352 - round_loss: 0\u001b[A\n",
      "Training:   0%| | 189/40960 [00:01<03:35, 189.28batches/s, l2_loss: 0.0352 - round_loss:\u001b[A\n",
      "Training:   0%| | 189/40960 [00:01<03:35, 189.28batches/s, l2_loss: 0.0301 - round_loss:\u001b[A\n",
      "Training:   1%| | 280/40960 [00:01<02:39, 255.60batches/s, l2_loss: 0.0301 - round_loss:\u001b[A\n",
      "Training:   1%| | 280/40960 [00:01<02:39, 255.60batches/s, l2_loss: 0.0271 - round_loss:\u001b[A\n",
      "Training:   1%| | 373/40960 [00:01<02:10, 310.83batches/s, l2_loss: 0.0271 - round_loss:\u001b[A\n",
      "Training:   1%| | 373/40960 [00:01<02:10, 310.83batches/s, l2_loss: 0.0250 - round_loss:\u001b[A\n",
      "Training:   1%| | 469/40960 [00:02<01:53, 356.65batches/s, l2_loss: 0.0250 - round_loss:\u001b[A\n",
      "Training:   1%| | 469/40960 [00:02<01:53, 356.65batches/s, l2_loss: 0.0235 - round_loss:\u001b[A\n",
      "Training:   1%| | 556/40960 [00:02<01:46, 377.64batches/s, l2_loss: 0.0235 - round_loss:\u001b[A\n",
      "Training:   1%| | 556/40960 [00:02<01:46, 377.64batches/s, l2_loss: 0.0223 - round_loss:\u001b[A\n",
      "Training:   2%| | 652/40960 [00:02<01:39, 405.96batches/s, l2_loss: 0.0223 - round_loss:\u001b[A\n",
      "Training:   2%| | 652/40960 [00:02<01:39, 405.96batches/s, l2_loss: 0.0213 - round_loss:\u001b[A\n",
      "Training:   2%| | 741/40960 [00:02<01:36, 416.07batches/s, l2_loss: 0.0213 - round_loss:\u001b[A\n",
      "Training:   2%| | 741/40960 [00:02<01:36, 416.07batches/s, l2_loss: 0.0205 - round_loss:\u001b[A\n",
      "Training:   2%| | 830/40960 [00:02<01:34, 424.12batches/s, l2_loss: 0.0205 - round_loss:\u001b[A\n",
      "Training:   2%| | 830/40960 [00:02<01:34, 424.12batches/s, l2_loss: 0.0198 - round_loss:\u001b[A\n",
      "Training:   2%| | 920/40960 [00:03<01:32, 431.64batches/s, l2_loss: 0.0198 - round_loss:\u001b[A\n",
      "Training:   2%| | 920/40960 [00:03<01:32, 431.64batches/s, l2_loss: 0.0192 - round_loss:\u001b[A\n",
      "Training:   2%| | 1015/40960 [00:03<01:29, 444.02batches/s, l2_loss: 0.0192 - round_loss\u001b[A\n",
      "Training:   2%| | 1015/40960 [00:03<01:29, 444.02batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:   3%| | 1110/40960 [00:03<01:28, 452.11batches/s, l2_loss: 0.0187 - round_loss\u001b[A\n",
      "Training:   3%| | 1110/40960 [00:03<01:28, 452.11batches/s, l2_loss: 0.0182 - round_loss\u001b[A\n",
      "Training:   3%| | 1205/40960 [00:03<01:26, 457.82batches/s, l2_loss: 0.0182 - round_loss\u001b[A\n",
      "Training:   3%| | 1205/40960 [00:03<01:26, 457.82batches/s, l2_loss: 0.0177 - round_loss\u001b[A\n",
      "Training:   3%| | 1294/40960 [00:03<01:27, 453.98batches/s, l2_loss: 0.0177 - round_loss\u001b[A\n",
      "Training:   3%| | 1294/40960 [00:03<01:27, 453.98batches/s, l2_loss: 0.0174 - round_loss\u001b[A\n",
      "Training:   3%| | 1387/40960 [00:04<01:26, 456.29batches/s, l2_loss: 0.0174 - round_loss\u001b[A\n",
      "Training:   3%| | 1387/40960 [00:04<01:26, 456.29batches/s, l2_loss: 0.0170 - round_loss\u001b[A\n",
      "Training:   4%| | 1478/40960 [00:04<01:26, 455.67batches/s, l2_loss: 0.0170 - round_loss\u001b[A\n",
      "Training:   4%| | 1478/40960 [00:04<01:26, 455.67batches/s, l2_loss: 0.0167 - round_loss\u001b[A\n",
      "Training:   4%| | 1573/40960 [00:04<01:25, 460.23batches/s, l2_loss: 0.0167 - round_loss\u001b[A\n",
      "Training:   4%| | 1573/40960 [00:04<01:25, 460.23batches/s, l2_loss: 0.0164 - round_loss\u001b[A\n",
      "Training:   4%| | 1664/40960 [00:04<01:25, 458.40batches/s, l2_loss: 0.0164 - round_loss\u001b[A\n",
      "Training:   4%| | 1664/40960 [00:04<01:25, 458.40batches/s, l2_loss: 0.0161 - round_loss\u001b[A\n",
      "Training:   4%| | 1758/40960 [00:04<01:25, 461.17batches/s, l2_loss: 0.0161 - round_loss\u001b[A\n",
      "Training:   4%| | 1758/40960 [00:04<01:25, 461.17batches/s, l2_loss: 0.0158 - round_loss\u001b[A\n",
      "Training:   5%| | 1845/40960 [00:05<01:26, 453.18batches/s, l2_loss: 0.0158 - round_loss\u001b[A\n",
      "Training:   5%| | 1845/40960 [00:05<01:26, 453.18batches/s, l2_loss: 0.0156 - round_loss\u001b[A\n",
      "Training:   5%| | 1931/40960 [00:05<01:27, 445.96batches/s, l2_loss: 0.0156 - round_loss\u001b[A\n",
      "Training:   5%| | 1931/40960 [00:05<01:27, 445.96batches/s, l2_loss: 0.0154 - round_loss\u001b[A\n",
      "Training:   5%| | 2020/40960 [00:05<01:27, 445.40batches/s, l2_loss: 0.0154 - round_loss\u001b[A\n",
      "Training:   5%| | 2020/40960 [00:05<01:27, 445.40batches/s, l2_loss: 0.0152 - round_loss\u001b[A\n",
      "Training:   5%| | 2110/40960 [00:05<01:27, 446.40batches/s, l2_loss: 0.0152 - round_loss\u001b[A\n",
      "Training:   5%| | 2110/40960 [00:05<01:27, 446.40batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:   5%| | 2203/40960 [00:05<01:25, 450.94batches/s, l2_loss: 0.0150 - round_loss\u001b[A\n",
      "Training:   5%| | 2203/40960 [00:05<01:25, 450.94batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:   6%| | 2298/40960 [00:06<01:24, 457.73batches/s, l2_loss: 0.0148 - round_loss\u001b[A\n",
      "Training:   6%| | 2298/40960 [00:06<01:24, 457.73batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:   6%| | 2394/40960 [00:06<01:23, 462.88batches/s, l2_loss: 0.0146 - round_loss\u001b[A\n",
      "Training:   6%| | 2394/40960 [00:06<01:23, 462.88batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:   6%| | 2485/40960 [00:06<01:23, 459.06batches/s, l2_loss: 0.0145 - round_loss\u001b[A\n",
      "Training:   6%| | 2485/40960 [00:06<01:23, 459.06batches/s, l2_loss: 0.0143 - round_loss\u001b[A\n",
      "Training:   6%| | 2577/40960 [00:06<01:23, 459.26batches/s, l2_loss: 0.0143 - round_loss\u001b[A\n",
      "Training:   6%| | 2577/40960 [00:06<01:23, 459.26batches/s, l2_loss: 0.0141 - round_loss\u001b[A\n",
      "Training:   7%| | 2670/40960 [00:06<01:23, 459.78batches/s, l2_loss: 0.0141 - round_loss\u001b[A\n",
      "Training:   7%| | 2670/40960 [00:06<01:23, 459.78batches/s, l2_loss: 0.0140 - round_loss\u001b[A\n",
      "Training:   7%| | 2766/40960 [00:07<01:22, 464.91batches/s, l2_loss: 0.0140 - round_loss\u001b[A\n",
      "Training:   7%| | 2766/40960 [00:07<01:22, 464.91batches/s, l2_loss: 0.0139 - round_loss\u001b[A\n",
      "Training:   7%| | 2862/40960 [00:07<01:21, 469.01batches/s, l2_loss: 0.0139 - round_loss\u001b[A\n",
      "Training:   7%| | 2862/40960 [00:07<01:21, 469.01batches/s, l2_loss: 0.0137 - round_loss\u001b[A\n",
      "Training:   7%| | 2959/40960 [00:07<01:20, 473.10batches/s, l2_loss: 0.0137 - round_loss\u001b[A\n",
      "Training:   7%| | 2959/40960 [00:07<01:20, 473.10batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:   7%| | 3056/40960 [00:07<01:19, 475.70batches/s, l2_loss: 0.0136 - round_loss\u001b[A\n",
      "Training:   7%| | 3056/40960 [00:07<01:19, 475.70batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   8%| | 3150/40960 [00:07<01:19, 472.69batches/s, l2_loss: 0.0135 - round_loss\u001b[A\n",
      "Training:   8%| | 3150/40960 [00:07<01:19, 472.69batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   8%| | 3242/40960 [00:08<01:20, 468.63batches/s, l2_loss: 0.0134 - round_loss\u001b[A\n",
      "Training:   8%| | 3242/40960 [00:08<01:20, 468.63batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   8%| | 3337/40960 [00:08<01:20, 469.81batches/s, l2_loss: 0.0132 - round_loss\u001b[A\n",
      "Training:   8%| | 3337/40960 [00:08<01:20, 469.81batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:   8%| | 3434/40960 [00:08<01:19, 473.17batches/s, l2_loss: 0.0131 - round_loss\u001b[A\n",
      "Training:   8%| | 3434/40960 [00:08<01:19, 473.17batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:   9%| | 3532/40960 [00:08<01:18, 477.58batches/s, l2_loss: 0.0130 - round_loss\u001b[A\n",
      "Training:   9%| | 3532/40960 [00:08<01:18, 477.58batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:   9%| | 3630/40960 [00:08<01:17, 480.04batches/s, l2_loss: 0.0129 - round_loss\u001b[A\n",
      "Training:   9%| | 3630/40960 [00:08<01:17, 480.04batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:   9%| | 3726/40960 [00:09<01:17, 479.72batches/s, l2_loss: 0.0128 - round_loss\u001b[A\n",
      "Training:   9%| | 3726/40960 [00:09<01:17, 479.72batches/s, l2_loss: 0.0127 - round_loss\u001b[A\n",
      "Training:   9%| | 3815/40960 [00:09<01:19, 469.12batches/s, l2_loss: 0.0127 - round_loss\u001b[A\n",
      "Training:   9%| | 3815/40960 [00:09<01:19, 469.12batches/s, l2_loss: 0.0127 - round_loss\u001b[A\n",
      "Training:  10%| | 3909/40960 [00:09<01:19, 468.71batches/s, l2_loss: 0.0127 - round_loss\u001b[A\n",
      "Training:  10%| | 3909/40960 [00:09<01:19, 468.71batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:  10%| | 4002/40960 [00:09<01:19, 466.30batches/s, l2_loss: 0.0126 - round_loss\u001b[A\n",
      "Training:  10%| | 4002/40960 [00:09<01:19, 466.30batches/s, l2_loss: 0.0125 - round_loss\u001b[A\n",
      "Training:  10%| | 4095/40960 [00:09<01:19, 465.56batches/s, l2_loss: 0.0125 - round_loss\u001b[A\n",
      "Training:  10%| | 4095/40960 [00:09<01:19, 465.56batches/s, l2_loss: 0.0124 - round_loss\u001b[A\n",
      "Training:  10%| | 4187/40960 [00:10<01:19, 463.73batches/s, l2_loss: 0.0124 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%| | 4187/40960 [00:10<01:19, 463.73batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:  10%| | 4281/40960 [00:10<01:18, 465.51batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:  10%| | 4281/40960 [00:10<01:18, 465.51batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:  11%| | 4373/40960 [00:10<01:18, 463.69batches/s, l2_loss: 0.0123 - round_loss\u001b[A\n",
      "Training:  11%| | 4373/40960 [00:10<01:18, 463.69batches/s, l2_loss: 0.0122 - round_loss\u001b[A\n",
      "Training:  11%| | 4461/40960 [00:10<01:20, 455.93batches/s, l2_loss: 0.0122 - round_loss\u001b[A\n",
      "Training:  11%| | 4461/40960 [00:10<01:20, 455.93batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:  11%| | 4545/40960 [00:10<01:21, 444.24batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:  11%| | 4545/40960 [00:10<01:21, 444.24batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:  11%| | 4630/40960 [00:11<01:22, 437.86batches/s, l2_loss: 0.0121 - round_loss\u001b[A\n",
      "Training:  11%| | 4630/40960 [00:11<01:22, 437.86batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:  12%| | 4723/40960 [00:11<01:21, 445.13batches/s, l2_loss: 0.0120 - round_loss\u001b[A\n",
      "Training:  12%| | 4723/40960 [00:11<01:21, 445.13batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:  12%| | 4815/40960 [00:11<01:20, 449.26batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:  12%| | 4815/40960 [00:11<01:20, 449.26batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:  12%| | 4909/40960 [00:11<01:19, 455.19batches/s, l2_loss: 0.0119 - round_loss\u001b[A\n",
      "Training:  12%| | 4909/40960 [00:11<01:19, 455.19batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  12%| | 4999/40960 [00:11<01:19, 453.10batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  12%| | 4999/40960 [00:11<01:19, 453.10batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  12%| | 5078/40960 [00:12<01:22, 435.13batches/s, l2_loss: 0.0118 - round_loss\u001b[A\n",
      "Training:  12%| | 5078/40960 [00:12<01:22, 435.13batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5169/40960 [00:12<01:21, 440.30batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5169/40960 [00:12<01:21, 440.30batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5256/40960 [00:12<01:21, 437.55batches/s, l2_loss: 0.0117 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5256/40960 [00:12<01:21, 437.55batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5351/40960 [00:12<01:19, 447.75batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5351/40960 [00:12<01:19, 447.75batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5449/40960 [00:12<01:17, 459.25batches/s, l2_loss: 0.0116 - round_loss\u001b[A\n",
      "Training:  13%|▏| 5449/40960 [00:12<01:17, 459.25batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5547/40960 [00:13<01:15, 467.23batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5547/40960 [00:13<01:15, 467.23batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5643/40960 [00:13<01:15, 469.83batches/s, l2_loss: 0.0115 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5643/40960 [00:13<01:15, 469.83batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5736/40960 [00:13<01:15, 468.01batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5736/40960 [00:13<01:15, 468.01batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5830/40960 [00:13<01:15, 467.48batches/s, l2_loss: 0.0114 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5830/40960 [00:13<01:15, 467.48batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5928/40960 [00:13<01:13, 474.17batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  14%|▏| 5928/40960 [00:13<01:13, 474.17batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6023/40960 [00:14<01:13, 474.34batches/s, l2_loss: 0.0113 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6023/40960 [00:14<01:13, 474.34batches/s, l2_loss: 0.0112 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6120/40960 [00:14<01:12, 477.32batches/s, l2_loss: 0.0112 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6120/40960 [00:14<01:12, 477.32batches/s, l2_loss: 0.0112 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6215/40960 [00:14<01:13, 475.77batches/s, l2_loss: 0.0112 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6215/40960 [00:14<01:13, 475.77batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6312/40960 [00:14<01:12, 477.17batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  15%|▏| 6312/40960 [00:14<01:12, 477.17batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6407/40960 [00:14<01:12, 475.73batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6407/40960 [00:14<01:12, 475.73batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6499/40960 [00:15<01:13, 470.63batches/s, l2_loss: 0.0111 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6499/40960 [00:15<01:13, 470.63batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6595/40960 [00:15<01:12, 472.56batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6595/40960 [00:15<01:12, 472.56batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6690/40960 [00:15<01:12, 472.12batches/s, l2_loss: 0.0110 - round_loss\u001b[A\n",
      "Training:  16%|▏| 6690/40960 [00:15<01:12, 472.12batches/s, l2_loss: 0.0109 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6784/40960 [00:15<01:12, 470.20batches/s, l2_loss: 0.0109 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6784/40960 [00:15<01:12, 470.20batches/s, l2_loss: 0.0109 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6879/40960 [00:15<01:12, 471.58batches/s, l2_loss: 0.0109 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6879/40960 [00:15<01:12, 471.58batches/s, l2_loss: 0.0109 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6976/40960 [00:16<01:11, 475.44batches/s, l2_loss: 0.0109 - round_loss\u001b[A\n",
      "Training:  17%|▏| 6976/40960 [00:16<01:11, 475.44batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7073/40960 [00:16<01:11, 477.26batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  17%|▏| 7073/40960 [00:16<01:11, 477.26batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7170/40960 [00:16<01:10, 479.17batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7170/40960 [00:16<01:10, 479.17batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7267/40960 [00:16<01:10, 480.91batches/s, l2_loss: 0.0108 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7267/40960 [00:16<01:10, 480.91batches/s, l2_loss: 0.0107 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7363/40960 [00:16<01:10, 479.58batches/s, l2_loss: 0.0107 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7363/40960 [00:16<01:10, 479.58batches/s, l2_loss: 0.0107 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7457/40960 [00:17<01:10, 476.12batches/s, l2_loss: 0.0107 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7457/40960 [00:17<01:10, 476.12batches/s, l2_loss: 0.0107 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7550/40960 [00:17<01:10, 472.68batches/s, l2_loss: 0.0107 - round_loss\u001b[A\n",
      "Training:  18%|▏| 7550/40960 [00:17<01:10, 472.68batches/s, l2_loss: 0.0106 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7641/40960 [00:17<01:11, 466.98batches/s, l2_loss: 0.0106 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7641/40960 [00:17<01:11, 466.98batches/s, l2_loss: 0.0106 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7735/40960 [00:17<01:11, 467.40batches/s, l2_loss: 0.0106 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7735/40960 [00:17<01:11, 467.40batches/s, l2_loss: 0.0106 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7831/40960 [00:17<01:10, 471.13batches/s, l2_loss: 0.0106 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7831/40960 [00:17<01:10, 471.13batches/s, l2_loss: 0.0105 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7926/40960 [00:18<01:10, 471.57batches/s, l2_loss: 0.0105 - round_loss\u001b[A\n",
      "Training:  19%|▏| 7926/40960 [00:18<01:10, 471.57batches/s, l2_loss: 0.0105 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8024/40960 [00:18<01:09, 477.01batches/s, l2_loss: 0.0105 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8024/40960 [00:18<01:09, 477.01batches/s, l2_loss: 0.0105 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8121/40960 [00:18<01:08, 479.13batches/s, l2_loss: 0.0105 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8121/40960 [00:18<01:08, 479.13batches/s, l2_loss: 0.0105 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8212/40960 [00:18<01:09, 471.76batches/s, l2_loss: 0.0105 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8212/40960 [00:18<01:09, 471.76batches/s, l2_loss: 0.0084 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8299/40960 [00:18<01:11, 459.35batches/s, l2_loss: 0.0084 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8299/40960 [00:18<01:11, 459.35batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|▏| 8385/40960 [00:19<01:12, 449.01batches/s, l2_loss: 0.0088 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8385/40960 [00:19<01:12, 449.01batches/s, l2_loss: 0.0094 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8471/40960 [00:19<01:13, 443.26batches/s, l2_loss: 0.0094 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8471/40960 [00:19<01:13, 443.26batches/s, l2_loss: 0.0097 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8556/40960 [00:19<01:14, 436.53batches/s, l2_loss: 0.0097 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8556/40960 [00:19<01:14, 436.53batches/s, l2_loss: 0.0097 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8642/40960 [00:19<01:14, 433.58batches/s, l2_loss: 0.0097 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8642/40960 [00:19<01:14, 433.58batches/s, l2_loss: 0.0098 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8729/40960 [00:19<01:14, 433.87batches/s, l2_loss: 0.0098 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8729/40960 [00:19<01:14, 433.87batches/s, l2_loss: 0.0098 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8819/40960 [00:20<01:13, 437.30batches/s, l2_loss: 0.0098 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8819/40960 [00:20<01:13, 437.30batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8906/40960 [00:20<01:13, 436.53batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8906/40960 [00:20<01:13, 436.53batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8994/40960 [00:20<01:13, 436.91batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8994/40960 [00:20<01:13, 436.91batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9078/40960 [00:20<01:13, 431.20batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9078/40960 [00:20<01:13, 431.20batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9164/40960 [00:20<01:13, 430.65batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9164/40960 [00:20<01:13, 430.65batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9249/40960 [00:21<01:13, 428.88batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9249/40960 [00:21<01:13, 428.88batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9337/40960 [00:21<01:13, 431.66batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9337/40960 [00:21<01:13, 431.66batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9426/40960 [00:21<01:12, 434.22batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9426/40960 [00:21<01:12, 434.22batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9510/40960 [00:21<01:13, 428.96batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9510/40960 [00:21<01:13, 428.96batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9592/40960 [00:21<01:14, 422.01batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9592/40960 [00:21<01:14, 422.01batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9672/40960 [00:22<01:15, 415.06batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9672/40960 [00:22<01:15, 415.06batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9757/40960 [00:22<01:14, 416.73batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9757/40960 [00:22<01:14, 416.73batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9841/40960 [00:22<01:14, 416.68batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9841/40960 [00:22<01:14, 416.68batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9923/40960 [00:22<01:14, 414.44batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9923/40960 [00:22<01:14, 414.44batches/s, l2_loss: 0.0099 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10010/40960 [00:22<01:13, 419.61batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  24%|▏| 10010/40960 [00:22<01:13, 419.61batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  25%|▏| 10097/40960 [00:23<01:12, 424.13batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  25%|▏| 10097/40960 [00:23<01:12, 424.13batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  25%|▏| 10184/40960 [00:23<01:12, 426.19batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  25%|▏| 10184/40960 [00:23<01:12, 426.19batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  25%|▎| 10273/40960 [00:23<01:11, 431.62batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  25%|▎| 10273/40960 [00:23<01:11, 431.62batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  25%|▎| 10360/40960 [00:23<01:10, 432.62batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  25%|▎| 10360/40960 [00:23<01:10, 432.62batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10445/40960 [00:23<01:11, 429.65batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10445/40960 [00:23<01:11, 429.65batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10533/40960 [00:24<01:10, 432.35batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10533/40960 [00:24<01:10, 432.35batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10622/40960 [00:24<01:09, 434.99batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10622/40960 [00:24<01:09, 434.99batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10708/40960 [00:24<01:09, 432.66batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10708/40960 [00:24<01:09, 432.66batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10796/40960 [00:24<01:09, 434.09batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  26%|▎| 10796/40960 [00:24<01:09, 434.09batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 10881/40960 [00:24<01:09, 430.19batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 10881/40960 [00:24<01:09, 430.19batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 10966/40960 [00:25<01:10, 428.23batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 10966/40960 [00:25<01:10, 428.23batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 11052/40960 [00:25<01:09, 427.55batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 11052/40960 [00:25<01:09, 427.55batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 11135/40960 [00:25<01:10, 423.45batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 11135/40960 [00:25<01:10, 423.45batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 11216/40960 [00:25<01:11, 417.16batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  27%|▎| 11216/40960 [00:25<01:11, 417.16batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11299/40960 [00:25<01:11, 416.43batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11299/40960 [00:25<01:11, 416.43batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11386/40960 [00:26<01:10, 421.71batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11386/40960 [00:26<01:10, 421.71batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11470/40960 [00:26<01:10, 418.59batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11470/40960 [00:26<01:10, 418.59batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11547/40960 [00:26<01:12, 408.49batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11547/40960 [00:26<01:12, 408.49batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11626/40960 [00:26<01:12, 403.54batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  28%|▎| 11626/40960 [00:26<01:12, 403.54batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 11697/40960 [00:26<01:15, 388.56batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 11697/40960 [00:26<01:15, 388.56batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 11773/40960 [00:27<01:15, 385.50batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 11773/40960 [00:27<01:15, 385.50batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 11857/40960 [00:27<01:13, 394.46batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 11857/40960 [00:27<01:13, 394.46batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 11944/40960 [00:27<01:11, 406.32batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 11944/40960 [00:27<01:11, 406.32batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 12030/40960 [00:27<01:10, 413.20batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  29%|▎| 12030/40960 [00:27<01:10, 413.20batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12111/40960 [00:27<01:10, 408.62batches/s, l2_loss: 0.0099 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|▎| 12111/40960 [00:27<01:10, 408.62batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12197/40960 [00:28<01:09, 414.17batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12197/40960 [00:28<01:09, 414.17batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12278/40960 [00:28<01:09, 410.30batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12278/40960 [00:28<01:09, 410.30batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12364/40960 [00:28<01:08, 415.03batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12364/40960 [00:28<01:08, 415.03batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12441/40960 [00:28<01:10, 404.64batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  30%|▎| 12441/40960 [00:28<01:10, 404.64batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12515/40960 [00:28<01:12, 393.56batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12515/40960 [00:28<01:12, 393.56batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12596/40960 [00:29<01:11, 396.37batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12596/40960 [00:29<01:11, 396.37batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12680/40960 [00:29<01:10, 402.65batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12680/40960 [00:29<01:10, 402.65batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12765/40960 [00:29<01:08, 409.05batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12765/40960 [00:29<01:08, 409.05batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12847/40960 [00:29<01:08, 408.24batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  31%|▎| 12847/40960 [00:29<01:08, 408.24batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 12933/40960 [00:29<01:07, 414.54batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 12933/40960 [00:29<01:07, 414.54batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 13017/40960 [00:30<01:07, 415.51batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 13017/40960 [00:30<01:07, 415.51batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 13102/40960 [00:30<01:06, 417.25batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 13102/40960 [00:30<01:06, 417.25batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 13188/40960 [00:30<01:06, 420.11batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 13188/40960 [00:30<01:06, 420.11batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 13276/40960 [00:30<01:05, 424.51batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  32%|▎| 13276/40960 [00:30<01:05, 424.51batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13362/40960 [00:30<01:04, 425.76batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13362/40960 [00:31<01:04, 425.76batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13448/40960 [00:31<01:04, 425.98batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13448/40960 [00:31<01:04, 425.98batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13534/40960 [00:31<01:04, 426.11batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13534/40960 [00:31<01:04, 426.11batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13620/40960 [00:31<01:04, 426.30batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13620/40960 [00:31<01:04, 426.30batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13708/40960 [00:31<01:03, 429.24batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  33%|▎| 13708/40960 [00:31<01:03, 429.24batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 13788/40960 [00:32<01:04, 420.35batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 13788/40960 [00:32<01:04, 420.35batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 13864/40960 [00:32<01:06, 408.15batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 13864/40960 [00:32<01:06, 408.15batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 13944/40960 [00:32<01:06, 404.70batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 13944/40960 [00:32<01:06, 404.70batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 14029/40960 [00:32<01:05, 409.80batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 14029/40960 [00:32<01:05, 409.80batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 14114/40960 [00:32<01:04, 414.13batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  34%|▎| 14114/40960 [00:32<01:04, 414.13batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14202/40960 [00:33<01:03, 420.62batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14202/40960 [00:33<01:03, 420.62batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14288/40960 [00:33<01:02, 423.38batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14288/40960 [00:33<01:02, 423.38batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14366/40960 [00:33<01:04, 412.07batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14366/40960 [00:33<01:04, 412.07batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14443/40960 [00:33<01:05, 403.53batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14443/40960 [00:33<01:05, 403.53batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14517/40960 [00:33<01:07, 392.49batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  35%|▎| 14517/40960 [00:33<01:07, 392.49batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14591/40960 [00:34<01:08, 385.07batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14591/40960 [00:34<01:08, 385.07batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14670/40960 [00:34<01:07, 387.67batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14670/40960 [00:34<01:07, 387.67batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14754/40960 [00:34<01:06, 396.41batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14754/40960 [00:34<01:06, 396.41batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14838/40960 [00:34<01:04, 402.36batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14838/40960 [00:34<01:04, 402.36batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14920/40960 [00:34<01:04, 404.19batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  36%|▎| 14920/40960 [00:34<01:04, 404.19batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  37%|▎| 14997/40960 [00:35<01:05, 397.12batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  37%|▎| 14997/40960 [00:35<01:05, 397.12batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  37%|▎| 15072/40960 [00:35<01:06, 389.49batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  37%|▎| 15072/40960 [00:35<01:06, 389.49batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  37%|▎| 15149/40960 [00:35<01:06, 387.43batches/s, l2_loss: 0.0099 - round_los\u001b[A\n",
      "Training:  37%|▎| 15149/40960 [00:35<01:06, 387.43batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  37%|▎| 15235/40960 [00:35<01:04, 399.53batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  37%|▎| 15235/40960 [00:35<01:04, 399.53batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  37%|▎| 15322/40960 [00:35<01:02, 408.88batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  37%|▎| 15322/40960 [00:35<01:02, 408.88batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15407/40960 [00:36<01:01, 413.42batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15407/40960 [00:36<01:01, 413.42batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15493/40960 [00:36<01:00, 418.27batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15493/40960 [00:36<01:00, 418.27batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15581/40960 [00:36<00:59, 423.64batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15581/40960 [00:36<00:59, 423.64batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15664/40960 [00:36<01:00, 419.73batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15664/40960 [00:36<01:00, 419.73batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15749/40960 [00:36<00:59, 420.76batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  38%|▍| 15749/40960 [00:36<00:59, 420.76batches/s, l2_loss: 0.0100 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|▍| 15833/40960 [00:37<00:59, 420.52batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 15833/40960 [00:37<00:59, 420.52batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 15917/40960 [00:37<00:59, 419.14batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 15917/40960 [00:37<00:59, 419.14batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16004/40960 [00:37<00:58, 423.19batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16004/40960 [00:37<00:58, 423.19batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16082/40960 [00:37<01:00, 412.99batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16082/40960 [00:37<01:00, 412.99batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16153/40960 [00:37<01:02, 394.56batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  39%|▍| 16153/40960 [00:37<01:02, 394.56batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16231/40960 [00:38<01:03, 391.94batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16231/40960 [00:38<01:03, 391.94batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16319/40960 [00:38<01:00, 405.10batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16319/40960 [00:38<01:00, 405.10batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16399/40960 [00:38<01:00, 403.11batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16399/40960 [00:38<01:00, 403.11batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16478/40960 [00:38<01:01, 399.61batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16478/40960 [00:38<01:01, 399.61batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16560/40960 [00:38<01:00, 401.68batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  40%|▍| 16560/40960 [00:38<01:00, 401.68batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16641/40960 [00:39<01:00, 401.78batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16641/40960 [00:39<01:00, 401.78batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16718/40960 [00:39<01:01, 395.43batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16718/40960 [00:39<01:01, 395.43batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16797/40960 [00:39<01:01, 394.18batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16797/40960 [00:39<01:01, 394.18batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16878/40960 [00:39<01:00, 397.40batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16878/40960 [00:39<01:00, 397.40batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16960/40960 [00:39<00:59, 400.16batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  41%|▍| 16960/40960 [00:39<00:59, 400.16batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17044/40960 [00:40<00:58, 405.40batches/s, l2_loss: 0.0100 - round_los\u001b[A\n",
      "Training:  42%|▍| 17044/40960 [00:40<00:58, 405.40batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17127/40960 [00:40<00:58, 407.92batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17127/40960 [00:40<00:58, 407.92batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17214/40960 [00:40<00:57, 415.30batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17214/40960 [00:40<00:57, 415.30batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17296/40960 [00:40<00:57, 412.76batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17296/40960 [00:40<00:57, 412.76batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17381/40960 [00:40<00:56, 416.29batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  42%|▍| 17381/40960 [00:40<00:56, 416.29batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17466/40960 [00:41<00:56, 418.73batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17466/40960 [00:41<00:56, 418.73batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17551/40960 [00:41<00:55, 419.42batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17551/40960 [00:41<00:55, 419.42batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17638/40960 [00:41<00:55, 423.43batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17638/40960 [00:41<00:55, 423.43batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17722/40960 [00:41<00:55, 421.15batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17722/40960 [00:41<00:55, 421.15batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17805/40960 [00:41<00:55, 419.09batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  43%|▍| 17805/40960 [00:41<00:55, 419.09batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 17889/40960 [00:42<00:55, 417.75batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 17889/40960 [00:42<00:55, 417.75batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 17970/40960 [00:42<00:55, 412.73batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 17970/40960 [00:42<00:55, 412.73batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18052/40960 [00:42<00:55, 411.05batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18052/40960 [00:42<00:55, 411.05batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18137/40960 [00:42<00:55, 413.91batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18137/40960 [00:42<00:55, 413.91batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18221/40960 [00:42<00:54, 415.69batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  44%|▍| 18221/40960 [00:42<00:54, 415.69batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  45%|▍| 18297/40960 [00:43<00:56, 404.51batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  45%|▍| 18297/40960 [00:43<00:56, 404.51batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  45%|▍| 18373/40960 [00:43<00:57, 396.04batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  45%|▍| 18373/40960 [00:43<00:57, 396.04batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  45%|▍| 18453/40960 [00:43<00:56, 396.50batches/s, l2_loss: 0.0101 - round_los\u001b[A\n",
      "Training:  45%|▍| 18453/40960 [00:43<00:56, 396.50batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  45%|▍| 18527/40960 [00:43<00:57, 387.08batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  45%|▍| 18527/40960 [00:43<00:57, 387.08batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  45%|▍| 18605/40960 [00:43<00:57, 387.77batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  45%|▍| 18605/40960 [00:43<00:57, 387.77batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18682/40960 [00:44<00:57, 386.74batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18682/40960 [00:44<00:57, 386.74batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18759/40960 [00:44<00:57, 386.12batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18759/40960 [00:44<00:57, 386.12batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18841/40960 [00:44<00:56, 392.48batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18841/40960 [00:44<00:56, 392.48batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18921/40960 [00:44<00:56, 393.38batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18921/40960 [00:44<00:56, 393.38batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18999/40960 [00:44<00:56, 391.32batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  46%|▍| 18999/40960 [00:44<00:56, 391.32batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19082/40960 [00:45<00:55, 397.71batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19082/40960 [00:45<00:55, 397.71batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19168/40960 [00:45<00:53, 406.70batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19168/40960 [00:45<00:53, 406.70batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19256/40960 [00:45<00:52, 416.59batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19256/40960 [00:45<00:52, 416.59batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19339/40960 [00:45<00:52, 414.97batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19339/40960 [00:45<00:52, 414.97batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  47%|▍| 19426/40960 [00:45<00:51, 419.62batches/s, l2_loss: 0.0102 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|▍| 19426/40960 [00:45<00:51, 419.62batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19505/40960 [00:46<00:52, 412.23batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19505/40960 [00:46<00:52, 412.23batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19588/40960 [00:46<00:51, 411.92batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19588/40960 [00:46<00:51, 411.92batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19670/40960 [00:46<00:51, 411.12batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19670/40960 [00:46<00:51, 411.12batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19746/40960 [00:46<00:52, 400.31batches/s, l2_loss: 0.0102 - round_los\u001b[A\n",
      "Training:  48%|▍| 19746/40960 [00:46<00:52, 400.31batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  48%|▍| 19821/40960 [00:46<00:53, 391.76batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  48%|▍| 19821/40960 [00:46<00:53, 391.76batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 19893/40960 [00:47<00:55, 381.10batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 19893/40960 [00:47<00:55, 381.10batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 19975/40960 [00:47<00:53, 389.72batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 19975/40960 [00:47<00:53, 389.72batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 20062/40960 [00:47<00:51, 403.11batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 20062/40960 [00:47<00:51, 403.11batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 20149/40960 [00:47<00:50, 411.68batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 20149/40960 [00:47<00:50, 411.68batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 20234/40960 [00:47<00:49, 414.59batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  49%|▍| 20234/40960 [00:47<00:49, 414.59batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▍| 20321/40960 [00:48<00:49, 420.15batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▍| 20321/40960 [00:48<00:49, 420.15batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▍| 20406/40960 [00:48<00:48, 421.60batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▍| 20406/40960 [00:48<00:48, 421.60batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▌| 20488/40960 [00:48<00:49, 417.67batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▌| 20488/40960 [00:48<00:49, 417.67batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▌| 20571/40960 [00:48<00:49, 416.00batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▌| 20571/40960 [00:48<00:49, 416.00batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▌| 20653/40960 [00:48<00:49, 413.43batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  50%|▌| 20653/40960 [00:48<00:49, 413.43batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  51%|▌| 20736/40960 [00:49<00:48, 413.16batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  51%|▌| 20736/40960 [00:49<00:48, 413.16batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  51%|▌| 20821/40960 [00:49<00:48, 415.95batches/s, l2_loss: 0.0103 - round_los\u001b[A\n",
      "Training:  51%|▌| 20821/40960 [00:49<00:48, 415.95batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  51%|▌| 20908/40960 [00:49<00:47, 421.36batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  51%|▌| 20908/40960 [00:49<00:47, 421.36batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  51%|▌| 20994/40960 [00:49<00:47, 422.98batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  51%|▌| 20994/40960 [00:49<00:47, 422.98batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  51%|▌| 21077/40960 [00:49<00:47, 419.78batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  51%|▌| 21077/40960 [00:49<00:47, 419.78batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21152/40960 [00:50<00:48, 405.32batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21152/40960 [00:50<00:48, 405.32batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21226/40960 [00:50<00:50, 393.75batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21226/40960 [00:50<00:50, 393.75batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21300/40960 [00:50<00:51, 384.37batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21300/40960 [00:50<00:51, 384.37batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21382/40960 [00:50<00:50, 390.98batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21382/40960 [00:50<00:50, 390.98batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21468/40960 [00:50<00:48, 401.49batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  52%|▌| 21468/40960 [00:50<00:48, 401.49batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  53%|▌| 21547/40960 [00:51<00:48, 399.36batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  53%|▌| 21547/40960 [00:51<00:48, 399.36batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  53%|▌| 21629/40960 [00:51<00:48, 401.52batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  53%|▌| 21629/40960 [00:51<00:48, 401.52batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  53%|▌| 21712/40960 [00:51<00:47, 404.54batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  53%|▌| 21712/40960 [00:51<00:47, 404.54batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  53%|▌| 21798/40960 [00:51<00:46, 411.53batches/s, l2_loss: 0.0104 - round_los\u001b[A\n",
      "Training:  53%|▌| 21798/40960 [00:51<00:46, 411.53batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  53%|▌| 21886/40960 [00:51<00:45, 419.11batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  53%|▌| 21886/40960 [00:51<00:45, 419.11batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 21972/40960 [00:52<00:45, 421.36batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 21972/40960 [00:52<00:45, 421.36batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 22058/40960 [00:52<00:44, 423.19batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 22058/40960 [00:52<00:44, 423.19batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 22142/40960 [00:52<00:44, 421.30batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 22142/40960 [00:52<00:44, 421.30batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 22219/40960 [00:52<00:45, 410.28batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 22219/40960 [00:52<00:45, 410.28batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 22297/40960 [00:52<00:46, 403.70batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  54%|▌| 22297/40960 [00:52<00:46, 403.70batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  55%|▌| 22384/40960 [00:53<00:45, 411.85batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  55%|▌| 22384/40960 [00:53<00:45, 411.85batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  55%|▌| 22469/40960 [00:53<00:44, 415.25batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  55%|▌| 22469/40960 [00:53<00:44, 415.25batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  55%|▌| 22558/40960 [00:53<00:43, 423.94batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  55%|▌| 22558/40960 [00:53<00:43, 423.94batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  55%|▌| 22646/40960 [00:53<00:42, 427.43batches/s, l2_loss: 0.0105 - round_los\u001b[A\n",
      "Training:  55%|▌| 22646/40960 [00:53<00:42, 427.43batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 22734/40960 [00:53<00:42, 430.52batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 22734/40960 [00:53<00:42, 430.52batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 22823/40960 [00:54<00:41, 433.74batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 22823/40960 [00:54<00:41, 433.74batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 22910/40960 [00:54<00:41, 433.32batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 22910/40960 [00:54<00:41, 433.32batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 22995/40960 [00:54<00:41, 430.82batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 22995/40960 [00:54<00:41, 430.82batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 23083/40960 [00:54<00:41, 432.47batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  56%|▌| 23083/40960 [00:54<00:41, 432.47batches/s, l2_loss: 0.0106 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|▌| 23168/40960 [00:54<00:41, 429.38batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23168/40960 [00:54<00:41, 429.38batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23256/40960 [00:55<00:40, 432.51batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23256/40960 [00:55<00:40, 432.51batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23341/40960 [00:55<00:40, 430.16batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23341/40960 [00:55<00:40, 430.16batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23429/40960 [00:55<00:40, 432.82batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23429/40960 [00:55<00:40, 432.82batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23516/40960 [00:55<00:40, 432.62batches/s, l2_loss: 0.0106 - round_los\u001b[A\n",
      "Training:  57%|▌| 23516/40960 [00:55<00:40, 432.62batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23603/40960 [00:55<00:40, 432.17batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23603/40960 [00:55<00:40, 432.17batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23690/40960 [00:56<00:39, 432.86batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23690/40960 [00:56<00:39, 432.86batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23777/40960 [00:56<00:39, 432.49batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23777/40960 [00:56<00:39, 432.49batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23865/40960 [00:56<00:39, 433.78batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23865/40960 [00:56<00:39, 433.78batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23954/40960 [00:56<00:38, 436.64batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  58%|▌| 23954/40960 [00:56<00:38, 436.64batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  59%|▌| 24038/40960 [00:56<00:39, 430.70batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  59%|▌| 24038/40960 [00:56<00:39, 430.70batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  59%|▌| 24126/40960 [00:57<00:38, 433.23batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  59%|▌| 24126/40960 [00:57<00:38, 433.23batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  59%|▌| 24211/40960 [00:57<00:38, 430.59batches/s, l2_loss: 0.0107 - round_los\u001b[A\n",
      "Training:  59%|▌| 24211/40960 [00:57<00:38, 430.59batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  59%|▌| 24298/40960 [00:57<00:38, 431.74batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  59%|▌| 24298/40960 [00:57<00:38, 431.74batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24385/40960 [00:57<00:38, 432.46batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24385/40960 [00:57<00:38, 432.46batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24474/40960 [00:57<00:37, 435.07batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24474/40960 [00:57<00:37, 435.07batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24562/40960 [00:58<00:37, 435.24batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24562/40960 [00:58<00:37, 435.24batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24648/40960 [00:58<00:37, 432.55batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24648/40960 [00:58<00:37, 432.55batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24726/40960 [00:58<00:38, 418.66batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  60%|▌| 24726/40960 [00:58<00:38, 418.66batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  61%|▌| 24805/40960 [00:58<00:39, 410.37batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  61%|▌| 24805/40960 [00:58<00:39, 410.37batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  61%|▌| 24889/40960 [00:58<00:38, 412.86batches/s, l2_loss: 0.0108 - round_los\u001b[A\n",
      "Training:  61%|▌| 24889/40960 [00:58<00:38, 412.86batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  61%|▌| 24972/40960 [00:59<00:38, 413.25batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  61%|▌| 24972/40960 [00:59<00:38, 413.25batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  61%|▌| 25056/40960 [00:59<00:38, 414.34batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  61%|▌| 25056/40960 [00:59<00:38, 414.34batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  61%|▌| 25134/40960 [00:59<00:38, 406.53batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  61%|▌| 25134/40960 [00:59<00:38, 406.53batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25211/40960 [00:59<00:39, 400.00batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25211/40960 [00:59<00:39, 400.00batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25295/40960 [00:59<00:38, 405.34batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25295/40960 [00:59<00:38, 405.34batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25380/40960 [01:00<00:37, 410.88batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25380/40960 [01:00<00:37, 410.88batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25464/40960 [01:00<00:37, 412.93batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25464/40960 [01:00<00:37, 412.93batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25549/40960 [01:00<00:37, 416.15batches/s, l2_loss: 0.0109 - round_los\u001b[A\n",
      "Training:  62%|▌| 25549/40960 [01:00<00:37, 416.15batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25634/40960 [01:00<00:36, 417.59batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25634/40960 [01:00<00:36, 417.59batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25717/40960 [01:00<00:36, 415.52batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25717/40960 [01:00<00:36, 415.52batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25801/40960 [01:01<00:36, 415.96batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25801/40960 [01:01<00:36, 415.96batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25887/40960 [01:01<00:35, 419.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25887/40960 [01:01<00:35, 419.61batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25972/40960 [01:01<00:35, 419.84batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  63%|▋| 25972/40960 [01:01<00:35, 419.84batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  64%|▋| 26058/40960 [01:01<00:35, 422.71batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  64%|▋| 26058/40960 [01:01<00:35, 422.71batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  64%|▋| 26141/40960 [01:01<00:35, 419.50batches/s, l2_loss: 0.0110 - round_los\u001b[A\n",
      "Training:  64%|▋| 26141/40960 [01:01<00:35, 419.50batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  64%|▋| 26224/40960 [01:02<00:35, 416.98batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  64%|▋| 26224/40960 [01:02<00:35, 416.98batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  64%|▋| 26309/40960 [01:02<00:35, 418.30batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  64%|▋| 26309/40960 [01:02<00:35, 418.30batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  64%|▋| 26393/40960 [01:02<00:34, 418.14batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  64%|▋| 26393/40960 [01:02<00:34, 418.14batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  65%|▋| 26478/40960 [01:02<00:34, 420.16batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  65%|▋| 26478/40960 [01:02<00:34, 420.16batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  65%|▋| 26566/40960 [01:02<00:33, 424.79batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  65%|▋| 26566/40960 [01:02<00:33, 424.79batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  65%|▋| 26652/40960 [01:03<00:33, 426.02batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  65%|▋| 26652/40960 [01:03<00:33, 426.02batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  65%|▋| 26740/40960 [01:03<00:33, 429.57batches/s, l2_loss: 0.0111 - round_los\u001b[A\n",
      "Training:  65%|▋| 26740/40960 [01:03<00:33, 429.57batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  65%|▋| 26816/40960 [01:03<00:34, 414.64batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  65%|▋| 26816/40960 [01:03<00:34, 414.64batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 26893/40960 [01:03<00:34, 405.69batches/s, l2_loss: 0.0112 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|▋| 26893/40960 [01:03<00:34, 405.69batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 26977/40960 [01:03<00:34, 409.73batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 26977/40960 [01:04<00:34, 409.73batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 27052/40960 [01:04<00:34, 398.30batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 27052/40960 [01:04<00:34, 398.30batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 27125/40960 [01:04<00:35, 388.11batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 27125/40960 [01:04<00:35, 388.11batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 27210/40960 [01:04<00:34, 398.37batches/s, l2_loss: 0.0112 - round_los\u001b[A\n",
      "Training:  66%|▋| 27210/40960 [01:04<00:34, 398.37batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27297/40960 [01:04<00:33, 408.01batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27297/40960 [01:04<00:33, 408.01batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27377/40960 [01:05<00:33, 404.28batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27377/40960 [01:05<00:33, 404.28batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27454/40960 [01:05<00:33, 397.30batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27454/40960 [01:05<00:33, 397.30batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27525/40960 [01:05<00:34, 384.05batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27525/40960 [01:05<00:34, 384.05batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27609/40960 [01:05<00:33, 393.72batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  67%|▋| 27609/40960 [01:05<00:33, 393.72batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27698/40960 [01:05<00:32, 409.00batches/s, l2_loss: 0.0113 - round_los\u001b[A\n",
      "Training:  68%|▋| 27698/40960 [01:05<00:32, 409.00batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  68%|▋| 27782/40960 [01:06<00:32, 411.60batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  68%|▋| 27782/40960 [01:06<00:32, 411.60batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  68%|▋| 27865/40960 [01:06<00:31, 412.55batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  68%|▋| 27865/40960 [01:06<00:31, 412.55batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  68%|▋| 27951/40960 [01:06<00:31, 416.67batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  68%|▋| 27951/40960 [01:06<00:31, 416.67batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  68%|▋| 28033/40960 [01:06<00:31, 413.36batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  68%|▋| 28033/40960 [01:06<00:31, 413.36batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  69%|▋| 28118/40960 [01:06<00:30, 416.11batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  69%|▋| 28118/40960 [01:06<00:30, 416.11batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  69%|▋| 28205/40960 [01:07<00:30, 421.51batches/s, l2_loss: 0.0114 - round_los\u001b[A\n",
      "Training:  69%|▋| 28205/40960 [01:07<00:30, 421.51batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  69%|▋| 28290/40960 [01:07<00:30, 421.18batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  69%|▋| 28290/40960 [01:07<00:30, 421.18batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  69%|▋| 28375/40960 [01:07<00:29, 421.37batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  69%|▋| 28375/40960 [01:07<00:29, 421.37batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  69%|▋| 28461/40960 [01:07<00:29, 423.57batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  69%|▋| 28461/40960 [01:07<00:29, 423.57batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  70%|▋| 28545/40960 [01:07<00:29, 421.28batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  70%|▋| 28545/40960 [01:07<00:29, 421.28batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  70%|▋| 28632/40960 [01:08<00:29, 424.91batches/s, l2_loss: 0.0115 - round_los\u001b[A\n",
      "Training:  70%|▋| 28632/40960 [01:08<00:29, 424.91batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  70%|▋| 28717/40960 [01:08<00:28, 424.62batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  70%|▋| 28717/40960 [01:08<00:28, 424.62batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  70%|▋| 28794/40960 [01:08<00:29, 411.81batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  70%|▋| 28794/40960 [01:08<00:29, 411.81batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  70%|▋| 28870/40960 [01:08<00:30, 402.16batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  70%|▋| 28870/40960 [01:08<00:30, 402.16batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  71%|▋| 28956/40960 [01:08<00:29, 409.28batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  71%|▋| 28956/40960 [01:08<00:29, 409.28batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  71%|▋| 29044/40960 [01:09<00:28, 417.45batches/s, l2_loss: 0.0116 - round_los\u001b[A\n",
      "Training:  71%|▋| 29044/40960 [01:09<00:28, 417.45batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  71%|▋| 29131/40960 [01:09<00:27, 422.55batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  71%|▋| 29131/40960 [01:09<00:27, 422.55batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  71%|▋| 29216/40960 [01:09<00:27, 422.44batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  71%|▋| 29216/40960 [01:09<00:27, 422.44batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  72%|▋| 29294/40960 [01:09<00:28, 412.31batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  72%|▋| 29294/40960 [01:09<00:28, 412.31batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  72%|▋| 29373/40960 [01:09<00:28, 406.48batches/s, l2_loss: 0.0117 - round_los\u001b[A\n",
      "Training:  72%|▋| 29373/40960 [01:09<00:28, 406.48batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  72%|▋| 29445/40960 [01:10<00:29, 392.27batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  72%|▋| 29445/40960 [01:10<00:29, 392.27batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  72%|▋| 29513/40960 [01:10<00:30, 376.55batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  72%|▋| 29513/40960 [01:10<00:30, 376.55batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  72%|▋| 29598/40960 [01:10<00:29, 390.91batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  72%|▋| 29598/40960 [01:10<00:29, 390.91batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  72%|▋| 29682/40960 [01:10<00:28, 399.33batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  72%|▋| 29682/40960 [01:10<00:28, 399.33batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  73%|▋| 29764/40960 [01:10<00:27, 401.38batches/s, l2_loss: 0.0118 - round_los\u001b[A\n",
      "Training:  73%|▋| 29764/40960 [01:10<00:27, 401.38batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  73%|▋| 29842/40960 [01:11<00:27, 397.27batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  73%|▋| 29842/40960 [01:11<00:27, 397.27batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  73%|▋| 29919/40960 [01:11<00:28, 392.34batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  73%|▋| 29919/40960 [01:11<00:28, 392.34batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  73%|▋| 30001/40960 [01:11<00:27, 396.97batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  73%|▋| 30001/40960 [01:11<00:27, 396.97batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  73%|▋| 30081/40960 [01:11<00:27, 397.53batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  73%|▋| 30081/40960 [01:11<00:27, 397.53batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  74%|▋| 30165/40960 [01:11<00:26, 404.19batches/s, l2_loss: 0.0119 - round_los\u001b[A\n",
      "Training:  74%|▋| 30165/40960 [01:11<00:26, 404.19batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  74%|▋| 30247/40960 [01:12<00:26, 405.65batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  74%|▋| 30247/40960 [01:12<00:26, 405.65batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  74%|▋| 30332/40960 [01:12<00:25, 411.44batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  74%|▋| 30332/40960 [01:12<00:25, 411.44batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  74%|▋| 30416/40960 [01:12<00:25, 412.75batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  74%|▋| 30416/40960 [01:12<00:25, 412.75batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  74%|▋| 30498/40960 [01:12<00:25, 411.80batches/s, l2_loss: 0.0120 - round_los\u001b[A\n",
      "Training:  74%|▋| 30498/40960 [01:12<00:25, 411.80batches/s, l2_loss: 0.0121 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|▋| 30569/40960 [01:12<00:26, 394.31batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  75%|▋| 30569/40960 [01:12<00:26, 394.31batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  75%|▋| 30644/40960 [01:13<00:26, 387.60batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  75%|▋| 30644/40960 [01:13<00:26, 387.60batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  75%|▊| 30729/40960 [01:13<00:25, 397.90batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  75%|▊| 30729/40960 [01:13<00:25, 397.90batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  75%|▊| 30814/40960 [01:13<00:25, 405.30batches/s, l2_loss: 0.0121 - round_los\u001b[A\n",
      "Training:  75%|▊| 30814/40960 [01:13<00:25, 405.30batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  75%|▊| 30892/40960 [01:13<00:25, 400.44batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  75%|▊| 30892/40960 [01:13<00:25, 400.44batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  76%|▊| 30964/40960 [01:13<00:25, 387.14batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  76%|▊| 30964/40960 [01:13<00:25, 387.14batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  76%|▊| 31043/40960 [01:14<00:25, 389.12batches/s, l2_loss: 0.0122 - round_los\u001b[A\n",
      "Training:  76%|▊| 31043/40960 [01:14<00:25, 389.12batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  76%|▊| 31122/40960 [01:14<00:25, 389.70batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  76%|▊| 31122/40960 [01:14<00:25, 389.70batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  76%|▊| 31195/40960 [01:14<00:25, 381.86batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  76%|▊| 31195/40960 [01:14<00:25, 381.86batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  76%|▊| 31271/40960 [01:14<00:25, 380.69batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  76%|▊| 31271/40960 [01:14<00:25, 380.69batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  77%|▊| 31344/40960 [01:14<00:25, 375.37batches/s, l2_loss: 0.0123 - round_los\u001b[A\n",
      "Training:  77%|▊| 31344/40960 [01:14<00:25, 375.37batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  77%|▊| 31419/40960 [01:15<00:25, 374.09batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  77%|▊| 31419/40960 [01:15<00:25, 374.09batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  77%|▊| 31492/40960 [01:15<00:25, 370.63batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  77%|▊| 31492/40960 [01:15<00:25, 370.63batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  77%|▊| 31566/40960 [01:15<00:25, 368.93batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  77%|▊| 31566/40960 [01:15<00:25, 368.93batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  77%|▊| 31643/40960 [01:15<00:24, 373.60batches/s, l2_loss: 0.0124 - round_los\u001b[A\n",
      "Training:  77%|▊| 31643/40960 [01:15<00:24, 373.60batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  77%|▊| 31722/40960 [01:15<00:24, 379.87batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  77%|▊| 31722/40960 [01:15<00:24, 379.87batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  78%|▊| 31798/40960 [01:16<00:24, 379.41batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  78%|▊| 31798/40960 [01:16<00:24, 379.41batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  78%|▊| 31865/40960 [01:16<00:24, 366.06batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  78%|▊| 31865/40960 [01:16<00:24, 366.06batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  78%|▊| 31937/40960 [01:16<00:24, 363.65batches/s, l2_loss: 0.0125 - round_los\u001b[A\n",
      "Training:  78%|▊| 31937/40960 [01:16<00:24, 363.65batches/s, l2_loss: 0.0126 - round_los\u001b[A\n",
      "Training:  78%|▊| 32009/40960 [01:16<00:24, 361.66batches/s, l2_loss: 0.0126 - round_los\u001b[A\n",
      "Training:  78%|▊| 32009/40960 [01:16<00:24, 361.66batches/s, l2_loss: 0.0126 - round_los\u001b[A\n",
      "Training:  78%|▊| 32077/40960 [01:16<00:25, 354.19batches/s, l2_loss: 0.0126 - round_los\u001b[A\n",
      "Training:  78%|▊| 32077/40960 [01:16<00:25, 354.19batches/s, l2_loss: 0.0126 - round_los\u001b[A\n",
      "Training:  78%|▊| 32153/40960 [01:17<00:24, 361.04batches/s, l2_loss: 0.0126 - round_los\u001b[A\n",
      "Training:  78%|▊| 32153/40960 [01:17<00:24, 361.04batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32230/40960 [01:17<00:23, 367.79batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32230/40960 [01:17<00:23, 367.79batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32311/40960 [01:17<00:22, 378.07batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32311/40960 [01:17<00:22, 378.07batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32396/40960 [01:17<00:21, 391.94batches/s, l2_loss: 0.0127 - round_los\u001b[A\n",
      "Training:  79%|▊| 32396/40960 [01:17<00:21, 391.94batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  79%|▊| 32481/40960 [01:17<00:21, 400.47batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  79%|▊| 32481/40960 [01:17<00:21, 400.47batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  79%|▊| 32561/40960 [01:18<00:21, 399.22batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  79%|▊| 32561/40960 [01:18<00:21, 399.22batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32638/40960 [01:18<00:21, 393.48batches/s, l2_loss: 0.0128 - round_los\u001b[A\n",
      "Training:  80%|▊| 32638/40960 [01:18<00:21, 393.48batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  80%|▊| 32712/40960 [01:18<00:21, 386.34batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  80%|▊| 32712/40960 [01:18<00:21, 386.34batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  80%|▊| 32780/40960 [01:18<00:21, 371.85batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  80%|▊| 32780/40960 [01:18<00:21, 371.85batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  80%|▊| 32851/40960 [01:18<00:22, 366.44batches/s, l2_loss: 0.0129 - round_los\u001b[A\n",
      "Training:  80%|▊| 32851/40960 [01:18<00:22, 366.44batches/s, l2_loss: 0.0130 - round_los\u001b[A\n",
      "Training:  80%|▊| 32933/40960 [01:19<00:21, 379.26batches/s, l2_loss: 0.0130 - round_los\u001b[A\n",
      "Training:  80%|▊| 32933/40960 [01:19<00:21, 379.26batches/s, l2_loss: 0.0130 - round_los\u001b[A\n",
      "Training:  81%|▊| 33018/40960 [01:19<00:20, 392.23batches/s, l2_loss: 0.0130 - round_los\u001b[A\n",
      "Training:  81%|▊| 33018/40960 [01:19<00:20, 392.23batches/s, l2_loss: 0.0130 - round_los\u001b[A\n",
      "Training:  81%|▊| 33095/40960 [01:19<00:20, 388.78batches/s, l2_loss: 0.0130 - round_los\u001b[A\n",
      "Training:  81%|▊| 33095/40960 [01:19<00:20, 388.78batches/s, l2_loss: 0.0131 - round_los\u001b[A\n",
      "Training:  81%|▊| 33169/40960 [01:19<00:20, 382.58batches/s, l2_loss: 0.0131 - round_los\u001b[A\n",
      "Training:  81%|▊| 33169/40960 [01:19<00:20, 382.58batches/s, l2_loss: 0.0131 - round_los\u001b[A\n",
      "Training:  81%|▊| 33252/40960 [01:19<00:19, 391.02batches/s, l2_loss: 0.0131 - round_los\u001b[A\n",
      "Training:  81%|▊| 33252/40960 [01:19<00:19, 391.02batches/s, l2_loss: 0.0131 - round_los\u001b[A\n",
      "Training:  81%|▊| 33338/40960 [01:20<00:18, 401.84batches/s, l2_loss: 0.0131 - round_los\u001b[A\n",
      "Training:  81%|▊| 33338/40960 [01:20<00:18, 401.84batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33423/40960 [01:20<00:18, 407.53batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33423/40960 [01:20<00:18, 407.53batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33508/40960 [01:20<00:18, 412.60batches/s, l2_loss: 0.0132 - round_los\u001b[A\n",
      "Training:  82%|▊| 33508/40960 [01:20<00:18, 412.60batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33588/40960 [01:20<00:18, 405.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33588/40960 [01:20<00:18, 405.98batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33675/40960 [01:20<00:17, 413.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33675/40960 [01:20<00:17, 413.50batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33761/40960 [01:21<00:17, 417.46batches/s, l2_loss: 0.0133 - round_los\u001b[A\n",
      "Training:  82%|▊| 33761/40960 [01:21<00:17, 417.46batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  83%|▊| 33834/40960 [01:21<00:17, 401.29batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  83%|▊| 33834/40960 [01:21<00:17, 401.29batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  83%|▊| 33904/40960 [01:21<00:18, 384.85batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  83%|▊| 33904/40960 [01:21<00:18, 384.85batches/s, l2_loss: 0.0134 - round_los\u001b[A\n",
      "Training:  83%|▊| 33985/40960 [01:21<00:17, 390.25batches/s, l2_loss: 0.0134 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|▊| 33985/40960 [01:21<00:17, 390.25batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  83%|▊| 34067/40960 [01:21<00:17, 395.01batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  83%|▊| 34067/40960 [01:21<00:17, 395.01batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  83%|▊| 34154/40960 [01:22<00:16, 405.78batches/s, l2_loss: 0.0135 - round_los\u001b[A\n",
      "Training:  83%|▊| 34154/40960 [01:22<00:16, 405.78batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34240/40960 [01:22<00:16, 412.20batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34240/40960 [01:22<00:16, 412.20batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34319/40960 [01:22<00:16, 405.41batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34319/40960 [01:22<00:16, 405.41batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34403/40960 [01:22<00:16, 409.22batches/s, l2_loss: 0.0136 - round_los\u001b[A\n",
      "Training:  84%|▊| 34403/40960 [01:22<00:16, 409.22batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  84%|▊| 34483/40960 [01:22<00:15, 405.72batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  84%|▊| 34483/40960 [01:22<00:15, 405.72batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  84%|▊| 34566/40960 [01:23<00:15, 408.47batches/s, l2_loss: 0.0137 - round_los\u001b[A\n",
      "Training:  84%|▊| 34566/40960 [01:23<00:15, 408.47batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  85%|▊| 34652/40960 [01:23<00:15, 414.17batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  85%|▊| 34652/40960 [01:23<00:15, 414.17batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  85%|▊| 34738/40960 [01:23<00:14, 417.82batches/s, l2_loss: 0.0138 - round_los\u001b[A\n",
      "Training:  85%|▊| 34738/40960 [01:23<00:14, 417.82batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  85%|▊| 34825/40960 [01:23<00:14, 422.02batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  85%|▊| 34825/40960 [01:23<00:14, 422.02batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  85%|▊| 34902/40960 [01:23<00:14, 409.42batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  85%|▊| 34902/40960 [01:23<00:14, 409.42batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  85%|▊| 34977/40960 [01:24<00:15, 397.94batches/s, l2_loss: 0.0139 - round_los\u001b[A\n",
      "Training:  85%|▊| 34977/40960 [01:24<00:15, 397.94batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  86%|▊| 35054/40960 [01:24<00:14, 394.00batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  86%|▊| 35054/40960 [01:24<00:14, 394.00batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  86%|▊| 35139/40960 [01:24<00:14, 402.25batches/s, l2_loss: 0.0140 - round_los\u001b[A\n",
      "Training:  86%|▊| 35139/40960 [01:24<00:14, 402.25batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  86%|▊| 35227/40960 [01:24<00:13, 413.12batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  86%|▊| 35227/40960 [01:24<00:13, 413.12batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  86%|▊| 35312/40960 [01:24<00:13, 415.51batches/s, l2_loss: 0.0141 - round_los\u001b[A\n",
      "Training:  86%|▊| 35312/40960 [01:24<00:13, 415.51batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  86%|▊| 35400/40960 [01:25<00:13, 421.40batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  86%|▊| 35400/40960 [01:25<00:13, 421.40batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  87%|▊| 35483/40960 [01:25<00:13, 418.60batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  87%|▊| 35483/40960 [01:25<00:13, 418.60batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  87%|▊| 35570/40960 [01:25<00:12, 422.54batches/s, l2_loss: 0.0142 - round_los\u001b[A\n",
      "Training:  87%|▊| 35570/40960 [01:25<00:12, 422.54batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35652/40960 [01:25<00:12, 418.43batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35652/40960 [01:25<00:12, 418.43batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35737/40960 [01:25<00:12, 419.90batches/s, l2_loss: 0.0143 - round_los\u001b[A\n",
      "Training:  87%|▊| 35737/40960 [01:25<00:12, 419.90batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  87%|▊| 35824/40960 [01:26<00:12, 423.78batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  87%|▊| 35824/40960 [01:26<00:12, 423.78batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  88%|▉| 35902/40960 [01:26<00:12, 412.40batches/s, l2_loss: 0.0144 - round_los\u001b[A\n",
      "Training:  88%|▉| 35902/40960 [01:26<00:12, 412.40batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  88%|▉| 35986/40960 [01:26<00:12, 413.94batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  88%|▉| 35986/40960 [01:26<00:12, 413.94batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  88%|▉| 36071/40960 [01:26<00:11, 416.24batches/s, l2_loss: 0.0145 - round_los\u001b[A\n",
      "Training:  88%|▉| 36071/40960 [01:26<00:11, 416.24batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  88%|▉| 36148/40960 [01:26<00:11, 406.04batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  88%|▉| 36148/40960 [01:26<00:11, 406.04batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  88%|▉| 36225/40960 [01:27<00:11, 398.64batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  88%|▉| 36225/40960 [01:27<00:11, 398.64batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  89%|▉| 36307/40960 [01:27<00:11, 401.81batches/s, l2_loss: 0.0146 - round_los\u001b[A\n",
      "Training:  89%|▉| 36307/40960 [01:27<00:11, 401.81batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  89%|▉| 36384/40960 [01:27<00:11, 395.76batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  89%|▉| 36384/40960 [01:27<00:11, 395.76batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  89%|▉| 36457/40960 [01:27<00:11, 385.20batches/s, l2_loss: 0.0147 - round_los\u001b[A\n",
      "Training:  89%|▉| 36457/40960 [01:27<00:11, 385.20batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36537/40960 [01:27<00:11, 389.50batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36537/40960 [01:27<00:11, 389.50batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36622/40960 [01:28<00:10, 399.72batches/s, l2_loss: 0.0148 - round_los\u001b[A\n",
      "Training:  89%|▉| 36622/40960 [01:28<00:10, 399.72batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36707/40960 [01:28<00:10, 406.71batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36707/40960 [01:28<00:10, 406.71batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36793/40960 [01:28<00:10, 412.88batches/s, l2_loss: 0.0149 - round_los\u001b[A\n",
      "Training:  90%|▉| 36793/40960 [01:28<00:10, 412.88batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 36880/40960 [01:28<00:09, 418.46batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 36880/40960 [01:28<00:09, 418.46batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 36963/40960 [01:28<00:09, 416.80batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 36963/40960 [01:28<00:09, 416.80batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 37044/40960 [01:29<00:09, 413.27batches/s, l2_loss: 0.0150 - round_los\u001b[A\n",
      "Training:  90%|▉| 37044/40960 [01:29<00:09, 413.27batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  91%|▉| 37129/40960 [01:29<00:09, 415.79batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  91%|▉| 37129/40960 [01:29<00:09, 415.79batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  91%|▉| 37217/40960 [01:29<00:08, 421.77batches/s, l2_loss: 0.0151 - round_los\u001b[A\n",
      "Training:  91%|▉| 37217/40960 [01:29<00:08, 421.77batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  91%|▉| 37299/40960 [01:29<00:08, 417.82batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  91%|▉| 37299/40960 [01:29<00:08, 417.82batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  91%|▉| 37380/40960 [01:29<00:08, 413.10batches/s, l2_loss: 0.0152 - round_los\u001b[A\n",
      "Training:  91%|▉| 37380/40960 [01:29<00:08, 413.10batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  91%|▉| 37465/40960 [01:30<00:08, 415.87batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  91%|▉| 37465/40960 [01:30<00:08, 415.87batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  92%|▉| 37551/40960 [01:30<00:08, 419.04batches/s, l2_loss: 0.0153 - round_los\u001b[A\n",
      "Training:  92%|▉| 37551/40960 [01:30<00:08, 419.04batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  92%|▉| 37638/40960 [01:30<00:07, 422.59batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  92%|▉| 37638/40960 [01:30<00:07, 422.59batches/s, l2_loss: 0.0154 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|▉| 37722/40960 [01:30<00:07, 421.08batches/s, l2_loss: 0.0154 - round_los\u001b[A\n",
      "Training:  92%|▉| 37722/40960 [01:30<00:07, 421.08batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  92%|▉| 37806/40960 [01:30<00:07, 419.52batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  92%|▉| 37806/40960 [01:30<00:07, 419.52batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  92%|▉| 37884/40960 [01:31<00:07, 409.81batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  92%|▉| 37884/40960 [01:31<00:07, 409.81batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  93%|▉| 37961/40960 [01:31<00:07, 402.30batches/s, l2_loss: 0.0155 - round_los\u001b[A\n",
      "Training:  93%|▉| 37961/40960 [01:31<00:07, 402.30batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  93%|▉| 38046/40960 [01:31<00:07, 408.74batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  93%|▉| 38046/40960 [01:31<00:07, 408.74batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  93%|▉| 38130/40960 [01:31<00:06, 411.29batches/s, l2_loss: 0.0156 - round_los\u001b[A\n",
      "Training:  93%|▉| 38130/40960 [01:31<00:06, 411.29batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  93%|▉| 38216/40960 [01:31<00:06, 416.75batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  93%|▉| 38216/40960 [01:31<00:06, 416.75batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  94%|▉| 38302/40960 [01:32<00:06, 419.87batches/s, l2_loss: 0.0157 - round_los\u001b[A\n",
      "Training:  94%|▉| 38302/40960 [01:32<00:06, 419.87batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  94%|▉| 38389/40960 [01:32<00:06, 423.37batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  94%|▉| 38389/40960 [01:32<00:06, 423.37batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  94%|▉| 38477/40960 [01:32<00:05, 427.96batches/s, l2_loss: 0.0158 - round_los\u001b[A\n",
      "Training:  94%|▉| 38477/40960 [01:32<00:05, 427.96batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "Training:  94%|▉| 38561/40960 [01:32<00:05, 424.25batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "Training:  94%|▉| 38561/40960 [01:32<00:05, 424.25batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "Training:  94%|▉| 38644/40960 [01:32<00:05, 420.81batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "Training:  94%|▉| 38644/40960 [01:32<00:05, 420.81batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "Training:  95%|▉| 38730/40960 [01:33<00:05, 423.03batches/s, l2_loss: 0.0159 - round_los\u001b[A\n",
      "Training:  95%|▉| 38730/40960 [01:33<00:05, 423.03batches/s, l2_loss: 0.0160 - round_los\u001b[A\n",
      "Training:  95%|▉| 38816/40960 [01:33<00:05, 423.86batches/s, l2_loss: 0.0160 - round_los\u001b[A\n",
      "Training:  95%|▉| 38816/40960 [01:33<00:05, 423.86batches/s, l2_loss: 0.0160 - round_los\u001b[A\n",
      "Training:  95%|▉| 38901/40960 [01:33<00:04, 423.42batches/s, l2_loss: 0.0160 - round_los\u001b[A\n",
      "Training:  95%|▉| 38901/40960 [01:33<00:04, 423.42batches/s, l2_loss: 0.0161 - round_los\u001b[A\n",
      "Training:  95%|▉| 38988/40960 [01:33<00:04, 425.83batches/s, l2_loss: 0.0161 - round_los\u001b[A\n",
      "Training:  95%|▉| 38988/40960 [01:33<00:04, 425.83batches/s, l2_loss: 0.0161 - round_los\u001b[A\n",
      "Training:  95%|▉| 39078/40960 [01:33<00:04, 432.36batches/s, l2_loss: 0.0161 - round_los\u001b[A\n",
      "Training:  95%|▉| 39078/40960 [01:33<00:04, 432.36batches/s, l2_loss: 0.0162 - round_los\u001b[A\n",
      "Training:  96%|▉| 39164/40960 [01:34<00:04, 430.22batches/s, l2_loss: 0.0162 - round_los\u001b[A\n",
      "Training:  96%|▉| 39164/40960 [01:34<00:04, 430.22batches/s, l2_loss: 0.0162 - round_los\u001b[A\n",
      "Training:  96%|▉| 39253/40960 [01:34<00:03, 433.29batches/s, l2_loss: 0.0162 - round_los\u001b[A\n",
      "Training:  96%|▉| 39253/40960 [01:34<00:03, 433.29batches/s, l2_loss: 0.0162 - round_los\u001b[A\n",
      "Training:  96%|▉| 39338/40960 [01:34<00:03, 430.57batches/s, l2_loss: 0.0162 - round_los\u001b[A\n",
      "Training:  96%|▉| 39338/40960 [01:34<00:03, 430.57batches/s, l2_loss: 0.0163 - round_los\u001b[A\n",
      "Training:  96%|▉| 39424/40960 [01:34<00:03, 429.18batches/s, l2_loss: 0.0163 - round_los\u001b[A\n",
      "Training:  96%|▉| 39424/40960 [01:34<00:03, 429.18batches/s, l2_loss: 0.0163 - round_los\u001b[A\n",
      "Training:  96%|▉| 39512/40960 [01:34<00:03, 431.89batches/s, l2_loss: 0.0163 - round_los\u001b[A\n",
      "Training:  96%|▉| 39512/40960 [01:34<00:03, 431.89batches/s, l2_loss: 0.0164 - round_los\u001b[A\n",
      "Training:  97%|▉| 39600/40960 [01:35<00:03, 433.09batches/s, l2_loss: 0.0164 - round_los\u001b[A\n",
      "Training:  97%|▉| 39600/40960 [01:35<00:03, 433.09batches/s, l2_loss: 0.0164 - round_los\u001b[A\n",
      "Training:  97%|▉| 39687/40960 [01:35<00:02, 432.88batches/s, l2_loss: 0.0164 - round_los\u001b[A\n",
      "Training:  97%|▉| 39687/40960 [01:35<00:02, 432.88batches/s, l2_loss: 0.0165 - round_los\u001b[A\n",
      "Training:  97%|▉| 39770/40960 [01:35<00:02, 426.96batches/s, l2_loss: 0.0165 - round_los\u001b[A\n",
      "Training:  97%|▉| 39770/40960 [01:35<00:02, 426.96batches/s, l2_loss: 0.0165 - round_los\u001b[A\n",
      "Training:  97%|▉| 39856/40960 [01:35<00:02, 426.40batches/s, l2_loss: 0.0165 - round_los\u001b[A\n",
      "Training:  97%|▉| 39856/40960 [01:35<00:02, 426.40batches/s, l2_loss: 0.0165 - round_los\u001b[A\n",
      "Training:  98%|▉| 39943/40960 [01:36<00:02, 427.67batches/s, l2_loss: 0.0165 - round_los\u001b[A\n",
      "Training:  98%|▉| 39943/40960 [01:36<00:02, 427.67batches/s, l2_loss: 0.0166 - round_los\u001b[A\n",
      "Training:  98%|▉| 40031/40960 [01:36<00:02, 430.10batches/s, l2_loss: 0.0166 - round_los\u001b[A\n",
      "Training:  98%|▉| 40031/40960 [01:36<00:02, 430.10batches/s, l2_loss: 0.0166 - round_los\u001b[A\n",
      "Training:  98%|▉| 40117/40960 [01:36<00:01, 428.85batches/s, l2_loss: 0.0166 - round_los\u001b[A\n",
      "Training:  98%|▉| 40117/40960 [01:36<00:01, 428.85batches/s, l2_loss: 0.0167 - round_los\u001b[A\n",
      "Training:  98%|▉| 40201/40960 [01:36<00:01, 425.17batches/s, l2_loss: 0.0167 - round_los\u001b[A\n",
      "Training:  98%|▉| 40201/40960 [01:36<00:01, 425.17batches/s, l2_loss: 0.0167 - round_los\u001b[A\n",
      "Training:  98%|▉| 40283/40960 [01:36<00:01, 420.23batches/s, l2_loss: 0.0167 - round_los\u001b[A\n",
      "Training:  98%|▉| 40283/40960 [01:36<00:01, 420.23batches/s, l2_loss: 0.0167 - round_los\u001b[A\n",
      "Training:  99%|▉| 40370/40960 [01:37<00:01, 423.63batches/s, l2_loss: 0.0167 - round_los\u001b[A\n",
      "Training:  99%|▉| 40370/40960 [01:37<00:01, 423.63batches/s, l2_loss: 0.0168 - round_los\u001b[A\n",
      "Training:  99%|▉| 40454/40960 [01:37<00:01, 421.79batches/s, l2_loss: 0.0168 - round_los\u001b[A\n",
      "Training:  99%|▉| 40454/40960 [01:37<00:01, 421.79batches/s, l2_loss: 0.0168 - round_los\u001b[A\n",
      "Training:  99%|▉| 40540/40960 [01:37<00:00, 424.20batches/s, l2_loss: 0.0168 - round_los\u001b[A\n",
      "Training:  99%|▉| 40540/40960 [01:37<00:00, 424.20batches/s, l2_loss: 0.0169 - round_los\u001b[A\n",
      "Training:  99%|▉| 40627/40960 [01:37<00:00, 426.91batches/s, l2_loss: 0.0169 - round_los\u001b[A\n",
      "Training:  99%|▉| 40627/40960 [01:37<00:00, 426.91batches/s, l2_loss: 0.0169 - round_los\u001b[A\n",
      "Training:  99%|▉| 40712/40960 [01:37<00:00, 425.59batches/s, l2_loss: 0.0169 - round_los\u001b[A\n",
      "Training:  99%|▉| 40712/40960 [01:37<00:00, 425.59batches/s, l2_loss: 0.0169 - round_los\u001b[A\n",
      "Training: 100%|▉| 40796/40960 [01:38<00:00, 423.40batches/s, l2_loss: 0.0169 - round_los\u001b[A\n",
      "Training: 100%|▉| 40796/40960 [01:38<00:00, 423.40batches/s, l2_loss: 0.0170 - round_los\u001b[A\n",
      "Training: 100%|▉| 40881/40960 [01:38<00:00, 422.60batches/s, l2_loss: 0.0170 - round_los\u001b[A\n",
      "Training: 100%|▉| 40881/40960 [01:38<00:00, 422.60batches/s, l2_loss: 0.0170 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-05-20 19:02:55.148051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround:  67%|▋| 2/3 [03:25<01:42, 102.55s/blocks, Layers=['model_cnn21/fc1_output_0']]2025-05-20 19:02:56.430153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 19:02:56.655931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "\n",
      "Training:   0%|                                          | 0/40960 [00:00<?, ?batches/s]\u001b[A2025-05-20 19:02:59.178076: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|                               | 1/40960 [00:01<12:31:11,  1.10s/batches]\u001b[A\n",
      "Training:   0%| | 1/40960 [00:01<12:31:11,  1.10s/batches, l2_loss: 18.0072 - round_loss\u001b[A\n",
      "Training:   0%| | 102/40960 [00:01<06:29, 104.79batches/s, l2_loss: 18.0072 - round_loss\u001b[A\n",
      "Training:   0%| | 102/40960 [00:01<06:29, 104.79batches/s, l2_loss: 20.3816 - round_loss\u001b[A\n",
      "Training:   1%| | 206/40960 [00:01<03:24, 198.84batches/s, l2_loss: 20.3816 - round_loss\u001b[A\n",
      "Training:   1%| | 206/40960 [00:01<03:24, 198.84batches/s, l2_loss: 19.2145 - round_loss\u001b[A\n",
      "Training:   1%| | 308/40960 [00:01<02:28, 274.57batches/s, l2_loss: 19.2145 - round_loss\u001b[A\n",
      "Training:   1%| | 308/40960 [00:01<02:28, 274.57batches/s, l2_loss: 18.4518 - round_loss\u001b[A\n",
      "Training:   1%| | 409/40960 [00:01<02:01, 334.20batches/s, l2_loss: 18.4518 - round_loss\u001b[A\n",
      "Training:   1%| | 409/40960 [00:01<02:01, 334.20batches/s, l2_loss: 17.8263 - round_loss\u001b[A\n",
      "Training:   1%| | 506/40960 [00:02<01:48, 374.28batches/s, l2_loss: 17.8263 - round_loss\u001b[A\n",
      "Training:   1%| | 506/40960 [00:02<01:48, 374.28batches/s, l2_loss: 17.2651 - round_loss\u001b[A\n",
      "Training:   1%| | 605/40960 [00:02<01:39, 407.44batches/s, l2_loss: 17.2651 - round_loss\u001b[A\n",
      "Training:   1%| | 605/40960 [00:02<01:39, 407.44batches/s, l2_loss: 16.7955 - round_loss\u001b[A\n",
      "Training:   2%| | 704/40960 [00:02<01:33, 432.07batches/s, l2_loss: 16.7955 - round_loss\u001b[A\n",
      "Training:   2%| | 704/40960 [00:02<01:33, 432.07batches/s, l2_loss: 16.4473 - round_loss\u001b[A\n",
      "Training:   2%| | 804/40960 [00:02<01:29, 451.16batches/s, l2_loss: 16.4473 - round_loss\u001b[A\n",
      "Training:   2%| | 804/40960 [00:02<01:29, 451.16batches/s, l2_loss: 16.1550 - round_loss\u001b[A\n",
      "Training:   2%| | 906/40960 [00:02<01:25, 467.41batches/s, l2_loss: 16.1550 - round_loss\u001b[A\n",
      "Training:   2%| | 906/40960 [00:02<01:25, 467.41batches/s, l2_loss: 15.8900 - round_loss\u001b[A\n",
      "Training:   2%| | 1009/40960 [00:03<01:23, 480.13batches/s, l2_loss: 15.8900 - round_los\u001b[A\n",
      "Training:   2%| | 1009/40960 [00:03<01:23, 480.13batches/s, l2_loss: 15.6134 - round_los\u001b[A\n",
      "Training:   3%| | 1109/40960 [00:03<01:22, 485.96batches/s, l2_loss: 15.6134 - round_los\u001b[A\n",
      "Training:   3%| | 1109/40960 [00:03<01:22, 485.96batches/s, l2_loss: 15.4037 - round_los\u001b[A\n",
      "Training:   3%| | 1210/40960 [00:03<01:20, 491.46batches/s, l2_loss: 15.4037 - round_los\u001b[A\n",
      "Training:   3%| | 1210/40960 [00:03<01:20, 491.46batches/s, l2_loss: 15.2242 - round_los\u001b[A\n",
      "Training:   3%| | 1311/40960 [00:03<01:20, 495.17batches/s, l2_loss: 15.2242 - round_los\u001b[A\n",
      "Training:   3%| | 1311/40960 [00:03<01:20, 495.17batches/s, l2_loss: 15.0438 - round_los\u001b[A\n",
      "Training:   3%| | 1412/40960 [00:03<01:19, 497.67batches/s, l2_loss: 15.0438 - round_los\u001b[A\n",
      "Training:   3%| | 1412/40960 [00:03<01:19, 497.67batches/s, l2_loss: 14.8698 - round_los\u001b[A\n",
      "Training:   4%| | 1513/40960 [00:04<01:19, 498.65batches/s, l2_loss: 14.8698 - round_los\u001b[A\n",
      "Training:   4%| | 1513/40960 [00:04<01:19, 498.65batches/s, l2_loss: 14.7299 - round_los\u001b[A\n",
      "Training:   4%| | 1614/40960 [00:04<01:18, 499.88batches/s, l2_loss: 14.7299 - round_los\u001b[A\n",
      "Training:   4%| | 1614/40960 [00:04<01:18, 499.88batches/s, l2_loss: 14.5883 - round_los\u001b[A\n",
      "Training:   4%| | 1714/40960 [00:04<01:18, 498.79batches/s, l2_loss: 14.5883 - round_los\u001b[A\n",
      "Training:   4%| | 1714/40960 [00:04<01:18, 498.79batches/s, l2_loss: 14.4578 - round_los\u001b[A\n",
      "Training:   4%| | 1814/40960 [00:04<01:18, 497.69batches/s, l2_loss: 14.4578 - round_los\u001b[A\n",
      "Training:   4%| | 1814/40960 [00:04<01:18, 497.69batches/s, l2_loss: 14.3183 - round_los\u001b[A\n",
      "Training:   5%| | 1916/40960 [00:04<01:18, 500.31batches/s, l2_loss: 14.3183 - round_los\u001b[A\n",
      "Training:   5%| | 1916/40960 [00:04<01:18, 500.31batches/s, l2_loss: 14.1801 - round_los\u001b[A\n",
      "Training:   5%| | 2017/40960 [00:05<01:17, 500.29batches/s, l2_loss: 14.1801 - round_los\u001b[A\n",
      "Training:   5%| | 2017/40960 [00:05<01:17, 500.29batches/s, l2_loss: 14.0566 - round_los\u001b[A\n",
      "Training:   5%| | 2116/40960 [00:05<01:17, 498.70batches/s, l2_loss: 14.0566 - round_los\u001b[A\n",
      "Training:   5%| | 2116/40960 [00:05<01:17, 498.70batches/s, l2_loss: 13.9712 - round_los\u001b[A\n",
      "Training:   5%| | 2218/40960 [00:05<01:17, 501.17batches/s, l2_loss: 13.9712 - round_los\u001b[A\n",
      "Training:   5%| | 2218/40960 [00:05<01:17, 501.17batches/s, l2_loss: 13.8687 - round_los\u001b[A\n",
      "Training:   6%| | 2318/40960 [00:05<01:17, 499.87batches/s, l2_loss: 13.8687 - round_los\u001b[A\n",
      "Training:   6%| | 2318/40960 [00:05<01:17, 499.87batches/s, l2_loss: 13.7676 - round_los\u001b[A\n",
      "Training:   6%| | 2417/40960 [00:05<01:17, 497.54batches/s, l2_loss: 13.7676 - round_los\u001b[A\n",
      "Training:   6%| | 2417/40960 [00:05<01:17, 497.54batches/s, l2_loss: 13.6818 - round_los\u001b[A\n",
      "Training:   6%| | 2516/40960 [00:06<01:17, 496.32batches/s, l2_loss: 13.6818 - round_los\u001b[A\n",
      "Training:   6%| | 2516/40960 [00:06<01:17, 496.32batches/s, l2_loss: 13.6090 - round_los\u001b[A\n",
      "Training:   6%| | 2618/40960 [00:06<01:16, 500.03batches/s, l2_loss: 13.6090 - round_los\u001b[A\n",
      "Training:   6%| | 2618/40960 [00:06<01:16, 500.03batches/s, l2_loss: 13.5157 - round_los\u001b[A\n",
      "Training:   7%| | 2719/40960 [00:06<01:16, 500.25batches/s, l2_loss: 13.5157 - round_los\u001b[A\n",
      "Training:   7%| | 2719/40960 [00:06<01:16, 500.25batches/s, l2_loss: 13.4316 - round_los\u001b[A\n",
      "Training:   7%| | 2819/40960 [00:06<01:16, 499.55batches/s, l2_loss: 13.4316 - round_los\u001b[A\n",
      "Training:   7%| | 2819/40960 [00:06<01:16, 499.55batches/s, l2_loss: 13.3503 - round_los\u001b[A\n",
      "Training:   7%| | 2921/40960 [00:06<01:15, 501.48batches/s, l2_loss: 13.3503 - round_los\u001b[A\n",
      "Training:   7%| | 2921/40960 [00:06<01:15, 501.48batches/s, l2_loss: 13.2737 - round_los\u001b[A\n",
      "Training:   7%| | 3021/40960 [00:07<01:15, 500.41batches/s, l2_loss: 13.2737 - round_los\u001b[A\n",
      "Training:   7%| | 3021/40960 [00:07<01:15, 500.41batches/s, l2_loss: 13.2004 - round_los\u001b[A\n",
      "Training:   8%| | 3123/40960 [00:07<01:15, 502.84batches/s, l2_loss: 13.2004 - round_los\u001b[A\n",
      "Training:   8%| | 3123/40960 [00:07<01:15, 502.84batches/s, l2_loss: 13.1379 - round_los\u001b[A\n",
      "Training:   8%| | 3225/40960 [00:07<01:14, 504.16batches/s, l2_loss: 13.1379 - round_los\u001b[A\n",
      "Training:   8%| | 3225/40960 [00:07<01:14, 504.16batches/s, l2_loss: 13.0719 - round_los\u001b[A\n",
      "Training:   8%| | 3324/40960 [00:07<01:15, 501.11batches/s, l2_loss: 13.0719 - round_los\u001b[A\n",
      "Training:   8%| | 3324/40960 [00:07<01:15, 501.11batches/s, l2_loss: 13.0076 - round_los\u001b[A\n",
      "Training:   8%| | 3425/40960 [00:07<01:14, 502.17batches/s, l2_loss: 13.0076 - round_los\u001b[A\n",
      "Training:   8%| | 3425/40960 [00:07<01:14, 502.17batches/s, l2_loss: 12.9425 - round_los\u001b[A\n",
      "Training:   9%| | 3525/40960 [00:08<01:14, 500.62batches/s, l2_loss: 12.9425 - round_los\u001b[A\n",
      "Training:   9%| | 3525/40960 [00:08<01:14, 500.62batches/s, l2_loss: 12.8799 - round_los\u001b[A\n",
      "Training:   9%| | 3628/40960 [00:08<01:13, 504.59batches/s, l2_loss: 12.8799 - round_los\u001b[A\n",
      "Training:   9%| | 3628/40960 [00:08<01:13, 504.59batches/s, l2_loss: 12.8243 - round_los\u001b[A\n",
      "Training:   9%| | 3730/40960 [00:08<01:13, 505.84batches/s, l2_loss: 12.8243 - round_los\u001b[A\n",
      "Training:   9%| | 3730/40960 [00:08<01:13, 505.84batches/s, l2_loss: 12.7673 - round_los\u001b[A\n",
      "Training:   9%| | 3833/40960 [00:08<01:13, 508.20batches/s, l2_loss: 12.7673 - round_los\u001b[A\n",
      "Training:   9%| | 3833/40960 [00:08<01:13, 508.20batches/s, l2_loss: 12.7136 - round_los\u001b[A\n",
      "Training:  10%| | 3935/40960 [00:08<01:12, 507.48batches/s, l2_loss: 12.7136 - round_los\u001b[A\n",
      "Training:  10%| | 3935/40960 [00:08<01:12, 507.48batches/s, l2_loss: 12.6597 - round_los\u001b[A\n",
      "Training:  10%| | 4033/40960 [00:09<01:13, 501.64batches/s, l2_loss: 12.6597 - round_los\u001b[A\n",
      "Training:  10%| | 4033/40960 [00:09<01:13, 501.64batches/s, l2_loss: 12.6097 - round_los\u001b[A\n",
      "Training:  10%| | 4133/40960 [00:09<01:13, 500.98batches/s, l2_loss: 12.6097 - round_los\u001b[A\n",
      "Training:  10%| | 4133/40960 [00:09<01:13, 500.98batches/s, l2_loss: 12.5601 - round_los\u001b[A\n",
      "Training:  10%| | 4235/40960 [00:09<01:12, 503.38batches/s, l2_loss: 12.5601 - round_los\u001b[A\n",
      "Training:  10%| | 4235/40960 [00:09<01:12, 503.38batches/s, l2_loss: 12.5174 - round_los\u001b[A\n",
      "Training:  11%| | 4337/40960 [00:09<01:12, 505.24batches/s, l2_loss: 12.5174 - round_los\u001b[A\n",
      "Training:  11%| | 4337/40960 [00:09<01:12, 505.24batches/s, l2_loss: 12.4659 - round_los\u001b[A\n",
      "Training:  11%| | 4437/40960 [00:09<01:12, 503.51batches/s, l2_loss: 12.4659 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%| | 4437/40960 [00:09<01:12, 503.51batches/s, l2_loss: 12.4189 - round_los\u001b[A\n",
      "Training:  11%| | 4538/40960 [00:10<01:12, 503.06batches/s, l2_loss: 12.4189 - round_los\u001b[A\n",
      "Training:  11%| | 4538/40960 [00:10<01:12, 503.06batches/s, l2_loss: 12.3796 - round_los\u001b[A\n",
      "Training:  11%| | 4641/40960 [00:10<01:11, 505.51batches/s, l2_loss: 12.3796 - round_los\u001b[A\n",
      "Training:  11%| | 4641/40960 [00:10<01:11, 505.51batches/s, l2_loss: 12.3298 - round_los\u001b[A\n",
      "Training:  12%| | 4738/40960 [00:10<01:12, 498.11batches/s, l2_loss: 12.3298 - round_los\u001b[A\n",
      "Training:  12%| | 4738/40960 [00:10<01:12, 498.11batches/s, l2_loss: 12.2829 - round_los\u001b[A\n",
      "Training:  12%| | 4841/40960 [00:10<01:11, 502.81batches/s, l2_loss: 12.2829 - round_los\u001b[A\n",
      "Training:  12%| | 4841/40960 [00:10<01:11, 502.81batches/s, l2_loss: 12.2373 - round_los\u001b[A\n",
      "Training:  12%| | 4941/40960 [00:10<01:11, 501.15batches/s, l2_loss: 12.2373 - round_los\u001b[A\n",
      "Training:  12%| | 4941/40960 [00:10<01:11, 501.15batches/s, l2_loss: 12.1967 - round_los\u001b[A\n",
      "Training:  12%| | 5043/40960 [00:11<01:11, 503.67batches/s, l2_loss: 12.1967 - round_los\u001b[A\n",
      "Training:  12%| | 5043/40960 [00:11<01:11, 503.67batches/s, l2_loss: 12.1544 - round_los\u001b[A\n",
      "Training:  13%|▏| 5147/40960 [00:11<01:10, 507.74batches/s, l2_loss: 12.1544 - round_los\u001b[A\n",
      "Training:  13%|▏| 5147/40960 [00:11<01:10, 507.74batches/s, l2_loss: 12.1144 - round_los\u001b[A\n",
      "Training:  13%|▏| 5250/40960 [00:11<01:10, 509.80batches/s, l2_loss: 12.1144 - round_los\u001b[A\n",
      "Training:  13%|▏| 5250/40960 [00:11<01:10, 509.80batches/s, l2_loss: 12.0764 - round_los\u001b[A\n",
      "Training:  13%|▏| 5349/40960 [00:11<01:10, 505.03batches/s, l2_loss: 12.0764 - round_los\u001b[A\n",
      "Training:  13%|▏| 5349/40960 [00:11<01:10, 505.03batches/s, l2_loss: 12.0388 - round_los\u001b[A\n",
      "Training:  13%|▏| 5450/40960 [00:11<01:10, 503.84batches/s, l2_loss: 12.0388 - round_los\u001b[A\n",
      "Training:  13%|▏| 5450/40960 [00:11<01:10, 503.84batches/s, l2_loss: 12.0024 - round_los\u001b[A\n",
      "Training:  14%|▏| 5553/40960 [00:12<01:09, 506.47batches/s, l2_loss: 12.0024 - round_los\u001b[A\n",
      "Training:  14%|▏| 5553/40960 [00:12<01:09, 506.47batches/s, l2_loss: 11.9639 - round_los\u001b[A\n",
      "Training:  14%|▏| 5657/40960 [00:12<01:09, 509.37batches/s, l2_loss: 11.9639 - round_los\u001b[A\n",
      "Training:  14%|▏| 5657/40960 [00:12<01:09, 509.37batches/s, l2_loss: 11.9251 - round_los\u001b[A\n",
      "Training:  14%|▏| 5755/40960 [00:12<01:10, 502.47batches/s, l2_loss: 11.9251 - round_los\u001b[A\n",
      "Training:  14%|▏| 5755/40960 [00:12<01:10, 502.47batches/s, l2_loss: 11.8911 - round_los\u001b[A\n",
      "Training:  14%|▏| 5856/40960 [00:12<01:09, 502.31batches/s, l2_loss: 11.8911 - round_los\u001b[A\n",
      "Training:  14%|▏| 5856/40960 [00:12<01:09, 502.31batches/s, l2_loss: 11.8601 - round_los\u001b[A\n",
      "Training:  15%|▏| 5955/40960 [00:12<01:10, 499.56batches/s, l2_loss: 11.8601 - round_los\u001b[A\n",
      "Training:  15%|▏| 5955/40960 [00:12<01:10, 499.56batches/s, l2_loss: 11.8227 - round_los\u001b[A\n",
      "Training:  15%|▏| 6055/40960 [00:13<01:10, 498.38batches/s, l2_loss: 11.8227 - round_los\u001b[A\n",
      "Training:  15%|▏| 6055/40960 [00:13<01:10, 498.38batches/s, l2_loss: 11.7871 - round_los\u001b[A\n",
      "Training:  15%|▏| 6157/40960 [00:13<01:09, 501.03batches/s, l2_loss: 11.7871 - round_los\u001b[A\n",
      "Training:  15%|▏| 6157/40960 [00:13<01:09, 501.03batches/s, l2_loss: 11.7573 - round_los\u001b[A\n",
      "Training:  15%|▏| 6260/40960 [00:13<01:08, 504.05batches/s, l2_loss: 11.7573 - round_los\u001b[A\n",
      "Training:  15%|▏| 6260/40960 [00:13<01:08, 504.05batches/s, l2_loss: 11.7206 - round_los\u001b[A\n",
      "Training:  16%|▏| 6362/40960 [00:13<01:08, 504.76batches/s, l2_loss: 11.7206 - round_los\u001b[A\n",
      "Training:  16%|▏| 6362/40960 [00:13<01:08, 504.76batches/s, l2_loss: 11.6875 - round_los\u001b[A\n",
      "Training:  16%|▏| 6461/40960 [00:13<01:08, 501.20batches/s, l2_loss: 11.6875 - round_los\u001b[A\n",
      "Training:  16%|▏| 6461/40960 [00:13<01:08, 501.20batches/s, l2_loss: 11.6604 - round_los\u001b[A\n",
      "Training:  16%|▏| 6563/40960 [00:14<01:08, 503.18batches/s, l2_loss: 11.6604 - round_los\u001b[A\n",
      "Training:  16%|▏| 6563/40960 [00:14<01:08, 503.18batches/s, l2_loss: 11.6290 - round_los\u001b[A\n",
      "Training:  16%|▏| 6666/40960 [00:14<01:07, 506.15batches/s, l2_loss: 11.6290 - round_los\u001b[A\n",
      "Training:  16%|▏| 6666/40960 [00:14<01:07, 506.15batches/s, l2_loss: 11.5969 - round_los\u001b[A\n",
      "Training:  17%|▏| 6769/40960 [00:14<01:07, 507.54batches/s, l2_loss: 11.5969 - round_los\u001b[A\n",
      "Training:  17%|▏| 6769/40960 [00:14<01:07, 507.54batches/s, l2_loss: 11.5709 - round_los\u001b[A\n",
      "Training:  17%|▏| 6871/40960 [00:14<01:07, 508.02batches/s, l2_loss: 11.5709 - round_los\u001b[A\n",
      "Training:  17%|▏| 6871/40960 [00:14<01:07, 508.02batches/s, l2_loss: 11.5372 - round_los\u001b[A\n",
      "Training:  17%|▏| 6974/40960 [00:14<01:06, 508.80batches/s, l2_loss: 11.5372 - round_los\u001b[A\n",
      "Training:  17%|▏| 6974/40960 [00:14<01:06, 508.80batches/s, l2_loss: 11.5118 - round_los\u001b[A\n",
      "Training:  17%|▏| 7074/40960 [00:15<01:07, 505.34batches/s, l2_loss: 11.5118 - round_los\u001b[A\n",
      "Training:  17%|▏| 7074/40960 [00:15<01:07, 505.34batches/s, l2_loss: 11.4832 - round_los\u001b[A\n",
      "Training:  18%|▏| 7176/40960 [00:15<01:06, 506.42batches/s, l2_loss: 11.4832 - round_los\u001b[A\n",
      "Training:  18%|▏| 7176/40960 [00:15<01:06, 506.42batches/s, l2_loss: 11.4573 - round_los\u001b[A\n",
      "Training:  18%|▏| 7279/40960 [00:15<01:06, 507.80batches/s, l2_loss: 11.4573 - round_los\u001b[A\n",
      "Training:  18%|▏| 7279/40960 [00:15<01:06, 507.80batches/s, l2_loss: 11.4268 - round_los\u001b[A\n",
      "Training:  18%|▏| 7381/40960 [00:15<01:06, 507.77batches/s, l2_loss: 11.4268 - round_los\u001b[A\n",
      "Training:  18%|▏| 7381/40960 [00:15<01:06, 507.77batches/s, l2_loss: 11.4022 - round_los\u001b[A\n",
      "Training:  18%|▏| 7483/40960 [00:15<01:05, 508.03batches/s, l2_loss: 11.4022 - round_los\u001b[A\n",
      "Training:  18%|▏| 7483/40960 [00:15<01:05, 508.03batches/s, l2_loss: 11.3751 - round_los\u001b[A\n",
      "Training:  19%|▏| 7583/40960 [00:16<01:06, 504.79batches/s, l2_loss: 11.3751 - round_los\u001b[A\n",
      "Training:  19%|▏| 7583/40960 [00:16<01:06, 504.79batches/s, l2_loss: 11.3483 - round_los\u001b[A\n",
      "Training:  19%|▏| 7685/40960 [00:16<01:05, 504.99batches/s, l2_loss: 11.3483 - round_los\u001b[A\n",
      "Training:  19%|▏| 7685/40960 [00:16<01:05, 504.99batches/s, l2_loss: 11.3261 - round_los\u001b[A\n",
      "Training:  19%|▏| 7787/40960 [00:16<01:05, 506.43batches/s, l2_loss: 11.3261 - round_los\u001b[A\n",
      "Training:  19%|▏| 7787/40960 [00:16<01:05, 506.43batches/s, l2_loss: 11.3000 - round_los\u001b[A\n",
      "Training:  19%|▏| 7888/40960 [00:16<01:05, 505.28batches/s, l2_loss: 11.3000 - round_los\u001b[A\n",
      "Training:  19%|▏| 7888/40960 [00:16<01:05, 505.28batches/s, l2_loss: 11.2752 - round_los\u001b[A\n",
      "Training:  20%|▏| 7991/40960 [00:16<01:05, 506.96batches/s, l2_loss: 11.2752 - round_los\u001b[A\n",
      "Training:  20%|▏| 7991/40960 [00:16<01:05, 506.96batches/s, l2_loss: 11.2529 - round_los\u001b[A\n",
      "Training:  20%|▏| 8093/40960 [00:17<01:04, 507.82batches/s, l2_loss: 11.2529 - round_los\u001b[A\n",
      "Training:  20%|▏| 8093/40960 [00:17<01:04, 507.82batches/s, l2_loss: 11.2299 - round_los\u001b[A\n",
      "Training:  20%|▏| 8193/40960 [00:17<01:04, 505.16batches/s, l2_loss: 11.2299 - round_los\u001b[A\n",
      "Training:  20%|▏| 8193/40960 [00:17<01:04, 505.16batches/s, l2_loss: 8.6742 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8283/40960 [00:17<01:06, 488.57batches/s, l2_loss: 8.6742 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8283/40960 [00:17<01:06, 488.57batches/s, l2_loss: 9.5358 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8374/40960 [00:17<01:08, 478.44batches/s, l2_loss: 9.5358 - round_loss\u001b[A\n",
      "Training:  20%|▏| 8374/40960 [00:17<01:08, 478.44batches/s, l2_loss: 9.2115 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8468/40960 [00:17<01:08, 475.35batches/s, l2_loss: 9.2115 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8468/40960 [00:17<01:08, 475.35batches/s, l2_loss: 9.3314 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8561/40960 [00:18<01:08, 471.40batches/s, l2_loss: 9.3314 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8561/40960 [00:18<01:08, 471.40batches/s, l2_loss: 9.2573 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8654/40960 [00:18<01:08, 468.66batches/s, l2_loss: 9.2573 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8654/40960 [00:18<01:08, 468.66batches/s, l2_loss: 9.2923 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8746/40960 [00:18<01:09, 465.78batches/s, l2_loss: 9.2923 - round_loss\u001b[A\n",
      "Training:  21%|▏| 8746/40960 [00:18<01:09, 465.78batches/s, l2_loss: 9.2582 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8838/40960 [00:18<01:09, 462.73batches/s, l2_loss: 9.2582 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8838/40960 [00:18<01:09, 462.73batches/s, l2_loss: 9.2198 - round_loss\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|▏| 8929/40960 [00:18<01:09, 460.08batches/s, l2_loss: 9.2198 - round_loss\u001b[A\n",
      "Training:  22%|▏| 8929/40960 [00:18<01:09, 460.08batches/s, l2_loss: 9.2037 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9021/40960 [00:19<01:09, 459.02batches/s, l2_loss: 9.2037 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9021/40960 [00:19<01:09, 459.02batches/s, l2_loss: 9.2118 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9113/40960 [00:19<01:09, 458.25batches/s, l2_loss: 9.2118 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9113/40960 [00:19<01:09, 458.25batches/s, l2_loss: 9.2002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9205/40960 [00:19<01:09, 457.51batches/s, l2_loss: 9.2002 - round_loss\u001b[A\n",
      "Training:  22%|▏| 9205/40960 [00:19<01:09, 457.51batches/s, l2_loss: 9.1996 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9294/40960 [00:19<01:09, 452.98batches/s, l2_loss: 9.1996 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9294/40960 [00:19<01:09, 452.98batches/s, l2_loss: 9.1683 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9386/40960 [00:19<01:09, 454.63batches/s, l2_loss: 9.1683 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9386/40960 [00:19<01:09, 454.63batches/s, l2_loss: 9.1810 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9479/40960 [00:20<01:08, 457.00batches/s, l2_loss: 9.1810 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9479/40960 [00:20<01:08, 457.00batches/s, l2_loss: 9.1668 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9570/40960 [00:20<01:08, 455.84batches/s, l2_loss: 9.1668 - round_loss\u001b[A\n",
      "Training:  23%|▏| 9570/40960 [00:20<01:08, 455.84batches/s, l2_loss: 9.1522 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9658/40960 [00:20<01:09, 449.90batches/s, l2_loss: 9.1522 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9658/40960 [00:20<01:09, 449.90batches/s, l2_loss: 9.1523 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9751/40960 [00:20<01:08, 454.15batches/s, l2_loss: 9.1523 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9751/40960 [00:20<01:08, 454.15batches/s, l2_loss: 9.1360 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9841/40960 [00:20<01:08, 452.11batches/s, l2_loss: 9.1360 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9841/40960 [00:20<01:08, 452.11batches/s, l2_loss: 9.1334 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9933/40960 [00:21<01:08, 454.42batches/s, l2_loss: 9.1334 - round_loss\u001b[A\n",
      "Training:  24%|▏| 9933/40960 [00:21<01:08, 454.42batches/s, l2_loss: 9.1294 - round_loss\u001b[A\n",
      "Training:  24%|▏| 10027/40960 [00:21<01:07, 457.64batches/s, l2_loss: 9.1294 - round_los\u001b[A\n",
      "Training:  24%|▏| 10027/40960 [00:21<01:07, 457.64batches/s, l2_loss: 9.1075 - round_los\u001b[A\n",
      "Training:  25%|▏| 10118/40960 [00:21<01:07, 455.88batches/s, l2_loss: 9.1075 - round_los\u001b[A\n",
      "Training:  25%|▏| 10118/40960 [00:21<01:07, 455.88batches/s, l2_loss: 9.1050 - round_los\u001b[A\n",
      "Training:  25%|▏| 10209/40960 [00:21<01:07, 454.97batches/s, l2_loss: 9.1050 - round_los\u001b[A\n",
      "Training:  25%|▏| 10209/40960 [00:21<01:07, 454.97batches/s, l2_loss: 9.0953 - round_los\u001b[A\n",
      "Training:  25%|▎| 10301/40960 [00:22<01:07, 455.77batches/s, l2_loss: 9.0953 - round_los\u001b[A\n",
      "Training:  25%|▎| 10301/40960 [00:22<01:07, 455.77batches/s, l2_loss: 9.0922 - round_los\u001b[A\n",
      "Training:  25%|▎| 10392/40960 [00:22<01:07, 454.19batches/s, l2_loss: 9.0922 - round_los\u001b[A\n",
      "Training:  25%|▎| 10392/40960 [00:22<01:07, 454.19batches/s, l2_loss: 9.0786 - round_los\u001b[A\n",
      "Training:  26%|▎| 10485/40960 [00:22<01:06, 456.38batches/s, l2_loss: 9.0786 - round_los\u001b[A\n",
      "Training:  26%|▎| 10485/40960 [00:22<01:06, 456.38batches/s, l2_loss: 9.0694 - round_los\u001b[A\n",
      "Training:  26%|▎| 10578/40960 [00:22<01:06, 457.73batches/s, l2_loss: 9.0694 - round_los\u001b[A\n",
      "Training:  26%|▎| 10578/40960 [00:22<01:06, 457.73batches/s, l2_loss: 9.0707 - round_los\u001b[A\n",
      "Training:  26%|▎| 10668/40960 [00:22<01:06, 454.69batches/s, l2_loss: 9.0707 - round_los\u001b[A\n",
      "Training:  26%|▎| 10668/40960 [00:22<01:06, 454.69batches/s, l2_loss: 9.0529 - round_los\u001b[A\n",
      "Training:  26%|▎| 10760/40960 [00:23<01:06, 455.52batches/s, l2_loss: 9.0529 - round_los\u001b[A\n",
      "Training:  26%|▎| 10760/40960 [00:23<01:06, 455.52batches/s, l2_loss: 9.0553 - round_los\u001b[A\n",
      "Training:  26%|▎| 10849/40960 [00:23<01:06, 451.32batches/s, l2_loss: 9.0553 - round_los\u001b[A\n",
      "Training:  26%|▎| 10849/40960 [00:23<01:06, 451.32batches/s, l2_loss: 9.0560 - round_los\u001b[A\n",
      "Training:  27%|▎| 10941/40960 [00:23<01:06, 452.55batches/s, l2_loss: 9.0560 - round_los\u001b[A\n",
      "Training:  27%|▎| 10941/40960 [00:23<01:06, 452.55batches/s, l2_loss: 9.0491 - round_los\u001b[A\n",
      "Training:  27%|▎| 11032/40960 [00:23<01:06, 452.21batches/s, l2_loss: 9.0491 - round_los\u001b[A\n",
      "Training:  27%|▎| 11032/40960 [00:23<01:06, 452.21batches/s, l2_loss: 9.0361 - round_los\u001b[A\n",
      "Training:  27%|▎| 11124/40960 [00:23<01:05, 454.43batches/s, l2_loss: 9.0361 - round_los\u001b[A\n",
      "Training:  27%|▎| 11124/40960 [00:23<01:05, 454.43batches/s, l2_loss: 9.0271 - round_los\u001b[A\n",
      "Training:  27%|▎| 11216/40960 [00:24<01:05, 455.53batches/s, l2_loss: 9.0271 - round_los\u001b[A\n",
      "Training:  27%|▎| 11216/40960 [00:24<01:05, 455.53batches/s, l2_loss: 9.0251 - round_los\u001b[A\n",
      "Training:  28%|▎| 11310/40960 [00:24<01:04, 458.41batches/s, l2_loss: 9.0251 - round_los\u001b[A\n",
      "Training:  28%|▎| 11310/40960 [00:24<01:04, 458.41batches/s, l2_loss: 9.0148 - round_los\u001b[A\n",
      "Training:  28%|▎| 11399/40960 [00:24<01:05, 453.06batches/s, l2_loss: 9.0148 - round_los\u001b[A\n",
      "Training:  28%|▎| 11399/40960 [00:24<01:05, 453.06batches/s, l2_loss: 9.0089 - round_los\u001b[A\n",
      "Training:  28%|▎| 11487/40960 [00:24<01:05, 448.05batches/s, l2_loss: 9.0089 - round_los\u001b[A\n",
      "Training:  28%|▎| 11487/40960 [00:24<01:05, 448.05batches/s, l2_loss: 9.0047 - round_los\u001b[A\n",
      "Training:  28%|▎| 11578/40960 [00:24<01:05, 449.49batches/s, l2_loss: 9.0047 - round_los\u001b[A\n",
      "Training:  28%|▎| 11578/40960 [00:24<01:05, 449.49batches/s, l2_loss: 8.9939 - round_los\u001b[A\n",
      "Training:  28%|▎| 11671/40960 [00:25<01:04, 452.67batches/s, l2_loss: 8.9939 - round_los\u001b[A\n",
      "Training:  28%|▎| 11671/40960 [00:25<01:04, 452.67batches/s, l2_loss: 8.9791 - round_los\u001b[A\n",
      "Training:  29%|▎| 11761/40960 [00:25<01:04, 450.81batches/s, l2_loss: 8.9791 - round_los\u001b[A\n",
      "Training:  29%|▎| 11761/40960 [00:25<01:04, 450.81batches/s, l2_loss: 8.9801 - round_los\u001b[A\n",
      "Training:  29%|▎| 11853/40960 [00:25<01:04, 452.31batches/s, l2_loss: 8.9801 - round_los\u001b[A\n",
      "Training:  29%|▎| 11853/40960 [00:25<01:04, 452.31batches/s, l2_loss: 8.9732 - round_los\u001b[A\n",
      "Training:  29%|▎| 11943/40960 [00:25<01:04, 450.97batches/s, l2_loss: 8.9732 - round_los\u001b[A\n",
      "Training:  29%|▎| 11943/40960 [00:25<01:04, 450.97batches/s, l2_loss: 8.9699 - round_los\u001b[A\n",
      "Training:  29%|▎| 12036/40960 [00:25<01:03, 453.75batches/s, l2_loss: 8.9699 - round_los\u001b[A\n",
      "Training:  29%|▎| 12036/40960 [00:25<01:03, 453.75batches/s, l2_loss: 8.9597 - round_los\u001b[A\n",
      "Training:  30%|▎| 12126/40960 [00:26<01:03, 451.87batches/s, l2_loss: 8.9597 - round_los\u001b[A\n",
      "Training:  30%|▎| 12126/40960 [00:26<01:03, 451.87batches/s, l2_loss: 8.9503 - round_los\u001b[A\n",
      "Training:  30%|▎| 12215/40960 [00:26<01:04, 449.09batches/s, l2_loss: 8.9503 - round_los\u001b[A\n",
      "Training:  30%|▎| 12215/40960 [00:26<01:04, 449.09batches/s, l2_loss: 8.9470 - round_los\u001b[A\n",
      "Training:  30%|▎| 12305/40960 [00:26<01:03, 448.87batches/s, l2_loss: 8.9470 - round_los\u001b[A\n",
      "Training:  30%|▎| 12305/40960 [00:26<01:03, 448.87batches/s, l2_loss: 8.9448 - round_los\u001b[A\n",
      "Training:  30%|▎| 12395/40960 [00:26<01:03, 448.12batches/s, l2_loss: 8.9448 - round_los\u001b[A\n",
      "Training:  30%|▎| 12395/40960 [00:26<01:03, 448.12batches/s, l2_loss: 8.9380 - round_los\u001b[A\n",
      "Training:  30%|▎| 12485/40960 [00:26<01:03, 448.56batches/s, l2_loss: 8.9380 - round_los\u001b[A\n",
      "Training:  30%|▎| 12485/40960 [00:26<01:03, 448.56batches/s, l2_loss: 8.9312 - round_los\u001b[A\n",
      "Training:  31%|▎| 12575/40960 [00:27<01:03, 448.21batches/s, l2_loss: 8.9312 - round_los\u001b[A\n",
      "Training:  31%|▎| 12575/40960 [00:27<01:03, 448.21batches/s, l2_loss: 8.9199 - round_los\u001b[A\n",
      "Training:  31%|▎| 12665/40960 [00:27<01:03, 448.29batches/s, l2_loss: 8.9199 - round_los\u001b[A\n",
      "Training:  31%|▎| 12665/40960 [00:27<01:03, 448.29batches/s, l2_loss: 8.9178 - round_los\u001b[A\n",
      "Training:  31%|▎| 12754/40960 [00:27<01:03, 445.97batches/s, l2_loss: 8.9178 - round_los\u001b[A\n",
      "Training:  31%|▎| 12754/40960 [00:27<01:03, 445.97batches/s, l2_loss: 8.9101 - round_los\u001b[A\n",
      "Training:  31%|▎| 12846/40960 [00:27<01:02, 449.78batches/s, l2_loss: 8.9101 - round_los\u001b[A\n",
      "Training:  31%|▎| 12846/40960 [00:27<01:02, 449.78batches/s, l2_loss: 8.9018 - round_los\u001b[A\n",
      "Training:  32%|▎| 12938/40960 [00:27<01:01, 452.15batches/s, l2_loss: 8.9018 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|▎| 12938/40960 [00:27<01:01, 452.15batches/s, l2_loss: 8.9017 - round_los\u001b[A\n",
      "Training:  32%|▎| 13027/40960 [00:28<01:02, 449.39batches/s, l2_loss: 8.9017 - round_los\u001b[A\n",
      "Training:  32%|▎| 13027/40960 [00:28<01:02, 449.39batches/s, l2_loss: 8.8988 - round_los\u001b[A\n",
      "Training:  32%|▎| 13116/40960 [00:28<01:02, 447.08batches/s, l2_loss: 8.8988 - round_los\u001b[A\n",
      "Training:  32%|▎| 13116/40960 [00:28<01:02, 447.08batches/s, l2_loss: 8.8901 - round_los\u001b[A\n",
      "Training:  32%|▎| 13207/40960 [00:28<01:01, 449.13batches/s, l2_loss: 8.8901 - round_los\u001b[A\n",
      "Training:  32%|▎| 13207/40960 [00:28<01:01, 449.13batches/s, l2_loss: 8.8851 - round_los\u001b[A\n",
      "Training:  32%|▎| 13297/40960 [00:28<01:01, 449.17batches/s, l2_loss: 8.8851 - round_los\u001b[A\n",
      "Training:  32%|▎| 13297/40960 [00:28<01:01, 449.17batches/s, l2_loss: 8.8821 - round_los\u001b[A\n",
      "Training:  33%|▎| 13388/40960 [00:28<01:01, 450.08batches/s, l2_loss: 8.8821 - round_los\u001b[A\n",
      "Training:  33%|▎| 13388/40960 [00:28<01:01, 450.08batches/s, l2_loss: 8.8722 - round_los\u001b[A\n",
      "Training:  33%|▎| 13478/40960 [00:29<01:01, 448.80batches/s, l2_loss: 8.8722 - round_los\u001b[A\n",
      "Training:  33%|▎| 13478/40960 [00:29<01:01, 448.80batches/s, l2_loss: 8.8696 - round_los\u001b[A\n",
      "Training:  33%|▎| 13566/40960 [00:29<01:01, 445.73batches/s, l2_loss: 8.8696 - round_los\u001b[A\n",
      "Training:  33%|▎| 13566/40960 [00:29<01:01, 445.73batches/s, l2_loss: 8.8624 - round_los\u001b[A\n",
      "Training:  33%|▎| 13656/40960 [00:29<01:01, 446.91batches/s, l2_loss: 8.8624 - round_los\u001b[A\n",
      "Training:  33%|▎| 13656/40960 [00:29<01:01, 446.91batches/s, l2_loss: 8.8531 - round_los\u001b[A\n",
      "Training:  34%|▎| 13746/40960 [00:29<01:00, 447.49batches/s, l2_loss: 8.8531 - round_los\u001b[A\n",
      "Training:  34%|▎| 13746/40960 [00:29<01:00, 447.49batches/s, l2_loss: 8.8546 - round_los\u001b[A\n",
      "Training:  34%|▎| 13835/40960 [00:29<01:00, 445.71batches/s, l2_loss: 8.8546 - round_los\u001b[A\n",
      "Training:  34%|▎| 13835/40960 [00:29<01:00, 445.71batches/s, l2_loss: 8.8451 - round_los\u001b[A\n",
      "Training:  34%|▎| 13924/40960 [00:30<01:00, 445.45batches/s, l2_loss: 8.8451 - round_los\u001b[A\n",
      "Training:  34%|▎| 13924/40960 [00:30<01:00, 445.45batches/s, l2_loss: 8.8378 - round_los\u001b[A\n",
      "Training:  34%|▎| 14011/40960 [00:30<01:01, 440.86batches/s, l2_loss: 8.8378 - round_los\u001b[A\n",
      "Training:  34%|▎| 14011/40960 [00:30<01:01, 440.86batches/s, l2_loss: 8.8371 - round_los\u001b[A\n",
      "Training:  34%|▎| 14102/40960 [00:30<01:00, 443.75batches/s, l2_loss: 8.8371 - round_los\u001b[A\n",
      "Training:  34%|▎| 14102/40960 [00:30<01:00, 443.75batches/s, l2_loss: 8.8278 - round_los\u001b[A\n",
      "Training:  35%|▎| 14192/40960 [00:30<01:00, 445.61batches/s, l2_loss: 8.8278 - round_los\u001b[A\n",
      "Training:  35%|▎| 14192/40960 [00:30<01:00, 445.61batches/s, l2_loss: 8.8243 - round_los\u001b[A\n",
      "Training:  35%|▎| 14281/40960 [00:30<01:00, 444.60batches/s, l2_loss: 8.8243 - round_los\u001b[A\n",
      "Training:  35%|▎| 14281/40960 [00:30<01:00, 444.60batches/s, l2_loss: 8.8193 - round_los\u001b[A\n",
      "Training:  35%|▎| 14371/40960 [00:31<00:59, 445.20batches/s, l2_loss: 8.8193 - round_los\u001b[A\n",
      "Training:  35%|▎| 14371/40960 [00:31<00:59, 445.20batches/s, l2_loss: 8.8138 - round_los\u001b[A\n",
      "Training:  35%|▎| 14462/40960 [00:31<00:59, 447.52batches/s, l2_loss: 8.8138 - round_los\u001b[A\n",
      "Training:  35%|▎| 14462/40960 [00:31<00:59, 447.52batches/s, l2_loss: 8.8091 - round_los\u001b[A\n",
      "Training:  36%|▎| 14552/40960 [00:31<00:59, 447.22batches/s, l2_loss: 8.8091 - round_los\u001b[A\n",
      "Training:  36%|▎| 14552/40960 [00:31<00:59, 447.22batches/s, l2_loss: 8.8011 - round_los\u001b[A\n",
      "Training:  36%|▎| 14641/40960 [00:31<00:59, 445.36batches/s, l2_loss: 8.8011 - round_los\u001b[A\n",
      "Training:  36%|▎| 14641/40960 [00:31<00:59, 445.36batches/s, l2_loss: 8.8003 - round_los\u001b[A\n",
      "Training:  36%|▎| 14723/40960 [00:31<01:00, 434.71batches/s, l2_loss: 8.8003 - round_los\u001b[A\n",
      "Training:  36%|▎| 14723/40960 [00:31<01:00, 434.71batches/s, l2_loss: 8.7942 - round_los\u001b[A\n",
      "Training:  36%|▎| 14805/40960 [00:32<01:01, 427.19batches/s, l2_loss: 8.7942 - round_los\u001b[A\n",
      "Training:  36%|▎| 14805/40960 [00:32<01:01, 427.19batches/s, l2_loss: 8.7890 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:32<01:00, 433.86batches/s, l2_loss: 8.7890 - round_los\u001b[A\n",
      "Training:  36%|▎| 14895/40960 [00:32<01:00, 433.86batches/s, l2_loss: 8.7856 - round_los\u001b[A\n",
      "Training:  37%|▎| 14981/40960 [00:32<01:00, 432.50batches/s, l2_loss: 8.7856 - round_los\u001b[A\n",
      "Training:  37%|▎| 14981/40960 [00:32<01:00, 432.50batches/s, l2_loss: 8.7802 - round_los\u001b[A\n",
      "Training:  37%|▎| 15063/40960 [00:32<01:00, 424.57batches/s, l2_loss: 8.7802 - round_los\u001b[A\n",
      "Training:  37%|▎| 15063/40960 [00:32<01:00, 424.57batches/s, l2_loss: 8.7758 - round_los\u001b[A\n",
      "Training:  37%|▎| 15151/40960 [00:32<01:00, 427.85batches/s, l2_loss: 8.7758 - round_los\u001b[A\n",
      "Training:  37%|▎| 15151/40960 [00:32<01:00, 427.85batches/s, l2_loss: 8.7687 - round_los\u001b[A\n",
      "Training:  37%|▎| 15240/40960 [00:33<00:59, 431.83batches/s, l2_loss: 8.7687 - round_los\u001b[A\n",
      "Training:  37%|▎| 15240/40960 [00:33<00:59, 431.83batches/s, l2_loss: 8.7679 - round_los\u001b[A\n",
      "Training:  37%|▎| 15332/40960 [00:33<00:58, 438.90batches/s, l2_loss: 8.7679 - round_los\u001b[A\n",
      "Training:  37%|▎| 15332/40960 [00:33<00:58, 438.90batches/s, l2_loss: 8.7623 - round_los\u001b[A\n",
      "Training:  38%|▍| 15420/40960 [00:33<00:58, 439.18batches/s, l2_loss: 8.7623 - round_los\u001b[A\n",
      "Training:  38%|▍| 15420/40960 [00:33<00:58, 439.18batches/s, l2_loss: 8.7542 - round_los\u001b[A\n",
      "Training:  38%|▍| 15510/40960 [00:33<00:57, 441.05batches/s, l2_loss: 8.7542 - round_los\u001b[A\n",
      "Training:  38%|▍| 15510/40960 [00:33<00:57, 441.05batches/s, l2_loss: 8.7549 - round_los\u001b[A\n",
      "Training:  38%|▍| 15599/40960 [00:33<00:57, 441.56batches/s, l2_loss: 8.7549 - round_los\u001b[A\n",
      "Training:  38%|▍| 15599/40960 [00:33<00:57, 441.56batches/s, l2_loss: 8.7479 - round_los\u001b[A\n",
      "Training:  38%|▍| 15684/40960 [00:34<00:58, 435.72batches/s, l2_loss: 8.7479 - round_los\u001b[A\n",
      "Training:  38%|▍| 15684/40960 [00:34<00:58, 435.72batches/s, l2_loss: 8.7437 - round_los\u001b[A\n",
      "Training:  38%|▍| 15762/40960 [00:34<00:59, 421.83batches/s, l2_loss: 8.7437 - round_los\u001b[A\n",
      "Training:  38%|▍| 15762/40960 [00:34<00:59, 421.83batches/s, l2_loss: 8.7385 - round_los\u001b[A\n",
      "Training:  39%|▍| 15849/40960 [00:34<00:59, 424.47batches/s, l2_loss: 8.7385 - round_los\u001b[A\n",
      "Training:  39%|▍| 15849/40960 [00:34<00:59, 424.47batches/s, l2_loss: 8.7351 - round_los\u001b[A\n",
      "Training:  39%|▍| 15940/40960 [00:34<00:57, 433.30batches/s, l2_loss: 8.7351 - round_los\u001b[A\n",
      "Training:  39%|▍| 15940/40960 [00:34<00:57, 433.30batches/s, l2_loss: 8.7334 - round_los\u001b[A\n",
      "Training:  39%|▍| 16029/40960 [00:34<00:57, 436.65batches/s, l2_loss: 8.7334 - round_los\u001b[A\n",
      "Training:  39%|▍| 16029/40960 [00:34<00:57, 436.65batches/s, l2_loss: 8.7265 - round_los\u001b[A\n",
      "Training:  39%|▍| 16119/40960 [00:35<00:56, 439.40batches/s, l2_loss: 8.7265 - round_los\u001b[A\n",
      "Training:  39%|▍| 16119/40960 [00:35<00:56, 439.40batches/s, l2_loss: 8.7197 - round_los\u001b[A\n",
      "Training:  40%|▍| 16204/40960 [00:35<00:57, 433.55batches/s, l2_loss: 8.7197 - round_los\u001b[A\n",
      "Training:  40%|▍| 16204/40960 [00:35<00:57, 433.55batches/s, l2_loss: 8.7197 - round_los\u001b[A\n",
      "Training:  40%|▍| 16277/40960 [00:35<00:59, 412.87batches/s, l2_loss: 8.7197 - round_los\u001b[A\n",
      "Training:  40%|▍| 16277/40960 [00:35<00:59, 412.87batches/s, l2_loss: 8.7127 - round_los\u001b[A\n",
      "Training:  40%|▍| 16364/40960 [00:35<00:58, 418.19batches/s, l2_loss: 8.7127 - round_los\u001b[A\n",
      "Training:  40%|▍| 16364/40960 [00:35<00:58, 418.19batches/s, l2_loss: 8.7095 - round_los\u001b[A\n",
      "Training:  40%|▍| 16454/40960 [00:35<00:57, 426.38batches/s, l2_loss: 8.7095 - round_los\u001b[A\n",
      "Training:  40%|▍| 16454/40960 [00:35<00:57, 426.38batches/s, l2_loss: 8.7058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16534/40960 [00:36<00:58, 417.82batches/s, l2_loss: 8.7058 - round_los\u001b[A\n",
      "Training:  40%|▍| 16534/40960 [00:36<00:58, 417.82batches/s, l2_loss: 8.7016 - round_los\u001b[A\n",
      "Training:  41%|▍| 16621/40960 [00:36<00:57, 422.09batches/s, l2_loss: 8.7016 - round_los\u001b[A\n",
      "Training:  41%|▍| 16621/40960 [00:36<00:57, 422.09batches/s, l2_loss: 8.6979 - round_los\u001b[A\n",
      "Training:  41%|▍| 16711/40960 [00:36<00:56, 429.12batches/s, l2_loss: 8.6979 - round_los\u001b[A\n",
      "Training:  41%|▍| 16711/40960 [00:36<00:56, 429.12batches/s, l2_loss: 8.6947 - round_los\u001b[A\n",
      "Training:  41%|▍| 16800/40960 [00:36<00:55, 433.23batches/s, l2_loss: 8.6947 - round_los\u001b[A\n",
      "Training:  41%|▍| 16800/40960 [00:36<00:55, 433.23batches/s, l2_loss: 8.6904 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|▍| 16891/40960 [00:36<00:54, 439.49batches/s, l2_loss: 8.6904 - round_los\u001b[A\n",
      "Training:  41%|▍| 16891/40960 [00:36<00:54, 439.49batches/s, l2_loss: 8.6843 - round_los\u001b[A\n",
      "Training:  41%|▍| 16973/40960 [00:37<00:55, 430.52batches/s, l2_loss: 8.6843 - round_los\u001b[A\n",
      "Training:  41%|▍| 16973/40960 [00:37<00:55, 430.52batches/s, l2_loss: 8.6810 - round_los\u001b[A\n",
      "Training:  42%|▍| 17058/40960 [00:37<00:55, 427.86batches/s, l2_loss: 8.6810 - round_los\u001b[A\n",
      "Training:  42%|▍| 17058/40960 [00:37<00:55, 427.86batches/s, l2_loss: 8.6785 - round_los\u001b[A\n",
      "Training:  42%|▍| 17149/40960 [00:37<00:54, 434.66batches/s, l2_loss: 8.6785 - round_los\u001b[A\n",
      "Training:  42%|▍| 17149/40960 [00:37<00:54, 434.66batches/s, l2_loss: 8.6738 - round_los\u001b[A\n",
      "Training:  42%|▍| 17238/40960 [00:37<00:54, 436.73batches/s, l2_loss: 8.6738 - round_los\u001b[A\n",
      "Training:  42%|▍| 17238/40960 [00:37<00:54, 436.73batches/s, l2_loss: 8.6692 - round_los\u001b[A\n",
      "Training:  42%|▍| 17326/40960 [00:37<00:54, 436.68batches/s, l2_loss: 8.6692 - round_los\u001b[A\n",
      "Training:  42%|▍| 17326/40960 [00:37<00:54, 436.68batches/s, l2_loss: 8.6654 - round_los\u001b[A\n",
      "Training:  43%|▍| 17416/40960 [00:38<00:53, 439.51batches/s, l2_loss: 8.6654 - round_los\u001b[A\n",
      "Training:  43%|▍| 17416/40960 [00:38<00:53, 439.51batches/s, l2_loss: 8.6617 - round_los\u001b[A\n",
      "Training:  43%|▍| 17507/40960 [00:38<00:52, 443.96batches/s, l2_loss: 8.6617 - round_los\u001b[A\n",
      "Training:  43%|▍| 17507/40960 [00:38<00:52, 443.96batches/s, l2_loss: 8.6595 - round_los\u001b[A\n",
      "Training:  43%|▍| 17599/40960 [00:38<00:52, 448.27batches/s, l2_loss: 8.6595 - round_los\u001b[A\n",
      "Training:  43%|▍| 17599/40960 [00:38<00:52, 448.27batches/s, l2_loss: 8.6544 - round_los\u001b[A\n",
      "Training:  43%|▍| 17692/40960 [00:38<00:51, 452.96batches/s, l2_loss: 8.6544 - round_los\u001b[A\n",
      "Training:  43%|▍| 17692/40960 [00:38<00:51, 452.96batches/s, l2_loss: 8.6518 - round_los\u001b[A\n",
      "Training:  43%|▍| 17783/40960 [00:38<00:51, 453.41batches/s, l2_loss: 8.6518 - round_los\u001b[A\n",
      "Training:  43%|▍| 17783/40960 [00:38<00:51, 453.41batches/s, l2_loss: 8.6473 - round_los\u001b[A\n",
      "Training:  44%|▍| 17873/40960 [00:39<00:51, 452.06batches/s, l2_loss: 8.6473 - round_los\u001b[A\n",
      "Training:  44%|▍| 17873/40960 [00:39<00:51, 452.06batches/s, l2_loss: 8.6451 - round_los\u001b[A\n",
      "Training:  44%|▍| 17966/40960 [00:39<00:50, 454.55batches/s, l2_loss: 8.6451 - round_los\u001b[A\n",
      "Training:  44%|▍| 17966/40960 [00:39<00:50, 454.55batches/s, l2_loss: 8.6384 - round_los\u001b[A\n",
      "Training:  44%|▍| 18057/40960 [00:39<00:50, 453.28batches/s, l2_loss: 8.6384 - round_los\u001b[A\n",
      "Training:  44%|▍| 18057/40960 [00:39<00:50, 453.28batches/s, l2_loss: 8.6349 - round_los\u001b[A\n",
      "Training:  44%|▍| 18149/40960 [00:39<00:50, 454.85batches/s, l2_loss: 8.6349 - round_los\u001b[A\n",
      "Training:  44%|▍| 18149/40960 [00:39<00:50, 454.85batches/s, l2_loss: 8.6316 - round_los\u001b[A\n",
      "Training:  45%|▍| 18239/40960 [00:39<00:50, 453.38batches/s, l2_loss: 8.6316 - round_los\u001b[A\n",
      "Training:  45%|▍| 18239/40960 [00:39<00:50, 453.38batches/s, l2_loss: 8.6277 - round_los\u001b[A\n",
      "Training:  45%|▍| 18329/40960 [00:40<00:50, 452.25batches/s, l2_loss: 8.6277 - round_los\u001b[A\n",
      "Training:  45%|▍| 18329/40960 [00:40<00:50, 452.25batches/s, l2_loss: 8.6230 - round_los\u001b[A\n",
      "Training:  45%|▍| 18420/40960 [00:40<00:49, 451.93batches/s, l2_loss: 8.6230 - round_los\u001b[A\n",
      "Training:  45%|▍| 18420/40960 [00:40<00:49, 451.93batches/s, l2_loss: 8.6198 - round_los\u001b[A\n",
      "Training:  45%|▍| 18508/40960 [00:40<00:50, 447.93batches/s, l2_loss: 8.6198 - round_los\u001b[A\n",
      "Training:  45%|▍| 18508/40960 [00:40<00:50, 447.93batches/s, l2_loss: 8.6162 - round_los\u001b[A\n",
      "Training:  45%|▍| 18595/40960 [00:40<00:50, 443.50batches/s, l2_loss: 8.6162 - round_los\u001b[A\n",
      "Training:  45%|▍| 18595/40960 [00:40<00:50, 443.50batches/s, l2_loss: 8.6116 - round_los\u001b[A\n",
      "Training:  46%|▍| 18681/40960 [00:40<00:50, 438.71batches/s, l2_loss: 8.6116 - round_los\u001b[A\n",
      "Training:  46%|▍| 18681/40960 [00:40<00:50, 438.71batches/s, l2_loss: 8.6089 - round_los\u001b[A\n",
      "Training:  46%|▍| 18772/40960 [00:41<00:50, 442.44batches/s, l2_loss: 8.6089 - round_los\u001b[A\n",
      "Training:  46%|▍| 18772/40960 [00:41<00:50, 442.44batches/s, l2_loss: 8.6047 - round_los\u001b[A\n",
      "Training:  46%|▍| 18863/40960 [00:41<00:49, 444.75batches/s, l2_loss: 8.6047 - round_los\u001b[A\n",
      "Training:  46%|▍| 18863/40960 [00:41<00:49, 444.75batches/s, l2_loss: 8.5999 - round_los\u001b[A\n",
      "Training:  46%|▍| 18954/40960 [00:41<00:49, 447.35batches/s, l2_loss: 8.5999 - round_los\u001b[A\n",
      "Training:  46%|▍| 18954/40960 [00:41<00:49, 447.35batches/s, l2_loss: 8.5988 - round_los\u001b[A\n",
      "Training:  46%|▍| 19044/40960 [00:41<00:48, 448.06batches/s, l2_loss: 8.5988 - round_los\u001b[A\n",
      "Training:  46%|▍| 19044/40960 [00:41<00:48, 448.06batches/s, l2_loss: 8.5958 - round_los\u001b[A\n",
      "Training:  47%|▍| 19133/40960 [00:41<00:48, 445.81batches/s, l2_loss: 8.5958 - round_los\u001b[A\n",
      "Training:  47%|▍| 19133/40960 [00:41<00:48, 445.81batches/s, l2_loss: 8.5919 - round_los\u001b[A\n",
      "Training:  47%|▍| 19224/40960 [00:42<00:48, 448.47batches/s, l2_loss: 8.5919 - round_los\u001b[A\n",
      "Training:  47%|▍| 19224/40960 [00:42<00:48, 448.47batches/s, l2_loss: 8.5859 - round_los\u001b[A\n",
      "Training:  47%|▍| 19316/40960 [00:42<00:47, 451.50batches/s, l2_loss: 8.5859 - round_los\u001b[A\n",
      "Training:  47%|▍| 19316/40960 [00:42<00:47, 451.50batches/s, l2_loss: 8.5851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19406/40960 [00:42<00:47, 449.94batches/s, l2_loss: 8.5851 - round_los\u001b[A\n",
      "Training:  47%|▍| 19406/40960 [00:42<00:47, 449.94batches/s, l2_loss: 8.5825 - round_los\u001b[A\n",
      "Training:  48%|▍| 19495/40960 [00:42<00:47, 448.45batches/s, l2_loss: 8.5825 - round_los\u001b[A\n",
      "Training:  48%|▍| 19495/40960 [00:42<00:47, 448.45batches/s, l2_loss: 8.5774 - round_los\u001b[A\n",
      "Training:  48%|▍| 19588/40960 [00:42<00:47, 452.33batches/s, l2_loss: 8.5774 - round_los\u001b[A\n",
      "Training:  48%|▍| 19588/40960 [00:42<00:47, 452.33batches/s, l2_loss: 8.5738 - round_los\u001b[A\n",
      "Training:  48%|▍| 19676/40960 [00:43<00:47, 448.64batches/s, l2_loss: 8.5738 - round_los\u001b[A\n",
      "Training:  48%|▍| 19676/40960 [00:43<00:47, 448.64batches/s, l2_loss: 8.5718 - round_los\u001b[A\n",
      "Training:  48%|▍| 19767/40960 [00:43<00:47, 449.47batches/s, l2_loss: 8.5718 - round_los\u001b[A\n",
      "Training:  48%|▍| 19767/40960 [00:43<00:47, 449.47batches/s, l2_loss: 8.5664 - round_los\u001b[A\n",
      "Training:  48%|▍| 19856/40960 [00:43<00:47, 447.86batches/s, l2_loss: 8.5664 - round_los\u001b[A\n",
      "Training:  48%|▍| 19856/40960 [00:43<00:47, 447.86batches/s, l2_loss: 8.5643 - round_los\u001b[A\n",
      "Training:  49%|▍| 19948/40960 [00:43<00:46, 450.09batches/s, l2_loss: 8.5643 - round_los\u001b[A\n",
      "Training:  49%|▍| 19948/40960 [00:43<00:46, 450.09batches/s, l2_loss: 8.5611 - round_los\u001b[A\n",
      "Training:  49%|▍| 20040/40960 [00:43<00:46, 452.29batches/s, l2_loss: 8.5611 - round_los\u001b[A\n",
      "Training:  49%|▍| 20040/40960 [00:43<00:46, 452.29batches/s, l2_loss: 8.5568 - round_los\u001b[A\n",
      "Training:  49%|▍| 20132/40960 [00:44<00:45, 454.35batches/s, l2_loss: 8.5568 - round_los\u001b[A\n",
      "Training:  49%|▍| 20132/40960 [00:44<00:45, 454.35batches/s, l2_loss: 8.5545 - round_los\u001b[A\n",
      "Training:  49%|▍| 20222/40960 [00:44<00:45, 452.74batches/s, l2_loss: 8.5545 - round_los\u001b[A\n",
      "Training:  49%|▍| 20222/40960 [00:44<00:45, 452.74batches/s, l2_loss: 8.5514 - round_los\u001b[A\n",
      "Training:  50%|▍| 20314/40960 [00:44<00:45, 453.47batches/s, l2_loss: 8.5514 - round_los\u001b[A\n",
      "Training:  50%|▍| 20314/40960 [00:44<00:45, 453.47batches/s, l2_loss: 8.5467 - round_los\u001b[A\n",
      "Training:  50%|▍| 20406/40960 [00:44<00:45, 455.31batches/s, l2_loss: 8.5467 - round_los\u001b[A\n",
      "Training:  50%|▍| 20406/40960 [00:44<00:45, 455.31batches/s, l2_loss: 8.5441 - round_los\u001b[A\n",
      "Training:  50%|▌| 20497/40960 [00:44<00:45, 454.65batches/s, l2_loss: 8.5441 - round_los\u001b[A\n",
      "Training:  50%|▌| 20497/40960 [00:44<00:45, 454.65batches/s, l2_loss: 8.5426 - round_los\u001b[A\n",
      "Training:  50%|▌| 20588/40960 [00:45<00:44, 453.96batches/s, l2_loss: 8.5426 - round_los\u001b[A\n",
      "Training:  50%|▌| 20588/40960 [00:45<00:44, 453.96batches/s, l2_loss: 8.5380 - round_los\u001b[A\n",
      "Training:  50%|▌| 20671/40960 [00:45<00:45, 442.11batches/s, l2_loss: 8.5380 - round_los\u001b[A\n",
      "Training:  50%|▌| 20671/40960 [00:45<00:45, 442.11batches/s, l2_loss: 8.5368 - round_los\u001b[A\n",
      "Training:  51%|▌| 20739/40960 [00:45<00:49, 410.43batches/s, l2_loss: 8.5368 - round_los\u001b[A\n",
      "Training:  51%|▌| 20739/40960 [00:45<00:49, 410.43batches/s, l2_loss: 8.5328 - round_los\u001b[A\n",
      "Training:  51%|▌| 20830/40960 [00:45<00:47, 423.12batches/s, l2_loss: 8.5328 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|▌| 20830/40960 [00:45<00:47, 423.12batches/s, l2_loss: 8.5300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20906/40960 [00:45<00:49, 409.09batches/s, l2_loss: 8.5300 - round_los\u001b[A\n",
      "Training:  51%|▌| 20906/40960 [00:45<00:49, 409.09batches/s, l2_loss: 8.5267 - round_los\u001b[A\n",
      "Training:  51%|▌| 20998/40960 [00:46<00:47, 424.26batches/s, l2_loss: 8.5267 - round_los\u001b[A\n",
      "Training:  51%|▌| 20998/40960 [00:46<00:47, 424.26batches/s, l2_loss: 8.5238 - round_los\u001b[A\n",
      "Training:  51%|▌| 21088/40960 [00:46<00:46, 430.84batches/s, l2_loss: 8.5238 - round_los\u001b[A\n",
      "Training:  51%|▌| 21088/40960 [00:46<00:46, 430.84batches/s, l2_loss: 8.5204 - round_los\u001b[A\n",
      "Training:  52%|▌| 21179/40960 [00:46<00:45, 437.50batches/s, l2_loss: 8.5204 - round_los\u001b[A\n",
      "Training:  52%|▌| 21179/40960 [00:46<00:45, 437.50batches/s, l2_loss: 8.5162 - round_los\u001b[A\n",
      "Training:  52%|▌| 21244/40960 [00:46<00:48, 403.04batches/s, l2_loss: 8.5162 - round_los\u001b[A\n",
      "Training:  52%|▌| 21244/40960 [00:46<00:48, 403.04batches/s, l2_loss: 8.5143 - round_los\u001b[A\n",
      "Training:  52%|▌| 21333/40960 [00:46<00:47, 414.39batches/s, l2_loss: 8.5143 - round_los\u001b[A\n",
      "Training:  52%|▌| 21333/40960 [00:46<00:47, 414.39batches/s, l2_loss: 8.5120 - round_los\u001b[A\n",
      "Training:  52%|▌| 21416/40960 [00:47<00:47, 414.42batches/s, l2_loss: 8.5120 - round_los\u001b[A\n",
      "Training:  52%|▌| 21416/40960 [00:47<00:47, 414.42batches/s, l2_loss: 8.5083 - round_los\u001b[A\n",
      "Training:  53%|▌| 21508/40960 [00:47<00:45, 427.04batches/s, l2_loss: 8.5083 - round_los\u001b[A\n",
      "Training:  53%|▌| 21508/40960 [00:47<00:45, 427.04batches/s, l2_loss: 8.5057 - round_los\u001b[A\n",
      "Training:  53%|▌| 21599/40960 [00:47<00:44, 434.98batches/s, l2_loss: 8.5057 - round_los\u001b[A\n",
      "Training:  53%|▌| 21599/40960 [00:47<00:44, 434.98batches/s, l2_loss: 8.5037 - round_los\u001b[A\n",
      "Training:  53%|▌| 21687/40960 [00:47<00:44, 435.71batches/s, l2_loss: 8.5037 - round_los\u001b[A\n",
      "Training:  53%|▌| 21687/40960 [00:47<00:44, 435.71batches/s, l2_loss: 8.4979 - round_los\u001b[A\n",
      "Training:  53%|▌| 21780/40960 [00:47<00:43, 443.60batches/s, l2_loss: 8.4979 - round_los\u001b[A\n",
      "Training:  53%|▌| 21780/40960 [00:47<00:43, 443.60batches/s, l2_loss: 8.4955 - round_los\u001b[A\n",
      "Training:  53%|▌| 21871/40960 [00:48<00:42, 446.30batches/s, l2_loss: 8.4955 - round_los\u001b[A\n",
      "Training:  53%|▌| 21871/40960 [00:48<00:42, 446.30batches/s, l2_loss: 8.4922 - round_los\u001b[A\n",
      "Training:  54%|▌| 21964/40960 [00:48<00:42, 450.56batches/s, l2_loss: 8.4922 - round_los\u001b[A\n",
      "Training:  54%|▌| 21964/40960 [00:48<00:42, 450.56batches/s, l2_loss: 8.4901 - round_los\u001b[A\n",
      "Training:  54%|▌| 22057/40960 [00:48<00:41, 454.03batches/s, l2_loss: 8.4901 - round_los\u001b[A\n",
      "Training:  54%|▌| 22057/40960 [00:48<00:41, 454.03batches/s, l2_loss: 8.4848 - round_los\u001b[A\n",
      "Training:  54%|▌| 22148/40960 [00:48<00:41, 454.18batches/s, l2_loss: 8.4848 - round_los\u001b[A\n",
      "Training:  54%|▌| 22148/40960 [00:48<00:41, 454.18batches/s, l2_loss: 8.4830 - round_los\u001b[A\n",
      "Training:  54%|▌| 22241/40960 [00:48<00:41, 456.25batches/s, l2_loss: 8.4830 - round_los\u001b[A\n",
      "Training:  54%|▌| 22241/40960 [00:48<00:41, 456.25batches/s, l2_loss: 8.4791 - round_los\u001b[A\n",
      "Training:  55%|▌| 22334/40960 [00:49<00:40, 458.63batches/s, l2_loss: 8.4791 - round_los\u001b[A\n",
      "Training:  55%|▌| 22334/40960 [00:49<00:40, 458.63batches/s, l2_loss: 8.4761 - round_los\u001b[A\n",
      "Training:  55%|▌| 22426/40960 [00:49<00:40, 457.60batches/s, l2_loss: 8.4761 - round_los\u001b[A\n",
      "Training:  55%|▌| 22426/40960 [00:49<00:40, 457.60batches/s, l2_loss: 8.4742 - round_los\u001b[A\n",
      "Training:  55%|▌| 22517/40960 [00:49<00:40, 455.25batches/s, l2_loss: 8.4742 - round_los\u001b[A\n",
      "Training:  55%|▌| 22517/40960 [00:49<00:40, 455.25batches/s, l2_loss: 8.4708 - round_los\u001b[A\n",
      "Training:  55%|▌| 22608/40960 [00:49<00:40, 454.99batches/s, l2_loss: 8.4708 - round_los\u001b[A\n",
      "Training:  55%|▌| 22608/40960 [00:49<00:40, 454.99batches/s, l2_loss: 8.4686 - round_los\u001b[A\n",
      "Training:  55%|▌| 22700/40960 [00:49<00:40, 455.28batches/s, l2_loss: 8.4686 - round_los\u001b[A\n",
      "Training:  55%|▌| 22700/40960 [00:49<00:40, 455.28batches/s, l2_loss: 8.4660 - round_los\u001b[A\n",
      "Training:  56%|▌| 22790/40960 [00:50<00:40, 453.28batches/s, l2_loss: 8.4660 - round_los\u001b[A\n",
      "Training:  56%|▌| 22790/40960 [00:50<00:40, 453.28batches/s, l2_loss: 8.4613 - round_los\u001b[A\n",
      "Training:  56%|▌| 22880/40960 [00:50<00:40, 451.19batches/s, l2_loss: 8.4613 - round_los\u001b[A\n",
      "Training:  56%|▌| 22880/40960 [00:50<00:40, 451.19batches/s, l2_loss: 8.4585 - round_los\u001b[A\n",
      "Training:  56%|▌| 22971/40960 [00:50<00:39, 451.73batches/s, l2_loss: 8.4585 - round_los\u001b[A\n",
      "Training:  56%|▌| 22971/40960 [00:50<00:39, 451.73batches/s, l2_loss: 8.4544 - round_los\u001b[A\n",
      "Training:  56%|▌| 23063/40960 [00:50<00:39, 454.15batches/s, l2_loss: 8.4544 - round_los\u001b[A\n",
      "Training:  56%|▌| 23063/40960 [00:50<00:39, 454.15batches/s, l2_loss: 8.4525 - round_los\u001b[A\n",
      "Training:  57%|▌| 23155/40960 [00:50<00:39, 454.64batches/s, l2_loss: 8.4525 - round_los\u001b[A\n",
      "Training:  57%|▌| 23155/40960 [00:50<00:39, 454.64batches/s, l2_loss: 8.4495 - round_los\u001b[A\n",
      "Training:  57%|▌| 23247/40960 [00:51<00:38, 454.72batches/s, l2_loss: 8.4495 - round_los\u001b[A\n",
      "Training:  57%|▌| 23247/40960 [00:51<00:38, 454.72batches/s, l2_loss: 8.4474 - round_los\u001b[A\n",
      "Training:  57%|▌| 23338/40960 [00:51<00:38, 453.87batches/s, l2_loss: 8.4474 - round_los\u001b[A\n",
      "Training:  57%|▌| 23338/40960 [00:51<00:38, 453.87batches/s, l2_loss: 8.4435 - round_los\u001b[A\n",
      "Training:  57%|▌| 23431/40960 [00:51<00:38, 455.95batches/s, l2_loss: 8.4435 - round_los\u001b[A\n",
      "Training:  57%|▌| 23431/40960 [00:51<00:38, 455.95batches/s, l2_loss: 8.4411 - round_los\u001b[A\n",
      "Training:  57%|▌| 23522/40960 [00:51<00:38, 455.17batches/s, l2_loss: 8.4411 - round_los\u001b[A\n",
      "Training:  57%|▌| 23522/40960 [00:51<00:38, 455.17batches/s, l2_loss: 8.4368 - round_los\u001b[A\n",
      "Training:  58%|▌| 23615/40960 [00:51<00:37, 457.69batches/s, l2_loss: 8.4368 - round_los\u001b[A\n",
      "Training:  58%|▌| 23615/40960 [00:51<00:37, 457.69batches/s, l2_loss: 8.4347 - round_los\u001b[A\n",
      "Training:  58%|▌| 23704/40960 [00:52<00:38, 453.03batches/s, l2_loss: 8.4347 - round_los\u001b[A\n",
      "Training:  58%|▌| 23704/40960 [00:52<00:38, 453.03batches/s, l2_loss: 8.4323 - round_los\u001b[A\n",
      "Training:  58%|▌| 23794/40960 [00:52<00:38, 451.14batches/s, l2_loss: 8.4323 - round_los\u001b[A\n",
      "Training:  58%|▌| 23794/40960 [00:52<00:38, 451.14batches/s, l2_loss: 8.4291 - round_los\u001b[A\n",
      "Training:  58%|▌| 23884/40960 [00:52<00:37, 449.56batches/s, l2_loss: 8.4291 - round_los\u001b[A\n",
      "Training:  58%|▌| 23884/40960 [00:52<00:37, 449.56batches/s, l2_loss: 8.4253 - round_los\u001b[A\n",
      "Training:  59%|▌| 23976/40960 [00:52<00:37, 451.31batches/s, l2_loss: 8.4253 - round_los\u001b[A\n",
      "Training:  59%|▌| 23976/40960 [00:52<00:37, 451.31batches/s, l2_loss: 8.4223 - round_los\u001b[A\n",
      "Training:  59%|▌| 24066/40960 [00:52<00:37, 449.49batches/s, l2_loss: 8.4223 - round_los\u001b[A\n",
      "Training:  59%|▌| 24066/40960 [00:52<00:37, 449.49batches/s, l2_loss: 8.4201 - round_los\u001b[A\n",
      "Training:  59%|▌| 24157/40960 [00:53<00:37, 450.03batches/s, l2_loss: 8.4201 - round_los\u001b[A\n",
      "Training:  59%|▌| 24157/40960 [00:53<00:37, 450.03batches/s, l2_loss: 8.4163 - round_los\u001b[A\n",
      "Training:  59%|▌| 24250/40960 [00:53<00:36, 453.02batches/s, l2_loss: 8.4163 - round_los\u001b[A\n",
      "Training:  59%|▌| 24250/40960 [00:53<00:36, 453.02batches/s, l2_loss: 8.4146 - round_los\u001b[A\n",
      "Training:  59%|▌| 24339/40960 [00:53<00:36, 449.85batches/s, l2_loss: 8.4146 - round_los\u001b[A\n",
      "Training:  59%|▌| 24339/40960 [00:53<00:36, 449.85batches/s, l2_loss: 8.4099 - round_los\u001b[A\n",
      "Training:  60%|▌| 24431/40960 [00:53<00:36, 452.54batches/s, l2_loss: 8.4099 - round_los\u001b[A\n",
      "Training:  60%|▌| 24431/40960 [00:53<00:36, 452.54batches/s, l2_loss: 8.4081 - round_los\u001b[A\n",
      "Training:  60%|▌| 24512/40960 [00:53<00:37, 436.53batches/s, l2_loss: 8.4081 - round_los\u001b[A\n",
      "Training:  60%|▌| 24512/40960 [00:53<00:37, 436.53batches/s, l2_loss: 8.4067 - round_los\u001b[A\n",
      "Training:  60%|▌| 24596/40960 [00:54<00:38, 430.59batches/s, l2_loss: 8.4067 - round_los\u001b[A\n",
      "Training:  60%|▌| 24596/40960 [00:54<00:38, 430.59batches/s, l2_loss: 8.4022 - round_los\u001b[A\n",
      "Training:  60%|▌| 24685/40960 [00:54<00:37, 433.92batches/s, l2_loss: 8.4022 - round_los\u001b[A\n",
      "Training:  60%|▌| 24685/40960 [00:54<00:37, 433.92batches/s, l2_loss: 8.4008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24778/40960 [00:54<00:36, 442.71batches/s, l2_loss: 8.4008 - round_los\u001b[A\n",
      "Training:  60%|▌| 24778/40960 [00:54<00:36, 442.71batches/s, l2_loss: 8.3981 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|▌| 24867/40960 [00:54<00:36, 443.33batches/s, l2_loss: 8.3981 - round_los\u001b[A\n",
      "Training:  61%|▌| 24867/40960 [00:54<00:36, 443.33batches/s, l2_loss: 8.3954 - round_los\u001b[A\n",
      "Training:  61%|▌| 24957/40960 [00:54<00:36, 443.89batches/s, l2_loss: 8.3954 - round_los\u001b[A\n",
      "Training:  61%|▌| 24957/40960 [00:55<00:36, 443.89batches/s, l2_loss: 8.3927 - round_los\u001b[A\n",
      "Training:  61%|▌| 25023/40960 [00:55<00:38, 409.26batches/s, l2_loss: 8.3927 - round_los\u001b[A\n",
      "Training:  61%|▌| 25023/40960 [00:55<00:38, 409.26batches/s, l2_loss: 8.3913 - round_los\u001b[A\n",
      "Training:  61%|▌| 25078/40960 [00:55<00:43, 368.62batches/s, l2_loss: 8.3913 - round_los\u001b[A\n",
      "Training:  61%|▌| 25078/40960 [00:55<00:43, 368.62batches/s, l2_loss: 8.3897 - round_los\u001b[A\n",
      "Training:  61%|▌| 25159/40960 [00:55<00:41, 378.58batches/s, l2_loss: 8.3897 - round_los\u001b[A\n",
      "Training:  61%|▌| 25159/40960 [00:55<00:41, 378.58batches/s, l2_loss: 8.3868 - round_los\u001b[A\n",
      "Training:  62%|▌| 25234/40960 [00:55<00:41, 376.73batches/s, l2_loss: 8.3868 - round_los\u001b[A\n",
      "Training:  62%|▌| 25234/40960 [00:55<00:41, 376.73batches/s, l2_loss: 8.3848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25308/40960 [00:56<00:41, 374.22batches/s, l2_loss: 8.3848 - round_los\u001b[A\n",
      "Training:  62%|▌| 25308/40960 [00:56<00:41, 374.22batches/s, l2_loss: 8.3822 - round_los\u001b[A\n",
      "Training:  62%|▌| 25400/40960 [00:56<00:38, 399.00batches/s, l2_loss: 8.3822 - round_los\u001b[A\n",
      "Training:  62%|▌| 25400/40960 [00:56<00:38, 399.00batches/s, l2_loss: 8.3807 - round_los\u001b[A\n",
      "Training:  62%|▌| 25475/40960 [00:56<00:39, 390.69batches/s, l2_loss: 8.3807 - round_los\u001b[A\n",
      "Training:  62%|▌| 25475/40960 [00:56<00:39, 390.69batches/s, l2_loss: 8.3784 - round_los\u001b[A\n",
      "Training:  62%|▌| 25565/40960 [00:56<00:37, 408.30batches/s, l2_loss: 8.3784 - round_los\u001b[A\n",
      "Training:  62%|▌| 25565/40960 [00:56<00:37, 408.30batches/s, l2_loss: 8.3759 - round_los\u001b[A\n",
      "Training:  63%|▋| 25655/40960 [00:56<00:36, 419.71batches/s, l2_loss: 8.3759 - round_los\u001b[A\n",
      "Training:  63%|▋| 25655/40960 [00:56<00:36, 419.71batches/s, l2_loss: 8.3736 - round_los\u001b[A\n",
      "Training:  63%|▋| 25744/40960 [00:57<00:35, 426.92batches/s, l2_loss: 8.3736 - round_los\u001b[A\n",
      "Training:  63%|▋| 25744/40960 [00:57<00:35, 426.92batches/s, l2_loss: 8.3706 - round_los\u001b[A\n",
      "Training:  63%|▋| 25834/40960 [00:57<00:34, 433.05batches/s, l2_loss: 8.3706 - round_los\u001b[A\n",
      "Training:  63%|▋| 25834/40960 [00:57<00:34, 433.05batches/s, l2_loss: 8.3682 - round_los\u001b[A\n",
      "Training:  63%|▋| 25926/40960 [00:57<00:34, 439.87batches/s, l2_loss: 8.3682 - round_los\u001b[A\n",
      "Training:  63%|▋| 25926/40960 [00:57<00:34, 439.87batches/s, l2_loss: 8.3668 - round_los\u001b[A\n",
      "Training:  64%|▋| 26017/40960 [00:57<00:33, 443.65batches/s, l2_loss: 8.3668 - round_los\u001b[A\n",
      "Training:  64%|▋| 26017/40960 [00:57<00:33, 443.65batches/s, l2_loss: 8.3640 - round_los\u001b[A\n",
      "Training:  64%|▋| 26109/40960 [00:57<00:33, 447.65batches/s, l2_loss: 8.3640 - round_los\u001b[A\n",
      "Training:  64%|▋| 26109/40960 [00:57<00:33, 447.65batches/s, l2_loss: 8.3609 - round_los\u001b[A\n",
      "Training:  64%|▋| 26203/40960 [00:58<00:32, 453.33batches/s, l2_loss: 8.3609 - round_los\u001b[A\n",
      "Training:  64%|▋| 26203/40960 [00:58<00:32, 453.33batches/s, l2_loss: 8.3587 - round_los\u001b[A\n",
      "Training:  64%|▋| 26293/40960 [00:58<00:32, 451.34batches/s, l2_loss: 8.3587 - round_los\u001b[A\n",
      "Training:  64%|▋| 26293/40960 [00:58<00:32, 451.34batches/s, l2_loss: 8.3556 - round_los\u001b[A\n",
      "Training:  64%|▋| 26384/40960 [00:58<00:32, 452.38batches/s, l2_loss: 8.3556 - round_los\u001b[A\n",
      "Training:  64%|▋| 26384/40960 [00:58<00:32, 452.38batches/s, l2_loss: 8.3534 - round_los\u001b[A\n",
      "Training:  65%|▋| 26476/40960 [00:58<00:31, 454.20batches/s, l2_loss: 8.3534 - round_los\u001b[A\n",
      "Training:  65%|▋| 26476/40960 [00:58<00:31, 454.20batches/s, l2_loss: 8.3515 - round_los\u001b[A\n",
      "Training:  65%|▋| 26568/40960 [00:58<00:31, 455.23batches/s, l2_loss: 8.3515 - round_los\u001b[A\n",
      "Training:  65%|▋| 26568/40960 [00:58<00:31, 455.23batches/s, l2_loss: 8.3499 - round_los\u001b[A\n",
      "Training:  65%|▋| 26661/40960 [00:59<00:31, 457.34batches/s, l2_loss: 8.3499 - round_los\u001b[A\n",
      "Training:  65%|▋| 26661/40960 [00:59<00:31, 457.34batches/s, l2_loss: 8.3471 - round_los\u001b[A\n",
      "Training:  65%|▋| 26750/40960 [00:59<00:31, 453.45batches/s, l2_loss: 8.3471 - round_los\u001b[A\n",
      "Training:  65%|▋| 26750/40960 [00:59<00:31, 453.45batches/s, l2_loss: 8.3448 - round_los\u001b[A\n",
      "Training:  66%|▋| 26839/40960 [00:59<00:31, 450.53batches/s, l2_loss: 8.3448 - round_los\u001b[A\n",
      "Training:  66%|▋| 26839/40960 [00:59<00:31, 450.53batches/s, l2_loss: 8.3424 - round_los\u001b[A\n",
      "Training:  66%|▋| 26930/40960 [00:59<00:31, 450.92batches/s, l2_loss: 8.3424 - round_los\u001b[A\n",
      "Training:  66%|▋| 26930/40960 [00:59<00:31, 450.92batches/s, l2_loss: 8.3398 - round_los\u001b[A\n",
      "Training:  66%|▋| 27022/40960 [00:59<00:30, 452.67batches/s, l2_loss: 8.3398 - round_los\u001b[A\n",
      "Training:  66%|▋| 27022/40960 [00:59<00:30, 452.67batches/s, l2_loss: 8.3377 - round_los\u001b[A\n",
      "Training:  66%|▋| 27111/40960 [01:00<00:30, 449.82batches/s, l2_loss: 8.3377 - round_los\u001b[A\n",
      "Training:  66%|▋| 27111/40960 [01:00<00:30, 449.82batches/s, l2_loss: 8.3351 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:00<00:30, 448.25batches/s, l2_loss: 8.3351 - round_los\u001b[A\n",
      "Training:  66%|▋| 27200/40960 [01:00<00:30, 448.25batches/s, l2_loss: 8.3322 - round_los\u001b[A\n",
      "Training:  67%|▋| 27291/40960 [01:00<00:30, 448.95batches/s, l2_loss: 8.3322 - round_los\u001b[A\n",
      "Training:  67%|▋| 27291/40960 [01:00<00:30, 448.95batches/s, l2_loss: 8.3307 - round_los\u001b[A\n",
      "Training:  67%|▋| 27382/40960 [01:00<00:30, 450.44batches/s, l2_loss: 8.3307 - round_los\u001b[A\n",
      "Training:  67%|▋| 27382/40960 [01:00<00:30, 450.44batches/s, l2_loss: 8.3285 - round_los\u001b[A\n",
      "Training:  67%|▋| 27476/40960 [01:00<00:29, 455.18batches/s, l2_loss: 8.3285 - round_los\u001b[A\n",
      "Training:  67%|▋| 27476/40960 [01:00<00:29, 455.18batches/s, l2_loss: 8.3261 - round_los\u001b[A\n",
      "Training:  67%|▋| 27570/40960 [01:01<00:29, 458.83batches/s, l2_loss: 8.3261 - round_los\u001b[A\n",
      "Training:  67%|▋| 27570/40960 [01:01<00:29, 458.83batches/s, l2_loss: 8.3233 - round_los\u001b[A\n",
      "Training:  68%|▋| 27662/40960 [01:01<00:29, 457.87batches/s, l2_loss: 8.3233 - round_los\u001b[A\n",
      "Training:  68%|▋| 27662/40960 [01:01<00:29, 457.87batches/s, l2_loss: 8.3214 - round_los\u001b[A\n",
      "Training:  68%|▋| 27756/40960 [01:01<00:28, 460.09batches/s, l2_loss: 8.3214 - round_los\u001b[A\n",
      "Training:  68%|▋| 27756/40960 [01:01<00:28, 460.09batches/s, l2_loss: 8.3189 - round_los\u001b[A\n",
      "Training:  68%|▋| 27848/40960 [01:01<00:28, 458.54batches/s, l2_loss: 8.3189 - round_los\u001b[A\n",
      "Training:  68%|▋| 27848/40960 [01:01<00:28, 458.54batches/s, l2_loss: 8.3165 - round_los\u001b[A\n",
      "Training:  68%|▋| 27935/40960 [01:01<00:28, 450.31batches/s, l2_loss: 8.3165 - round_los\u001b[A\n",
      "Training:  68%|▋| 27935/40960 [01:01<00:28, 450.31batches/s, l2_loss: 8.3146 - round_los\u001b[A\n",
      "Training:  68%|▋| 28011/40960 [01:02<00:30, 428.02batches/s, l2_loss: 8.3146 - round_los\u001b[A\n",
      "Training:  68%|▋| 28011/40960 [01:02<00:30, 428.02batches/s, l2_loss: 8.3133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28097/40960 [01:02<00:30, 427.30batches/s, l2_loss: 8.3133 - round_los\u001b[A\n",
      "Training:  69%|▋| 28097/40960 [01:02<00:30, 427.30batches/s, l2_loss: 8.3102 - round_los\u001b[A\n",
      "Training:  69%|▋| 28188/40960 [01:02<00:29, 435.12batches/s, l2_loss: 8.3102 - round_los\u001b[A\n",
      "Training:  69%|▋| 28188/40960 [01:02<00:29, 435.12batches/s, l2_loss: 8.3085 - round_los\u001b[A\n",
      "Training:  69%|▋| 28276/40960 [01:02<00:29, 436.06batches/s, l2_loss: 8.3085 - round_los\u001b[A\n",
      "Training:  69%|▋| 28276/40960 [01:02<00:29, 436.06batches/s, l2_loss: 8.3064 - round_los\u001b[A\n",
      "Training:  69%|▋| 28359/40960 [01:02<00:29, 428.74batches/s, l2_loss: 8.3064 - round_los\u001b[A\n",
      "Training:  69%|▋| 28359/40960 [01:02<00:29, 428.74batches/s, l2_loss: 8.3045 - round_los\u001b[A\n",
      "Training:  69%|▋| 28421/40960 [01:03<00:31, 392.80batches/s, l2_loss: 8.3045 - round_los\u001b[A\n",
      "Training:  69%|▋| 28421/40960 [01:03<00:31, 392.80batches/s, l2_loss: 8.3034 - round_los\u001b[A\n",
      "Training:  70%|▋| 28497/40960 [01:03<00:32, 388.85batches/s, l2_loss: 8.3034 - round_los\u001b[A\n",
      "Training:  70%|▋| 28497/40960 [01:03<00:32, 388.85batches/s, l2_loss: 8.3017 - round_los\u001b[A\n",
      "Training:  70%|▋| 28577/40960 [01:03<00:31, 390.77batches/s, l2_loss: 8.3017 - round_los\u001b[A\n",
      "Training:  70%|▋| 28577/40960 [01:03<00:31, 390.77batches/s, l2_loss: 8.2989 - round_los\u001b[A\n",
      "Training:  70%|▋| 28667/40960 [01:03<00:30, 408.20batches/s, l2_loss: 8.2989 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|▋| 28667/40960 [01:03<00:30, 408.20batches/s, l2_loss: 8.2978 - round_los\u001b[A\n",
      "Training:  70%|▋| 28757/40960 [01:03<00:29, 420.43batches/s, l2_loss: 8.2978 - round_los\u001b[A\n",
      "Training:  70%|▋| 28757/40960 [01:03<00:29, 420.43batches/s, l2_loss: 8.2950 - round_los\u001b[A\n",
      "Training:  70%|▋| 28849/40960 [01:04<00:28, 432.21batches/s, l2_loss: 8.2950 - round_los\u001b[A\n",
      "Training:  70%|▋| 28849/40960 [01:04<00:28, 432.21batches/s, l2_loss: 8.2929 - round_los\u001b[A\n",
      "Training:  71%|▋| 28940/40960 [01:04<00:27, 438.62batches/s, l2_loss: 8.2929 - round_los\u001b[A\n",
      "Training:  71%|▋| 28940/40960 [01:04<00:27, 438.62batches/s, l2_loss: 8.2908 - round_los\u001b[A\n",
      "Training:  71%|▋| 29031/40960 [01:04<00:26, 442.73batches/s, l2_loss: 8.2908 - round_los\u001b[A\n",
      "Training:  71%|▋| 29031/40960 [01:04<00:26, 442.73batches/s, l2_loss: 8.2894 - round_los\u001b[A\n",
      "Training:  71%|▋| 29120/40960 [01:04<00:26, 442.44batches/s, l2_loss: 8.2894 - round_los\u001b[A\n",
      "Training:  71%|▋| 29120/40960 [01:04<00:26, 442.44batches/s, l2_loss: 8.2878 - round_los\u001b[A\n",
      "Training:  71%|▋| 29211/40960 [01:04<00:26, 445.56batches/s, l2_loss: 8.2878 - round_los\u001b[A\n",
      "Training:  71%|▋| 29211/40960 [01:04<00:26, 445.56batches/s, l2_loss: 8.2852 - round_los\u001b[A\n",
      "Training:  72%|▋| 29302/40960 [01:05<00:26, 447.62batches/s, l2_loss: 8.2852 - round_los\u001b[A\n",
      "Training:  72%|▋| 29302/40960 [01:05<00:26, 447.62batches/s, l2_loss: 8.2832 - round_los\u001b[A\n",
      "Training:  72%|▋| 29393/40960 [01:05<00:25, 449.14batches/s, l2_loss: 8.2832 - round_los\u001b[A\n",
      "Training:  72%|▋| 29393/40960 [01:05<00:25, 449.14batches/s, l2_loss: 8.2805 - round_los\u001b[A\n",
      "Training:  72%|▋| 29486/40960 [01:05<00:25, 453.80batches/s, l2_loss: 8.2805 - round_los\u001b[A\n",
      "Training:  72%|▋| 29486/40960 [01:05<00:25, 453.80batches/s, l2_loss: 8.2793 - round_los\u001b[A\n",
      "Training:  72%|▋| 29576/40960 [01:05<00:25, 452.26batches/s, l2_loss: 8.2793 - round_los\u001b[A\n",
      "Training:  72%|▋| 29576/40960 [01:05<00:25, 452.26batches/s, l2_loss: 8.2770 - round_los\u001b[A\n",
      "Training:  72%|▋| 29667/40960 [01:05<00:24, 452.18batches/s, l2_loss: 8.2770 - round_los\u001b[A\n",
      "Training:  72%|▋| 29667/40960 [01:05<00:24, 452.18batches/s, l2_loss: 8.2755 - round_los\u001b[A\n",
      "Training:  73%|▋| 29759/40960 [01:06<00:24, 454.45batches/s, l2_loss: 8.2755 - round_los\u001b[A\n",
      "Training:  73%|▋| 29759/40960 [01:06<00:24, 454.45batches/s, l2_loss: 8.2731 - round_los\u001b[A\n",
      "Training:  73%|▋| 29851/40960 [01:06<00:24, 456.00batches/s, l2_loss: 8.2731 - round_los\u001b[A\n",
      "Training:  73%|▋| 29851/40960 [01:06<00:24, 456.00batches/s, l2_loss: 8.2706 - round_los\u001b[A\n",
      "Training:  73%|▋| 29941/40960 [01:06<00:24, 453.38batches/s, l2_loss: 8.2706 - round_los\u001b[A\n",
      "Training:  73%|▋| 29941/40960 [01:06<00:24, 453.38batches/s, l2_loss: 8.2689 - round_los\u001b[A\n",
      "Training:  73%|▋| 30035/40960 [01:06<00:23, 457.54batches/s, l2_loss: 8.2689 - round_los\u001b[A\n",
      "Training:  73%|▋| 30035/40960 [01:06<00:23, 457.54batches/s, l2_loss: 8.2668 - round_los\u001b[A\n",
      "Training:  74%|▋| 30127/40960 [01:06<00:23, 456.94batches/s, l2_loss: 8.2668 - round_los\u001b[A\n",
      "Training:  74%|▋| 30127/40960 [01:06<00:23, 456.94batches/s, l2_loss: 8.2653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30219/40960 [01:07<00:23, 457.82batches/s, l2_loss: 8.2653 - round_los\u001b[A\n",
      "Training:  74%|▋| 30219/40960 [01:07<00:23, 457.82batches/s, l2_loss: 8.2630 - round_los\u001b[A\n",
      "Training:  74%|▋| 30311/40960 [01:07<00:23, 456.01batches/s, l2_loss: 8.2630 - round_los\u001b[A\n",
      "Training:  74%|▋| 30311/40960 [01:07<00:23, 456.01batches/s, l2_loss: 8.2603 - round_los\u001b[A\n",
      "Training:  74%|▋| 30402/40960 [01:07<00:23, 455.31batches/s, l2_loss: 8.2603 - round_los\u001b[A\n",
      "Training:  74%|▋| 30402/40960 [01:07<00:23, 455.31batches/s, l2_loss: 8.2591 - round_los\u001b[A\n",
      "Training:  74%|▋| 30492/40960 [01:07<00:23, 452.53batches/s, l2_loss: 8.2591 - round_los\u001b[A\n",
      "Training:  74%|▋| 30492/40960 [01:07<00:23, 452.53batches/s, l2_loss: 8.2577 - round_los\u001b[A\n",
      "Training:  75%|▋| 30583/40960 [01:07<00:22, 452.12batches/s, l2_loss: 8.2577 - round_los\u001b[A\n",
      "Training:  75%|▋| 30583/40960 [01:07<00:22, 452.12batches/s, l2_loss: 8.2556 - round_los\u001b[A\n",
      "Training:  75%|▋| 30673/40960 [01:08<00:22, 451.01batches/s, l2_loss: 8.2556 - round_los\u001b[A\n",
      "Training:  75%|▋| 30673/40960 [01:08<00:22, 451.01batches/s, l2_loss: 8.2538 - round_los\u001b[A\n",
      "Training:  75%|▊| 30764/40960 [01:08<00:22, 451.07batches/s, l2_loss: 8.2538 - round_los\u001b[A\n",
      "Training:  75%|▊| 30764/40960 [01:08<00:22, 451.07batches/s, l2_loss: 8.2510 - round_los\u001b[A\n",
      "Training:  75%|▊| 30839/40960 [01:08<00:23, 426.95batches/s, l2_loss: 8.2510 - round_los\u001b[A\n",
      "Training:  75%|▊| 30839/40960 [01:08<00:23, 426.95batches/s, l2_loss: 8.2496 - round_los\u001b[A\n",
      "Training:  76%|▊| 30932/40960 [01:08<00:22, 437.17batches/s, l2_loss: 8.2496 - round_los\u001b[A\n",
      "Training:  76%|▊| 30932/40960 [01:08<00:22, 437.17batches/s, l2_loss: 8.2472 - round_los\u001b[A\n",
      "Training:  76%|▊| 31023/40960 [01:08<00:22, 441.90batches/s, l2_loss: 8.2472 - round_los\u001b[A\n",
      "Training:  76%|▊| 31023/40960 [01:08<00:22, 441.90batches/s, l2_loss: 8.2454 - round_los\u001b[A\n",
      "Training:  76%|▊| 31115/40960 [01:09<00:22, 447.16batches/s, l2_loss: 8.2454 - round_los\u001b[A\n",
      "Training:  76%|▊| 31115/40960 [01:09<00:22, 447.16batches/s, l2_loss: 8.2442 - round_los\u001b[A\n",
      "Training:  76%|▊| 31203/40960 [01:09<00:21, 444.50batches/s, l2_loss: 8.2442 - round_los\u001b[A\n",
      "Training:  76%|▊| 31203/40960 [01:09<00:21, 444.50batches/s, l2_loss: 8.2425 - round_los\u001b[A\n",
      "Training:  76%|▊| 31289/40960 [01:09<00:21, 439.78batches/s, l2_loss: 8.2425 - round_los\u001b[A\n",
      "Training:  76%|▊| 31289/40960 [01:09<00:21, 439.78batches/s, l2_loss: 8.2399 - round_los\u001b[A\n",
      "Training:  77%|▊| 31358/40960 [01:09<00:23, 410.92batches/s, l2_loss: 8.2399 - round_los\u001b[A\n",
      "Training:  77%|▊| 31358/40960 [01:09<00:23, 410.92batches/s, l2_loss: 8.2389 - round_los\u001b[A\n",
      "Training:  77%|▊| 31444/40960 [01:09<00:22, 415.86batches/s, l2_loss: 8.2389 - round_los\u001b[A\n",
      "Training:  77%|▊| 31444/40960 [01:09<00:22, 415.86batches/s, l2_loss: 8.2368 - round_los\u001b[A\n",
      "Training:  77%|▊| 31534/40960 [01:10<00:22, 425.34batches/s, l2_loss: 8.2368 - round_los\u001b[A\n",
      "Training:  77%|▊| 31534/40960 [01:10<00:22, 425.34batches/s, l2_loss: 8.2346 - round_los\u001b[A\n",
      "Training:  77%|▊| 31627/40960 [01:10<00:21, 435.92batches/s, l2_loss: 8.2346 - round_los\u001b[A\n",
      "Training:  77%|▊| 31627/40960 [01:10<00:21, 435.92batches/s, l2_loss: 8.2332 - round_los\u001b[A\n",
      "Training:  77%|▊| 31718/40960 [01:10<00:20, 441.32batches/s, l2_loss: 8.2332 - round_los\u001b[A\n",
      "Training:  77%|▊| 31718/40960 [01:10<00:20, 441.32batches/s, l2_loss: 8.2316 - round_los\u001b[A\n",
      "Training:  78%|▊| 31799/40960 [01:10<00:21, 429.25batches/s, l2_loss: 8.2316 - round_los\u001b[A\n",
      "Training:  78%|▊| 31799/40960 [01:10<00:21, 429.25batches/s, l2_loss: 8.2296 - round_los\u001b[A\n",
      "Training:  78%|▊| 31881/40960 [01:10<00:21, 422.97batches/s, l2_loss: 8.2296 - round_los\u001b[A\n",
      "Training:  78%|▊| 31881/40960 [01:10<00:21, 422.97batches/s, l2_loss: 8.2276 - round_los\u001b[A\n",
      "Training:  78%|▊| 31961/40960 [01:11<00:21, 415.89batches/s, l2_loss: 8.2276 - round_los\u001b[A\n",
      "Training:  78%|▊| 31961/40960 [01:11<00:21, 415.89batches/s, l2_loss: 8.2256 - round_los\u001b[A\n",
      "Training:  78%|▊| 32052/40960 [01:11<00:20, 426.61batches/s, l2_loss: 8.2256 - round_los\u001b[A\n",
      "Training:  78%|▊| 32052/40960 [01:11<00:20, 426.61batches/s, l2_loss: 8.2244 - round_los\u001b[A\n",
      "Training:  78%|▊| 32140/40960 [01:11<00:20, 429.77batches/s, l2_loss: 8.2244 - round_los\u001b[A\n",
      "Training:  78%|▊| 32140/40960 [01:11<00:20, 429.77batches/s, l2_loss: 8.2223 - round_los\u001b[A\n",
      "Training:  79%|▊| 32229/40960 [01:11<00:20, 434.16batches/s, l2_loss: 8.2223 - round_los\u001b[A\n",
      "Training:  79%|▊| 32229/40960 [01:11<00:20, 434.16batches/s, l2_loss: 8.2208 - round_los\u001b[A\n",
      "Training:  79%|▊| 32319/40960 [01:11<00:19, 438.66batches/s, l2_loss: 8.2208 - round_los\u001b[A\n",
      "Training:  79%|▊| 32319/40960 [01:11<00:19, 438.66batches/s, l2_loss: 8.2190 - round_los\u001b[A\n",
      "Training:  79%|▊| 32409/40960 [01:12<00:19, 440.88batches/s, l2_loss: 8.2190 - round_los\u001b[A\n",
      "Training:  79%|▊| 32409/40960 [01:12<00:19, 440.88batches/s, l2_loss: 8.2161 - round_los\u001b[A\n",
      "Training:  79%|▊| 32494/40960 [01:12<00:19, 436.03batches/s, l2_loss: 8.2161 - round_los\u001b[A\n",
      "Training:  79%|▊| 32494/40960 [01:12<00:19, 436.03batches/s, l2_loss: 8.2152 - round_los\u001b[A\n",
      "Training:  80%|▊| 32581/40960 [01:12<00:19, 435.58batches/s, l2_loss: 8.2152 - round_los\u001b[A\n",
      "Training:  80%|▊| 32581/40960 [01:12<00:19, 435.58batches/s, l2_loss: 8.2138 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|▊| 32670/40960 [01:12<00:18, 437.69batches/s, l2_loss: 8.2138 - round_los\u001b[A\n",
      "Training:  80%|▊| 32670/40960 [01:12<00:18, 437.69batches/s, l2_loss: 8.2112 - round_los\u001b[A\n",
      "Training:  80%|▊| 32760/40960 [01:12<00:18, 441.31batches/s, l2_loss: 8.2112 - round_los\u001b[A\n",
      "Training:  80%|▊| 32760/40960 [01:12<00:18, 441.31batches/s, l2_loss: 8.2104 - round_los\u001b[A\n",
      "Training:  80%|▊| 32848/40960 [01:13<00:18, 440.72batches/s, l2_loss: 8.2104 - round_los\u001b[A\n",
      "Training:  80%|▊| 32848/40960 [01:13<00:18, 440.72batches/s, l2_loss: 8.2086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32938/40960 [01:13<00:18, 443.28batches/s, l2_loss: 8.2086 - round_los\u001b[A\n",
      "Training:  80%|▊| 32938/40960 [01:13<00:18, 443.28batches/s, l2_loss: 8.2070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33028/40960 [01:13<00:17, 444.86batches/s, l2_loss: 8.2070 - round_los\u001b[A\n",
      "Training:  81%|▊| 33028/40960 [01:13<00:17, 444.86batches/s, l2_loss: 8.2051 - round_los\u001b[A\n",
      "Training:  81%|▊| 33110/40960 [01:13<00:18, 433.26batches/s, l2_loss: 8.2051 - round_los\u001b[A\n",
      "Training:  81%|▊| 33110/40960 [01:13<00:18, 433.26batches/s, l2_loss: 8.2031 - round_los\u001b[A\n",
      "Training:  81%|▊| 33192/40960 [01:13<00:18, 425.93batches/s, l2_loss: 8.2031 - round_los\u001b[A\n",
      "Training:  81%|▊| 33192/40960 [01:13<00:18, 425.93batches/s, l2_loss: 8.2020 - round_los\u001b[A\n",
      "Training:  81%|▊| 33266/40960 [01:14<00:18, 407.88batches/s, l2_loss: 8.2020 - round_los\u001b[A\n",
      "Training:  81%|▊| 33266/40960 [01:14<00:18, 407.88batches/s, l2_loss: 8.2008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33346/40960 [01:14<00:18, 404.92batches/s, l2_loss: 8.2008 - round_los\u001b[A\n",
      "Training:  81%|▊| 33346/40960 [01:14<00:18, 404.92batches/s, l2_loss: 8.1990 - round_los\u001b[A\n",
      "Training:  82%|▊| 33430/40960 [01:14<00:18, 408.43batches/s, l2_loss: 8.1990 - round_los\u001b[A\n",
      "Training:  82%|▊| 33430/40960 [01:14<00:18, 408.43batches/s, l2_loss: 8.1978 - round_los\u001b[A\n",
      "Training:  82%|▊| 33516/40960 [01:14<00:17, 414.60batches/s, l2_loss: 8.1978 - round_los\u001b[A\n",
      "Training:  82%|▊| 33516/40960 [01:14<00:17, 414.60batches/s, l2_loss: 8.1960 - round_los\u001b[A\n",
      "Training:  82%|▊| 33594/40960 [01:14<00:18, 405.89batches/s, l2_loss: 8.1960 - round_los\u001b[A\n",
      "Training:  82%|▊| 33594/40960 [01:14<00:18, 405.89batches/s, l2_loss: 8.1947 - round_los\u001b[A\n",
      "Training:  82%|▊| 33667/40960 [01:15<00:18, 392.20batches/s, l2_loss: 8.1947 - round_los\u001b[A\n",
      "Training:  82%|▊| 33667/40960 [01:15<00:18, 392.20batches/s, l2_loss: 8.1928 - round_los\u001b[A\n",
      "Training:  82%|▊| 33747/40960 [01:15<00:18, 394.27batches/s, l2_loss: 8.1928 - round_los\u001b[A\n",
      "Training:  82%|▊| 33747/40960 [01:15<00:18, 394.27batches/s, l2_loss: 8.1920 - round_los\u001b[A\n",
      "Training:  83%|▊| 33830/40960 [01:15<00:17, 399.73batches/s, l2_loss: 8.1920 - round_los\u001b[A\n",
      "Training:  83%|▊| 33830/40960 [01:15<00:17, 399.73batches/s, l2_loss: 8.1898 - round_los\u001b[A\n",
      "Training:  83%|▊| 33915/40960 [01:15<00:17, 405.64batches/s, l2_loss: 8.1898 - round_los\u001b[A\n",
      "Training:  83%|▊| 33915/40960 [01:15<00:17, 405.64batches/s, l2_loss: 8.1887 - round_los\u001b[A\n",
      "Training:  83%|▊| 33999/40960 [01:15<00:17, 408.81batches/s, l2_loss: 8.1887 - round_los\u001b[A\n",
      "Training:  83%|▊| 33999/40960 [01:15<00:17, 408.81batches/s, l2_loss: 8.1868 - round_los\u001b[A\n",
      "Training:  83%|▊| 34090/40960 [01:16<00:16, 422.18batches/s, l2_loss: 8.1868 - round_los\u001b[A\n",
      "Training:  83%|▊| 34090/40960 [01:16<00:16, 422.18batches/s, l2_loss: 8.1852 - round_los\u001b[A\n",
      "Training:  83%|▊| 34173/40960 [01:16<00:16, 419.03batches/s, l2_loss: 8.1852 - round_los\u001b[A\n",
      "Training:  83%|▊| 34173/40960 [01:16<00:16, 419.03batches/s, l2_loss: 8.1838 - round_los\u001b[A\n",
      "Training:  84%|▊| 34257/40960 [01:16<00:16, 418.42batches/s, l2_loss: 8.1838 - round_los\u001b[A\n",
      "Training:  84%|▊| 34257/40960 [01:16<00:16, 418.42batches/s, l2_loss: 8.1824 - round_los\u001b[A\n",
      "Training:  84%|▊| 34340/40960 [01:16<00:15, 416.43batches/s, l2_loss: 8.1824 - round_los\u001b[A\n",
      "Training:  84%|▊| 34340/40960 [01:16<00:15, 416.43batches/s, l2_loss: 8.1809 - round_los\u001b[A\n",
      "Training:  84%|▊| 34427/40960 [01:16<00:15, 421.07batches/s, l2_loss: 8.1809 - round_los\u001b[A\n",
      "Training:  84%|▊| 34427/40960 [01:16<00:15, 421.07batches/s, l2_loss: 8.1792 - round_los\u001b[A\n",
      "Training:  84%|▊| 34517/40960 [01:17<00:15, 429.13batches/s, l2_loss: 8.1792 - round_los\u001b[A\n",
      "Training:  84%|▊| 34517/40960 [01:17<00:15, 429.13batches/s, l2_loss: 8.1774 - round_los\u001b[A\n",
      "Training:  84%|▊| 34604/40960 [01:17<00:14, 429.77batches/s, l2_loss: 8.1774 - round_los\u001b[A\n",
      "Training:  84%|▊| 34604/40960 [01:17<00:14, 429.77batches/s, l2_loss: 8.1767 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [01:17<00:14, 433.77batches/s, l2_loss: 8.1767 - round_los\u001b[A\n",
      "Training:  85%|▊| 34693/40960 [01:17<00:14, 433.77batches/s, l2_loss: 8.1746 - round_los\u001b[A\n",
      "Training:  85%|▊| 34782/40960 [01:17<00:14, 436.60batches/s, l2_loss: 8.1746 - round_los\u001b[A\n",
      "Training:  85%|▊| 34782/40960 [01:17<00:14, 436.60batches/s, l2_loss: 8.1730 - round_los\u001b[A\n",
      "Training:  85%|▊| 34873/40960 [01:17<00:13, 440.91batches/s, l2_loss: 8.1730 - round_los\u001b[A\n",
      "Training:  85%|▊| 34873/40960 [01:17<00:13, 440.91batches/s, l2_loss: 8.1719 - round_los\u001b[A\n",
      "Training:  85%|▊| 34959/40960 [01:18<00:13, 437.24batches/s, l2_loss: 8.1719 - round_los\u001b[A\n",
      "Training:  85%|▊| 34959/40960 [01:18<00:13, 437.24batches/s, l2_loss: 8.1700 - round_los\u001b[A\n",
      "Training:  86%|▊| 35046/40960 [01:18<00:13, 435.62batches/s, l2_loss: 8.1700 - round_los\u001b[A\n",
      "Training:  86%|▊| 35046/40960 [01:18<00:13, 435.62batches/s, l2_loss: 8.1688 - round_los\u001b[A\n",
      "Training:  86%|▊| 35136/40960 [01:18<00:13, 438.80batches/s, l2_loss: 8.1688 - round_los\u001b[A\n",
      "Training:  86%|▊| 35136/40960 [01:18<00:13, 438.80batches/s, l2_loss: 8.1667 - round_los\u001b[A\n",
      "Training:  86%|▊| 35225/40960 [01:18<00:13, 439.64batches/s, l2_loss: 8.1667 - round_los\u001b[A\n",
      "Training:  86%|▊| 35225/40960 [01:18<00:13, 439.64batches/s, l2_loss: 8.1650 - round_los\u001b[A\n",
      "Training:  86%|▊| 35315/40960 [01:18<00:12, 441.74batches/s, l2_loss: 8.1650 - round_los\u001b[A\n",
      "Training:  86%|▊| 35315/40960 [01:18<00:12, 441.74batches/s, l2_loss: 8.1639 - round_los\u001b[A\n",
      "Training:  86%|▊| 35403/40960 [01:19<00:12, 440.93batches/s, l2_loss: 8.1639 - round_los\u001b[A\n",
      "Training:  86%|▊| 35403/40960 [01:19<00:12, 440.93batches/s, l2_loss: 8.1624 - round_los\u001b[A\n",
      "Training:  87%|▊| 35492/40960 [01:19<00:12, 441.18batches/s, l2_loss: 8.1624 - round_los\u001b[A\n",
      "Training:  87%|▊| 35492/40960 [01:19<00:12, 441.18batches/s, l2_loss: 8.1610 - round_los\u001b[A\n",
      "Training:  87%|▊| 35582/40960 [01:19<00:12, 443.42batches/s, l2_loss: 8.1610 - round_los\u001b[A\n",
      "Training:  87%|▊| 35582/40960 [01:19<00:12, 443.42batches/s, l2_loss: 8.1596 - round_los\u001b[A\n",
      "Training:  87%|▊| 35664/40960 [01:19<00:12, 433.20batches/s, l2_loss: 8.1596 - round_los\u001b[A\n",
      "Training:  87%|▊| 35664/40960 [01:19<00:12, 433.20batches/s, l2_loss: 8.1586 - round_los\u001b[A\n",
      "Training:  87%|▊| 35746/40960 [01:19<00:12, 424.96batches/s, l2_loss: 8.1586 - round_los\u001b[A\n",
      "Training:  87%|▊| 35746/40960 [01:19<00:12, 424.96batches/s, l2_loss: 8.1571 - round_los\u001b[A\n",
      "Training:  87%|▊| 35824/40960 [01:20<00:12, 413.30batches/s, l2_loss: 8.1571 - round_los\u001b[A\n",
      "Training:  87%|▊| 35824/40960 [01:20<00:12, 413.30batches/s, l2_loss: 8.1556 - round_los\u001b[A\n",
      "Training:  88%|▉| 35906/40960 [01:20<00:12, 410.93batches/s, l2_loss: 8.1556 - round_los\u001b[A\n",
      "Training:  88%|▉| 35906/40960 [01:20<00:12, 410.93batches/s, l2_loss: 8.1540 - round_los\u001b[A\n",
      "Training:  88%|▉| 35987/40960 [01:20<00:12, 408.67batches/s, l2_loss: 8.1540 - round_los\u001b[A\n",
      "Training:  88%|▉| 35987/40960 [01:20<00:12, 408.67batches/s, l2_loss: 8.1527 - round_los\u001b[A\n",
      "Training:  88%|▉| 36071/40960 [01:20<00:11, 411.71batches/s, l2_loss: 8.1527 - round_los\u001b[A\n",
      "Training:  88%|▉| 36071/40960 [01:20<00:11, 411.71batches/s, l2_loss: 8.1514 - round_los\u001b[A\n",
      "Training:  88%|▉| 36156/40960 [01:20<00:11, 414.92batches/s, l2_loss: 8.1514 - round_los\u001b[A\n",
      "Training:  88%|▉| 36156/40960 [01:20<00:11, 414.92batches/s, l2_loss: 8.1500 - round_los\u001b[A\n",
      "Training:  88%|▉| 36242/40960 [01:21<00:11, 418.16batches/s, l2_loss: 8.1500 - round_los\u001b[A\n",
      "Training:  88%|▉| 36242/40960 [01:21<00:11, 418.16batches/s, l2_loss: 8.1488 - round_los\u001b[A\n",
      "Training:  89%|▉| 36328/40960 [01:21<00:11, 420.82batches/s, l2_loss: 8.1488 - round_los\u001b[A\n",
      "Training:  89%|▉| 36328/40960 [01:21<00:11, 420.82batches/s, l2_loss: 8.1470 - round_los\u001b[A\n",
      "Training:  89%|▉| 36412/40960 [01:21<00:10, 420.10batches/s, l2_loss: 8.1470 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|▉| 36412/40960 [01:21<00:10, 420.10batches/s, l2_loss: 8.1454 - round_los\u001b[A\n",
      "Training:  89%|▉| 36498/40960 [01:21<00:10, 422.18batches/s, l2_loss: 8.1454 - round_los\u001b[A\n",
      "Training:  89%|▉| 36498/40960 [01:21<00:10, 422.18batches/s, l2_loss: 8.1442 - round_los\u001b[A\n",
      "Training:  89%|▉| 36583/40960 [01:21<00:10, 421.76batches/s, l2_loss: 8.1442 - round_los\u001b[A\n",
      "Training:  89%|▉| 36583/40960 [01:21<00:10, 421.76batches/s, l2_loss: 8.1426 - round_los\u001b[A\n",
      "Training:  89%|▉| 36652/40960 [01:22<00:10, 397.94batches/s, l2_loss: 8.1426 - round_los\u001b[A\n",
      "Training:  89%|▉| 36652/40960 [01:22<00:10, 397.94batches/s, l2_loss: 8.1423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36722/40960 [01:22<00:11, 382.72batches/s, l2_loss: 8.1423 - round_los\u001b[A\n",
      "Training:  90%|▉| 36722/40960 [01:22<00:11, 382.72batches/s, l2_loss: 8.1411 - round_los\u001b[A\n",
      "Training:  90%|▉| 36807/40960 [01:22<00:10, 394.98batches/s, l2_loss: 8.1411 - round_los\u001b[A\n",
      "Training:  90%|▉| 36807/40960 [01:22<00:10, 394.98batches/s, l2_loss: 8.1391 - round_los\u001b[A\n",
      "Training:  90%|▉| 36886/40960 [01:22<00:10, 394.23batches/s, l2_loss: 8.1391 - round_los\u001b[A\n",
      "Training:  90%|▉| 36886/40960 [01:22<00:10, 394.23batches/s, l2_loss: 8.1386 - round_los\u001b[A\n",
      "Training:  90%|▉| 36968/40960 [01:22<00:10, 398.86batches/s, l2_loss: 8.1386 - round_los\u001b[A\n",
      "Training:  90%|▉| 36968/40960 [01:22<00:10, 398.86batches/s, l2_loss: 8.1375 - round_los\u001b[A\n",
      "Training:  90%|▉| 37052/40960 [01:23<00:09, 403.86batches/s, l2_loss: 8.1375 - round_los\u001b[A\n",
      "Training:  90%|▉| 37052/40960 [01:23<00:09, 403.86batches/s, l2_loss: 8.1360 - round_los\u001b[A\n",
      "Training:  91%|▉| 37133/40960 [01:23<00:09, 403.22batches/s, l2_loss: 8.1360 - round_los\u001b[A\n",
      "Training:  91%|▉| 37133/40960 [01:23<00:09, 403.22batches/s, l2_loss: 8.1345 - round_los\u001b[A\n",
      "Training:  91%|▉| 37209/40960 [01:23<00:09, 396.24batches/s, l2_loss: 8.1345 - round_los\u001b[A\n",
      "Training:  91%|▉| 37209/40960 [01:23<00:09, 396.24batches/s, l2_loss: 8.1332 - round_los\u001b[A\n",
      "Training:  91%|▉| 37284/40960 [01:23<00:09, 389.10batches/s, l2_loss: 8.1332 - round_los\u001b[A\n",
      "Training:  91%|▉| 37284/40960 [01:23<00:09, 389.10batches/s, l2_loss: 8.1322 - round_los\u001b[A\n",
      "Training:  91%|▉| 37364/40960 [01:23<00:09, 390.96batches/s, l2_loss: 8.1322 - round_los\u001b[A\n",
      "Training:  91%|▉| 37364/40960 [01:23<00:09, 390.96batches/s, l2_loss: 8.1311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37448/40960 [01:24<00:08, 398.92batches/s, l2_loss: 8.1311 - round_los\u001b[A\n",
      "Training:  91%|▉| 37448/40960 [01:24<00:08, 398.92batches/s, l2_loss: 8.1298 - round_los\u001b[A\n",
      "Training:  92%|▉| 37537/40960 [01:24<00:08, 411.81batches/s, l2_loss: 8.1298 - round_los\u001b[A\n",
      "Training:  92%|▉| 37537/40960 [01:24<00:08, 411.81batches/s, l2_loss: 8.1282 - round_los\u001b[A\n",
      "Training:  92%|▉| 37627/40960 [01:24<00:07, 423.21batches/s, l2_loss: 8.1282 - round_los\u001b[A\n",
      "Training:  92%|▉| 37627/40960 [01:24<00:07, 423.21batches/s, l2_loss: 8.1271 - round_los\u001b[A\n",
      "Training:  92%|▉| 37717/40960 [01:24<00:07, 430.49batches/s, l2_loss: 8.1271 - round_los\u001b[A\n",
      "Training:  92%|▉| 37717/40960 [01:24<00:07, 430.49batches/s, l2_loss: 8.1262 - round_los\u001b[A\n",
      "Training:  92%|▉| 37798/40960 [01:24<00:07, 421.47batches/s, l2_loss: 8.1262 - round_los\u001b[A\n",
      "Training:  92%|▉| 37798/40960 [01:24<00:07, 421.47batches/s, l2_loss: 8.1243 - round_los\u001b[A\n",
      "Training:  92%|▉| 37879/40960 [01:25<00:07, 416.23batches/s, l2_loss: 8.1243 - round_los\u001b[A\n",
      "Training:  92%|▉| 37879/40960 [01:25<00:07, 416.23batches/s, l2_loss: 8.1236 - round_los\u001b[A\n",
      "Training:  93%|▉| 37966/40960 [01:25<00:07, 420.88batches/s, l2_loss: 8.1236 - round_los\u001b[A\n",
      "Training:  93%|▉| 37966/40960 [01:25<00:07, 420.88batches/s, l2_loss: 8.1223 - round_los\u001b[A\n",
      "Training:  93%|▉| 38055/40960 [01:25<00:06, 428.08batches/s, l2_loss: 8.1223 - round_los\u001b[A\n",
      "Training:  93%|▉| 38055/40960 [01:25<00:06, 428.08batches/s, l2_loss: 8.1208 - round_los\u001b[A\n",
      "Training:  93%|▉| 38146/40960 [01:25<00:06, 435.94batches/s, l2_loss: 8.1208 - round_los\u001b[A\n",
      "Training:  93%|▉| 38146/40960 [01:25<00:06, 435.94batches/s, l2_loss: 8.1198 - round_los\u001b[A\n",
      "Training:  93%|▉| 38233/40960 [01:25<00:06, 434.92batches/s, l2_loss: 8.1198 - round_los\u001b[A\n",
      "Training:  93%|▉| 38233/40960 [01:25<00:06, 434.92batches/s, l2_loss: 8.1184 - round_los\u001b[A\n",
      "Training:  94%|▉| 38324/40960 [01:26<00:05, 440.32batches/s, l2_loss: 8.1184 - round_los\u001b[A\n",
      "Training:  94%|▉| 38324/40960 [01:26<00:05, 440.32batches/s, l2_loss: 8.1177 - round_los\u001b[A\n",
      "Training:  94%|▉| 38414/40960 [01:26<00:05, 442.20batches/s, l2_loss: 8.1177 - round_los\u001b[A\n",
      "Training:  94%|▉| 38414/40960 [01:26<00:05, 442.20batches/s, l2_loss: 8.1160 - round_los\u001b[A\n",
      "Training:  94%|▉| 38504/40960 [01:26<00:05, 443.54batches/s, l2_loss: 8.1160 - round_los\u001b[A\n",
      "Training:  94%|▉| 38504/40960 [01:26<00:05, 443.54batches/s, l2_loss: 8.1146 - round_los\u001b[A\n",
      "Training:  94%|▉| 38580/40960 [01:26<00:05, 424.04batches/s, l2_loss: 8.1146 - round_los\u001b[A\n",
      "Training:  94%|▉| 38580/40960 [01:26<00:05, 424.04batches/s, l2_loss: 8.1138 - round_los\u001b[A\n",
      "Training:  94%|▉| 38658/40960 [01:26<00:05, 412.89batches/s, l2_loss: 8.1138 - round_los\u001b[A\n",
      "Training:  94%|▉| 38658/40960 [01:26<00:05, 412.89batches/s, l2_loss: 8.1127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38747/40960 [01:27<00:05, 421.37batches/s, l2_loss: 8.1127 - round_los\u001b[A\n",
      "Training:  95%|▉| 38747/40960 [01:27<00:05, 421.37batches/s, l2_loss: 8.1112 - round_los\u001b[A\n",
      "Training:  95%|▉| 38834/40960 [01:27<00:04, 425.24batches/s, l2_loss: 8.1112 - round_los\u001b[A\n",
      "Training:  95%|▉| 38834/40960 [01:27<00:04, 425.24batches/s, l2_loss: 8.1099 - round_los\u001b[A\n",
      "Training:  95%|▉| 38922/40960 [01:27<00:04, 428.38batches/s, l2_loss: 8.1099 - round_los\u001b[A\n",
      "Training:  95%|▉| 38922/40960 [01:27<00:04, 428.38batches/s, l2_loss: 8.1089 - round_los\u001b[A\n",
      "Training:  95%|▉| 39006/40960 [01:27<00:04, 425.22batches/s, l2_loss: 8.1089 - round_los\u001b[A\n",
      "Training:  95%|▉| 39006/40960 [01:27<00:04, 425.22batches/s, l2_loss: 8.1073 - round_los\u001b[A\n",
      "Training:  95%|▉| 39095/40960 [01:27<00:04, 430.15batches/s, l2_loss: 8.1073 - round_los\u001b[A\n",
      "Training:  95%|▉| 39095/40960 [01:27<00:04, 430.15batches/s, l2_loss: 8.1074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39175/40960 [01:28<00:04, 420.12batches/s, l2_loss: 8.1074 - round_los\u001b[A\n",
      "Training:  96%|▉| 39175/40960 [01:28<00:04, 420.12batches/s, l2_loss: 8.1058 - round_los\u001b[A\n",
      "Training:  96%|▉| 39254/40960 [01:28<00:04, 412.58batches/s, l2_loss: 8.1058 - round_los\u001b[A\n",
      "Training:  96%|▉| 39254/40960 [01:28<00:04, 412.58batches/s, l2_loss: 8.1049 - round_los\u001b[A\n",
      "Training:  96%|▉| 39340/40960 [01:28<00:03, 416.73batches/s, l2_loss: 8.1049 - round_los\u001b[A\n",
      "Training:  96%|▉| 39340/40960 [01:28<00:03, 416.73batches/s, l2_loss: 8.1031 - round_los\u001b[A\n",
      "Training:  96%|▉| 39429/40960 [01:28<00:03, 424.16batches/s, l2_loss: 8.1031 - round_los\u001b[A\n",
      "Training:  96%|▉| 39429/40960 [01:28<00:03, 424.16batches/s, l2_loss: 8.1021 - round_los\u001b[A\n",
      "Training:  96%|▉| 39518/40960 [01:28<00:03, 429.13batches/s, l2_loss: 8.1021 - round_los\u001b[A\n",
      "Training:  96%|▉| 39518/40960 [01:29<00:03, 429.13batches/s, l2_loss: 8.1013 - round_los\u001b[A\n",
      "Training:  97%|▉| 39606/40960 [01:29<00:03, 431.40batches/s, l2_loss: 8.1013 - round_los\u001b[A\n",
      "Training:  97%|▉| 39606/40960 [01:29<00:03, 431.40batches/s, l2_loss: 8.1006 - round_los\u001b[A\n",
      "Training:  97%|▉| 39699/40960 [01:29<00:02, 440.24batches/s, l2_loss: 8.1006 - round_los\u001b[A\n",
      "Training:  97%|▉| 39699/40960 [01:29<00:02, 440.24batches/s, l2_loss: 8.0989 - round_los\u001b[A\n",
      "Training:  97%|▉| 39788/40960 [01:29<00:02, 440.63batches/s, l2_loss: 8.0989 - round_los\u001b[A\n",
      "Training:  97%|▉| 39788/40960 [01:29<00:02, 440.63batches/s, l2_loss: 8.0978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39875/40960 [01:29<00:02, 438.55batches/s, l2_loss: 8.0978 - round_los\u001b[A\n",
      "Training:  97%|▉| 39875/40960 [01:29<00:02, 438.55batches/s, l2_loss: 8.0965 - round_los\u001b[A\n",
      "Training:  98%|▉| 39962/40960 [01:30<00:02, 437.39batches/s, l2_loss: 8.0965 - round_los\u001b[A\n",
      "Training:  98%|▉| 39962/40960 [01:30<00:02, 437.39batches/s, l2_loss: 8.0954 - round_los\u001b[A\n",
      "Training:  98%|▉| 40051/40960 [01:30<00:02, 439.51batches/s, l2_loss: 8.0954 - round_los\u001b[A\n",
      "Training:  98%|▉| 40051/40960 [01:30<00:02, 439.51batches/s, l2_loss: 8.0946 - round_los\u001b[A\n",
      "Training:  98%|▉| 40141/40960 [01:30<00:01, 441.94batches/s, l2_loss: 8.0946 - round_los\u001b[A\n",
      "Training:  98%|▉| 40141/40960 [01:30<00:01, 441.94batches/s, l2_loss: 8.0937 - round_los\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|▉| 40230/40960 [01:30<00:01, 442.37batches/s, l2_loss: 8.0937 - round_los\u001b[A\n",
      "Training:  98%|▉| 40230/40960 [01:30<00:01, 442.37batches/s, l2_loss: 8.0920 - round_los\u001b[A\n",
      "Training:  98%|▉| 40318/40960 [01:30<00:01, 441.59batches/s, l2_loss: 8.0920 - round_los\u001b[A\n",
      "Training:  98%|▉| 40318/40960 [01:30<00:01, 441.59batches/s, l2_loss: 8.0908 - round_los\u001b[A\n",
      "Training:  99%|▉| 40406/40960 [01:31<00:01, 440.46batches/s, l2_loss: 8.0908 - round_los\u001b[A\n",
      "Training:  99%|▉| 40406/40960 [01:31<00:01, 440.46batches/s, l2_loss: 8.0902 - round_los\u001b[A\n",
      "Training:  99%|▉| 40498/40960 [01:31<00:01, 445.59batches/s, l2_loss: 8.0902 - round_los\u001b[A\n",
      "Training:  99%|▉| 40498/40960 [01:31<00:01, 445.59batches/s, l2_loss: 8.0894 - round_los\u001b[A\n",
      "Training:  99%|▉| 40589/40960 [01:31<00:00, 447.24batches/s, l2_loss: 8.0894 - round_los\u001b[A\n",
      "Training:  99%|▉| 40589/40960 [01:31<00:00, 447.24batches/s, l2_loss: 8.0875 - round_los\u001b[A\n",
      "Training:  99%|▉| 40680/40960 [01:31<00:00, 449.25batches/s, l2_loss: 8.0875 - round_los\u001b[A\n",
      "Training:  99%|▉| 40680/40960 [01:31<00:00, 449.25batches/s, l2_loss: 8.0862 - round_los\u001b[A\n",
      "Training: 100%|▉| 40770/40960 [01:31<00:00, 448.54batches/s, l2_loss: 8.0862 - round_los\u001b[A\n",
      "Training: 100%|▉| 40770/40960 [01:31<00:00, 448.54batches/s, l2_loss: 8.0849 - round_los\u001b[A\n",
      "Training: 100%|▉| 40858/40960 [01:32<00:00, 444.72batches/s, l2_loss: 8.0849 - round_los\u001b[A\n",
      "Training: 100%|▉| 40858/40960 [01:32<00:00, 444.72batches/s, l2_loss: 8.0842 - round_los\u001b[A\n",
      "Training: 100%|▉| 40951/40960 [01:32<00:00, 449.72batches/s, l2_loss: 8.0842 - round_los\u001b[A\n",
      "Training: 100%|▉| 40951/40960 [01:32<00:00, 449.72batches/s, l2_loss: 8.0831 - round_los\u001b[A\n",
      "                                                                                        \u001b[A2025-05-20 19:04:30.715300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Adaround: 100%|█| 3/3 [05:00<00:00, 100.24s/blocks, Layers=['model_cnn21/fc1_output_0']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Adaround is done (completion time is 00:05:01.91)\n",
      "[info] Quantization-Aware Fine-Tuning skipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:04:33.111226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:33.115978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:33.116211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:33.118364: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:33.118579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:33.118845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:34.749025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:34.749282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:34.749499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:34.749653: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 19:04:34.749680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-05-20 19:04:35.168227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:35.169827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:35.170107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:35.171465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:35.171691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:35.171889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:36.800839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:36.801127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:36.801403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:04:36.801606: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 19:04:36.801635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Starting Layer Noise Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Quant Analysis:  50%|████████████            | 1/2 [00:00<00:00,  9.82iterations/s]2025-05-20 19:04:38.137666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 19:04:38.160429: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 19:04:46.186766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "Full Quant Analysis: 100%|████████████████████████| 2/2 [00:08<00:00,  4.47s/iterations]\n",
      "2025-05-20 19:04:46.963775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-05-20 19:04:46.972033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,32,32,5]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Layer Noise Analysis is done (completion time is 00:00:09.28)\n",
      "[info] Output layers signal-to-noise ratio (SNR): measures the quantization noise (higher is better)\n",
      "[info] \tmodel_cnn21/output_layer1 SNR:\t36.16 dB\n",
      "[info] Model Optimization is done\n"
     ]
    }
   ],
   "source": [
    "# Cuantizar el modelo con el dataset de calibración\n",
    "\n",
    "# For calling Optimize, use the short version: runner.optimize(calib_dataset)\n",
    "# A more general approach is being used here that works also with multiple input nodes.\n",
    "# The calibration dataset could also be a dictionary with the format:\n",
    "# {input_layer_name_1_from_hn: layer_1_calib_dataset, input_layer_name_2_from_hn: layer_2_calib_dataset}\n",
    "hn_layers = runner.get_hn_dict()[\"layers\"]\n",
    "print(\"Input layers are: \")\n",
    "print([layer for layer in hn_layers if hn_layers[layer][\"type\"] == \"input_layer\"])  # See available input layer names\n",
    "calib_dataset_dict = {\"model_cnn21/input_layer1\": calib_dataset}  # In our case there is only one input layer\n",
    "\n",
    "optimization_level = 4\n",
    "compression_level = 5\n",
    "# Mapeamos las proporciones de pesos de 4 bits según el nivel de compresión\n",
    "compression_ratios = {\n",
    "    0: 0.0,\n",
    "    1: 0.2,\n",
    "    2: 0.4,\n",
    "    3: 0.6,\n",
    "    4: 0.8,\n",
    "    5: 1.0\n",
    "}\n",
    "auto_4bit_ratio = compression_ratios.get(compression_level, 0.0)\n",
    "\n",
    "alls_lines = [\n",
    "    # \"normalization1 = normalization([123.675, 116.28, 103.53], [58.395, 57.12, 57.375])\\n\",\n",
    "    # Batch size is 8 by default; 2 was used for stability on PCs with low amount of RAM / VRAM\n",
    "    f\"model_optimization_flavor(optimization_level={optimization_level}, compression_level={compression_level}, batch_size=8)\\n\",\n",
    "    # The following line is needed because this is a really small model, and the compression_level is always reverted back to 0.'\n",
    "    # To force using compression_level with small models, the following line should be used (compression level=4 equals to 80% 4-bit):\n",
    "    f\"model_optimization_config(compression_params, auto_4bit_weights_ratio={auto_4bit_ratio})\\n\",\n",
    "    # The application of the compression could be seen by the [info] messages: \"Assigning 4bit weight to layer ..\"\n",
    "]\n",
    "\n",
    "runner.load_model_script(\"\".join(alls_lines))\n",
    "\n",
    "runner.optimize(calib_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c487df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:41.850019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:41.851191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:41.851397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:41.853478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:41.853684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:41.853873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:43.415667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:43.415903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:43.416094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-20 19:06:43.416232: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-05-20 19:06:43.416254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:43.501976: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:44.563854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-05-20 19:06:48.275712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2025-05-20 19:06:48.996718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Inference: 104entries [00:04, 22.62entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 1] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:49.507358: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:49.588820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1864.68entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 2] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:50.051909: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:50.131137: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1938.54entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 3] Error medio: 0.0200 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:50.570866: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:50.649724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2044.78entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 4] Error medio: 0.0500 ; Coincidencias: 97/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:51.118233: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:51.197066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2059.30entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 5] Error medio: 0.0000 ; Coincidencias: 100/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:51.633722: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:51.712709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1844.19entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 6] Error medio: 0.0600 ; Coincidencias: 97/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:52.149953: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:52.233551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 700.81entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 7] Error medio: 0.1300 ; Coincidencias: 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:52.797801: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:52.877736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2060.71entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 8] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:53.306186: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:53.389566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 693.25entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 9] Error medio: 0.0500 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:53.941976: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:54.020912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2070.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 10] Error medio: 0.0500 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:54.453668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:54.535152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 595.19entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 11] Error medio: 0.0300 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:55.087037: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:55.165560: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2121.92entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 12] Error medio: 0.0200 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:55.599963: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:55.683491: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 550.45entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 13] Error medio: 0.0400 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:56.250055: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:56.330308: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1932.69entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 14] Error medio: 0.0700 ; Coincidencias: 96/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:56.770070: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:56.863261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 605.82entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 15] Error medio: 0.0400 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:57.412050: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:57.492098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2073.36entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 16] Error medio: 0.1600 ; Coincidencias: 94/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:57.932180: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:58.014514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 558.05entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 17] Error medio: 0.0600 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:58.580584: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:58.661099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2005.61entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 18] Error medio: 0.0300 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:59.101734: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:59.184928: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 586.39entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 19] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:06:59.739992: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:06:59.820776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2056.56entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 20] Error medio: 0.0300 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:00.254506: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:00.337985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 544.33entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 21] Error medio: 0.0100 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:00.911438: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:00.991924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2096.23entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 22] Error medio: 0.0600 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:01.425308: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:01.508295: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 549.71entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 23] Error medio: 0.0300 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:02.076560: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:02.157402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1947.58entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 24] Error medio: 0.0200 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:02.605021: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:02.688299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 622.74entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 25] Error medio: 0.0400 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:03.241983: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:03.322065: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2098.15entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 26] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:03.754864: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:03.837789: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 571.03entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 27] Error medio: 0.0700 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:04.408332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:04.488377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2092.25entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 28] Error medio: 0.0400 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:04.929337: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:05.013420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 592.61entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 29] Error medio: 0.0300 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:05.568393: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:05.649253: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2075.61entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 30] Error medio: 0.0700 ; Coincidencias: 96/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:06.088339: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:06.172639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 586.47entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 31] Error medio: 0.0800 ; Coincidencias: 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:06.735014: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:06.816779: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2081.31entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 32] Error medio: 0.0200 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:07.252350: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:07.336794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 588.41entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 33] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:07.896408: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:07.976079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2075.99entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 34] Error medio: 0.0700 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:08.410773: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:08.494546: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 559.65entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 35] Error medio: 0.0300 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:09.059616: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:09.141083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2086.41entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 36] Error medio: 0.0600 ; Coincidencias: 97/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:09.578944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:09.662213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 586.86entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 37] Error medio: 0.0500 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:10.226453: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:10.308047: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2110.34entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 38] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:10.747419: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:10.831328: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 573.77entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 39] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:11.395792: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:11.476717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2089.60entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 40] Error medio: 0.0000 ; Coincidencias: 100/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:11.917823: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:12.002474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 545.71entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 41] Error medio: 0.0100 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:12.578145: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:12.660345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2039.00entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 42] Error medio: 0.0200 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:13.096090: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:13.181117: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 590.09entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 43] Error medio: 0.0200 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:13.739797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:13.821241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2102.01entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 44] Error medio: 0.0200 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:14.263778: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:14.349441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 607.15entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 45] Error medio: 0.0600 ; Coincidencias: 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:14.907083: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:14.987729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2071.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 46] Error medio: 0.0700 ; Coincidencias: 96/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:15.422435: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:15.507083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 575.11entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 47] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:16.077541: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:16.158824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2092.66entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 48] Error medio: 0.0000 ; Coincidencias: 100/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:16.601812: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:16.684126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 636.70entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 49] Error medio: 0.0500 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:17.231815: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:17.313072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1966.27entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 50] Error medio: 0.0700 ; Coincidencias: 97/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:17.749965: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:17.834028: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 588.34entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 51] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:18.396437: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:18.479064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1976.11entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 52] Error medio: 0.0000 ; Coincidencias: 100/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:18.918045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:19.004340: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 583.02entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 53] Error medio: 0.0700 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:19.563734: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:19.645946: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1941.74entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 54] Error medio: 0.0200 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:20.088000: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:20.172637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 612.98entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 55] Error medio: 0.0400 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:20.730547: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:20.812351: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2073.67entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 56] Error medio: 0.0400 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:21.250098: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:21.332922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 513.03entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 57] Error medio: 0.0200 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:21.919478: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:22.001195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2074.33entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 58] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:22.440187: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:22.525940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 573.39entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 59] Error medio: 0.0200 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:23.089778: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:23.171445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1942.86entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 60] Error medio: 0.0000 ; Coincidencias: 100/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:23.614182: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:23.699103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 623.87entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 61] Error medio: 0.0400 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:24.249606: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:24.334032: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2092.50entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 62] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:24.773617: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:24.857676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 559.35entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 63] Error medio: 0.0500 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:25.424899: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:25.507658: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2091.11entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 64] Error medio: 0.0400 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:25.950135: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:26.035903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 621.67entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 65] Error medio: 0.0100 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:26.589263: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:26.673021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2075.08entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 66] Error medio: 0.0300 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:27.112653: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:27.195795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 512.10entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 67] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:27.781315: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:27.864024: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2048.04entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 68] Error medio: 0.0600 ; Coincidencias: 97/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:28.301976: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:28.387784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 593.03entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 69] Error medio: 0.0100 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:28.949728: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:29.031127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2093.68entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 70] Error medio: 0.0500 ; Coincidencias: 97/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:29.465829: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:29.550894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 599.23entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 71] Error medio: 0.0100 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:30.110763: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:30.193705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2051.84entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 72] Error medio: 0.0300 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:30.630987: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:30.717275: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 591.69entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 73] Error medio: 0.0300 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:31.274955: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:31.357669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2066.97entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 74] Error medio: 0.0600 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:31.789196: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:31.875220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 588.02entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 75] Error medio: 0.0400 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:32.436100: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:32.517850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2127.20entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 76] Error medio: 0.0700 ; Coincidencias: 97/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:32.976938: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:33.065905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 584.54entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 77] Error medio: 0.0800 ; Coincidencias: 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:33.630014: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:33.714045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2018.47entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 78] Error medio: 0.1000 ; Coincidencias: 96/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:34.154925: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:34.242090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 631.34entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 79] Error medio: 0.0200 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:34.806933: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:34.892215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1942.39entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 80] Error medio: 0.0800 ; Coincidencias: 97/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:35.342868: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:35.429684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 697.13entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 81] Error medio: 0.0300 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:35.967556: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:36.049481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2124.93entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 82] Error medio: 0.1200 ; Coincidencias: 96/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:36.488395: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:36.572841: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 642.64entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 83] Error medio: 0.0400 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:37.129206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:37.212267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2051.70entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 84] Error medio: 0.0000 ; Coincidencias: 100/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:37.653670: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:37.739394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 610.89entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 85] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:38.294075: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:38.376673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2123.42entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 86] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:38.818874: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:38.905935: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 632.40entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 87] Error medio: 0.0300 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:39.456094: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:39.539243: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2092.87entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 88] Error medio: 0.0300 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:39.980370: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:40.067439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 608.07entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 89] Error medio: 0.0500 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:40.624871: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:40.709948: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2006.41entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 90] Error medio: 0.0200 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:41.151970: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:41.237256: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 644.97entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 91] Error medio: 0.0100 ; Coincidencias: 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:41.790649: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:41.876474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 1954.98entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 92] Error medio: 0.0800 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:42.325217: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:42.412108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 682.53entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 93] Error medio: 0.0200 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:42.950532: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:43.034546: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2061.50entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 94] Error medio: 0.0200 ; Coincidencias: 98/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:43.479879: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:43.566611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 661.94entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 95] Error medio: 0.0000 ; Coincidencias: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:44.115752: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:44.199876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2123.82entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 96] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:44.635766: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:44.721765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 625.51entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 97] Error medio: 0.0400 ; Coincidencias: 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:45.277738: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:45.362545: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2084.43entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 98] Error medio: 0.0300 ; Coincidencias: 99/100\n",
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:45.802746: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:45.888166: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 623.10entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 99] Error medio: 0.0700 ; Coincidencias: 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 1 GPU for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 19:07:46.438045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "Inference: 0entries [00:00, ?entries/s]2025-05-20 19:07:46.521654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Inference: 104entries [00:00, 2098.89entries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteración 100] Error medio: 0.0100 ; Coincidencias: 99/100\n",
      "Resultados globales para 10000 predicciones (100 iteraciones):\n",
      "Error medio absoluto (promedio): 0.035600\n",
      "Precisión global: 98.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en HAR cuantizado\n",
    "\n",
    "total_error = 0\n",
    "total_matches = 0\n",
    "total_elements = 0\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    \n",
    "    inputs_np = inputs.numpy()\n",
    "\n",
    "    # Inferencia para el modelo en ONNX\n",
    "    outputs = ort_session.run(None, {'input': inputs_np})\n",
    "    preds_onnx=np.argmax(outputs[0], axis=1) # outputs[0] contiene las predicciones\n",
    "\n",
    "    # Inferencia para el modelo en HAR\n",
    "    with runner.infer_context(InferenceContext.SDK_QUANTIZED) as ctx:\n",
    "        inputs_har = np.transpose(inputs.numpy(), (0, 2, 3, 1))\n",
    "\n",
    "        # Realizar la inferencia en el modelo .har\n",
    "        native_res = runner.infer(ctx, inputs_har)\n",
    "        \n",
    "        preds_har=np.argmax(native_res, axis=-1).squeeze()\n",
    "\n",
    "    # Comparar la diferencia entre ONNX y har utilizando el error medio absoluto\n",
    "    error = np.abs(preds_onnx - preds_har).mean()\n",
    "    total_error += error\n",
    "    \n",
    "    # Comparacion exacta\n",
    "    matches = np.sum(preds_onnx == preds_har)\n",
    "    total_matches += matches\n",
    "    total_elements += preds_onnx.size\n",
    "    \n",
    "    print(f\"[Iteración {i+1}] Error medio: {error:.4f} ; Coincidencias: {matches}/{preds_onnx.size}\")\n",
    "    \n",
    "# Resultados globales\n",
    "mean_error = total_error / num_iters\n",
    "accuracy = total_matches / total_elements\n",
    "\n",
    "print(f\"Resultados globales para {total_elements} predicciones ({num_iters} iteraciones):\")\n",
    "print(f\"Error medio absoluto (promedio): {mean_error:.6f}\")\n",
    "print(f\"Precisión global: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61eebb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Saved HAR to: /home/pablo/Documentos/Enxeñaría Informática/Cuarto/2º Cuatrimestre/Traballo Fin de Grao/hyper-rpi/results/model_cnn21_quantized_model_o4_c5.har\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo cuantizado\n",
    "# Let's save the runner's state to a Quantized HAR\n",
    "quantized_model_har_path = f\"{model_name}_quantized_model_o{optimization_level}_c{compression_level}.har\"\n",
    "runner.save_har(quantized_model_har_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24260b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b9b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e8585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e46da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bddfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad4227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f51e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6bf698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f531731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5561f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ada418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fb9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hailo_gpu_env] *",
   "language": "python",
   "name": "conda-env-hailo_gpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
